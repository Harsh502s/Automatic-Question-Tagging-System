{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import tensorflow as tf\n",
    "from transformers import BartTokenizer, TFBartModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Head</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tags Count</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brain segmentation to 3d model</td>\n",
       "      <td>my goal is to take a dataset of brain tumor s...</td>\n",
       "      <td>['computer-vision', 'python']</td>\n",
       "      <td>brain segmentation to 3d model  my goal is to ...</td>\n",
       "      <td>2</td>\n",
       "      <td>brain segmentation 3d model goal dataset brain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>active learning regression with random forest</td>\n",
       "      <td>i have a dataset of about 8k points and i am ...</td>\n",
       "      <td>['machine-learning', 'regression', 'uncertaint...</td>\n",
       "      <td>active learning regression with random forest ...</td>\n",
       "      <td>5</td>\n",
       "      <td>active learn regression random forest dataset ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comparing reinforcement learning models</td>\n",
       "      <td>i am currently completing my thesis on optimi...</td>\n",
       "      <td>['reinforcement-learning', 'policy-gradients',...</td>\n",
       "      <td>comparing reinforcement learning models  i am ...</td>\n",
       "      <td>4</td>\n",
       "      <td>compare reinforcement learning model currently...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>why good model that performs great on holdout ...</td>\n",
       "      <td>i have this binary regression model that has ...</td>\n",
       "      <td>['deep-learning', 'deep-neural-networks', 'pre...</td>\n",
       "      <td>why good model that performs great on holdout ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good model perform great holdout validation da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are reservoir computers used for today</td>\n",
       "      <td>reservoir computers were very popular in the ...</td>\n",
       "      <td>['machine-learning', 'recurrent-neural-network...</td>\n",
       "      <td>what are reservoir computers used for today   ...</td>\n",
       "      <td>3</td>\n",
       "      <td>reservoir computer today reservoir computer po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48798</th>\n",
       "      <td>where to get older digital ocr d data sets of ...</td>\n",
       "      <td>i am trying to locate older unsummarized us c...</td>\n",
       "      <td>['data-request', 'usa', 'us-census']</td>\n",
       "      <td>where to get older digital ocr d data sets of ...</td>\n",
       "      <td>3</td>\n",
       "      <td>old digital ocr datum set unsummarized census ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48799</th>\n",
       "      <td>orthophoto rwanda free download</td>\n",
       "      <td>i m looking for image datas for east africa s...</td>\n",
       "      <td>['data-request', 'images', 'aerial-photography...</td>\n",
       "      <td>orthophoto rwanda free download   i m looking ...</td>\n",
       "      <td>4</td>\n",
       "      <td>orthophoto rwanda free download look image dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48800</th>\n",
       "      <td>finding online finance datasets</td>\n",
       "      <td>i am searching for finance datasets that has ...</td>\n",
       "      <td>['data-request', 'finance']</td>\n",
       "      <td>finding online finance datasets  i am searchin...</td>\n",
       "      <td>2</td>\n",
       "      <td>find online finance dataset search finance dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48801</th>\n",
       "      <td>healthcare finder api links broken</td>\n",
       "      <td>it seems that the healthcare finder api schem...</td>\n",
       "      <td>['healthcare-finder-api']</td>\n",
       "      <td>healthcare finder api links broken   it seems ...</td>\n",
       "      <td>1</td>\n",
       "      <td>healthcare finder api link break healthcare fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48802</th>\n",
       "      <td>hios plan year 2016 xsd schema</td>\n",
       "      <td>can someone provide a link to the new plan ye...</td>\n",
       "      <td>['data-format', 'healthcare-finder-api']</td>\n",
       "      <td>hios plan year 2016 xsd schema  can someone pr...</td>\n",
       "      <td>2</td>\n",
       "      <td>hios plan year 2016 xsd schema provide link ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48803 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Head  \\\n",
       "0                         brain segmentation to 3d model   \n",
       "1          active learning regression with random forest   \n",
       "2                comparing reinforcement learning models   \n",
       "3      why good model that performs great on holdout ...   \n",
       "4           what are reservoir computers used for today    \n",
       "...                                                  ...   \n",
       "48798  where to get older digital ocr d data sets of ...   \n",
       "48799                   orthophoto rwanda free download    \n",
       "48800                    finding online finance datasets   \n",
       "48801                healthcare finder api links broken    \n",
       "48802                     hios plan year 2016 xsd schema   \n",
       "\n",
       "                                                    Body  \\\n",
       "0       my goal is to take a dataset of brain tumor s...   \n",
       "1       i have a dataset of about 8k points and i am ...   \n",
       "2       i am currently completing my thesis on optimi...   \n",
       "3       i have this binary regression model that has ...   \n",
       "4       reservoir computers were very popular in the ...   \n",
       "...                                                  ...   \n",
       "48798   i am trying to locate older unsummarized us c...   \n",
       "48799   i m looking for image datas for east africa s...   \n",
       "48800   i am searching for finance datasets that has ...   \n",
       "48801   it seems that the healthcare finder api schem...   \n",
       "48802   can someone provide a link to the new plan ye...   \n",
       "\n",
       "                                                    Tags  \\\n",
       "0                          ['computer-vision', 'python']   \n",
       "1      ['machine-learning', 'regression', 'uncertaint...   \n",
       "2      ['reinforcement-learning', 'policy-gradients',...   \n",
       "3      ['deep-learning', 'deep-neural-networks', 'pre...   \n",
       "4      ['machine-learning', 'recurrent-neural-network...   \n",
       "...                                                  ...   \n",
       "48798               ['data-request', 'usa', 'us-census']   \n",
       "48799  ['data-request', 'images', 'aerial-photography...   \n",
       "48800                        ['data-request', 'finance']   \n",
       "48801                          ['healthcare-finder-api']   \n",
       "48802           ['data-format', 'healthcare-finder-api']   \n",
       "\n",
       "                                                    Text  Tags Count  \\\n",
       "0      brain segmentation to 3d model  my goal is to ...           2   \n",
       "1      active learning regression with random forest ...           5   \n",
       "2      comparing reinforcement learning models  i am ...           4   \n",
       "3      why good model that performs great on holdout ...           5   \n",
       "4      what are reservoir computers used for today   ...           3   \n",
       "...                                                  ...         ...   \n",
       "48798  where to get older digital ocr d data sets of ...           3   \n",
       "48799  orthophoto rwanda free download   i m looking ...           4   \n",
       "48800  finding online finance datasets  i am searchin...           2   \n",
       "48801  healthcare finder api links broken   it seems ...           1   \n",
       "48802  hios plan year 2016 xsd schema  can someone pr...           2   \n",
       "\n",
       "                                            Text_Cleaned  \n",
       "0      brain segmentation 3d model goal dataset brain...  \n",
       "1      active learn regression random forest dataset ...  \n",
       "2      compare reinforcement learning model currently...  \n",
       "3      good model perform great holdout validation da...  \n",
       "4      reservoir computer today reservoir computer po...  \n",
       "...                                                  ...  \n",
       "48798  old digital ocr datum set unsummarized census ...  \n",
       "48799  orthophoto rwanda free download look image dat...  \n",
       "48800  find online finance dataset search finance dat...  \n",
       "48801  healthcare finder api link break healthcare fi...  \n",
       "48802  hios plan year 2016 xsd schema provide link ne...  \n",
       "\n",
       "[48803 rows x 6 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/cleaned_data_2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2686\n"
     ]
    }
   ],
   "source": [
    "df['Tags'] = df['Tags'].apply(lambda x: literal_eval(x))\n",
    "all_tags = [item for sublist in df['Tags'].values for item in sublist]\n",
    "\n",
    "# Get all unique tags\n",
    "unique_tags = list(set(all_tags))\n",
    "print(len(unique_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['machine-learning',\n",
       " 'r',\n",
       " 'regression',\n",
       " 'deep-learning',\n",
       " 'neural-networks',\n",
       " 'data-request',\n",
       " 'python',\n",
       " 'reinforcement-learning',\n",
       " 'classification',\n",
       " 'time-series',\n",
       " 'probability',\n",
       " 'neural-network',\n",
       " 'distributions',\n",
       " 'bayesian',\n",
       " 'hypothesis-testing',\n",
       " 'keras',\n",
       " 'mathematical-statistics',\n",
       " 'scikit-learn',\n",
       " 'logistic',\n",
       " 'convolutional-neural-networks',\n",
       " 'clustering',\n",
       " 'tensorflow',\n",
       " 'terminology',\n",
       " 'nlp',\n",
       " 'correlation',\n",
       " 'self-study',\n",
       " 'normal-distribution',\n",
       " 'geospatial',\n",
       " 'cross-validation',\n",
       " 'optimization',\n",
       " 'random-forest',\n",
       " 'mixed-model',\n",
       " 'data-mining',\n",
       " 'feature-selection',\n",
       " 'pca']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(all_tags)\n",
    "frequencies_words = counts.most_common(35)\n",
    "tags_features = [word[0] for word in frequencies_words]\n",
    "tags_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(tags):\n",
    "    tags_filtered = []\n",
    "    for i in range(0, len(tags)):\n",
    "        if tags[i] in tags_features:\n",
    "            tags_filtered.append(tags[i])\n",
    "    return tags_filtered\n",
    "\n",
    "df['Tags'] = df['Tags'].apply(lambda x: most_common(x))\n",
    "df['Tags'] = df['Tags'].apply(lambda x: x if len(x)>0 else None)\n",
    "\n",
    "df = df.dropna(subset=['Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Head</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tags Count</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19322</th>\n",
       "      <td>sampling from skew normal distribution</td>\n",
       "      <td>i want to draw samples from a skew normal dis...</td>\n",
       "      <td>[distributions]</td>\n",
       "      <td>sampling from skew normal distribution  i want...</td>\n",
       "      <td>5</td>\n",
       "      <td>sample skew normal distribution want draw samp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517</th>\n",
       "      <td>hypothesis test for difference in medians amon...</td>\n",
       "      <td>question the test scores of three groups of p...</td>\n",
       "      <td>[r, hypothesis-testing]</td>\n",
       "      <td>hypothesis test for difference in medians amon...</td>\n",
       "      <td>5</td>\n",
       "      <td>hypothesis test difference median sample quest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13494</th>\n",
       "      <td>variance covariance matrix interpretation</td>\n",
       "      <td>assume we have a linear model model1 and vcov...</td>\n",
       "      <td>[r]</td>\n",
       "      <td>variance covariance matrix interpretation  ass...</td>\n",
       "      <td>5</td>\n",
       "      <td>variance covariance matrix interpretation assu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13495</th>\n",
       "      <td>mixing continuous and binary data with linear ...</td>\n",
       "      <td>so i ve been playing around with svms and i w...</td>\n",
       "      <td>[feature-selection]</td>\n",
       "      <td>mixing continuous and binary data with linear ...</td>\n",
       "      <td>5</td>\n",
       "      <td>mix continuous binary datum linear svm play sv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13501</th>\n",
       "      <td>using glm as substitute for simple chi square ...</td>\n",
       "      <td>i am interested in changing the null hypothes...</td>\n",
       "      <td>[r, hypothesis-testing]</td>\n",
       "      <td>using glm as substitute for simple chi square ...</td>\n",
       "      <td>5</td>\n",
       "      <td>glm substitute simple chi square test interest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Head  \\\n",
       "19322             sampling from skew normal distribution   \n",
       "13517  hypothesis test for difference in medians amon...   \n",
       "13494          variance covariance matrix interpretation   \n",
       "13495  mixing continuous and binary data with linear ...   \n",
       "13501  using glm as substitute for simple chi square ...   \n",
       "\n",
       "                                                    Body  \\\n",
       "19322   i want to draw samples from a skew normal dis...   \n",
       "13517   question the test scores of three groups of p...   \n",
       "13494   assume we have a linear model model1 and vcov...   \n",
       "13495   so i ve been playing around with svms and i w...   \n",
       "13501   i am interested in changing the null hypothes...   \n",
       "\n",
       "                          Tags  \\\n",
       "19322          [distributions]   \n",
       "13517  [r, hypothesis-testing]   \n",
       "13494                      [r]   \n",
       "13495      [feature-selection]   \n",
       "13501  [r, hypothesis-testing]   \n",
       "\n",
       "                                                    Text  Tags Count  \\\n",
       "19322  sampling from skew normal distribution  i want...           5   \n",
       "13517  hypothesis test for difference in medians amon...           5   \n",
       "13494  variance covariance matrix interpretation  ass...           5   \n",
       "13495  mixing continuous and binary data with linear ...           5   \n",
       "13501  using glm as substitute for simple chi square ...           5   \n",
       "\n",
       "                                            Text_Cleaned  \n",
       "19322  sample skew normal distribution want draw samp...  \n",
       "13517  hypothesis test difference median sample quest...  \n",
       "13494  variance covariance matrix interpretation assu...  \n",
       "13495  mix continuous binary datum linear svm play sv...  \n",
       "13501  glm substitute simple chi square test interest...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['Tags Count'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bayesian</th>\n",
       "      <th>classification</th>\n",
       "      <th>clustering</th>\n",
       "      <th>convolutional-neural-networks</th>\n",
       "      <th>correlation</th>\n",
       "      <th>cross-validation</th>\n",
       "      <th>data-mining</th>\n",
       "      <th>data-request</th>\n",
       "      <th>deep-learning</th>\n",
       "      <th>distributions</th>\n",
       "      <th>...</th>\n",
       "      <th>python</th>\n",
       "      <th>r</th>\n",
       "      <th>random-forest</th>\n",
       "      <th>regression</th>\n",
       "      <th>reinforcement-learning</th>\n",
       "      <th>scikit-learn</th>\n",
       "      <th>self-study</th>\n",
       "      <th>tensorflow</th>\n",
       "      <th>terminology</th>\n",
       "      <th>time-series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bayesian  classification  clustering  convolutional-neural-networks  \\\n",
       "0         0               0           0                              0   \n",
       "1         0               0           0                              0   \n",
       "2         0               0           0                              0   \n",
       "3         0               0           0                              0   \n",
       "4         0               0           0                              0   \n",
       "\n",
       "   correlation  cross-validation  data-mining  data-request  deep-learning  \\\n",
       "0            0                 0            0             0              0   \n",
       "1            0                 0            0             0              0   \n",
       "2            0                 0            0             0              0   \n",
       "3            0                 0            0             0              1   \n",
       "4            0                 0            0             0              0   \n",
       "\n",
       "   distributions  ...  python  r  random-forest  regression  \\\n",
       "0              0  ...       1  0              0           0   \n",
       "1              0  ...       0  0              0           1   \n",
       "2              0  ...       0  0              0           0   \n",
       "3              0  ...       0  0              0           0   \n",
       "4              0  ...       0  0              0           0   \n",
       "\n",
       "   reinforcement-learning  scikit-learn  self-study  tensorflow  terminology  \\\n",
       "0                       0             0           0           0            0   \n",
       "1                       0             0           0           0            0   \n",
       "2                       1             0           0           0            0   \n",
       "3                       0             0           0           0            0   \n",
       "4                       0             0           0           0            0   \n",
       "\n",
       "   time-series  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Create a MultiLabelBinarizer to encode the tags\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit the MultiLabelBinarizer on the tag data and transform it\n",
    "multi_label_encoded_tags = mlb.fit_transform(df['Tags'].tolist())\n",
    "\n",
    "# Create a dataframe from the multi-label encoded tags\n",
    "multi_label_tags_df = pd.DataFrame(multi_label_encoded_tags, columns=mlb.classes_)\n",
    "\n",
    "# Now, multi_label_tags_df contains the multi-label encoded tag features\n",
    "multi_label_tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-base\"  # You can change this to a different BERT variant\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the embeddings\n",
    "\n",
    "\n",
    "def create_embeddings():\n",
    "    embeddings = []\n",
    "        \n",
    "    # Loop through each text sample and generate BERT embeddings\n",
    "    for text in tqdm(df['Text_Cleaned'].tolist(), desc=\"Generating BERT embeddings\"):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Extract the [CLS] token embedding for each text sample\n",
    "        cls_token_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Append the embedding to the list\n",
    "        embeddings.append(cls_token_embedding)\n",
    "\n",
    "    # Convert the list of embeddings to a PyTorch tensor\n",
    "    embeddings_tensor = torch.cat(embeddings, dim=0)\n",
    "    return embeddings_tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
