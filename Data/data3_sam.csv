Head,Body,Tags,First Answer
Bulk downloading Wikimedia Commons images from search query,"
I am trying to understand how to bulk download Wikimedia Commons images, based on a search query (as in an artists name, as in my case ""Michael Wolgemut"").
Most of the resources I've been able to find seem to focus on downloading images based on Category, but this isn't going to work for me, as the images I want are spread over many categories. A search using the online interface (link) gives me a collection of the images I want, with somewhere in the region of 2,700 results (not an unreasonable quantity to download).
However, I can't work out how to translate this kind of search into an API query. I tried the commons-downloader tool linked on the Wikimedia site, which only returned 277 images, and the answers here and here, which were less helpful (I cannot untangle how to adapt them to my use case).
I'd like to limit the solution to bash and Python scripting, if possible, but that's not hugely important.
Also, if this can be done in such a way as to download the image descriptions as well, that would be excellent, but I'll settle for just the image files!
","['images', 'wikimedia-commons']",
"Request to get a key for 7,200 calls an hour (120 calls per minute) to Federal Electoral Commission API","
After extracting 2000 records. 100 per page, the Federal Electoral Commission (FEC) API throws an error given below. According to the documentation it ought to accept up to 1000 requests per hour with the generic API. I need to overcome the issue so I get data without the ""Max retries"" exception. Is there limits on endpoints requests too?
requests.exceptions.ProxyError: HTTPSConnectionPool(host='api.open.fec.gov', port=443): Max retries exceeded with url: /v1/schedules/schedule_a/?api_key=mCf2MXteY3H3GcpZmqL1uVTacWEe5eiW3OWFQgBQ&sort_hide_null=false&sort_nulls_last=false&data_type=processed&committee_id=C00540302&committee_id=C00580399&committee_id=C00703975&committee_id=C00833392&committee_id=C00833913&committee_id=C00836544&committee_id=C00839365&committee_id=C00841130&committee_id=C00842237&committee_id=C00842302&two_year_transaction_period=2024&min_date=01%2F01%2F2023&max_date=05%2F30%2F2023&sort=-contribution_receipt_date&per_page=100&last_index=4071820231753777371&last_contribution_receipt_date=2023-05-30T00%3A00%3A00 (Caused by ProxyError('Unable to connect to proxy', RemoteDisconnected('Remote end closed connection without response')))

",['openfec'],
Is there a dataset that has average road quality by United States county?,"
I can't think of a measure for road quality, exactly, but I'm looking for a dataset that ideally has some numeric value (e.g., 1 through 10, 1 being the ""worst"" road quality) representing the average quality of the roads in a given county in the United States. Maybe it's average prevalence of traffic delays, maybe it's the number of potholes, I'm not sure.
Is there an open dataset like this?
","['data-request', 'usa', 'infrastructure']",
mdr text is missing for many report numbers,"
I am using the below mentioned adverse event device open API url but it is not giving MDR text for many report numbers like 2112667-2023-03226, 2112667-2023-03227, 2112667-2023-03228 etc though the MDR text is present for same report numbers in https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfmaude/detail.cfm?mdrfoi__id=17224075&pc=BSZ
This is the API which I am using:
https://api.fda.gov/device/event.json?search=date_received:[20230601+TO+20230629]AND+device.device_report_product_code.exact:%22BSZ%22&limit=1000
Kindly suggest.
Thanks,
Shailendra J
","['data-request', 'api', 'openfda']",
Geometries of Statistical Areas (Statistický obvod) in Czech Republic,"
I’m looking for up-to-date census data about total population, age groups, buildings, … for Czech Republic at the highest possible spatial resolution. And I want to visualize them on a map. The smallest units on which data are published seem to be Statistical Areas (Statistický obvod).
Výsledky sčítání 2021 - otevřená data has the Census 2021 open data in CSV format. The files in the last section contain basic population data on statistical areas as far as I can tell.
The files contain an area ID in the column uzemi_kod, but no geometries.
https://geodata.statistika.cz/geonetwork/srv/cze/catalog.search#/metadata/czso-id-metadata-inspire-su-20110326 lists geographical areas for download and this file contains the Statistický obvod: https://geoportal.gov.cz/atom/CSU/SU/SUV_STAT_OBVOD_4258.gml. But they are from 2011.
The 2021 CSV file and the 2011 GML file can be mostly matched by ID. But there are some “holes” where data cannot be joined. I guess some of the statistical areas were redefined between 2011 and 2021 and their IDs changed.
The statistical areas are continuously maintained in the Registr sčítacích obvodů a budov (RSO). On their website you can download the database in DBF format, but it doesn’t contain geometries.
So, I’m looking for the missing piece which are the geometries that match the 2021 census area IDs. Any format would work – Shapefile, GeoJSON, GML, WFS, …. Any pointers would be appreciated.
","['geospatial', 'census', 'population']",
Is there any free Lidar dataset available?,"
I need a lidar-captured dataset to test my pointcloud model with that. Is there any free available lidar dataset?
",['data-request'],
"Is there a corpus of ""nice"" English words?","
I'm looking for an English language corpus that doesn't include profanity or ""unpleasant"" words to generate easy to remember passwords and other strings for users. Does anybody know of such a thing?
","['nlp', 'english', 'corpus']",
Available api - State to County,"
I'm looking for an api that says the available counties for each states.... Like for Nebraska, it should return Douglas, Sarpy, Fremont, etc...
Any answer would be appreciated.
","['usa', 'api', 'county', 'state']",
Twitter Churn Rate,"
I need the monthly churn rate for twitter. How do I get the number of annual users from  the number of Monthly Active Users for a social media site? Is there some general formula or some percentage that is used? I am guessing the churn rate would help.
","['data-request', 'twitter']",
Public database with celebrity names?,"
Essentially I have a list of customer names (first, last), and we want to know whether or not any of these have celebrity status, so looking to cross-reference my list with an external database.
Again, I only need their first + last name, and to know whether or not they are a public figure (eg. do they have a Wikipedia entry about them?), with no need for other personal information.
Thanks in advance!
","['wikidata', 'large-datasets']",
GPA data not available in API reponse,"
I have noticed a somewhere weird behaviour where I don't see any data related to GPA in API response, but it is available in the data dump. Anyone know how I can get the GPA from the API ?
Thanks in advance :D
","['data-request', 'api', 'data.gov', 'uses-of-open-data', 'data']",
Resumes Dataset for a NEE model,"
Where can I find an indexed resume dataset for a machine learning project? I found 200 online, but I need more.
",['data-request'],
Looking for repurposed drugs database,"
I'm a MSc student and my thesis is probably going to be about repurposed drugs. But I can't seem to find any sort of database about already repurposed drugs, or any drugs that are undergoing clinical trials (this one is more important), except a cancer database. Truth to be told, I want to work in something other than cancer, but if that's not an option,. I'll take a cancer database as well. Does anyone have any links, or tips? Thanks in advance!!
","['medical', 'bibliography']",
What is the eigenvalue ​of drug info [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 3 days ago.







                        Improve this question
                    



I want to know drug's eigenvalue.
product_ndc ?  product_id ? what is eigenvalue.. help
{
""product_ndc"": ""53145-081"",
""generic_name"": ""Methyl Salicylate"",
""labeler_name"": ""MENPER DISTRIBUTORS, INC."",
""brand_name"": ""Mascura la Vaca Plus"",
""active_ingredients"": [
{
""name"": ""METHYL SALICYLATE"",
""strength"": ""10.5 g/100g""
}
],
""finished"": true,
""packaging"": [
{
""package_ndc"": ""53145-081-03"",
""description"": ""86 g in 1 JAR (53145-081-03)"",
""marketing_start_date"": ""20190619"",
""sample"": false
}
],
""listing_expiration_date"": ""20231231"",
""openfda"": {
""manufacturer_name"": [
""MENPER DISTRIBUTORS, INC.""
],
""rxcui"": [
""1101920""
],
""spl_set_id"": [
""3d670f8a-4ebc-497c-9a09-d1f563d0eada""
],
""is_original_packager"": [
true
],
""upc"": [
""0042279813035""
],
""unii"": [
""LAV5U5022Y""
]
},
""marketing_category"": ""OTC MONOGRAPH NOT FINAL"",
""dosage_form"": ""OINTMENT"",
""spl_id"": ""c4231532-de31-4c0d-8aa9-e3bc0694f0ba"",
""product_type"": ""HUMAN OTC DRUG"",
""route"": [
""TOPICAL""
],
""marketing_start_date"": ""20190619"",
""product_id"": ""53145-081_c4231532-de31-4c0d-8aa9-e3bc0694f0ba"",
""application_number"": ""part348"",
""brand_name_base"": ""Mascura la Vaca Plus""
}
","['openfda', 'drugs', 'open-source', 'national-drug-code']",
Pan Canadian Strahler Order stream data,"
I am working with the CanVec series linear_flow spatial data set, however, it doesn't have the strahler order value attached to the stream/river segments.  Is there a pan Canadian strahler order spatial data set out there that is routable i.e. has the direction of flow for each stream ?
","['geospatial', 'canada']",
Why does device.device_report_product_code require = rather than :?,"
To successfully search the device/event endpoint for device.device_report_product_code, you must search using = instead of : like this:
https://api.fda.gov/device/event.json?search=device.device_report_product_code=""HQF""
But the API documentation (to my knowledge) doesn't document the required use of = for device.device_report_product_code. Furthermore, if you use : instead of =, you don't get an error. You get ""No results found!"", which is what this query returns:
https://api.fda.gov/device/event.json?search=device.device_report_product_code:""HQF""
Yet HQF is a valid 3-letter device code. Can someone explain when = must be used and why : (which I thought meant ""contains"") returned no matches?
",['openfda'],
Open dataset of urban temperature,"
I am looking for open dataset of the urban temperature with a spatial resolution of the single building (like the one that can be seen in some site specialized in weather forecasting)
","['data-request', 'geospatial', 'buildings', 'data', 'satellite']",
I need to get all school names with the college score card API with pagination in table format,"
I need to get all school names with pagination with college score Card API
How can I write this query
",['collegescorecard'],
"Seeking floorplan for college, university, large school, government offices, shopping mall, hosptial, etc","
I need some data for a digital signage demo project. Preferably something with multiple floors, even multiple buildings, which can be categorized (e.g history/computing/arts dept. Or types of shop or office).
This is so I can have a nice fancy demo. Show all shoe shops, or computer lecture halls, all licensing offices), plus search for individual shops, people, etc, maybe show opening hours, menus for restaurants, how to get there ...
... but, I digress. I just want a floorplan.
",['geospatial'],
FDA API not working since last month,"
The FDA API is not able to extract data for the month of May and June. The API used in collecting the data for May is given below: 'https://api.fda.gov/device/event.json?search=date_received:[20230501+TO+20230515]+AND+device.manufacturer_d_name:""INTUITIVE SURGICAL, INC""&limit=1000'
But the API response is:
<Response [404]>
{
""error"": {
""code"": ""NOT_FOUND"",
""message"": ""No matches found!""
}
}
What would be the reason for the response and by when would the API be up and running.
",['openfda'],
US Basement Map in Shapefile,"
I am looking for the shapefile that contains the basement top (depth) for the entire US. I have found a Tiff image, but not the Shapefile. Any recommendations?
",['geospatial'],
A file of all Korean language words?,"
Is there an open data set file (not an open API) containing all (or almost all) Korean language words?
There are some famous Korean dictionaries such as the Standard Korean Dictionary published by the National Institute of the Korean Language (국립국어원 표준국어대사전).
I know there are some Transformers-based language models' vocab files but they are not what I want because they contain some non-standard form of words.
","['language', 'dictionary']",
Linking OSHA accident/accident_injury data to Establishment,"
I am analyzing some of the OSHA datasets,  For Inspection dataset (estab_name) is available to identify which Establishment/Company was inspected and also if there are any Violation (using activity_nr to link Inspection data set to Violation).
I am looking for Establishment Name (estab_name) in Accident/Accident_Injury dataset to identify which Establishment/Company had accident.
Is there any option to identify the Establishment/Company info here.
Thanks in Advance.
",['labor'],
Forest/tree data for all cities,"
Is there a dataset that has forest/tree cover and more information about the density of trees per city/location in the US? I looked into them and I can find it only on state level.
","['data-request', 'data']",
Looking for motorcycle crash statistics database,"
I'm looking for a database with information on motorcycle crashes, specifically information about the motorcycle involved in the accident (make,model,speed at time of crash, location, time etc).
","['api', 'medical']",
Back and forth emails and letters,"
For a research project, I am currently looking for datasets that consists of large amounts of e-mails, text messages, or OCR-processed letters that were written as part of a conversational exchange between two people.
There are quite a few open datasets that include a (significant amount) of emails. For instance, one has the Enron dataset, the Jeb Bush dataset, and the Hillary Clinton dataset. However, these datasets are not exactly what I'm looking for.
I'd like to have a dataset that consists of a large amount of (written) conversations between exactly two people. The emails should alternate between these two people, with one email (or letter or text message) for each person, each time.
Question: do such open datasets exist? If so, where can I find them?
","['text', 'email']",
GPS signal strength over locations,"
Is there any data with GPS signal strength information? I'm trying to understand GPS wrt locations and some just in general have better signal than rest. Is there any data suggestive of this, which says like at this latitude and longitude, GPS in not that great? Like the satellites don't have a great reach, like at high elevations and areas like that.
","['geospatial', 'data']",
Point in polygon analysis in excel,"
In excel, I have one table where each row corresponds to a geospatial point, with exact x and y coordinates. Total number of rows is over 200,000, for example:

In a separate table, I have a list of grids created in QGIS and exported as a csv file. These grids outline left, right and bottom, top coordinates. Total number of rows is just over 8000, for example:

so essentially, person 1 should be assigned to grid a, person 2 to grid b, and so on. The ultimate goal is to get, for each grid, a total count of IDs within each grid.
I've tried all sorts of options with vlookup, lookup and conditional statements and so on, but at a dead end. Any help would be appreciated!!
Just for context, I can only use excel for this issue, rather than other GIS tools.
Thanks in advance!
","['geospatial', 'geocoding', 'excel']",
Can the DOL add an External API solution for IRC 6621 Table of Underpayment Rate quarterly updates,"
As a financial service provider dealing with qualified defined contributions, we support clients in VCP corrections. Assisting in the DOL Calculations at scale for large participant base corrections would be ideal to have an external API developed to verify the latest updates for the (a)(2) Underpayment Rate and the (c)(1) Underpayment Rate tables.
","['api', 'labor']",
Datasets of legal correspondences,"
I am searching for datasets of legal correspondences between for example lawyers.
For example, a response to a complaint from an airline customer.
Preferably the legal basis should be with respect to the European Union. I got the hot tip of searching at public institution, but could not find any.
","['nlp', 'legal']",
"In Google Books Ngram datasets, what are the meanings of '._.' (dot-underscore-dot) and '_._' (underscore-dot-underscore)?","
Consider the Version 3 dataset for 2-grams labeled 'Brunswick_NOUN Memorial_NOUN' (its actual name is '2-00109-of-00589.gz'). Compare the following three entries:

Buitenhuis .      1859,2,2                 1895,1,1                                1914,4,2 … 1950,1,1 …
Buitenhuis ._.    1859,2,2                 1895,1,1                                1914,4,2 … 1950,1,1 …
Buitenhuis _._   1859,4,2  1886,3,3  1895,1,1   1899,2,1  1905,2,2  1914,4,2 … 1950,15,13 …

I have spaced out the first two a bit so the years align with the third. This shows the general pattern for these entries: the first two are always the same, but the third one is in general different.
I assume the first entry counts the occurrences of Buitenhuis followed by a period (possibly with one or more spaces in between). What about the second and third?
As best as I can tell, this isn't addressed on Google's information page.
All I have been able to find out is the statement, in the Supplementary Material of the 2011 Science article1 is the following (p. 10):
1The Supplementary Material is not behind a paywall, so one can download it here.

(3) The following characters are not tokenized as separate words:
& (ampersand) _ (underscore) Examples of the resulting
words include AT&T, R&D, and variable names such as
HKEY_LOCAL_MACHINE.
(4) . (period) is treated as a separate word, except when it is part
of a number or price, such as 99.99 or $999.95. A specific pattern
matcher looks for numbers or prices and tokenizes these special
strings as separate words.

Mind you, this concerns Version 1 of the datasets. Things could be at least somewhat different in Verson 3.
(And I think they indeed are. For example, in Version 3, the following is listed in a 2-gram file:
H. Pluckrose    1912,2,1        1913,6,5 …
Therefore, a single capital letter followed by a dot is tokenized as a single word.)
In a separate paper relevant to Version 2, there doesn't seem to be any new relevant information.
Question
What are the meanings of '._.' (dot-underscore-dot) and '_._' (underscore-dot-underscore) in Google NGram datasets, Version 3?
",['corpora'],
Geospatial data set for monthly averaged wind speed or power density,"
I want to evaluate seasonal variability of wind turbines (in combination with a Power to X plant). Ideally, wind turbines would create a constant seasonal power output to supply the continuous demand of PtX process, which would reduce the need and size for electricity and hydrogen storage.
For this I am looking for a geospatial data set that provides monthly averaged wind speed oder wind power density, ideally at a global scale. Specifically I am looking for data sets in Spain and Australia.
The Global Wind Atlas only offers yearly averaged wind speed and power density data.
Similarly, the Global Solar Atlas offers monthly averaged Global horizontal irradiation GeoTIFF files (e.g. Global Solar Atlas for Australia under LTAym_YearlyMonthlyTotals). That is what I need just for wind.
","['geospatial', 'weather', 'climate', 'open-source']",
Exploring API Options for Ticketing and Group Purchases: Wizzair and Other Low-Cost Airlines,"
Do you know if Wizzair or any other low-cost airline provides an API that allows me to access booking information, specifically related to ticketing and group purchases? I am particularly interested in finding out if they offer group bookings for flights and what kind of price benefits I can receive when purchasing tickets for a group or multiple individuals.
","['api', 'prices', 'travel']",
Which states are supported by marketplace.api.healthcare.gov,"
I am using https://marketplace.api.healthcare.gov/api/v1/plans/search?
  ""place"": {
      ""countyfips"": '06085',
      ""state"":'CA',
      ""zipcode"":'95129'    
}

I am getting:
{""code"":""1003"",""status"":""400"",""message"":""state is not a valid marketplace state"",""error"":""state is not a valid marketplace state""}
",['healthcare-finder-api'],
Is it possible to get geoJSON data for all zipcodes in Malaga Spain?,"
Trying to use mapbox to create polygons outlining all zipcodes in Malaga. Mapbox requires geoJSON data in order to draw the polygon around the zipcode boundaries. Any recommendations would be greatly appreciated!
",['geospatial'],
How many Youtube videos have more than 100 million views?,"
For at least a billion views, I know that there are more than 400 videos. So there will probably be many thousands of videos with ay least 100M views. Where can I find the exact number?
Ideally, I would also like to see a complete list. I am prepared to spend some money on it.
","['data-request', 'social-media', 'video']",
Settlement data for Colombia to use in QGIS,"










                                This question was migrated from Geographic Information Systems Stack Exchange because it can be answered on Open Data Stack Exchange.
                                Migrated last month.
                            






Where can I find data about settlements to use in QGIS? I tried OpenStreetMap but can't find the data. I need it for Colombia.
","['geospatial', 'openstreetmap', 'colombia']",
Land Ownership Data,"
I am conducting some research on land ownership within the Guadalupe-Nipomo Dunes complex located on the Central Coast of California. I need land ownership data but having trouble finding it. I was able to locate data for State and Federal Agencies, but some data is missing.
Does anyone have any good resources for finding and ownership data, especially private land?
I am using ArcGIS Pro.
","['land', 'data']",
"Introducing NBA Stats API: Access NBA Season and Playoff Totals, Advanced Statistics, and More!","
Hello, fellow data enthusiasts and NBA fans!
I am excited to announce the release of my latest project, the NBA Stats API (version 0.1 Beta). This API provides access to NBA season and playoff player totals, advanced statistics, shot chart data, and more. As an NBA fan and data enthusiast myself, I've always had a passion for finding patterns and trends in sports statistics. This API is my contribution to the community, in hopes that it will fuel your own analysis, be it for fantasy leagues, sports journalism, predictive modeling, or simply out of curiosity.
I've put in many hours of work into this project, ensuring that the data is not only accurate but also easy to access and understand. The API is currently in its Beta version (0.1), and I'm excited to see how it will evolve with your valuable feedback and suggestions. Currently, the advanced statistics is in testing and will be made available very soon.
The complete API documentation is available as a POSTMAN collection at the following link: API Documentation.
I've also hosted all the code behind this project on GitHub under MIT license: NBA Stats GitHub Repository
I am continuously working on improving and expanding the API, and your feedback and suggestions are more than welcome. Feel free to ask any questions, provide suggestions, or even share what you've managed to achieve using the API. I'm looking forward to your creations!
I've created a small website to start visualizing this data. Check out my favorite chart displaying Total Points vs. Win Shares. All data on this site fetches from the API.
Thank you for your time and happy data diving!
",['sports'],
Telemetry system for garden sensors,"
I apologize if this isn't the right place for this post. Essentially, I'm trying to find a (relatively) low-cost solution for how to take data from a water content and conductivity sensor (specifically this: https://www.metergroup.com/en/meter-environment/products/teros-12-soil-moisture-sensor) and display/view it on a remote device (i.e. phone, PC, etc.)
Currently, the only way to view the data from the sensor is to be physically near it via Bluetooth and using their app. If you want to view the data remotely (outside of Bluetooth range) METER Group requires that you buy their whole platform, which is $3,600/year for access in addition to $3,500 for the equipment to do so.
Does anyone know of a system where I could plug their device in and be able to access the water content, temperature, and conductivity data?
",['sensors'],
Financial data: index ticker lists?,"
I am looking for some way to get index ticker lists. I'd like an up to date source and a practical way to get data. Exemple for sp500 I currently use:
import pandas as pd
import numpy as np

sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')
sp500_list = np.array(sp500[0]['Symbol'])

I am not entirely happy with this solution as wikipedia might not be entirely up to date, the thing to scrap depend on the index (for cac40 we need to scrap the second or third table in the page) and the pipeline depend on the read_html pandas function. I'd like something a bit more polished, with additional indices. Know something that could do the job ?
",['finance'],
Seeking weather data for past and this year for 4500 cities around world,"
I'm looking for weather data on 4500 cities throughout the world for 2022 and 2023 for a school project.
Is there a way to get this for free?
I can see it according to weather stations, but that might be too much to compile.
Is there anything city level directly available?
I tried APIs but they allow very limited use for free
","['data-request', 'weather', 'data']",
Appropriate dataset for restricted maximum likelihood Estimation,"
I need a dataset that works with Restricted Maximum likelihood.
thank you
","['data-request', 'medical', 'uses-of-open-data']",
Interesting Datasets to show the felibility with SVMs in R,"
I hope this is the right place for this question. I am working on a lecture for SMVs. The audience will mostly be beginners. Next to a very graphical theroy presentation I am looking to give two examples on how to use SVMs in R. My idea is to go through the whole process (importing the data to interpreting the SVM model) once. I am now looking for two data sets. A simple one that works well with a linear kernel. And a more complex one where you need a polinomial kernel.
I had thought of something like the setosa datase. My question, however, is whether the forum here knows of more interesting data sets that might be suitable for my project. Interesting refers primarily to the context of the datasets, i.e. something more tangible than the length of flowers ;)
If I am completely wrong in this forum, I would be happy if you could give me a hint where my question would be better placed.
Thank you very much!
","['data-request', 'machine-learning', 'programming']",
We are interested in an API to browse the Labor Dept. form 5500 datasets,"
Is there an API in development to allow search/transmissions of the 5500 form datasets?
https://www.dol.gov/agencies/ebsa/about-ebsa/our-activities/public-disclosure/foia/form-5500-datasets
",['labor'],
"Data needed for Cadastral Survey in Colorado, USA","
I need points for the Cadastral surveys for my project and I have a hard time find one... It can be anything that  can add to the project such as online, layers, hyperlinks etc...
The project I am working on is on my Forest and I had a project from another forest. He uses the Cadastral Survey points for his forest.  It looked like they use the GPS points on their forest to collect.
I, myself, do not understand what Cadastral Survey is.  I know they came  from the BLM that started this.
My current project is on the Forest on the Pike and San Isabel National Forest and Cirmarron and Comanche National Grasslands.  I am in Colorado.
Thanks
","['geospatial', 'download', 'data']",
Are there any data for GIS for Substations?,"
I am working on a project and review each quad using the USGS Topos and need the data for Substation that has the points.  I could not find it .  Location is in Colorado. This is for my field crew workers that will be using for Field Maps or apps in the field
","['geospatial', 'data', 'substation', 'electric', 'gas']",
In the GRAD_DEBT_MDN variable who is in the cohorts used to calculate?,"
I am trying to recreate how this is calculated so I can track our students in real time.  I want to know who is counted in the cohort calculation. I understand it is two years of rolling information based on Fiscal Year cohorts of those that completed. But is it all graduates or only those graduates who had any debt? Also, is the FY July 1 to June 30?
Thank you.
",['collegescorecard'],
Carbon Credit Prices,"
I am looking for Carbon Credit Prices, for different geographical zones. Ideally I'd like a reference data source with a practical API. Any idea on where to get that ?
","['finance', 'prices']",
Does the Chinese Government have any open satellite imagery?,"
I'm looking for online data from Chinese satellites. I see them make the news frequently but is any of this public?
","['images', 'china', 'aerial-photography', 'space', 'satellite']",
Speech intelligiblity tests such as rhyme tests,"
Can anyoe point me to .wav files or the like for
speech intelligiblity tests, e.g.
Rhyme tests
""not, tot, got, pot, hot, lot"" ?
What I want are reproducible tests for various hearing aids and settings,
in a quiet room, not speech-in-noise.
(I'm an old guy with high-frequency hearing loss --
https://hearingtest.online says 4 kHz ~ 30 dB down from 2 kHz.)
Any European language would be ok.
((I'd really like to know if hearing aid equalizers can flatten out high-frequency drop,
specifically Phonak P30,
but how to measure the effect on speech ?)
","['data-request', 'language', 'corpora', 'audio']",
"Free recipes API returning XML, without HTTP headers","
I need a recipe api with the following prefrences:

Needs to be in xml
Has a free version
Headers should not be required/ api key should be in url

Any help would be appreciated. Thank You.
","['api', 'xml', 'recipes']",
"a list of HighShools, Universities in Europe, South America and Asia","
i am looking for a list of HighShools, Universities in Europe, South America and Asia
is there a dataset that is free - and available!?
OpenStreetMap (OSM): OpenStreetMap is a collaborative mapping project that provides free and open geographic data. You can extract data from OSM to get information about schools and universities worldwide. The data is available in various formats, including XML, CSV, and shapefiles. You can use the Overpass API or download pre-extracted datasets from websites like Geofabrik.
UNESCO Institute for Statistics (UIS): The UIS provides comprehensive data on education, including information about schools and universities worldwide. They offer a variety of datasets and publications that you can access for free. Visit the UIS Data Centre (data.uis.unesco.org) to explore their available datasets.
European Commission's Education, Audiovisual, and Culture Executive Agency (EACEA): The EACEA provides datasets related to education in Europe, including information about schools and universities. Their datasets cover various aspects of education, such as institutions, programs, and funding. You can access their data through the EACEA website (eacea.ec.europa.eu).
Data.gov: Data.gov is a platform that provides access to a wide range of datasets from various government agencies in the United States. While the focus is primarily on US data, they also offer some international datasets, including educational data. You can search their catalog and filter by location to find relevant datasets.
World Bank Open Data: The World Bank provides open data on various topics, including education. While the data may not be as extensive as specialized education sources, you can find information about schools and universities in different countries. Visit the World Bank Open Data website (data.worldbank.org) and explore the education-related datasets.
","['data', 'highschool']",You can get list of universities(not all) on World Higher Education database which is in collaboration with UNESCO. You can search here country wise : https://www.whed.net/home.php.
Need a Random Quotes API,"
I need a Quote API with the following requirements:

Needs to come out in xml format
It needs to be free

Any help would be appreciated. Thank you.
","['api', 'xml']","Sure! Here's a random quote API:API Endpoint: https://quotes.rest/qod.xml?category=inspireThe free plan that allows you to make a limited number of requests per day. To retrieve a random quote, you can use the provided endpoint with the ""category"" parameter set to ""inspire.""Example Request:Example Response (XML):"
How can one edit the title of a dataset?,"
I need to 'standardize' the titles of several draft datasets for uniformity. How can I go about this? I can't seem to find a way in 'edit' mode. Thanks.
",['usaidopen'],
How do I get the population of each state using WorldBank API?,"
I tried using this link:
https://api.worldbank.org/v2/state/NE/indicator/SP.POP.TOTL?date=2021
and it says that the endpoint is not found ... please give me a link that will work using the worldbank api to get the info by a specific state. Please and thank you.
","['api', 'population', 'state']",
Import Export Data for India,"
I am looking for trade data of India with other countries in the form of Import or Export. Creating a research project in my field.
","['data-request', 'india']",
Need dataset composed of noisy observations sampled from normalised function,"
I am looking for a data application to test a particular regression algorithm.
In particular, I am looking for an application where the data items are noisy samples coming from a normalised function f(x), that we don't observe. By normalised I mean that the integral of f(x) in its support is ∫f(x)dx = 1. The algorithm attempts to reconstruct the normalised f(x) given the observed samples that are contaminated with noise.
I would very much appreciate it if somebody could point me to such a dataset, or perhaps to a domain where this problem naturally appears.
","['data-request', 'machine-learning']",
Mental Health Funding by State,"
I need help finding mental health funding per capita by state dating all the way back to 1999. I have searched URS reports but they are extremely time consuming.
","['usa', 'medical']",
Automobiles data catalog,"
I'm looking for API to integrate that provides list of spare parts details, cars details and possibly vin numbers. I have found Tecalliance but they seem to be overpriced for their subscription especially for a startup like mine.
Do you have any suggestions on other data providers? either free or not.
thanks.
","['data-request', 'cars']",
UK Bridges point dataset,"
I am looking for a free dataset of bridges that cover roads/rivers/rail in the UK, specifically South East, as a point layer. It doesn't seem to be available from OS or National Highways, does this exist?
Thanks
","['data-request', 'uk']",I would consider openstreetmap data. Please have a look on bridge tag. You can start with Overpass query like https://overpass-turbo.eu/s/1vOs or download the OSM data set for GB: https://download.geofabrik.de/europe/great-britain.html
Address location data for Israel,"
I am trying to find address location data for Israel - that is, a geospatial point dataset giving a latitude and longitude (or similar in another co-ordinate system) for each address in Israel.
I can't seem to find anything on the Israeli Open Data site, or anything on the Israel Postal Service site.
Does such a dataset exist?
","['data-request', 'geospatial', 'address']",
CollegeScorecard.gov SAT & ACT requirements,"
From CollegeScorecard.gov, how can I get data about whether SAT is required, optional or not used at all? We are using the API.
There's a section with this info. It's titled ""Test Scores"" under the larger header ""Test Scores & Acceptance""
California State University-Sacramento has an acceptance rate of 94%. California State University-Sacramento does not require admission test scores (SAT/ACT) during the application process and does not recommend that students provide them.
Harvard University has an acceptance rate of 4%. Harvard University considers admission test scores (SAT/ACT) during the application process, but does not require them. Students who were admitted to Harvard University and enrolled typically had admission test scores in these ranges.
University of North Alabama has an acceptance rate of 90%. University of North Alabama recommends students provide admission test scores (SAT/ACT), during the application process.
",['collegescorecard'],
Number of images being used for the annual product,"
I am using the v2.1 annual nighttime light (NTL) product for my analysis. My study areas are several megacities, which include:
Los Angles, Mexico City, Tehran, Paris, Cairo, Manila, Tokyo.
I would like to ask you if you could tell me where to find how many clear images have been used to create the annual products for the above megacities. I am using the VNL_v21_npp_2018_global_vcmslcfg_c202205302300.average.dat.tif.gz product for my analysis.
I have searched the website for any metadata but I couldn't find any relevant information.
",['metadata'],
I'm looking for a dataset related to environmental monitoring,"
I'm looking for a dataset related to environmental monitoring, made up of values obtained from various types of sensors (such as temperature, pressure, CO2...etc) for the purpose of a classification task. However, I'm not sure this is possible with any dataset, so I wanted to ask you if you had any suggestions for a dataset I could use.
Multimodal data (images and sensors) are also accepted and could be very useful.
Please let me know if you have any recommendations or potential sources. I've already looked through Google Datasets and Kaggle.
","['data-request', 'environment', 'deep-learning', 'sensors', 'remote-sensing']",
Free car picture from VIN or model and make,"
I am building a iOS app and wanted to know if anyone knows of any good free APIs that have images of a car using either the VIN or model make.
I already have the basic vehicle information API, but the image would be a nice touch :)
","['api', 'cars']",
Small self-contained email datasets,"
For a research article, I am currently looking for a small, self-contained email dataset.
The reason I'm saying small, is because many email datasets I've found so far contain a large amount of emails. Examples include the Enron dataset (about 500 thousand emails), the Jeb Bush dataset (290 thousand emails), and the Hillary Clinton dataset (30 thousand emails).
For the purposes of the research I'm conducting, I need much smaller e-mail datasets. One of the things I could do I extract a small sample from these larger datasets, but then coherence between and theme among these messages might be lost somewhat.
I am therefore looking for self-contained, small, English, public datasets consisting of at most 50 emails, preferably even smaller (around 25 emails). The idea behind the research project is to formulate a model that can describe the different relations between such emails (both their metadata and their textual contents), and to illustrate this model with a visualization of the emails and the relations among them (topical, causal, entity-based, etc.).
What I mean by self-contained is that the e-mails sent and received within a certain period don't have any follow-up e-mails after that period on that case or topic. So it's a collection of e-mails that is sort of sealed off, the case is closed so to speak.
Question: are there any self-contained, public, English datasets that consist of fewer than 50 emails?
","['research', 'email', 'visualization']",
"What's the `EFFYALEV` variable in the IPEDS ""EFFY2020"" data table?","
When I query the column, it seems to be arbitrary values from 1-60:




EFFYALEV
count




1
6169


2
5881


3
5878


4
5670


5
5689


11
2893


12
2049


19
3573


20
5668


22
5828


23
5824


24
5587


25
5631


31
2403


39
3552


40
5610


42
4212


43
4176


44
3579


45
4090


51
2793


59
2903


60
4065




But the official documentation's description [0][1] doesn't explain how the values map to different enrollment types:

Level,  full- and part-time status, degree-seeking/non degree-seeking status  and year of study of student  - This variable identifies the level of enrollment (unduplicated headcount) data for the institution.  Enrollment counts are available by level of student (undergraduate or graduate).  Undergraduate enrollments are disaggregated by degree-seeking and non-degree seeking status. Degree-seeking enrollments are further broken out by first-time, first year students, transfer-ins and continuing students.  Undergraduate categories are available by full- and part-time status.
Undergraduate  A student enrolled in a 4- or 5-year bachelor's degree program, an associate's degree program, or a vocational or technical program below the baccalaureate.
Degree/certificate-seeking students  Students enrolled in courses for credit and recognized by the institution as seeking a degree, certificate, or other formal award. High school students also enrolled in postsecondary courses for credit are not considered degree/certificate-seeking.
First-time student (undergraduate)  A student who has no prior postsecondary experience (except as noted below) attending any institution for the first time at the undergraduate level. This includes students enrolled in academic or occupational programs. It also includes students enrolled in the fall term who attended college for the first time in the prior summer term, and students who entered with advanced standing (college credits earned before graduation from high school).
Transfer-in student (undergraduate)  A student entering the reporting institution for the first time but known to have previously attended a postsecondary institution at the same level. The student may transfer with or without credit.
Graduate student  A student who holds a bachelor's degree or above and is taking courses at the postbaccalaureate level. These students may or may not be enrolled in graduate programs.
Full-time student  Undergraduate: A student enrolled for 12 or more semester credits , or 12 or more quarter credits, or 24 or more clock hours a week each term. Graduate: A student enrolled for 9 or more semester credits, or 9 or more quarter credits, or a student involved in thesis or dissertation preparation that is considered full time by the institution. Doctor's degree - Professional practice - as defined by the institution.
Part-time student  Undergraduate: A student enrolled for either less than 12 semester or quarter credits, or less than 24 clock hours a week each term. Graduate: A student enrolled for less than 9 semester or quarter credits

[0] https://nces.ed.gov/ipeds/use-the-data/download-access-database
[1] https://nces.ed.gov/ipeds/tablefiles/tableDocs/IPEDS202021Tablesdoc.xlsx
",['collegescorecard'],
"Download Environmental Geodata for Germany (SHP, KML, WMS, WFS, etc.)","
I'm having trouble finding environmental QGIS layers for Germany. I managed to find the main ones for all the country, such as Biosphere Reserves, National Parks, Natura 2k sites, etc., but I can't find more specific information like Flood Zones, rivers / streams, forests, peatlands, renewable energy projects, etc.
Where can I find this info in downloadable format (.shp, KML, WMS, WFS, etc.), either for Germany in general or for it's Federal States (e.g. Bayern)?
","['germany', 'environment']",
Words list by category / topic,"
For my side project, I need to get a categorization of as many English words as possible. With ""categorization of words"" I mean the assignment of categories / topics to each word, as it is done in most language dictionaries, e.g.:
Animals
=======

- lion
- horse
- tiger
- cat
- dog
- mouse
...
- mare
- stallion
- calf
...

Plants
- tree
- plant
- root
- branch
...

Up to now, I am using a language dictionary to get such a categorization, but this has its limits. It works fine for frequent words like ""lion"" and ""cat"", but rarer words like ""stallion"" and ""mare"" are not included in such topic word lists.
What I need is a thorough, as-complete-as-possible list of English words together with their ""category"". If a word denotes the name of an animal, it belongs to the category ""animals"", no matter how rare it is. If a word denotes the name of a mechanical tool, or a mechanical action, it should belong to ""Tools"" or ""Crafts"" or whatever.
I tried Wordnet with their ""hypernym"" feature, but the results are limited too. For example, all adjectives seem to not have hypernyms, making it impossible to classify them.
Some comments:

Note that a word can belong to more than one category.
I am looking for open data sources, but I'm also grateful for answers suggesting non-open data.
Bonus points if the data source has the same for other languages.

(Edit) Wordnet limitations
As per Nicolas' request, here a couple of problems with Wordnet. This is just to indicate why Wordnet is not a real solution to our problem.

For example, the adjective ""salty"" (which could have hypernyms auch as ""taste"", ""chemical characteristic""), has the synsets piquant.s.02, salty.a.02, salty.s.03. However, none of them has any hypernyms.
Other adjectives and adverbs without hypernyms: ""useless"", ""lateral"", ""friendly"", ""silly"", ""creepy"", ""merely"", ""creamy"", ""hot"", ""yellow"", ""dreamy"", ""done"". Some of them have hypernyms as nouns, but not as their main meaning as adjectives or adverbs.
As another example, ""Mexico"" (mexico.n.01) has no hypernym that indicates that it's a country's name. Same for (all?) other countries.
""above"" has ""r"", ""s"" and ""n"" part-of-speeches. None of them has a hypernym, except the ""n"" (noun), which has section.n.01, writing.n.02, written_communication.n.01, i.e. the meaning of ""the above"" in the sense of ""what is written above"". This is a very narrow meaning of the word ""above"". The spatial meaning, which is much more general, is not captured by any hypernym.

I understand that it's not easy to find a coherent ontology for adjectives. However, a basic categorization should be possible:

salty, sweet, sour, bitter, ... ==> taste
red, orange, yellow, ... ==> color
friendly, dreamy, creepy, ... ==> moods
friendly, silly, ... ==> personal characteristics
creamy, hot, ... ==> food characteristics (of which ""taste"" would be a sub category)
above, bottom, left, ... ==> spatial

","['language', 'wordnet']",
I am looking for a data set of conversation between real state agent & prospect to train model to evaluate customer care employee performance,"
By using the data set I will train model for analyzing customer care's representatives performance and ensure customer satisfaction. The data set should be in English.
","['data-request', 'machine-learning', 'large-datasets']",
Socioeconomic free geodata?,"
Where can I find free socioeconomic geodata to download for Germany? Any helpful websites tat provide data in shp or tif format?
","['data-request', 'germany', 'social-process', 'economy']",
"Where to download annual data for heating and cooling degree days for US counties not one-by-one, but all at the same time","
Could anybody help me find reliable source for downloading csv files of HDD and CDD for all USA's counties.
For those wondering about heating and cooling days definition, you can refer to this.
","['usa', 'weather', 'csv', 'climate', 'noaa']",
Occurence rates and FAERS data,"
I had a question regarding rates of occurence in FAERS. According to the FAERS documentation,

Rates of occurrence cannot be established with reports: The number of
suspected reactions in FAERS should not be used to determine the
likelihood of a side effect occurring. The FDA does not receive
reports for every adverse event or medication error that occurs with a
product. Many factors can influence whether an event will be reported,
such as the time a product has been marketed and publicity about an
event. Therefore, information in these reports cannot be used to
estimate the incidence (occurrence rates) of the reactions reported.

In light of this, is there a way to directly compare two different drugs that would account for total prescriptions? I've reviewed several publications based on the FAERS data which seem to use ROR and PRR for the purpose of comparing across drugs; however, neither of these methods account for total prescriptions.
Furthermore, to establish a rate (e.g., # reports of AE XX/100K prescriptions), I anticipate that it would difficult, if not imposssible, to identify an appropriate denominator, so it's unlikely that the results would even be meaningful/interpretable. There are likely other limitations of the FAERS system (e.g., data quality, duplicate reports, incomplete reports, etc.) that would further complicate this task.
FWIW, we are looking specifically at PTs related to abuse (e.g., drug abuse, drug dependence, and drug withdrawal syndrome).
Many thanks in advance for your any assistance that you are able to provide.
",['openfda'],
Households' wealth deciles by country,"
I'm looking for data (either directly the deciles, or data allowing me to compute the deciles) on households' wealth by country on the recent years.
Much of the data that I have found only include the top 1%, 5%, 10%, 50% and the bottom 50%, or something of the sort. Also, I've never been able to find the underlying data in order to compute the deciles myself.
The only country for which I've found the data seems to be France, with their INSEE's ""Patrimoine net des ménages"". The data is downloadable, and in the couple sheets there is, one lists the deciles.
Is there any place to find this type of data, and this data in particular? Thanks a lot!
",['economics'],
Has the percent of unplanned pregnancies in France increased since the legalization of contraception in 1967?,"
Has the percent of unintended pregnancies (relatively to all pregnancies) risen since legal contraception was first introduced in France in 1967. Where can I find a graph like this: y-axis is the percentage and x-axis being years from 1967 to 2023? Is there data before 1967 to compare?
","['demographics', 'france']",
Where can I find individual-level name and street address data?,"
I'm looking for, more or less, phone book type data, including full name, street addresses, and sex for the purpose of generating simulated data for research. This seems like it would be easy to find, but I'm having trouble locating, e.g. historical census transcripts.
Am I missing where to find this data through the US Census? Are there other sources of this sort of information? The data does not need to be current (historical records are ok).
","['us-census', 'address', 'names']",
speed limits for roads,"
Shapefiles of roads can be downloaded from the US Census's TIGER database and from local municipalities but what about speed limit data?
Like from point A to point B on a given roadway the speed limit is x mph, while from point B to point C, the speed limit on that same roadway might be y mph.
Is this data available anywhere as a shapefile or anything?
If it's not available on a national level might it be available at various state or local levels?
Data Source for Speed Limits is a similar question but it's from 10 years ago and the answer looks less like a definitive answer and more like a ""you can make certain educated guesses based on this ruleset"" type of answer.
","['geospatial', 'usa', 'transportation', 'map']",
How to download headlines from GDELT database,"
I tried to use GDELT from Google BigQuery, but I can't find Headline column there.
Can you please tell me how to do it on BigQuery or using Python?
I need data from 2015 to 2023 by keywords.
Thank you!
","['database', 'news']",
Are there free datasets available with several tables?,"
I want to make a presentation with comparison of pandas and pyspark. For this purpose I need some data and ideally a research task that will allow me to:

Show how joins works in both libraries. So at least the data should consist of two datasets. Ideally data should allow and the task should require some joins/group bys to be performed to show all the spark sql features.
Compare the speed of the libs.
Ideally data should come with a research task/tutorial, so I could show PySpark mllib in action

Could someone please suggest a tutorial/kaggle page/anything that will fit my requirements?
",['data-request'],
Australian construction cost forecasts,"
The Australian Bureau of Statistics publishes a series of Producer Price Indexes (PPI) that include an index for housing construction costs, both for Australia as a whole and for each of the individual states.
I'm trying to find a series that I can use in conjunction with the actual PPI, in the same way that one might look at inflation forecasts together with later, empirically recorded inflation values. Specifically, I'm looking for a series that shows what the expectation was at some point in time prior to the publication of any particular quarterly index value. For example, the (hypothetical-until-found) series might show what March 2023 quarterly value of the PPI was expected back in 2021 ... or even more crudely, what the annual 2023 change was expected to be back in 2021.
Any suggestions for where I might look.
","['data-request', 'time-series', 'australia']",
DOL Data Dictionary Code Table,"
I have reviewed the existing DOL data dictionary where certain codes are missing and it references the code table throughout the list. For example, the following table, osha_accident_injury in the description states cause of injury (code table OPER). The code table is referenced throughout the list but I need help finding this code table.
",['labor'],
Block randomization with blockrand,"
I would like to do stratified randomization on three variables: gender, age (2 categories) and center (4 categories). So the number of strata is 2X2X4. This makes 16 strata. I would like 50 people per stratum. So I coded it like this (below).
## Stratified on center/ Sexe / Age
C1_ageSup60_male <- blockrand(n=50, id.prefix='C1S60M', block.prefix='C1S60M',stratum='C1_ageSup60_male')
C1_ageSup60_female <- blockrand(n=50, id.prefix='C1S60F', block.prefix='C1S60F',stratum='C1_ageSup60_female')
C1_ageInf60_male<-blockrand(n=50, id.prefix='C1I60F', block.prefix='C1I60F',stratum='C1_ageInf60_male')
C1_ageInf60_female<-blockrand(n=50, id.prefix='C1I60', block.prefix='C1I60',stratum='C1_ageInf60_female')

C2_ageSup60_male <- blockrand(n=50, id.prefix='C2S60M', block.prefix='C2S60M',stratum='C2_ageSup60_male')
C2_ageSup60_female <- blockrand(n=50, id.prefix='C2S60F', block.prefix='C2S60F',stratum='C2_ageSup60_female')
C2_ageInf60_male<-blockrand(n=50, id.prefix='C2I60M', block.prefix='C2I60M',stratum='C2_ageInf60_male')
C2_ageInf60_female<-blockrand(n=50, id.prefix='C2I60F', block.prefix='C2I60F',stratum='C2_ageInf60_female')


C3_ageSup60_male <- blockrand(n=50, id.prefix='C3S60M', block.prefix='C3S60M',stratum='C3_ageSup60_male')
C3_ageSup60_female <- blockrand(n=50, id.prefix='C3S60F', block.prefix='C3S60F',stratum='C3_ageSup60_female')
C3_ageInf60_male<-blockrand(n=50, id.prefix='C3I60M', block.prefix='C3I60M',stratum='C3_ageInf60_male')
C3_ageInf60_female<-blockrand(n=50, id.prefix='C3I60F', block.prefix='C3I60F',stratum='C3_ageInf60_female')

C4_ageSup60_male <- blockrand(n=50, id.prefix='C4S60M', block.prefix='C4S60M',stratum='C4_ageSup60_male')
C4_ageSup60_female <- blockrand(n=50, id.prefix='C4S60F', block.prefix='C4S60F',stratum='C4_ageSup60_female')
C4_ageInf60_male<-blockrand(n=50, id.prefix='C4I60M', block.prefix='C4I60M',stratum='C4_ageInf60_male')
C4_ageInf60_female<-blockrand(n=50, id.prefix='C4I60F', block.prefix='C4I60F',stratum='C4_ageInf60_female')

I would like to make sure that my program is correct.
","['programming', 'randomized-trial']",
datasets on international cross-border trade by mode of transportation,"
I'm looking for datasets on the volume and value of goods transported across international borders by different modes of transportation, such as air, sea, road, and rail. Specifically, I'm interested in the percentage of goods transported by air, and data that shows the growth in the volume of freight transported over time.
I've checked data portals such as IATA, World Bank and UN Comtrade, but haven't been able to find the specific data I'm looking for. I'm wondering if you know of any other sources or datasets that might provide this information, preferably at a global or regional level. Thank you!
","['transportation', 'global', 'trade']",
Get Wikidata Dump with countries and attributes,"
I'm trying to write a SPARQL-query for wikidata, returning all European countries with their most recent properties (population, area, average income, age of retirement and human development index). One country should fill one line because I would like to cluster this data later.
I wrote the following query but it didn't work as expected.
SELECT ?countryLabel ?population ?populationDate ?area ?areaDate ?income ?incomeDate ?retirementAge ?retirementAgeDate ?hdi ?hdiDate WHERE {
  ?country wdt:P31 wd:Q6256.
  OPTIONAL {
    SELECT ?country (MAX(?popDate) AS ?latestPopDate) ?population WHERE {
      ?country p:P1082 ?popStmt.
      ?popStmt ps:P1082 ?population.
      ?popStmt pq:P585 ?popDate.
    } GROUP BY ?country ?population
  }
  OPTIONAL {
    SELECT ?country (MAX(?areaDate) AS ?latestAreaDate) ?area WHERE {
      ?country p:P2046 ?areaStmt.
      ?areaStmt ps:P2046 ?area.
      ?areaStmt pq:P585 ?areaDate.
    } GROUP BY ?country ?area
  }
  OPTIONAL {
    SELECT ?country (MAX(?incomeDate) AS ?latestIncomeDate) ?income WHERE {
      ?country p:P3529 ?incomeStmt.
      ?incomeStmt ps:P3529 ?income.
      ?incomeStmt pq:P585 ?incomeDate.
    } GROUP BY ?country ?income
  }
  OPTIONAL {
    SELECT ?country (MAX(?retirementAgeDate) AS ?latestRetirementAgeDate) ?retirementAge WHERE {
      ?country p:P8772 ?retirementAgeStmt.
      ?retirementAgeStmt ps:P8772 ?retirementAge.
      ?retirementAgeStmt pq:P585 ?retirementAgeDate.
    } GROUP BY ?country ?retirementAge
  }
  OPTIONAL {
    SELECT ?country (MAX(?hdiDate) AS ?latestHdiDate) ?hdi WHERE {
      ?country p:P1081 ?hdiStmt.
      ?hdiStmt ps:P1081 ?hdi.
      ?hdiStmt pq:P585 ?hdiDate.
    } GROUP BY ?country ?hdi
  }
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""[AUTO_LANGUAGE],en"". }
} ORDER BY ?countryLabel

How would you write such a query?
","['wikidata', 'sparql']","You can get some of the geographical data (e.g. area) easily from geonames.org. This list comprises all world countries though.Perhaps join that list with this query to get the current list of 47 souvereign states in Europe, according to Wikidata, https://w.wiki/6nnb,Does this list fit your needs or do you define Eurpe differently (e.g. only  Western European countries)?As for retirement age, you proposed query fragment  ?country p:P8772 ?retirementAgeStmt. ...  makes no sense to me. p:P8772 is ""has blogger id"". (?)I suggest that you search some specialized databases such as data.europa.eu. It also has a (difficult to use) SPARQL interface.
Retirement ages can be found there via classic search forms, though, example: Average age at which not employed persons started receiving a retirement pension - by sex and main reason for retirement or early retirement , textfile."
"Looking for locations of childcare facilities in Spokane, Washington","
Someone has proposed an ordinance banning homeless camps in Spokane within a thousand feet of ""parks, schools, and childcare facilities"".  He admits that he hasn't made a map of the areas that would be affected, so I'm looking to rectify that situation.
Parks were easy: the city of Spokane publishes a ""parks"" dataset through their open data portal.  Schools were nearly as easy: I exported them from OpenStreetMap, since they've got both public and private schools, where the city's data only has public ones.
Childcare is proving to be difficult.  OpenStreetMap has nothing.  The city doesn't appear to have any data on the subject, and the closest thing I've found in Spokane County data is parcel data with a usage classification of ""Service - Education"", which is both overly broad and omits childcare facilities that are not the primary user of a parcel.  The state might have something, but unlike the city and county, the state doesn't have a single unified GIS or open data portal.
I'm looking for any zero-cost source of data that's better than what I've currently got.  Ideally it would be in a format that I can just open directly with QGIS, but I'm pretty good at beating data into shape.
In terms of accuracy/completeness, I'm mainly looking to answer the question ""would this cover so much of the city as to be effectively a prohibition?""  I suspect the answer is ""no, but it does effectively force homeless people out of the urban core and the poor parts of town, and into the upscale parts"", and I'd like to make an actual map demonstrating this.
",['data-request'],
Shapefile for Leeds house numbers/ civic numbers?,"
Is there a shapefile available for Leeds House Numbers/Civic numbers in line with residential population?
","['data-request', 'geospatial']",
Which licence do I need to link to when using a resource under CC BY 4.0 Generalitat?,"
I am using this WMS endpoint:
https://terramapas.icv.gva.es/0202_2022CVAL0025?service=wms&request=getcapabilities
The XML source says:
<AccessConstraints>CC BY 4.0 Generalitat</AccessConstraints>

I know that standard CC BY 4.0 licence requires me to ""provide a link to the license"". What licence do I need to link to when the licence is CC BY 4.0 Generalitat?
",['licensing'],
Unsorted list of people's first names written in only ASCII characters,"
I realize that this question is too easy for most people, but I am hoping people who type into google, ""Example of a list of people's names"" can find this.
It will save them the trouble of writing a program to procedurally generate people names or something like that.
",['names'],
"Using the openfda API, is there a way to download the 510(k) summary documents using the API? Or simple get the links to those summaries?","
I can use the API to determine if a ""statement_or_summary"" exists. Is there a way to download the 510(k) summary documents, or get links to those documents? I am fine ignoring the documents that are missing summaries.
",['openfda'],
Geographic Information Systems Public/free access to GIS data of mapped underground utilities in Metro Manila,"
I am really new to GIS, but am currently practicing this new skill via QGIS since its opensource. I am trying to make a map that will showcase known underground utilities such as water lines, fiber optics, telecom lines, drainage, electric lines, etc.. I actually manage to produce some data locations for some of these by manually locating all visibles utilities on site and transferring them thereafter to the software. But I felt lacking at some points and I might miss some important locations that is not visually present.
Can I find some useful source (shapefile,etc) for these utilities in Metro Manila so that I can compare my own set of data and merge them eventually?
",['geospatial'],
"Weather Conditions for Remagen , Germany in spring of 1945","
What were the daily weather conditions for Remagen, Germany from April 28, 1945 to May 28, 1945?
","['weather', 'germany']",
OECD API access unable to find dataset identifiers,"
I'm trying to access OECD data through their API
The documentation says the query string should look like this:
http://stats.oecd.org/SDMX-JSON/data/<dataset identifier>/<filter expression>/<agency name>

with a working example being:
http://stats.oecd.org/sdmx-json/data/QNA/all/all

I'd like to change the <dataset identifier> to point to different datasets, but I can't find the Ids used. The documentation states:

Available datasets are listed in the catalogue of OECD databases with
API. Queries can be built using the Export / Developer API feature of
the dataset browser.

But the catalogue doesn't appear to have an Export / Developer API feature. how can I find the correct API strings?
","['api', 'oecd']",I've found the XML description here:https://stats.oecd.org/RestSDMX/sdmx.ashx/GetKeyFamily/allAfter digging through this R package https://cran.r-project.org/web/packages/OECD/OECD.pdf
Public source of garden plans?,"
Is it any public repository and format of garden plans where I can check the layout and used plans, flowers of my favorite gardens? Like i.e. Hauser & Wirth garde?

","['images', 'database']",
"How to get ""Author"" field for Wikimedia Commons audio file","
I'm going to ask this by example. Take a look at this media file's page
https://commons.wikimedia.org/wiki/File:Sheerness.ogg
It has a table showing ""Author"" with a value of ""Speaker: The Voice of Hassocks
Authors of the article"". (I'm only interested in the ""The Voice of Hassocks"" part but the whole thing would be fine).
Is that author value accessible via the API? Generally speaking I can see how I can get other file info via, e.g.
https://commons.wikimedia.org/w/api.php?action=query&titles=File:Sheerness.ogg&prop=imageinfo&iiprop=timestamp|url|user|metadata|extmetadata&format=json
But looking through the output of that API request, I don't see ""The Voice of Hassocks"" appearing anywhere. Nor, looking through the API docs, do I see anything else other than metadata and extmetadata that might contain it. Is that ""Author"" info exposed via the API anywhere?
","['wikipedia', 'wikimedia-commons']","This is absolutely in the output of your query.In the Json output, look in query> pages> 3532106> ImageInfo> 0> extmetadata> Artist> value, and you'll get the following data, that may need some further data cleaning depending on your use case:Depending on what you're after exactly, it may be worth looking into the sibling node Credit> value too."
"How to get data containing the Country, the phone country code and the mobile phone digits length?","
I'm looking for data containing the name of the country, the phone country code, and the phone digits length (without the phone country code) like this
[{""name"": ""United States"", ""code"": ""+1"", ""length"": 10},
  {""name"": ""China"", ""code"": ""+86"", ""length"": 11}]

I don't need the landline number length, just the mobile number length. if a country can have multiple number lengths, like 7 and 8, then the dataset should have the max length, in this case, 8.
It would be great if I can get this data in JSON, but any format would do. I'm only finding this data on Wikipedias and such, with no reliable sources, and hard to work with, I need to copy and paste from webpages.
I need this data to validate input field phone numbers. I currently have 80 countries already, I'd like to have the complete list though.
",['data-request'],"I think this website globalcallforwarding.com/international-call-prefixes has the right data for you. It includes 242 Countries. To generate the JSON data from this, you can use this website https://tableconvert.com/html-to-json"
US Opinion Polling by State and Policy,"
I'm looking for a dataset that has a state by state breakdown of opinion polling on specific policy ideas (i.e. 'should taxes be raised' as opposed to 'how do you feel about the economy'). Most datasets I've looked through such as exit polling are too demographic focused. Additionally, most of the data on specific issues seems to focus on one issue at a time, without an easy way to scrape the data into a single dataset.
","['data-request', 'usa', 'polling']",
FDA APIs have data discrepancies,"
FDA APIs have data discrepancies. Last month and current month, I ran APIs for getting values using the below APIs, but the results were different. Last month it showed 500+ records for my filter, but this month it reduced to 250+ (February month data).The UI showing 500+ records
https://api.fda.gov/device/event.json?search=date_received:[20230201+TO+20230228]&limit=100
","['data-request', 'api', 'medical', 'openfda']",
Free or paid for quality bible data available for download?,"
Where do the ""bible apps"" for iPhone and such get their data? Are they purchasing it from somewhere? Where can I find quality bible data for download, free or paid (ideally not too expensive)?
The bible data should include things like the full text as JSON/XML/etc., be usable in commercial products somehow (through licensing or open source), and/or extra metadata related to the texts such as mapping of words to definitions or mapping to translations in different languages, counting words, etc.. Could also have bibles in multiple languages.
Where do you get the highest quality of this data for use in commercial products? I found this list of links, but not sure if that is a good place to continue my search. For example, one link says:

ABS BibleSearch API @ API.Bible – American Bible Society (free)
With nearly 2500 Bible versions available across over 1600 languages, API.Bible offers the largest collection of Bibles available. The Bible Search Application Programming Interface (API) allows any developer to include Scripture content and text anywhere in their website or application for non-commercial purposes. Access via XML or JSON requests served over HTTP using RESTful resources.

That is useless, because it can't be used for commercial purposes :/
","['licensing', 'json']",
Is there a comprehensive database of African elections that includes the number of electoral constituencies?,"
Datasets like QOG and VDEM include statistics like district magnitude, but without the actual number of electoral districts, one cannot calculate district magnitude from scratch. I have also consluted the IPU database which contains scattered information, but does not cover all African elections.
","['africa', 'elections', 'district']",
Free downloadable recipes database,"
So I had an idea to create an app for myself.
I would love to get different recipes based on X,Y,Z ingredients.
What's the best approach to do this - is there a free database/table/excel that I can get openly or are all recipes hidden under API services that are paid?
I found spoonacular that provides API for what I need, but it feels quite expensive and I'd like to have an app that I can trust that I'll always receive data and not trust 3rd party that might shut down in a year or so.

Is there some recipes that are openly available (easily downloadable) that I can start off of?
Or is there some super cheap API for this?
Or do I have to scrape free recipes websites and do it all myself? (any tips on how to do this, maybe some useful tool)?

Cheers,
","['api', 'database', 'food', 'recipes']",
Looking for historical human population density data (USA),"
I often work with GPW (Gridded Population of the World) rasters, and I know for the US part they use the housing and population censuses.
However of the US census, I have only found census data for 1990, 2000, and 2010. https://www.sciencebase.gov/catalog/item/57753ebee4b07dd077c70868
While for GPW, they have 2000, 2005, 2010, 2015, 2020. This is odd because the USA part of the GPW is supposed to be based on the US census data?
Ideally, I'd need 1990-2020 data, one raster every 5 years, but from the same source.
","['data-request', 'geospatial', 'usa', 'population']",
Is there way to get a consistent output from optFederov()?,"
In R, when I create a full factorial plan with the fac.design() function from the DoE.base package to reduce the number of necessary runs, the optFederov() function from the AlgDesign package gives a different answer every time the code is executed.
What code should I add to ensure that the optFederov() function gives a consistent answer?
I tried to use set.seed() but it has no effect here.
Here is a dummy code to show you the problem:
library(DoE.base)
library(AlgDesign)
  
  plan <-
    fac.design(factor.names=list(A=c(""A1"",""A2""),
                                 B=c(""B1"", ""B2""),
                                 C=c(""C1"", ""C2""),
                                 D=c(""D1"", ""D2""),
                                 E=c(""E1"", ""E2"")),
               seed = 2000)
  
  
  optFederov(data = plan,
             nTrials = 16,
             approximate = FALSE)

",['programming'],
Get the country from city/state/etc human input,"
I have 200000 rows of twitter data having the location attribute. I want to map the city names to their respective countries for producing demographic result based on countries. How can I do that using some formula in excel or in other efficient way.
For example: new delhi mapped to India

","['machine-learning', 'geocoding', 'sentiment-analysis', 'data-mapping', 'twitter']",
Occupational Safety and Health Act: What is Inspection type code M,"
The CSV inspection file includes a code M as an inspection type, yet the webpage does not provide a definition for M
https://developer.dol.gov/health-and-safety/dol-osha-enforcement/#osha_inspection
","['labor', 'occupational-safety-and-health-act']",
digital innovation hubs in Europe and the world - like global startup ecosystem map,"
is there a way to see all digital innovation hubs in Europe - and the world?
Guess that, there are several ways to find digital innovation hubs in Europe and the world. Here are a few options:
European Commission's Digital Innovation Hubs: The European Commission has established a network of Digital Innovation Hubs (DIHs) across Europe to help businesses digitize and innovate. You can find a list of these hubs on the European Commission's website.
Link: s3platform.jrc.ec.europa.eu/digital-innovation-hubs-tool
Digital Europe's map of innovation hubs: Digital Europe, an organization representing the digital technology industry in Europe, has created a map of digital innovation hubs in Europe. This map provides information on the location, focus areas, and services provided by each hub.
StartupBlink's global startup ecosystem map:
link: https://www.startupblink.com/startups
StartupBlink is a global startup ecosystem map that shows the location and ranking of startup ecosystems around the world. The map includes information on innovation hubs, accelerators, and other startup-related resources.
Global Innovation Index: The Global Innovation Index (GII) is an annual report published by the World Intellectual Property Organization (WIPO) that ranks countries based on their innovation capabilities. The report includes information on innovation hubs and other innovation-related resources in each country.
Google search: You can also use a search engine like Google to find digital innovation hubs in Europe and the world.
Are there more options to find digital hubs in the world - e.g. similar to the Digital Europe's map of innovation hubs
","['europe', 'digital', 'hub']",
How to access the plus-4 zip codes for NY and Boston,"
I am looking for shapefiles (or, any other GIS format) or csv/excel files on 9-digit Zip codes for the US (NY and MA states), which includes the regular 5-digit zip codes plus the 4-digit courier/routing codes. I found the 5-digit zip codes via multiple portals (including the census bureau data) but not the full 9-digit dataset. Is there a way to access the 4-digit courier codes or the full 9-digit dataset? Some private delivery services make them available for a very high fee. I am looking for open data alternatives as my funding does not cover data purchasing. Any direction will be much appreciated.
Thank you.
","['geospatial', 'usa', 'postal-code', 'new-york', 'massachusetts']",
Create a Transition/Mobility Matrix for a Panel Data,"
I am seriously stuck and need some help. If you can help me, I am open to any help or any solutions in Python, R, Stata, or Excel. I have panel data containing different waves of a survey, and this data contains quantile values of individuals (from 1 to 5). I need to create a transition matrix indicating the movements of individuals from one quantile to another for each wave change. Let’s say I have N waves of the survey, then I need to have (N-1) rows for wave changes, and 25 columns indicating the quantile changes (e.g., 1-to-1, 1-to-2, . . . , 5-to-4, 5-to-5). So, the values of each row must add up to 1, by definition. I tried a lot in Python but could not figure out how to deal with this.
I am open to trying any ideas in Python, R, Stata, or Excel, and I appreciate your help.
Note: There are some individuals that exist in each wave and there are some individuals participated only some waves.

","['programming', 'time-series', 'python']",
openfda results in spl_patient_package_insert_table not rendering HTML correctly,"
I'm accessing the spl_patient_package_insert_table data in the https://api.fda.gov/drug/label.json endpoint.  The HTML returned in this field is not rendering correctly in a browser.  Does this require any CSS or other formatting to display correctly?  See attached screen shot. Please advise.  Thank you.

","['openfda', 'html']",
EEGs of tripping brains,"
Does anyone know of available and downloadable EEG datasets of people experiencing ""psychedelic tripping"" on such drugs as LSD, Psilocybin, Ayahuasca, etc? I'm interested in whether such data can be used, similarly to field recordings, as the source of music/soundscapes that in turn can be used via listening to induce the original, or similar, tripping experiences. I'm not talking about music inspired by tripping but rather music that directly reflects the original tripping EEGs.
","['data-request', 'drugs', 'electroencephalogram']",
Access SCA Wage Determinations with REST or SOAP API,"
We would like to pull SCA Wage Determinations through the REST or SOAP API.
Can you please provide the endpoint, WADL or WSDL, and protocols for pulling this data each day?
","['labor', 'service-contract-act', 'wage-determination']",
Hospital spendings on IT services and infrastructure,"
How much do hospitals in the EU spend on Software, IT-consulting and IT-infrastructure (servers and such)? How much in individual countries, Germany being of particular interest?
This is what I tried:

checking annual reports of publicly listed companies
checking the NHS website
Scanning consulting reports from big consultancies
Reading govt reports on digitalisation in healthcare
EU initiatives and reports

So far I have not been able to find a reliable source that gives this information. It seems to me like this should be available somewhere, especially as governments are so heavily involved in health-care. Does anybody have an idea how to source this information?
","['medical', 'europe', 'germany', 'computing', 'technology']",
Endpoint to provide formatted (hyphenated) NDC from NDC with no hyphens?,"
Is there an endpoint to provide the proper formatted NDC from an NDC that's only numeric with no hyphens?
","['api', 'national-drug-code']",
Open database on food additives,"
I need an open database on food additives with the following:

The rating of the supplement.
What it's used for.
Harm.
Benefit

By supplements I mean: ""milk fat, emulsifier (soy lecithin), flavoring (vanillin); glucose syrup (corn, wheat), sugar, refined deodorized palm oil.""
I need any. even SQL, even API.
I have already tried some, but unfortunately they all only look for specific products (for example: coca cola), while I need additives (for example: sugar)
","['api', 'database', 'food', 'sql', 'additive']",
Submissions data not showing for all drugs in Drugs@FDA,"
I'm using the Drugs@FDA API to get data on submissions (e.g. for when labeling changes) for a list of drugs. I've noticed that sometimes I can get a ""Submissions"" table beneath ""Results"", but not always.
For example, I can see the submissions for HUMIRA
https://api.fda.gov/drug/drugsfda.json?search=products.brand_name:%22HUMIRA%22
But cannot see submissions for ALINIA
https://api.fda.gov/drug/drugsfda.json?search=products.brand_name:%22ALINIA%22
Checking against a direct search of Drugs@FDA, it's not as if ALINIA doesn't have any supplemental materials connected to its NDA. What explains why I don't consistently see the Submissions table? Is this the same problem as described here? New Indications via OpenFDA API
","['data-request', 'drugs', 'us-food-and-drug-administration']",
"Where can I find pdf of articles in French, their titles and abstracts/summaries?","
I have a task to find a title/make a summary of market research, in pdfs, in French.
So I'm trying to find a dataset of the closest to it to create a model.
I was thinking of press articles in pdf as long as we have their title already extracted, and the pdf. I then thought about scientific articles. If you have better ideas, I'm interested.
For the moment I have found:

A code on Kaggle that allows me to create a dataframe of scientific articles from Arxivx, with their abstracts and links to the pdfs. However it seems that it is only in English.

","['data-request', 'nlp', 'pdf', 'french', 'research-papers']",
Structure of Results Appear to Change Based on Query,"
If I run this query: https://api.data.gov/ed/collegescorecard/v1/schools?latest.school.city=Los Angeles&api_key=XXXXXXXXXXX, then the results look something like this: 
However, if I run this query: https://api.data.gov/ed/collegescorecard/v1/schools?latest.school.city=Los%20Angeles&latest.programs.cip_4_digit.code=1312&api_key=XXXXXXXXXX, then the results look something like this:

Is there a way to run the second query so that the results are structured the same way that the results from the first query are structured?
","['data-request', 'api', 'collegescorecard', 'programming', 'data-format']",
Data for multi-modal semantic search,"
Context: I am interested in the potential to use vector indexing and semantic search for multimodal data. For instance, a retail website may have unstructured text data from the advertising copy on their website, as well as structured text data (in e.g. JSON format) of chat logs between customers and sales agents, and some structured clickstream data.
There are a number of sentence embeddings that claim to be able to make semantic similarity comparisons between data with drastically different surface forms (see OpenAI's ada-002, which outperforms older models on code search, text search, and translation tasks). Theoretically, then, with these models it should be possible to embed and index a multimodal data source. The resulting index should be able to return relevant excerpts from varied sources - text chunks from the website, agent chat logs, or customer website interactions - given a queried topic.
Data: To test whether this sort of system would be possible, I'm looking for an open-source multimodal dataset with three key characteristics:

At least three data 'modes' - e.g. unstructured text, structured text, structured numeric, clickstream, etc.
Shared semantic topics - the data sources must focus on shared topics. This is important to prove that semantic comparisons can be made across surface forms.
Varied surface forms - again, to prove the system works, we need to have data sources that 'look' different, even if the topics they concern are similar.

Region: Any variant of English is OK.
License: Must be usable for commercial purposes (this is a research project, but I work for a private firm hence the requirement).
Format: Very flexible - ideally, unstructured data in .txt files and structured text/clickstream data in .json files.
","['data-request', 'nlp', 'language', 'json', 'text']",
Does anyone have good data on the evolution of the Persian Gulf from Sumerian to Modern Times?,"
So far I can't find good data on the evolution of the Persian Gulf silting up, only what it was in 6000 BP, and how it is now without anything in between. Is there any dataset (preferably vector) you can point me to?
An example of the Persian Gulf Shoreline 6000 BP

","['historical', 'time-series', 'hydrology']",
Are there any sources where you can see on what initial data the Midjourney neural network was trained,"
Is there somewhere in open sources some of the data on which this neural network was trained?
Also interested in DALL-E source dataset.
I think these datasets should be identical.
If someone has met or has information, please help.
","['data-request', 'machine-learning']",
Looking for data sets which contain psychographic and behavioural data on sports fans/ football fans,"
I am looking for data sets that study consumer personas in football, but I am fine with any sport at the moment.
These data sets can also be social media behavior data set that need not necessarily be collected through a questionnaire
","['machine-learning', 'sports', 'football']",
"Seeking DB, digital corpus, or text archive of Zen Buddhist texts","
Particularly interested in Sutras and Koans in English (open domain).
","['data-request', 'english', 'religion', 'corpus', 'buddhism']",
2 and 4 year graduation data per institution,"
I am new to the IPEDS datasets and I am interested in pulling together graduation data and related demographics per institution.
Any help is much appreciated.
Best!
","['data-request', 'usa', 'research', 'collegescorecard', 'education']",
Individual patient data (or spaghetti plot) for mutli-dose longitudinal randomized trial,"
I'm looking for data that meets the following criteria:

Randomized controlled (clinical) trial (could be in humans, but animals also fine)
individual patient data/individual records (rather than summary level information) available (or something one can digitize like a table in an online supplement, a spaghetti plot etc.)
Studied multiple doses vs. a control (e.g. dose finding RCT with placebo control, trying various intensity levels of radiation etc.)
Continuous outcome measured repeatedly over time (longitudinal data) with (approx.) fixed assessment schedule (e.g. baseline, week 2, 4, 8, 12...)
Officially published/available (or can be requested through some method) so that it could be used in a publication about a new analysis method (not somehow restricted/with unresolved privacy issues).

","['drugs', 'longitudinal', 'randomized-trial']",
Source for historical Argentina aerial WMS,"
I'm looking for information on an area between Alta Gracia - Córdoba from c. pre-1993 (anything in the 1970s or 1980s will help). Is anyone able to direct me towards any sources of historical aerial imagery in Argentina, or any WMS sources?
",['geospatial'],
"Download Point Of Interest (POI) as GIS point layer for the city of Los Angeles, USA","
I am looking for free Points Of Interest (POI) GIS data for the city of Los Angeles (LA), USA, for the year 2018. I tried OSM but the file format is .pbf. I was wondering if there is any other website where I can get historical POI (year 2018) for LA.
","['data-request', 'geospatial']",
Industry of a company in Schema.org,"
I would like to specify industry of companies (e.g., Financial, Tech, Telecom, etc.). In Schema.org, industry is only specified on Job posting. Could you let me know what schema.org type to use as the industry of a company?
","['ontology', 'network-structure', 'industry', 'semantic-web', 'schema.org']",You should consider using https://schema.org/naics on Organization since industry on job posting refers to NAICS codes based on their example. See screenshot below.You can find NAICS codes here.
"Subnational African election results, disaggregated","
I was wondering if there exists a database that tracts election results in African countries on a disaggregated level. So far, I was unsuccessful in finding one... I would be particularly interested in the elections in North & South Sudan,Cameroon, Liberia, and Mali
","['data-request', 'africa', 'elections', 'north-sudan', 'south-sudan']",
Where can I find a copy of the 2018 Uniform Plumbing Code?,"
My state, Texas, delegates to the Uniform Plumbing Code to establish standards,

Section 1301.255 adopts the Uniform Plumbing Code and the International Code Council's International Plumbing Code as they existed on May 31, 2001. The statute notes that the Texas State Board of Plumbing Examiners may adopt later versions of this code.
As of June 2021, the 2018 edition of the Uniform Plumbing Code and the 2018 edition of the International Code Council's International Plumbing Code have been adopted by the State Board's Rule 367.2 in Title 22 of the Texas Administrative Code.
Rule 367.2 also adopts codes incorporated by reference within the 2018 International Plumbing Code, which include the International Code Council's 2018 International Fuel Gas Code and the 2018 International Residential Code.
See the text of Rule 367.2 for details.

Where I can find the 2018 edition of the Uniform Plumbing Code? I know I can buy one on Amazon for $200. Since this is a part of the Texas Occupation Code, can I find a copy for free anywhere?
","['standards', 'plumbing']",
Compile-able Dataset for static analysis framework,"
I am searching for an open dataset of compile-able source code (meaning all code files are present to be fully compiled and linked) and their vulnerability CVE as a label.
most datasets I find either use code snippets (not complete code) or commit-id and we have to build the repo from scratch which cannot be done by an automated script due to the unstructured nature of the repos.
couldn't find except Juliet test suite, which is not that good for training a DL model, we need another dataset.
We can also accept datasets of binary executables with their vulnerability CVE but this type of datasets is even harder to find.
TIA
","['data-request', 'machine-learning', 'programming']",
MRI-CT paired Open Dataset for MRI synthesis from CT using Supervised Learning,"
I'm finding MR-CT Paired images to do some experiments on synthesize MRI from CT images using U-Net Architecture.
However I still have struggling finding these free datasets.
I've tried finding Open datasets  at Dataset Search on Google but the most relevant one is this one on Kaggle. But it doesn't have license and have some problems at the discussion.
I've also tried finding on IEEE DataPort but I couldn't find things I want.
Could anyone please give me some Sites to find this kind of Dataset?
Thank you.
","['data-request', 'medical', 'images', 'global', 'deep-learning']",
How are the Human Rights Data Analysis Group (HRDAG) data delimited?,"
I am trying to read an HRDAG dataset into R. (here is a link to the dataset). I don't understand how the columns are separated, and was wondering if there is a particular argument I need to specify in order to correctly read the data.
","['csv', 'human-rights', 'human-rights-data-analysis-group']",It is a tab-delimited file. You can read it in with the the readr package. For instance:
How can I use the API to query for institutions with student bodies greater than 1000?,"
I tried
https://api.data.gov/ed/collegescorecard/v1/schools?latest.student.size__gt=1000&api_key={API_KEY}

but it returns schools with exactly 1000 students
",['collegescorecard'],Looks like the correct API call is
"Database of ""metabolic profiles"" or ""power duration curves"" for cyclists","
I am looking for databases concerning the performance profiles of cyclists. It should contain values like anaerobic treshold or power around vo2peak / vo2max.
An alternative would be power-duration-curves or the whole metabolic profile including the ventilatory and lactate data.
","['data-request', 'sports']",
Customer review dataset that can be publicly reshareable,"
I'm looking for a dataset of customer reviews and whose license allows academic and industry researchers to annotate the dataset and publicly share the annotated dataset (e.g., via a GitHub repo).
I found Customer review dataset but in my case I don't wish to pay for the dataset, and it has to be publicly reshareable.
","['data-request', 'nlp']",
"Trying to get a qualifier to work, not sure what's wrong","
I'm trying to get total assets for companies within the US, but I only want assets from the most recent year available in Wikidata. I'm using P2403 to get total assets and I'm trying to use the qualifier P585, but I'm not getting results.
 SELECT distinct ?company ?companyLabel ?founding ?founder ?founderLabel ?CEO ?CEOLabel ?employeeCount ?time
WHERE 
{
  ?company wdt:P31 wd:Q6881511 .
  ?company wdt:P17 wd:Q30.
  OPTIONAL {?company wdt:P571 ?founding.}
  OPTIONAL {?company wdt:P112 ?founder.}
  OPTIONAL {?company wdt:P169 ?CEO .}
  OPTIONAL {?company wdt:P1128 ?employeeCount.}
  OPTIONAL {?company wdt:P2403 ?totalAssets.}
  OPTIONAL {?totalAssets wdt:P585 ?time}
  OPTIONAL {?company wdt:P2137 ?totalEquity.}
  
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""[AUTO_LANGUAGE],en"". }
}

","['wikidata', 'sparql', 'ontology']",
Is there a way to scrap AirBnB listings using R?,"
I would like to construct a dataset of airbnb listing locations (coordinates) for a specific area. I have tried using the R script at this link, but unfortunately does not work: https://gist.github.com/benizar/6cac0fdaab900bc5624797331aeba926
","['data-request', 'scraping']",
Unified online resource / dataset where I can view the percentage of an ETF dividend that is regarded as qualified dividends by the IRS?,"
I'm looking for an online resource / dataset where I can enter the ticker symbol of an ETF and I can see the percentage of its dividends that is regarded as qualified dividends by the IRS. Does such resource exist?
I unsuccessfully tried Fidelity's screener and seekingalpha.com. I don't want to have to dig into the ETF issuer's official website each time I'm looking for such information.
","['data-request', 'finance']",
Up-to-date Sweden geolocation of postcode,"
I am trying to calculate distance between postcode in Sweden.
But Sweden is changing post codes every year since 2012, and no an open database is up-to-date.
(Source : Here : https://www.postnummerservice.se/nyheter/postnummeraendringar-mars-2023)

Sources found with full addresses but not up to date:

http://download.geonames.org/export/zip/ (is often the source of all sources, and contains a lot of countries)
https://pypi.org/project/pgeocode/
https://data.opendatasoft.com/explore/dataset/geonames-postal-code%40public/information/?flg=fr
https://swe.postcodebase.com/taxonomy/term/1268?page=5
https://data.opendatasoft.com/explore/dataset/geonames-postal-code@public/export/?flg=fr
https://www.aggdata.com/free/sweden-postal-codes
https://www.geonames.org/postalcode-search.html?q=170+62&country=SE


Seems up-to-date but can't find a downloadable source:
https://www.worldpostalcodes.org/l1/en/se/sweden/profile/postalcode/170-62
https://postal-codes.cybo.com/search/?q=170+62&pl=&i=&t=

The only up-to-date source seems to be: https://www.postnummerservice.se/ It is even used by https://www.postnord.se/ as only source of truth
But is not free
","['data-request', 'geospatial', 'postal-code', 'sweden']",
"Software quality attributes including usability, performance","
I need a dataset of software quality attributes, preferably with the classes 'usability', 'performance' and so on.
I already have ""AWARE_Aspect-Based_Sentiment_Analysis_Dataset_of_Apps_Reviews_for_Requirements_Elicitation"" dataset but it doesn't have the class 'Performance'
","['data-request', 'machine-learning', 'software']",
How to obtain traffic count for a specific highway in Germany?,"
I would like to get historical on the traffic count for a specific stretch of highway in Germany. Where can I find this information? I tried to check the BASt data but could not find a way to filter it to a specific stretch of the highway.
","['data-request', 'historical', 'traffic', 'germany']",
Where stellarium get his data on planets?,"
I wonder where stellarium get his data on all the planets, like the position, rotation etc...
I've searched a little on their GitHub but I couldn't find anything.
If there's any way to get that data with an API it'll be better
Thanks for your help :-)
","['data-request', 'astronomy']",
How should an office based business doing their carbon report deal with air conditioning chemicals? Scope 1 or Scope 3?,"
If a business, working in an office setting uses the building's AC unit (they might even own the unit) but hires in a third party for maintenance and refrigerant top-up, should they report this in scope 1 or scope 3 in their carbon report?
My thinking is, technically, they do have control over the unit, as they can choose to turn it on or off (scope 1). However, they might not get the breakdown of chemical use if it is a maintenance company doing the top-ups (scope 3). Even if they could see a breakdown of what chemicals were used, should they report this within scope 1 or 3?
Any suggestions welcome.
Context: USA, EPA greenhouse gas inventory
","['usa', 'environment', 'epa', 'office']",
What are some good web scraping services in 2023?,"
I'm trying to find a webscraper which allows me to comply with Canada's anti-spam laws (CASL) for emailing. My goal is to build connections with other companies. I want to bulk upload company websites and find emails with the scraper (primarily @info), and see if there is any expression against consent for emailing on the page where the email is on. The scraper will sort the emails which do not consent contact into one list, and sort the ones which imply consent into a different list. Implied consent simply means they don't say anything about NOT emailing the addresses, and I can redflag some keywords like ""do not"",""don't contact"" etc..
Is there any prebuilt webscraping service that offers this? Or should I get this built by someone? What are some possible companies I could contact to build this?
Will appreciate all guidance and feedback, thank you for your time.
","['web-crawling', 'scraping']",
Is it possible to download all audios of English words from Wiktionary,"
Inspired by this answer I downloaded 68563 pronunciation files(both mp3 and ogg), but I found that some audios are missing. For instance, cloze and demise. Then I tried WiktionaryParser:
from wiktionaryparser import WiktionaryParser
parser = WiktionaryParser()
word = parser.fetch('cloze')
word

The audio part is also empty, but I can find the sounds from Wiktionary: demise and cloze.
Can I still obtain these missing audio files and if not, what alternatives (such as TTS engines) are available?
","['english', 'audio', 'dictionary', 'wiktionary']",
Embed URL in text of OpenRefine cell,"
I am working on a project using open refine to search then send users to the relevant link for data that is hard to search. My current URLs to access the records take the form www.mywebsite.com/?recordID=1234 but are much longer. I would like to use HTML or some other method to create a hyperlink functionally equivalent to <a href=""www.mywebsite.com/?recordID=1234"">1234<\a> in the cell so it occupies less space.
I have been able to edit individual cells in OpenRefine using inspect element to get this to work as a proof of concept but I can edit 100K+ cells.
I have been unable to find advice/example about this. Is open refine capable of doing something like this?
",['openrefine'],
Georeferenced data on archeological discoveries in Africa,"
I am looking for any kind of georeferenced data on archeological discoveries (or maybe unsuccessful expeditions) in African countries. Ideally, these would span the last 100 years and identify the location of discovery and the ""discoverer"".
","['data-request', 'geospatial', 'historical', 'africa', 'archeology']",
Is OpenFDA for Food Recall Enforcement Reports [/food/enforcement] bulk download supports in TLS 1.2 enabled servers?,"
The bulk download with below link is not working in TLS 1.2 enabled servers. Can someone help me to understand whether OpenFDA bulk download supports in TLS 1.2 enabled servers? Or do I needs to use its API instead of bulk download.
https://download.open.fda.gov/food/enforcement/food-enforcement-0001-of-0001.json.zip
Thanks
",['openfda'],
Database of Facebook profile photos,"
Does there already exists a data set containing, for at least 100 individual people, the photos in their facebook profiles (or their profiles at the time of collection)? I want to use these some facebook profiles for a study and also potentially in marketing, but of course permission is required from each individual. It would be a pain to reach out to potentially thousands of people and get them to sign forms agreeing for their photos to be used, so I was wondering if there already exists such a dataset in which everyone represented in the data set already legally agreed for their photos to be used by any 3rd party.
","['social-media', 'faces', 'large-datasets', 'photographs']",
Tomtom historical data for specific day and time,"
Hi I’m trying to obtain a historic visual traffic report for the B219, Peckham Rye (London, UK) on the 27/4/21 at 16.45. The request is for a court case that I am involved in due to a Road traffic accident. I understand Tomtom can provide this data, but cannot find anyone who can do such a report. Prepared to pay someone if possible.
",['traffic'],
High-quality open-source street view panoramas,"
We need ~1000 high-quality panorama street view images with location that can be downloaded and used as part of an open-source project. The ideal dataset would be Google Street View Static API, but their API severely limits its use and our project does not fulfil the restrictions.
Mapillary and KartaView (formerly OpenStreetCam) both have 360-degrees panorama images licensed using CC BY-SA, which is great for open-source projects. However, the images are of very varying quality and many of them would not be suitable for our project due to being very dark, low resolution or not having full 360 degrees view.
Is there any such open-source dataset available or has anyone devised a way to filter Mapillary/KartaView to curate the high-quality images?
","['geospatial', 'images']",
Where can I find medical prescription dataset in image format?,"
I'm new to NLP and recently read about a package sciSpacy which is used to process bio-medical text. I looked online for medical prescription datasets but couldn't find anything. I was wondering if there are any such datasets available online, preferably in image format, so that I can use OCR to extract relevant details like symptoms or diagnosis? Any help is greatly appreciated!
",['medical'],
NHANES-like citizen-health dataset but for other countries (EU),"
In the USA, the NHANES datasets are collected by the Center for Disease Control (CDC, the national public health institute in the United States). It represents a random sample of US residents.
Conveniently in R these are already available in the NHANES package, containing 2009/2010 data. (I have recommended this in previous answers here).
In NHANES, there are 10000 rows and 76 columns: ID, SurveyYr, Gender, Age, AgeDecade, AgeMonths, Race1, Race3, Education, MaritalStatus, HHIncome, HHIncomeMid, Poverty,  HomeRooms,  HomeOwn,  Work,  Weight,  Length,  HeadCirc,  Height,  BMI,  BMICatUnder20yrs,  BMI_WHO,  Pulse,  BPSysAve,  BPDiaAve,  BPSys1,  BPDia1,  BPSys2,  BPDia2,  BPSys3,  BPDia3,  Testosterone,  DirectChol,  TotChol,  UrineVol1,  UrineFlow1,  UrineVol2,  UrineFlow2,  Diabetes,  DiabetesAge,  HealthGen,  DaysPhysHlthBad,  DaysMentHlthBad,  LittleInterest,  Depressed,  nPregnancies,  nBabies,  Age1stBaby,  SleepHrsNight,  SleepTrouble,  PhysActive,  PhysActiveDays,  TVHrsDay,  CompHrsDay,  TVHrsDayChild,  CompHrsDayChild,  Alcohol12PlusYr,  AlcoholDay,  AlcoholYear,  SmokeNow,  Smoke100,  Smoke100n,  SmokeAge,  Marijuana,  AgeFirstMarij,  RegularMarij,  AgeRegMarij,  HardDrugs,  SexEver,  SexAge,  SexNumPartnLife,  SexNumPartYear,  SameSex,  SexOrientation,  PregnantNow
As you can see many questions are quite specific (UrineVol1) and personal (SexNumPartnLife).
Are there any datasets comparable to this,? Similar column-definitions, similar survey method, but for other countries? I am mainly interested in EU countries. Like a GapMinder dataset but for health data, and on an individual level.
(Note to self: check answers to Q Various country Statistics Q
","['medical', 'europe']",
"Daily temperature, GDP growth, population growth for Long Island (New York) during 2015-2022","
I need to predict the daily peak electricity demand for Long Island during 2015-2022. I found the weather forecast data (here). I also looked at this, but I could not find the temperature data for the Long Island. Also, I do not know how to extract other data from here and here. I would greatly appreciate it if you could let me know how to have access to the daily temperature, GDP growth, and population growth data for the Long Island zone during 2015-2022.
","['data-request', 'uses-of-open-data']","Try this for your temperature data. You'll need to use a location that is close to your region of interest.
https://www.weather.gov/wrh/climate?wfo=okxFor the GDP, as far as I know, the smallest geography available is at county and metro level so, again, you'll need to use a region that is representative of your area of interest. I suggest you determine a geography that best fits your area and try to stick with that for all your data in order to be consistent. Since you can find quite a bit of data by county, maybe use Nassau County for the GDP and Population?GDP data comes from the Bureau of Economic Analysis (BEA) here: https://www.bea.gov/data/gdp/gdp-county-metro-and-other-areasFRED (the St Louis Federal reserve) has the BEA GDP here, that is sometimes easier to digest: Metro area data here: https://fred.stlouisfed.org/series/NGMP35620 and for the county here https://fred.stlouisfed.org/series/REALGDPALL36059And finally, population growth would come from the Census Bureau, as you know. Estimates are not yet available for 2022, but you can get growth through 2021 data from here:
https://www.census.gov/programs-surveys/popest/data/tables.2021.List_58029271.html#list-tab-List_58029271Happy data wrangling!"
Availability of diffusion prepared pseudo continuous arterial spin labelling open source data set,"
I am new to the neuroimaging field and would like to ask if there is a possibility for me to access open source diffusion prepared pseudo continuous arterial spin labelling MRI images for me to familiarise myself with the processing steps of such images. I am currently waiting for my lab to introduce the above mentioned sequence into their protocol and was hoping to do some processing in the mean time with the above stated open source images. Thank you
","['medical', 'uses-of-open-data', 'images', 'research']",
"Finding multi-family homes in Atlanta, GA","
How would you all suggest looking for this home type in Atlanta, GA ITP and not too far south. Using a Realtor, a modern website (Zillow, Redfin etc.), browsing bank foreclosures? Maybe there are other data sources that you suggest that I am not aware of as well.
",['real-estate'],
Where to find more detailed data relative to doctoral students registered in the US Student and Exchange Visitor Information System?,"
In short, I'm looking for some detailed data about doctoral students registered in the US Student and Exchange Visitor Information System (SEVIS), broken down by type of doctoral degree (e.g. PhD vs. professional doctorates).
To give some context, if it's of any help: I'm conducting some research on international students, and I noticed an important discrepancy between the Organization for Economic Co-operation and Development (OECD) data and the official figures given by the SEVIS, relative to the number of international doctoral students enrolled in the US.
For example, according to the OECD data, in 2019 there were 88,530 mobile students who were enrolled in a doctoral program in the US. However, the SEVIS says (p.5) that ""There were 187,902 F-1 students who sought a doctoral degree in calendar year 2019"". There might be a small difference between the definition of ""mobile student"" and ""F-1 student"", but I don't think that on its own it explains a difference of 100,000 people.
The most likely explanation I see is that the SEVIS definition of ""doctoral program"" differs from what the OECD calls ""doctoral or equivalent level"". Unfortunately, in the link mentioned above, the SEVIS does not give information on what they include in ""doctoral programs"".
My suspicion is that the SEVIS counts professional doctorates as doctoral degrees, while the OECD does not. But I'd like to make sure this is actually where the difference comes from, and I probably need more detailed data for that.
If you have some suggestions of other datasets or documents that might explain this difference, I'd be glad to hear about it!
Thank you,
","['research', 'education', 'migration']",
Seeking open SNMP data,"
I want to code an SNMP decoder, but only have simplistic examples.
I would strongly prefer SNMP Get Responses - as raw hex dumps. I would like to see a response for a Get with multiple OIDs; even better if the response values are of different data types (int, string, bool, etc).
I would settle for details of the parameters to an SMP Get command which will return me a raw hex dump. Failing that just the command line and I can capture the raw hex with Wireshark.
",['snmp'],
SQL version of Wordnet,"
The original Wordnet is not in SQL format. I found these two as SQL converters
http://www.semantilog.org/wn2sql.html#word
https://wnsql.sourceforge.net/
There may be others.
Could you help me in choosing between them or suggesting any others?
",['wordnet'],
API to get the population by country,"
Is there a free API to get the population of every country ?
I've searched on the World Bank Open Data but I didn't find the API for it.
","['api', 'uses-of-open-data', 'population']","Yes, the World Bank offers an API access for free, and you can retrieve this kind of data quite easily. The API documentation is available here: https://datahelpdesk.worldbank.org/knowledgebase/topics/125589In the ""API Basic Call Structures"" section, they give a very simple example of how to get the population of all countries in the year 2000, in XML format:http://api.worldbank.org/v2/country/all/indicator/SP.POP.TOTL?date=2000.Don't forget to follow their recommendations when using the API: https://datahelpdesk.worldbank.org/knowledgebase/articles/902064-development-best-practices"
Looking for a free dataset of book titles classified by some well-established and unified classification system,"
I am looking for a free dataset of book titles:

Classified by Dewey Decimal Classification (DDC) or by Library of Congress Classification (LCC).
Wide coverage. I've seen Researcher Format (CSV) datasets at British Library: https://www.bl.uk/collection-metadata/downloads, but they contain only themed (very specific) samples of books. I would like to have a wide variety of DDC categories covered.
Ready to download as dump. I know there are API endpoints (SPARQL) to their resources but before jumping to this kind of task I would like to make sure such a dataset does not exist.
With titles in English.

","['data-request', 'language', 'english', 'books', 'bibliography']","I think you may be underestimating the BL dataset - the ""researcher-format"" CSVs are small themed sets of papers, but the ones just above it on that page include the British National Bibliography (BNB). 2GB fully linked RDF/XML for books, or a smaller 1GB file with less detailed RDF/XML.The BNB is (more or less) every book published in the UK and Ireland since 1950 - if they have made it to one of the UK or Irish legal deposit libraries, they will be indexed here (some general exceptions).The sample file for the basic BNB dataset appears to have 2958 titles and 2828 have a Dewey code assigned, so it looks like coverage is pretty good. Almost everything will be English-titled given the origins - I think all the records in the sample are? - but there is a language field so you can screen out non-English material.(The Integrated Catalogue files is non-BNB material held by the BL, primarily overseas and historic books, and generally speaking these are less likely to have Dewey numbers assigned and also substantially more likely to be non-English language.)"
Average/median hotel price per US county,"
I am looking for a dataset containing or allowing me to compute the average or median hotel price per US county. So far, I've only found the average rent per US county (visualization), but not for hotels.
","['data-request', 'usa', 'travel']",
Need NRCS 2008 Common Land Unit (CLU) GIS dataset,"
I am hoping someone in this group has a copy of the NRCS Common Land Unit GIS coverage. People were looking for it back in 2017 and earlier, but all the sources listed then have dried up. Can anyone help me? I am specifically looking for coverage of northern California.
","['data-request', 'geospatial', 'agriculture']",
Getting an error trying to submit app to showcase,"
When I try and submit my app to the showcase at:
https://datasf.org/showcase/made-with-open-data-survey/
I get a error: ""Error saving""
Any suggestions on how to get around this?
",['uses-of-open-data'],
"Where can I find the 2015, or any version for that matter, of the ImageNet VID dataset?","
I don't know if this is the right place to ask. If it isn't, I hope I can be referred to a more appropriate place.
Most of the papers for video object detection reference ImageNet VID so I want to access it to make sure the models are working fine. However, I can't find a working link to download the dataset. I was looking for the 2015 version but at this point any version will do.
I tried The official website but nothing happens when I try to download, even after I made an account on the website. The help email isn't responding either. I found similar questions on stackoverflow and reddit but they either provide dead links or go unanswered. Kaggle datasets include the images but I couldn't find the video datasets.
Is the ImageNet VID dataset no longer available or am I missing something? Your help and guidance are greatly appreciated.
","['data-request', 'machine-learning']",
PRP(Platelet reach plasma) and blood bags,"
I am looking for some websites that can give me more information about PRP and blood bags market in the world and specialy in GCC. This kind of PRP is useful for ortopedi. Also I need to know about amount of importation of blood bags in GCC or  Dubai . If you know suitable website that can give me this information free please introduce me.
",['global'],
What data format (from German destatis) is that?,"
I would like to identify that data format. Is there an official name for it that I could use in a search engine (of my trust) to go on with research about supporting tools? Is this a (quasi) standardized data format?
This question is not about to understand the data or how to process them. I do understand the structure and I'm able to write my own code to process it. But I assume the format is quit old and there must be some tools out there. I also want to understand the design decisions behind that (IMHO wired) format.
It comes form Destatis (Federal Statistical Office of Germany) and can be downloaded here. The codebook for that data is a PDF file and is also bundeled with the archive behind that download link.
102023013101          Schleswig-Holstein                                Kiel                                                                                                                     
402023013101001       Flensburg, Stadt                                  Flensburg                                         41                                                                     
502023013101001   0000Flensburg, Stadt                                                                                    50                                                                     
6020230131010010000000Flensburg, Stadt                                                                                    61    000000056730000009111300000045336    24937*****  2115111211901001
402023013101002       Kiel, Landeshauptstadt                            Kiel                                              41                                                                     
502023013101002   0000Kiel, Landeshauptstadt                                                                              50                                                                     
6020230131010020000000Kiel, Landeshauptstadt                                                                              61    000000118650000024624300000119860    24103*****  2119151713101005
402023013101003       Lübeck, Hansestadt                                Lübeck                                            41                                                                     
502023013101003   0000Lübeck, Hansestadt                                                                                  50                                                                     
6020230131010030000000Lübeck, Hansestadt                                                                                  61    000000214190000021627700000104005    23552*****  2122172113501011
402023013101004       Neumünster, Stadt                                 Neumünster                                        41                                                                     
502023013101004   0000Neumünster, Stadt                                                                                   50                                                                     
6020230131010040000000Neumünster, Stadt                                                                                   61    000000071660000007949600000039382    24534*****  2124151913901006
402023013101051       Dithmarschen                                      Heide                                             43                                                                     
502023013101051   0011Brunsbüttel, Stadt                                                                                  50                                                                     
502023013101051   0044Heide, Stadt                                                                                        50                                                                     
502023013101051   5163Burg-St. Michaelisdonn                            Burg (Dith.)                                      51                                                                     
502023013101051   5166Marne-Nordsee                                     Marne                                             51                                                                     
502023013101051   5169Eider                                             Hennstedt                                         55                                                                     
502023013101051   5172Heider Umland                                     Heide                                             55                                                                     
502023013101051   5175Mitteldithmarschen                                Meldorf                                           51                                                                     
502023013101051   5178Büsum-Wesselburen                                 Büsum                                             51                                                                     
6020230131010510015175Albersdorf                                                                                          64    000000017120000000377200000001837    25767       2123131912701003
6020230131010510025175Arkebek                                                                                             64    000000006920000000022000000000114    25767       2123131912701003
6020230131010510035163Averlak                                                                                             64    000000009060000000055800000000290    25715       2123131912705003
6020230131010510045175Bargenstedt                                                                                         64    000000011900000000096500000000468    25704       2123131912713003
6020230131010510055169Barkenholm                                                                                          64    000000005110000000016400000000092    25791       2116131912701002
6020230131010510065175Barlt                                                                                               64    000000022880000000077700000000385    25719       2123131912713003
6020230131010510085169Bergewöhrden                                                                                        64    000000002640000000003700000000017    25779       2116131912701002
6020230131010510105163Brickeln                                                                                            64    000000006070000000019800000000108    25712       2123131912705003

The codebook or description of the format comes as a (non machine readable) PDF file. Here is a snippet from it describing the Satzart 10.

Here is another part of the codbook describing the Satzart 60.

Some facts about that format.

There is no field separator.
Fields have a fixed length.
But number of fields and their length is different between the lines. The format of one line is not consistent of the whole file.
The first two characters of each line decide how the rest of the line should be interpreted.

",['data-format'],
Dutch TTF Daily Prices,"
I am looking for a daily price time series of Dutch TTF Natural Gas from 2016 until now.
I've been looking for quite some time now and I probably looked at most search results on google for this. I found some nice data at investing.com, but the data is only available from the end of 2017. Does anyone now where I can get more daily data?
","['time-series', 'energy', 'prices']",
How to populate instances of World news Ontology,"
We are trying to implement this research paper named: ""Semantic search in the World News domain using automatically extracted metadata files"" (available at https://www.sciencedirect.com/science/article/pii/S0950705111002735)
In this paper, the authors used an ontology called World News ontology (WNO). But we are not sure about how they populated instances for this ontology. The main purpose of this ontology is to annotate online news articles. For that, they loaded this ontology in the GATE developer (General Architecture of Text Engineering) and used the ANNIE pipeline to do the final annotation.
World News Ontology: IPTC (International Press Telecommunications Council) provides a set of terms called NewsCodes. The authors used a subset of NewsCodes to build this ontology. This subset contains the following subjects:

crime, law & justice
disaster & accident
economy, business & finance
environmental issue
health
labour
politics
science & technology
social issue
unrest, conflicts & war
weather

Each of these subjects has three levels: Subject, Subjectmatter, and Subjectdetail.

Subject: terms of level ‘‘Subject’’ provides a description of the editorial content of news at a high level
Subject matter: a ‘‘Subjectmatter’’ provides a description at a more precise level.
Subject detail: a ‘‘Subjectdetail’’ provides a description at a rather specific level.

For example,

For science and technology, the first level, subject is science & technology, the second level, Subjectmatter is biomedical science, and the third level, Subjectdetail is Subjectdetail.
Since they have not provided any explicit reference to the structure of the ontology, we have assumed that all the Subjects would be the World News Ontology classes. The terms of the next level (Subjectmatter) would be subclasses of the 1st level and the terms of the last level (Subjectdetail) would be subclasses of the 2nd level. But we are not hundred percent sure if our assumption is correct.
Now to annotate texts from news articles, we need to have instances in this ontology. The only thing the authors mention about populating the World News Ontology is as follows:

Onto Gazetteer makes use of one important concept in the ANNIE
subsystem, which is gazetteer lists. These are very important for the
annotation process because they contain the words that are going to be
matched in the document so as to produce annotations. In our case, the
WNO is integrated with ANNIE so as to find terms and concepts from the
ontology. To achieve this, we created a gazetteer list for every term
of the WNO. This list contains synonyms of the term or even phrases
that may define it. This process resulted in the creation of 465
gazetteer lists with a total of approximately 24000 records. The Onto
Gazetteer component is responsible for finding matches of words or
phrases contained in these lists in the articles which are being
processed. Finally, it generates an annotation for every match.

This seemingly indicates that they populated the ontology using Gazetteer lists. But surely they haven't created all these 465 gazetteer lists manually. Is there any way to automatically create a gazetteer list? And also, how to populate an ontology from a gazetteer list? Is our assumption for the World News Ontology correct?
",['ontology'],
Where can I find the number of family caregivers in the United States by year?,"
There are data sources like Caregiver Action that cite the AARP with data every 4 - 5 years, for example, and there are past supplements to surveys like the CDC's BRFSS, but I'm looking for a data source that has relatively recent data, by year, on something like ""X# of people ages 18 - 45 care for an elderly family member or a child or a sick family member.""
","['data-request', 'usa', 'medical']",
Occupational Prestige Measures,"
I'm looking for data where occupational prestige has been measured. I would like to analyze data over time to see, if occupational prestige of different jobs changes over time. If you don't know of any primary data sources, you may have an idea of what data indirectly measures occupational prestige.
Thank you in advance!
",['data-request'],
Fort Peck historic topographic maps,"
I am looking for historic topographic maps of the Missouri River before the Fort Peck Reservoir/Dam was built in 1940 (in the area of the Fort Peck Reservoir). I have searched National Map Viewer but they only have a small portion of the area. If anyone has scans of these topos or knows where I could look or find them I’d be grateful!
Alternatively if anyone had bathymetry data for Fort Peck Reservoir, that would be second best!
","['data-request', 'usa', 'historical']",
"Images of basal cell carcinomas (BCC) annotated with the BCC type (Superficial, Nodular, Pigmented, Morpheaform / Infiltrating, etc.)","
I am looking for a dataset containing images of basal cell carcinomas (BCC) annotated with the BCC type (Superficial, Nodular, Pigmented, Morpheaform / Infiltrating, etc.) and ideally some image segmentation indicating where the BCC is on the image.
https://skinio.com/education/basal-cell-carcinoma/ (mirror) presents the main 4 types of BCC:

","['data-request', 'medical', 'images']",
data.dol.gov/get 'invalid API key' (python),"
I keep getting an 'Invalid API key' response when trying to make a call to the data.dol.gov v2 API. Here is what my call looks like, please help!
base_endpoint = 'https://data.dol.gov/get/'
target_endpoint = 'publications_view/format/json/limit/1'
token = 'MY_API_TOKEN'

response = requests.get(base_endpoint + target_endpoint, headers={""X-API-KEY"":f""{token}""})
print(json.dumps(json.loads(response.content.decode('utf-8')), indent=2))

I have been following the instructions on the API version 2 for the department of labor here: https://developer.dol.gov/accessing-the-apis-using-http-requests/
I also saw multiple unanswered posts from other users in the forum.
P.S. If I try v1 api it works, but I cannot get to the data I need using V1.
response = requests.get(""http://api.dol.gov/V1/DOLAgency/Agencies/?KEY=MY_API_TOKEN"")
print(response.content.decode('utf-8'))

","['api', 'labor', 'python']",
Dataset for training siamese convolutional neural network for identifying identical unique objects,"
The problem I am trying to solve is, given two images, determining whether they contain the same object or not. Here is an example:



The first two images contain the same object, while the third image contains a similar, but different object. My goal is for the first two images to be seen as a match, but the first and third (and second and third) being seen as not matching. I want the matching to work in general with any object. It should be able to tell if any two pictures of any two objects are identical objects (not just similar) even if they are taken at different angles, cameras, and lighting conditions.
To accomplish this goal I have moved towards using transfer learning to train a siamese neural network (on a pretrained imagenet model) with the triplet loss function. The problem is that I do not have a dataset that is suitable for this. I cannot find any datasets that have pairs of identical objects from different angles, lighting, cameras, ... This is what I believe I would need for training to be successful.
","['data-request', 'machine-learning']",
api.fda.gov is failing security check,"
This server couldn't prove that it's api.fda.gov; its security certificate is from *.fr.cloud.gov. This may be caused by a misconfiguration or an attacker intercepting your connection.
",['openfda'],
Open source earth imagery Web Map Tile Service,"
I need a WMTS earth imagery (just normal, rgb band) that is open source.
I am going to use it as a basemap in webgis.
Is there any?
","['geospatial', 'api', 'images', 'legal', 'open-source']",
Biomedical datasets (preferably single-cell) that are amenable to logistic regression,"
Can anyone suggest some biological datasets, preferably measuring gene expression levels, that I could use as examples for logistic regression (so there's some sort of categorical outcome variable)?  The larger the better (within reason, I guess)
","['data-request', 'medical', 'biology', 'categories']",
Airport passenger traffic dataset - worldwide,"
I am searching for an open database of airport traffic data. Ideally, the dataset would contain as many airports for as many countries as possible. Something like this Wikipedia page but much larger.
Ideally, the data would be of a format similar to the above link:
|airport name| airport code| airport lat/lon| passengers in year X| passengers in year X-1| change in passengers traffic compared to previous year
","['data-request', 'api']",
San Francisco traffic lights green/yellow/red timings,"
Where would one go about finding data for traffic lights?
For example, scheduled timings as well as actual (historical) timings.
(San Francisco)
","['usa', 'traffic']",
The 2023-01-02 openFDA recall file is missing searchable fields,"
The 2023-01-02 openFDA json file (https://open.fda.gov/apis/device/recall/download/) is missing searchable fields.
For example, the field cfres_id is missing (was available in the 2022 json files).
Is this file somehow corrupted?
",['openfda'],"Sorry for the late reply here, but it looks like this was a temporary issue - the field is available on the download files now. Let me know if you're still having issues.Regards,Violet WrenopenFDA Tech Lead"
Count number of pedestrians on an arbitrary street,"
I'm looking for data that allow me to estimate the number of pedestrians and/or cars passing by on a certain part of a certain street at a certain time. Any ideas on where and/or how I can get this data?
I'm also interested in demographics of such a dataset.
","['geospatial', 'city', 'demographics']",
Family budget or expense-money tracker dataset,"
I'm looking for some family budget or expense tracker large dataset, in any format, to have some sample data to test an application on large scale.
The dataset must have the detailed records of any payment, I'm not interested in aggregated data, since it is the job my application has to do.
I would love to have something with those columns: date, type, description, amount (of the single transaction), like in this template I have found online, which unfortunatly does not come with any data, BUT with single transactions instead of subtotals:

Maybe I'm missing some important keyword or just searching in the wrong place.
Thanks for your help!
EDIT
After searching for some hours I found this dummy data link from a youtube video on how to create an expense tracker, if anybody can provide a better dataset it would be very useful!
For those who don't want to open the link, this is how the data looks like (as I said I'm more interested in something like the image I posted above with also payment type and a description, and the ""vendor"" column isn't interesting for me, but this was the ""best"" I've found):

",['data-request'],
fda Drug -NDC API/ information,"
I am in the process of developing a drug/NDC service/API(planning to create a Drung/NDC db local copy) After going through fda documentation have some questions in terms of the solution option. If i understand right i can get the latest fda ndc data from https://open.fda.gov/data/ndc/ (Original dataset downloads). If i load this via SSIS etc what are the options to keep this updated. Downloading and loading this daily seems too much over head. Is there a better option via the API to get the delta updates daily. the API seems to have only filtering based on start marketing date (there is no create or update date field). Thanks in advance for the help
",['api'],
Ready dataset which one piece of the dataset is in csv flat files and the other piece in a database schema,"
Is there any ready dataset which one piece of the dataset is in a csv flat files and the other piece in a database schema to mount a Data Warehouse?
Basically I wanna do this process in my lab and create a DW.

",['data-request'],
Is there a database where I can find the postal codes of Portugal as polygons?,"
I am searching for a file where I can see Portugal's 7-digit postal codes as polygons.
Does anybody know of a database or a site where I can find information like that?
","['data-request', 'geospatial', 'postal-code', 'portugal']",
Is there a database where I can find the postal codes of Portugal as polygons?,"
I am searching for a file where I can see Portugal's 7-digit postal codes as polygons.
Does anybody know of a database or a site where I can find information like that?
","['data-request', 'geospatial', 'postal-code', 'portugal']",
Two or more functional explanatory variables X for the same scalar response variable y to test group prediction,"
I evaluate the performance of prediction algorithms in the PLS family (Partial Least Squares or Projection onto Latent Structures; information). They used datasets  composed of N observations of  one-dimensional functional data (independent or explanatory variables) X_n (gathered in a matrix X), to predict a scalar response or dependent variable y_n (gathered in a vector y).
I am looking for (at least) two sets of explanatory variables X1 and X2 that, separately, can be used to predict the same response y, to evaluate whether combining X1 and X2 yields improved performance in the prediction of y. Typical observations of interest are in the field of chemometrics: explanatory functional data are analytical chemistry signals/spectra (chromatography, infrared spectrometry, NMR), and the response variable is a macroscopic property (density, viscosity), related to chemical mixtures.
","['data-request', 'machine-learning']",
The openFDA API supports searching by range in date not working?,"
I would like to create an URL, that shows me all reports from the MAUDE database from December with the product key 'MQB'. I created the this URL as an attempt:
https://api.fda.gov/device/recall.json?search=product_code:MQB%20event_date_posted:[2022-12-01%20TO%202022-12-31]&limit=1000

I have also tried without the hyphens between the year, month and day, so: ...[20221201+TO+20221231]&limit=1000.
Both behave the same, they display all reports from all months. The date limit doesn't really apply.
Has anyone had the same or a similar problem?
The syntax of the query is described on the official site, here.
","['api', 'openfda']",
Any sources for Global Hailstorm Spatial Data?,"
Is there somewhere I could find the global Hailstorm data which I could further use as a base to find/identify the Hail Risk and annualized frequency? NOAA has it pretty well but only for US.
","['data-request', 'geospatial', 'open-source']",
Hourly wind turbine electricity/power production data for single installations in the UK?,"
I'd like to check my wind speed calculated yield against actual yield. Ideally, I would like to know:

Turbine location
Turbine model details
Hourly yield (or other small timestamp)

I've found helpful answers referring to this French resource: https://opendata-renewables.engie.com. But one or more datasets of turbine output data for the UK would be really helpful, if anyone knows of such a resource.  Thank you.
","['data-request', 'weather', 'uk', 'time-series', 'energy']",
Looking for a Cellular network environment or Heteregenous wireless networks environment Datasets,"










                                This question was migrated to Open Data Meta Stack Exchange, our site for discussion, support, and feature requests for this site.
                                Migrated 8 months ago by Orophile♦.
                            






I am looking for a Cellular network environment or Heterogeneous wireless networks environment Dataset. A dataset that includes network parameters as features such as delay, jitter, throughput, cost fo network ...etc.
","['data-request', 'large-datasets']",
River catchment dataset for the Middle East,"
I need river catchment spatial data belonging to the Middle East for a research project. It can be any spatial data format(GeoPackage, GeoJSON, Shapefile, CSV with coordinate, KML, etc.). I can easily convert it to the format I need.
All I found in the context of hydrology is Geo-referenced database of dams (Middle East). There are other kind of hydrological data like rivers, lakes etc, but no river catchments.
","['data-request', 'geospatial', 'hydrology']",
How to find occupancy/vacancy rates of apartments,"
According to https://www.apartmentdata.com/databases/marketlineADSonline_TXAU.pdf the Apartment Occupancy rate in Austin, TX is just over 90%. My question is...  How did they make this determination? Is there some public data set that contains this data? Is there a way, using a free or paid data set, to determine the occupancy / vacancy rate of a particular apartment complex?
","['usa', 'real-estate']",
Competitions and incentives for open source data,"
There are websites such as Kaggle that people compete to best analyse open source datasets, but are there any websites or organisations where people compete or are incentivised to create open source datasets?
",['releasing-data'],
Where do I get the location of Elon Musk's private jet?,"
Given that he has banned the Twitter account that tracked his private jet, I wondered if anyone knew where the account got its data from.
",['aviation'],"The new microblogging account is on Mastodon:https://mastodon.social/@elonjetHowever, the data is and always has been coming from https://ADSBExchange.comWhile free to see on the website, ADSBExchange's data is not actually strictly open in API nor download form:Commercial Usage TermsAs noted in the legal terms and conditions, commercial (for profit or non-profit organization) use requires written authorization from ADS-B Exchange.  This is necessary to ensure operating this site remains financially viable and continues to provide unfiltered global tracking services.Commercial users are required to contact ADSBexchange for a commercial data license agreement. While our pricing is far less than other “big” providers, the technical infrastructure for running a site of this scale does require ongoing funds to support it.No bulk resale or redistribution is permitted without consent from ADSBexchange.com.Global low latency access is available with a commercial usage agreement."
Question re: Recent full service restaurant data sweep (W&H Compliance),"
I am working with the Wage & Hour Compliance Data to understand FLSA violations in the full-service restaurant sector and am using the WHD Whisard dataset. I am wondering if there has been a recent data sweep for full-service restaurant wage violations? My specific area of interest is in the sub-minimum wage (aka tipped wage).
A secondary question is: is there a variable for repeat offenders?
Thank you!
","['labor', 'restaurant']",
Wikidata COUNT(*) query times out,"
I have a straightforward query that counts how many humans have an English Wikipedia page.
prefix schema: <http://schema.org/>
PREFIX wikibase: <http://wikiba.se/ontology#>
PREFIX wd: <http://www.wikidata.org/entity/>
PREFIX wdt: <http://www.wikidata.org/prop/direct/>

SELECT ?item ?article
WHERE 
{
  ?item wdt:P31 wd:Q5 . # Must be of a human
  ?article schema:about ?item ; # Must have a Wikipedia article
           schema:inLanguage ""en"" ; # Article must be in English
           schema:isPartOf <https://en.wikipedia.org/> . # Wikipedia article must be regular article
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". } # Helps get the label in your language, if not, then en language
}

I get expected output as follows:
 wd:Q11124  <https://en.wikipedia.org/wiki/Stephen_Breyer>
 wd:Q10727  <https://en.wikipedia.org/wiki/Steve_Leo_Beleck>
 wd:Q10065  <https://en.wikipedia.org/wiki/Taichang_Emperor>
 wd:Q9605   <https://en.wikipedia.org/wiki/Sarah_Allen_(software_developer)>

However, if I change the SELECT statement from
SELECT ?item ?article

to
SELECT (count(?item) as ?count)

I get timeout error. Please note that the count statement works if I only specify ""human"" condition and exclude English Wiki article condition. So, clearly, some kind of background join is causing the query to timeout.
However, this is a fairly trivial join, so the query timeout is surprising.
Please let me know what may I be missing here.
Thanks!
","['wikidata', 'sparql', 'wikipedia']",
Is there any publicly available dataset for interview setup except for the MIT Interview Dataset?,"
I want to work on behavior analysis of human beings during the interview process. Does anybody know any publicly available dataset that is available in person setting or with any virtual agent setup? I found only one such dataset but need much more. If anyone knows kindly reply?
",['data-request'],
Average Annual Cost of Attendance,"
Does anyone know which spefific values are used from IPEDS to calculate the college scorecard average annual cost of attendance (academic programs) ?
",['collegescorecard'],
Public RDF Ontology for Football (soccer) or Tennis?,"
Do you know of an RDF ontology for either football or tennis matches? I want to describe play-by-play events in the game and some statistics datasets.
I did an extenstive reaserch but only really found the generic BBC Ontology for sports as a whole.
","['rdf', 'ontology', 'football']",
Year Structure Built By Zip Code,"
I am looking for a breakdown of ""year houses/structures are built broken down"" by zip code (i.e. houses built after 1980s, 1990s, etc) in an excel format (for New Jersey). I have used data.census.gov for year structures built but they can be broken down only to counties, not zip codes--there are no zip codes filters available.
I believe this information should be available in a table format but cannot find it. I have accessed websites such as unitedstateszipcode.org which gives me the information of ""year houses built"" when I type in a zip code on the search bar. But I have to do this one by one manually, which is why i am hoping there is a table in excel format. Thank you in advance.
","['us-census', 'census', 'postal-code', 'real-estate']",
510(k) summary documents indicated on openFDA are not available from FDA 510(k) database,"
I have a question regarding the openFDA 510k data:
According to the File Layout for Releasable 510(k)s the statement_or_summary entry gives following information:

SUMMARY indicates that a summary of safety and effectiveness
information is available from FDA

However, for many devices with a summary entry in statement_or_summary, no summary document is available on the 510(k) Premarket Notification Database: e.g., for K990380
Where are these summary documents available?
",['openfda'],"Unfortunately, the FDA 510(k) Premarket Notification database misses many PDFs for items that have a statement or summary entry in the openFDA 510k data file.I think in many cases with a missing PDF there is most likely no electronic copy available. If someone really needs these files, they could probably be recovered via a Freedom of Information Act request (FOIA).Here the data for the /device/510k data downloaded on 2022-11-16"
High quality elevation data for Europe,"
I am looking for high quality elevation data for Europe. I am looking of around 2 meters or lower of resolution. So if anyone knows a good provider or programs (Can be payware or free) let me know
","['data-request', 'europe']",
Any way to access the API for Benefits.gov?,"
I'm reaching out because I'm working on a project and would like to know if there is a way to access the API for Benefits.gov.
Is this something the public would have open access to?
","['usa', 'api', 'labor']",
Seeking shapefile for project work in India,"
Can anyone provide the shapefile of KOZHIKODE City (not the district), and the same for BHUJ city as well?
I tried the district file, but I need the city's shapefile, not the entire district.
","['geospatial', 'city', 'india']",
Where can I find world covid death or vaccination datasets which include age group columns?,"
I have a dataset showing age groups of 60 > but couldn't understand the data values. I'm seeking a dataset with more age ranges or how to read the one below.
I have used this Dataset.
",['data-request'],
Where can I find people's visual acuity dataset?,"
I need a dataset with the following data:

Visual acuity
Age of the person

",['medical'],
TLS version statistics usage - Firefox,"
Does anyone know if the data for TLS version usage statistics (what percentage of connections is established using 1.1, 1.2, 1.3) are somewhere public?
For example I have noticed that Mozilla has this telemetry site https://telemetry.mozilla.org/ but most of the stuff seems to not be public. Does anyone know if it is possible to read the data from there somehow?
I know about annual reports that some companies make on this topic but I am more interested in a up-to-date (like every month fresh) statistic source.
",['data-request'],
Prediction of dress size by body measurment,"
Hope you all doing well. I am making an E-commerce project where there is need of recommendation system that would recommend dress size as S(small), M(medium), L(Large), XL(Extra large) ,2XL on the basis of body measurements like height, chest size, arm length, etc. I am trying to find a dataset that would be used to train ML model to recommend dress size but I am still not able to find one. Please anyone could suggest me a dataset or any other method for size recommendation system.
","['machine-learning', 'business', 'classification', 'large-datasets', 'deep-learning']",
Multiple Regression Dataset needed,"
I need a dataset to run a multiple regression (and find best equation) wherein
Y / Dependent Variable - is a quantitative variable There should be at least 6 X / dependent variables - which should be quantitative and one other X / dependent variable which should be categorical (2 categories OK).
Another condition is that at least some part of this dataset should be from the past year.
I have spent hours and hours on the web (Google / Kaggle) searching for one but unable to find one which meets this criteria.
Can anyone suggest me a dataset OR explain to me how to scrape any real-world data and make my own dataset which satisfies the above ? (I do not understand how to do the latter)
Thanks!
",['data-request'],
Geo data for Arctic 10ºC (50ºF) isotherm,"
I'm looking for GeoJSON or shapefile data showing the Arctic 10ºC isotherm (shown here https://arcticportal.org/maps/download/arctic-definitions/2419-arctic-10-c-isotherm). Does anyone have this or know where to look? I have been googling to no avail.
",['geospatial'],
Looking for a list of common street prefixes/suffixes for different languages,"
I'm currently working on a project to strip out prefixes and suffixes from street name, so for example:
""North Roosevelt Avenue"" becomes ""Roosevelt""
I need a list of common prefixes and suffixes as a staring point, ideally I'd like to be able to handle international street names too so any resources that have data from non-English languages would be preferred.
","['data-request', 'language', 'global', 'address']",
Is there any state-by-state data on approval for LBJ or the Vietnam War?,"
I cannot find any data on approval ratings for LBJ on a state by state level.
(Recommendations for sources of political/cultural data in general, especially of the sort that can't be readily found on google, would be appreciated.)
","['data-request', 'usa', 'politics', 'state']",
Football players' twitter accounts,"
Is there anywhere a ~comprehensive list of top football players and their twitter accounts?
","['football', 'twitter']",
Station-wise rainfall data,"
I want to map the spatial rainfall distribution and variation in India. Is there a platform I can download station-wise rainfall data for Co-kriging interpolation?
",['geospatial'],
Bureau Van Dijk - Orbis - or equivalent - sample data,"
I am interested in network analytics on economics graphs and financial graphs.
The research on this kind are usually done against samples of Bureau Van Dijk - Orbis dataset.
Access to it can only be funded by a strong university - it is costly.
I wonder if there is a sample of it for free access, where sample can be statistically representative of a defined geographical region.
I am looking at onwership of companies, and return of capital estimated by their balance sheets.
Where could I find a sample of Bureau Van Dijk - ORbis - or equivalent datasets?
--
Geographical areas of interest could be any at Country level, or metropolitan level.
Might there be dataset about Brazilian companies, I'd look at agricultural sector, so that I can cross potentially with other datasets.
It is important to me to characterise a geographical region with their corporates.
","['finance', 'economics', 'companies', 'opencorporates']",
Hydroponic dataset,"
I have the intention of performing a machine learning project on hydroponic culture. The real problem is that it seems that there is not a public dataset available for this purpose.
I'm particularly interested in predicting the results of culture ( such as size of the fruits, size of the plant, etc..) in relation to the temperature, macronutrients, etc.. .
Could you please suggest me any method to find a dataset?
","['data-request', 'machine-learning', 'releasing-data']",
Example data to experiment with splines,"
I want to experiment with smoothing splines, specifically on higher dimensional data (4 or more variables). How do I go about finding some nice data suitable for this? I also don't mind if it's synthetic data.
The examples I see online usually use very simple cases (of course this is better for learning the concept).
I want to do some comparisons between methods of spacing the knots, using a penalty term or not, visualising the model fits for higher dimensions, etc.
Thanks in advance.
",['data-request'],
Datasets whose attributes/dimensions are intuitively visualizable and easily selectable?,"
TL;DR: I am looking for datasets of which the attributes can be intuitively visualized (e.g. as a matrix, an image, a diagram, etc.) and are easy to individually select (e.g. by dragging/brushing over the matrix/image). What's more, it should be a dataset with which t-SNE has some difficulty, and of which some conceptual clusters are erroneously merged or separated in the embedding.
I am developing an adaptation of t-SNE that allows users to manipulate embeddings on-the-fly. Imagine one apparent cluster in a t-SNE embedding of which the user suspects or knows it to consist of two or more ""actual""/conceptual clusters. t-SNE likely hasn't been able to separate them due to the discriminatory attributes (i.e. the high dimensions on which those conceptual clusters differ the most) being a minority within the dataset's high dimensions. In such a case, the user should be able to select all datapoints in this erroneously merged cluster in the embedding, select the discriminatory attributes in a visualization summarizing the selected datapoints, and let t-SNE adapt the similarities in such a way that:

inter-similarities (between datapoints from different conceptual clusters) are reduced by a lot

intra-similatities (between datapoints from the same conceptual cluster) are reduced very little


Now, I am looking for datasets with which I can demonstrate this feature. Suitable datasets have attributes that can be intuitively visualized and are individually selectable. Grayscale image datasets are the most obvious example (I'm already aware of these MNIST-like datasets), but it can be any dataset with a natural visualization.
Any suggestions for datasets that exhibit this problem, or directions for where to look, or ideas to go about this, are very much appreciated!
","['data-request', 'visualization']",
Alternative OpenWeb crawling repositories? I currently use Common crawl and GDELT,"
Essentially, as stated above, I'm working on some analysis programs reliant on the latest headlines. Things like GDELT and Commoncrawl are useful, but I'd like to round out my options. Are there any others that function similarly to these, or are they the only options. Thanks.
","['data-request', 'web-crawling', 'sentiment-analysis']",
data.dol.gov key works for version 1 but not version 2 APIs,"
My keys work fine for the version 1 APIs but not for the version 2 APIs.
Can you please advise?
Account: etomer1
Version 1:
Param:   KEY = [my key]
Version 2:
Header:  X-API-KEY - [my key]
Status: 403 Forbidden
Error: Invalid API Key
GET   https://data.dol.gov/get/documents_view
This is a newer account. Did it migrate to the data.dol.gov  ?
","['data-request', 'labor']",
suggestion for PET/MRI dataset,"
Do you have any suggestion for PET/MRI dataset ?
thanks
ps: I had a look into this one https://www.kaggle.com/datasets/4quant/soft-tissue-sarcoma, but it seems it's missing the MRI part...
","['data-request', 'medical']",
"What is the MERGED dataset in College Scorecard? Also, NULL data in DEBT_MDN","
I'm stepping in for someone who has worked with this data previously, so be gentle.
I don't understand all the different files in the CollegeScorecard_Raw_data set downloaded. Specifically, the MERGED files.

Some questions. I looked in the data dictionary, and on the website, and I can't find a straight answer explaining what the MERGED files are.

What are the MERGED files. What are they merged with?
DEBT_MDN data. Why does the MERGED2020_21_PP.csv have NULL data for DEBT_MDN? The DEBT_MDN was available in MERGED2019_20_PP.csv file.
How is the MERGED data different from the Most-Recent-Cohorts-Institution file? Does this file maintain values if the most recent data is NULL? Meaning, if in 2019-20, there was $XXX in a field, and the most recent year shows NULL, which value is maintained in the Most-Recent-Cohorts-Institution file?

",['collegescorecard'],
"Connection between ""Recalls"" and ""Unique Device Identifier"" databases","
I would like to easily link a field on the ""Unique Device Identifier"" database to a field on the ""Recalls"" database, so I can easily see more information of a device/lead which has a recall.
Which field would it be?
Thank you
",['openfda'],
Download datasets from https://www.dol.gov/agencies/ebsa/about-ebsa/our-activities/public-disclosure/foia/form-5500-datasets,"
Using the Department Of Labor API, how do I automate downloading datasets https://www.dol.gov/agencies/ebsa/about-ebsa/our-activities/public-disclosure/foia/form-5500-datasets in a .NET C# application?
",['labor'],
Why some items on Wikidata have no corresponding Wikipedia entry?,"
I get stuck by this Wikidata item: 9., and wonder why there is no corresponding Wikipedia entry?
","['wikidata', 'wikipedia']",
Open data sets for whale strandings in eastern U.S?,"
Would love anything related to whale strandings, even if not in eastern US, just must be a singular area (west, midwest, etc.).
","['geospatial', 'environment', 'animals']",
Is there an open dataset about what freelance services are requested?,"
The objective is to suggest freelance skills which may be lucrative either because the market is undersupplied or because the market is so large. In both cases, demand is higher than supply.
I would like to know which freelance services are searched for, not which are purchased.
The difficulty is considering what the source of that data would be. It seems like it would have to be composite from multiple sources. If you tried to scrape one freelancing site, your perspective would be limited to what is currently sought on that site, not what could be sought if some sector became more prominent on that site.
Therefore, it would ideally try to define where “requests” occur - including Google searches, a variety of social media posts, and multiple freelancing sites.
I guess the scope can be made even broader, by somehow trying to analyze services that aren’t even being expressed on the internet but could become new internet markets.
Realistically, is there any open data set something like this?
",['economy'],
Is there a way to retrieve navigation data from Google Maps e.g. to R?,"
How would an HTTP request or API request retrieve navigation data from Google Maps? Are there some simple lines of code for that? Let's say I want to give an input of origin and destination address, then the results of car, public transport, walking etc. are given with distance, required time and so on. Basically, setting the navigation UI Google Maps settings which results in a somewhat tabular form or any other format that can be used for analyzing.
Thank you in advance!
","['geospatial', 'api', 'programming', 'scraping']","Yes, from R you can call Google Maps' Directions API.API calls look like this:You can specify to receive results in either JSON or XML.You will need an API key."
Database for drugs admitted in germany with an API,"
there is an official api from the FDA that, among other things, allows me to search drugs.
https://open.fda.gov/apis/drug/drugsfda/
Is there any database that offers an open api for Medication admitted in germany (containing the german PZN)?
So far I have only found something like drugbase which requires a fee that I can't afford that for a small private project.
Then the official AMIce from bfarm (Bundesinstitut für Arzneimittel und Medizinprodukte) does not appear to offer a propper api - at least the free part (but frankly, and sorry for the off-topic comment here - tech-wise it looks about as advanced as the medical php websites I built for university back in 2005 before i started studying computer science...)
","['api', 'medical', 'germany']",
Drugs@FDA Endpoint - Why is the openFDA field missing from some applications,"
I'm building a search form using the openFDA API starting with the Drugs@FDA endpoint. In my attempts to find a consistent method and identifiable field to search for drugs I have noticed some inconsistencies not talked about in the project documentation.
Question: What is the openFDA field and why is it not included in every application.
","['api', 'openfda']",
Total number of website visits in a month in the world?,"
[Asked here on advice from Cross Validated SE.]
According to Semrush, in September 2022 the top websites by number of visits were:

google.com (88bn)
youtube.com (69bn)
facebook.com (12bn)
twitter.com (7bn)
wikipedia.org (6bn)
reddit.com (5bn)
instagram.com (4bn)
amazon.com (4bn)

I would like to convert these to percentages of all website visits in the world during the same period. What is a good estimate of the total number of website visits?
","['global', 'internet']",
Where can I find a dataset of company office addresses?,"
For an application I'm building, I need to find a list of all office addresses for large companies (e.g. the addresses for each of Google's 170+ offices, not just their headquarters).
The closest solution I've found is https://craft.co/, although that seems to be an API for large enterprises.
(happy to write code to scrape the data, or pay for the data, etc.)
","['business', 'companies', 'address', 'location']",
getting the latest data about covid-19 pandemic per country with a Wikidata SPARQL query,"
I'm trying to extract some of the latest data about covid-19 pandemic statistics (number of cases, recoveries, point in time) per country from Wikidata using this SPARQL query:
SELECT DISTINCT ?COVID19_loc ?COVID19_locLabel ?countryLabel ?cases ?timeC ?recoveries ?timeR {  
    ?pandemic wdt:P1269 wd:Q81068910;
    FILTER ( ?pandemic in ( wd:Q83741704)).
    ?pandemic wdt:P527 ?COVID19_loc.
    ?COVID19_loc wdt:P17 ?country.
    ?COVID19_loc wdt:P1603 ?cases.
    FILTER NOT EXISTS {?COVID19_loc wdt:P1603/wdt:P585 ?timeC_Other FILTER ( ?timeC_Other > ?timeC)}.
    ?COVID19_loc wdt:P8010 ?recoveries.
    FILTER NOT EXISTS {?COVID19_loc wdt:P8010/wdt:P585 ?timeR_Other FILTER ( ?timeR_Other > ?timeR)}.
SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". } }

The thing is I'm getting multiples cases and recoveries results instead of the latest of them only, also timeC and timeR don't return a thing!
","['wikidata', 'sparql']",
Why are some entries so long and strange on Wikidata?,"
I wonder why Wikidata includes/filters in this kind of entries:

Foundations of Astrophysics Barbara Ryden Bradley M. Peterson. 596 pp. Addison-Wesley, San Francisco, 2009. Price: $137.33 (hardcover). ISBN 978-0-321-59558-4 (Q105030571)


German Reich and Protectorate of Bohemia and Moravia September 1939–September 1941 (Q104958086)

Do they imply mistakes somewhere?
","['wikidata', 'wikipedia']",
Data source for probable location of rough primary residences over the globe?,"
I'm looking for a data source that would allow me to generate a lat/long that is ""probable location of a human's home"". I'd hope that if I ran it ~8 billion times, it'd give me something 'similar' to the distributions of humans on the planet at any given time.
I'm comfortable with the data being very rough â€” it'd be ideal if I could get single digit number of different lat/long 'bins' for a major metropolis for example (eg. the east side of NYC has an X% chance of hosting a human, the west side Y%), but not a requirement â€” whole city level 'bins' would be fine too.
I live in the UK, so I'm reasonably familiar with the ONS, which I'm sure has data I can use for my country, but is there anything global I could lean on?
","['data-request', 'geospatial']","As determined in the comments, what you are looking for is a ""population density map"", a search term which gives plenty of results. You could start from here: luminocity3d.org/WorldPopDen/ and the data sources of that map."
Query Syntax by Drug Class,"
I am interested in creating a dataset that only contains that class of drugs. I would prefer being able to search by the drug name, but entries for that field are masked. Does anyone know if I can search by and create a dataset by drug class?
","['api', 'openfda']",
"Is there any recovered data for covid-19 after August 4th, 2021?","
I'm searching for the recovered data after that day for any country for my SIR model fitting with python. But I cannot find any recovered data except for CSSE data, there is a data for recovered population but not after August 4th 2021.
Or is it the case that They do not collect the data because it's kind of not essential information? because by period about 10-12 days, we can just predict the recovered population? I mean I'm wonder the reason cannot find an single data for recovered is whether there is no data or my poor searching
","['uses-of-open-data', 'covid19']","The problem with the recovered measurement is that the definition/concept is almost entirely separate from how it is calculated. It is very difficult for researchers/contact tracers to get follow-up information from confirmed infected after the initial exposure. As a result, many agencies will simply calculate the measurement for the actively infected population and recovered population as being within 45 days of a positive PCR and 45 days or more since a positive PCR respectively. Given the many issues with the recovered measurement, I am not surprised to see many reporting agencies deprecating that indicator."
Alternate WMTS layers for world imagery,"
The WMTS url for ESRI imagery is http://services.arcgisonline.com/arcgis/rest/services/World_Imagery/MapServer/WMTS/1.0.0/WMTSCapabilities.xml
Does anyone know of any other WMTS urls for world imagery?
",['geospatial'],
The Chinese English parallel corpus from Wikidata?,"
I have these two corpora: 1) wikidata alias; 2) wikidata labels.
What confused me is that 数学常数 and Mathematical constant's QIDs are respectively Q866140 and Q186509, even though they are linked to each other by switching languages. The traditional Chinese version 數學常數's QID is the same as Mathematical constant's, and the former is also linked with the latter by the language setting. I filtered in only alias and labels with language codes ""en"" and ""zh"".
Are there something wrong? Or how to download interlanguage links data? This interlanguage links dataset is too small.
","['wikidata', 'dbpedia', 'china']","It's important to note that you are linking to dbpedia's version of Wikidata, as noted in the other question, and they might have done things a little differently when processing it. I can't really answer from the dbpedia side of things, so this is a Wikidata-oriented answer...The Wikipedia pages you mention link to the same item, https://wikidata.org/wiki/Q186509 - the other item links to a related set of WP pages, in English ""Mathematical constants by continued fraction representation"". However, this item has had its Chinese label truncated (it lost the brackets in 数学常数 (以连分数表示排列)) and so it shows up on Wikidata with the same Chinese label as the first.If you are simply matching on labels or aliases, then the key thing to know is that Wikidata's labels and aliases are not unique. There might be a hundred items with an identical ""John Smith"" label in English and fifty more with that alias. In general, Wikidata does not keep the disambiguation notes in brackets from Wikipedia page titles, which is probably why the Chinese one here lost the bracketed section, but there can be many other differences.You can get a copy of the full set of the interlanguage links from the Wikidata dumps at https://dumps.wikimedia.org/ - you will want the wikidatawiki dump and the wb-items-per-site file (""For each Wikidata item, this contains rows with the corresponding page name on a given wiki project.""). Documentation for the file is at mediawiki.org and more general documentation on the dumps is available on Wikidata."
Looking for geocoded survey data of households and individuals,"
I am looking for open datasets with survey data of households and individuals which includes the location of the survey respondents in coordinates. The datasets should be worldwide or covering at least areas exceeding single counties or small (sub-)continents.
For example, the Demographic & Health Surveys (DHS) collect survey data in 90 countries that provide information on a wide range of monitoring and impact evaluation indicators in the areas of population, health, and nutrition. Most of the surveys also include the location of households in small clusters of around 20 to 30 households. Now I am looking for alternatives of the DHS data.
","['data-request', 'geospatial', 'survey']",
One to Many Model Number to Part Number Crosswalk,"
Looking for a cross-reference table containing model numbers and their constituent part numbers, for 2 domains. The first domain is major appliances, refrigerators, washer/dryers, dishwashers. The second domain is HVAC equipment, such as AC condensing units, evaporator coils, etc.
For the appliance domain, the dataset will likely be in a one to main relationship. One model number (a Kitchenaid French-Door Refrigerator in Stainless, model 12345) to main part numbers (the parts available for model 12345, i.e., ice maker part number 54321, compressor part no 6544321)
The HVAC dataset will probably be the AHRI data set, I'm hoping someone knows an open source for it. Either of the two domains would be incredibly useful to the project we're working on.
Thank you!
","['data-request', 'products']",
What is the difference between sameAs and alias in Wikidata?,"
From the descriptions of sameAs and alias I don't know how the two relate to each other, and it also provides the redirects. And aliases also appear in properties.
","['wikidata', 'wikipedia', 'dbpedia']",
How can I get the category of a term by its QID?,"
I obtained entities(and their QIDs) and the category data from Wikidata, but cannot connect the two.
Here is what an entity entry is like:

<http://wikidata.dbpedia.org/resource/Q100000001> <http://dbpedia.org/ontology/alias> ""Franklin School""@tl .

and here is a category data entry:

<http://dbpedia.org/resource/!Oka_Tokat> <http://purl.org/dc/terms/subject> <http://dbpedia.org/resource/Category:Television_shows_set_in_the_Philippines> .

We can see that the two dataset cannot be linked by a foreign key.
I know that I cant extract the page of an entity by its QID, but I wonder if there is a table containing the QID-category mapping?
","['wikidata', 'dbpedia']",
Workflow for data version control using git in a team,"
What would be the basic workflow to use version control via git and GitHub for the initialization and updating of a data set in a team? What are pitfalls?
More specifically, if I want to create a dataset and work and update this dataset with collaborators, what would be the best way to achieve version control? Updates would include adding observations but potentially also new variables to the dataset.
My basic idea would be:

Set up initial dataset as a .csv file.
Create a GitHub repo for this file
Use git to update it

What would be pitfalls in this workflow?
",['git'],
Data / charts on US federal debt composition by maturity and across the yield curve?,"
Is there good place to see data or charts on the composition of US federal debt by maturity length (or security type) and across the yield curve? As well as the added context of what entities or categories of entities own what percentages of those segments of debt (eg. as can kinda be seen here (https://datalab.usaspending.gov/americas-finance-guide/debt/analysis/index.html))?
","['data-request', 'usa']",
Long-term care insurances that satisfy the requirements to opt out from the long-term care payroll tax in Washington state,"
I'm looking for a data set that contains all long-term care insurances that satisfy the requirements to opt out from the  long-term care payroll tax in Washington state. I'd prefer if the dataset state when was/is the last day when they stopped accepting applications.
I found https://www.insurance.wa.gov/long-term-care-insurance-companies-approved-sell-washington-state but they don't say which ones satisfy the criteria to opt out.
","['data-request', 'usa', 'medical', 'finance', 'taxes']",
Dataset on the real speed of cars in German autobahns,"
I am looking for a dataset on the real speed of cars in German autobahns.
This question was inspired by https://travel.stackexchange.com/q/139723/1810.
","['data-request', 'germany']",
Programmatically retrieving VFR/IFR Charts from FAA,"
I am trying do the following:
Subscribe and be alerted when a new version of the VFR and IFR charts are available from the following websites:
https://www.faa.gov/air_traffic/flight_info/aeronav/digital_products/vfr/
https://www.faa.gov/air_traffic/flight_info/aeronav/digital_products/ifr/
If a new version is available, download all zip flies  from the """"Next Edition"""" columns which are the following:
Sectional Set
Terminal Area Set
Helicopter Set
Grand Canyon Set
Caribbean Set
Planning Set""
If a new version is available, go to the FAA website for IFR Charts, and select the ""56-Day Sets""
Download the zip file in the ""Next Edition"" column ""DDECUS XXX"".
Is there an API that will allow me to do that?
","['data-request', 'geospatial', 'api', 'scraping']",
Looking for data on silicon or semiconductor computer chips or wafers,"
I am looking for data sets on silicon computer chips, specifically in regards to the shortage.
The format of the data (e.g., CSV, Excel, JSON) is not important.
The only data sets I have been able to find were through Google Research Dataset Search, and none of them were licensed for open use (not free to access).
This is for performing statistical analysis (the details on the type of analysis is not too relevant at this time) in a course at my university, so I would greatly appreciate any assistance is finding this data.
To contact me, please reply to this post.
Thank you.
","['data-request', 'economics', 'global', 'computing', 'trade']",
Extreme hyperparameter tuning for XGBoost,"
One important skill is to know how to build models that would produce good results, and not take a whole day to run at the same time. That said, I have time, and I want to try lots of hyperparameter values for my xgboost model. I want to show you my code, and knowing I don't mind it to take some time, can you please help me with the tuning process? what do you think about my code? I filled lots of values for each hyperparameter hoping to get good results. My model so far is not performing well, it is overfitting, as it produces AUC = 0.85 in the train set and AUC = 0.60 in the test set.
I know it could be a problem with the data itself, but I have several solutions that I want to try and one of them is an extreme tuning of the model.
param_Grid = {
            'objective':['binary:logistic','binary:hinge'], 
            'n_estimators': [30,50,100,120,150,200,250,300,400,500,1000],
            'subsample': [0.3,0.4,0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
            'max_depth': [2,3,4,6,7,8,9,10],
            'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],
            'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
            'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
            'gamma': [0, 0.25, 0.5, 1.0],
            'learning_rate': [0.001, 0.01, 0.1, 0.2, 0,3],
            'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],
            'colsample_bytree': [0.5,0.6,0.8,1]
        }  

optimal_params = GridSearchCV(estimator=xgb.XGBClassifier(seed = 42),
                             param_grid=param_Grid,
                              scoring = 'roc_auc',
                              verbose = 2,
                              cv = 10)

optimal_params.fit(X_train, 
                  Y_train,
                  early_stopping_rounds = 10,
                  eval_metric = 'auc',
                  eval_set = [(X_test, Y_test)],
                   verbose = 1)

As you see I want to use the ROC metric to evaluate the model. I also use cross validation of k = 10. The data at hand has 1550 observations, with about 26 predictive features (after feature selection) and one binary target feature.
","['machine-learning', 'python']",
R: sampling using dbinom(y-0:200),"
In R:
I have a sample (y) of length 1e4.
y = sample(0:200, 1e4, replace = TRUE)
I have plugged this sample into:
dbinom(y-x,100,0.3)
However, I would like to gather samples from this function but simulate for x values from 0:200
i.e
x = 0:200
For e.g. the first iteration will be 1e4 samples of dbinom(y-0,100,0.3) which will produce 1e4 samples then the next iteration will be dbinom(y-1,100,0.3) etc up until x = 200.
This is for going to be used in getting the M = max(f(y)/h(y)) for accept-reject envelope method however since my f(y) is discrete I would like to sample for each integer value of x = 0:200 and then get the max from there.
However, I am unsure as to how to approach this as I am new to R.
Any help is much appreciated!
",['programming'],
Where to get a speech dataset of people with voice disorders?,"
I'm trying to implement a model for speech recognition of people with voice disorders, but I can't find a suitable dataset for this. An example of the speech that will be received at the entrance(reference project):
https://www.youtube.com/watch?v=EU2oCVlzEZk&feature=emb_logo If you share links to datasets suitable for me, I will be very grateful to you
","['machine-learning', 'audio', 'large-datasets', 'deep-learning']",
Annotated Corpus for Named Entity Recognition in Finance,"
I'm looking for a textual dataset (e.g. documents) for a named entity recognition task in finance. The required entities are:
1- Credit Card Number
2- CVV Number
3- Account Balance
4- Salary
5- Tax payer number
6- Value of a property
I've been looking for a while, but all I got is a financial corpus with conll entities(PER, LOC, ORG, MISC) like ""SEC-FILINGS- and another one with a lot of financial entities out of interest and it's ""finer-139"".
So kindly if anyone knows how to get such data if it exists, I'll be grateful.
","['machine-learning', 'nlp', 'finance', 'corpora', 'text']",
On mandatory vaccines,"
I am looking for a list of mandatory vaccines for as many countries as possible.  The data set I am interested in could look like something along the following lines.
          | Chickenpox | Flu        | Shingles   |
----------|------------|------------|------------|
Borduria  | True       | False      | True       |
Ruritania | True       | True       | True       |
Syldavia  | True       | True       | True       |
----------|------------|------------|------------|

My motivation is to find vaccines that are mandatory in, say, Borduria, but not in neighbouring Syldavia.
","['data-request', 'medical']",
"Simple way to get dem, grayscale elevation maps for EU (10m resolution)","
I need 10 or 12.5 m spatial resolution dem maps of mountainous areas, precisely grey scale(map with height data) version for use in 3d software.
I found geoTiff maps from Copernicus, but they are 25m spatial and I need more precision.
Other option is https://scihub.copernicus.eu/dhus/#/home, data from Sentinel satellites, but it is a pain, because I need to use Snap software and then another one and still I cant get it to work properly. So hard to get simple gray scale elevation map out of Sentinel 1 satellite data. Lost a lot of time trying to do it.
I seek some resource to get that resolution Geo Tiff preferably or a fast, uncomplicated way to get 10m spatial resolution maps.
Update 1: I do not need one map for whole Europe. Smaller area maps like one for one part of the Alps, another for another part,.. are all right, but they need to be 10m or 12.5m spartial res.
Thank you!
","['data-request', 'geospatial']",
Full National Dataset of all County Appraisers' Property Records,"
Does anyone know of a free (or relatively cheap) source that has combined all county appraiser property tax records into one dataset? I am specifically looking for fields related to property location, owner, and appraised value for every multifamily property across the entire US. I have come across CoStar, Regrid, ATTOM, Reonomy, and CoreLogic, but these all seem to provide a lot more bells and whistles than I really need, and are outside of my budget (I am using this for academic publication purposes).
","['data-request', 'economics', 'real-estate', 'county', 'taxes']",
Finding dataset for some specific years,"
Is there any websites where I can find the health risk prediction open source tabular dataset in the year between 2015 - 2017?  Also, I need to find out some research papers that used those datasets. I know about the Google Dataset website but it seems not very resourceful.
","['data-request', 'medical']",
"Data on global building stock (foundation type, structure type, etc) by country or region?","
As part of a larger analysis comparing natural hazard risk between countries I'm hoping to identify a dataset (or multiple datasets) that could help characterize trends in building stock by country. I'm particularly interested in the distribution of foundation types and structure types by country. So far my web research hasn't return anything but I suspect I'm not using the right keywords.
I'm imagining a dataset where the rows are countries (or larger regions/continents) and then there are columns like ""% of structures with slab foundations"" ""% of structures built from wood"" etc.
Note - I previously posted this question to engineering.stackexchange.com but was told it was off-topic so I am now reposting it here.
","['data-request', 'global', 'real-estate', 'buildings']",
Where can I find boundaries of all German voting districts in federal elections (since 1949)?,"
I am looking for shapefiles containing the boundaries of all voting districts in German federal elections, 1949-2021. I appreciate any pointers.
","['data-request', 'germany', 'district']",
Where can I find boundaries of all German voting districts in federal elections (since 1949)?,"
Where can I find shapefiles containing the boundaries of all voting districts in German federal elections, 1949-2021?
","['data-request', 'geospatial', 'germany']",
road names in texas?,"
The TxDOT Roadways dataset includes stuff like RM2222 but it doesn't include the names of the road. Portions of RM2222 are known as Northland Drive, Allandale Road and Koenig Lane.
My question is...  where can I find the road names vs just the TxDOT road designations?
(idk if these roads were named by the city, county or state)
","['data-request', 'geospatial', 'usa', 'transportation', 'state']",
Seeking free stereo paired .tiff image files,"
I'm somewhat new to GIS and am exploring creating DEM's from stereo paired images using s2p. I've searched high and low for a source for stereo paired tiff files but I haven't had any luck.
Can someone point me in the right direction?
",['data-request'],
Look up property owner using ROLL number (Ontario),"
I have the tax ROLL number (aka ARN - Active Rolle Number) of a specific property/parcel in Ontario, Canada. I want to determine who the owner of the parcel is. (For what it's worth, I also have the municpal address and spatial location too.)
How can I look up the property owner using the ROLL number?
Are there any free or paid resources where I can do that online?

Edit:
An example of something similar - look up a PIN instead of a ROLL number:
I can use the steps on this page: https://www.ihunterapp.com/using-ihunter-and-onland-to-find-property-information/.

Subscribe to iHunter for ~$40 CAD per year. The iHunter map has polygons that have parcel PIN numbers.

From there, enter the PIN number into OnLand to download a PDF that has the property owner info (costs ~$30 CAD).

As an alternative to using OnLand, I think the same thing can be done using Teranet Express . It seems to cost ~$30 CAD too, the same as OnLand, so I'm not sure if there is a benefit to one or the other.



Using those steps, I can look up the property owner using parcel's PIN number. Which works, but isn't what I'm looking for. I want to look up the ROLL number instead -- since that's the information I have on hand.
","['data-request', 'real-estate', 'canada']",
List of Ontario road names,"
Where can I find a list of all roads in Ontario?
I'm looking for a publicly available list, such as a website or downloadable PDF/spreadsheet. The intended audience aren't GIS professionals, so a GIS layer wouldn't be suitable.
Example use case:
Find all the roads in Ontario that have the word marble in their names.
","['data-request', 'canada']",
Sentiment analysis applied to reviews of pharmaceutical drugs,"
I'm looking for a dataset for sentiment analysis applied to reviews of pharmaceutical drugs. I.e. a set of sentences from reviews of pharmaceutical drugs labels with a score indicating their sentiment.
","['data-request', 'medical', 'machine-learning', 'nlp']",
Very coarse spatial resolution (>1000m) global digital elevation raster data,"
I am searching for very coarse spatial resolution (>1000m pixel size) digital elevation model (DEM) global raster data. I am aware of data sources like SRTM or Copernicus DEM (90m pixel size) but unfortunately it will be very difficult to download a global DEM with such resolution. Do you know any sources from where I can, freely, download very coarse spatial resolution DEM data?
","['data-request', 'download']","The easiest way would be using R and download prepared set like:The parameter res corresponds to desired resolution: 10, 5, 2.5, and 0.5 minutes of a degree. The data itself comes from UC Davis https://geodata.ucdavis.edu/climate/worldclim/2_1/base/wc2.1_10m_elev.zipCreated on 2022-09-30 with reprex v2.0.2"
"India: State-wise, Over the years, Urban Population Percentage","
I'm looking for a dataset that shows, for each Indian state (or at least the more populated ones),
the proportion of population living in urban areas over the years.
The more years the better, but even the last 10-20 years will do.
Anything less will be quite biased.
I have found World Bank data but this is for the whole country and not just India.
This is a comprehensive report on Urbanisation in India but doesn't have the data as I need it.
","['data-request', 'india']",
Worldwide Income data at city level,"
I was wondering if there are sites where I can find worldwide income data at city level (in conformity with levels that are used in the GADM dataset https://gadm.org/). Even a site to scrape would be fine. I've searched through answers on here but I've found only expired link or data at country level
","['data-request', 'income']",
Looking for a data list/file/website of the USA Lucky Lottery Retail Locations and historical lucky retailers?,"
I am looking for a website, data file, list, or something similar of the ""lucky"" lottery retail locations. Specifically for the Powerball and MegaMillions lottery tickets.
Hopefully listing the store, location, date of win, and amount of win.
Lottery Retailers qualified as “lucky” by meeting one or more of the criteria below:

Sold at least one $100,000 or higher winning ticket
Paid out an average of 400 winning tickets per week
Paid out an average of $4,000 in winning tickets per week

Any help would be greatly appreciated! All I can seem to find is individual local listings and not a complete list.
","['data-request', 'database', 'games']",
Animal population dataset,"
Does anyone know where I can find animal population censuses or datasets with different types of animals? It's for a paper on a type of sampling called capture-recapture sampling.
","['data-request', 'animals']",
Seeking latitude and longitude data for roads/highways,"
I wish to make an analysis where I intend to differentiate if my vehicle is on road or it is in other places like forests/farms/other land.
For this I need either a database of coordinates of roads or a way I can differentiate the location based on whether coordinates are on road or not on road.
","['data-request', 'location', 'longitudinal']",
Dataset on faces and relationships,"
For a computer vision project, I wish to analyse the relationship between the faces of people and the people they date.
famousbirthdays.com contains images for thousands of celebrities and provides unstructured data on their relationships.
Before I attempt to use machine learning to mine each description for information, is there a dataset which already contains this?
","['data-request', 'faces']",
Where can I find a map of US county boundaries that reasonably shows the boundaries over bodies of water?,"
Census, ESRI, and others provide shapefiles and feature classes of county boundaries, but all the data sets I can find seem to clip the boundaries at the shoreline. So they really only show the boundaries over land, but not over water, that is, bodies of water along a boundary are shown to not be in any county.
I need a similar data source that shows the boundaries between counties over both land and water. Great accuracy is not needed, I just need data that resemble the typical printed map where there is one relatively smooth boundary between adjacent counties (for example) following the course of a river, instead of two boundaries along the two shorelines.
I would have assumed that Census and others start with maps with the boundaries in the water, but my search skills have not been good enough to find such sources.
Any idea where I might find such a data set?
","['data-request', 'usa', 'county']",
"Data Source For Images (Soil Sealing, Water Bodies, Surface Flooding, Parks etc.), at Scale of 1:30000","
I want image data sources for following conditions:
Mapping soil sealing and water bodies at scale of 1:30000
Mapping surface flooding when there is persistent high cloud cover
Mapping parks in urban areas and the sub-classes: lawn, trees, tree groups, water bodies, road (sealed) and road (unsealed) at a scale of 1:3000.
What are the individual best RS data sources for above conditions?
","['data-request', 'images', 'open-source', 'remote-sensing']",
GeoTIFF over WMTS data source,"
Could you please recommend some GIS projects with an open source (or free trial) access to the GeoTIFF data over WMTS protocol (image/tiff format in Capabilities.xml)?
","['data-request', 'geospatial', 'api']","There are Web Services/Cloud Providers that can stream GeoTIFF tiles over WMTS.For example, Sentinel-Hub https://www.sentinel-hub.com/It accepts GetTile request URL parameters:FORMAT The returned image format.Optional, default: ""image/png"", other options: ""image/jpeg"", ""image/tiff""Details: https://www.sentinel-hub.com/develop/api/ogc/standard-parameters/wmts/Some notes on WMTS:See https://www.ogc.org/standards/wmts"
Office of Labor-Management Standards - API Access,"
Does anyone know if there is API access the Online Public Disclosure Room for Union Reports?   I can access it here: https://olmsapps.dol.gov/olpdr/ but I would love to be able to to it through an API.
","['usa', 'labor']",
Universal botanical data set of plant species according to the latest AGP classification,"
I want to monitor some species of trees planted in my neighborhood on OSM. It's roughly ~200 species from my first glances. Some people I'm working with have also done their own classification (hand made) for that, using plant names both in the local language and latin. But I think it's not a good practice to do such data set on our own side, because if other people communities do the same nearby, they won't exactly agree on how to write species names for example and will won't be able to combine the two data sets; there will be missing matches.
Therefore, I'm looking for a data set of plant species according to the (or one of the~) latest AGP classification. Something ""official"" which everybody can firmly and scientifically rely on. It especially has to have a unique identifier which is commonly accepted and recognized as such in the field of botanic around the world.
An Open API would be the Holy Grail, but I feel that I will have to download a large text file (which is ~OK, I guess) instead and do some lookup in it instead using a scripting tool.
Any ideas?
","['data-request', 'api']",
dataset with max 500 Token text with different content,"
for training a model on question answering im looking for a dataset that contains text from different sources, like a paragraph
should contain
from different sources like Wikipedia, random web article
each text should ideally have different topic biology, history
300 - 500 tokens
english
","['data-request', 'nlp']",
Where can I get total electricity consumption of a year of Indian cities?,"
I need electricity consumption data of cities in India for a year. On CEA (central electricity authority, India) site I have got this data: electricity forecast report
They are using electricity consumption data from 2003 to 2018 of cities to forecast future electricity consumption. but they have not included base data. I need actual electricity consumption for at least 200 cities for one year. I would be thankful if you could provide a source related to this.
","['data-request', 'energy']",
High quality parallel word or sentence pair corpus in different languages,"
I am looking for a parallel corpus with many sentence pairs that can be used for machine translation purposes.
The most comprehensive website is https://opus.nlpl.eu/, however it does not rank the corpora by quality. The problem I face is that many corpora are pretty bad. I looked into a few and made following observations:

CCMAtrix/Wikimetrix is pretty flawed, number of nonsensical sentences (in CCMatrix)/non-literal translations is too high.

Europarl/EUbookshop also has too many formatting errors/garbled characters

Opensubtitles also has a high number of errors/misalignments

TED Talk has also a lot of misalignments


My conclusion: Finding a dataset that doesn't suck is super difficult. And those examples I listed are used a lot!
My question is: What are the good datasets? And is there research that calculates a dataset's quality?
My candidates for good datasets seem to be (after reading some examples).:

GNOME

Tatoeba

Generally open translation projects of open source games, I looked at Battle of Wesnoth and the quality seemed to be much much better than in the datasets I listed above. Maybe there is also a way to mass download data from Transifex, which hosts lots of translation projects, but I couldn't identify any.


","['data-request', 'corpora', 'translation']",
403 Issue when accessing College Scorecard API,"
I signed up for an API_KEY and received an email with the key. When attempting to access the api. I receive a 403 error. this is what I see on the screen:
API_KEY_INVALID
An invalid api_key was supplied. Get one at https://api.data.gov:443
This is my request:
https://api.data.gov/ed/collegescorecard/v1/schools?api_key=[API_KEY]

",['collegescorecard'],
Data detecting lies in voices,"
I am looking for data that contains voice recordings of people lying or doing illegal or unethical things. Does anyone know of this kind of data anywhere?
",['data-request'],
Where can I obtain data on Indian GDP by city?,"
I'm looking for data on GDP by city in India, say for example for the top 60-70 cities. I have looked in the World Bank, UN, IMF, but couldn't find it.
","['data-request', 'city', 'india', 'gdp']",
Where can I find a large unprocessed dataset?,"
I am looking for a large dataset (greater than 100MB), preferably CSV, which is raw and unprocessed, with missing values. It is for a data preprocessing assignment as part of my college course on Big Data Analytics. I have to demonstrate data preprocessing in R or Python which I will work on. However, I am having a hard time finding a good dataset. On Kaggle, the datasets I looked at did not have missing values.
The dataset I have been considering is one from the New Zealand 2018 Census from https://www.stats.govt.nz/large-datasets/csv-files-for-download/. The one I have selected is the Age and sex by ethnic group (grouped total responses), for census usually resident population counts, 2006, 2013, and 2018 Censuses (RC, TA, SA2, DHB). It seems to be a good dataset for this purpose. It has around 34 million rows:

However, the problem here is 18M out of those 34M records have a non-numeric value called ""..C"" for the count column which I'm not exactly sure what it means. I thought about considering them as ""missing values"" but that is more than 50% of the entire dataset:

Any help regarding finding a good dataset or further information on the above dataset would help!
Update: The above dataset seems to have a lot of outliers. So I would prefer a recommendation for a new dataset instead.
","['data-request', 'metadata', 'large-datasets']",
Seeking up-to-date shapefile of Sierra Leone,"
I'm looking for a current map of Sierra Leone provinces (admin 1 level). One province split in 2017, making a total of 5, but I can only find files with 4 provinces.
I've checked humdata, DIVA-GIS, and GADM, and they're all out-of-date . As far as I can tell, there isn't a way to have only admin borders on the OpenStreetMap/Geofabrik data set.
Alternately, is there any workaround? I don't need much, just the polygons for the provinces. This is for use in a scientific manuscript. Ultimately, I want to import it into R and add data to it. Thanks!
","['data-request', 'geospatial', 'africa']",
Dataset for human body that may include the following attributes,"
I'm looking for a data set in which the following attributes are present: Heart rate, Body temperature, External temperature, Blood oxygen saturation, Acceleration of accelerometer, Angular velocity of gyro sensors, GPS positions
","['data-request', 'medical', 'accelerometer']",
Find date and time of past events,"
I am looking for an efficient way to find exact date and time for events in the recent past which have been in the news. Finding the date is not difficult, but I am also interested in the exact time the event has first been reported in the media and as such been made available to the public.
As an example, the WHO has announced on 11 March 2020 that the Covid-19 outbreak is now considered a pandemic, that's easy to find in press statements or on news sites, but I spent hours trying to find the time when the media briefing started and/or when it was first reported in the news. I have a whole list of such events, and I am hoping to speed up the research.
Is anyone aware of websites or tools that can provide such information on date and time? Or a good strategy? I tried google search, google news, websites of big media, wikipedia articles, original press statements, ...
","['data-request', 'media', 'search-engine', 'news']",
Seeking Publicly Available Map-Matched Datasets of Raw Trajectory Data/Traces,"
This is a repost from https://gis.stackexchange.com/questions/440336/seeking-publicly-available-map-matched-datasets-of-raw-trajectory-data-traces where I got asked to repost this question here as it is more relevant.
I have been doing some work related to map-matching of raw trajectory datasets (traces), and I'm not sure if there is any map-matched datasets that are publicly available. Most datasets I see publicly accessible are the raw traces, but they do not have include the map-matched data of those trajectories onto the road network.
What I am interested in is those datasets that have already been map-matched (either by some map-matching algorithm OR perhaps the actual ground truth road segments for which the vehicle has taken in its trip/route).
Is there a whole library/repository/database where I can find these data?
","['data-request', 'geospatial', 'open-source']",
"Different results from API based on range input, but database includes the data","
When I am searching this API range 500-999, I get good results.
If I search 999 - 1010, I get good results.
If I search 1000-1100, I get 502 Bad Gateway nginx.
Similar results with average SAT scores... some ranges work fine, while others do not.
How to fix or work around the problem?
","['api', 'collegescorecard', 'json']",
How to find a dataset with column requirements?,"
For a data mining course I need a dataset with at least 7 numerical values, 7 categorical values (of which 2 are binary) and at least 2000 rows. The domain does otherwise not matter, but it should be somewhat interesting to work with. Is there an easy way to find such a dataset or do you have one?
I scanned many datasets on kaggle and datasetsearch by Google and I could not find anything that meets the requirements.
","['data-request', 'uses-of-open-data', 'metadata']",
Historical Weather Forecasts,"
Does anybody know if there is a place I can find historical data of weather forecasts by forecaster? I'm mainly interested in forecasts of high temperature and low temperature, but precipitation forecasts would be great as well.
To clarify, I am looking for historical forecast data. For example, I would be interested in knowing what Wunderground said the weather forecast for April 20th was on April 16th. Essentially, I am looking to compare historical forecasts against the actual weather that occurred to see if different sources of forecasts have different biases.
","['data-request', 'weather', 'historical']","The NOAA / National Weather Service has an archive from the Weather Prediction Center, but it only started archiving most products a few years ago:http://www.hpc.ncep.noaa.gov/archives/web_pages/wpc_arch/get_wpc_archives.phphttps://www.wpc.ncep.noaa.gov/archives/web_pages/wpc_arch/get_wpc_archives.phpMost of what's archived are weather maps (like what you'd see behind the weatherman on the news as he's giving his forecast), and not specific temperatures.  Their 'national high/low' product just reports where the highest & lowest temperature on a given day was recorded, not the high/low for lots of cities.For many years, they only maintained a 'rolling archive', where they'd keep maybe 30-60 days of forecasts, and then purge them.  It's possible that something like archive.org might have some of it, but it'd likely be an incomplete record.  If you wanted to go that route, take a look at the list of NOAA's national centers:http://www.hpc.ncep.noaa.gov/html/othersites.shtmlhttps://www.wpc.ncep.noaa.gov/html/othersites.shtml"
How can we get EAN 13 barcode information of products?,"
I want to get data for barcode, from EAN. In my case, it's mostly about Funko Pop.
Few example code with ""Good Answer"" as link: 889698466844, 889698327169, 889698471947, 889698247016, 889698256551
I found this post which have lot of answer, but no one is working fine.
All proposed options:

OpenProductData : No longer available. All ""reborn"" way are not updated.
DataKick is no longer working, and GtinSearch (the replication) isn't updated
OpenFoodFacts is only for Food, which is not what I'm looking for.
EAN search, UPC, Barcoo are not open data
Amazon Affiliate is not open data and require multiple things to use it
DukTen : the domain name is for sale
Barcode Monster don't find content, scrape and take lot of time to run
EAN13 is in Russian and not open

How can I get barcode information, for free, thanks to open data ?
","['data-request', 'products', 'barcodes']","The issue with this is that there is, in general, no incentive to make this information available to entities outside the business using the barcodes.They are similar to Internet Number Registries. They only lease the IP addresses to ISP's and Businesses. In the case of GS1, they only lease sections of the various barcode number ranges.Working inside retail environments, I've witnessed manufacturers make a number of mistakes:"
Free MIDI file collections,"
Are there any free collections of .mid files for research purposes? I want to do some machine learning over musical works and all places I could find make it really hard to download larger collections of MIDI files. Are there any free resources, similar to text collections like e.g. OSCAR?
","['data-request', 'music', 'open-source']",
Querying LCA (H1-B) data with the Department of Labor (DOL) API,"
To preface, from what I've gathered from other questions relating to DOL, their API website links to this stack exchange site with the hashtag ""labor"" when attempting to contact the API team or ask any questions relating to the API.
This is the Department of Labor developer website: Department of Labor developer website
And this is the link to the documentation on how to use the API.  API Beginner's guide
I'm having difficulty following the documentation and querying the information I'm interested in.  In particular, I'm interested in LCA (H1-B) data, the latest data.
It seems the Department of Labor releases CSV data quarterly.  This can be found here under the ""Disclosure Data"" section:
Department of Labor - Link to CSV for LCA
I imagine through the API, I can find the latest LCA data?  If anyone knows how to query it, please let me know.
I generated an API key on the website, and I've done some basic requests, but I haven't figured out how to query the latest LCA data following the documentation.  Is that even possible?
Any help would be appreciated.
","['api', 'government', 'labor']",
Property transactions datasets in Europe,"
I am looking for data on real estate transactions for as many countries as possible in Europe. These data would ideally include a home's exact location, the transaction price, the transaction date, home characteristics (e.g. number of bedrooms), and information about the transaction (like whether or not it was an arm's length transaction). I have found (via this question]) data like this on the UK, and am now looking for comparable data elsewhere in Europe. Similar datasets in the US context include ZTRAX and CoreLogic's transactions dataset. Thanks in advance!
","['data-request', 'europe', 'real-estate']",
where to find reliable statistics regarding the adoption of public cloud and IAC globally,"
I need to find statistics regarding the adoption of public cloud services (such as AWS, Azure, and GCP) around the world, the adoption of infrastructure as code services, and the distribution between different IaC providers (such as Terraform, Pulumi, Cloudformation, etc..)
the issue is that when I search I can only find stats regarding revenue growth and percentages of companies using them, the stat I need is the actual number of companies that use cloud worldwide (or at least in the US). Regarding IaC I could barely find anything regarding those, I'm pretty new at searching for these things so I would appreciate some good trustworthy sources to look at (and if you have the exact stats I need it would be amazing as well).
I'm not sure this is the correct exchange to ask this. If you have an idea for a better place please, I'm open for suggestions
","['data-request', 'business', 'companies']",
Search for specific media types in a Wikimedia Commons category,"
I'm trying to get a list of all files of a specific media type (e.g. 'video') directly in a category (not in subcategories).
I've tried with list:categorymembers&cmtype:file which gives me all files ,but I can't find a way to filter for specific media types.
And querying all the files and then filtering them seems overkill.
I tried for a while with generator:search but didn't get really far.
",['wikimedia-commons'],You can use filetype:video to get only videos. For example:
Request for Lunar seismic data from Apollo missions (ALSEP),"
I've been trying to find the seismic data of moonquakes from the Apollo missions. I was able to find out Catalogue of Lunar Seismic Data from Apollo Passive Seismic Experiment on 8-mm Video Cassette (Exabyte) Tapes prepared by Yosio Nakamura but not the original dataset itself. Does anyone know if the dataset is actually available to public? The catalogue does provide information about the index and other stuff related with the data but not the data itself. I've tried searching for data on NASA open dataset portal amd got a few csv files but they don't seem like a proper data set. If someone knows anything about it, it would be very beneficial.
",['data-request'],
Dataset for Linux Desktop OS users over time,"
I am looking for a dataset that shows the number of Linux Desktop users over time. The data should only be for Linux desktop users and not Linux servers.
The data should also include the type of distribution and if possible the hardware that was used by the user.
The origin of the data should be available, for example of the source of collection was web based or other.
","['data-request', 'large-datasets']",
Historical EUR exchange rates,"
I am looking for a panel dataset of the EUR with other countries / currencies that give the average exchange rate in each year. Any ideas?
","['data-request', 'finance', 'europe']",
OpenSeaMap data and their attributation,"
I am downloading OpenSeaMap data using the overpass api. However, using [""seamark:type""] is not downloading all the data shown in the TSM (https://tiles.openseamap.org/seamark/{z}/{x}/{y}.png) and downloading data without the seamark type I am drowning in more or less unclassified data.
Hence I am very interested in information on how data are filtered in the OpenSeaMap project to achieve the data shown on OpenSeaMap.org!
It is not only the knowledge what data goes in, but also based on what attributes the symbolization / style is set. For example, most of the buoy are within the group of 'unknown_point', and looking at the attributes, I cannot find an indicator why some of the points are vertex points of restricted area polygons, and others are buoys.
Looking forward to some insights!

ps: I never managed to get into the OpenSeaMap forum, so if any of the good people from this forum are reading here: please make it happen that any credentials work, it's only an email and a password...
",['openstreetmap'],
Experimental data on searching for breast cancer,"
In addition to the Wisconsin breast cancer (diagnosis) can be found in UCI machine learning library for breast cancer datasets, what websites can you find similar breast cancer datasets?Or which websites can provide free breast cancer data sets?
","['data-request', 'medical']",
Collaboratively adding linked data?,"
I don't want to reinvent the wheel, are there any sites where you can actually link data collaborative.
Meaning: finding a picture online in an archive that doesn't have specific metadata, adding that link+metadata on a collaborative platform e.g. website?
","['tool-request', 'linked-data', 'json']",
Oregon property boundaries,"
Is there a freely (libre and gratis) available database of private and public property boundaries in Oregon that could be loaded onto a Garmin GPS as a map overlay, or converted to a suitable format?
","['geospatial', 'usa']",
License to choose for data sharing and re-use for research outputs,"
I'm writing a research proposal. There is a part dedicated to ""Research data management"".
Our product is a priority software, which is not open-source, but people have access to the software by free-trial. We plan to publish regularly a research output by running each major version of software on public test sets that we collect. We don't mind people sharing these outputs, since they can also reproduce these outputs by running our software on these public test sets.
The proposal asks to specify ""Reusability of data/research outputs:  Licenses for data sharing and re-use (e.g. Creative Commons, Open Data Commons)"". My question is what would be an appropriate license for the research output I described.
Could anyone help?
","['uses-of-open-data', 'licensing', 'creative-commons']",
A complete table to guess the usability of something based on wins/losses,"
In the following table from (Algorithms to live by) it provides a guess on how much something is usable based on the numbers of wins/losses, but the table is not complete.
I need a full table or a formula that can calculate these values, to use it as a rating criteria

",['data-request'],
Where to get US State income tax bracket data?,"
I'm building a personal finance calculator app, and want to use state income tax brackets to assist in calculations. Is there a place that I can get a data set of the current years income tax info for a particular state?
Also, if there is an api out there that I could hit for it too, that would be awesome as well.
","['data-request', 'usa', 'api', 'taxes']",
Linking data and making it available as linked data,"
I know some websites with photographs that have missing metadata. For example it could be missing location, missing event (WW1, WW2, …).
If I have a source URL: http://example.org/imgwithoutlocation.png
And I know the image is located in Brussels:

https://www.geonames.org/2800866/brussels.html
http://vocab.getty.edu/page/tgn/7007868 (https://www.getty.edu/vow/TGNFullDisplay?find=brussel&place=&nation=&prev_page=1&english=Y&subjectid=7007868)

I can also link it to WW2 (don't know which vocab to use here?).
1. If I want to create a list of ""missing links"" and make it available on my website as /missing.jsonld, would this be a good start?
[{
  ""@context"": ""https://schema.org/"",
  ""@type"": ""Photograph"",
  ""image"": ""http://archive.org/imgwithoutlocation.png"",
  ""contentLocation"": {
    ""@type"": ""City"",
    ""sameAs"": [
        ""https://www.geonames.org/2800866/brussels.html"",
        ""http://vocab.getty.edu/page/tgn/7007868""
    ]
  }
},
{
  ""@context"": ""https://schema.org/"",
  ""@type"": ""Photograph"",
  ""image"": ""http://archive.org/otherone.html"",
  ""contentLocation"": {
    ""@type"": ""City"",
    ""sameAs"": [
        ""https://www.geonames.org/2800866/brussels.html"",
        ""http://vocab.getty.edu/page/tgn/7007868""
    ]
  }
}]

","['linked-data', 'json', 'rdf', 'semantic-web']","If the source doesn’t provide a URI which represents the work/concept (in addition to the URI that represents the actual image file, and separate from a webpage about the photograph),
I think it makes sense to provide a blank node representing the photograph (like you did).Using the image property doesn’t seem to be appropriate, as it would be an image of (!) the Photograph. The encoding property (and/or its synonym, the associatedMedia property) could be used instead.I can also link it to WW2 (don't know which vocab to use here?)To convey that the photograph depicts a situation associated with World War II, you could use Schema.org’s recordedAt property, representing the war as an Event.This means in natural language:What this structure doesn’t convey is that you are the author of some of these statements. The PROV ontology might be useful for that."
Water quality data for regression,"
I'm searching for a dataset that correlates pH, TDS (total dissolved solids), salinity (in either PPM or percent), ORP (oxidation reduction potential), specific gravity and hardness with at least 500 samples to predict water hardness based on the other parameters using a random forest regression. It doesn't matter location or license as long as I don't have to pay. Timeframe is not important but recent data would be preferable. Ideally the dataset would be in CSV or Excel but JSON or web scraping is OK.
I've tried the USGS water quality portal but It doesn't seem to work
","['data-request', 'environment']","I found it!
It's in India but it's almost exactly what I needed. I'll leave it here if someone else needs it:
https://www.kaggle.com/datasets/harsh2040/surface-water-dataset?"
Google Earth Engine - Sentinel-1 SAR GRD: C-band Synthetic Aperture Radar,"
I'm trying to use SAR data/ image for modeling riverine flood to central Sudan, South Egypt but there no images covering such area.
Is it normal or is SAR data covering the whole world?
What are other data can be used for flood modeling?
","['data-request', 'machine-learning', 'large-datasets']",
Historical Mexico City weather data with humidity,"
i´m looking for a dataset of daily weather data for mexico city going at least to 2010 (yes. i know it´d be huge) to correlate with the polution dataset I found, however all the data i found, inluding the NOAA CDO just includes temperatures and precipitation, however I need relative humidity (either average or max per day).
Ideally the dataset would be a .CSV file but i´m ok with excel files, databases, .TXT or JSON files.
Any license is ok as long as i don´t have to pay for it.
","['data-request', 'weather']",
How to get the data of Supply Chain Index Pressure for each country?,"
From the introduction of NY Fed, they have an index called Global Supply Chain Pressure Index (GSCPI).
I can retrieve the GLOBAL Supply Chain Pressure Index from their website.
However, they also mentioned in the website that:

In addition, we use the index’s underlying data to discuss the drivers
of recent moves in the GSCPI. Finally, these data are used to create
country-specific supply chain pressures indices.

I am wondering where to get the country-specific supply chain pressures indices as mentioned.
",['data-request'],
"Data on vehicle registrations by make, model, year?","
Is there any data available on how many, e.g., 2002 nissan maximas were on US roads in 2019?
I've found this which is almost right.  It lists registrations by vehicle ""type"" (e.g. ""truck"" or ""car""), but I need the make and model of the car for my use case.
",['usa'],
"""officer command code"" in NYC stop and frisk data","
I have been playing with NYC's interesting ""stop and frisk"" data. I noticed a column titled ""ISSUING_OFFICER_COMMAND_CODE"". I was wondering if this is an ID for the officer. Reasons to doubt this is that it only seems to be 3 digits and I imagine there are more than 1000 NYPD officer who could stop and frisk someone. Also searching the internet I found a remark on github that it may not be a unique ID since there are multiple ""ISSUING_OFFICER_RANK"" values corresponding to a single ""ISSUING_OFFICER_COMMAND_CODE"". Though it is possible an officer could have changed rank while keeping the same ID.
","['usa', 'metadata']",
Where can I find a heightmap of South Africa?,"
I've been looking for a heightmap of South Africa for a while but I can't seem to find the kind I need anywhere. It needs to be a Grayscale Raster of high quality.
","['data-request', 'africa']",
Where do sites get all the upcoming flights from?,"
There are various sites where we can search for various flights (opodo, flights.google.com and so on).
I think, these sites get some public, centralized aviation planning of all the upcoming (planned) flights of the world, and then they use various algorithms to present the best for us.
What are they using?
","['data-request', 'aviation']","Yes it's public, You can see all flights on https://www.flightradar24.com/and you can get data from API's like:
https://rapidapi.com/collection/flightradar24-api"
Road tunnels in Italy - list or shapefile,"
I am looking for a list of all road tunnels of Italy. Either a list of the tunnels with the year of opening and their location or a shapefile.
I already downloaded the Open Street Map data but it looks like there are really few tunnels identified there.
Any other sources?
","['data-request', 'geospatial', 'italy']",
Looking for a project similar to UN CartoTile,"
I am looking for map data (geojson) that is similar in style to the UN CartoTile style of map found here: https://www.un.org/geospatial/mapsgeo/webservices.
I found a site some time back that has this data but I am unable to find it again.  That is, the site has data that will render a simplified, blocky style administrative regions on a map.
If I am recalling correctly the site was for a fairly recent project, open source, and was from a pretty well known organization. On the home page there was a graphic showing the blocky administrative regions of Europe I think. I believe with a purplish color.
It definitely is not the UN site but here is a screen capture from the link above for reference.

It was recommended that I ask here. See: https://meta.stackexchange.com/q/381068/1238100.
","['data-request', 'geospatial']",
Latest data on frequency of insurance claims,"
I have developed a new model which caters for frequency data with large number of zeroes and ones. I am looking for new and latest data on number of insurance claims for any types of claims. In insurance claims, many policyholders do not claim because it will affect their No-Claim Discount/Bonus provided by their insurance company. And usually, if they claim, they will claim only once because most policyholders are believed to be a good driver with enough experiences to not cause accident and takes good care of their vehicles. Is there any datasets that gives information like the following:

Policy Number or ID Number or any distinct information for the policyholders.
Number of times claimes in a particular time (a year or 10 years).
Type of Cars (based on the brand or cubic capacity or both).
Types of insurance coverage (if available).
Location (states or urban-suburban-city types).
Other informations.

The model will then be further developed to accomodate all these variables as covariates in my research. If anyone can direct me to pages/links regarding this, it will be highly appreciated.
p/s: It is okay if the data has been studied previously because it will allow us to do some comparison as well.
",['data-request'],
Need help finding dataset whose original source is removed,"
Energy Consumption in schools Dundee
I need this dataset for a project. The original source has been removed. I couldnt find any references to it. Any help would be appreciated.
",['data-request'],
Comprehensively of FBI Crime Reporting Program,"
Does anyone know how comprehensive the FBI crime reporting program is? For example, if I wanted to answer the question: how likely is crime x to happen, can I rely on this data* or should I assume there is a lot missing from local, country, state, etc
*I'd also need to take into account some crimes are likely not reported at all.
https://www.fbi.gov/services/cjis/ucr
","['usa', 'crime']",
,,,
What is the projection system used in Bhunaksha Rajasthan?,"
I am trying to get the survey number details from Bhunaksha website . The website shows the coordinates on the top left corner, when I move cursor over a land record. I am able to find projection system of the coordinates displayed on top left corner.
Can anyone help me in this ?
","['geospatial', 'india']",
British shipping forecast boundary shapefile,"
Does anyone have access to a shapefile containing British shipping forecast boundaries? I can see a shapefile on the ESRI website but I cannot download it and have not been able to contact the owner of the data.
","['data-request', 'geospatial', 'uk']",I used to have a shapefile but I can't find it any longer - I created it by hand using the coordinates given at http://www.users.zetnet.co.uk/tempusfugit/marine/area_coord.htm and a UK coastal outline.
How to format openFDA API results?,"
I am able to retrieve the results for a drug from the openFDA via PHP; however the results are just strings of text without any indicators for formatting such as html tags or splitting them up into different objects. Is there a version of the data that can be more easily formatted? I feel the data is pointless if it isn't human readable.
EDITED above for clarification.
How I am retrieving the data:
$xml_path = 'https://api.fda.gov/drug/label.json?api_key='.$api.'&search=set_id:'.$setid;

$ch = curl_init();
curl_setopt($ch, CURLOPT_URL,$xml_path);
curl_setopt($ch, CURLOPT_FOLLOWLOCATION, 1);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);
$data = curl_exec($ch);
curl_close($ch);

$setid_array = json_decode($data, true);

// Empty string
$results = '';

// Ensure there is a setid array
if (!empty($setid_array)) {

    // Results 
    $sections = $setid_array['results'][0];

    // Cycle through each
    foreach ($sections as $key => $section) {

        // Get the content
        $content = $section[0];
        echo $content;
    }
}

What I get for ""Indications & Usage"" on Rosuvastatin for example:
1 INDICATIONS AND USAGE Pediatric use information for patients 7 to 17 years of age is approved for AstraZeneca’s CRESTOR (rosuvastatin calcium) tablets. However, due to AstraZeneca’s marketing exclusivity rights, this drug product is not labeled with that pediatric information. Rosuvastatin tablets are an HMG Co-A reductase inhibitor indicated for: • adult patients with hypertriglyceridemia as an adjunct to diet ( 1.3 ) • adult patients with primary dysbetalipoproteinemia (Type III hyperlipoproteinemia) as an adjunct to diet ( 1.4 ) • adult patients with homozygous familial hypercholesterolemia (HoFH) to reduce LDL-C, total-C, and ApoB ( 1.5 ) Limitations of use (1.8): Rosuvastatin tablets have not been studied in Fredrickson Type I and V dyslipidemias. 1.3 Hypertriglyceridemia Rosuvastatin tablets are indicated as adjunctive therapy to diet for the treatment of adult patients with hypertriglyceridemia. 1.4 Primary Dysbetalipoproteinemia (Type III Hyperlipoproteinemia) Rosuvastatin tablets are indicated as an adjunct to diet for the treatment of adult patients with primary dysbetalipoproteinemia (Type III Hyperlipoproteinemia). 1.5 Adult Patients with Homozygous Familial Hypercholesterolemia Rosuvastatin tablets are indicated as adjunctive therapy to other lipid-lowering treatments (e.g., LDL apheresis) or alone if such treatments are unavailable to reduce LDL-C, Total-C, and ApoB in adult patients with homozygous familial hypercholesterolemia. 1.8 Limitations of Use Rosuvastatin tablets have not been studied in Fredrickson Type I and V dyslipidemias.

",['openfda'],
"Wind power generation in Germany (location, actual operation of turbines)","
I'm looking for microdata on the location and actual operation of wind turbines in Germany. There is a similar question (see here), however it is from 2019 and links (e.g. to German plant listings) are broken.
I don't need actual energy generation. However, I would need information on if some wind turbine was actually operating at some point in time or not plus the respective location of the turbine.
Alternatively, the location and the date a wind turbine (or wind park) assumed operation would be an option for me as well.
I know that Bundesnetzagentur published data on wind turbines in the past, but I don't know what is published exactly (and where).
","['data-request', 'energy', 'germany']","It might be a bit late but I was looking for the same kind of data recently. You can find the data on German power plants on this platform.This is the official registry in Germany since 2019. They provide information on the location, the capacity and the status. I hope it will help you."
Where can I get projections of the population by income level and age (such as population by income percentile) in a US county through 2040?,"
For example, a long-term projection of the population in Fulton County, GA (not this one specifically, just a random county I picked) with the number of people age 65+ earning more than $100,000, the number of people age 65+ earning more than $200,000, etc. I know the error bars will be huge on this, especially that many years out, but I have to ignore that for now. It doesn't have to be those exact income levels, but I'm looking for some measure of the projected income distribution by age or age bracket.
","['data-request', 'economics', 'population', 'income']",
"French list of word where I can use filters like nouns, singular form, verbs…","
I often need to find a list of french words (sometimes english as well, but that's certainly for another question) where I can filter words depending on multiple criterias. For instance, I may like to select only nouns, singular nouns, or non-conjugated verbs (infinitif), nouns masculin... It would be even nicer if I could also filter depending on the frequency of the word.
Note that I'm fine if the file is simply a csv/sql/whatever format that I need to parse using python or alike.
One application could be to create a list of words to generate passphrase, in such a way that this list only contains nouns or verbs that are not conjugated.
","['data-request', 'language', 'french']","I suggest Lexique.org or OpenLexicon.Lexique gives the word, a phonological representation, morphological information, frequency in a subtitles corpus, etc.OpenLexicon gathers multiple lexical databases, among which many for French."
Wikidata dump in another language,"
I am aware that you can download a Wikidata dump file from here
But is it possible to only include results for a specific language?I have in the past worked with a json dump file and used python to parse it as well as this library to get the labels of properties such as P106 in english (""occupation""). But is this something that can be done for other languages as well?
","['wikidata', 'python']",
What are the available labeled twitter datasets by topic,"
I want to know about recently available datasets for twitter topics where each tweet has its topic.
","['data-request', 'social-media', 'large-datasets', 'social-process']",
TSA Wait Times API,"
https://www.dhs.gov/mytsa-api-documentation
There used to be an API for TSA airport wait times, but it seems to have been closed down. Does anyone know if this data is available from anywhere else?
",['data-request'],Turns out there is no good answer to this! Some people have clearly figured it out but there doesn't appear to be a solid API or easily available dataset.
Looking for a DEM elevation model for entire UK - not in tile form,"
I need to calculate the elevation of 1600 survey plots covering all of the UK - I have these formatted as a point shapefile. I have looked at the OS50 dataset but this is only available as tiles and it would take forever to process each tile individually - my points cover the entire country. Is there free-to-use raster elevation data anywhere that is not split into many tiles?
I have read several questions on here relating to sourcing elevation data and I also downloaded the Environment Agency LIDAR composite dtm dataset - but this does not appear to contain any asc or tiff files so I can't get a raster from it. I just want a simple calc of elevation for all these plots without having to process many individual tiles.
","['data-request', 'geospatial']",
Does the NWS/NOAA provide a Beach Safety conditions API?,"
I see that the National Weather Service has a couple of pages with current Green/Yellow/Red flag conditions for beaches:
https://www.weather.gov/greatlakes/beachhazards
But where does that data come from? I can see it's an embedded ArcGIS map, but do they provide beach conditions as an API somewhere?
","['api', 'weather', 'noaa']",
Georeferenced timeseries on EU/Global energy load by powerplant (including information on fuel type),"
I am looking for a georeferenced dataset in any format providing longitudinal information at the year/month and EU or global powerplant levels. Ideally, it should have information on load, capacity, and fuel(s) used.
","['data-request', 'geospatial', 'time-series', 'energy', 'longitudinal']",You will have to work a bit but you can take a look at the Entsoe platform and JRC's power plant database.The Entsoe database provide information on the power plants load and capacity. The JRC's database provides the geolocalisation.They both identify the power plant by a code so it should be fairly easy.
Event log data for Process Mining,"
Process mining assumes the existence of an event log where each event refers to a case, an activity, and a point in time. An event log can be seen as a collection of cases and a case as a trace/sequence of events.
Event data may come from a wide variety of sources:

a database system (e.g., patient data in a hospital),
a transaction log (e.g., a trading system),
a business suite/ERP system (SAP, Oracle, etc.),
a message log (e.g., from IBM middleware),
an open API providing data from websites or social media,

I am looking for publicly available event logs with csv or xes or any other available formats.
",['data-request'],processmining.orgAvailable data sets in XES:Available data sets in CSV:
Where can I find the source code of Wikipedia / Wiktionary templates?,"
Wikipedia and its sister sites make heavy use of templates. I want to find the source code behind those templates, i.e. the code that renders the HTML from a given template reference.
Looking here, I found a few files which seem to deal with templates, but I could not find any results when looking for a specific one. For example, the template {es-conj}, which renders a conjugation table for a given Spanish verb, did not show up in the search list.
",['wikipedia'],
How can I list FDA approved drugs in a year? asked again,"
Does anyone figur this out?
How can I list FDA approved drugs in a year?
The answer stated the example for the year of 1981, and that call contains [1981-01-01+TO+1981-12-31].  So, I assumed that I should change to 2021.  However, what I got was ""SYMTUZA"" which is not on the list of approved drugs in 2021.
Here is the
openFDA API call I used, and I was wrong. I got:REMICADE.
Still, I could not get a drug on the list of approved drugs in 2021.
One answer suggested to add a filter of submission_type:""ORIG"". The follwing is the API call revised, I blieve, adding the filter.
another openFDA API call
I still get REMICADE, which is not on the list of drugs approved in 2021.
",['openfda'],
How to get data from pandora papers,"
From pandora papers we know that who are in that list.
But how do i get pdf, excel sheets, images etc. types data,to use as evidence, from pandora papers for a person in that list ?
","['uses-of-open-data', 'images', 'pdf', 'excel', 'leak']",
Device Events for 2022 Q2 are missing,"
I want to ask why the Maude-Device-Event Files for Q2 are currently not available in the downloads. See:

https://open.fda.gov/data/downloads/

It states last updated on 2022-06-23.
","['openfda', 'download']",
I'm looking for the share of nudists per country,"
I'm looking for a dataset regarding the share of people who identify as naturists/nudists or have tried nudism per country, preferably as a CSV or JSON file or a spreadsheet but web scraping would work too.
Ideally this would include all the OECD countries but anything that includes at least one or 2 countries per continent (including South America) would work.
I don't need a specific license so anything is ok as long as I don't have to pay for it.
I'm not sure if this kind of data exists at all.
","['data-request', 'demographics', 'global']",
Updated and Cleaned World Railroads Data,"
Does anybody have the updated and cleaned and connected world railroads network?
In a way that could be used for routing.
","['data-request', 'geospatial']",
Elevation/LiDAR/DTM Data with resolution less than 5m for Cheshire UK,"
I'm trying to find some elevation data - either LiDAR, elevation or DTM - for the UK, specifically in Cheshire. I am a University student, so have access to gov data and other databases. I currently have the OS Terrain 5 which has a resolution of 5m. Ideally I need 1-2m or less. However, I can't find this.
Any ideas of whether this data is out there?
UPDATE:
I have tried the government portal, however, my site is currently part of the country that has yet to be mapped. This is the government coverage for the area I am looking for (Brown layer). The green polygon is the area I need data for.

","['data-request', 'geospatial', 'open-source']",
How do I find NDC-level therapeutic equivalency (TE) codes (Orange Book),"
FDA Orange Book data contains a column for strength, but it is formatted so differently from the strength columns available in other FDA data (i.e. NDC catalog).  Therapeutic equivalency codes (TE codes) from Orange Book are at the dose form-route-strength level yet without a map between the strengths in Orange Book and FDA NDC catalog, I'm finding it impossible to know that a given NDC has a given TE code.  The closest you could get would be to say that a given Application Number (i.e. ANDA012345) has products with 1 to n TE codes.
Mapping the strengths between the two data sources seems tedious and error prone; however, Orange Book data also contains a ""Product Number"" (i.e. 001, 002, 003) field that - if included at the product NDC level in other FDA NDC data sources - could be a reliable map between the two sources.
Can this be added, or is there another way to accomplish this?
Example:

",['openfda'],
Why is my API call for drug.active_ingredients.name.exact not working? (Animal and Veterinary endpoint),"
I am trying to look up data on the ingredient milbemycin oxime, and I want results that contain only milbemycin oxime as the active ingredient.
https://api.fda.gov/animalandveterinary/event.json?search=drug.active_ingredients.name.exact:""milbemycin+oxime""&limit=1000
returns 0 results. This cannot be the case as there are several pet medicines with milbemycin oxime as the sole active ingredient for which I know adverse reaction events have been reported.
I also tried ""spinosad"" (Comfortis single active ingredient) and again 0 results.
However, there are many results when a query allows for multiple active ingredients.
Thanks in advance!
","['api', 'openfda', 'uses-of-open-data']",
Monthly city-level data for public transport usage (or ticket sales),"
Are there sources through which data on passenger numbers (or ticket sales) for European cities (in particular DE, AT, CH and Scandinavia) are available at a monthly resolution?
","['europe', 'public-transport']",
How do I modularize openFDA API requests?,"
I'm trying to iterate through an excel sheet and find the NDC of a drug from its generic name in each cell in a column so that I don't have to manually type in each generic name. This is what I have so far, but the parameter value is not recognized as a valid key. Is there a syntax problem or something else wrong?
wrkbk = openpyxl.load_workbook('data.xlsx')
sh = wrkbk.active

for i in range(1, sh.max_row):

    cell_obj = sh.cell(row=i+1, column=3)
    parameter = cell_obj.value

    response = requests.get('https://api.fda.gov/drug/ndc.json?search=generic_name:',parameter)    

    jprint(response.json())

","['api', 'openfda']",
Well-Known Text format (WKT) country dataset,"
Is there a dataset free online that I can download to get the country coordinates (polygons) in WKT format?
I cannot find it anywhere. I would like a dataset that includes both the country name and the polygons (no multipolygons) of the same country in WKT format. Also, I would like that the dataset ignores the islands (for example I would like only the mainland of France and not the islands). Thank you in advance.
",['geospatial'],
Does IKEA have a json / XML access point for product information?,"
For a small project I would like to get the product data for IKEA products. Things like dimensions, color, assembly instructions etc.
Other parts of IKEA data (product names, item number, stock level and stores) are available in an XHR call, but I can not find the product details anywhere except inside the HTML code as a json structure inside an attribute. So lots of overhead here.
Do anyone know of an IKEA API for these details ? Or know how to get access to the new InterIkea API developer portal ?
","['data-request', 'api']",
Dataset of Indian Address,"
I am looking for a dataset of Indian Address.
Possibly in the following format:
Address Line 1,
Address Line 2,
Town/City,
State,
Postal code.
I have tried to find it but there doesn't seem to be one freely available.
Has anyone tried point me to a spot where it may be available.
","['address', 'large-datasets']",
Bulgarian dataset for sentiment analysis or comment helpfulness,"
My team is researching solutions about sentiment analysis or comment(preferably product review) helpfulness in Bulgarian. Anybody know a good source for those? The comment health one is a long shot for sure, but at least somebody should know a sentiment labeled dataset. Any other suggestions would also be appreciated!
","['data-request', 'products', 'sentiment-analysis']",
Germany Transmission Network,"
Is there any source to find the high voltage (110kV and above) substation and transmission network for Germany.
I have tried contacting the Transmission System Operators but have only got generic responses back.
For the substations a list of coordinates would be ideal but even a static map that could be geo-referenced in would work.
Any ideas as google searches have started to fail me.
","['data-request', 'geospatial', 'energy', 'germany']","Have a look at the openmod wiki, which lists currently available sources.The appropriateness of sources depends on the details of your use case. For example, if you are happy with quantitative transmission capacities between ""reasonable"" grid nodes, you could go for the input data of the open source ELMOD-DE. If you require full geographical detail, your best bet is likely to pull the data from OpenStreetMap and do some postprocessing: Check out this discussion concerning the extraction of distribution/transmission lines. Substations would be analogous. To the best of my knowledge, that's what most models rely as original input. Don't count on the TSOs ;)"
Are there any open datasets for commercial use?,"
I am creating a bootcamp for data analyst and it's been 2 days I am looking for some good dataset fit for commercial use that I can use to create Tableau and Power BI tutorials. Even on kaggle some datasets are licensed as CC0 but when you track back the company the data was scrapped from, it states that the data shouldn't be used for commercial use (e.g Zomato dataset).
Are there any good data sources which I can use for this bootcamp's tutorial? Does the sample superstore dataset of Tableau can be used? But I think it does come under strict copyrights as well.
P.S I have emailed tons of people for permission and haven't heard back from anyone.
","['data-request', 'data.gov']",
Fail to search a wikidata item through SPARQL,"
I tried to search and get the ID of a item with a certain label: Teodor Bogdanov. I can search this name successfully through wikidata website. However, I failed to do so by searching through SPARQL. The code is here.
I also copied it here:
SELECT distinct ?item ?itemLabel ?itemDescription WHERE{  
  ?item ?label ""Teodor Bogdanov"".
}

The same thing happens for Félix Anaut
Could anyone help me fix this issue? Thank you in advance.
","['wikidata', 'sparql']",
I'm looking to match quite a lot of US companies to their NAICS codes without having to manually search it up,"
I know it can be done manually through the NAICS website but I have over 3000 companies and I need to get their NAICS codes. So I'm looking for a database or anything else which I can download.
","['data-request', 'business']",
Seeking free georeferenced databases,"
Could you help me to find free georeferenced databases for study purpose?
For example, database with georeferenced data about soil chemestry (N-P-K, Calcium, Magnesium...), soil physics (Soil Density), electric conductivity, Cation Exchange Capacity (CEC) and other relevant information.
","['data-request', 'geospatial', 'data.gov', 'uses-of-open-data']",
Seeking global metropolitan areas geospatial dataset,"
I am looking for a current, global vector dataset of metropolitan areas. The US Census Bureau has what I am after, though only for the USA. I also see that Natural Earth has an Urban Areas dataset, yet this is based of fairly old data for my purposes (2002-2003).
Is there a generally accepted global dataset of metropolitan areas similar to the linked US Census data, or will I need to piece together multiple datasets?
","['geospatial', 'spatial']",
"Asking for some sources of country-level data regarding technology literacy, cashless level, financial moneytary policy, and financial stability","
I am looking for the sources for these variables (country-level), as many countries as possible about: the technology literacy levels, cashless level, financial monetary policy, and financial stability system of each country.
Regarding the financial stability, I found a source from Bo Sun but they just cover 22 countries
",['economics'],
Wind Speed and Direction Datasets,"
I am trying to find historical (e.g., one year) wind speed and wind direction datasets for different suburbs in Sydney/Greater Sydney in CSV format. I tried different platforms for it but could not find it. If it is not possible to get free of charge, any other city's dataset including different station locations could also be acceptable.
Any help in this regard is much appreciated.
","['data-request', 'data.gov', 'releasing-data', 'large-datasets']",
Correspondence table between regional spatial units from NUTS and GADM,"
The NUTS (https://en.wikipedia.org/wiki/Nomenclature_of_Territorial_Units_for_Statistics) divides countries into regions.
So does the GADM (https://gadm.org/).
Is there any publicly available correspondence table that allows for an (approximate) matching between the two?
",['spatial'],
augment/enrich latitude longitude data,"
I am looking for ways to augment/enrich latitude longitude data, to obtain for example information like this (for the EU/Europe and the UK):

rural/urban area
distance to lake/sea
distance to nearest town/village
number of restaurants nearby

I tried some basic Python code to use :
import geocoder

g = geocoder.osm([45,-75], method='reverse')
print(g)

This returns:
<[OK] Osm - Reverse [Ault Drive, Ingleside, South Stormont, Stormont, Dundas and Glengarry Counties, Eastern Ontario, Ontario, K0C 1M0, Canada]>

so not useful for my use case. What else could I explore, please?
","['demographics', 'geocoding', 'python', 'population', 'restaurant']","I'm actually working on a project like this (feel free to contact me directly for more details) and here are some sources I know above and beyond OpenStreetMap:Coastal distance: https://oceancolor.gsfc.nasa.gov/docs/distfromcoast/ (caveat: treats inland seas, such as the Caspian Sea, as land)More accurate coastal distance (but you have to calculate it yourself, I used GRASS GIS): http://www.soest.hawaii.edu/pwessel/gshhg/Land cover/use data (rural vs urban for example):https://eoimages.gsfc.nasa.gov/images/news/NasaNews/ReleaseImages/LCC/https://www.gsi.go.jp/kankyochiri/gm_global_e.html under ""Land Cover (GLCNMO)https://www.esa-landcover-cci.org/?q=node/158Elevation data: https://www2.jpl.nasa.gov/srtm/Animal habitat data: https://www.iucnredlist.org/resources/spatial-data-download (may require free login to actually download linked data)Climate data: http://koeppen-geiger.vu-wien.ac.at/Population count and density:https://sedac.ciesin.columbia.edu/data/collection/gpw-v4https://data.worldpop.org/GIS/Population/Global_2000_2020/ (see https://data.worldpop.org/ or https://data.humdata.org/ for more general information)Ethnicity data: https://icr.ethz.ch/data/epr/#geoeprSolar energy availability: https://energydata.info/dataset/world-photovoltaic-power-potential-pvout-gis-data-global-solar-atlashttps://www.naturalearthdata.com/ has lots of free data of various types though it's at lower resolution that some of the more specific sites aboveFor completeness, there are many sources of weather data at Sources of weather data but, if you're looking for general properties of a given latitude/longitude, you're almost certainly more interested in climate, not weatherI do have other data, but it's fairly obscure and probably uninteresting."
Types of data great for webscraping,"
I am a professional web-crawler and love scraping sites for potential data. However, I have recently hit a brick-wall on openly sourced websites with unique data that can be webscraped.
So I would like to gather a few ideas on data that would be great to scrape for the following reasons:

It's unique; It has not been scraped before, or minimal places to access this information.
Having a larger database for this data would be optimal for professionals in various fields to work with.

links to the websites to get the data would be great also!
Additional note:

There is no specific region for this request; If the data can be found in various countries that would be a bonus!
If the website does not like being web-crawled because the data is that much more difficult to grab, I am still happy to look into it

","['data-request', 'web-crawling']",
Does anyone have electricity consumption data of Turkey on hourly basis for last 25 years or any period?,"
I am looking for electricity consumption data for provinces/ districts/regions of Turkey for last 25 years (or any period) on an hourly basis. On there official statistics site it is available only on yearly basis.
","['data-request', 'energy']","There is no an open data for that. The official statistics site and TEİAŞ have main statistical data for electricity consumption. If both don't have it, you won't find it anywhere else. Finding hourly/weekly basis data! It is almost impossible."
"Same distribution and median on all five features in point cloud dataset, weird?","
I wanna start off by saying I'm new to asking questions on forums, so I'll try to do it as best as I can...
Backstory:
I'm using point cloud data from an FMCW radar to do binary classification for human activity recognition. When I evaluate the model on the test data (unseen data) it gets an accuracy of 81%. However, during live tests when deployed it performs poorly and sometimes feels like flipping a coin.
I plotted histograms to take a better look at the data that I collected. I know I should've plotted histograms earlier when visualizing the data but simply forgot to do it.
Good to know:
The features are Elevation, Azimuth, Doppler, Range, and SNR. The data is recorded from two radars, positioned in the corner of a room and the other placed in the opposite corner. The plots show the histogram for each feature across the whole dataset.
The problem:
I'm starting to get worried that something weird is going on with the data since the histograms for the features are identical and the median is practically the same. I'd expect some kind of offset in the median since not all features have the same unit (Range has meters, SNR has steps of 0.1 dB and Azimuth has radians). There is interference between the radars of course, but should only cause problems with some values (which often result in outliers).
There is a total of 62,046,400 numerical values per feature.

Elevation median: 0.791562
Azimuth median: 0.795468
Doppler median: 0.796543
Range median: 0.797557
SNR median: 0.797557

Histograms:
Y-axis is amount, X-axis is the numerical value
Azimuth

Doppler

Elevation

Range

SNR

",['machine-learning'],
Downloading sectorwise classification map and data of India,"
Can you suggest where I can download the exact data and map of the sectorwise (industrial, commercial, residential, agricultural, and forest) land use patterns of India?
Is this available on the Bhuvan (Indian Geo-spatial data portal) or Survey of India websites.
Or any other sources?
","['geospatial', 'india', 'map']",
What is the best way to convert a taxonomy from wikipedia into a JSON-like object?,"
I'm trying to use the Wikipedia academic fields as a JSON object in one of my projects. I couldn't find it in a useable or convertible format so I am looking into the best approach to obtain it.
I came up with 3 approaches:

Get the data from DBPedia (https://dbpedia.org/data/Outline_of_academic_disciplines.json) but it returns a non-ordered list with no hierarchical level
Copy-paste the markdown from the Wikipedia page and proceed with a regex/find/replace trickery but it is not as easy as it seemed at first (inconsistencies in the page to deal with across 5900 lines once prettified)
Go the programmatic way: I import the markdown file and parse it. It feels like I'm doing a computer science exercise (a fun little recursive function) and I would gladly spend time on it if I had some to spare. The part where I go through trial-error to correct all the inconsistencies in the file doesn't look too appealing tho. :-)

I probably will go for the third option if I don't find an easier way. However, as all 3 options would require a good amount of work and I would gladly welcome a better/simpler approach.
Any ideas? Any other source to find wikimedia related data in a suitable format in general and this page in particular?
Thanks
","['uses-of-open-data', 'wikidata', 'json', 'wikipedia']",
Does anyone have the monthly data export and import of Russia?,"
I am looking for data regarding the export and import of Russia during the recent 3 months monthly. I am wondering if anyone can give me a hint
","['data-request', 'economics', 'russia']",
Spanish Cadastre Owner,"
I have done a few researches about the spanish cadastre. I found the incredible QGIS plug-in ""Spanish Inspire Catastral Downloader"" which allows to retrieve the parcels.
I am now asking if there is a dataset linking the parcels and the owners. As a comparaison, in France, a dataset of the parcels owned by a moral person -ie a company- is published.
Is there something like this in Spain ?
",['geospatial'],
Has any recent academic research been done on the comparative performance of FOIA response speeds by different European governments?,"
Recently, I took part in a large, international investigative journalistic project on dumps of oily waste water by ships. In that context, I did a FOIA request to the Dutch government. Whereas the journalists that partook in the same investigation received the relevant documents pretty quickly in their respective countries when they sent out a similar request, I haven't received the information I asked for even after 8 months and a legal procedure with the administrative judge - who decided in my favour.
The inadequate response from the Dutch government in this case got me wondering about whether any systematic, academic research has been done on the comparative performance of FOIA response speeds by different European countries. I've tried finding recent and relevant scientific literature about this topic on - for instance - Google Scholar, but to no avail.
Question: are there any academic research papers that compare the response speed and adequateness of FOIA requests in different European countries, preferably including the Netherlands?
","['data-request', 'government', 'europe', 'academia', 'foia']",
Address Data and Coordinates in Germany,"
I'm looking to purchase the a database containing all the address data in Germany including the coordinates of these properties.
Does anyone know where I can download such a database or a provider that could provide one?
","['data-request', 'database', 'real-estate', 'address']","I would suggest to use OSM data: https://download.geofabrik.de/europe/germany/Regards,
Grzegorz"
oxford dictionary database for NLP,"
I am using NLP for sentiment analysis ,so I need to determine the type of speech , can any one help me where can I download dataset/database  for oxford dictionary?
","['data-request', 'nlp']",
Does anyone know where to find the WSJ audio dataset?,"
I'm trying to duplicate the SVoice results here shared by Facebook:
https://github.com/facebookresearch/svoice/
They mentioned that their model was created using WSJ. They couldn't share the model due to legal concerns but the repo outlines how to replicate if you have access to this data. Would anyone know where I could find it?
","['data-request', 'audio']",
I would like to take an online Fraud course and need help finding it?,"
I would like to take an online Fraud course and need help finding it?
",['usaidopen'],
"Looking for datasets about poverty and its effects (eg education, health)","
I want to analyse the impacts of poverty (absolute poverty) on areas such as education and health. Some of the variables I would like to analyse are: years of schooling, rates of diseases, unemployment rate. I am preferably looking for latest data, at least until 2021. I would prefer several datasets, such as data categorized by continents. However, a country specific dataset would also be fine.
","['data-request', 'economics', 'global']",
OpenStreetMap power grid data for a given year,"
How do I download OSM power grid data (for India) for a particular year or at a particular time point? I do not want the latest maps but those with specific timestamps.
",['openstreetmap'],
"Is there such a thing as a truly objective, neutral, factual news source for world news?","
I'm trying to fetch not headlines but rather facts. I have no interest in reading any ""opinions"" or ""articles"".
I do not want to hear propaganda such as Thousands Fleeing Ukraine After Russia Attack, but instead Russia fires 10-12 missiles toward Ukraine with a timestamp attached to it, etc.
I hope I make myself clear. I've stopped reading any so-called ""mainstream"" since many years, but even the so-called ""alternative"" news are full of idiotic, unwanted ""opinions"" which I have no interest in wading through.
I've already gone through the phase of collecting ""all sources"", but it very quickly exhausts me. I don't want to manually scan through tons of ""opinion"" headlines. I just want cold, established facts with zero ""feelings"" or ""spins"" added. Just a feed of ""events that happen"". I imagine it to look something like this (these are completely made up ""facts""):
Microsoft releases Windows 12
YouTube removes downvotes
Ukraine adopts Bitcoin as primary currency
Russia buys 10-15 containers of Bitcoin miners
USA elects John Doe as new president
Nintendo stops making hardware

And so on.
I have never been able to find any such thing anywhere. It always ends up with me having to add a million different keyword-based filters and then unwanted ""opinions"" still keep slipping through. Slashdot is a perfect example of something where 1% is actual news but 99% of it is propaganda/noise. It drives me insane to try to wade through headlines even with all my ""automatic processing"".
Is there really no such project run where they only report ""what happened"" rather than ""how I am supposed to feel and think about it; here is my annoying and wrong opinion which I'm forcing down your throat""?
",['news'],
St Michael's cave in Gibraltar,"
St Michael's cave in Gibraltar
Unesco World Heritage site
I would like to know how a new world heritage site is updated in the Unesco world heritage sites repository?
Can the St.Michael's Cave in Gibraltar be added as a new Unesco world heritage site?
","['geospatial', 'research']",
Dataset that contains customer support interaction,"
I am looking for datasets containing customer support interaction. Not any aggregated statistics (resolution time, survey results), but the actually written emails/chat messages between customers and support assistants. IT forums could be helpful as well, but I don't know any that provide a dataset with the QAs.
I tried Google DatasetSearch, but I wasn't able to find exactly what I am looking for.
","['data-request', 'nlp']",
Open data with GIS locations of bombing or artillery attacks in Ukraine,"
I was wondering if anyone know of a dataset that is tracking the GIS locations of the bombing and artillery attacks in Ukraine? I was particularly interested in Kiev or Kharkiv regions, but I will take whatever I can get. If anyone know of data like this, please respond with the link.
","['data-request', 'geospatial', 'ukraine']",This website looks like it has the data you are looking for. You could reach out to the owners of the site to see if they would send you the raw data. Another potential hit is ACLED which has geo-located conflict instances.
TSA Checked Passengers Daily Data for 2002-2022,"
The TSA has daily checked passenger data on their website for 2019 to present. Where can I find the data for the prior years?
","['data-request', 'federal']",
How can I get information about redirects in the Wayback Machine API?,"
As some of you may have noticed across the network, I have a couple of scripts to repair broken images or broken links. They often make use of the Wayback Machine, which has a simple API to query the latest snapshot of a page.
I'm currently checking whether I can fix the many broken links to springerlink.com. I've noticed that broken links like http://www.springerlink.com/content/g29akrhnyf0ul4np/, found in this Skeptics.SE answer, have been saved in the Wayback Machine:

Loading...
http://www.springerlink.com/content/g29akrhnyf0ul4np/ |
02:35:13 January 12, 2015
Got an HTTP 301 response at crawl time
Redirecting to...
http://link.springer.com/10.1023%2FA%3A1014576505223?from=SL

and this redirect is very helpful; I'd like to use the final URL (https://link.springer.com/article/10.1023/A:1014576505223?from=SL) in the edit. However, there seems to be no way for me to get this URL, or even the 'snapshot' from the API. It seems the API only serves 'completely successful' snapshots. I've tried the following URLs:

https://archive.org/wayback/available?url=www.springerlink.com/content/g29akrhnyf0ul4np/
https://archive.org/wayback/available?url=//www.springerlink.com/content/g29akrhnyf0ul4np/
https://archive.org/wayback/available?url=http://www.springerlink.com/content/g29akrhnyf0ul4np/
https://archive.org/wayback/available?url=https://www.springerlink.com/content/g29akrhnyf0ul4np/

but none of them work. Any ideas, or should I just try to mimic a browser request?
","['api', 'archive.org']",
Hourly historical data in Google Trends?,"
It was possible to collect any data on google trends hour by hour in the past.
However, Google changed the search engine, and nowadays, we can only get hourly data at the platform since a week ago.
Some solutions (e.g., PyTrends) are not working correctly.
Is there any way to get historical hourly data at Google Trends that works in 2022?
Thank you.
",['data-request'],
Where to find USA river drainage data as shapefile in R,"
I'm looking for a shapefile of all major river drainages in the USA. Something similar to this in R:

Specifically, I need the Arizona/New Mexico boundaries but probably could zoom in from the US shapefile...
","['geospatial', 'usa', 'hydrology']",
"Need top 1000 city names in Ukraine in English, Ukrainian, and Russian","
I'm working on a project to track Russian troop movements in the Ukraine with a large group of people. I'm tasked with internationalizing the data.
We need a list of the top 1,000 cities in Ukraine and we need them in English, Ukrainian, and Russian. I'm hoping someone here can help me do this faster than if I were to learn it myself.
Right now I'm using https://query.wikidata.org/ because I think it has the ability to do this, but not having much luck.
Is there someone who can help me print a list of these names in 3 languages? One column per language?
","['data-request', 'geospatial', 'wikidata', 'translation', 'ukraine']",
Does it make sense to restrict the meaning of an external entity for our purposes?,"
We create a standard for a data exchange format in form of an RDF graph.  We would like to re-use existing class entities of external ontologies that fit our needs – except that they are too general and can be related to entities of other external classes too freely.
Thus, does it make sense to say in our standard

Use http://example.com/SomeClass for that but relate it to http://example.com/SomeOtherClass only to express <some explanation>.

Or, is it necessary to define new entity classes for that in our own namespace, possible with is-a relations to the external classes?
To give an example: We must describe physical experiments in RDF.  There are two classes, “process” and “sample”.  “process” may be hierarchically connected to sub- and super processes.  The external ontology allows to connect “sample” with every ”process”, but we like to restrict the connection only to processes that represent a concrete run of an experimental setup.  Can we still take the external class URIs and refine their use in our specification?
","['rdf', 'ontology', 'semantic-web']","This is what rdfs:subClassOf/rdfs:subPropertyOf is for. So yes, recreate these classes in your own namespace, narrowing the meaning.If you can express the restriction in terms of an owl:equivalentClass on an owl:Restriction the inference engine will find those classes in terms of the external ontology that also fit your (narrower) meaning.  You'd still need to use your namespace to describe your idea of the classes.Using just rdf-schema you'd probably want an alignment dataset where you mention those individuals (instances of external classes, what you call external entities) that fulfil your narrower definition."
Identifying parameters accepted by API request,"
I'm playing around with the data.gov API and was trying to reconstruct a API request from the websearch.
ex: COVID-19 datasets filtered by Texas
my url looks like
https://catalog.data.gov/dataset?q=COVID-19++&sort=views_recent+desc&as_sfid=AAAAAAVj354uPLWh4A-rtCGREQUj1meuoN7meraqiIpM0fYfGGWoEaGfEPqUjArih-22d-oaV26Dhfu_Id9XjdmN1nx2RQRL_KrLPw3K57Fv7P5zT9Z0HR3-ShUHdp8UvZdqXuM%3D&as_fid=8563fb05fbeea54c88ab1649dfdc5c5933f46436&ext_location=Texas&ext_bbox=-106.6501%2C25.8456%2C-93.5074%2C36.4939&ext_prev_extent=-110.390625%2C22.43134015636061%2C-89.82421875%2C37.579412513438385

and yields 36 results
But when I use just the q and ext_location parameters in the following request get a much higher result.
https://catalog.data.gov/api/3/action/package_search?q=COVID-19&ext_location=Texas

I understand that ext_bbox and ext_prev_extent are related to the spatial search and adding them to my requests gives me my expected results.
My question is how do I find the parameters that are accepted in package_search API ?
(The CKAN documentation does not go into details here)
TLDR; How does one identify parameters that are accepted in an API request
","['api', 'scraping']",
Data for generating a world map,"
I have an idea for an alternative world-map projection. Is there a (simple) public data-source which indicates for each longitude/latitude-location whether it is land or sea I could use for this purpose? As an added bonus longitude/latitude of state-borders would be nice.
",['geospatial'],
"Is passing an ""&"" as a string character possible using the openFDA API? If no, is there a way to access data with manufacturer name containing ""&""?","
I am using the openFDA NDC API. Searching and counting using the ""manufacture_name.exact"" field results in a status 400 bad request when passing the character ""&"" as part of the manufacturer name.
I am using the fetch API and JavaScript. The code is provided below; where ""${manufacturer}"" may be exactly:  ""The Procter & Gamble Manufacturing Company""
const manufacturerResponse = await fetch(`${this.ndcBaseEndpoint}?${this.apiKey}&search=openfda.manufacturer_name.exact:${manufacturer}&limit=10`)

I have reviewed this question  where an answer by Nag lists the supported characters and & is not on that list.
I have tried using %26 as a replacement without success.
Is there a method to search with & inside the manufacturer name? If not, is there a reliable way to access the data which has ""&"" in the manufacturer's name?
",['openfda'],This is now fixed:https://api.fda.gov/drug/label.json?search=openfda.manufacturer_name.exact:%22The%20Procter%20%26%20Gamble%20Manufacturing%20Company%22Sorry about the inconvenience.
"Variables ""dolprovider"" and ""admcon7""","
Hello CollegeScorecard folks, I'm doing some work on updating my college scorecard data file. I'm seeing a couple variables in the documentation (dolprovider and admcon7). But, I'm not finding the variables in the data files.
I see dolprovider documented in the Institution_Data_Dictionary tab (and other tabs) of CollegeScorecardDataDictionary.xlsx file. For example see lines 2650 & 2651 of the Institution_Data_Dictionary tab.
I also see admcon7 documented in the same way over there in then CollegeScorecardDataDictionary.xlsx file. For examples see lines 2652 and 2656 of the Institution_Data_Dictionary tab.
It looks like these variables came along with the Aug 2021 update. I'm seeing references to these new variables in the change log under Aug 2021. Could the documentation have been updated (but somehow the data files not updated)?
I think think I've thoroughly searched the data files for these variables. But, I'm not finding them in the data files. Has anyone else noticed this? Any thoughts on what I might be missing?
",['collegescorecard'],
patient and credit card dataset,"
I am trying to do some experiments with data science algorithms and looking for some sample datasets.
For example, I am looking for a sample patient dataset. For example, a dataset that each row is a patient (without identifiable information) and each column is a feature of that patient. For example a dataset with information about patients who checked for cancer and the result of the test.
I also like to have information about credit card applications. Each row is a person who applied for a credit card and information on the application result.
Where can I find this type of sample information?
","['data-request', 'medical', 'bank']",
Which API to use to find the information based on NDC code?,"
I found out that there are two ways to find drug information based on NDC code but I am not quite sure which one to choose.
Here is an example
NDC API - https://api.fda.gov/drug/ndc.json?search=product_ndc:73408-709
Drug label API - https://api.fda.gov/drug/label.json?search=openfda.product_ndc:%220573-0134%22
","['openfda', 'drugs']","Using the NDC endpoint would be a logical choice. And you can supplement that by calling Drug Label, too, in case you need additional fields otherwise not provided by NDC (e.g. details from the drug's label)."
Search via NDC api and brand name outputs different results,"
I was trying to search information about Advil so I tried two ways
Search by drug name:
https://api.fda.gov/drug/event.json?search=patient.drug.openfda.brand_name:advil
Search by ndc code: https://api.fda.gov/drug/ndc.json?search=product_ndc:0573-0134
In second link output I could get lot of information about the drug where as first link doesn't provide much information about the drug.
Example fields found in second link but missing in first link
dosage_form
active_ingredients
many more fields
Is it expected to work like that? If so, would you help out me with your reasoning.
","['openfda', 'drugs']",
Find random 10 people Wikidata,"
Using Sparql I can find person on Wikdata by his name:
SELECT distinct (SAMPLE(?image)as ?image) ?item ?itemLabel ?itemDescription
                (SAMPLE(?DR) as ?DR)(SAMPLE(?RIP) as ?RIP)(SAMPLE(?article) as ?article)
                WHERE {?item wdt:P31 wd:Q5. ?item ?label 'Putin' @en. OPTIONAL{?item wdt:P569 ?DR .}
                ?article schema:about ?item . ?article schema:inLanguage 'en'. ?article schema:isPartOf <https://en.wikipedia.org/>.
                OPTIONAL{?item wdt:P570 ?RIP .}
                OPTIONAL{?item wdt:P18 ?image .}
                SERVICE wikibase:label { bd:serviceParam wikibase:language 'en'. }}
                GROUP BY ?item ?itemLabel ?itemDescription

See this on Wikidat Query Service
Or if you know his ID:
SELECT distinct (SAMPLE(?image)as ?image)  ?item ?itemLabel ?itemDescription
            (SAMPLE(?DR) as ?DR)(SAMPLE(?RIP) as ?RIP)(SAMPLE(?article) as ?article)
            WHERE{ ?article  schema:about ?item ; schema:inLanguage  'en' ; schema:isPartOf    <https://en.wikipedia.org/>
            FILTER ( ?item = <http://www.wikidata.org/entity/Q303> )
            OPTIONAL { ?item  wdt:P569  ?DR }
            OPTIONAL { ?item  wdt:P570  ?RIP }
            OPTIONAL { ?item  wdt:P18  ?image }
            SERVICE wikibase:label { bd:serviceParam wikibase:language  'en'}}
            GROUP BY ?item ?itemLabel ?itemDescription

This query on Wikidata
But can't figure out how to get several random persons. If I remove search criteria and add limit 10, I get timeout, probably because it query all people even I just want 5 or 10.
Any idea how I can get 10 random people?
","['wikidata', 'sparql']",Below code gives different 10s of people in different runs (Random) but it gives new results only when running incognito or private tab (May be because of caching)
Is it possible to have 2 drugs with same NDA number,"
I am facing a very peculiar issue with the USFDA database. There is one NDA number 050790 corresponding to 2 different drug names viz. Restasis and Restasis multidose! Both the drugs have different patents.
If I were to download these data from the API, my database will get confused as to which patents are applicable to which drugs. Also when generics of these drugs will come, how will we know which one is the RLD for the approved generic (assuming approval letters are not uploaded).
","['api', 'openfda']",
Average Mean Sea Level per FIPS Code,"
I am trying to find the AMSL (average mean sea level) of a bunch of different counties based on their FIPS code. I am hoping there might be a table out there that contains the AMSL that I might be able to join my table to. I have already found the USGS site where I can plug in lat and longs (https://www.usgs.gov/faqs/how-do-i-find-average-elevation-county) but that only gives elevation of that particular spot, I am hoping to find the average value instead of a singular spot.
","['geospatial', 'county', 'usgs']",
Dataset for Swiss (.ch) domain names with basic traffic stats,"
Where can I find Swiss website domains with .ch and with some basic stats about popularity?
","['data-request', 'internet', 'switzerland']","switch.ch publishes some stats about the top 1000 domains with .chhttps://www.switch.ch/open-data/direct link to ""latest"" CSV file: https://www.switch.ch/open-data/top1000/latest.csv"
how I can read the content of the dataset in pkl file and return 67 sparse matrix of type '<class 'numpy.int64'>'in python?,"
I have a dataset in pkl file, and I write the following code to unpkl the file and read the data
import pickle
f=open(""data_cdg.pkl"",""rb"")
a = pickle.load(f)
f.close()
print(a)

but I got in the output 67 sparse matrix of type '<class 'numpy.int64'>' so how I can read the content of the dataset in python?
","['machine-learning', 'python', 'large-datasets', 'deep-learning']",
Dataset for human-level artificial intelligence,"
I think a human-centric multi-modal dataset (i.e.: head mounted binocular cameras, steroes mics, text transciption, skeletal pose, skin area contact) would be a great starting point for building human-level artificial intelligence. Do you know if such a dataset exists or if there are open data efforts to build one. (It'd be terrible if Tesla or another private company were the first to become an AI superpower in this domain. It's unlikely they'd release any data)
","['data-request', 'language', 'text', 'video']",
Is there a database that provides chapter lengths of books?,"
I'm trying to test an idea regarding the chapter lengths of various books. I was wondering if there's a database I can query for this information? This similar to this question, though I would like to have more granular data than the average chapter length of a book.
","['api', 'database', 'books']",
Shapefile for Petrol Fueling stations across Europe,"
I'm looking for petrol stations across Europe either in a shapefile format, coordinate data as .csv or addresses from a webpage which I can scrape.
I have had a look and couldn't find anything that covers all of europe
","['geospatial', 'europe', 'csv', 'scraping']",
I am looking for temporal EHR dataset,"
I am looking for temporal EHR dataset for my project work. I know some hospital website allows to download the dataset. But it requires permission and the dataset huge which will be difficult to manage. I am looking medium simple temporal EHR dataset. Could you give me link of the website.
","['data-request', 'medical']",
Seeking hard water data source,"
I'm in need of finding a data source that I can use to create a heat map showing varying water hardness in the U.S.
I've tried the usual, i.e. usgs, epa, and I'm not able to find what I need.
I'd like to make something similar to this (I can't find the original creator so I have to make my own

","['data-request', 'usa']",
Seeking global data for georeferenced CO2 emissions of industrial sites,"
I am looking for georeferenced CO2 emissions of sites of energy-intensive industry sectors on a global scale. Besides the EU-ETS and the E-PRTR, I found the Hotmaps projects covering EU28, but no project covering the global scale.
Does anyone know of such a project?
If such a comprehensive overview of energy-intensive industry sectors on a global scale is not available, I would also be interested in open-source sectoral databases covering the global scale.
During my research I came across the following data sources:

GIDmodel database covering the cement, iron and steel industry
RISI Pulp and Paper database covering the pulp and paper industry, which is not available for free
GlassGlobal database covering the glass industry, which is not available for free

","['data-request', 'global', 'industry']",
Kinneret water levels,"
I am looking for daily data for the water level of Kinneret over the years (ideally 20+ years).
Is there such thing?
","['historical', 'hydrology']",
Where can I find all United States' railroad & subway station list and its passenger usage of each station?,"
I have been searching for a list of all (or atleast a significant list of say top 1000 of) United States' railroad & subway station with its passenger usage of each station. Where can I find such information. Is there a single open source dataset that contains the information that I need or do I need to combine information from multiple sources? Any guidance on where and how to put together such data will be very helpful?
","['usa', 'traffic']",
frequency of data updates in source system,"
Is the source database for OpenFDA APIs updated on real time with the updates released by FDA?
If not, what is the ideal update frequency, particularly for medical devices recalls and classification.
",['openfda'],
"Extemporaneous speech, as text, tagged by speaker?","
tl;dr; I'm looking for a corpus (or multiple of them) of un-scripted English speech, transcribed to text and tagged by who said what. Ideally, I'd like hundreds or even thousands of distinct speakers.
I've found a few possibilities, but they have issues. Also, I don't have much of a data science background (I'm a dev tools programmer by trade) so I frankly have no idea where to even start looking beyond the blindingly obvious search terms, and those haven't returned anything very inviting.

I'm working on a literary project where I want to create dialog with recognizably distinct ""voices"". I don't want everyone's speech to sound like they are quoting me, but rather seem like actual different people. I've a few different ideas of how to approach this, but all of them require training data with rather specific properties.

I need text, not audio.
I need data source from speech, not written materiel and I'd strongly prefer non-scripted speech. (I know that for some people, myself included, the way they speak and write can be very different from each other).
I need data tagged by who came up with the words. (The same person giving speeches from different speech writes, or a screenplay where everyone's dialog is written by one person would be undesirable.)
I want a diverse set of speakers. (A data set where everyone in it works in the same industry or is talking about the same subject could be problematic.)

On the flip side, my ""openness"" constraints are rather lax; I'm not going to pay for data is about the only hard constraint. I'd like to be able to redistribute the source data, but as long as I can make the cooked data available to a private group I'm fine with most restrictions.

Most of the natural langue data sets I've found fail hard at the second point: most text data set seem to be from written work like questions on this site or reviews/comments on other web pages. Also the third point is problematic, data sets with speaker tagging don't necessarily tag it ""correctly"" for my needs.
Off hand the only source I've come up with that would already exist would be court transcripts. However it looks like they are often far from free and/or open, thought some some are free to download, but maybe not in the easiest format. Also, I suspect that such transcripts will have significant over representations of legal professionals and legal topics, likely more so at the higher court level which are the ones likely to be easiest to obtain.
","['data-request', 'language', 'english']",
Does anybody know where to find very detailed NBA player salary data?,"
I'm looking for a very specific kind of dataset or a website that documents this data. I need data for NBA players' salaries ideally going back 30 years. I've found some sites that have the data, but they don't go into enough detail. I would like the data to include a marker that says when a new contract is signed and a number specifying how much of the contract is guaranteed.
",['data-request'],
Are there domain standards for open data?,"
When talking about open data the 5-star principle has paved our way. And although the highest level, linked data, is machine readable, it is not application friendly from a reusability perspective. By ""reusable applications"" I mean applications (mobile apps, server apps, web-apps, etc) that work on multiple data sources from different data publishers without configuration changes.
For example, an application to visualize results of local elections would be far more reusable if there were a data format for election results.
I am looking for data standards for open data that applications can use to operate on multiple data sources. I could not find any standards directories nor standardizing bodies that drive this process.
This could be a killer feature for the open data movement since, on one hand, application developers could rely on a single format description, and on the other hand data publishers get applications for published data faster and cheaper.
Do we already have such ""domain"" standards for open data formats? Am I missing something?
","['data-format', 'standards', '5-star-scheme']",
Does Life Expectancy at a certain year refer to lifespan of people born that year or average lifespan of all people living that year?,"
For example, life expectancy in Russia in 1945 was 23.6 years.
► Does this mean that ANYONE alive in 1945 was expected to die at around 24 years of age (on average)?
► Or does this mean that people born in 1945 were expected to live only 24 years (on average)?
Follow-up question: Is there a name for or a way to find data for the OTHER definition?
",['demographics'],
Open place names and geographic coordinates?,"
Is geonames the best data source for finding geographic place names for every place on earth? Or is there any open data that comes closer to the level of Google or Apple maps? Just looking for place names, with potentially geographic coordinates, nothing too fancy.
","['geospatial', 'location']",
WikiData: filter mwapi results,"
I am trying to write a sparql query that can retrieve all categories/items from a root and filter down only the ones that are of ""human"" type.
Using the query below, I can retrieve all categories & items for the category ""Obama"", but for some reason the filter isnt kicking in to narrow down the results from the service. In both my filter attempts the query timesout, but there shouldnt be that many items in the first place.
SELECT 
*
WHERE {
  # get all categories
  wd:Q76 wdt:P910 ?category .  
  ?link schema:about ?category; schema:isPartOf <https://en.wikipedia.org/>; schema:name ?title .
  SERVICE wikibase:mwapi {
     bd:serviceParam wikibase:endpoint ""en.wikipedia.org"";
                     wikibase:api ""Generator"";
                     mwapi:generator ""categorymembers"";
                     mwapi:gcmtitle ?title;
                     mwapi:gcmprop ""ids|title|type"";
                     mwapi:gcmlimit ""max"".
     ?member wikibase:apiOutput mwapi:title.
     ?ns wikibase:apiOutput ""@ns"".
     ?item wikibase:apiOutputItem mwapi:item.
  }
  
  #filter results

  #attemp1: this times out
  #?item (wdt:P31) ?type
  #filter exists {?type wdt:P31 wd:Q5}
  
  #attemp2: this times out
  #?item wdt:P31 wd:Q5 
}

","['wikidata', 'sparql']",
Cant Search By NDC String,"
Hello I know this may be a dumb question but I would like to search for a drug by the NDC like this https://api.fda.gov/drug/ndc.json?search=product_ndc:""54868-4517""&limit=100 but I get a
{
error: {
code: ""NOT_FOUND"",
message: ""No matches found!""
  }
}

as the result. Would love any suggestions with this thank you.
","['api', 'openfda']",
FDA Cosmetics Data,"
I see that open.fda.gov has data for drugs, food, etc, but I can't find anything about cosmetics (makeup, shampoo etc) recalls. Any ideas?
","['data-request', 'openfda']","Unfortunately, openFDA does not provide any datasets related to cosmetics."
looking for support ticket data set with tickets and answers,"
Im searching for a dataset which contains support tickets and the corresponding answers
I did found various datasets with support ticket questions like
this  support ticket dataset but the answers are missing
",['data-request'],
Connecting FDA API to SAP Data Warehouse Cloud,"
I am trying to connect the Adverse Events API to SAP's Data Warehouse Cloud. I do not know what to enter in the fields, can I please get some advice?
FDA Base URL: https://api.fda.gov/device/event.json

What type of pagination? Offset or Cursor?
Authentication Type = Basic? Custom?



Must I add any configurations or parameters? I would like to see all of the Device Adverse Events and load them into SAP Data Warehouse Cloud.



Any help is appreciated, I do not know where to start consuming this data!
",['openfda'],
US Trademark Data,"
Anyone have any experience working with US trademark  data? Bulk data is easy to retrieve, but it's challenging to work with. The assignments are small but need to be joined with other data to be interesting. And then the applications data sets are rather large (for my purposes) and the volume is quite high. I wasn't sure if there was an API that was a bit simpler to work with and thought someone here might have some experience.
","['data-request', 'parsing', 'xml']",
Store-specific barcodes?,"
Currently we have a solution that uses both EAN and GS1 barcodes, but there is a need for a small business to have barcodes for local products or other products that don't have barcodes. These barcodes would only have meaning within the store.
Does EAN provide any provision for these sort of products or should we be using a different barcode type for this? Any advice would be helpful. Whatever we use should be supported by barcode scanners and not clash with external EAN or GS1 barcodes.
",['barcodes'],"In GS1 Parlance, this is called Restricted Circulation Numbers in section 1.4.1.2 of the specification.Restricted Circulation Numbers are used for special applications in restricted environments. They are allocated by GS1 for internal use:The RCN-8 are 8 digit barcodes with prefix 0 or 2. Many barcode scanner systems and applications have trouble reading these properly. Especially if you attempt to use UPC-E barcodes in the same location.The RCN-12 have 12 digit barcodes with prefix 04 is for use inside a company and 02 is for use inside a company within a geographic region.Finally with the RCN-13 you have 13 digit barcodes with prefix 04 and 02 identical to the RCN-12 designations.Keep in mind you have the prefix, some number of digits, and the checksum. How you arrange the digits in the middle are left up the the site using the restricted circulation number."
Device recalls - difference between date entry was created in openFDA database and date manufacturer informed about recall,"
I am using the recalls database to always be aware of the recalls for some specific vendors and products.
This is the call I am doing: https://api.fda.gov/device/recall.json?search=recalling_firm:(""Medtronic Inc., Cardiac Rhythm And Heart Failure (CRHF)""+OR+""Boston Scientific""+OR+""Biotronik""+OR+""St Jude Medical""+OR+""Abbott"")+AND+product_code:(""DSZ""+OR+""DTB""+OR+""DTD""+OR+""DTE""+OR+""DXY""+OR+""MXC""+OR+
""MXD""+OR+""PNJ""+OR+""LWP""+OR+""LWS""+OR+""LWW""+OR+""MRM""+OR+""NIK""+OR+""NKE""+OR+""NVY""+OR+""NVZ""+OR+""PCW""+OR+""QFV"")&limit=1000
However, I realized for most of the recalls the event_date_initiated (Date that the firm first began notifying the public or their consignees of the recall) is 1 month earlier than the event_date_created (Date on which the recall record was created in the FDA database). Could you exolain this difference?
I see the database is updated frequently (according to what you have in https://open.fda.gov/about/status/) and I am affraid I cannot use it because of this delay.
Thank you.
",['openfda'],
ISBN market history?,"
Is there a database to get the sales / market history from various vendors of a book specified by its ISBN? I think ISBNDB.com has this ability, but it's not free/open.
","['historical', 'books']",
Shapefile of Portugal 4 digit Postal codes,"
I'm looking for shapefiles that contain Portugal 4 digits postal codes polygons
Are there any open-source or public resources where I can obtain these files?
","['geospatial', 'postal-code', 'portugal']",
vaccine or roof over your head which is more important,"
when will people in Pensacola Florida receive landlord assistance the application sure is discouraging
",['data.gov'],
Open data that changes daily for every county in the United States,"
Is there any open data that changes daily for every county in the United States? I'm working on a project that involves finding patterns in data across counties. I've had a difficult time finding daily weather data. Is there crime data available every day in every county? Any government data? Financial?
","['usa', 'data.gov', 'crime', 'county']",
Seeking toutable file of German Road System,"
I am looking for a routable file of the German Road System in order to perform route calculation in QGIS, ArcGIS Desktop or even R Studio.
Can someone help me out?
","['data-request', 'geospatial', 'transportation', 'germany']",
Seeking Geodata on German Roads,"
I am looking for a free datasource (or a possibility to extract that data from OpenStreetMap) on Germany`s roads. I need this data for the purpose of routing/ calculating the travel distance between several points. The programs available to me are QGIS, ArcGIS and R Studio. Unfortunately, I do not know python language, thus the geodata should be readable in one of those programs for the purpose of my calculations.
","['geospatial', 'transportation', 'germany']",
Data set with time-series data for visualization exercise,"
I am trying to find a data set for data visualization purposes. This can be a data set which has only three months of data in it, or a subset of a larger data set. What reputable data sets can you reccomend to me? I tried to search in Kaggle.com , and data.gov.uk but I have not found a dataset which contains a date field. Thank you in advance!
","['data-request', 'large-datasets', 'visualization']",
The difference between exact with suffix and without suffix,"
Can you explain the difference between searching on OpenFDA with the .exact suffix, and without the suffix?  I'm a little confused
",['openfda'],
how to modify time range in interactive chat?,"
Deadlines are always up to date in interactive chat ,for example:i want to query time range between 2015/01/01-2020/01/01.how to modify?
",['openfda'],
Sources of yearly electricity consumption data for India?,"
I am looking for yearly or monthly electricity consumption data for India for the period 2013-2020. Is there any website that provides these kind of data? The data set should be at the District level at least (748 districts in total).
","['data-request', 'geospatial', 'energy', 'india', 'open-source']",
getting notified when someone's address changes?,"
Last time I moved some of the companies I do business with (maybe credit unions, companies that I had loans with, etc) seemed to be aware that my address had changed and updated it in their DB accordingly. My question is...  how did they learn that my address has changed? Is there some sort of notification service that USPS provides?
","['usa', 'address']",It's done by change of address. Many companies offer this. Here is the link for the USA.https://postalpro.usps.com/mailing-and-shipping-services/NCOALink
GIS Data on US College Dormitories,"
I am trying to find spatial data on all (or as many as possible) US college dormitories. Specifically, I want to find the location as a polygon or centroid. I have tried a few methods to acquire this data, including using the serpapi Python scraping package. I tried using the following but it seems it is returning an incomplete dataset (I tried Raleigh, NC to test, which probably has a couple dozen dorms and it only returned 3-4).
 from serpapi import GoogleSearch
 search2 = GoogleSearch({""q"": ""dormitory"", ""location"": ""Raleigh, North Carolina"", ""api_key"": <my_api_secret_key>})
 result2 = search2.get_dict()

If you print the results, it returns a json object with a key called ""local_results"" that has the data I need but, like I said, it was incomplete and only returned a few dorms. Is anyone familiar with this API package or know of another source where I might find this data?
","['geospatial', 'python', 'large-datasets', 'scraping']",
FDA Api Issue with Brackets,"
When I'm making what seems like a working query:
https://api.fda.gov/food/enforcement.json?api_key=123&search=report_date:[2021111+TO+20211112]

I get an error:

[token_mgr_error] token_mgr_error: Lexical error at line 1, column
32. Encountered: ""]"" (93), after :

That same query works fine when done in browser but it's failing in my API tool. Any ideas?
Secondly, Is there another way to do a relative date or date range in the API if brackets simply can't work for me?
","['api', 'openfda']",
Average property price per country?,"
Where can I find the average price of properties in each country? I know prices vary from city to city but I was hoping there was something for each country much like for the UK (link)
","['real-estate', 'prices']",
Seeking polygon data for upper tier local authorities in England,"
I'm trying to draw an interactive map showing boundaries for upper tier local authorities in England, but can't find the polygon data I need.
Can anyone help?
","['data-request', 'geospatial', 'uk']",
Why are the results of two search statements inconsistent?,"
https://api.fda.gov/drug/event.json?search=(receivedate:[20040108+TO+20210401])+AND+patient.drug.medicinalproduct:%22IBUPROFEN%22&count=patient.reaction.reactionmeddrapt.exact

Using the above search request, I get values as (full response)

""term"": ""PAIN"", ""count"": 9080

.
https://api.fda.gov/drug/event.json?search=(receivedate:[20040108+TO+20210401])+AND+patient.drug.medicinalproduct.exact:%22IBUPROFEN%22+AND+patient.reaction.reactionmeddrapt.exact:%22PAIN%22

Using the above search request, I get (full response)

""total"": 2914

How does the above two search requests differentiate so that the result are different?
",['openfda'],
How to sort in an API call for College ScoreCard,"
I'm trying to sort an API query by size of students, but I can't figure out how to get the API to accept the &sort parameter. Can someone provide me an example? I'm referring to the documentation here but it isn't very clear (to me, a noob at API's). I've already tried the following:
let collegeDataAPIoptions = {
    url: 'https://api.data.gov/ed/collegescorecard/v1/schools.json' +
        '?school.' +
        'operating=0,1' +
        '&_fields=' +
        'id,' +
        'school.name,' +
        '2019.student.size,' +
        '2019.academics.program_percentage.education' +
        '&sort=2019.student.size' +
        '&api_key=[redacted]'
}

This is the error I'm getting:
StatusCodeError: 400 - ""{\""error\"":{\""error\"":\""unknown_column\"",\""message\"":\""Only select columns are available for filtering. 
Please see the data documentation column \\\""INDEX\\\"" to find out which ones are allowed.\"",\""input\"":\""Unknown column '2019_student_size' in 'order clause'\""}}""

","['api', 'collegescorecard']",
R or Excel: Calculate difference between dates,"
I have a list of course completion dates (person, start, end) in the following format (exemplary):
Person X || Sept 21, 2021 06:30 PM || Sept 21, 2021 06:50 PM
Now I'd like to calculate the overall spent time in minutes from the difference between end and start date. However, I struggle with formatting the start and end date in a way that allows such difference calculations. Excel does not seem to provide a date format that suits the given table record. Manual formatting would take ages since the table is pretty long.
Any help would be highly appreciated!
Many thanks in advance
","['programming', 'excel']",
Retrieving first-recorded ejection fraction value,"
I want to retrieve the the first recorded ejection fraction (EF) of patients. From my attempts, the codes 2697, 2699, 226272, and 227008 represent ejection fractions:
SELECT itemid, label, abbreviation, linksto, category, unitname
FROM d_items
WHERE itemid IN ('2697', '2699', '226272', '227008');

...which gives:
 itemid |       label       |   abbreviation    |   linksto   |        category        | unitname
--------+-------------------+-------------------+-------------+------------------------+----------
   2697 | EF %              |                   | chartevents |                        |
   2699 | EF                |                   | chartevents |                        |
 226272 | EF (CCO)          | EF (CCO)          | chartevents | Hemodynamics           | %
 227008 | Ejection Fraction | Ejection Fraction | chartevents | Scores - APACHE IV (2) | %

To extract the values of EF, I use:
SELECT subject_id, hadm_id, icustay_id, itemid, charttime, value, valuenum
FROM
(
    SELECT * 
    , RANK() OVER (PARTITION BY chartevents.subject_id ORDER BY chartevents.charttime) as charttime_id_order
    FROM chartevents
    WHERE itemid IN ('2697', '2699', '226272', '227008')
) AS tbl_ef
WHERE charttime_id_order=1

...which returns the following:
 subject_id | hadm_id | icustay_id | itemid |      charttime      | value | valuenum
------------+---------+------------+--------+---------------------+-------+----------
        711 |  158767 |     270525 | 227008 | 2185-03-23 14:45:00 | 45    |       45
       1581 |  113063 |     217900 |   2699 | 2171-11-13 00:30:00 | 32    |       32
       2638 |  135772 |     264212 |   2699 | 2138-10-02 04:30:00 | 40    |       40
       9767 |  195886 |     277000 |   2699 | 2154-11-13 20:30:00 | 35    |       35
      14135 |  196667 |     238064 |   2699 | 2136-09-15 21:00:00 | 16    |       16
      14588 |  177135 |     270609 |   2699 | 2187-12-03 08:00:00 | 44    |       44
      15145 |  142200 |     248846 |   2697 | 2162-09-18 01:00:00 | 31    |       31
      16630 |  136282 |     264249 |   2699 | 2108-01-22 12:00:00 | 26    |       26
      28426 |  153325 |     245963 | 227008 | 2124-01-10 14:32:00 | 0     |        0
      40094 |  193368 |     210633 | 226272 | 2147-11-23 17:30:00 | 46    |       46
      43961 |  150566 |     247783 | 226272 | 2120-07-02 20:22:00 | 42    |       42
      52532 |  124500 |     255738 | 226272 | 2195-02-05 19:53:00 | 31    |       31
      54187 |  116451 |     246413 | 226272 | 2112-04-29 20:48:00 | 58    |       58
      63961 |  160874 |     284945 | 226272 | 2140-08-11 20:28:00 | 54    |       54
      71243 |  124711 |     243996 | 226272 | 2140-06-04 07:47:00 | 35    |       35
      78419 |  126041 |     203258 | 226272 | 2179-06-07 03:36:00 | 39    |       39
      81087 |  106452 |     228342 | 226272 | 2155-05-21 07:43:00 | 20    |       20
      86155 |  145282 |     296472 | 226272 | 2190-10-28 09:00:00 | 38    |       38
      89356 |  159967 |     256091 | 226272 | 2104-12-02 09:00:00 | 35    |       35
      96218 |  122615 |     275009 | 226272 | 2187-10-14 14:00:00 | 36    |       36
      97539 |  178571 |     215558 | 226272 | 2139-11-08 18:06:00 | 36    |       36
(21 rows)

The result set is ridiculously small. Am I doing something wrong or are EF values stored somewhere else as well?
",['mimic-iii'],"Ejection fraction values are contained within the echodiagram notes. To get the text of the echodiagram notes, use the following:The charttime values for most records is blank, so you will have to get the values from the echodiagram text itself. Use the following:Now that we have the text of the echodiagram notes and when they were taken, we can rank the charttime values to determine the first echodiagram note:The above may not be the most optimal query but it gets the job done. After this step, you will have to use Regex to get the actual values (or value ranges) for the ejection fractions.Please see the R ejection fraction extraction function by vincentmajor on GitHub."
How can I list FDA approved drugs in a year?,"
I am trying to list all of the approved drugs in a particular year, (e.g. https://www.fda.gov/drugs/new-drugs-fda-cders-new-molecular-entities-and-new-therapeutic-biological-products/novel-drug-approvals-2021), but when I try going through the searchable fields I am not able to find anything relevant. How might I do this?
",['openfda'],
Payroll taxes per state in the United States,"
I am looking for a dataset containing which state payroll taxes individuals residing in the United States must pay, broken down per state.  E.g., Washington tax residents must pay a 0.58% long-term care insurance payroll tax (unless they have managed to opt out of it).
Some state payroll taxes are employer contributions (e.g., Unemployment Insurance (UI) and Employment Training Tax (ETT)  in California) while some others are withheld from employees’ wages (e.g., State Disability Insurance (SDI) and Personal Income Tax (PIT) in California). I'm only interested in state payroll taxes withheld from employees’ wages.
E.g. the dataset could be something like (the number for CA is made up):




US State
Payroll tax rate withheld from employees’ wages.
Tax name(s)




California
3%
State Disability Insurance (SDI) and Personal Income Tax (PIT) in California


Texas
0%



Washington
0.58%
long-term care insurance tax


[...]
[...]





https://gusto.com/tools/employer-tax-calculator (mirror) only contains state payroll taxes that are employer contributions, whereas I want state payroll taxes withheld from employees’ wages:

","['data-request', 'usa', 'finance', 'taxes']",
How to obtain ROR and PRR of an adverse drug event using openFDA,"
I am writing a paper on adverse reaction mining, and I need to calculate ROR and PRR values of all adverse reactions of a drug. May I ask how to use openFDA to build query statements?
",['openfda'],
Sports data set. Olympics. High jump,"
I am seeking, but have been unable to find, detailed information about the women's high jump at the 2020 Tokyo Olympics (which was of course held in 2021). I particularly want data about the sequence in which the athletes jumped (but not necessarily time-stamped) including whether an athlete chose not to try a particular height, as well information about as success or failure. I had hoped that the Olympics site itself would have the information but I was surprised to find that it does not. In the absence of anything else, I would be willing to watch the entirety of the replays but I have been unable to find the videos for the qualifying events.
","['data-request', 'sports']",
Russian Dictionary that contains stress marks,"
I am looking to automate the process of setting the stress of Russian words. There are already tools that do this (RussianGram or https://morpher.ru/accentizer/), but nothing open source which can be executed offline as far as I know.
So what I am looking for is a dataset that contains Russian words with their stresses and correct forms of е or ё. I have had some success so far by using the dataset provided by https://kaikki.org/, which contains Russian words (and English translations) and many of their inflections. The only problem is that right now it does not support the short form of many verbs (like завершён). It is possible that the creator will parse the sites more so that the short form of verbs will be included in the dataset as well. (That was his plan I think). Edit: Now all this information is available, making this maybe the best resource.
Another option would be to attempt to use the https://github.com/tatuylonen/wiktextract project, which right now only works for the English Wiktionary, on the Russian Wiktionary or to try to parse the Russian Wiktionary dumps, but both options would probably be a lot of work.
I also found one project which attempted to parse the Russian Wiktionary: http://whinger.krc.karelia.ru/soft/wikokit/index.html
Unfortunately the database dump contains the files misencoded in some form, which is not trivial to fix (at least for me).
Does anyone have any other ideas?
","['data-request', 'language', 'dictionary', 'russia']",
A comprehensive list of words in Chinese?,"
I'm trying to find a Chinese (and also French) word list, similar to this one for English: https://www.mit.edu/~ecprice/wordlist.10000
All I'm finding are 100-500 word lists. Anyone know a comprehensive list?
",['data-request'],"The MDBG dictonary has a downloadable text file in csv format containing 200,000+ Chinese words in alphabetical order. There is also a (smaller) version with French word definitions of Chinese words."
Dataset with French words by CEFR level,"
As a German speaker learning French, I really enjoyed the ""Fremdsprachentexte Reclam"" books: they are French literature books for German learners, each book has a CEFR level (e.g. B2, C1...), and the words that are deemed complicated to that CEFR level have translations/explanations in the footnote. B2 example here.
I find this an amazing reading experience for language learners.
I'm wanting to create an app for this. I would like to see if there's an open database of French words mapped to their CEFR level. I found answers for English and Swedish, and I'm sure there' something for French.
Thanks.
","['language', 'french']",
Reading Current FAA ADs via API,"
Is anyone aware of a way to query/download Airworthiness Directives? I don't want to resort to HTML scraping, but I can't seem to find any alternatives.
I wouldn't be opposed to downloading whole chunks of the data and parsing it locally, but I don't even see a great way to do that.
Any help would be appreciated!
Daniel
","['data-request', 'api', 'aviation']",
Seeking carbon geospatial data,"
Is there a easy way to access and query carbon data such as the data that comes from OCO-2 satellite?
I’m trying to find a easy way of quantifying the carbon emissions within a certain area.
Ideally I enter an address or coordinates and I get the data. Does something like this exist?
","['data-request', 'geospatial', 'geocoding', 'environment']",
"Filtering pma dataset for only new PMA decisions (that is, no supplmements)","
All - admittedly, a beginner question.  I'm looking at the most recent pma json dataset from OpenFDA to understand trends in new applications over time and by geographic location.  My first look at the data suggests that everything I can find in the data set is a supplement, rather than a first approval.  What values in which fields indicate that an entry represents a newly approved device?
",['openfda'],
download static/snapshot satellite data of the USA,"
I'm looking to download satellite data with resolution good enough to see objects that are 10 meters in size (eg tiles that are 20m x 20m).  I do not care about changes over time.  I'm basically just looking at rocks and static/snapshot (one point in time) data is fine.  I don't care if the data is 20 years old or new today.
I really want to be able to download all of the data, ideally as a bunch of files/images containing zoomed in views, instead of accessing bits of data via an API.
I primarily care about the USA but would be fine with data from the whole world.  I'm not intending on using these data for financial gain, nor will I share with the public, so okay with data that has limitations around that type of usage.
Thank you so much for any tips!
","['geospatial', 'map']",
Office equipment consumption 2000-2021,"
Where can I read a graph that describes the worldly prevalence of office equipment consumption?
These data might help me assume ""how much"" have offices become digital and even ""remote"", in practice.
I didn't find any such information in Google Images.
",['industry'],
"Looking for ""minimum viable English utterances"" to provide sufficient phoneme coverage for TTS training","
There are quite a lot of really, really large utterance/phoneme datasets out there, but I can't seem to find anything small. I'm looking for the minimum viable set of utterances/sentences in English that would provide sufficient coverage of phonemes so that, if you fed them all into a training algorithm, you could get a half-decent model. I don't actually want any audio data, because I'm going to generate that myself (custom voice model).
","['english', 'models']",
UVA and UVB radiations every hour over a year in a given city,"
I'm looking for a dataset that contains how much UVA and UVB radiations a given city received every hour over a year.
E.g.:

0.0 kJ/m² UVA and 0.0 kJ m² UVB between 00 and 01 AM on 2020-01-01 in Seattle.
0.0 kJ/m² UVA and 0.0 kJ m² UVB between 01 and 02 AM on 2020-01-01 in Seattle.
[...]
0.3 kJ/m² UVA and 0.0 kJ m² UVB between 08 and 09 AM on 2020-01-01 in Seattle.
0.9 kJ/m² UVA and 0.1 kJ m² UVB between 09 and 10 AM on 2020-01-01 in Seattle.
1.2 kJ/m² UVA and 0.3 kJ m² UVB between 10 and 11 AM on 2020-01-01 in Seattle.
etc.

Preference if values are averaged over several years. Also, the finer the wavelength ranges, the better: e.g., instead of having UVA = [315 nm; 400 nm] and UVB = [280 nm; 315 nm], measurements could be move fine-grained, such as range_1 = [315 nm; 330 nm], range_2 = [330 nm; 345 nm]; etc. I'd also be interested in UVC ([100 nm; 280 nm]).
I am not interested in the UV index because it is erythemally weighted UV: I want the UVA and UVB breakdown.
","['data-request', 'medical', 'weather', 'climate']",
New Indications via OpenFDA API,"
Is it possible to access new indication submissions or approvals via the OpenFDA API?
I can see the information that I am looking for via the the Drugs@FDA website. For example, the page for Jakafi has submissions labeled as ""Efficacy-New Indication"".

However, when I try to query the same information via the the Drugs@FDA API, the same submissions are returned without the ""New Indication"" label.
API Query:
https://api.fda.gov/drug/drugsfda.json?search=openfda.brand_name:%22JAKAFI%22
API Response Excerpt:
{
          ""submission_type"": ""SUPPL"",
          ""submission_number"": ""23"",
          ""submission_status"": ""AP"",
          ""submission_status_date"": ""20210922"",
          ""review_priority"": ""PRIORITY"",
          ""submission_class_code"": ""EFFICACY"",
          ""submission_class_code_description"": ""Efficacy"",
          ""submission_property_type"": [
            {
              ""code"": ""Orphan""
            }


","['api', 'openfda']",
Number of rainy days per year in a given city,"
I'm looking for a dataset that could allow me to compute, or better give me directly;

How many days per year a city x experiences some rain for more than y hours.
How many days per year a city x experiences some rain for more than z mm of rains at time.

(where x, y and z are specified by the user)
E.g. how many days per year Seattle experiences more than two hours of rain.
","['data-request', 'weather', 'meteorology']",
Uniquely Identify Items in OpenFDA (MAUDE),"
Im downloading and processing the complete data of OpenFDA as described in:

https://open.fda.gov/apis/downloads/
https://api.fda.gov/download.json

But i could not find a way to uniquely identify the records that i read, as there seems to be no uniqueId for most of the data. Am i right ?
For example:
The Adverse-Events (device.event) does not seem to provide any field, that uniquely identifies a record.
See also:

https://open.fda.gov/apis/device/event/searchable-fields/

It is very problematic to not have unique-identifiers, because i need to compeletely drop my data and reimport it every month, when i want to import new changes in the OpenFDA to my local database.
Am i really correct, that the data does not have such unique-identifiers?
",['openfda'],
Is there an identifier that might indicate 505(b)(1) vs 505(b)(2) filing?,"
I'm skimming through the Drugs@FDA dataset, and I'm wondering if any of the identifiers would tell me which pathway the application went through. Of the options, SubmissionClassCodeID seems most likely, but I'm not sure how to read the definitions. Any ideas?
",['openfda'],
Is there a data set which lists common objects and their sizes / measurements / dimensions?,"
I'd like to find a dataset which lists common objects and their physical dimensions:

apple: 5cm-15cm height, 5cm-10cm width
car: 1m-2m height, 3m-5m width
cat: 20cm-30cm height, 30cm-50cm width

Does such a dataset exist?
",['data-request'],
How to get a computer-parseable (JSON preferably) feed of all new video game releases?,"
MobyGames has a ""begware"" API where you have to contact them and ask for access.
GameFAQs actively blocks scraper bots and appear to have no API whatsoever, and if they do, they probably charge through the nose.
I'm looking for some sort of reliable JSON blob which returns the 100 latest video games released, such as:
{
    ""title"": ""Halo 123"",
    ""platform"": ""Xbox 1024"",
    ""developer"": ""Bungie"",
    ""publisher"": ""Microsoft"",
    ""genre"": ""FPS"",
    ""released-date"": ""2021-09-22"",
    ""URL"": ""https://www.halo123game.com/""
},
...

Does it exist? There is no way that I will try to keep up with these modern games in any kind of manual way, but if I can do this automated, I may pay some minimal interest in them.
","['data-request', 'releasing-data', 'games']",
PLS with one component,"
I'm working with partial least square regression with 1 component, and I would like to know where can I find datasets for this model where the number of predictors p is greater than the number of observations n. I know this is a typical framework in chemometrics, but most dataset I found are with more then 1 component. Thanks
",['data-request'],
High-Definition Map - sample data,"
Description of High Definition Maps from Wikipedia:

A high-definition map (HD map) is a highly accurate map used in autonomous driving, containing details not normally present on traditional maps. Such maps can be precise at a centimetre level. ... HD maps are often captured using an array of sensors, such as LiDARs, radars, digital cameras, and GPS. HD maps can also be constructed using aerial imagery. ... High-definition maps for self-driving cars usually include map elements such as road shape, road marking, traffic signs, and barriers.

HD maps are being produced by Tomtom, Nvidia and other giants for the purpose of autonomous driving but I believe they will have other applications. I have been trying to find sample HD maps for download but with no luck so far. It seems like an emerging field with great competition between the commercial companies, but perhaps some pilot project was made available to download, or a FOSS initiative has been launched? I would appreciate any piece of data, even abstract examples.
","['geospatial', 'map']",
What kind of alternatives to Google staticmap exist?,"
I need to get a bunch (>100.000) of static satellite images around a specific spot.
The way I do it now is simple: I send a request with longitude and latitude to Google staticmap API, like that:
https://maps.googleapis.com/maps/api/staticmap?center=39.87514383009362 -83.09151320633832&zoom=19&size=1000x1000&maptype=satellite&key=MY_API_KEY

The example is here: https://codepen.io/chapkovski/full/mdWaxgp
The problem is that some satellite images by Google Maps are pretty old (sometimes 2 or 3 years old).
Any ideas of a similar API with the comparable pricing (Google charges $2 for 1000 images), but with more recent data?
",['geospatial'],
When did USPS start/stop producing its TIGER/ZIP+4 dataset?,"
When did USPS start/stop producing its TIGER/ZIP+4 dataset?
Updates to the product page archived by the WayBack Machine stopped in July 2011, but it looks like some people might have been using it later than that.
I'm trying to figure out the range of years this product would cover if I could get a hold of the old CDs and DVDs.
Unfortunately, the support team for this data product no longer exists.
","['geospatial', 'geocoding', 'postal-code']",
Is there a publicly accessible map of the Swedish medium-voltage electricity grid?,"
I am aware of Open Infrastructure Map - it does a great job of showing electric power lines. I would like to have a datasource independent from OIM, showing the Swedish electricity grid, possibly with substations.
I am also aware of this map - I need higher resolution though. This map shows the locations connected, but the power lines itself are not marked with precision. I can use this map to confirm OIM's map of high voltage power lines, but that map has only the highest voltage lines, and not the lower level ones.
This map is about the US. I would need a similar one but of Sweden.
","['data-request', 'geospatial', 'government', 'europe', 'energy']",
Time zones and country ISO codes,"
I am looking for a simple CSV with the list of country names, country ISO codes, city, time zone UTC and DST... It seems simple, but I am struggling to find it. Any advice/help would be very much appreciated.
","['data-request', 'geospatial', 'csv']",
Wikidata reconciliation with OpenRefine—get only those subjects with English as the language flag,"
Leptospermum scoparium (Q1520028) has 8 common name (P1843) entries.
I have data in OpenRefine reconciled to this object:

How can I get only those P1843 entries that are in English? The reconciliation documentation says to use Len to get, for example, the English label of a given object, but I can't work out the SPARQL syntax that would deliver what I want.
I have tried P1843/Len and P1843|Len but these operators don't work the way I thought:

I realise I can limit the number of values returned per row, but the values are returned in the order in which they appear, meaning in this instance the Welsh common name appears first.
If I can't do what I need through a SPARQL-like syntax on the reconcile screen, is there some way to obtain the JSON response from the reconciliation and parse it? I've tried jsonize(cell.recon.match) but that just gives:
{""id"":""Q1520028"",""name"":""Leptospermum scoparium"",""types"":[""Q16521""],""score"":100}

","['wikidata', 'sparql', 'openrefine']","Currently there is no way to do this simply via the reconciliation API. What you could do instead is use the ""Add columns by fetching URLs"" feature to retrieve the JSON representation of the item from Wikidata (for instance with the expression ""https://www.wikidata.org/wiki/Special:EntityData/""+cell.recon.match.id+"".json"").Then manipulate that object to get what you need (probably doable in GREL, but personally I would go for Python)."
Dataset of Brazilian Portuguese audio classified by emotion,"
I plan to create an algorithm for detecting voice sentiment in Brazilian Portuguese, but i wasn't able to find any datasets to train the model with. If anyone knows where I could find a dataset of voices classified by emotion in Brazilian Portuguese, I would greatly appreciate it.
Region: no region requirements as long as the data is in Brazilian Portuguese and preferably voiced by native speakers.
License: open data.
Format: preferably a csv file, but any format will do.
","['data-request', 'sentiment-analysis', 'brazil']",
U.S. rail terminal location county correspondence table,"
Does anyone know of a place to get a correspondence table between standard point location codes (SPLC) or freight station accounting codes (FSAC), and county-level federal information processing standards (FIPS) codes? Preferable formats would be a txt, csv, or xlsx file.
","['transportation', 'county', 'conversion']",
Dishwasher and hand washing water consumption data,"
There are some blogs and dishwasher manufacturers that say that handwashing of dishes can be between 3.5 and 5 more water-consuming than using a dishwasher. I would like to know if there is some open data to back such statement.
The closest I have been to data is this page in reviewed, but it's not clear how many cases were analyzed. I am particularly intrigued by the variability I expect in hand washing (machine washing being pretty stable). In another page they say that they followed AHAM's ""standardized testing methodology"".
I would appreciate if you could lead me towards an open database of water consumption for either (ideally both) hand or machine dishwashing.
",['data-request'],
Where can I find shapefiles of US county or city neighborhoods?,"
When I search for a neighborhood in Google I usually get a preview of that neighborhood on Google Maps in my search results. My question is...  where do they get this data?
If it's city / county dependent then is there a good rule of thumb for finding this data?
Here's an example of what I mean:

","['geospatial', 'usa']",Neighborhood data can be downloaded from here:https://catalog.data.gov/dataset/neighborhoods-us-2017-zillow-segsStack Overflow: Where can I find a city/neighborhood database? has good info as well.
Sentencing decisions,"
In the book ""Noise"" by Kahneman, Sibony & Sunstein, extensive reference is made to a study by Clancy, Bartolomeo, Richardson and Wellford (1981). I'm particularly interested in the study because multiple decision makers made decisions about a single, complete set of data. Does anyone know whether the dataset for the study is available?
",['legal'],
Public Domain Watershed Data for Central and South America,"
I'm working on a project that will be in the public domain/ creative commons. I would like to find watershed/drainage basin data for Central and South America.
WWF provides HydroSHEDS, which covers the planet very well. Unfortunately WWF provides the data under a license. It's free, but there are terms and clauses on derivative work which would undermine goal of having the project be public domain/ CC.
Short of being able to find other national or NGO sources, the only option seems to be building the polygons from the same SRTM topo data.
","['geospatial', 'hydrology']",
Gun Homicide Rate per US County,"
Does anyone know where I might find data for the number of gun homicides per county in 2020, for the entire United States? I can settle for another year if 2020 is not available and I can settle too for homicides instead of gun homicides.
I have found this but its per state:
https://ucr.fbi.gov/crime-in-the-u.s/2019/crime-in-the-u.s.-2019/tables/table-20
","['usa', 'crime', 'county']","Here is a county based dataset of the number of deaths due to homicide per 100,000 population from 2013-2019. The data source is National Center for health statistics.Dataset Link:  https://www.countyhealthrankings.org/explore-health-rankings/measures-data-sources/county-health-rankings-model/health-factors/social-and-economic-factors/community-safety/homicides"
How to get the graph for covid-death per capita for specific countries?,"
I am looking for a source that allows me to perform the logarithmic chart of COVID-19 Deaths per capita for selected countries with up-to-date data as below

",['covid19'],Your concern is right herehttps://ourworldindata.org/covid-deathsYou can choose the countries based on your desires.
Where can I find real world salt and pepper noise image?,"
I am looking for real world salt and pepper or gaussian noise images. Where can I find them?
",['data-request'],"The following image data sets with the requested distortions can be found with the following links:https://archive.ics.uci.edu/ml/datasets/Discrete+Tone+Image+Dataset#
http://signal.ece.utexas.edu/~bevans/synthetic/However, they are synthetic data sets and, for the second link, you will need to contact some one for the password.I did find one with natural images that had the noise synthetically introduced.https://www.kaggle.com/tarunpathak/natural-images-with-synthetic-noise"
How to get person name and other attributes from Wikidata Sparql (resolving entities)?,"
I have this Node.js sparql fetcher from Wikidata:
next()

async function next(offset = 0) {
  const sparql = `
  SELECT ?person ?pic ?givenName ?familyName ?placeOfBirth
  WHERE {
    ?person wdt:P31 wd:Q5 .
    ?person wdt:P18 ?pic .
    ?person wdt:P735 ?givenName .
    ?person wdt:P734 ?familyName .
    ?person wdt:P19 ?placeOfBirth .
    SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". }
  }
  OFFSET ${offset}
  LIMIT 50`
  const query = new URLSearchParams({ query: sparql }).toString();
  const url = ` https://query.wikidata.org/bigdata/namespace/wdq/sparql?${query}`
  console.log(url)
  const res = await fetch(url, { headers: { Accept: 'application/sparql-results+json' } })
  const json = await res.json()
  const array = json.results.bindings
  if (!array.length) {
    return
  }
  console.log(array)
}

However, it is returning an array of values like this:
{
  person: { type: 'uri', value: 'http://www.wikidata.org/entity/Q15198783' },
  placeOfBirth: { type: 'uri', value: 'http://www.wikidata.org/entity/Q61' },
  familyName: { type: 'uri', value: 'http://www.wikidata.org/entity/Q2658150' },
  pic: {
    type: 'uri',
    value: 'http://commons.wikimedia.org/wiki/Special:FilePath/Charles%20Baker%202016.jpg'
  },
  givenName: { type: 'uri', value: 'http://www.wikidata.org/entity/Q2958359' }
}

The pic is at least resolved, but everything else is not. How can I just get both the entity ID for each, as well as the resolved literal value for it, for all these properties?
","['wikidata', 'sparql']",You need to select additional variables on the pattern ${variableName}Label:See the User Manual for more details
Linking investigational drugs to name of owning company,"
I see that AACT (https://aact.ctti-clinicaltrials.org/data_dictionary) has investigational drugs. I find the table/field: keywords/name to be useful for finding investigational drugs.
I'm wondering though how to find the name of the company that owns an investigational drug.
I'm also interested in finding drugs that are competitors / have similar effects.
Can anyone point me in the right direction?
","['data-request', 'medical', 'drugs']","I've never used that dataset, but I can give you general guidance.The name of the company that owns an investigational drug can have several answers. The drug could be the product of collaboration (e.g. the Pfizer/BioNTech covid vaccine), so to which company would you attribute ownership? Some ways are through the name of the drug (e.g. Merck investigational drugs start with ""MK-""), or through the name of the company listed as the sponsor of the clinical trial.For drugs with similar effects, you may need to use TF/IDF against research publications and then cluster based on frequently-used terms.I hope this helps."
How Can I use SPSS to conduct a Generalized Least Square regression,"
I ran OLS regression on my data and found issues with auto correlation due to non-stationarity of data (time series data). I need to conduct a Generalized least Square regression as it is robust against biased estimators
",['time-series'],
What is the total number of deaths world-wide in 2020?,"
This is a very simple question. I'm looking for the total number of deaths in 2020 world-wide. We are already well into 2021 - the statistics from 2020 should be available - yet I couldn't find the simple total number of deaths that occurred in 2020 world-wide.
","['data-request', 'demographics', 'global']",
No inactive_ingredient field when query for drug substance in Drug Label API,"
I am looking for the inactive ingredients for a dozen of different drugs. However when querying in the Label API, most results return without an ""inactive_ingredient"" field. The field only exists in the  Fields Reference Document: https://open.fda.gov/apis/drug/label/searchable-fields
Example1, Propofol search:
https://api.fda.gov/drug/label.json?search=openfda.substance_name:propofol&limit=3
Examlpe2, Albuterol search:
https://api.fda.gov/drug/label.json?search=openfda.substance_name:albuterol&limit=3
No inactive_ingredient field is found in any of these queries.
","['data-request', 'api', 'openfda', 'data-format']",
Non Geographic and Special Postcodes,"
I originally asked this on the Stack GIS - incorrectly
I'm trying to get a list of special (those receive an exceptionally large amount of mail) and non-geographic postcodes (eg PO boxes).
There's nothing definitive available on ONS or OS that I can find.
The ONS postcode lookup provides a lookup against Grid Ref positional quality indicator but this isn't definitive. eg PO Boxes are assigned an osind of 6 but so are other things.  So this doesn't work for me.
Other than this Wiki article I can't find anything.
","['data-request', 'uk', 'postal-code']",
Seeking mean annual temperature raster or vector map for land surfaces worldwide,"
In an attempt to do some climate and climate change vulgarization, in relation to vegetation sciences, I would need to find some reference sourced world map of annual mean temperature (monthly means would be nice but I'm looking for annual means as my principal focus) , in common raster or vector format which I could readily open with QGIS (or which I could easily georeference), something similar to these kind of maps (which I've found for precipitations) :
Rustemeier et al. 2020. « GPCC Precipitation Climatology Version 2020 at 0.25°: Monthly Land-Surface Precipitation Climatology for Every Month and the Total Year from Rain-Gauges built on GTS-based and Historic Data: Globally Gridded Monthly Totals ». Global Precipitation Climatology Centre (GPCC). https://doi.org/10.5676/DWD_GPCC/CLIM_M_V2020_025
https://opendata.dwd.de/climate_environment/GPCC/html/gpcc_normals_v2020_doi_download.html
My researches :
Looking the generic web browser as well as scholar browser I mostly encounter

some sourceless maps on website of poor credibility like : https://www.eldoradoweather.com/climate/world-maps/world-annual-temps-map.html which is exactly the kind of map which I'm looking for (well it'd be nice to find some better resolution but, it's ok), the problem with the eldoradowheather.com is that they give no source for the data, so I won't trust it, and would not like to base my vulgarization work on such poor information.

as well as

maps of anomalies to normal temperatures like this on Berkeley : http://berkeleyearth.org/global-temperature-report-for-2020/ but this is NOT what I'm looking for,

Some results that look good but I'm unable to handle :

Climate Data Guide have Global (Land) precipitation and temperature: Willmott & Matsuura, University of Delaware, which provide ASCII (raster) files for each year from 1900 to 2014.
These are text files with X, Y, and january to december mean temperature columns. When I try to open it within QGIS (as a raster) it says : ""Could'nt determine X spacing raster layer""
https://climatedataguide.ucar.edu/climate-data/global-land-precipitation-and-temperature-willmott-matsuura-university-delaware

I've found the ERA5 data : https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land-monthly-means?tab=overview but it comes as GRIB or NetCDF formats and I don't know how to handle such files. And I'm not willing to learn to use some new software.

I've tried to browse US's NOAA's climate.gov ( https://www.climate.gov/maps-data/datasets/coverage/global/variables/atmospheric/collection_type/land?search_api_views_fulltext=temperature ) but can't find what I'm looking for.

I've reach till GHCN Gridded Products : https://www.ncdc.noaa.gov/temp-and-precip/ghcn-gridded-products/maps/202013 but these are like Berkeley's deviations to normal temperatures. Although it does seem to have annual means somewhere, but I can't find it.


My question is closely related to this one :
Looking for 0.25x0.25 spatial resolution grid data for land surface temperature/precipitation
but It would be ok to be oriented to maps at other resolutions, however, as already mentioned, the finer the better.
","['geospatial', 'climate']",
Reasons for incarceration in the United States,"
I'm looking for a dataset that contains the incarceration numbers in the United States broken down by reason of incarceration. E.g. 30% theft, 20% drugs, 10% gun violence, etc. Bonus point if it is broken down by year and US state.
","['data-request', 'usa', 'legal']",
Crosswalk from US Census Block to Congressional District,"
The Census geographic hierarchy diagram indicates that Congressional Districts are built from Census Blocks. However, I don't see any crosswalks from blocks to congressional districts on the Census Congressional District Relationship Files website section. I also couldn't find such a crosswalk on sites like NHGIS, though I did just ask on the IPUMS forum.
A similar question was asked in 2015, but it asked about a specific past congressional session, and all the links in questions and answers are now dead.
Specifically I'm most interested in a crosswalk from 2010 Census Block to 117th (current) Congressional District, but ideally would like to know a general solution.
","['data-request', 'geospatial', 'usa', 'us-census']",
List of all NYC bodegas and delis,"
I'm looking for a full list of NYC bodegas and delis. Could or could not have a spatial component. A list would suffice.
","['data-request', 'usa', 'restaurant']",
Database of canceled flights,"
I am looking for a table of flights that have been canceled.
For each canceled flight I need:

Date and time at which departure had been expected. Example: 2017-08-25T19:20:00Z
Departure airport. Example: KIX
Destination airport. Example: OKA
(optional) airline company. Example: JAL
(optional) flight number. Example: JAL909
(optional) cancellation reason. Example: weather

The more open the better, but I am OK with not-so-open databases too.
Ten years of data would be ideal, but I am OK with one year of data too.
Worldwide would be ideal, but I am particularly interested in Japan/JAL data.

Context: In Japan, flights get canceled whenever a typhoon comes close by, which happens every few weeks. Using past weather data and current weather forecast, I want to predict what flights will probably get canceled. JAL only provides data going back to the day before.
","['data-request', 'public-transport', 'aviation']",
Where can I download data on registered Canadian charities (form T3010) in bulk?,"
I'm looking for a data source that will let me download, in bulk, machine-readable format, the list of all charities that file form T3010, along with information about the organization. Ideally I'd like the following info:

Name
CRA category code
Revenue
Expenses
Any other fields on the form

You can request these data from the CRA, but this can take up to four weeks and I can't look at the data beforehand. Is there anywhere (similar to, in the US, the IRS' bulk download tools) where I can just download the full list for the most recent tax year as a machine readable file?
","['data-request', 'canada']","Open Data Canada portal should help
https://search.open.canada.ca/en/od/?sort=score%20desc&page=1&search_text=T3010Alternatively, you could parse the data from List of charities search"
Seeking UK School performance data,"
I am looking for UK school performance data.
I don't know what format that comes from, but I want to compare results achieved by pupils, for instance average number and grade of O and A levels per pupil, preferably over at least 5 years.
It would be a bonus if I could chose the subjects, and lean heavily towards STEM, but that's not ""must have"", just nice to have.
Apparently, house prices in the UK are ridiculously expensive, and a friend in the UK wants me to correlate house prices to education, so that they can find a good school and a relatively affordable house nearby.
I imagine that I will post a second question asking for UK house price data, but the potential problem is that I need them to have the same geolocation data. It is not of much use if one dataset is at town/city level while the other is at post code level. Unless, of course, they can be easily converted, so, any dataset that helps towards that end would be gratefully received.
","['geospatial', 'uk', 'education']",School performance data is collected by the Department for Education (DfE) and can be accessed via the gov.uk web site - https://www.gov.uk/school-performance-tablesThe types of data available (for 2018-19 anyway) are:It looks like it comes as Excel files (even if you select CSV in the download) and you have to do your own joining from the school information table to the actual performance data. The geography of the school can probably be inferred from it's post code but I don't know if that works for say multi-site academy chains.
"What are the known standards to map country names to super regions APAC, EMEA, and AMER?","
I am looking for country-superregion mapping for the following super regions:

APAC = Asia Pacific
EMEA = Europe, Middle-East and Africa
AMER = North, Central and South America

So far I have only seen a compiled list on GitHub as a gist. Would be great to have a standard list and wonder where I may be able to find such information.
","['geospatial', 'geocoding']",
Asking for some data sources relating to democratic score of all countries in 2020?,"
I am wondering if there are some sources for the democratic level of countries all over the world in 2020? (to separate Democratic and Dictatorship)
",['politics'],V-dem and Polity IV probably have the most commonly used measures of democracy/autocracy in political science.
I need help finding and downloading traffic data,"
can anyone direct me to instructions to show how to download traffic data across the US?  I've been all over the site and not finding the data.
",['data.gov'],
Asking for some geopolitical variables datasource,"
Normally, we control for geography variables in some economic studies. However, in the study examining how well the government implements the laws and orders, my advisor told me that we can think of the ""geopolitical variables"".
From Reynaud(2008), geopolitic is

Geopolitics traditionally indicates the links and causal relationships
between political power and geographic space; in concrete terms it is
often seen as a body of thought assaying specific strategic
prescriptions based on the relative importance of land power

I am wondering if there is any popular geopolitical variable in published resource?
In another word, ""Geopolitics"" is how geographical factor affects the national behaviors. More specific, geopolitic examines some factors as: geography, natural resources, population,... affects a country's foreign policy and the position of this country in international system
Some suggested me to think the data about ""spending on the military, trade agreements, research agreements and size of trade relationships, voting power in international bodies, closeness of government systems, to which countries does a given country provide aid""
",['politics'],"Quite a broad concept, but I would say databases such as V-Dem (varieties of democracy), QoG (quality of governance), DPI (database of political institutions) are all pretty comprehensive when it comes to looking and country-level political variables.The above datasets contain information on population, resources, GDP, elections, etc.If you are more interested in spatial information, conflict, etc., I would recommend PRIO, UCDP, and Polity IV. These all have good coverage of geo-referenced conflict events, and other useful spatial data (i.e. area of state, proximity to oceans, topography, trade, etc.).It might well be the case that you will need to join these datasets together to get at all the variables you are interested in -- this can be done fairly easily in R or similar tools."
Number of deaths during flood events,"
I am studying about flood events and its results. Because of that I need to find the number of people who die as a result of the flooding in the country scale. Is there any source that shows these statistics and numbers?
",['data-request'],"Emergency Events Database (EM-DAT) created by the Centre for Research on the Epidemiology of Disasters (CRED) has global disaster related data. It has free access to data of all kinds of disasters geophysical, hydrological, biological etc. in detail (including number of deaths). I think it would be helpful for you.Visit the EM-DAT website for details. To access the database Click here"
"COVID-19 cases broken down by whether the individuals are vaccinated, and if so, with which vaccine","
I'm looking for a dataset that contains number of COVID-19 cases broken down by whether the individuals are vaccinated, and if so, with which vaccine.
I'd prefer if the COVID-19 cases broken down by day and country, similarly to https://studylib.net/coronavirus:

(but the screenshot is missing vaccine info)
","['data-request', 'medical', 'covid19']",
Is there a way to obtain US and UK customs data?,"
I'm being asked to find all the information I can about US and UK customs data, but I just don't know where to search for, any suggestions?
","['data-request', 'usa', 'uk', 'migration']",You could submit a Freedom of Information Act Request to CBP. Here's a link with more information on how to do that.The UK has a similar law. Here is a link to the non-specific FOI instructions for the UK. And a specific link for HM Revenue and Customs.
OpenFDA - Parsing Indications and Dosage Variables,"
I have a question about parsing two specific variables from the Product Labeling Endpoint on OpenFDA:

indications_and_usage
dosage_and_administration

Ideally I would like to:

Extract each indication and its abbreviation.
E.g. drug: Keytruda would be Melanoma, Non-Small Cell Lung Cancer (NSCLC), etc..

Extract each dosage (related to indication and population)

Map the indication with the dosage


The request via the API returns a long text/string, which is unstructured and difficult to parse.
Some questions I have:

Are there any existing libraries that can parse these two variables out?

Is there a paid service that OpenFDA offers that contains a parsed or more structured format of these two variables?

Are there any existing services by other companies that parses this information into a structured format?


I've already looked at the DailyMed XML files for these two sections (indications and dosages) and tried to parse it that way, however, the structure of the XML files for each drug is different and also difficult to parse.
Is this still the only way: Can we get the dosage list for a drug
","['openfda', 'parsing']",
"Why # positives and % positives align, and why use former?","
Background: the Dutch government publishes certain Covid-related metrics via a dashboard (https://coronadashboard.government.nl/) and I have a few questions about the underlying data science.

NUMBER OF POSITIVES
It's shown either as-is or as ratio per 100K inhabitants. Since population of the country hasn't changed significantly within 1 year, they both just reflect the number of positive cases:



OBJECTION: if people get themselves tested more (eg going abroad on holiday during July/August, and are required by the destination countries to get tested), even if the same proportion of tests are positive, then because we have more tests, we'll have more positives, so by measuring # positives and not adjusting to # tests, we're subject to various biases towards # tested.

PERCENTAGE OF TESTS WHICH ARE POSITIVE
This one is the ratio # positives  / # tests. Surprisingly, the trends are very similar, which seems to invalidate (at least partially) the objection formulated earlier:



Q1: Is there an explanation why the trends in [# positives] and [# positives / # tested] align so well?
My hypothesis: if you've been in contact with a positive case, it makes you more likely to be positive, and if you know you were in contact, it makes you more likely to get yourself tested, hence why the trends of # positives and  # positives / # tested follow each other. Are there other explanations?

COMPARING BOTH
I downloaded the source data and compared both metrics:
import pandas as pd
import plotly.express as px

# Loading the source data
df_src = pd.read_csv('./COVID-19_uitgevoerde_testen.csv',sep=';')
# Keeping only coluns we're interested in and renaming
df = df_src[['Date_of_statistics','Tested_with_result','Tested_positive']]
df = df.rename(columns = {'Date_of_statistics': 'date', 'Tested_with_result': 'tested', 'Tested_positive': 'positive'})
# Grouping by test
df = df.groupby(['date']).sum().reset_index()
# Rolling 7-day mean
df['tested'] = df['tested'].rolling(7).mean()
df['positive'] = df['positive'].rolling(7).mean()
# Removing first 6 days for which we have no data due to 7-day rolling
df = df.iloc[6:]
# Calculating percentage of tests which came back positive
df['positive_rate'] = df['positive']/df['tested']
# Normalizing # positives and % positives as their peak so we can compare them
df['% positives (normalized)'] = df['positive_rate'] / df['positive_rate'].max() * 100
df['# positives (normalized)'] = df['positive'] / df['positive'].max() * 100
# Visualizing both # positives and % positive on the same chart
compare = df[['date','% positives (normalized)','# positives (normalized)']].melt(id_vars=['date'],var_name='metric')
compare.head()
fig = px.line(compare, x=""date"", y=""value"", color='metric')
fig.show()

Here is what I get:

As we can see the trends follow each other closely, the correlation coefficient on that dataset is actually 0.88 which confirms what we're seeing
Q2: Despite the very strong correlation, [# positives / # tested] seems a more robust metric than [# positives] as it removes biases towards # tested, so is there any reason why we would want to report on [# positives] at all?
","['medical', 'covid19']",
"Find who owns a doi:// domain? (A ""whois"" for doi Links)","
Is there a command-line tool, or a website, or a ""directory service"",  that I can use to determine which organization (or person) owns a doi// domain?
I want to know ""Who owns 10.2312?""
(That's the same as: who owns doi://10.2312?).
(I could also ask on softwarerecs.stackexchange.com, or academia.SE, but this ""open data"" forum is bigger and seems more appropriate.
",['doi'],
U.S. major cities busiest intersections?,"
Is there a database of the busiest intersections in major U.S. cities?
Could this be figured out with, e.g., Google Maps API?
","['usa', 'transportation', 'traffic']",https://trafficview.org/ presents Google Maps's traffic congestion data.
R cannot allocate vector. Where is the object?,"
I misjudged how much memory would be required and my computer ran out of memory when R was 76% done with an lapply function. Is there a way to recover and saveRDS the object or do I have to start over from the beginning?
",['programming'],
Where to find a database of AIS vessel information?,"
The US Coast Guard provides a service by which a snippet of boat/ship identifying data, most typically an MMSI number, can be used to retrieve a more complete data set of ship information, such as draft, name, dimensions, etc...
I'd like to download this database for offline usage. Is there, either (semi-)official or community created?
",['ais'],
How many *Non-Native* speakers of Egyptian Arabic are there world wide?,"
Every time I try to look this up, it always gives me the number for native speakers. I'm not looking for that. I specifically want to know how prevalent Egyptian Arabic is as a second language around the world. Only 68% of Egyptian citizens speak Egyptian Arabic natively but the other 32% have to have some kind of fluency in it, right? Not to mention, Egyptian Arabic is often the language used in Arabic movies, tv shows, and books. So there's a lot of people in the Arab world who have learned Egyptian Arabic as a second language.
Every article I find states that Egyptian Arabic is spoken in Iraq, Israel, Jordan, Kuwait, Libya, Saudi Arabia, United Arab Emirates, and Yemen, but they never specify how many people in those countries speak it. I've also tried looking at the demographics for some of those countries and they almost never mention Egyptian Arabic. The closest I got was a demographic chart that said roughly 600,000 of Saudi Arabians speak Egyptian Arabic but that was only counting. Egyptian immigrants to the country and not the people in Saudi Arabia who learned it as a second language. I'm looking for L2 speakers of Egyptian Arabic, not native speakers who have moved to other countries. I'm not sure where else to look, so I came here hoping someone would either know the answer or know a good place to look.
","['data-request', 'language']",
Wikimedia: Delta-Dumps or Timestamp of Last Change,"
I am looking for a list of all the entries of https://de.wiktionary.org (German Wiktionary, but I think this works for all Wikimedia the same way) that have had any changes since the last dump. Is there something like that? Under which URL is this list available? Or is there a list that contains the timestamp of the last change for each entry?
Background:
Wikimedia (including Wikipedia, Wiktionary etc.) provides dumps of its contents every 1 or 2 weeks.
A script I wrote loads every day the page https://dumps.wikimedia.org/dewiktionary/latest/ and reads the timestamp of the current version of the file dewiktionary-latest-all-titles-in-ns0.gz. If there is a new version of this file (usually every 1 - 2 weeks), the script downloads it.
This file contains all the titles of the sites de.wiktionary.org (only the titles, no contents). My script compares this list with the titles that are already in my database. It marks entries as deleted if they are no longer in the current list, and marks titles for download that do not yet exist in my database.
Then another script iterates through all the new titles and downloads their contents, one after the other, for example by going to this page: https://de.wiktionary.org/w/index.php?action=raw&title=Titel (where you can find the sourcecode for this site: https://de.wiktionary.org/wiki/Titel) using the respective title instead of Titel, of course.
To conserve both my own server's and Wiktionary's bandwidth, this script always pauses briefly between two titles, thus downloading the contents of a maximum of about 100,000 titles per day. There are about 1,000,000 titles in total in German Wiktionary, so the download of the whole German Wiktionary was done in less than 2 weeks.
And here's the point:
I want to keep my database as up-to-date as possible, but I also want to download as little data as possible. Above all, I don't want to download content again and again every 10 days, that already exists in exactly the same version in my database.
So ideally I only want to download the contents of those titles where there has been any change since the last dump (as provided on https://dumps.wikimedia.org/dewiktionary/latest/). Is there such a list? If so, where can I find it?
A list where each title has a timestamp of it's last change also will do.
","['wikidata', 'download']","There are two ways to generate a list of last-revision data for all pages. The preferable tool is probably the second one listed here, PetScan.The first is to use the Wikimedia Quarry SQL service (quarry.wmflabs.org - documentation) to generate a list of all pages with metadata. This query (took about 25m to run, most recent results are cached) gives the page ID, page title, and latest revision ID for all ns=0 (ie main article space) pages on dewiktionary. You could also tweak the query so it picks up the actual timestamp of the latest revision ID (this is available from the revisions table, but my SQL competency to tie them together is a bit limited...).The second is a slightly hacky approach should be ""good enough"" for most purposes: the PetScan tool (petscan.wmflabs.org - documentation) can generate this data for arbitrary queries like ""all articles in this set of categories"". It can't do ""every page on the wiki"", which is a pity, but as it turns out pretty much every Wiktionary article page is in a sub-category of Kategorie:Sprachen, so we can just use that as our source. This query looks for everything filed in Sprachen or up to three levels below it, takes ~60s to run, and identifies almost the same number of pages as the main one - 992644, versus 993681 in the Quarry list. You can get this list of results as a TSV or other file by selecting the relevant format in the last tab (""output"") and re-running.There are three important identifiers here. One is the page title, which you know about. This is likely to be static for Wiktionary (given it is the headword) but might change if you were eg doing an analysis on Wikipedia. The next is the page ID, which is assigned when the page is created and does not change even if the title does. The last is the latest revision ID (in Quarry) or the last changed date (in Petscan). For example, ""Pferd"" has a latest revision ID of 8615119, which corresponds to being edited on 22 June). This is the one you're looking for.In terms of which source to use - well, either would work. I think the PetScan approach is likely to be preferable, as it is a much quicker system (data in ~1m not ~25m) and so is presumably a lot less expensive on the back-end systems. I think it is also possible to trigger a fresh PetScan query with wget etc, using the exact URL for the query, while Quarry may have to be manually triggered in the browser.There is a slight risk that the PetScan approach would lose any pages that have not been categorised for whatever reason, but it looks like this is very rare. On examination they are probably redirects to another page title, which would count on the Quarry list (they exist in namespace 0) but which would not be picked up by PetScan as they are usually not placed in categories; there are currently around 1050 redirects in namespace 0 per this index, which is very close to the discrepancy we saw between the two lists."
Dataset of PDF invoices,"
I'm looking for examples of PDF invoices. I want to write a code for extraction and analysis.
I need PDF invoices from companies such as Uber, Amazon, AliExpress, Nike, Adidas, Apple, Huawei, all kind of internet providers and phone network providers, hotels etc.
It would be good if examples are on english, but german is also good.
I have looked all over the Kaggle, UCI ML Repository, GitHub but I have found only 2-3 pdf invoice documents. It would be great if you can tell me where can I download more of the REAL PDF invoices
","['data-request', 'pdf']",
How can I get completion rate data from all colleges and cohorts in a longitudinal format from college scorecard? (with R),"
What I want:
To obtain a R dataframe with completion-rate data from all colleges in the US (or all the colleges that have available data in college scorecard datalake).
What I expect:
A data frame in the long format with data from multiple cohorts for each college, something like:
| college_id (if available) | college_name               | cohort | completion_rate | median_program_length | average_sat_score |
|---------------------------|----------------------------|--------|-----------------|-----------------------|-------------------|
| 1                         | Yale University            | 1980   | 0.823           | 4 years               | .                 |
| 1                         | Yale University            | 1981   | 0.791           | 4 years               | .                 |
| ...                       | ...                        | ...    | ...             | ...                   | ...               |
| 1                         | Yale University            | 2000   | 0.918           | 4 years               | 1421              |
| 1                         | Yale University            | 2001   | 0.907           | 4 years               | 1447              |
| ...                       | ...                        | ...    | ...             | ...                   | ...               |
| 1387                      | New College of Springfield | 2000   | 0.231           | 2 years               | 704               |
| 1387                      | New College of Springfield | 2001   | 0.257           | 2 years               | 753               |

What I tried:
I registred in the College Scorecard API website and got my key. I also read and tried to understand the documentation and dictionary, but not quite sure if I understood it well. Then I tried to extract data from the API following some tutorials on the internet, I managed to download some lists of different objects but I cannot manage to extract an R dataframe from them. One of the problems is that these objects apparently do not contain any data.
For example:
library(httr)
library(jsonlite)

completion = GET(""https://api.data.gov/ed/collegescorecard/v1/completion?api_key=0eXXXXXXXXXXXXX"")

df= fromJSON(rawToChar(completion$content))

print(df)


The result is:
$message
[1] """"

That is, I do not even know If I am being able to download the data that I want. Apparently, the object has no data.
I also tried variants of that request, but it seems that all returned with objects that are lists of lists of empty objects. Or at least I was not able to extract data from it:
completion2 = GET(""https://api.data.gov/ed/collegescorecard/v1/schools?fields=completion_rate_4yr_150nt&api_key=0eXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"")

completion3 = GET(""https://api.data.gov/ed/collegescorecard/v1/completion?fields=completion_rate_4yr_150nt&api_key=0eXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"")

completion4 = GET(""https://api.data.gov/ed/collegescorecard/v1/schools?fields=completion&api_key=0eXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"")


Possible solutions
I have some experience with handling dataframes in R, but I am completely new to accessing APIs with R and also to json files. I read some material on both, but I am still struggling with college scorecard API. I only need help with data extraction from the API and to convert it to an R dataframe. There is no problem if not all data from my example are available in a single request (cohort, completion rate, program length, average SAT score). I can put it together if I have some type of ID variable (like college_id, or unique college names, etc).
","['data-request', 'api', 'programming', 'collegescorecard']",
Dataset that contains human-written transcripts of videos or audio files,"
I'm looking for a dataset that contains human-written transcripts of videos or audio files (e.g., podcast). I'm aware of the IWSLT2011 (TED) dataset and OpenSubtitles. What else exists?
","['data-request', 'nlp']",
Making CKAN Postgres DB permanent on Cloud,"
We're working on deploying CKAN on Cloud using this docker-compose network. We're not storing any datasets but only publish URLs to data resources. We would like to stand up a permanent Postgres database on Cloud (AWS) to replace the db service, but it's not clear to me how this can be done. For example, how can we point to the db endpoint, having only db name, user and password editable in Dockerfile? How Docker volumes come into play here?
So far, I created on AWS an RDS instance with 4 databases (ckan, ckan_test, datastore and datastore_test) and 2 users (ckan and datastore_ro) with the former having read and write access to all the databases while datastore_ro has only read access to datastore* databases. I updated the env vars accordingly. But I still don't understand if this would entirely replace the db service or they're two completely different components?
Pointers to any helpful documentation will be appreciated!
",['ckan'],
(How) can I use CKAN when data needs to be kept in place and only its data dictionary should be published?,"
Context
I am investigating how I can set-up a data management system for a department of 100+ colleagues.
Many of our datasets are stored (scattered is a better word) on different network drives, database instances and servers, and the organisation needs to keep it that way (for now) due to security and certification reasons.
However, the department does see the value in knowing what data exists and where it can be accessed. Because of that it's looking for a searchable data catalog method that would allow us to search the metadata of the datasets and then, use existing processes to actually request access to the data if needed.
In my ideal case:

A data owner would use CKAN to extract a data dictionary (tables, files, columns, types) from a stored dataset (database, CSV's, etc...) without storing the data in CKAN itself.
With that data dictionary the data admin creates a CKAN dataset with all the relevant metadata and perhaps a few data samples (e.g. first 100 rows of each table).
The data owner adds a link to the CKAN dataset with instruction on how to request access (e.g. contact Dilbert and request read rights for network share \\unc\path\to\data).
Colleagues without read rights to the dataset can search the metadata in CKAN and requests access to the data itself outside of CKAN.

Question
Will CKAN (+extensions) allow me to do the above? If so, how would that process look like roughly?
If not, is there another data cataloguing method that I can use?
Looked into so far
User manual
From the user guide I see that it supports three methods to add data:

Link to file
Link to API
Upload a file

It's not clear to me if any of these methods would be able to create a dataset while only reading the data once to obtain it's data dictionary.
Extensions

I found the ckanext-dataproxy extension that allows one to read remote databases.
It's unclear though if that preview can be used to extract a persistent data dictionary.

I found the ckanext-extractor extension which seems to do the metadata extraction part, however the examples seem to be limited to documents (doc, pdf) and don't mention databases or CSV's.


","['metadata', 'ckan']",
Olympics data request,"
I am looking for Olympics data.
What I must have is all the world records in every competition (at least for modern Olympics) including: when and by who the world record was broken.
I would also like to have:

All athletes participating in every Olympiad including meta data such as birthdate, age, nationality, height, weight, etc.

For each competition the results of all the athletes in every round including final rankings.


Basically, I am looking for all possible data. I am sure it is stored somewhere, but can't find it.
Any clue where can I find this data?
Thanks
",['data-request'],
Combined search query of openfda.generic_name and inactive ingredients only provides info for OTC products?,"
I think the title explains the question.  Im trying to run a query that pull specified legend drug name and specified inactive ingredient.  The results only seem to have an inactive ingredient property for OTC products and not rx drugs?
",['openfda'],
"What ""MOUNT_TYPE"", ""URBN_TYPE"", and ""COAST_TYPE"" represents in European NUTS shape files?","
I have downloaded the shapefile for European NUTS region fro here.
In particular I have downloaded the 1:1 Million SHP file for NUTS 2021 from here.
I have opened them using QGIS.
In each region there are 3 categorical variables, named ""MOUNT_TYPE"", ""URBN_TYPE"", and ""COAST_TYPE"", as can be seen in this example from Mance:

What does the value of that categorical variables represent?
There is a ""metadata.pdf"" file together with the shapefile that doesn't explain them. Also the online reference in that PDF file doesn't explain them.
I googled for them but could not find anything.
","['geospatial', 'geocoding']","Following the link in the metadata file you arrive here where is states:Specific geographies such as coastal regions, mountain regions, border
regions or island regions are also covered.It's does not take a massive leap in imagine to realise that Mount/UrBn/Coast type fields relate to these typologies.That said I completely agree their metadata falls short of explaining what these fields are and their values. EUROSTAT appear to have ""dropped the ball"" on this and published their data without updating their metadata. Would have expected better...Fortunately for you I clicked on a few more links and ended up here, click on the  NUTS 2021 classification link to download an Excel file and the information you seek (what the codes mean) are embedded in the sheets."
USA block-level census data for mass-download,"
Quick version
Is there a way to mass-download block-level data from the USA Decennial Census besides just total population and housing?
Explanation
I know that some of the 2010 Census block-level data is available here in GDB format, but that data set only contains total population and total household units.
I also know that the full data set for the American Community Survey (ACS) for 2010 is available here in GDB format. But note that the smallest/finest level of geographic aggregation available is Block Group, not Block.
Lastly, I found that you can download block-level data tables one-by-one on the Census Data portal, clicking on the ""Filter"" button and selecting Geography -> Block -> State -> All Blocks within State in the ""Browse Filters"" section that pops up. This will filter the tables on the left-hand side to only contain tables related to block-level data (see screenshot below). The problem is that, in order to download a set of data, I need to select each data table one-by-one from the left-hand panel and wait a significant amount of time for the server to ""prepare"" the data. If I just want to download all the available block-level data for a given state, this quickly becomes a very tedious and time-consuming process.

Is the block-level census data available somewhere for mass-download instead of having to download one table at a time from the Census Data portal?
I believe the old ""Fact Finder"" portal allowed you to download multiple data tables at once, but that tool has been sadly decommissioned. This is only tangentially related, but it was still worth mentioning.
This question was originally asked on the GIS Stack Exchange and is now copied here.
","['geospatial', 'usa', 'us-census', 'census', 'download']",
Tourism Multivariate Time Series Dataset (daily observations),"
I am looking for a tourism related dataset (ideally air traffic) with daily observations and a reasonable number of dimensions (thinking at least 1000 observations, and over 50 dimensions), ideally it would include the year 2020 (i.e. it has the impact of COVID). Most tourism datasets aggregate monthly/annually, and if they do aggregate daily they are only one or two dimensions. Any pointers would be greatly appreciated!
",['time-series'],Found what I was looking for here EU airport traffic dataset. Daily observations for many EU airports going back to January 1 2016.
Seeking API for live ASOS/AWOS reports,"
Many weather apps and websites are now including airport ASOS/AWOS weather reports. (All the colored dots in the below screenshot, from SkyVector)

I'd like to find the API for getting the NOAA (NWS?) data feed. So far, nothing has jumped out at me in my searches, although I have found https://www.faa.gov/air_traffic/weather/asos/ where I could scrape the site for data.
","['api', 'weather']","I have been searching for something similar. So far this is the best API I have found (for free). Just looking to make a site for a fun side project.API Swagger doc:
https://mesonet.agron.iastate.edu/api/1/docs#/default/Main site to play around with and look for the ""network"" you want to query:
https://mesonet.agron.iastate.edu/sites/locate.php?I have not gone through all of the endpoints but found the /current.{fmt} to have at least the basics of what I'm going for."
How can I align the College Scorecard population totals to those that are derived from IPEDS?,"
According to the scorecard dictionary, the undergraduate totals are defined as ""the number of degree/certificate-seeking undergraduates enrolled in the fall, as reported in the IPEDS Fall Enrollment component.
In the IPEDS raw data (https://nces.ed.gov/ipeds/datacenter/DataFiles.aspx?goToReportId=7), one gets a more finite breakdown of enrollment by year. I have synthesized the total undergrad population by combining the full-time and part-time undergraduate men and women total counts (efrace15/efrace15), but this number does not always seem to match the College Scorecard Data.
I'd love to figure out how my totals can match for replication purposes!
","['collegescorecard', 'population']",
"AI/ML specialists - Where to find open source, medical data for creating AI algorithm which could diagnose glaucoma/cataract?","
I need to build theory for this school project - AI algorithm that could identify with some probability - glaucoma/cataract. My question is - where to get data? This should be existing data, preferably from some open source. The project assumes that we could for example cooperate with some research unit, basically we can assume anything that is within the bounds of common sense - this may be important - we play the role of company that produces Advanced OCT Solutions. We need to feed the algorithm with photos of healthy eyes and of eyes with glaucoma/cataract. And the photos have to be labeled. Any ideas guys?
","['machine-learning', 'ai']",
Scraping sec filings,"
I'm trying to scrap all the historical filings of a particular Central Index Key (CIK) using python but I get http error codes.
First, I got 403 error, I resolved by using requests session and timing the requests every 5 seconds.
Now, I get http 400 after processing 30-40 requests. Not sure how to resolve this.
I have set the user-agent field as well.
","['finance', 'python', 'scraping']",
Dataset for directed graphs classification,"
I want to evaluate some algorithms for the directed graph classification task. Therefore, I'm looking for directed graphs data sets (preferably without node or edge features) as benchmarks.
Do you have any ideas for datasets that could fit?
","['data-request', 'classification']",
Searching for cooking/food ingredients in German,"
I am searching for data in German with the names of cooking ingredients.
The example would be: Milch, Rindfleisch, Tomato, Mayonaisse, Knoblauch, Salz
Nutrient factors (fat, calories) would be a plus, but are not required
","['data-request', 'food', 'germany']",
What is the best way to create private wikidata items,"
I am looking for a way to create new private wikidata items to be integrated with the existing public wikidata.
Example:

Fluffy (Qxxxx) is a (P31) red (Q3142) rabbit (Q9394) stuffed toy (Q682582) .
Poo (Qyyyy) is a (P31) stuffed toy (Q682582).
Fluffy (Qxxxx) is friends with (P3342) Poo (Qyyyy).

What would be the most straightforward way to

create the new items,
populate them with the corresponding properties, and
keep them in an appropriate database in such a way that they may be queried in the same way as the public items are?

(my main programming language is python, so suggestions of existing packages are welcome).
",['wikidata'],
Extracting data from OpenFDA using python to save it locally,"
I have been looking to extract all data from FDA so I can use it all.

I created this code below that works but seems it is too much data it fails. This way it just gives me 25000 records.

url = 'https://api.fda.gov/drug/ndc.json?sort=dea_schedule:desc&limit={}&skip={}'

all_data_df = []

limit = 100
for skip in range(0, total, limit):
    query = url.format( limit, skip)
    print('query:', query)
    data = pd.read_json(query, orient='values', typ='series', convert_dates=False)
    data = data['results']
    all_data_df = pd.DataFrame(all_data_df.append(data))

I need all data. FDA site says to use paging
here the link https://open.fda.gov/apis/paging/
This below will give me the next page that they mention but I am not sure how to do put it together. Any help is appreciated
re = requests.get('https://api.fda.gov/drug/ndc.json?sort=dea_schedule:desc&limit=100')
url =re.links['next']['url']

","['openfda', 'python', 'json']",
Layers with soil properties in the UK,"
I am looking for companies/sources that can provide GIS layers about soil properties (e.g. soil moisture, soil pH, texture, nutrients) at a relatively high resolution (< 500 m pixel) in the UK for research in the Agritech sector. These sources can be either free or paid.
","['data-request', 'geospatial', 'agriculture']",You probably want to start by looking at the UK Soil Observatory run by the British Geological Survey. There is also the National Soil Map and other datasets in the Cranfeld University Land Information System. Both these sources provide online data but may also be able to help you further if you contact them directly.
Race and poverty data at the census block group level?,"
I need 4 pieces of data at the census block group level for the most recent year available:

% non-white population
Poverty rate
% Vacant homes
Per-capita income

From what I can tell, the American Community Survey (ACS) 5-year summary data for 'Tracts_Block_Groups_Only' is the best source for this data, and the following data fields are the ones I'd need:
B01001_001 SEX BY AGE% Total population%Total
B01001A_001 SEX BY AGE (WHITE ALONE)% People who are White alone%Total
B17001_001 POVERTY STATUS IN THE PAST 12 MONTHS BY SEX BY AGE% Population for whom poverty status is determined%Total
B19301_001 PER CAPITA INCOME IN THE PAST 12 MONTHS (IN 2019 INFLATION-ADJUSTED DOLLARS)% Total population%Per capita income in the past 12 months (in 2019 inflation-adjusted dollars)
B25002_001 OCCUPANCY STATUS% Housing units%Total
B25002_003 OCCUPANCY STATUS%Housing units%Total%Vacant
B17001_002 POVERTY STATUS IN THE PAST 12 MONTHS BY SEX BY AGE%Population for whom poverty status is determined%Total%Income in the past 12 months below poverty level 

Of these fields, however, it appears that B01001A_001, B17001_001, B17001_002 are only available at the tract - not block group - level.
I've seen maps and tables in other publications with race and poverty data at the block group level, but can't find it in this dataset. Is there another dataset, or are there other data fields in this dataset, that I should look for?
","['us-census', 'demographics']","The 2015-2019 ACS estimates are your best bet.These tables you can get block group level (sumlevel 150):For non-white population, use table B03002. Subtract B03002003 (white alone, non Hispanic) from the total pop B03002001.For poverty rate, the easiest way to get it by block group is to use table C17002. Add C17002002 + C17002003 for the population with income below poverty, then divide it by the total pop for whom poverty is determined, C17002001.You should have no trouble using B25002 for vacancyPer capita income is table B19301, variable B19301001"
Web pages graph data sets,"
Is anyone aware of any web graph datasets, such that the nodes represent the webpages and the link represent the URLS? I am looking for a dataset which has node attributes. I have found many datasets, but not sure if they have provided the node attributes (as I'm new to Graph Theory).
The node attributes should basically represent the features of the web pages.
Thanks
","['data-request', 'metadata', 'network-structure']",
High Resolution Digital Elevation Model for recent years,"
Where do I find SRTM or sentinel's high resolution DEMs for recent years? USGS is only giving the data till 2014, and I need at least for 2019. I've even tried sentinel hub but the cloud cover is too much for recent years.
","['data-request', 'geospatial', 'remote-sensing']",
Where can a list of popular recording artists and their songs be downloaded,"
I'm trying to find a list of popular recording artists and their songs (not the actual music, but their names and titles).  The list could be a simple ascii file, or csv or spreadsheet, or even an sqlite file, anything that I can download as a single file and isn't a proprietary format that requires costly software. Also, I'm familiar with Billboards website, RIAA's Gold and Platinum list and Wikipedia's various lists.  I've also found enormous databases that are hundreds of gigabytes in size and talk of a million songs, but I haven't figured out how to use it.  The entire Bible is 4.13MB in byte size, so I figure if the file is over a gigabyte then it has a lot of extraneous data, perhaps audio or video or some other data.  I'm interested in text data, not audio or video.
My ultimate goal is simple.  I'm trying to find an early 70s song from youth that I heard over and over.  It had a fast lively energetic beat at it's climax, and definitely wasn't a slow ballad.  But I haven't heard it again since.  It was probably in about 1974 but could have been recorded earlier than that.  It was popular on AM contemporary listening radio, but I haven't heard it a single time since the 70s.  I'd like to find it again.
So, I want to collect a list of songs, weed through them one by one, and eventually find it.  Neil Diamond, Tony Orlando, BJ Thomas were artists that I thought it might have been, but so far I haven't discovered it.
Here are some examples of song data I've already discovered:
WIKIPEDIA -- they have a plethora of lists. However, they are usually by year and genre --
https://en.wikipedia.org/wiki/List_of_Billboard_number-one_adult_contemporary_hits
(this is a directory to links specific to each there. there are a plethora of similar lists for other genres on WIKIPEDIA)
I need a portable file, but here's is a link to a 300GB ""million song dataset"" billed to run on an AWS cloud server:
http://millionsongdataset.com/pages/getting-dataset/
",['music'],The following Kaggle dataset contains csv files of around 600k audio tracks with associated artists' names:https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks
Do you know any dataset about color harmonies?,"
I am working on a model to assess color harmonies (given a set of colors, output an evaluation of their harmony).
Do you know any dataset of images (real or artificial) that contain information about color harmonies?
",['images'],
Q1 2021 Drug Event Endpoint Update,"
It looks like the Q1 2021 FAERS release was posted on 10-May-2021. Does anyone know when openFDA will refresh its Drug Event endpoint to include the new data? I know this typically occurs once a week, so hopefully soon?
TIA
",['openfda'],
Is there a dataset with time series on water consumption for household needs in Russia?,"
I have time series data about water consumption by day and hour in all of the apartments in a specific residential building located in Moscow, Russia. It covers the time period from 1st of January 2006 to 10th of February 2006. The example output of pandas DataFrame for hot water consumption (in liters):
                 Time  1   2  3  4  5    6  7  ...   77  78  79  80  81  82  83  84
0     01.01.2006 0:00  0   0  0  0  0    0  0  ...    0   0   0   0   0   0  40   0
1     01.01.2006 1:00  0   0  0  0  0    0  0  ...    0   0   0   0  40  10   0   0
2     01.01.2006 2:00  0  30  0  0  0    0  0  ...    0  20   0   0   0   0   0   0
3     01.01.2006 3:00  0   0  0  0  0    0  0  ...    0   0   0   0   0   0   0   0
4     01.01.2006 4:00  0   0  0  0  0   10  0  ...    0   0   0   0   0   0   0   0
..                ... ..  .. .. .. ..  ... ..  ...  ...  ..  ..  ..  ..  ..  ..  ..
979  10.02.2006 19:00  0  20  0  0  0   20  0  ...  120   0   0   0   0  10   0   0
980  10.02.2006 20:00  0  10  0  0  0   20  0  ...    0   0   0  20   0  10  30   0
981  10.02.2006 21:00  0  70  0  0  0  110  0  ...   10  20  10   0  10  80  10   0
982  10.02.2006 22:00  0   0  0  0  0   10  0  ...    0  50   0  30   0  40   0   0
983  10.02.2006 23:00  0   0  0  0  0   10  0  ...   10   0   0   0   0  10  40   0

Every column except the first (Time) marks the apartment number. The values in the Time column have a period of one hour. At the intersection of rows and columns there is the amount of water distributed to the specific apartment in the last hour. For example, a cell with timestamp 01.01.2006 2:00 in column 2 indicates that at 1st of January 2006 apartment 2 has consumed 30 liters of hot water between 1 pm and 2 pm.
Original dataset also has a count of registered residents in each apartment, which is not included in the example above. The cold water consumption dataframe looks the same.
In the process of developing the Python application I got to the point where I need to analyze more data.
I am looking for a dataset that covers at least a whole year (to analyze the seasonality) and includes more than a single building (to assign some of the results to buildings with certain characteristics).
So, the needs are as follows:

Daily or hourly data, the shorter the period, the better
Two buildings or more, preferably with the basic characteristics about each building (e.g. the number of registered residents in each apartment, level of quality, location) or with some info through which I can get these characteristics (e.g. address)
It has to be Russian, but any other country will be helpful too in some way

The type of water (cold or hot) doesn't really matter.
I am open to the data with totally not the same structure as in the example above, because the requirements are already strong enough.
","['data-request', 'time-series', 'russia', 'buildings']",
Public domain worldmap image showing Exclusive Economic Zones (water around islands etc),"
I am looking for a public domain version of this image:

Requirements:

Raster or vector image (PNG, TIFF, SVG, etc)
Public domain (or MIT license, CC0)
Shows Exclusive Economic Zones of each country separately. For instance, you can tell whether a pixel in the sea ""belongs"" to USA or Mexico.
Also shows countries and their limits.

It can also be territorial waters, contiguous zone, or continental shelf, as long as the whole image is coherent.
(Map above is Creative Commons Attribution-Share Alike 3.0 Kvasir at English Wikipedia)
","['data-request', 'geospatial', 'oceanographic']",
How can I get the English Wikipedia Corpus?,"
I am using this model for word embeddings trained using word2vec, I want to get the embedding using GloVe to compare the performance. The model is trained using the English Wikipedia corpus, nevertheless, I have not found such a dataset online. Does anyone knows where can I find the dataset?
",['data-request'],"Have a look at this page from the ""DBpedia"" project which show everything in great detail. DBpedia is a subset  of Wikipedia.Downloadable Files are given in Turtle format (.ttl, compressed as .bz2) which is a plain-text file format.For more expert advice I would ask around on the Wikidata Telegram group - the Wikipedia and Wikidata developers hang around there, AFAIK."
get info on all catholic churches in Europe,"
i 'm looking to get info on all catholic churches in Europe. Specifically, I'd love to get:
their address
Denomination
Active/Not
Contact Info (website, email, phone)
and any other info I can get.
well we ve got several approaches:

use overpass-tubro.eu;
we can get a list of all ""places of worship"" by downloading bulk osm files from geofabrik.de and then using use osmfilter or osmosis to select only certain tags, for example: wiki.openstreetmap.org/wiki/Tag:amenity=place_of_worship


to use the Open StreetMap data with Nominatom for a base file. This
should get the #1 and then we can get #2 just by text mining their
titles. For #3 I believe the closest you'll get is just to use the
most recent available data. For #4 I think we'd need to do original
data scraping from the Internet - at least to get their websites (I'm
not sure on this one, actually).

btw: see a List of Catholic dioceses (structured view)
https://en.wikipedia.org/wiki/List_of_Catholic_dioceses_(structured_view)#Episcopal_Conference_of_France

As of May 31, 2018, the Catholic Church in its entirety comprises
3,160 ecclesiastical jurisdictions, including over 645 archdioceses
and 2,236 dioceses,  as well as apostolic vicariates, apostolic
exarchates, apostolic administrations, apostolic prefectures, military
ordinariates, personal ordinariates,  personal prelatures, territorial
prelatures, territorial abbacies and missions sui juris around the
world.

do you know more ways to go ahead and find the appropiate dataset
","['geospatial', 'openstreetmap']",
Avian phylogenetic trees,"
I am looking for a phylogeny of old-world vultures that would be downloaded into R for a project.
I am not an expert on this kind of data, and my research has not been successful so far. Does someone know if this kind of dataset exists somewhere? A larger tree would also do the job (e.g. a tree of all raptors) as long as the level of precision is species.
",['data-request'],"A good start when you want a phylogeny that includes specific species is to use the NCBI Taxonomy Common Tree tool: https://www.ncbi.nlm.nih.gov/Taxonomy/CommonTree/wwwcmt.cgiIt allows you to specify 2 or more species. You specify the species by searching their binomials or TAXIDs one by one to add them, or upload a text file with one species binomial per line. It then produces the shared phylogeny that connects the entire set of species.In your case you want the 16 species of Old World vultures. Wikipedia has them in a list here. I right clicked to inspect element, then extracted the species with this code:Producing this list:I uploaded that list to CommonTree, and here's your tree:In Phylip format (which you can load in most phylogenetic tools, or convert easily:There are lots of other ways to achieve this but the NCBI tools are extremely useful to know about. The TAXIDs from NCBI can be used to pull data using many of the R packages for phylogenetics."
S&P 500 index actual official stock weights,"
Where can I found on https://spglobal.com S&P 500 index actual official stock weights.
","['data-request', 'finance']",
USA Residential Electricity Prices,"
EDITED QUESTION to add context:
I'm interested in ""modeling"" the Electricity Price for Residential Users in the US, particularly (if possible) in Massachusetts.
I'd like to obtain something like a 24 hourly-prices list for every day of the year.
To relax this constraint, I could also accept a list of 24 hourly-prices per month, or even just per season.
And, to relax even more, I could also accept a resolution greater than 1 hour.
E.g.: resolution = 4 hours:
so, instead of having a price for each hour of the day, I could accept a single price for an interval of 4 hours (so 6 prices per day).
So, I'm looking for something similar to the dataset of this link: https://data.open-power-system-data.org/time_series/2020-10-06.
It consists of a CSV file which collects hourly electricity prices 32 European countries, but I'm interested in the US.
Another way could also be to find scientific papers (or other sources) which model the electricity price associated to every hour of the day (this time interval could be relaxed) in the US as a PDF, by providing the 'mean' and the 'standard deviation' (or any other parameter which describe the PDF).
Is there anyone who knows any reference (papers, dataset, link, ...) which could be useful?
","['data-request', 'usa', 'historical', 'time-series', 'energy']","I believe the closest you can get is a monthly average retail price. The Energy Information Agency provides a monthly report on average retail price of electricity by state (note that EIA has an API if you want to access this data programmatically):As mentioned in the comments, it's unlikely that any significant amount of residential customers in Massachusetts are on a rate that would change during the course of the day. To confirm, you could get a list of Massachusetts utilities (xlsx) from EIA, then check their rates at USURDB. I spot checked and see that there are a few optional TOU rates at a couple of the larger utilities. However, according to this 2017 study, only about 3% of customers are using TOU rates where they are offered."
"is there source code on github with a neural network that animates photos, making photos moving pictures like in a video","
is there source code on github with a neural network that animates photos, making photos moving pictures like in a video? For example somithing similar on Deep Nostalgia (https://www.myheritage.com/deep-nostalgia?lang=EN)
","['data-request', 'open-source', 'git']",
Is there an open data somewhere that has information on musical bands,"
I am looking for information on musical bands with attributes like genre and members of the bands, etc.
",['music'],Have a look at https://musicbrainz.org. I think it has what you're looking for.
"Where do I find a database of each city in the world and the languages spoken there? (Ex. Barcelona - Catalan, Spanish vs. Madrid - Spanish)","
I'm looking to set up a dropdown of languages once the app picks up the city a person is in. Where would I find this database or API?
","['data-request', 'language', 'city']",
Can I use openFDA API for Drugs side effects?,"
Is there any way to get Drugs side effect for specific drug name like Paxil from openFDA API. I read the documentation but don't really understand
","['api', 'openfda', 'drugs']",
Seeking Elevation Data,"
I'm trying to get elevation data and I have no idea where to look. I'm basically trying to get where land is above a certain elevation.
I'm primarily concerned with where land is above X' in Washington State and a kml file would be easiest for me to use.
Are there freely available websites or software programs where I can get this data?
","['data-request', 'geospatial', 'usa', 'kml']",
Where can I find a database with edible plants?,"
I'm building an web-application where users can add plants they want to grow in a list!
So my user would type, for example Oregano, and using that keyword i should be able to collect info regarding that specific plant!
What I'm looking for is a database where I can collect information regarding edible plants such as:

Temperature needed
Humidity needed
Water consumption
Light needed
Soil required
Habitat needed (i.e. African continent)
...

PS: I'm not sure if this is the right forum, I don't know what tags to use for this question. I would prefer if the data was in JSON format! Please be nice.

UPDATE:
I wrote a javascript application to get wiki data for the keyword OREGANO, and this is what I get back. I obviously can't work with this because each page would result differently. I only need parameters, such as Low_Temperature: 20,  High_Temperature: 34, Light: Partial Shade or something similar!
{{Short description|Perennial herb}}
{{Other uses}}
{{Use dmy dates|date=May 2012}}
{{Speciesbox
|image = Origanum vulgare - harilik pune.jpg
|image_caption = Flowering oregano
|genus = Origanum
|species = vulgare
|authority = [[Carl Linnaeus|L.]]
}}

'''Oregano''' ({{IPAc-en|US|ɔː|ˈ|r|ɛ|g|ə|n|oʊ|,_|ə|-}},<ref name=""Collins"">{{cite web|url=http://www.CollinsDictionary.com/dictionary/american/oregano?showCookiePolicy=true|title=American: Oregano|access-date=25 September 2014|publisher=Collins Dictionary|date=n.d.}}</ref> {{IPAc-en|UK|ˌ|ɒr|ɪ|ˈ|ɡ|ɑː|n|əʊ}};<ref name=""Collins2"">{{cite web|url=http://www.CollinsDictionary.com/dictionary/english/oregano?showCookiePolicy=true|title=British: Oregano|access-date=25 September 2014|publisher=Collins Dictionary}}</ref> '''''Origanum vulgare''''') is a [[flowering plant]] in the [[mint family]] (Lamiaceae). It is native to [[temperate]] Western and Southwestern [[Eurasia]] and the [[Mediterranean]] region.

Oregano is a [[Perennial plant|perennial]] [[herb]], growing from {{convert|20|–|80|cm|in|0|abbr=on}} tall, with [[opposite leaves]] {{convert|1|–|4|cm|in|frac=4|abbr=on}} long. The [[flower]]s are purple, {{convert|3|–|4|mm|in|frac=16|abbr=on}} long, produced in erect spikes. It is sometimes called '''wild marjoram''', and its close relative, ''[[Origanum majorana|O. majorana]]'', is known as '''sweet marjoram'''.

==Etymology==
Used since the middle [[18th century]], ''oregano'' is derived from the [[Spanish (language)|Spanish]] ''orégano'' and [[Latin]] ''orīganum'' from the [[Classical Greek]] {{lang|grc|ὀρίγανον}} (''orī́ganon'').<ref name=""oed"">{{cite web|url=http://www.etymonline.com/index.php?term=oregano|title=Oregano|publisher=Online Etymology Dictionary, Douglas Harper, Inc. |access-date=6 October 2016}}</ref> This is a compound Greek term that consists of {{lang|grc|ὄρος}} (''óros'') meaning ""mountain"", and {{lang|grc|γάνος}} (''gános'') meaning ""brightness"", thus, ""brightness of the mountain"".<ref name=oed/>

==Description and biology==
Oregano is related to the herb [[marjoram]], sometimes being referred to as wild marjoram. It has purple flowers and spade-shaped, olive-green leaves. It is a perennial,<ref name=""W21"">{{cite web|url=http://plants.usda.gov/java/profile?symbol=ORVU|title=Origanum vulgare L. oregano|publisher=Plants Database, United States Department of Agriculture|access-date=30 January 2011}}</ref><ref name=""W1"">{{cite web|url=http://www.omafra.gov.on.ca/english/crops/facts/02-049.htm|title=Growing Culinary Herbs In Ontario|publisher=Ontario Ministry of Agriculture, Food & Rural Affairs|access-date=30 January 2011|archive-url=https://web.archive.org/web/20100719222438/http://www.omafra.gov.on.ca/english/crops/facts/02-049.htm|archive-date=19 July 2010|url-status=dead}}</ref> although it is grown as an annual in colder climates, as it often does not survive the winter.<ref name=""B266"">{{cite book|last=Peter|first=K. V.|title=Handbook of herbs and spices|chapter-url =https://books.google.com/books?id=jITovbFEuO8C&pg=PA215|access-date =30 January 2011|volume=2|year=2004|publisher=Woodhead Publishing Limited|location=Abington Hall, Abington|isbn=1-85573-721-3|page=219|chapter =14.3.1 Growth habit of wild oregano populations}}</ref><ref name=""aW1"">{{cite web|url=http://www.agriculture.gov.sk.ca/Default.aspx?DN=b1d5ac77-718e-45d1-9aec-ccc6d293e4a1|title=Herbs|date=September 2009|publisher=Government of Saskatchewan|access-date=30 January 2011|archive-url=https://web.archive.org/web/20111003060853/http://www.agriculture.gov.sk.ca/Default.aspx?DN=b1d5ac77-718e-45d1-9aec-ccc6d293e4a1|archive-date=3 October 2011|url-status=dead}}</ref>
Oregano is planted in early spring, the plants being spaced {{convert|12|in|cm|order=flip|abbr=on|sigfig=1}} apart in fairly dry soil, with full sun. It will grow in a pH range between 6.0 (mildly acidic) and 9.0 (strongly alkaline), with a preferred range between 6.0 and 8.0. It prefers a hot, relatively dry climate, but does well in other environments.<ref>{{Cite web|url=http://www.omafra.gov.on.ca/CropOp/en/herbs/culinary/orega.html|title=Oregano and Marjoram|publisher=Ontario Ministry of Agriculture, Food and Rural Affairs, Guelph, Canada|date=17 October 2012|access-date=31 January 2017}}</ref>

==Taxonomy==
[[File:Majorana syriaca - za'atar.jpg|thumb|right|[[Syrian oregano]] (''Origanum syriacum'')]]
[[File:Bombus lucorum - Origanum vulgare - Keila.jpg|thumbnail|Pollination with [[white-tailed bumblebee]]]]
[[File:S oregano.png|thumb|Oregano leaves]]
[[File:Origanum vulgare young plant 2.JPG|thumb|right|Young plant]]
Many subspecies and strains of oregano have been developed by humans over centuries for their unique flavours or other characteristics. Tastes range from spicy or astringent to more complicated and sweet. Simple oregano sold in garden stores as ''Origanum vulgare'' may have a bland taste and larger, less-dense leaves, and is not considered the best for culinary use, with a taste less remarkable and pungent. It can pollinate other more sophisticated strains, but the offspring are rarely better in quality.

The related species, ''[[Origanum onites]]'' (Greece, Turkey) and ''O. syriacum'' (West Asia), have similar flavours. A closely related plant is marjoram from Turkey, which differs significantly in taste though, because [[natural phenol|phenolic compounds]] are missing from its essential oil. Some varieties show a flavour intermediate between oregano and marjoram.

===Subspecies===
Accepted subspecies:<ref>{{cite web|url=http://apps.kew.org/wcsp/namedetail.do?name_id=143954|title=Oregano, ''Origanum vulgare'' L.|publisher=Kew World Checklist of Selected Plant Families, Royal Botanic Gardens, Kew, Richmond, Surrey, UK|date=2017}}</ref>
# ''O. v.'' subsp. ''glandulosum'' <small>(Desf.) Ietsw.</small> – Tunisia, Algeria
# ''O. v.'' subsp. ''gracile''  <small>(K.Koch) Ietsw.</small> (= ''O. tyttanthum'')  has glossy green leaves and pink flowers. It grows well in pots or containers, and is more often grown for added ornamental value than other oregano. The flavor is pungent and spicy.<ref name=drugs/> – Central Asia, Iran, India, Turkey, Afghanistan, Pakistan. 
# ''O. v.'' subsp. ''hirtum''  <small>(Link) Ietsw.</small> – (Italian oregano, Greek oregano) is a common source of cultivars with a different aroma<ref name=drugs/> from those of ''O. v. gracile''. Growth is vigorous and very hardy, with darker green, slightly hairy foliage. Generally, it is considered the best all-purpose culinary subspecies. – Greece, Balkans, Turkey, Cyprus
# ''O. v.'' subsp. ''virens'' <small>(Hoffmanns. & Link) Ietsw.</small> – Morocco, Spain, Portugal, Balearic Islands, Canary Islands, Azores, Madeira
# ''O. v.'' subsp. ''viridulum'' <small>(Martrin-Donos) Nyman</small> – widespread from Corsica to Nepal 
# ''O. v.'' subsp. ''vulgare'' – widespread across Europe + Asia from Ireland to China; naturalized in North America + Venezuela

===Cultivars===
Example [[cultivars]] of oregano include:
* 'Aureum' – golden foliage (greener if grown in shade), mild taste: It has gained the [[Royal Horticultural Society]]'s [[Award of Garden Merit]]<ref>{{cite web|title=RHS Plant Selector – ''Origanum vulgare'' 'Aureum'|url=https://www.rhs.org.uk/Plants/89773/Origanum-vulgare-Aureum/Details | access-date = 16 January 2021}}</ref> 
* 'Greek Kaliteri' – ''O. v.'' subsp. ''hirtum'' strains/[[landrace]]s, small, hardy, dark, compact, thick, silvery-haired leaves, usually with purple undersides, excellent reputation for flavor and pungency, as well as medicinal uses, strong, archetypal oregano flavor ([[Greek (language)|Greek]] ''kaliteri'': the best)
* 'Hot & Spicy' – ''O. v.'' subsp. ''hirtum'' strain
* 'Nana' – dwarf cultivar
Cultivars traded as Italian, Sicilian, etc. are usually hardy sweet marjoram ([[Origanum ×majoricum|''O.'' ×''majoricum'']]), a [[hybrid (biology)|hybrid]] between the southern [[Adriatic]] ''O. v.'' subsp. ''hirtum'' and sweet marjoram (''O. majorana''). They have a reputation for sweet and spicy tones, with little bitterness, and are prized for their flavor and compatibility with various recipes and sauces.

==Uses==
{{more citations needed section|date=November 2017}}

===Culinary===
[[File:Oregano (অরেগানো).JPG|thumb|Dried Oregano Leaves]]

Oregano is a culinary herb, used for the flavor of its leaves, which can be more flavorful when dried than fresh. It has an [[aroma]]tic, warm, and slightly [[Bitter (taste)|bitter]] taste, which can vary in intensity. Good-quality oregano may be strong enough almost to numb the tongue, but cultivars adapted to colder climates may have a lesser flavor. Factors such as climate, season, and soil composition may affect the aromatic oils present, and this effect may be greater than the differences between the various species of plants. Among the chemical compounds contributing to the flavour are [[carvacrol]], thymol, [[limonene]], [[pinene]], [[ocimene]], and [[caryophyllene]].<ref>{{cite journal |doi=10.1016/S0031-9422(00)00474-X |pmid=11336262 |title=The essential oil of Origanum vulgare L. Ssp. Vulgare growing wild in Vilnius district (Lithuania) |journal=Phytochemistry |volume=57 |issue=1 |pages=65–9 |year=2001 |last1=Mockute |first1=Danute |last2=Bernotiene |first2=Genovaite |last3=Judzentiene |first3=Asta }}</ref>

Oregano's most prominent modern use is as the staple herb of [[Italian cuisine]]. Its popularity in the U.S. began when soldiers returning from [[World War II]] brought back with them a taste for the ""pizza herb"", which had probably been eaten in southern Italy for centuries.<ref>{{cite news |last=Martyris |first=Nina |date=May 9, 2015 |title=GIs Helped Bring Freedom To Europe, And A Taste For Oregano To America |url=https://www.npr.org/sections/thesalt/2015/05/09/405302961/gis-helped-bring-freedom-to-europe-and-a-taste-for-oregano-to-america |publisher=[[NPR]] |access-date=May 28, 2018}}</ref> There, it is most frequently used with roasted, fried, or grilled vegetables, meat, and fish. Oregano combines well with spicy foods popular in southern Italy. It is less commonly used in the north of the country, as marjoram generally is preferred.

The herb is widely used in [[cuisine]]s of the [[Mediterranean Basin]] and [[Latin American cuisine|Latin America]], especially in [[Argentine cuisine]].

In Turkish cuisine, oregano is mostly used for flavoring meat, especially for [[mutton]] and lamb. In barbecue and [[kebab]] restaurants,{{Clarify|reason=does this refer to a restaurant in Turkey that serves various kebab dishes, or a [[kebab shop]] that sells fast-food [[Doner kebab]]?|date=May 2016}} it can be usually found as a [[condiment]], together with [[paprika]], salt, and pepper.

During the summer, generous amounts of dried oregano are often added as the aromatic and flavorful topping to a tomato and cucumber salad in [[Portugal]], but it can be used to season meat and fish dishes as well.

The dried and ground leaves are most often used in Greece to add flavor to [[Greek salad]], and is usually added to the lemon-olive oil sauce that accompanies fish or meat grills and [[casserole]]s.

===Oregano oil===
[[File:OreganoEssentialOil.png|thumb|Oregano essential oil in a clear glass vial]]

Oregano oil has been used in [[Traditional medicine|folk medicine]] over centuries.<ref name=""drugs"">{{cite web | url=https://www.drugs.com/npp/oregano.html | title=Oregano | publisher=Drugs.com | date=2016 | access-date=7 October 2016}}</ref> Oregano essential oil is extracted from the leaves of the oregano plant. Although oregano or its oil may be used as a [[dietary supplement]], there is no clinical evidence to indicate that either has any effect on human health.<ref name=drugs/><ref name=""mp"">{{cite web | url=https://medlineplus.gov/druginfo/natural/644.html | title=Oregano | publisher=MedlinePlus, US National Library of Medicine | date=2016 | access-date=7 October 2016}}</ref>

In 2014, the US [[Food and Drug Administration]] (FDA) warned a [[Utah]] company, [[Young Living]], that its herbal products, including oregano [[essential oil]], were being promoted to have numerous unproven anti-disease effects, and so were being sold as unauthorized misbranded [[prescription drug|drugs]] subject to seizure and federal penalties.<ref name=""fda"">{{cite web|url=https://www.fda.gov/inspections-compliance-enforcement-and-criminal-investigations/warning-letters/young-living-09222014|title=Warning Letter: Young Living|author=LaTonya M. Mitchell|publisher= Inspections, Compliance, Enforcement, and Criminal Investigations, US Food and Drug Administration|date=22 September 2014|access-date=7 October 2016}}</ref> Similar FDA [[FDA warning letter|warning letters]] for false advertising and unproven [[health claim]]s about oregano essential oil products were published in 2017 and 2018.<ref name=""fda2"">{{cite web|url=https://www.fda.gov/inspections-compliance-enforcement-and-criminal-investigations/warning-letters/absonutrix-508557-07252017|title=Warning Letter: Absonutrix|author=Ingrid A. Zambrana|publisher= Inspections, Compliance, Enforcement, and Criminal Investigations, US Food and Drug Administration|date=25 July 2017|access-date=18 May 2019}}</ref><ref name=""fda3"">{{cite web|url=https://www.fda.gov/inspections-compliance-enforcement-and-criminal-investigations/warning-letters/long-life-unlimited-533282-01312018|title=Warning Letter: Long Life Unlimited|author=Kimberly L. McMillan|publisher= Inspections, Compliance, Enforcement, and Criminal Investigations, US Food and Drug Administration|date=31 January 2018|access-date=18 May 2019}}</ref>

==Chemical components==
Oregano contains [[polyphenol]]s, including numerous [[flavone]]s.<ref name=""Dragland2003"">{{cite journal|url=http://jn.nutrition.org/cgi/pmidlookup?view=long&pmid=12730411|last1=Dragland|first1=Steinar|last2=Senoo|first2=Haruki |last3=Wake|first3=Kenjiro|last4=Holte|first4=Kari|last5=Blomhoff|first5=Rune|title=Several culinary and medicinal herbs are important sources of dietary antioxidants|journal=Journal of Nutrition|volume=133|issue=5|pages=1286–90|date=1 May 2003|doi=10.1093/jn/133.5.1286|issn=0022-3166|pmid=12730411|doi-access=free}}</ref><ref>{{cite journal|doi=10.1080/14786419.2014.896011|pmid=24635145|title=Origanum species native to the island of Crete: in vitro antioxidant characteristics and liquid chromatography–mass spectrometry identification of major polyphenolic components|journal=[[Natural Product Research]]|volume=28|issue=16|pages=1284–7|year=2014|last1=Tair|first1=Asma|last2=Weiss|first2=Erika-Krisztina|last3=Palade|first3=Laurentiu Mihai|last4=Loupassaki|first4=Sofia|last5=Makris|first5=Dimitris P.|last6=Ioannou|first6=Efstathia|last7=Roussis|first7=Vassilios|last8=Kefalas|first8=Panagiotis|s2cid=42500633}}</ref>

The essential oil of oregano is composed primarily of [[monoterpenoid]]s and [[monoterpenes]], with the relative concentration of each compound varying widely across geographic origin and other factors. Over 60 different compounds have been identified, with the primary ones being carvacrol and [[thymol]] ranging to over 80%, while lesser abundant compounds include [[p-cymene|''p''-cymene]], [[γ-terpinene]], caryophyllene, [[spathulenol]], [[germacrene D]], [[β-fenchyl alcohol]] and [[δ-terpineol]].<ref>{{cite journal|doi=10.1002/jsfa.6089|pmid=23553824|title=Chemical composition and bioactivity of different oregano (''Origanum vulgare'') extracts and essential oil|journal=[[Journal of the Science of Food and Agriculture]]|volume=93|issue=11|pages=2707–14|year=2013|last1=Teixeira |first1=Bárbara|last2=Marques|first2=António|last3=Ramos|first3=Cristina|last4=Serrano|first4=Carmo|last5=Matos|first5=Olívia |last6=Neng|first6=Nuno R|last7=Nogueira|first7=José M F|last8=Saraiva|first8=Jorge Alexandre|last9=Nunes|first9=Maria Leonor}}</ref>

Drying of the plant material affects both quantity and distribution of volatile compounds, with methods using higher heat and longer drying times having greater negative impact. A sample of fresh whole plant material found to contain 33 g/kg dry weight (3.1 g/kg wet) decreased to below a third after warm-air convection drying. Much higher concentrations of volatile compounds are achieved towards the end of the growing season.<ref>{{cite journal|doi=10.1016/j.jfoodeng.2010.01.002|title=Composition of oregano essential oil (Origanum vulgare) as affected by drying method|journal=[[Journal of Food Engineering]]|volume=98|issue=2|pages=240–7|year=2010|last1=Figiel |first1=Adam|last2=Szumny|first2=Antoni|last3=Gutiérrez-Ortíz|first3=Antonio|last4=Carbonell-Barrachina|first4=Ángel A.}}</ref>

==Other plants called ""oregano""==

* ''[[Coleus amboinicus]]'', known as Cuban oregano, {{lang|es|orégano poleo}} ('[[Hedeoma|pennyroyal]] oregano'), {{lang|fr|orégano francés}} ('French oregano'), Mexican mint, Mexican thyme, and many other names, is also of the mint family (Lamiaceae).  It has large and somewhat [[succulent]] leaves.  Common throughout the tropics, including Latin America, Africa, and Southeast Asia, it is probably of eastern-hemisphere origin.
* ''[[Lippia graveolens]]'', Mexican oregano, known in Spanish as {{lang|es|orégano cimarrón}} ('wild oregano'), is not in the mint family, but in the related [[vervain family]] (Verbenaceae). The flavor of Mexican oregano has a stronger savory component instead of the piney hint of rosemary-like flavor in true oregano, and its citrus accent might be more aromatic than in oregano. It is becoming more commonly sold outside of Mexico, especially in the southeastern United States. It is sometimes used as a substitute for [[epazote]] leaves.<!-- Move most of this material – to the extent any of it can be sourced – to the article on that plant. See WP:COATRACK. -->
* ''[[Hedeoma patens]]'', known in Spanish as {{lang|es|orégano chiquito}} ('small oregano'), is also among the Lamiaceae.  It is used as an herb in the Mexican states of [[Chihuahua (state)|Chihuahua]] and [[Coahuila]].

==See also==
* ''[[Thymus vulgaris]]'', thyme

==References==
{{Reflist|30em}}

==External links==
{{Commons|Origanum vulgare}}
{{Wikiquote}}
* [http://rbg-web2.rbge.org.uk/cgi-bin/nph-readbtree.pl/feout?FAMILY_XREF=&GENUS_XREF=Origanum+&SPECIES_XREF=vulgare&TAXON_NAME_XREF=&RANK= Flora Europaea: ''Origanum vulgare'']
* [https://www.ars-grin.gov/cgi-bin/npgs/html/taxon.pl?25913 Germplasm Resources Information Network: ''Origanum vulgare'']

{{Herbs & spices}}
{{Medicinal herbs & fungi}}
{{Transient receptor potential channel modulators}}
{{Taxonbar|from=Q134283}}
{{Authority control}}

[[Category:Flora of Asia]]
[[Category:Flora of Europe]]
[[Category:Herbs]]
[[Category:Medicinal plants]]
[[Category:Origanum]]
[[Category:New Mexican cuisine]]
[[Category:Plants described in 1753]]

","['database', 'json']",
Looking for Ratings in a female dominated game by gender,"
I have examined the male to female average rating difference in chess
To determine if women are inherently worse at chess (on average) or if there is just a selective bias against them, I would now like to evaluate ratings in a similar female dominated game, but I am having trouble finding any (with available gendered ratings).
Could anybody point me to a usable dataset?
","['data-request', 'sports', 'demographics', 'games']",
Data on age demographics by individual age for some uniformly distributed measure,"
tl;dr: I'm looking for data on age demographics in the US for individual ages on some characteristic/measure that is reasonably ""smooth"" across the population. In other words, no sharp distinction like ""number who drink"" where we'll see a huge change at the drinking age, or ""number of unemployed"" where we'll see a huge change at ~60yrs.
Ideally something within the past 10yrs and for an even year (aligns with election data I already have).
That said, I'll take what I can get, and data on individual ages has been hard to find, period.
This is my first post here, so if context is appreciate on this site, see below. Otherwise, this is the short and sweet request!

I recently read a theory on voter fraud with the core finding being that one could predict votes cast from registered voters, claiming that the resemblance between the shapes of the two curves is too similar to be accidental.
I believe this is an age-based analog of this xkcd cartoon, and that the ""illusion"" (i.e. this ""wow"" factor on shape alignment between two curves) stems from the fact that we never see data for individual age demographics plotted.
I did find it for all elections going back to 2000 to show that VAP, VEP, registrations, and all curves always match in shape. No surprises, as of those who exist some smooth % multiplier across the ages tracks with those who register and vote (from that same population).

Now I'd like to find some preposterous dataset on individual age, showing that you can correlate any data along age demographics with any other data on age demographics because both track to the parent population (kind of like ""any activity tends to happen more in summer, which is why burlaries and ice cream eating both go up"").
That said, it needs to be something that is relatively ""smooth"" across each age. No sharp changes for e.g. drinking age or retirement. Perhaps the number of people by age who: visit the doctor, drive, travel out of state/country, get a passport, buy stock, watch youtube... anything like that where given some age being higher than average compared to neighboring ages, this disproportionate spike will carry through in the measure as well.
","['usa', 'demographics']",
(Drug API with NDC) Drug name with specified strength & NDC Error,"
Our website is a platform for patients to consult with physicians and specialists on-demand.
The doctors will be able to search for the drug name though the database (NDCID drug database integrated in our system i.e open FDA API ). Through this subsection the doctor will be able to verify Allergy details and Active medication; add drug name and strength. The same info will be pushed to e-prescription (third party) platform where doctors will write the prescription for patient and send to pharmacy.
We have implemented Drug API with NDC dictionary to get all drug databases into our system.
API End point - https://api.fda.gov/drug/ndc.json?search=finished:true&limit=1
Problem Statement –
As per requirement, we need to allow Doctors to add drug strength for the respective drugs. While integrating the open FDA API, we reviewed the available response for the API for locating the drug strength, but were unable to find the same.
We need drug information along with its strength & 11 digit NDC code(packaging NDC). We have illustrated problem statement with following example.
Eg. Consider drug with name ""Lovastatin"". For this drug we need detail information like below.
Lovastatin tablet (generic)
10 mg
20 mg
40 mg
Lovastatin tablet extended release 24 hr
20 mg
40 mg
60 mg
When we are pulling drug information using NDC API endpoint then we are getting appx. 72 records with brand_name ""Lovastatin"". This drug information contains values like packaging, active ingredients, brand name, generic name. But not the strength like 10mg, 20mg along with NDCs (packaging code).
Sample API Result from Open FDA  for one of the ""Lovastatin"" drug found (out of 72).
    ""_id"" : ObjectId(""601930da98fbb123706a4c94""), 
    ""product_ndc"" : ""70518-0194"", 
    ""generic_name"" : ""Lovastatin"", 
    ""labeler_name"" : ""REMEDYREPACK INC."", 
    ""brand_name"" : ""Lovastatin"", 
    ""active_ingredients"" : [
        {
            ""name"" : ""LOVASTATIN"", 
            ""strength"" : ""10 mg/1""
        }
    ], 
    ""finished"" : true, 
    ""packaging"" : [
        {
            ""package_ndc"" : ""70518-0194-0"", 
            ""description"" : ""90 TABLET in 1 BOTTLE, PLASTIC (70518-0194-0)"", 
            ""marketing_start_date"" : ""20170202"", 
            ""sample"" : false, 
            ""ndcid"" : ""70518019400""
        }, 
        {
            ""package_ndc"" : ""70518-0194-1"", 
            ""description"" : ""30 TABLET in 1 BLISTER PACK (70518-0194-1)"", 
            ""marketing_start_date"" : ""20171004"", 
            ""sample"" : false, 
            ""ndcid"" : ""70518019401""
        }
    ], 
    ""listing_expiration_date"" : ""20211231"", 
    ""openfda"" : {
        ""manufacturer_name"" : [
            ""REMEDYREPACK INC.""
        ], 
        ""rxcui"" : [
            ""197903""
        ], 
        ""spl_set_id"" : [
            ""84a67585-8c8d-4309-b7fa-bd7be330c4a1""
        ], 
        ""nui"" : [
            ""N0000175589"", 
            ""N0000000121""
        ], 
        ""pharm_class_epc"" : [
            ""HMG-CoA Reductase Inhibitor [EPC]""
        ], 
        ""pharm_class_moa"" : [
            ""Hydroxymethylglutaryl-CoA Reductase Inhibitors [MoA]""
        ], 
        ""unii"" : [
            ""9LHU78OQFD""
        ]
    }, 
    ""marketing_category"" : ""ANDA"", 
    ""dosage_form"" : ""TABLET"", 
    ""spl_id"" : ""a3d6c1c7-9f51-6937-e053-2a95a90a3d10"", 
    ""product_type"" : ""HUMAN PRESCRIPTION DRUG"", 
    ""route"" : [
        ""ORAL""
    ], 
    ""marketing_start_date"" : ""20170202"", 
    ""product_id"" : ""70518-0194_a3d6c1c7-9f51-6937-e053-2a95a90a3d10"", 
    ""application_number"" : ""ANDA075991"", 
    ""brand_name_base"" : ""Lovastatin"", 
    ""pharm_class"" : [
        ""HMG-CoA Reductase Inhibitor [EPC]"", 
        ""Hydroxymethylglutaryl-CoA Reductase Inhibitors [MoA]""
    ], 
    ""createdOn"" : ISODate(""2021-03-04T07:38:43.216+0000""), 
    ""modifiedOn"" : ISODate(""2021-03-04T07:38:43.216+0000"")
}

Third party e-prescription platform integrated on our platform is using 'First data bank' for drug database from where they are getting all the information of drug along with strength & NDCs. Sending the NDC codes or the drugs identified from our platform is not matching for the specified drug strength. As we are not able to locate the desired drug strength on our platform using open FDA API drug db.
For the above example ""Lovastatin 10mg"" they have (Third party e-prescription platform) specific NDCs. They have provided us following NDC against ""Lovastatin"".
00185007001,00093092610,00093092606,68180046707,68180046703,68180046701,61442014110,61442014101,68001031400,68180046709,00440669285,00440669281,00440669260,00440669230,00440669201,00440669200,49999029330,52959097430,63629358302
Out of the shared NDCs (19 records) few of the records are available and matching (10 records) with the open FDA db. Though, the strength for the same is unavailable.
Would be great if you can help us with locating or finding the strength in open API FDA API response for the specified drug.  Also let us know if we are missing something at our end.
Thanks
","['api', 'openfda', 'drugs']",
Seeking other source of information for road networks to increase precision of shapefiles in Balkans,"
I am trying to create an infrastructure map for Balkan countries. The thing is that for countries such as Albania, Bosnia - Herzegovina e.tc., the shapefiles from OpenStreetMap http://download.geofabrik.de, as well as from DIVA-GIS https://www.diva-gis.org/gdata. However, the road network is not precise. For instance, there are many ""gaps"" between the lines, looking like something is missing...
Is it possible to find another source of information for shapefiles of roads at a country level?
","['geospatial', 'open-access']",
How to know which drug product is a reference listed drug (RLD)?,"
I trying to figure out how to know which drug product is a reference listed drug (RLD).
Let's take for an example following spl_set_id:
https://api.fda.gov/drug/drugsfda.json?search=products.reference_drug:""Yes""+AND+openfda.spl_set_id:""051be7ae-6504-c2d8-7424-2e328e4fcfc2""
I can see that three of six products have ""reference_drug"": ""Yes"". This should be a flag that marks drug product as RLD.
Question: How can I find related spl_set_id for the particular product since in the response I have three of them in the spl_set_id array?
Thanks,
",['openfda'],
"Label language, how to change to local names","
I'm viewing Wikidata with Swedish set as my user interface language. This turns all the language names in the list of labels into Swedish, which makes the list hard to follow in my opinion since the list is ordered by language code and not localised name. I would like the list to show local names instead of the translated ones, is there any way of doing this? Preferably I'd also like the list to also show the language code of the items.
","['language', 'wikibase']",
Is there an open-source master list of MSA (Metro / Micro Statistical Areas) available in a machine-readable format,"
Is there a freely available master list of MSA (Metropolitan or Micropolitan Statistical Area (USA)) with the codes and their corresponding human-friendly name, one that can be downloaded in a single file in a machine-readable format like CSV or Excel? I haven't found one in an importable format yet.
I have been handed a dataset of locations that have been characterized by a MSA code and I need to write a simple report against it that displays the human-friendly area name.
",['data-request'],"The Census Bureau has MSA's outlined in their API system. Here is an example of the list of 2019 MSA with total populations. It is technically in JSON format, but it would be very easy to Find/Replace the brackets and end-of-line commas out to turn it into a comma-separated values structure."
Is there is exists dataset contains images labels/classes from some social network like Instagram?,"
I'm doing a recommender for one social network disabled yet.
Social network includes images post, like in Instagram. My idea is scrap images labels/classes and then try to classify it in some given classes. However since social network disabled, there are a few data for handling this task and I'm searching some opened dataset of network images labels.
Maybe you know some? Or I could do scrapping by myself from Instagram? How to do it exactly?
",['data-request'],
Is there a tool to match zip codes to states?,"
I have a CSV of thousands of zip codes and need to add the state data. I don't need cities, just states. Any ideas?
","['data-request', 'postal-code']",
Puerto Rico Land Use Land Cover GIS Data,"
I am looking for Puerto Rico Land Use Land Cover GIS data that has residential/commercial office/commercial retail classifications. I have not been able to find anything
",['geospatial'],
Georeferenced list of international border crossings,"
I am looking for a georeferenced list of international border crossings for Middle East and South Asia. Is there any reliable source?
","['data-request', 'geospatial']","As with most requests for spatial data for more than one country, Open Street Map is likely to be your friend here. Depending on what GIS software you're using, you can search for features tagged as barrier=border_control or government=border_control.If you don't want to use Open Street Map (for example because you don't have time to learn how to use it and are unlikely to need those skills in future) there is a file of border crossings derived by identifying places where major roads cross national borders, although you should note that many border crossings do not carry major roads."
CIK Number and Jurisdiction details - Private companies,"
Can you please suggest on how to get the CIK number and jurisdiction details of private companies registered in the US? What I have is a list of companies and its address, but in need of CIK and Jurisdiction for downloading returns. Open source or paid is fine with me.
","['data-request', 'usa', 'data.gov', 'state', 'federal']",
Consolidated search platform for company documents (federal and state),"
Please excuse due to lack of knowledge in the area of private company filings in the US.
My assumption is that private companies in the US must make 2 separate returns (at federal and state)
For federal, we can use EDGAR platform to search for filing/documents. But when it comes to State, we need to visit individual state portal ( for eg  for California, and for Nevada etc) to download documents such as annual returns/certificate of incorporation etc.
I am in process of building a search feature which help user to search/download all returns across federal and state portals. Unfortunately, I am finding it difficult to perform search across various states since there is no unified identifier (something like CIK for EDGAR) handy for me to perform this search.
Question: Is there any provider (open source or paid) available out there who could abstract this complexity of search. Something like an API which would perform a consolidated search across various states and return the result ?
","['data-request', 'usa', 'data.gov', 'state', 'federal']",
Need US federal source for ZIP codes (not ZCTAs) including ZIP code type,"
I'm looking to locate either a published table or federally hosted API that returns current (and/or past, if available) ZIP codes that includes the ZIP code type (S/P/U/Z/etc). This data must be published by an agency of the federal government. I'm not looking for ZCTA shapefiles, just a list of active codes, their type, and ideally the address of the corresponding post office for P- and Z- type zip codes. I've checked data.gov but they do not appear to offer datasets from the USPS.
Most open geography datasources I have checked are based on ZCTA instead of the entire ZIP code universe (because they have to have polygon shapefiles, which I don't care about). This does not work for me, ZIP and ZCTA are separate systems even though they use the same unique identifier (ZIP5). ZCTAs are maintained by the census bureau as approximations of the delivery area of S-type zip codes, and exclude P-, U- and Z- type ZIP codes, which do not have a postal delivery area. I need a datasource that includes P- and Z- ZIP codes (I don't care about U-type zip codes or any other types, if any exist).
I can't use any source encumbered by restrictive terms of use and I don't want to use a commercial service for my project. I'd like my data to come directly from the Postal Service, or from another federal agency if no data is available from the Postal Service.
","['geospatial', 'usa', 'data.gov', 'government', 'postal-code']",
Seeking global (worldwide) list of street abbreviations,"

I want to normalize my address by country wise and I'm in search of
dataset set that contains abbreviations for street values.
For example: (St => Street, Rd => Road, Avn => Avenue and so on.)

This is for English countries. But I want this abbreviations for every country in their local language.
Am searching for this data for    almost a week but I could find is not that informative. Can anyone    please suggest some data source for such data.?
Thank you very much for your response. :)
","['data-request', 'global', 'address', 'normalization']",
Are there any overfishing aerial imagery datasets?,"
I'm trying to build an aerial imagery satellite overfishing detector. I've seen somebody has posted a question but that was 5 years ago and without aerial imagery.
","['geospatial', 'machine-learning', 'images', 'aerial-photography']",
"Institutional level earnings data (e.g. MN_EARN_WNE_P10, etc.,) has been updated since FY15. Is there anything more current? When will it be updated?","
According to the most recent Scorecard Dictionary, institutional level earnings data (e.g. MN_EARN_WNE_P10, MS_EARN_WNE_P6, etc.,) hasn't been updated since FY15. Is that correct - or is there more current earnings data by institution that I missed? In variation, When will this information be updated, if at all? Lastly, are you aware of any similar alternative sources - at the institutional level.
",['education'],
Why is my API call for application_number is not working?,"
#1: https://api.fda.gov/drug/event.json?search=patient.drug.openfda.application_number:ANDA076407
I am trying to make a similar API call to above but for below application#
New Drug Application (NDA): 212994
Company: COMMCAVE THERAPEUTICS SA
However I am getting code not found error when using the API call below. Why is call #1 working and #2 not working? What am I doing wrong in call #2?
#2: https://api.fda.gov/drug/event.json?search=patient.drug.openfda.application_number:NDA212994
",['openfda'],
Any good website to find local companies and firms?,"
I am looking for website catalogs of companies in Europe - Spain, Portugal, Baltic states, etc.
My knowledge of their native languages is very low, so I couldn't find any relevant results in English.
Could anyone please recommend such a website? For example - Czech Republic has firmy(dot)cz - something like yellow pages, but a local variant.
I am looking for websites and e-mails.
","['research', 'europe', 'business', 'social-media', 'email']",
Is there a list of all municipalities in the USA with population values as a spreadsheet?,"
so I am looking for a list of every municipality in the USA in spreadsheet form, or at least that can be easily imported into a spreadsheet. I would like it to include every municipality type in every state, whether it's a town, township, city, or anything else.
It should also have population values for every municipality, as well as the name and state it's located in. I would like the population values to be estimates from 2016 or later, preferably as recently as possible. Though I would also accept older estimates or 2010 census figures.
I would also prefer if each entry also had a land area, but that is somewhat optional. It is fine if the spreadsheet also contains more information than name, state, population, and area, but it is not necessary.
I did find this, but it is paid. I would like to find a free dataset if at all possible, especially because what I'm looking for doesn't quite need to be as extensive as this one is.
So does such a dataset exist? And where can I find it if so?
","['usa', 'city', 'population']",
How to find undergraduate earnings data,"
Having difficulty accessing this data file - EARN_MDN_HI_2YR.  have tried the search bar, but have not been successful.
","['data-request', 'data.gov', 'collegescorecard']",
Public Data sets on News paper headlines or articles from 2019-2020,"
I was wondering if there are any available data sets on newspaper headline/article aggregation over 2019 and 2020, I'm interested in exploring sentiment analysis over the period but have been unable to find anything contemporary enough?
",['data-request'],
3D Building high LOD,"
I'm working on a project with 3d buildings and looking for high LOD 3d buildings like this


Where can I get these high LOD buildings?
","['data-request', 'buildings']",
Does maps of rocky habitats exist?,"
I am working on a multifactorial model to explain preferences for a given habitat for a species of bird,
on a European scale. In this model, I have included variables such as slope or terrain ruggedness, which caraterize mountain habitat. However, I would like to be a little more precise regarding presence of rocks, boulders, screes, or anything related to broken rock fragments. My research has been unsuccessful so far, I could only find lithological maps, which is not quite my goal.
Do you know if such maps exist? Or is there a proxy that I have not thought about?
I am new to habitat modelling, so any help would be greatly appreciated!
(I use both QGIS and R)
","['data-request', 'geospatial', 'europe', 'data-mapping']","I doubt there is any pan European dataset that maps boulders!In the UK the national mapping agency OS will map on 1:25,000 scree, boulder fields and the like, I suspect this data is in OS MasterMap. I would imagine other national mapping agencies will capture similar detail although quality and resolution will surely vary.There are very few datasets that map consistently across different nations and at scale that could identify fine detail.The only cross-continental dataset that I'm aware of is OpenStreetMap and this is unlikely to capture what you are looking for in any consistent manner."
Projects similar to google books?,"
Are there other projects similar to google books that allow (legally defensible) search, snippet view, and/or metadata exploration of non-public domain books?
","['metadata', 'books']",
Landsat 5 missing archives in Africa,"
I am trying to download Landsat 5 tile on USGS explorer from the Landsat Collection 1 and Landsat Collection 2 dataset in order to do temporal analysis. However, in Africa, I can only retrieve a few images between 1984 and 2002 (approximately one every two year). In other continent such as Europe, I can access all images (every 14 days).
Is it a USGS issue, or can I get the data somewhere else ?
PS : I am posting my issue here because custserv@usgs.gov has not answering to me.
","['data-request', 'africa']",
Seeking remote sensing dataset for fire perimeter by hour in California,"
If anyone has worked with Cal Fire Perimeter dataset, can you advise what will be a good data source to get hourly California Fire perimeter, by date and by location, from 2010s and later?
I am looking for a dataset that will give me the timestamp and the location, in term of longitude and latitude, when a fire occurs. I did look at NASA VIIRS Active Fire Data to get active fire hotspot. However, when I compared the data I got from there with Cal Fire Perimeter dataset, I noticed that NASA VIIRS Active Fire Data did not contain all of the fire's hotspot when it occurs. Thus, to get a more accurate picture of the fire's spreading time, I just wonder if anyone has any recommendations on what dataset I should use.
","['usa', 'real-time', 'fire']",
FDA Press Releases/Announcements,"
I am looking at the openFDA documentation and I don't see an endpoint to gather all of their press releases/announcements.  Can I back into that using the existing api?
","['api', 'openfda']","Unfortunately, such an endpoint is not yet available in openFDA."
"Given the 510k dataset, how do I derive the location of summary PDFs?","
Having ingested the 510k dataset, several of the entries have a statement_or_summary value of ""Summary"" or ""Statement"" which I understand means a summary/statement is available.
For example, given this record:
{
  ""third_party_flag"": ""N"",
  ""advisory_committee_description"": ""Ear, Nose, Throat"",
  ""statement_or_summary"": ""Summary"",
  ""product_code"": ""ETN"",
  ""openfda"": {
    ""device_name"": ""Stimulator, Nerve"",
    ""medical_specialty_description"": ""Ear, Nose, Throat"",
    ""regulation_number"": ""874.1820"",
    ""device_class"": ""2"",
    ""registration_number"": [...],
    ""fei_number"": [...]
  },
  ""applicant"": ""THE MAGSTIM COMPANY LTD."",
  ""decision_date"": ""1995-06-02"",
  ""decision_code"": ""SESE"",
  ""device_name"": ""NEUROSIGN 100 IMPEDANCE METER"",
  ""advisory_committee"": ""EN"",
  ""contact"": ""CHRIS  HOVEY"",
  ""expedited_review_flag"": """",
  ""k_number"": ""K945799"",
  ""date_received"": ""1994-11-28"",
  ""decision_description"": ""Substantially Equivalent"",
  ""clearance_type"": ""Traditional""
},

Although the record says ""Summary"", one doesn't exist when viewing the FDAs database: https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfpmn/pmn.cfm?ID=K945799
So far I've seen that the URL structure for these is normally https://www.accessdata.fda.gov/cdrh_docs/pdf<k number year>/<k number>.pdf However, for years 95ish through 01ish, it's just /pdf/ with no year. Is this behavior documented anywhere (or possibly purposely not exposed)? Is there something I'm missing?
","['api', 'openfda']","openFDA renders its 510K dataset from the downloadable 510K files, which unfortunately do not provide any information about the links to PDF letters. We would recommend that you contact CDRH directly to inquiry about the best way of programmatically obtaining the links to PDFs."
Weekly temperature data for Europe on a regional level NUTS 1,"
I am currently writing my thesis on how temperature affects mortality in Europe.
I obtained an excellent dataset from the Eurostat Database containing weekly Mortality numbers on NUTS1 level (regions). It is important that my data fits this NUTS1 specification (Germany for instance has 16 NUTS1 regions).
So far I've only been able to find daily data from weather stations where the frequency is way too high for my research.
I could do with daily data for NUTS1, NUTS2, or even NUTS3 (Germany is divided into 400 of these).
But when the data is from stations the task of getting data and matching it to coordinates seems a bit much.
I heard something about a software called QGis that can match stations to coordinates but that is not something I have experience doing though.
Any help is much appreciated
","['data-request', 'programming']",
Any tips dealing with GTFS-realtime v2 compared with GTFS-relatime v1,"
Transit Open Data APIs often use GTFS-realtime for providing real time status updates (service late, currently here, effectively RT differences against scheduled services).
The GTFS-realtime spec is now at v2 for what seems like a lot of good reasons.
Wondering if anyone has any tips / advice / gotchas on migrating an existing code base (java) from v1 to v2?
","['api', 'uses-of-open-data', 'public-transport', 'real-time']",
Language demographics of Swiss citizens,"
I am looking for demographics of languages spoken or not-spoken by Swiss citizens or residents.
Although I don't think it's possible to find this exact dataset, this is the core question: how many swiss citizens can't speak one of the national languages?
The best would be on the country level, but broken down into different Cantons. And relevant is if the person speaks or does not speak one of official languages of the country or region.
For example, 95% of Swiss citizens in Kanton Zürich speak German/Swiss-German fluently.

I just need some stats, so I'm flexible with the license of the data.
","['data-request', 'language', 'demographics', 'switzerland']","Demographics split by official languages, English, and ""other"" https://www.bfs.admin.ch/bfs/de/home/statistiken/bevoelkerung/sprachen-religionen/sprachen.assetdetail.15384580.htmlBy Kanton: https://www.bfs.admin.ch/bfs/de/home/statistiken/bevoelkerung/sprachen-religionen/sprachen.assetdetail.15384656.html.Part of the population having one of the national languages as (one of) their man language(s):
https://www.bfs.admin.ch/bfs/de/home/statistiken/bevoelkerung/migration-integration/integrationindikatoren/alle-indikatoren/sprache/landessprache.assetdetail.5546593.htmlBy Kanton: https://www.bfs.admin.ch/bfs/de/home/statistiken/bevoelkerung/migration-integration/integrationindikatoren/alle-indikatoren/sprache/landessprache.assetdetail.5546605.htmlEnglish page: https://www.bfs.admin.ch/bfs/en/home/statistics/population/migration-integration/integration-indicators/all-indicators/language/national-languages-main.htmlPercentage of people regularly using 3,2,1 or no national language(s): https://www.bfs.admin.ch/bfs/de/home/statistiken/bevoelkerung/migration-integration/integrationindikatoren/alle-indikatoren/sprache/3-2-1-0-landessprachen.assetdetail.5546599.htmlEnglish page: https://www.bfs.admin.ch/bfs/en/home/statistics/population/migration-integration/integration-indicators/all-indicators/language/using-national-language.html"
Open source SAR data for the year 1999-2001 over India,"
where I can get Radarsat-1 data for 1999-2001 over Indian region(open for download)?
or can anyone suggest me SAR dataset for the above mentioned year and location which can be downloaded free of cost.
","['data-request', 'geospatial', 'uses-of-open-data', 'historical']",
"Where can I find the lease rates for office and industrial space in my area (Sturgeon Bay, Wisconsin to be specific)?","
I'm looking for a data source that shows me lease rates.  I know there are some on Costar and LoopNet, but I do not have a subscription and am hoping there is a free data source available.
",['data-request'],
What website to use to find data for my highschool project on BMI and Covid deaths?,"
Im doing an assessment for my highschool project where I need to find data for BMI and number of covid deaths associated with that BMI. Is there any website that will give me just the raw numbers on a table or anything like that?
","['data-request', 'covid19']",
Seeking location data for UK parliamentary constituencies,"
I'm trying to do some data analysis on crime rates within my local constituency. I'm using the UK Police API to get the data but currently, I have to manually define the boundary using longitude and latitude coordinates defining a polynomial.
Is there any way to download the outline of UK constituencies as longitude and latitude coordinates?
","['geospatial', 'uk', 'elections', 'politics']","The ONS has what looks like the data you're looking for - digital vector boundaries for Westminster Parliamentary Constituencies in the UK, as at 31 December 2017."
List of software and versions for test data,"
Does anybody know where I can find some sample data to use as stub data for my application to test with I don't want it to be just random strings and numbers?
I was originally going to user Microsoft ""Ready for Windows"" list but this appears to have vanished. I'm looking for a list of Software with Vendor, Application Name and Version e.g. (Mozilla, Firefox, 85.0).
In terms of quantity as many as possible (thousands if possible) and format doesn't really matter as I can write some code to deal with that.
Thanks
C
","['data-request', 'programming']",
Seeking EV charging station data for Denmark,"
Does anyone have a link to some open source data on EV charging station data preferably in Denmark, but maybe Europe?
","['geospatial', 'transportation']",
Is there a resource that links legal terminology to categories of law?,"
By categories, I mean areas such as:
Bankruptcy law
Consumer finance
Contracts
Tax law
Employment Law
Housing discrimination

I’m looking to build a list of specific terminology by legal category, and am wondering if this already exists somewhere.
For example: “Chapter 11,” “Bankruptcy petition,” “Adversary proceeding,” all relate to Bankruptcy law.
The two parts I'm looking to join together do exist, on sites such as https://dictionary.law.com/Default.aspx and https://www.enjuris.com/students/types-of-law-careers.html, but it's the connection between them that's proving difficult.
Does anyone know if a resource like this already exists?
",['legal'],
South Korea pre-reform postcodes dataset,"
""The Korea Postal code system changed from a 6-digit postal code system to a 5-digit postal code system on August 1, 2015"" (source). So if you look up for example the old ""korea 110-744"" or ""korea 110744"" on Google Maps or GeoNames.org, you draw a blank. But if you simply Google it, you do find references to gazetteer websites, such as http://south-korea.postcode.info/p/110-744.
Is there a good (ideally open) source of structured (machine-readable) geolocation (address and ideally long-lat) data for South Korea pre-reform postcodes (and ideally current ones as well)? The address could be romanised or in hangul, but that would be indifferent if long-lat is provided. The goal is to geolocate (long-lat) a dataset of addresses going back to the 1980s.
","['data-request', 'postal-code', 'korea']",
Historical CoronaVirus Papers,"
I wonder where the historical Corona Virus research papers can be downloaded. Probably a bulk download of all papers from a couple of years or decades.
","['data-request', 'research', 'covid19', 'research-papers']",
British National public Art Gallery High Quality Images for GAN Modelling,"
Looking for a British National public Art Gallery with high-quality images, to train GANs for Image Regeneration.
","['data-request', 'machine-learning', 'images', 'deep-learning']",
Index of YouTube video titles,"
I'm looking for a way to identify (as many as possible) YouTube videos on a certain topics based on a keywords occurring in their titles.
YouTube Data API provides a way to search for videos based on the keywords but limits results up to 500 titles only.
Common Crawl indexes YouTube.com domain but it contains information only about page URLs and not its HTML <title> while YouTube.com videos do not have their titles in URL (basicaly it's https://www.youtube.com/watch?v=v01QZUxYg62).
There's YouTube 8M dataset of segmented videos but it seems an overkill to just get the titles. Is there any other corpora of up-to-date YouTube video titles?
","['nlp', 'text', 'video']",
"Computer monitor dataset listing display size, resolution and weight","
I'm looking for a data set listing computer models with at least the following information:

display size (e.g., 24 inches)
resolution (e.g.,1920x1080)
weight

",['data-request'],
Open Source huge dataset for Language Modelling,"
Looking for text data including books, GitHub repositories, webpages, chat logs, and medical, physics, math, computer science, and philosophy papers for Language modeling.
","['data-request', 'text', 'large-datasets']",
UK train data in real-time,"
Is there an API for rail company/ies, preferably for all UK locations?
Lat/long, train Id at a minimum but data such as train name, speed, from/to station, ETA, number of coaches/passengers, train type (freight/mail/passenger), etc will be useful too.
","['geospatial', 'uk', 'public-transport']",
UK battle sites,"
Is there a dataset of UK battle sites?
At a minimum, Lat/Long, but the more data the better such as who fought who, how many, who won, when was it, was it part of a particular war, etc?
","['data-request', 'geospatial', 'historical', 'uk']",
All citizens in a city geolocation dataset,"
I am building a demo dashboard for an app that tracks the location of everyone's phones in anonymized manner to evaluate traffic, crowding dynamics and so one. For my demo I would want to have a sample dataset for a big city, e.g. New York with pinpoints (location lat. and long.) for each person in the city. Are you aware of some similar open datasets which I can use in my app?
","['data-request', 'machine-learning', 'uses-of-open-data']",
Data on forest production in Europe,"
I am wondering if there are some GIS (Geographical Information System) resources for finding data on forest production in Europe, e.g. raster data depicting yearly production of beech hard mast (Fagus sylvatica) or other tree species, in order to perform some studies on the influence of this parameter on some animal species.
Perhaps something obtained from remote sensing. Any suggestion?
","['geospatial', 'europe']",
Who Makes This Map,"
My co-worker is seeking to find where or who made these maps ?
","['data-request', 'download', 'federal']",
Latest new updated for GIS or CAD or KML for Colorado Datasets?,"
In the past , I have asked for Colorado Ski Areas here: Colorado Ski Areas GIS dataset
There are very limited gis data that I am seeking to find more new information
I am looking for new GIS or CAD  or kml data that I need to update for my projects. They have to be the most recently ones.  Do know know of any sites that will be very useful for me to review them ?
","['data-request', 'geospatial', 'usa', 'ski']",
1918 Bureau of Transportation Statistics North American Transportation Atlas Data?,"
In 2008 User:NE2 on wikipedia added a bunch of train routes from 1918 to wikipedia:
https://en.wikipedia.org/wiki/Missouri%E2%80%93Kansas%E2%80%93Texas_Railroad#/media/File:Missouri,_Kansas_and_Texas_Railway_system_map_(1918).svg
https://en.wikipedia.org/wiki/File:Detroit,_Toledo_and_Ironton_Railroad_system_map_(1918).svg
https://en.wikipedia.org/wiki/File:Oregon_and_California_Railroad_system_map_(1918).svg
https://commons.wikimedia.org/wiki/File:Michigan_Central_Railroad_system_map_(1918).svg
He says the data for these maps came from ""Bureau of Transportation Statistics North American Transportation Atlas Data"". Google'ing that I found this:
https://data-usdot.opendata.arcgis.com/datasets/north-american-rail-lines
But that data isn't from 1918.
Archives going as far back as 2011 can be found here:
https://www.bts.gov/archive/publications/national_transportation_atlas_database/index
But 2011 is a far cry from 1918.
https://geodata.lib.ncsu.edu/fedgov/bts/nortad/ has data going back to 1998 but that's still not 1918.
So my question is...  where can I get train route info going back to 1918?
","['geospatial', 'usa', 'historical', 'transportation', 'public-transport']",
Where can I find ACS data for *specific* countries of origin and languages spoken at home?,"
I wanted to map out where Ethiopians live in the Puget Sound area. ArcGIS has mapped ACS data, but I could only find data for places of birth grouped by continent.  Same with languages spoken. What I really want is data that shows how many people came from ""Ethiopia"", or speak ""Amharic"" at home (or Oromo, Tigrinya, etc.) Does such data exist?
I'd also like to drill down into specific ethnicities, e.g. Arabs and Kurds, Sinhalese vs. Tamil, Kinh vs. Hmong. After all, many people of Ethiopian descent were born in the United States! Does the ACS even have data that specific?
",['us-census'],
How to look up the Census Block Code of an address?,"
I am trying to divide up a pool of addresses currently in Microsoft Excel according to the Census Block Code. Would anyone tell me where can I access data like that? Any instructions? Moreover, is it possible to retrieve those data with VBA or any programming API?
","['us-census', 'census', 'address', 'excel']","The U.S. Census Bureau has a geocoder API service that you might want to look into. Here is the landing page with some additional information.I was able to return information on the Census Block of a given address using the ""FIND GEOGRAPHIES USING..."" OPTION --> One Line option."
Interesting topics of opendata datasets for learning about data warehouses,"
I am a final year CS student and have a class about data warehouses.
For term requirements, we are supposed to choose 3 datasets that should have about 10 columns and at least 500 rows each. Otherwise, we are not limited in any way. Then we will process it via data warehouse (i am not exactly sure about details, as I have no experience).
I am from the Czech Republic, but as I said the data origin is not much important.
I have searched multiple sites of opendata providers but could not choose interesting topics that would be related together. I know that there are tons and tons of datasets to choose from, but exactly that is the issue for me that I am overwhelmed with the options and cant choose any.
As I am a total newbie in this field, could you please advise me with topics, you have encountered and found interesting or found some hidden correlation within them?
","['data-request', 'education']",
Dataset for company name aliases,"
I am looking for a dataset or service providing company name aliases. For example HP == Hewlett Packard, PWC = Price Waterhouse Coopers.
Is there such a dataset or service?
",['companies'],
"GIS data for Castles - UK, Europe also nice","
I am looking for data on castles, preferably UK, although I won't object if it extends to Europe.
Must be mappable, so lat/long is necessary. Any data beyond that is a bonus. E.g date of con/de-struction (and by whom), famous sieges, battles, photos, other descriptive data - the more, the merrier.
I am honing my mapping skills, so this is more of a coding exercise, but I think that castles could be interesting.

[Update] So far, I have found lat/long/name of 181 castles ""outside of USA/Canada"". However, there are no further details. I could doa lot of research, but , as I said, it's more about coding fancy map features than castles. So, unless someone can come up with better, then I will find another topic. Hope this helped someone, though.
","['geospatial', 'historical']",
Human normal EEG Relative Power Spectra during Rest,"
Where can I find a open dataset of an adult man healthy/normal EEG Relative Power Spectra Density during rest?
Like this, but in a Relative PSD (%) How to convert ""Fourier amplitude a.u."" into Relative PSD (%)?

",['data-request'],
List of Codified Laws from Around the World in Structured Format?,"
I am wondering where can one find datasets with all the laws on Earth (or all the laws from every country).
","['europe', 'legal', 'asia', 'north-america', 'south-america']",
"In need of some open address data, that i can match against a list of UK postcodes","
I have a JSON document full of UK postcodes, and I need the list of addresses that are matched to these postcodes. Does anyone know where I can find this data?
","['data-request', 'address', 'location']",
Can I find a dataset of EEG signals to classify a depression?,"
I searched a lot about a dataset of EEG signals which can I use to classify a depression? I want a labeled dataset?
I appreciate all your help thanks.
","['data-request', 'classification', 'deep-learning']",
Whole national market volume data,"
I am looking for open data about daily whole stock exchange volumes in order to test the claim that Amsterdam ousted London as Europe’s top share trading hub by the Financial Times. I didn't find the volume information on yahoo finance ...
","['finance', 'europe', 'stock']","Here's another secondary source of the info:Bloomberg: https://archive.is/omvKxIt turns out the calculation was made by ""Cboe Global Markets"", who will have real-time market data access ($$$).I tried to recreate the numbers but for the London exchange I only foundhttps://www.londonstockexchange.com/reports?tab=market-summary(archive link)where the daily trading amount is on average ~£4 billion (see excel download for more days).I couldn't find any recent data for the Amsterdam exchange.So without reading the actual report from Cboe, it's hard to know where they are getting their numbers."
to train the neural network to simulate the interior and the arrangement of furniture,"
Is any dataset and codefor task to simulate the interior and the arrangement of furniture ?
For example like in nvidia post?
https://developer.nvidia.com/blog/archigan-generative-stack-apartment-building-design/
however, without modeling furniture arrangement
","['data-request', 'machine-learning']",
Ground data(real data) for precipitation(rainfall/mm) of India,"
I need recent 10-15 years datasets of precipitation(rainfall/mm) for India. I have obtained many projection datasets but I need real datasets.
Requirements:

Real Datasets
datasets of 2005-2020
1 degree * 1 degree
3 hourly or 6 hourly datasets
India datasets

Can anyone can suggest sources for the above?
",['uses-of-open-data'],
Social trust/faith in political system datasets for Africa pre-2000?,"
I am looking for data that covers social trust/trust in elected officials/political system/etc. data for Africa pre-2000. Afrobarometer/WVS have good coverage until around 1999 though do not have the variables I am looking for, and I was wondering if there were any datasets that cover earlier years?
","['africa', 'politics', 'survey']",
Seeking live bar/ restauarant UK data API for ML application,"
Looking for an API I can use to create a bar/restaurant recommendation app in the UK, with the possibility of commercial use.
Will need to train a model on this data which may necessitate the ""storing"" or caching of the dataset.
Does anybody know of data I can legally use for this? Happy to pay for the use.
","['data-request', 'api', 'scraping']",
Error retrieving adverse events by country,"
I was using a query like this one  https://api.fda.gov/drug/event.json?search=patient.drug.medicinalproduct.exact:(""ELIQUIS"")+AND+receivedate:[20110101+TO+20151231]%27+AND+occurcountry:%27fr%27&count=serious to retrieve all adverse events for a specific country.
It was working some month ago. But now it seems the searchable fields occurcountry doesn't work anymore. When I deleted it the query works. It is an bug  or I missed an update for the API?
","['api', 'openfda']",
1945 (spring) daily weather Germany,"
Perhaps understandably, I am having difficulty tracking down daily weather data for Germany in early 1945.
My specific interest is in daily temps and any other daily weather observations for January through March 1945, particularly for the area of Bonn or Cologne -- although I would be grateful even if such data were only available for Berlin.  My greatest interest is in the first three weeks of March 1945.
","['data-request', 'weather', 'historical', 'germany']",
Various sources for self-reported heights of adults,"
I'm looking for various sources (Global: US, UK, Europe) of adult height data. And it should be self-reported (meaning the person reports their own height, and not that a doctor measures them).
","['data-request', 'medical', 'demographics', 'global']","This question has a relevant answer on this forum: https://opendata.stackexchange.com/a/12085/1511https://www.kaggle.com/hugomathien/soccerAnd the data even has a weird distribution (big bar at 182-185 cm, which contains 6 feet 0 inches):and another one with two peakshttps://www.kaggle.com/stefanoleone992/fifa-20-complete-player-datasetBut I can't be sure it's self-reported."
is there a way to fetch only the updated documents in openFDA?,"
I am using a query like the following one
https://api.fda.gov/drug/label.json?search=effective_time:[20110601+TO+20121231]&limit=1
to search for all records with effective_time between Jun 01, 2011, and Dec 31, 2012
But, is there any way to fetch the records updated/created from a certain date?
","['api', 'openfda', 'drugs']",
Is there any publically available job recommendation (person to job fit) dataset?,"
I want a dataset that contains resumes and job descriptions, and information about successful job applications for my research work. Is there any dataset available publically?
","['data-request', 'nlp']",
P2P loans dataset WITH lender information,"
Many P2P loan datasets are public. Commonly these datasets include information on the loan and the borrower (e.g. http://kivatools.com/downloads).
However, I am interested in lenders and their activity on the platforms.
Surprisingly, I did not find any dataset that includes (anonymized) information on the lenders of a loan. Meaning (1) which lender did (2) when (3) how much money. I would need this over multiple years (> 5 years).
Has anyone a link to such a dataset with time-series information on lenders and their activity?
","['data-request', 'finance']",
Covid 19 regionalized historical hospitalization data for european countries,"
I am looking for the regionalized historical covid 19 data for western european countries, especially the number of hospitalization.
By regionalized, I mean for each subdivision of a given country (lander for germany for example).
By historical, I mean data for, ideally, every day since last march.
By western european I mean Germany, Italy, Switzerland, Spain and Portugal mainly.
France already have precise historical data per departements: https://www.data.gouv.fr/fr/datasets/r/63352e38-d353-4b54-bfd1-f1b3ee1cabd7 (from https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-resultats-des-tests-virologiques-covid-19/). I would like the equivalent for the aforementioned countries.
","['historical', 'covid19']",
(Crowdsourced) Dataset with label/annotation metadata like duration/quality,"
I'm looking for a research project for datasets (the more the better), potentially crowdsourced, which go beyond basic feature vectors + labels, and include additionally some metadata about the labels. Specifically I'd like the annotation time, or some other cost metric, and if the dataset was crowdsourced, the individual labels per annotator. On top, some measure of the quality of the labels by different annotators would be helpful as well. The Dataset domain is not relevant.
So far I could only find this dataset.
","['data-request', 'machine-learning', 'deep-learning', 'crowdsourcing']",
BiBTeX reference API (from DOI),"
Is there a robust API available to download BiBTeX references from a DOI?
E.g. a query such as  https://api.somesite.net/10.1111/j.2517-6161.1995.tb02060.x should return something like
@article{mackay1998choice,
    title={Choice of basis for Laplace approximation},
    author={MacKay, David JC},
    journal={Machine learning},
    volume={33},
    number={1},
    pages={77--86},
    year={1998},
    publisher={Springer}
}

",['api'],"If you know Python, doi2bib might help you.It seems that CrossCite offers a similar service; take a look at the Documentation to see how it works."
Seeking list of all US cities and their latitude and longitude,"
I am looking for a list of all US cities and their latitude and longitude.
Ideally something free will work but I'm willing to pay for it if its not too expensive and its complete.
","['data-request', 'geospatial', 'city', 'location']",
Getting newly approved drugs from any of the Drug API Endpoints,"
I am looking to build and maintain a database of newly approved oncology drugs from the FDA.
I need something similar to their ""What's new"" or ""Novel Drug Approvals"" section on their site.
https://www.fda.gov/drugs/new-drugs-fda-cders-new-molecular-entities-and-new-therapeutic-biological-products/novel-drug-approvals-2020
I am not interested as much in shortages, recalls, etc.
My questions is (a) which openFDA endpoint do I need (Drugs@FDA? Product labeling?)? and (b) will this endpoint have the fields I need / is there a way to get the fields I need?
I am interested in getting

generic name for a given drug
tissue type or oncotree type the drug applies to
some sort of open text field regarding the ""-INDICATIONS AND USAGE-"" section of the prescribing info that I can use to mine relevant genes and/or conditions relating to the drug.

I feel like this should be possible and this information should be available but I am a bit confused by openFDA as a whole right now.
Additionally there seems to be many RSS feeds on the FDA site but there isn't one that seems to correlate to the FDA Drugs emails I subscribe to (Drugs / Oncology Drugs). If there was such a feed, I could use the drug names from that to query Drugs@FDA.
",['openfda'],
Agricultural data of Uttarakhand (1960-till date),"
Can anyone link me a page which mentions statistical data of Agriculture in Uttarakhand(India), I searched the internet for 4hrs now and still I got no result. Specifically the data around 1960s as it was the prime time of green revolution
",['agriculture'],
Where can I find ready-to-use region features for Visual Genome?,"
I am searching for region specific features extracted from e.g Faster R-CNN for the Visual Genome dataset.
","['images', 'deep-learning']",
Seeking shapefile for countries of former Soviet Union,"
I have data at the country level for the 15 countries of the former Soviet Union but does anyone have a shapefile?
My research assistant is claiming she cannot find one.
","['geospatial', 'russia']",
Is there a test dataset of research papers in computer science with relevance judgments,"
Is there a freely available test dataset of research papers in computer science field? I need to evaluate my text retrieval system which uses a computer science domain ontology called CSO, so the dataset should come with a ground truth/relevance judgments for text retrieval task and/or classification task.
",['corpora'],
"(Labeled, if possible) time-series datasets for anomaly detection","
I would like to create a big list of available time-series datasets for anomaly detection. I'm especially interested in the following:

The time-series data should be segmented into cycles
Ideally, these cycles should be of the same length
These cycles should be labeled as normal/anomalous

But anything goes. I will be sharing the ones I found below.
","['data-request', 'time-series']",
"Linking to Supplemental Material on arXiv (empirical data, code, etc)","
In Dec'20 the open access pre-print service, arXiv, introduced the ability to include a link to code in the metadata for a preprint. Certainly a step in the right direction. However, with a little tweak it could be described as a link to 'supplemental material' more generally, not just code. Then it could be used to link to empirical data, video material, etc. as well.
My question: Where can I raise discussion about an arXiv feature like this with those who determine arXiv policies? After extensive searching I cannot find anywhere for feature requests or public discussion about arXiv facilities or policies.
Failing that, please feel free to discuss the merit of my proposal here.
Obviously, a link can be included in the article itself, but the facility to include a link or links in the top level metadata emphasizes the importance of supporting material. arXiv already had a facility for uploading ancillary files, but this was not intended for large datasets, for which a facility to add a hyperlink would seem far more useful.
","['releasing-data', 'open-access']",
Downloading Bhuvan Panchayat 3.0 raw data,"
I am trying to download road and other spatial data files used on the Bhuvan Panchayat 3.0 website (https://bhuvan-panchayat3.nrsc.gov.in/). Is there a way to either directly download the raw data from the website, or are there existing scripts that would allow me to scrape the data I need?
","['geospatial', 'india']",
How many countrywide weekly mortality datasets are available?,"
It is a major topic of interest during the covid pandemic to analyse excess mortality. And it is particularly helpful to look at weekly death counts as the resulting year-year comparisons of weekly data provide rich information about the variability of deaths rates across seasons and years.
The USA's CDC provide such data from at least 2015 to the end of 2020 and this make identifying excess mortality related to covid a breeze. See this analysis, for example:

But how many other countries provide weekly mortality stats?
Note the CDC provide the stats with several levels of detail (in the case above by age group). But weekly totals even without the extra breakdowns would be useful. The UK's ONS recently released some weekly stats for 2020 but this didn't seem to have the equivalent weekly totals for previous years when I investigated the equivalent files.
","['data-request', 'medical', 'time-series', 'covid19']",
Bus passenger data,"
I'm looking for a dataset that gives me data on bus passengers. The dataset does not have to come from any specific city or country.
Specifically, I want:

Which bus station they depart from
Which bus station is their destination station.
When they want to arrive at their destination station. Failing that, when they actually do arrive (according, if need be, to bus schedules) at their destination bus station.

Also maybe acceptable:
1) Data on departures from and arrivals to a specific station
2) Number of people in each station at a given time/day.
",['public-transport'],"I asked on Twitter and got this response:Closest you can get AFAIK is the estimated count of people on each vehicle which is available in the real-time feeds.  Unclear how it is calculated or how accurate it is.@chris_whonghttps://bt.mta.info/wiki/Developers/Indexspecifially: SIRI for the MTA Bus Time Developer APIThe SIRI web service calls implemented by MTA Bus Time are:VehicleMonitoring: real-time information about one, many, or all vehicles tracked by the system.StopMonitoring: real-time information about vehicles serving a particular stop.Requires an API key but is free to use. You'd have to collect data from the API regularly. And you wouldn't know which passenger got on/off where.You can also find some archive data: https://bt.mta.info/wiki/Developers/ArchiveData"
Real-life monotonic data sets,"
Does anyone know examples of real-life data sets {(x_1,y_1), ... ,(x_n,y_n)} that are monotonic in the sense that either (i) for any two indices i and j the inequality x_i<x_j implies y_i<=y_j or (ii) for any two indices i and j the inequality x_i<x_j implies y_i>=y_j? Here, the x_i's and y_i's are real numbers.
",['data-request'],
multi-spectral high resolution satellite images for forests Greece (for vegetation indices),"
Looking for open-source high-resolution multi-spectral images (raster data) for Greece in order to analyze the vegetation indices of small forests smaller than 1kmx1km. Preferably if the data is from multiple years in order to see a progression in the forests.
",['images'],
"Orthophotos of Athens, Greece","
I'm looking for orthophotos of Athens, Greece to measure forest development (raster data).
Is there any open source for such material? I'm looking for orthophotos dating back to 1980s if possible...
If there is also sensor data (infrared/near infrared) taken by planes that would be helpful too.
","['europe', 'aerial-photography']",
Rest APIs or Database for Vaccinations and Allergies,"
I am doing research and looking for an API for Vaccination and Allergies. I found some link like  https://data.cdc.gov/ where I can the information but I am looking for something which has all information in one dataset or API. Please advise
","['api', 'medical', 'database', 'healthcare-finder-api']",
Time series dataset where historical values are updated,"
I am looking for a time series dataset where the historical values changed through updated reports.  The data would be reported on some regular frequency, and the historical values (might) change with different reporting dates.  I am flexible as to the frequency of either the reporting or the actual data.  An example for what I am looking for is the below (fictional) data (does not have to be medical):
Cases of Disease X by diagnosis date:
Data reported on January 10th
January 5th: 23
January 6th: 12
January 7th: 14
January 8th: 16
January 9th: 10
January 10th: 2
Data reported on January 11th
January 5th: 24
January 6th: 15
January 7th: 18
January 8th: 20
January 9th: 21
January 10th: 22
Data reported on January 12th
January 5th: 24
January 6th: 16
January 7th: 18
January 8th: 23
January 9th: 24
January 10th: 29
","['data-request', 'time-series']",
Question RE Safety Report ID,"
I'm seeing the following in the drug event endpoint:

On a ""conceptual"" level, it would appear that these are the same person, however, they appear in the drug event endpoint repeatedly, so I'm trying to gain a better understanding, given that openFDA only shows the most recent version. Is this an artifact of some sort of reporting error? How many individual reports are represented above?
",['openfda'],
Publishers: Identifiers & Imprints,"
I have a list of ca. 300 (academic) publishers entailing their commonly used names, such as Taylor & Francis.
There are two problems now:
1.) Imprints: Some are imprints of other publishers. For instance, Routledge is an imprint of Taylor & Francis.
2.) Names: Sometimes I am unsure about the correct name. For example, is it Springer, Springer Publishing, Springer Science+Business Media or Springer Nature (whereby the latter might be an imprint of Springer)?
Thus, my question is:
Are there any open data that could disambiguate names of publishers, show (persistent?) identifiers, and detect relations between imprints and their overarching companies?
This would greatly facilitate the task (in comparison to manual research).
","['companies', 'publishing', 'publications']",
Does anyone have access to the Parler dataset?,"
There have been a number of stories in the last couple of dats claiming a team of developers were able to scrape practically the entirety of the Parler social media platform before it went offline.
For example:
https://gizmodo.com/every-deleted-parler-post-many-with-users-location-dat-1846032466
https://www.buzzfeednews.com/article/johnpaczkowski/amazon-parler-aws
But so far I have been unable to find any evidence this data set actually exists. There are a couple of data sets labeled 'parler' on archive.org but they certainly aren't anywhere close to 70TB of data.
Does anyone know the status of this dataset? Is it available anywhere? Does it really exist?
","['data-request', 'social-media']","update: the full dataset is available here: https://ddosecrets.com/wiki/ParlerFiles are accessible from two Amazon S3 buckets, ddosecrets-parler (32.1TB) and ddosecrets-parler-images (235GB).At this time, we only have a partial scrape of text posts (1.6 million), which was provided by a 3rd party. The 18 GB torrent can be downloaded here: https://ddosecrets.com/images/d/de/Parler_2020-01-06_posts-partial.torrentAt the moment only the metadata is available. This means not the content itself, but the creation, id, creation date, and some gps tagging. The full dataset (70+ TB) is being processed by https://www.archiveteam.org/index.php?title=Parler and will be available soon.Grab status: https://tracker.archiveteam.org/parler/in the meantime, the metadata:https://donk.sh/metadata.tar.gz (check for mirrors on this twitter thread)Also a magnet torrent link:Jupyter notebook to parse gps-tagged metadata (videos): https://gist.github.com/kylemcdonald/8fdabd6526924012c1f5afe538d7dc09 (tweet)I also made a parser for a different (meta)data source (this one was only gps-tagged videos in csv format): https://github.com/philshem/parler-switzerland"
In need of a color aerial photography or LIDAR,"
I am seeking a few color aerial photography that are the most recently that I need to cover this area of interest.
It has to be overlapped in 60/40 percent  so I can perform them in an Agisoft Metashape.
Location is in Central Colorado
It is in the border between Leadville/Chaffee counties.
Point of interest is Twin Lakes river area. It is just to the west all the way to the east leading to the Lake.
Let me know if you are able to see the Area of Interest in Google Earth.
In order to see it,
Go to the Menu at the top left corner, then
Hit the projects, then
It should say Survey Area.
Google Earth :
https://earth.google.com/web/search/Twin+Lakes,+CO/@39.13113129,-106.42151985,3599.28893251a,44275.95222716d,35y,0h,0t,0r/data=CigiJgokCf8jXbmA3zRAEfwjXbmA3zTAGYU_JarUuihAIfMfULmClVbA
ArcGIS Online : https://arcg.is/1jiHD50
",['images'],"Never mind. I found one that allowed me to fill it out from the state of Colorado Hazard Mapping Departmenthttps://coloradohazardmapping.com/P.S. For those that want the LIDAR from on that site, I do want to caution you that the data is very large to download even if you want to submit them your area of interest shapefile.."
How to inquire about adverse events of aspirin in the open FDA？,"
I want to check the adverse events of aspirin drugs in the open fda data within the specified date
I have tried many times and it keeps getting an error display
Where did I go wrong ？ How can I query correctly？
I try to:
https://api.fda.gov/drug/event.json?search=patient.drug.openfda.pharm_class_epc:""aspirin+Antipyretic and analgesic+drug""&limit=1

https://api.fda.gov/drug/event.json?search=patient.drug.openfda.pharm_class_epc:""Antipyretic+analgesic+drug""&limit=1

","['openfda', 'drugs']",
Is it possible to download [ETA 539-Weekly Claims and Extended Benefits Trigger Data] through the DOL API?,"
is it possible to download the DOL's ETA 539 weekly report through the DOL API?
ETA 539 Report information can be found here... scroll down to report.
ETA 539 raw data.
DOL Developer tools link.
",['labor'],
How to obtain cmip6 projected temperature data?,"
I would like to get projected temperature data under various climate scenarios till 2100 for different European countries.
I find CMIP5 data under four RCPs in world bank, I am also interested in the new scenarios of CMIP6 but I am not sure that there are available.
","['data-request', 'climate', 'meteorology']",
Data about financing renewable energy,"
I am searching for data on financing renewables. The best case would be a data set with a split in private and public funding whereas private should be divided into equity and debt and the public into subsidies and credit.
Historic data or projections for 2030 targets are appreciated. Most interesting for me is Europe, but I am also interested in other data.
If you have any idea where to look or whom to ask, please let me know.
","['finance', 'energy']",
Seeking traffic and weather datasets,"
I am looking for a dataset of traffic flow and its corresponding weather data, such as rain and temperature, of the same location. I am studying the effect of weather variables on traffic, preferably inside cities not on highways.
P.S. I could find traffic data of some locations without the corresponding weather, and vice versa. What I need is both data of the same location.
","['data-request', 'weather', 'traffic']",
Dataset of health vitals from wearables,"
Are there any places where I can find a combined dataset for health vitals like Body Temperature, Blood Pressure, Respiration, Glucose, Heart Rate, Oxygen Saturation, Electro Cardiogram etc. I am looking for such dataset to create a personal project.
",['medical'],
"What are few datasets that we can use to build OCR model to detect text from documents like resumes etc.,?","
Do any-one know few good annotated OCR datasets that we can use to train a OCR model for detecting text from documents like resume (i.e., document image)?
","['data-request', 'machine-learning', 'ai', 'deep-learning']",
Hotel Historical Data,"
I need a dataset of historical prices of hotel rooms in the United Kingdom (for the last five years at least).
Does anyone know where I could find it?
",['data-request'],
Database of US Maine companies,"
I'm looking for a database of US Maine companies.
All I found is the page where you can search for companies from here. But I cannot find anywhere a place to download a list.
","['data-request', 'usa', 'business']",
Explanation for behaviour of FILTER in WDQS,"
I try to write a simple SPARQL query using WDQS to show some information about a city. My first attempt was to filter using a check for equality, like:
SELECT ?city ?cityLabel
WHERE 
{
  ?city wdt:P31/wdt:P279* wd:Q515 .
  FILTER(?city = wd:Q8471) .
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""[AUTO_LANGUAGE],en"". }
}

However, this query returns no records. My next attempt was to use ""IN"":
FILTER (?city in (wd:Q8471)) .

The result is the same as above. Then I found a solution using ""VALUES"":
SELECT ?city ?cityLabel
WHERE 
{
  ?city wdt:P31/wdt:P279* wd:Q515 .
  VALUES ?city
  {
    wd:Q8471
  }
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""[AUTO_LANGUAGE],en"". }
}

This solution works and returns 2 records. But it's not clear to me, why a simple ""="" comparision as in ""FILTER(?city = wd:Q8471)"" does not work in this query (I successfully used it in another query). Funnily enough I found out that enhancing the comparision with ""?city = wd:0"" (either ""FILTER(?city = wd:0 || ?city = wd:Q8471)"" or ""FILTER (?city in (wd:Q8471, wd:Q0))"") leads to the result I expected.
What is the error in my considerations?
","['wikidata', 'sparql']",
Looking for an Argument Mining dataset of customer reviews,"
I am looking for a dataset containing customer reviews (can be about hotels, restaurants, movies...) to build an algorithm able to detect arguments (premises, evidences...) in a given review and the relation between them.
My research leads me to this hotel reviews dataset.
However, it does not seem available for download.
Is there any public customer reviews dataset for argument detection or anything close?
","['machine-learning', 'sentiment-analysis']",
Dataset of many different types of time series noise - for testing filter quality,"
I'm working on a 1D time series data problem where I need a filter to be robust to a very wide range of types of signal noise - basically any type of noise where the mean is approximately zero and the magnitude is not too large. We're talking white noise, gaussian noise, funky distributions, random pulses and stutters, multiple frequencies, periodic, and anything else that you can imagine.
I'm currently testing this by trying to synthesise different types of noise by just mixing various permutations of standard distributions. Is there a dataset of different real world noises seen in a wide range of real world signals that I could sample from instead?
A dataset built for this purpose would be ideal, but any dataset containing a large range of time series signals with many different characteristics could be adapted to this purpose.
This feels to me like a relatively common requirement, but I haven't yet found the standard approach to solving it.
","['data-request', 'time-series']",
train schedules for freight trains?,"
I've taken an interest to filming trains as they go over bridges. For commuter trains I can guestimate when they'll be over a bridge based on the times that they're going to be at the stop before the bridge and the stop after the bridge. But not all train routes have commuter trains - some just run freight trains and that's it. For these freight trains...  is there a way I could look up scheduled stops online? If I knew what time they were going to be at the stop before and the stop after I could camp out at a bridge for that length of time (possibly guestimating the time that they'll cross the bridge) and take the picture I want to take.
The alternative is just to camp out for a potentially indefinite period of time, which has little appeal to me. If I'm going to be camping out I'd prefer to know how long I'd need to be there to get the shot I want to get.
",['usa'],
Is the SUBJECT_ID filed in the dataset the same as the PRODUCT_ID?,"
Is the SUBJECT_ID filed in the dataset same as the PRODUCT_ID as noted in downloadable datasheets at
http://www.trustlet.org/extended_epinions.html
",['releasing-data'],
SPARQL query to find invalid date in Wikidata,"
The following wikidata query lists the teams Cristiano Ronaldo played for including start and end dates.
SELECT ?playerLabel ?teamLabel ?start ?end WHERE {
  VALUES ?player {
    wd:Q11571
  }
  ?player p:P54 ?teams.
  ?teams ps:P54 ?team;
    pq:P580 ?start.
  OPTIONAL { ?teams pq:P582 ?end. }
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""[AUTO_LANGUAGE]"". }
}

Link to query
His end date at Juventus is not a valid date.
Partial Result




playerLabel
teamLabel
start
end




Cristiano Ronaldo
Juventus F.C.
10 July 2018
t2136841315




Question: What is the correct way to show items with invalid dates?
","['wikidata', 'sparql']",
"What's your favorite tool, SDK or language to to access Rest APIs","
I have been looking into some Rest APIs for Open Data. There are many languages out there (most) that have reasonably easy to use programming constructs and APIs out there that you can use to access Rest APIs.
Do you have a preferred one?
Is there one with a highly convenient Rest API built in?
How do you adapt to custom formats and schema's being returned?
(Am I asking too many questions in one?)
What I have played with myself so far is basic C# (because I know this best) HTTP getters (HttpRestRequest/Response) and JsonSerializer with custom format classes. Pretty basic and very problem specific but it worked. But I write a lot of code that is not necessarily reusable for other problems.
","['api', 'rest']",
"Medical Risk Factor Datasets - heart disease, metabolic syndrome diet","
I am interested in learning data and in understanding health. I have listened to a lot of Robert Lustig, M.D. the past several months. I know about Framingham's study and the China Study and Ancel Key's work.
I was wondering if the data for any of these is available.
My goal is to do multivariate linear regressions on the data available and find what is to be found.
","['medical', 'food']","The free MIT Online Course ""The Analytics Edge"" used a subset of the Framingham study in their Unit 3 as an introduction to Linear Regression.  (1 Table, 4000 rows, ~20 columns, no NAs).You can enroll and see if they still use that example, as they did in 2015.Otherwise take a look at the NHANES dataset - that's the National Health and Nutrition Examination Survey of the USA. But with this dataset you'll have to do a lot more preprocessing (because of the many NAs)."
Sales Transcript Dataset,"
I am interested in a dataset of sales phone calls. Ideally, I would like it to have the transcripts for each phone call, but I am also open to a set of audio recordings for each call as well.
","['data-request', 'research']",
How can one interpret the NVSS Mortality Multiple Cause-of-Death data sets?,"
I've downloaded the past 6 years of data from the NVSS for Mortality Multiple Cause-of-Death files. I'm a bit perplexed however, because the user's guide does not seem to provide any understandable mapping between the columns of data in the data set and the values mentioned in the guide.
It seems to refer to ""Tape Locations"" (?) instead of the columns of the data set, e.g.:

whereas the actual data looks like this:

Not only do the ""Tape Locations"" not seem to correspond to columns, the actual values in the columns are not mentioned anywhere in the guide that I can determine. How can one understand this?
Since this guide seems to be the only resource for interpreting the data, I tried searching on GitHub and Stack Overflow for past researchers facing the same problem.
I found a couple of things, but they are a number of years old (2013, 2014 mostly) and it seems that the data format must've changed since then. For example the data read in by these files was not the .txt files you can now download in a compressed format, rather it was something called DUSMCPUB:
FILENAMES = [
    'VS09MORT.DUSMCPUB',
    'VS10MORT.DUSMCPUB',
    'VS11MORT.DUSMCPUB',
    'VS12MORT.DUSMCPUB',
    'VS13MORT.DUSMCPUB',
    'VS14MORT.DUSMCPUB',
    'VS15MORT.DUSMCPUB'
]

There also seems to have been some sort of pre-processing before the data was read in by the Python code I found on GitHub...
","['medical', 'government']","This is a fixed-width text file. Instead of separating the different variables with a delimiter (like a comma or tab), the locations of the different variables are specified based on character position. If you look on the 3rd page of the 2018 documentation, it says the first 1-19 positions are blank. Then at position 20 there is a residence variable that is one character in length. The codebook indicates this variable is a number between 1 and 4, and provides the description of the variable. Positions 21 to 60 are blank (40 characters long), and then at position 61 you have an education variable that is 4 characters long, and the codebook provides you with the descriptors, etc.In short, to parse the file you need to indicate where to split the lines into the individual variables based on their position. If this were a small file, you could import it into Excel and specify the breaks for each variable prior to import. That's not going to work in this case as the file is too large. I'm not familiar with stats packages, but I believe some of them contain import functions that will allow you to manually specify breaks when importing fixed width data files.If you use Python, there are some suggestions here:https://stackoverflow.com/questions/4914008/how-to-efficiently-parse-fixed-width-filesA simple approach I've used in the past, which you can use with any scripting language:An example of a function to parse a data list using a widths list in Python:"
How can I sufficiently rigorously create a list from news reports?,"
For a research paper I'm currently working on, I need to compile a dataset based on various news reports. Obviously, there's no way I can be sure that my list is exhaustive, but how can I compile data based on scattered news reports I find on the Internet in a way that is sufficiently rigorous and acceptable for an academic publication?
",['best-practice'],
superstore data analysis projects,"
where can I find good projects on retail/superstore data analysis and visualization? I am trying to see the scheme and how to go about it, as well as the different visualisation techniques used? Preferably in R.
",['visualization'],
Month-by-month baby name data,"
I'm looking for a database cataloging the number of babies born with the name ""Isis"" by month, along with the corresponding database for number of female births per month. Ideally, this data would be from a government source for an English-speaking Western nation.
I need this to be by month or some smaller time period, not by year.
","['demographics', 'names']",
Can't Retrieve the OUI (Weekly Unemployment Claims in Reverse Chronological Order with most recent data first,"
I'm trying very hard to get this thing to work.   I'm using the AddOn ""importJSON"" from NoDataNoBusiness on a Google Sheet.  I've got it to a point where I can import data from the OUI, but it is in date order ascending, so I'm getting the stuff going all the way back to 1967 first.   And it limits to 99 rows.
So - I need reverse the order of this and essentially get the last rows.   I'm trying to sort in descending order by date, and I've been following the guidlines for the sort statement - but the documentation is COMPLETELY unclear on how the $ sign and ? sign works, what goes where, and in what order.
My importJSON cell statement looks like this:
=transpose(importJSON($C$1, $C$2))
Here are the contents of $C$1
https://api.dol.gov/V1/Statistics/OUI_InitialClaims/unemploymentInsuranceInitialClaims?KEY=mykey
Here are the contents of $C$2 which filters (selects) the columns I want to look at:
nonSeasonallyAdjustedInitialClaims, seasonallyAdjustedInitialClaims, nonSeasonallyAdjustedContinuingClaims, seasonallyAdjustedContinuingClaims, week, id
I'll attach a sample of the results so you can see how perfectly it's working ...
BUT
I can't get the data in the order I want it.
At the URL for the DOL, they have information about sorting, and they show this:
http://api.dol.gov/V1/FORMS/AgencyForms?$orderby=FormNumber desc
...but when I try to place this in the call line with the key, I'm hosed.   In my particular case, my order by statement, following this logic, would look like this ...
https://api.dol.gov/V1/Statistics/OUI_InitialClaims/unemploymentInsuranceInitialClaims?$orderby='week'?KEY=mykey
It fails.  I've tried every imaginable permutation and combination.  No 's around the word week, only one? mark, I mean - I'm going nuts here trying to get this to work - and I can't.
Can ANYONE help me please so that I can have this run the way it's supposed to?   I'll be in your debt!
","['api', 'labor']",
pct_estimate and pct_adjusted in FiveThirtyEight polling data,"
I'm working on polling data from fivethirtyeight1. What is the meaning of pct_trend_adjusted column here? What are they adjusting for?
","['elections', 'polling']",
Datasets for custom size sudoku puzzles,"
I have found tons of datasets for 9x9 sudoku puzzles, though couldn't find custom size puzzles (e.g block size of 2x5 and board size of 10x10, block size of 7x3 and board size of 21x21).
Any clue on how to find (puzzles or generating algorithms) and (solutions or solver algorithms)?
",['data-request'],
Downloading Pradhan Mantri Gram Sadak Yojana (PMGSY) GIS data?,"
I am trying to download road data from the PMGSY/GRRIS website (http://www.pmgsy-grris.nic.in/). While the in-site visualizations are helpful, I wanted to know if there was a way to access the raw data used to create these maps. My understanding is that it is all stored on a SQL server, but I am not sure if this is accessible to the public.
","['geospatial', 'india']",
MAP Data More detailed for Airports Simulations,"
I am looking for  a map api that would provide data such as this as you can see from this diagram. Little nav map adds the following I need to be able to replicate the same In my apps but I dont see a common format or much information around the process I have been using gmap with some success in that I have placed my plane on the map at the lat and long of the aiport but I need the below information to be added.
It was suggested I posted here in relation to this as I tried on other exchanges.
https://github.com/judero01col/GMap.NET/issues

Runway Numbers
ILS Detail the green aprons of ils
Aiport runway lengths


",['openstreetmap'],
AERIAL IMAGERY dataset of Crops,"
I am working on crop classification and for that purpose i need the datasets of aerial imagery of of different crops. There are many satellite imagery datasets available for this sort of task but i need AERIAL IMAGERY datasets.
",['data-request'],
Looking for public news articles dataset with their associated categories,"
I'm looking for datasets that contain labeled news articles. I'm trying to build information retrieval application using latent semantic analysis.
I've already used:

http://qwone.com/~jason/20Newsgroups/
http://mlg.ucd.ie/datasets/bbc.html

These two are not big enough for my needs. I would like to have articles that are decent sized, liked articles on bbc, and there are a lot of them (more than 10k). What is more they must be categorized. I've found this: https://www.kaggle.com/snapcrack/all-the-news
but there is no info about categories. I can't find anything that would fulfill my needs.
","['machine-learning', 'nlp']",
Does the API return 401k data?,"
Specifically, the data I can see on the https://5500search.dol.gov/#q={criteria} page.
",['labor'],
Seeking Digital Terrain Map of Israel,"
Where can I find an open detailed DEM/DTM model of Israel for some research?
I have found:

https://www.diva-gis.org/gdata
https://www.gov.il/en/departments/general/israel-and-regions-aerial-photo-map
https://www.gov.il/en/departments/general/relief-map-of-israel-2

This one below is 25m and is nice (from the link), but a pdf, not the raster, is provided.

","['data-request', 'geospatial']","You can take the SRTM 1 arc (30m) by going through this web GUI https://dwtkns.com/srtm30m/ to get the links. You need an account on NASA Earthdata (link in the GUI to create one)Israel covered by 5 SRTM tiles e.g screencapture belowYou will need to merge these 5 tiles. You may use ""gdalbuildvrt"" (https://gdal.org/programs/gdalbuildvrt.html) to do so and then convert the resulting VRT with ""gdal_translate"" https://gdal.org/programs/gdal_translate.html Both command line utilities are provided by GDAL. You may also use QGIS to do the same using a GUI but ""I do not know where you are starting from"" concerning your skillsets.PS: All tools mentioned are Open Source and the data is also available freely after creating your NASA account."
Get all historical data for a specific stock?,"
On Yahoo Finance, you don't seem to be able to get any data earlier than from January second 1962, and from Google Finance, the corresponding date is December nineteenth 1980. However, General Electric has been on the stock market since at least 1896 so there has to be more than this. How can I see a company's entire historical stock data? Can I get that data for free somehow or do I have to pay for it?
","['historical', 'stock']",
NLP ITSM / Ticket / Datasets for classification and model fine-tuning,"
Currently I am searching for a public ITSM dataset with NLP features (to perform a classification task - or - to use it for BERT model fine-tuning). Are there any public sources available?
Anything dealing with customer support requests, ticket data, IT issues, IT incidents, security incidents or monitoring data would be fine.
",['data-request'],
Cic 2018 dataset protocol feature,"
the CSE-CIC-IDS2018 dataset has a protocol feature which is integers encoding, what those integers encoding mean, and how many values it has.
","['machine-learning', 'security']",
Geotagged wiki data,"
For a research purpose how can I extract geotagged wiki data (containing page id or titles for articles that refer to particular geolocation) for a city in England.
",['wikipedia'],
Older Satellite Images from Saudi Arabia,"
For Research purposes on ""how Sprawl effects Urbans"", Is it possible to get a 50 OR 40 years old Image of a certain location ( 26°37'59.59""N,  49°58'3.32""E) in the eastern province of Saudi Arabia. Google Earth Pro gave me 15 years back only.
","['data-request', 'geospatial', 'asia']",
Is there dataset of historical geocoordinates of ancient cities and places?,"
Is there a freely available dataset (csv, geojson, topojson, etc.) with geocoordinates (latitude, longitude) of ancient and tombs, for example of the towt? Ideally with additional information like population size?
I've searched Egypt but found nothing
","['data-request', 'geospatial', 'historical']",
Seeking locations data of all police stations in India,"
I want to get the locations of all the police stations in India. There is definitely some data which is present in the OpenStreetMap which I am able to crawl. However, there are about 15,579 police stations in the country and only about 4000 are present in the osm bulk data.
How can I get the data of all the other police stations?
Any kind of procedure even including manual effort will suffice.
","['data-request', 'geospatial', 'government', 'india', 'police']",
Postal code to ISO 3166-2 code?,"
A system I'm developing is using ISO 3166-2 codes / names to serve as a dropdown for users to pick their state / province / country / etc. However, as I recently learned, some countries, like Great Britain, have gone a bit overboard with their subdivisions, making it a bit hard for some users to pick the correct one for themselves. For example, instead of having ""Greater London"", you have to specify the specific borough inside of London, etc.
This made me have an idea that if I took the postal code someone put in their address field I could pre-populate the proper area and not have to ask the user for it, saving some confusion.
I was wondering - is there some list or service that correlates a postal code to an ISO 3166-2 code, ideally on a global scale? I know it's possible to find such data sets for the US or UK individually, but I haven't found anything on a global scale...
","['postal-code', 'address', 'data-mapping']","Geonames has postal codes but they're per city not per ADM1.Eg the city https://www.geonames.org/728378/pazardzhik.html shows post=4400, and in Hierarchy shows its parent ADM1 https://www.geonames.org/728379/pazardzhik.html.This is available in structured data, so you need to find all populated places (featureClass=P) per ADM1 and collect their postal codes.Then you need to find ISO_3166-2 codes of ADM1 from eg https://en.wikipedia.org/wiki/ISO_3166-2:BG and link them to Geonames.Actually it's best to use Wikidata, where this info is connected:Now you need to learn some SPARQL to tie all this up"
How can I get access to IEC TC 10 database?,"
Here is the link with the relevant page. However, I need to sign in into IEC, but there's no option to create an account. How can I get around this? How can I get access to this data?
","['data-request', 'machine-learning']",
Where can I find old global road maps?,"
I am looking for some old global road maps (anytime before 1990 or 2000). Does anyone have any suggestions where I can find such data?
","['global', 'historical', 'map']",
Where can I find geodata on residential building footprint in US (or Texas)?,"
Where can I find Texas residential building footprint data with information on building area and number of floors?
I came across National Structural Inventory github repo (https://github.com/HydrologicEngineeringCenter/NSI) which only contains data description. Does anyone know how I can download the data?
","['data-request', 'usa']",
Annual average temperature and precipitation data set (with data after 2016),"
I am wondering whether any of you knew of data sets for all countries with already calculated annual averages in temperature and precipitation levels? I am aware of all the different websites and databases that give all sorts of aggregated data, mostly daily and monthly.
However, I am rather looking at a ready-made data set as I am not an expert in any geospatial software.
","['data-request', 'climate']",
Data about Power Transformer Failure for predictive maintenance,"
I'm having trouble finding data about this subject, the data banks that I've explored were of little use. Essentially what would be useful is several data about transformer usage, external conditions, maintenance, etc. Does anyone know where I can find it?
","['data-request', 'machine-learning']",
Local instance setup instructions,"
I'd like step by step instructions for setting up OpenFDA in my lab.
The goal is to have the available pipelines populate and update the data in Elasticsearch so that I can make use of Kibana for research.
I have been unsuccessful in attempting this myself and would greatly appreciate any walkthrough, detailed setup instructions, or other advice.
",['openfda'],
Seeking River Thames polygon data,"
I'm having trouble finding data on the River Thames, specifically in the greater London, UK area. I am trying to georeference and digitize a map of the 1666 fire of London for my final project in my GIS class. I figured if I found a polygon of the Thames that I could use that as a reference feature for digitizing, but for the life of me I can only find polyline data.
Does anyone have any suggestions of where to look?
","['geospatial', 'historical', 'uk', 'hydrology']",
Is there a open source database of licensed physicians in the US by state,"
I am creating a database of preferential physicians for special needs families - is there an open-source database of licensed physicians in the US by the state?
","['data-request', 'medical', 'data.gov']",
Meta collection or database of structured vocabularies,"
A short question; does a meta aggregation or collection of ontologies and structured vocabularies which exist out there, each single ones being ready to be used as linked data? (ideally with links to each other)?
I would expect such a collection to be made publicly available by an association or a consortium in the semantic web domain, but I'm not much into it (actually, I discovered this familys of concept a few days ago only, and things are fuzzy so I'm still learning about it).
I found this page until now but without any list of that sort.
","['linked-data', 'ontology', 'semantic-web']",
How to know which are required and recommended linked data properties to use from schema.org,"
On this page, https://developers.google.com/search/docs/guides/sd-policies#completeness we can read:


Specify all required properties for your rich result type. Items that
are missing required properties are not eligible for rich results.

The more recommended properties that you provide, the higher quality
the result is to users. (...)



But on schema.org, I'm not able to find which are the required and which are the recommended properties.
Are these required and recommended properties only a thing which is understandable for the google search algorithms to work well, or are they intrinsic values of any properties of the schema.org vocabulary? In the latter case, how and where can I find them (I'm not able to figure it out on schema.org)?
","['linked-data', 'ontology', 'semantic-web']",
Where can I find sample product data for demo purposes?,"
I'm looking for a product catalog of sample products mainly electronics and clothing that I can use to showcase in demo applications, e-commerce themes, etc.
Any ideas of sources that would be suitable to use for this purpose without copyright issues?
I mean even sample data that don't refer to real products but with images would be fine.
The format could be json,csv,xls and they should at the very least have

name
description
image
category
brand

",['products'],
Most famous list of the rich: Where to find Forbes 400 lists (1982 to 1990). Are they all lost?,"
Question: I am looking for a way to find every Forbes 400 list since 1982. Sources where I can easily download data are best. Anyway, I am also happy about any sources where I can read up all lists.
Background:
Forbes 400 lists contain the richest 400 people of America. The first list appeared in 1982 and thereafter annually a new list has been published.
Downloading as csv (1990-2020) with R:
write.csv(do.call(""rbind.data.frame"", lapply(1990:2020, function(year_i){
 cbind.data.frame(jsonlite::fromJSON(paste0(""http://www.forbes.com/ajax/list/data?year="",
                                             year_i, ""&uri=forbes-400"", ""&type=person"")),
                  year= year_i)})),
 file= ""Forbes 400.csv"")

My problem: The code above uses this source. But there is no data before 1990 and, the data of the first records is not complete, i.e. does not contain all 400 people. This source is the best I have found so far but I can literally find no source with all 400 entries of the Forbes 400 list 1982, 1983 and so on.
","['download', 'open-source']","Since you have the records that are later than 1990, I will only post those from 1982-1989 here. Sadly I couldn't find any records for the year 1984. I guess your best attempt would be to find some archived pdfs or images of the original publication and scrape it yourself. Also there is no main source for the data and they are not perfectly formatted but the following links should help you make your own lists quickly:Recommended related links:"
Is there an open standard for recording pieces of media?,"
‘Social cataloguing’ sites like Goodreads/Letterboxd/etc. allow users to record the media they read/watch/etc., usually with dates, reviews, etc. and social elements. This can also extend beyond media (e.g., Strava for cycling), but here I'm limiting my scope to just the cataloguing of discrete pieces of media.
I've been toying with the idea of developing a self-hosted, content-agnostic cataloguing tool as a personal project, using the ActivityPub standard to handle the social elements.
Does there exist any open standard that would be good for formatting the cataloguing data of a content-agnostic social cataloguing tool? Something like STIX, but instead of describing infosec threats it would be expressive enough to describe books, films, games, whatever but more restrictive than just unbounded JSON.
I've not been able to find any direct answers from online searching. The best almost-solution I've thought of so far is BibTeX, but I know from experience that that gets quite janky the further one gets from academic papers.
","['metadata', 'ontology']",
Does anyone knows any technique to find the location of an object in an image?,"
We are doing a project in which we are detecting (using YOLOv4) runway debris using a fixed camera mounted at a pole on the side of the runway. We want to find out the position of the object with respect to the runway surface. Does anyone know about any algorithm or technique that will help us find out the position of the object with respect to runway dimensions?
","['data-request', 'machine-learning', 'computing', 'deep-learning']",
Where can I find a list of all/top instagram account handles and their number of followers?,"
I am interested in analysing instagram data, particularly some simple text analysis on the user names AKA 'handles' (language, characters, length etc), as well as number of followers for those accounts.
Is there somewhere I can find a list of all instagram account handles and their number of followers?
If not, is there somewhere I can find a list of the top x account handles ranked by followers? (even if x is small relative to the total number of users, it will still be interesting to analyse)
Notes:

I have a strong preference for a dataset that is already created (rather than a web scraper that would go an do it, but that would also be useful).

I don't need it to be up to date - it can be a year or two old


","['data-request', 'social-media']",
COVID level of lockdown by state by month or week?,"
Looking to compare my salespeople's sales to their ability to reach their customers due to lockdown measures. Where would I look to see each state's official response/level of lockdown by week or month through 2020?
","['usa', 'time-series', 'covid19', 'state']","The Oxford COVID-19 Government Response Tracker appears to have the data you want.  The dataset covers the whole world and is day-by-day, so you'll need to do some processing to extract just the US state data and merge or filter it to produce week-by-week or month-by-month data."
Why are the 6 year completion rates at 4-year institutions at times higher than the 8 year completion rates?,"
I have been taking a closer look at HBCU 4 year institutions and am looking at their 6 and 8 year completion rates (C200_4 & C150_4). I have noticed that several of the 8 year completion rates are lower than the 6 year rates. Why would this be true? Shouldn't the 8 year completion rates always be higher?
",['collegescorecard'],"I don't know about the exact schools or years that you are looking at, but in general this situation can easily if the 6-year graduation rate is based on looking at the students who entered in e.g. the fall of 2013 and graduated by 2019; and if the 8-year graduation rate is based on the students who entered in fall of 2011 and graduated by 2019.Those are exactly the entering and graduating classes that every college submitted in their IPEDS surveys last year.  If you're looking at the latest data in the College Scorecard you're probably looking at those years.And as the example shows, those are two completely different groups of students!  Maybe the students who entered in the fall of 2011 didn't do so well and had a low graduation rate whereas the ones who entered in the fall of 2013 enjoyed campus with better support and programs ... or maybe the fall 2013 students were just better.And thus the 6-year graduation rate of the fall 2013 cohort could be higher than the 8-year graduation rate of the fall 2011 cohort."
"User reviews for consumer tech products, but in French","
So I am working on a sentiment analysis project where I need to gather french reviews about some giving product (iPhone XR, PS5, or anything as long as there is enough data), I tried Reddit (praw API) but most of the comments are in English, twitter(Tweeppy API) couldn't get more than 5k reviews because of the API limitations (couldn't get tweets older than 1 week). My question is: if anyone ever worked on a similar project, please could you tell me what API and website you used or if there any other alternatives.
Please feel free to ask me anything if the subject is not clear to you.
","['data-request', 'nlp', 'french']",
Question about total number of drug adverse event reports from 1998-2004,"
Is there a reason why from 1998-2003 the total number of reports in the FDA Adverse Event Database is 235 but after one year there were suddenly increased by about 100000
",['openfda'],"As can be seen here, FAERS data files really start from year 2004. Those 235 records could be outliers that made it into the database as well, but you'd have to contact the FDA directly in case you need a precise answer."
How to find data for classifying grocery store items into categories?,"
I know this doesn't sound like a good question but I've been googling and can't find broad range of data for grocery store items. As in, I want to be able to classify things like:
strawberry, banana -> fruit
potato, onion -> vegetable
cheese, yogurt -> dairy
detergent, dish soap -> cleaning supplies
I don't need it to be certain specificity(there could be a dozen categories or a hundred), but it's just daunting to classify thousands of items in a grocery store by hand when I'm trying to look into the data. What is the best approach?
",['classification'],
Travel warnings,"
Does anybody know a multi-country data source on travel warnings?
I've data sources that cover general travel restrictions during Corona, and data of travel from one country (Country specific information for travellers using opendata api/dataset), but not a more comprehensive data source of country-wise travel warnings.
",['travel'],
Looking up older unitids,"
We'd like to resolve older unitid -> opeid without referencing the crosswalk datafiles directly. However, lookups frequently fail.  The first unit id (and many others) present in the 1996-1997 crosswalk data serves as an example:
unitid,opeid,opeid6
100636,01230800,012308

Attempting to retrieve this from the API:
In [1]: rsp = requests.get('https://api.data.gov/ed/collegescorecard/v1/school
     ...: s?api_key=8CoAdCZ2zCcLHf6ClaFCMPWwQMRWvVb4FVjKJHIY&fields=ope8_id%2Cid
     ...: &id=100636')

In [2]: rsp.json()
Out[2]: {'metadata': {'total': 0, 'page': 0, 'per_page': 20}, 'results': []}

Is there any way to look these up via the API and not have to access the CSV's?
",['collegescorecard'],
MIMIC III - Inputevents_mv\ inputevents_cv IV pumps,"
were the pumps in use when the data for inputevents_mv \inputevents_cv tables was collected, smart pumps? I'm asking because I wonder if the starttime\endtime was entered manually or not for the IV inputs.
",['mimic-iii'],
Foreign Object Debris Dataset,"
Is there any dataset available for detection of Foreign Object Debris (FOD) on Runways and Taxiways of Airports?
We have a project in which we want to detect any foreign object on the runway. These objects mostly consist of airplane parts metal/ plastic/ rubber etc.
Is there any images/ dataset available for this purpose?
","['data-request', 'machine-learning', 'images', 'aviation']",
Could privacy friendly open source OS/software be made for most tech products?,"
This is related to open source, but somewhat a new topic here that I hope you will contribute to in the discussion.
Many are tired of getting their privacy invaded by Google and all companies who take your data with and without consent. Would it not be great if there was an alternative?
Would it be possible to for instance:

To install an app/software that denies any data going from for instance your smartwatch to Samsung, so they can't sell your data? Or from Google Nest to Google?
If this is not possible, could you delete everything on for instance a Google Nest or smartwatch, collaborate on building open-source operating systems so that the product works and does not give away personal data?

The legality could be an issue, but one can argue that when major companies either steal data or take data with consent, you should react to protect the public interests. The Cambridge Analytica scandal should have taught everyone by now that our privacy and data should be better protected. And the companies selling our data to the highest bidders are not someone who should have the power of our data in their hands.
I'm new to IT, so these are questions I cannot find answers to online or here at the forum. If this discussion proves that either of the options can be realized, then I could be interested in bringing any of these ideas to life.
","['big-data', 'security', 'open-source', 'privacy']",
Seeking shapefile of Districts Cyprus in vector format,"
Where do I find the shapefile of Cyprus communities?
I am referring to the small black polygons that made the districts - Famagusta, Kyrenia, Larnaca, Limassol, Nicosia and Paphos in the picture below.
Gadm.org has only level0 and level1. What I needed is probably level2 or level3?

","['geospatial', 'map']",
How do I programmatically and reliably determine how much a sum of money was in some other currency at a given date without paying money?,"
I've long searched for this, but only find entities that want me to pay them money. I don't have money. I can't pay money. This is for my personal, non-commercial use. I can't afford to pay for every little thing I need and which doesn't generate me a cent.
I've also found numerous broken or semi-broken webpages intended for humans to manually look up historical currency rates. These are of no use to me since I need it to be automatable, and don't want to rely on some third party for privacy and reliability reasons. They also have the problem that they frequently only go very shortly back in history, whereas I want a far longer span, at least 1900-2020. (Although if nothing else can be had, I'd settle for just 1990-2020).
It seems like the only way is for me to ""do it myself"" somehow. But to do this, I need some sort of raw data. Large tables for each ""currency pair"" and date, I imagine. Maybe something like a bunch of CSV files like this:
# Date,From,To,Ratio
1900-01-01,USD,JPY,0.5
...

While it would be a lot of annoying and hard work, I could probably do it if I had such (or similar) data. But where would I get that from? And would they also want money from me? Is there some kind of ""public service"" providing such data for ""most"" currencies/currency pairs?
Once I have imported the data into my own local database, I would probably be able to figure out how to actually make it answer questions such as:
How much in JPY was 32 USD worth in 1995-03-25?

Logically, the existing services must get this data from somewhere.
","['economics', 'economy']",
Bibliographic database for books,"
Im developing an application where I need to display some bibliographic information of books (title, author, publisher, description and book cover).
In order to do so im looking for API's to get this data.
I read about the following API's:

Google books
Goodreads
LibraryThing
OpenLibrary

but each has it's limitations such as 1 call per second/ 50,000 calls a day and so on, so im looking for more databases with hope to find a good data with less restrictive limitations.
Any recommendations will be appreciated.
","['api', 'database', 'books']",
Where can I find the country of origin information of migrants who passed away in the Mediterranean Sea?,"
I'm planning on making a video that depicts a map of the locations of the deaths of migrants and refugees that attempt to cross the Mediterranean Sea as time progresses. Specifically, I'd like to show the country of origin of those who passed away. The International Organization for Migration (IOM) has collected data on migrant deaths. In their methodology, it is explained which variables ought to be included in the data sets.
However, some variables appear to be missing. In particular, the “Country of Origin” and “Region of Origin” variables are excluded from the data sets. I've already contacted the IOM about this, but so far they haven't responded to my query.
Questions:

Have these variables indeed gone missing from the aforementioned data sets, or am I just not looking carefully enough?
Is there any way to obtain the country of origin information that belongs to these rows in the tabular data?

","['migration', 'un']",
Seeking data for Deming regression function,"
I have programmed a Deming regression function in VBA for EXCEL. I want to test it but I cannot find a data set. What I find are R codes where the data sets are created, but since I don't know any R this does not help me. Could some one please point me at a data set.
Here is one example in R that I have found.
http://www.lithoguru.com/scientist/statistics/Deming%20Regression.R
I do not know if it is helpful as I don't know any R.
",['data-request'],"I pasted the code from the URL (archive) into RStudio and ran the code. It creates three vectors that, without much analyzing, seem to be input vectors: x, y, y_ideal:Actually y_ideal is just set to x., so really you should only need x and y:The function rnorm() gives you a normal distribution with the variables:N: number of observationsmean: vector of meanssd: vector of standard deviationsI then made a data.frame (aka ""matrix"") with the 3 vectors:a data frame can have an Excel-like view in RStudio:and then exported it to a csv:which I'll put here for your convenience - and onlineThe R script also generates this image:and if you print dem.regInstructions for installing R and RStudio are here: https://rstudio.com/products/rstudio/download/#downloadHere's what my screen looks like - you'll see RStudio has sort of a ""Matlab"" look and feel."
How can I access open food facts through my Application?,"
I need a Database for food and especially ingredients for my App programmmed in android studio.
I found open food facts and tried to implement it in my project but I don´t know how to access the database through my Application.
What should I write in my dependencies?
","['database', 'food']",
Hydroponics/ vertical farming dataset and techniques,"
I am working on a Machine Learning project to improve/automate hydroponics farming systems. Are there any datasets covering crop yields in vertical/hydroponic farming setups? Any hints or tips on how to find such data will be highly appreciated.
","['data-request', 'agriculture']",
Where do I get hourly temperature data for cities with a high spatial resolution?,"
I want to do a project with very high spatial resolution temperature data from a city (any city) with very high resolution (<10 m), in an attempt to create an animated 3D microclimate map for that city (kind of a 3D heatmap).
The data would probably have to be raster data and it should be a time series of any kind (preferably hourly but could also be daily, the goal here is to test the 3D animated presentation). Where could I get such data?
","['geospatial', 'climate']",
What is a good way to find research with statistics data?,"
I'm searching for some researches for a study project , I'm looking for some researches that contains data bases or statistics data so i can apply my project on those researches , any practical way to find researches with such things( statistics data ) ? for example i want a study that shows relation between online studying and 6 different independent variables about the people who practiced in the study ex : gender , age, etc, or any other topics..
",['data-request'],
CO2 dataset from Scripps is broken. How can in inform the owner?,"
I'm using the daily CO2 measurement dataset from the Scripps CO2 Program
Data page: https://scrippsco2.ucsd.edu/data/atmospheric_co2/mlo.html
Direct link to daily dataset: https://scrippsco2.ucsd.edu/assets/data/atmospheric/stations/in_situ_co2/daily/daily_in_situ_co2_mlo.csv

You'll see in the ""good"" csv, that the data continues to almost the present day.

Archived ""good"" csv: https://raw.githubusercontent.com/co2birthdate/dataops/4d2ed6fd5b3987be8b6ce502d592949414275920/input_data/daily_in_situ_co2_mlo.csv
While in the ""broken"" csv, it's spotty data and only until 2006.

Archived ""broken"" csv: https://raw.githubusercontent.com/co2birthdate/dataops/9edf3968806266774e5f97865f9f368d368e8c9c/input_data/daily_in_situ_co2_mlo.csv
--
I suspect that something is broken in the data owner's pipeline, but I haven't been able to bring it to their attention.
I've tried:

Emailing the person listed in the ""data sharing policy""



Contacting them on Twitter: https://twitter.com/philshem/status/1323338982084780033?s=20

Emailing webmaster@ucsd.edu and webmaster@scrippsco2.ucsd.edu



How can I report this ""broken"" dataset?
","['uses-of-open-data', 'environment', 'csv']","Via some emails, I was able to make contact with some people responsible for the data - and they have informed me that the daily CSV has been corrected.https://scrippsco2.ucsd.edu/assets/data/atmospheric/stations/in_situ_co2/daily/daily_in_situ_co2_mlo.csv"
UK house prices including latitude & longitude,"
I am aware of the question House Price Data in UK by LSOA.
While it does have some excellent answers, their granularity is postcode.
That is actually good enough for me, but I need to be able to correlate each house sale price with a latitude & longitude (a bonus for additional data, such as number of rooms/square footage, garage, detached, semi-detached, flats, etc - but I really only need price and lat/long).
I started with the governments data for last month's house sales, of which there were more than 65,000 in the UK in September.
I tried using an Open Street Map NOMI API to get lat/long from post code. But, 65k requests blew the 30 second limit on a PHP script.I suppose that I could pause between requests, or offload that part to the client side & build my map gradually, but that might take 5 or 10 minutes :-(  and that's only for a single month.
So, short story long, I am looking for a data source that has already done the conversion and can provide me with sale price + lat/long for UK house sales, preferably a month at a time.
","['data-request', 'uk', 'real-estate']",
Downloading LIDAR from The National Map,"
I have found the .las file I'm looking for of Mill Basin, Brooklyn, NYC... USGS Lidar Point Cloud NY CMPG 2013 18TWK910955 LAS 2015.
I navigate to the area of interest, create my bounding box, search for LiDAR files, locate the file, click ""Download ZIP"" and the Download link opens a new tab but never downloads anything.
Are others experiencing this same issue? What am I missing here?

","['geospatial', 'download', 'usgs']",
gps coordinates of train routes,"
I have a project wherein having train route information would be useful. Like if I could get GPS coordinates that form the routes themselves I could do maps like https://www.amtrak.com/track-your-train.html using the Simple Polylines API on Google Maps.
Is that stuff publicly available? I'm most specifically interested in this for Texas railroads: https://ftp.txdot.gov/pub/txdot-info/tpp/maps/2016-railroad.pdf
","['geospatial', 'usa', 'openstreetmap']","Both https://data-usdot.opendata.arcgis.com/datasets/usdot::north-american-rail-network-lines and https://hifld-geoplatform.opendata.arcgis.com/datasets/2a9677db741d4a78bd221586fe9a61f5_0/data appear to have this data as KMLs, Shapefiles, etchttps://www.fla-etat.org/est/metadata/rails_abandoned.htm explains the various fields.https://gis-txdot.opendata.arcgis.com/datasets/90f8c6d733274c26b9c8ea25e41fff62_0 has this data for Texas, specifically."
Where to find a dataset where each record includes location?,"
I am looking for a dataset for federated learning that includes the location of each client.
For example a database for:

word prediction where the location of each phone user is also included in the data records.
heart rate where the location of each person is also included in the data records.
credit score to predict financial distress that includes the location of each client.

any dataset that contains the location of each user and is suitable for federated learning is useful for me.
","['data-request', 'location']",
Can we identify that an academic dataset was used for commercial purpose,"
There are many datasets released on the internet. Authors of many of these datasets state that the datasets are strictly for academic usage and not for commercial purposes. Although some datasets are released for both academic and commercial use, many of them are restricted from commercial use.
If someone uses many of these academic datasets to train a model and then offers this trained model as a REST-API based Cloud service to earn a profit, then what is the way to find out that he or she used academic datasets to train the model? Many people might be already using academic datasets to earn a profit?
Similarly, If I collected data from many of my friends and family and published it for the academic research community and did not allow license for commercial purposes, then someone might use this data to build products and sell it commercially? How can we find that my dataset was used unethically? My friends and family might not give their data as they won't like someone to earn a profit from their data?
","['machine-learning', 'uses-of-open-data', 'academia', 'deep-learning', 'models']",
How to find Logos for payment providers?,"
I am implementing a payment system (based on Stripe Elements). Each payment provider as SEPA, Giropay, Sofort, Klarna, credit card, etc. needs its own brand logo icon, to be distinguishable. I spent multiple hours searching for these resources.
Searching, checking licensing, reformatting to or from svg, png, creating black and white versions of the logo. etc. And the whole time I had this nagging feeling that there must be a better way. Does a central resource for such Logos exist that I didn't find yet? If not, what is the way?
","['images', 'finance']",
Is there such a thing as a generic English-language news headline feed in JSON or RSS format?,"
I'm trying to make a mechanism which basically tells me in a few keywords what currently is being pumped out in the major news.
I could of course sit and try to determine which websites currently are the biggest and see if they might have RSS feeds, and deal with all that, and then perpetually keep myself updated as they come and go, etc.
However, that's a huge amount of work which I'd like to avoid if possible.
Is there a single RSS feed or JSON blob somewhere which is constantly updated with all those news sources' headlines in one single computer-parseable feed?
I don't care about the article contents -- just the headlines. In fact, I won't even be reading or storing the headlines, but simply extract keywords from them and store those to see which ones are the most frequent, etc.
Of course, there's always a trust issue with this third party. What if they modify/suppress/add to the headlines in subtle ways? Still, the thought of manually even visiting those websites, let alone finding the RSS feeds, is just a monumental task. We're talking about thousands of major news sources, after all.
(Plus points if it also has a separate feed for other languages than English as well.)
","['data-request', 'json', 'news']",
I am looking for data on temperature by country,"
I would like to performed a spatiotemporal study on COVID-19 in Africa. I would like to study the impact of temperature on COVID-19, but I don't know if there are temperature data for African countries (by country or region).
I am looking for recent and open data on temperature (over several periods) in Africa.
","['uses-of-open-data', 'climate', 'africa']",
Extract chemical names from biomedicine publications,"
I'm looking to build an undirected network of chemicals extracted from biomedicine papers, specifically from MEDLINE. In this network, the nodes would be chemicals and the links would determine publications which mentioned two or more chemicals together. Eg., if A and B are two chemicals, then a link between them would correspond to a paper that mentioned them together. More the papers featuring those two chemicals, greater the link weight between the two corresponding nodes. A paper mentioning 5 chemicals would form a total of 15 links between the 5 nodes - connecting a pair at once. There are tools to extract words, citations, authors, etc. from journal metadata for analysis (like VOSViewer). Is there a way that I can extract the chemical names from titles and abstracts of MEDLINE papers?
","['network-structure', 'extracting', 'pubmed']",
Catalog of all websites on the entire internet,"
Needs
For a project, I am trying to run analysis on a representative sample of all websites on the entire internet.  I'm trying to do things like measure market penetration of certain web technologies, hosting providers, etc.
domainsproject.org
I stumbled across this dataset - is it legit? Has anyone used this data before?  It's based on crawlers, so it'll be biased towards websites that actually get traffic, which for my purposes is totally fine.  The git repo just looks a bit stale - the only people commenting are the maintainers. Before I do much work with this, I'd like a bit of validation from the community.
Other options
Does anyone have any other suggestions on how to get a representative sample of all websites on the entire internet?
","['data-request', 'machine-learning', 'internet', 'web-crawling', 'security']","Regarding git repo: it's not stale, it was updated about a month ago. Still,
there aren't newer/larger and available datasets just yet. If you stumble upon one - just drop a line here, I'll merge it with mine.Anyway, here are some relevant posts:"
What is the difference between OpenFDA's Drug Label API and DailyMed?,"
I am interested in downloading and processing structured product label (SPL) data. What is the difference between DailyMed API and OpenFDA's (https://open.fda.gov/apis/drug/label/) API?
Is one more robust? Does one have a better format?
","['openfda', 'drugs']","DailyMed SPL API (example) returns the actual SPL XML file while openFDA API (example) returns a JSON document containing information parsed out of SPL along with annotations added via the openfda element. The choice between the two really depends on the needs specific to your project.Since you mentioned ""downloading and processing"", please note that you can download all the drug labels in SPL format ""in bulk"" here for further processing on your end or you can download openFDA JSON drug label data in bulk as well."
Best Sources of Earth's Topographic + Bathymetric Data?,"
I used some data from Nasa (Topographic & Bathymetric) to create a 3D (non-round) model of the Earth's surface, nothing insanely detailed. Those images are large enough for what I need, but they are greyscale images that results in only 256 possible values per pixel (even though they are TIFF, Nasa only used 8 bits per pixel! How frustrating!), and thus resulting in banding/jaggedness:

(This is the South-West coast of Australia's Continent Shelf)
So I desperately need something more accurate.
A 43,200x21,600+ spreadsheet of the Earth's surface's data (per longitude/latitude) would work great for what I'm doing, but I would bet that something other than a spreadsheet is what map services and scientist use.
What data format or file type do scientists or other software use for such information that I could search for? I was told that it's GeoTIFF, but isn't that what this was?
Any recommended sites would be appreciated. (Currently using C#) As such, an API could work, but surely somewhere someplace is the data that I can store on my hard drive and read the data in C#.
","['data-request', 'geospatial']",
Seeking Variables Codebook for Merged 2018-2019 PP College Score Card Data,"
Can anyone direct me to where I can access the Variables Codebook for the Merged 2018-2019 PP College Score Card Data? It would be most helpful to connect with this resource by 11/18/2020.
","['data-request', 'collegescorecard']",
Database or API of icao24 (aircraft ID) information,"
Is anyone aware of a database, API, or other source of data on icao24?
I want to be able to give an icao24 (from an OpenSky API), and get some information as much information as possible about the associated aircraft.
","['data-request', 'aviation']","They do have an aircraft database available right on the website (also for download): https://opensky-network.org/aircraft-databaseOtherwise, the usual suspects are there for individual research but no API: https://flightradar24.com/data, FlightAware, Radarbox etc."
EU countries with regions and population density per each country's region,"
I'm trying to create a Europe map with countries in it with Leaflet. Is there a resource that has structured data about each of EU country within regions with population density per region?
","['data-request', 'europe', 'population']",
Existing record (spl_id) now showing not found,"
We are storing spl_id in our DB and using it as primary key in the API. But after some time, when we search it via the API, we get the following response:
{
  ""error"": {
    ""code"": ""NOT_FOUND"",
    ""message"": ""No matches found!""
  }
}

Here is an example:

In this use case, we used the following spl_id: a732f55b-9001-34b8-e053-2a95a90a23ab
URL used for searching medicine:
https://api.fda.gov/drug/ndc.json?api_key=xxxxxx&search=spl_id:a732f55b-9001-34b8-e053-2a95a90a23ab

On the other end:

Here is a current valid API example: https://api.fda.gov/drug/ndc.json?search=spl_id:999ea441-65f0-9946-e053-2a95a90a0753

Not sure why that id is no longer available, but it was valid when it was first pulled from the external API into our local DB.
Any help will be appreciated.
","['api', 'openfda']",
OpenFDA NDC endpoint has multiple RXCUI values for a single product NDC,"
I'm currently operating under the assumption that any two NDCs with the same RxCUI value are pharmaceutical equivalents. Hopefully that's correct.
When querying the NDC data from OpenFDA, I noticed that for any given product NDC, there can be multiple RxCUI values. My understanding of the RxCUI value is very limited, but I would like to get a one-to-one relationship for RxCUI to package NDC. Is this possible?
",['openfda'],
"Where can I find the list of price elasticities of demand for various industrial products, such as electricity?","
I am writing an economic piece and I would like to find estimated that are not older than 10 years at least.
",['economics'],
Road network data with speed limits,"
I need road network data of Sweden with the speed limit of each segment of the road. I downloaded it from https://download.geofabrik.de/ but unfortunately, there are a lot of missing values there. Is there any other website to get this data from?
","['data-request', 'geospatial', 'europe']",
Request: Network device parts images dataset,"
I'm working on a object tracking model and I'm looking for a suitable training dataset. It should contain pictures of parts of networks devices (or even the whole device), mainly ethernet and power sockets, buttons, switches, LEDs and antennas. Even if it's preferable it's fine if the dataset isn't annotated (i.e. labels, bounding boxes).
I'm aware that maybe such dataset isn't that easy to find therefore I'll gladly accept also suggestions on sites to scrape or other crazy ideas. Surprise me!
Thanks for your time, I rely on your wisdom!
","['data-request', 'machine-learning', 'images']",
GDP per IP or location,"
Is it any public database, API where I could download GDP data per location, per city or IP address?
","['city', 'postal-code', 'gdp']",
About Dataset：HYCOM Water Temperature and Salinity,"
I am using the dataset HYCOM Water Temperature and Salinity for my work. However, I find its image ID a bit confusing. For example, for the ImageCollection filtered by Date of '2019-01-01' to '2019-01-02', there are 8 images for one specific day which seems to have no difference:

HYCOM/sea_temp_salinity/2019010100
HYCOM/sea_temp_salinity/2019010103
...
HYCOM/sea_temp_salinity/2019010121

I am wondering if there is anyone who knows the temporal resolution of this dataset and the rule of image ID naming.
",['uses-of-open-data'],
Preserving user-privacy whilst enabling strangers to perform data analysis on some form of private data,"
Context
This question is about the intent to analyse taskwarrior data of people to improve automatic schedulers of tasks for individual taskwarrior users. This intend is accompanied with two desires. However I am not sure whether these two desires are realisable without compromise. The desires are:

Users of taskwarrior are able to maintain privacy when they share their taskwarrior data. The user don't have to trust the data-analyst with their private data whilst still allowing their data to be used in data analysis.
The second desire, is the ability for any arbitrary data-scientist to perform analysis on the data.

Doubts

The simplest conclusion I would draw is: one can't perform data analysis on data that is not seen/accessible.
Yet, I thought
differential privacy might be a suitable tool to grant users privacy
whilst also enabling arbitrary datascientists to perform analysis on
that data. Though, I can't quite wrap my head around the privacy implications in scenarios where people enter identifying information along with a secret in a single ""datapoint"". For example, suppose it is a taboo to bake pancakes, and a person enters a task description secretly bake pancakes *with my mother Joe at 4 O' clock on  1930 under the northern corner of this meadow at the blabla street 33 in Somecity*. This would contain a secret, e.g. baking pancakes, and it would identify the person because, suppose, there were only 1 person in this world with a mother named Joe that were on the northern corner of that meadow at that city.

I am not sure whether differential privacy is able to automatically obfuscate, with mathematical certainty whom the person was that baked pancakes, or what the person was doing at that time and place with that company. It is also not clear to me up to what extend this would require some intelligence to pre-process the data and set up the dataset that is parsed through a differential privacy software to yield an anonymised data set.

I thought perhaps if the entire dataset is split into an encrypted sample- and an encrypted label dataset, that the relative patterns might be preserved, and I thought perhaps that would allow deep learning algorithms to train on that data and make predictions on new data that follows the same encryption.

Question
Are there solutions that allow arbitrary data-scientists to perform data analysis on datasets whilst maintaining privacy of the persons whose data is in the datasets, without relying on the ""intelligent"" filtering of some person that preprocesses/prepares the data?
","['releasing-data', 'best-practice', 'privacy']",
How to find different nodes in proximity to each other in OSM?,"
I have been tasked with researching good locations for vending machines.
I have positive factors such as:

School nearby
Bus Stop nearby
Gas station nearby

Then I have some negative factors like:

fast food joints
super markets

and others.
I am trying to find a systematic way of identifying good places.
What I really need is to display nodes, which are nearby each other but are not nearby my negative list.
So far I managed to display multiple types of nodes in overpass turbo with the following code:
/*
This has been generated by the overpass-turbo wizard.
The original search was:
“amenity=school”
*/
[out:json][timeout:25];
// gather results
(
  node[""highway""=""bus_stop""]({{bbox}});
  relation[""amenity""=""school""]({{bbox}});
  relation[""industrial""=""factory""]({{bbox}});
);
// print results
out body;
>;
out skel qt;

https://overpass-turbo.eu/s/ZVJ
Bus Stops and Schools are shown, however, factories for some reason are not.
How can I filter from here to, for example only show bus stops and school in close proximity to each other? How do I exclude nodes based on proximity to other nodes?
Are there any other useful methods I should look at to achieve my aim of finding the best places for vending machines? Is there a way to visualize traffic statistics (busy roads) on OSM?
","['geospatial', 'openstreetmap']",
Datasets for Activity Detection from images,"
I'm searching for some datasets to implement a Human Activity Recognition model I can use on images/videos. Most of the datasets seem to be using sensory data obtained through an accelerometer along with other parameters. I would like to know if there are any image datasets for the same.
","['data-request', 'machine-learning', 'images']",The following links include various resources related to your search:
Binary classification: dataset with a binary output where I can apply logistic regression,"
I am looking for a dataset with binary output. I would prefer it to be something like years of experience, salary, and a binary output like a subscription to a website. This is to create a use case for logistic regression. I looked on glassdoor for the salaries of data scientists but it doesn't seem there is an available xhr, and it doesn't look like we have their years of experience neither. I tried to generate it using distributions but I wasn't convinced by the results:
from scipy.stats import poisson, truncnorm
import matplotlib.pyplot as plt

def get_truncated_normal(mean=0, sd=1, low=0, upp=10):
    return truncnorm(
        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)
    
years_of_experience = poisson.rvs(mu=4, size=15)
salaries = get_truncated_normal(mean=45000, sd=5000, low=38000, upp=57000).rvs(15)
subscriptions = [random.randint(0,1) for _ in range(0,15)]
data = [[experience, salary, account] for experience, salary, account in zip(years_of_experience, salaries, subscriptions)]

Which creates:

Whereas I'm rather looking for something like:

",['data-request'],
Looking for Export Processing Zone Database,"
I am looking for GIS data on Export Processing Zones (for all countries where data is available). I have googled the various free GIS data libraries and not come across any such dataset. If you can guide to me to one (or several) that would be great.
",['global'],
Elder patient dialogue corpus,"
I am looking for a corpus with dialogue between elderly patients (in a nursing home, hospital, their houses) and caregivers (nurses, doctors, family members). Do you know of anything like this?
","['medical', 'nlp', 'text']",
FAERS Quarterly Extracts and openFDA,"
Does anyone know, on average, how long it takes for openFDA to be updated once the quarterly extracts are released? Is there a way to track this? TIA
","['openfda', 'releasing-data']","openFDA refreshes its Drug Event endpoint once a week, which means a new quarterly FAERS release would get picked up within 7 days after the release.You could track this, for example, by making periodic calls to https://api.fda.gov/drug/event.json and checking meta.results.total value. It increases significantly with each FAERS release."
Alignment between openFDA and PV data,"
I figured it might be worth a shot to pose this question here. We are analyzing adverse event data from openFDA related to a specific product. As an exercise, we looked at specific events over a 10-year period and compared the data from openFDA to the manufacturer's own pharmacovigilance (PV) data. We found that the PV data contains cases that are not in openFDA, and openFDA contains cases that are not in the PV data. We were hoping to see better alignment between the two sources and are struggling to account for the differences since identical criteria were used to query both sources.
Perhaps a long shot; however, would anyone be able to provide a plausible explanation for why discrepancies might exist between the two sources?
",['openfda'],
"Which attributes may be used for Field Capacity, WIlting point and Available Water Content as mentioned in the metadata of SoilGrids v1?","
I would like to use the layer for Field Capacity, Wilting Point & Available Water Content (difference between field capacity & wilting point). What does the following attribute mean as mentioned in the metadata file of SoilGrids v1 -

Derived available soil water capacity (volumetric fraction) with FC = pF 2.0 for depth 0 cm
Derived available soil water capacity (volumetric fraction) with FC = pF 2.3 for depth 0 cm
Derived available soil water capacity (volumetric fraction) with FC = pF 2.5 for depth 0 cm
Derived available soil water capacity (volumetric fraction) until wilting point for depth 0 cm
Derived saturated water content (volumetric fraction) teta-S for depth 0 cm

",['soils'],
Looking for AutoLot database that comes with Pro C# book by Andrew Troelsen,"
I am following the book in subject line. Chapter 22 works with database and the book uses SQL Server database called AutoLot.
I don't want to recreate and fill this database with all entries. I search its git source code here but it doesn't have the database (I don't know why). I can't find it anywhere else either.
Can someone please help me find it?

","['data-request', 'books']",
Is there a free open database of all companies/businesses in the world?,"
Is there a free open database of all companies/businesses in the world? If not, how would you go about building one, what would you need to do?
","['data-request', 'business', 'opencorporates']",
"Is there a Simplified Chinese thesaurus file, like Moby for English?","
I'm looking for a manually curated thesaurus/synonyms file for Simplified Chinese. Like the English Moby thesaurus, but in simplified Chinese. Does such a thing exist?
I'm aware that WordNet can be used to obtain synonyms, but, in English at least, it is not very comprehensive.
To clarify:
I need it to be manually/human curated, not based on statistical similarity as I am already doing cosine similarity based on a large corpus, and this is intended to be an additional check.
It needs to be an offline data file so I can use it for automatic processing.
","['nlp', 'language', 'text']",
Data on Consumer Price Index (inflation rate) by state (USA),"
I'm looking for a dataset that would contain historical CPI/inflation for each state of the US.
It seems that bls.gov should have this data, but it's either regional (South/North) or area (city/town) based data. 
","['data-request', 'usa', 'economics', 'cpi']",
LiDAR coverage East Africa,"
I want to use ArcGIS to pinpoint the location of fossils.
There are three variables related to the fossils: (i) lat/long; (ii) elevation.
All of the fossils are hominin fossils found in East Africa.
I would like to know if LiDAR exists for East Africa (Kenya / Turkana) regions? If not, is it possible to do this project without LiDAR?
The reason I want to use LiDAR is to get a more in-depth view of the landscape to examine fluvial landforms such as rivers, terraces, and lakes - but maybe it is still possible to do this in ArcGIS Pro without LiDAR?
",['research'],
Cryptocurrency historical prices,"
I'm looking for cryptocurrency historical data, including prices and market cap (either from exchanges or average price) of the main cryptocurrencies, namely: Bitcoin, Ripple, Litecoin, Ethereum, Dash.
So far I've only been able to find this source on Quandl and the historic daily price on blockchain.info 
Any additional additional sources for other cryptocurrencies and more detailed data (like hourly price or Open-High-Low-close) will be helpful.
Ideally the data should go back as far as possible but realistically data since 2012 would be enough. As for younger cryptocurrencies 1 or 2 years will suffice.
","['data-request', 'finance', 'historical']","As it turns out there are several resources one can use for all main cryptocurrencies so I will post here the most relevant and flexible I was able to gather.All CryptocurrenciesCoinmetricshttps://coinmetrics.io/data-downloads/This page has data for: Bitcoin, Litecoin, Ethereum, NEM, Decred, ZCash (transparent transactions only), Dash, Dogecoin, Ethereum Classic, PIVX, Monero.ETH -  BTCPoloniex As chartPoloniex As JSONOne needs to edit the timestamps in the API to get a different snapshot. And edit the period to adjust the details.BitcoinCoindesk Closing price and OHLCClosing price blockchain.infoBitcoin data on QuandlBitcoin data on Quandl IIEtherThanks to the answer to this question on Ethereum's stackexchangeEtherchain's APII will keep updating this answer with more links as I find them."
How to search for the number of papers per year worldwide?,"
I want to know the number of papers published by the year from the last 100 years. Where can I find that? or How can I create that?
I'm completely lost because with few searches I found nothing, just the papers relatives to a specific topic like artificial intelligence or aquaculture.
",['data-request'],
Does anyone know a similar dataset for training a neural network?,"
I'm looking for an eCommerce dataset, which works with implict data and should be suitable for a neuronal network. This dataset should be equivalent to the Spotify Million Playlist Dataset Challenge (please see below)

Instead of the tracks, there should be the order with different articles. The dataset that I'm looking for should be:
""order"": [
               {
                   ""orderid"": ""01"", 
                   ""order_at"": 1493424000, 
                   ""num_articels"": 5,
                   ""price"": 120.85 
                   ""articels"": [
                       {
                           ""pos"": 0, 
                           ""articel_name"": ""Apple"", 
                           ""articel_id"": ""articel1545"", 
                           ""price"": 12.45, 
                   ""amount"": 2, 
                       }, 
                       {
                           ""pos"": 0, 
                           ""articel_name"": ""Banana"", 
                           ""articel_id"": ""articel1585"", 
                           ""price"": 5.45, 
                   ""amount"": 1, 
                       }, 
                      ...
                  }

It doesn't matter if json, csv or other formats.
Does someone know a dataset that is similar to what I'm looking for? Thanks for suggestions, ideas and answers!
",['data-request'],
Seeking web service to return waterbody names for “unimpaired water segments”,"
I am looking for a dataset or a web service that can return a list of unimpaired water segments.

There exists ATTAINS, a web service that will give the name of ""impaired water segments"" by using - a 12 digit HUC, and an Assessment Unit Id.

But I need a dataset for ""unimpaired water segments"".
Would anyone happen to know where to find one?
","['data-request', 'geospatial', 'environment']",
Open data for Visible cell towers outside the US,"
I've been trying to find an open data source for cell and radio towers. OSM often includes these, but not in the areas I am looking at outside the US. I've been trying to see what I can get from opencellid.org but as their FAQ says:

In addition, one of the basic rules of OSM is to map visible things. This is not the case here as MCC/MNC/LAC/CID are not visible in most cases.
Therefore, only a very small number of cell towers is currently mapped in OSM with MCC/MNC/LAC/CID tags.

What I really need is the location of actual visible large cell towers, and ideally some idea as to their type.
Any ideas?
","['data-request', 'open-source']",
Weather data: hail data for europe (belgium),"
Does anyone know any website where I can get (in structured or unstructured form) data for hail events in Europe (especially Belgium)? I've found quite some (paying) sites for the US/Canada, but no site for Belgium. Ideally, I would need the size of the hail fallen and localization information.
","['data-request', 'weather']","Sometimes it helps to search in different languages, so since you are interested in data for Belgium, maybe it is worthy to search also in French and Flemish/ Dutch and German."
Linguistics. German verbs,"
One might think that this question should be on the StackExchange German site, but they appear not to like requests for lists and such like. Hence this post ...
I'm looking for large electronic list of German verbs with the following essential fields: infinitive, 3rd-person present indicative, 3rd-person simple past, and the past-participle. For example, in the case of the irregular verb, bringen, the list would have

bringen, bringt, brachte, gebracht,

and in the case of the weak verb, sagen, the list would have

sagen, sagt, sagte, gesagt.

I'm particularly looking for a list that separately lists verbs (where they exist) with the various separable and inseparable prefixes, such as

ab-, an-, auf-, aus-, be- emp, ent-, er- ge-, miss-, ver- zer-,

etc.
I have been able to locate printed lists such as the Collins Pocket German Verb Tables (ISBN 000470153-4) which are quite comprehensive. However, aside from the disadvantage of not being in electronic form, the book does not list the parts I'm looking for. Instead, the body of the book consists of 200 example verbs to which some 2000 verbs are then cross-referenced. The wanted material is all there, but in a very awkward form for linguistic purposes.
","['data-request', 'language']",This verbs.csv seems to be exactly what you are looking for. It includes 8049 verb with their associated conjugations. The list is part of the german-verbs-database.
Open databases representing a tree,"
I'm looking for open databases representing a tree data structure. I've already found the animal taxonomy, which is a perfect use case, but I'm looking for further open databases, focusing on a topic of commercial and/or scientific interest. I've found several databases representing a directed graph, but I have difficulty at finding databases representing a tree.
",['data-request'],
Where to find large survival dataset with at least one time dependent variable?,"
Looking for a large dataset for survival analysis where at least one of the variables is time-dependent.
For example, this a sample dataset:
    time status sex age year thickness ulcer
1     10      3   1  76 1972      6.76     1
2     30      3   1  56 1968      0.65     0
3     35      2   1  41 1977      1.34     0
4     99      3   0  71 1968      2.90     0
5    185      1   1  52 1965     12.08     1

Ideally, I would want the ""thickness"" time history progression for each element/row until event time.
I have had no luck to find such dataset thus far.
","['data-request', 'medical', 'finance', 'metadata', 'time-series']",
OpenFda data seems to grow lot each quarter,"
Why the data we get from openfda seems to grow a lot each quarter? The 2020Q2 openfda csv file we create is 2.3GB vs the 2019Q2 data which is 1.3GB. On the other hand, the FAERS data only changed from 118MB to 123MB in the same time period.
",['openfda'],
Where can I find datasets to predict rainfall for a certain city?,"
I am seeking datasets for predicting rainfall with the help of the following variables:

Temperature
Wind Speed
Humidity
Air Pressure
Quantity of Rainfall

Please suggest and advise.
","['data-request', 'weather', 'climate']",
"Are weekly CRON jobs possbile for for openFDA, new indications_and_usage inquiries?","
How would I track new FDA drug indications or other major changes each month?
Example Dupixent expanded its atopic dermatitis indication from 12 years + to 6 years + in May 2020.
How could I set up a CRON job to check for new indications each week or month?
e.g. ' indications_and_usage ' family, 'purpose' parameter
e.g.  'Other fields' family, 'recent_major_changes' parameter
Example Inquiry:
https://api.fda.gov/drug/label.json?search=effective_time:[20110501+TO+20121231]&limit=1
","['api', 'openfda']",
Extracting Smartphone Data From a Webpage,"
I'm try to do some data analysis on smartphone prices but am having trouble finding a dataset. The data found here looks like exactly what I need, but it's in this interactive chart format. I was wondering if there was a way to extract the data put into this chart as a .csv file so that I can use it in SAS and R for data analysis. Any help is appreciated!
",['data-request'],
Determine Heating costs in $/kWh for a specific location,"
Suppose I wanted to find the average heating price for a specific location in the US, where:

heating_price: The price of equivalent unit energy intensity of heating energy source (e.g. natural gas), measured in $/kWh.

Is there a public API that would return such information for either residential, commercial or industrial spaces? After doing my own research I am able to find electricity costs/general energy costs but am unable to find endpoints or data specific to heating.
Disclaimer: I apologize if this is the wrong Q/A forum to ask in advance. If you could please redirect me to the proper site/SE site that would be helpful.
","['api', 'energy']",
Finder API Access,"
I'm trying to find an API key to access https://finder.healthcare.gov/#services.
The form to request the API Is broken.
How do I get access to the API?
","['api', 'healthcare-finder-api']",
Finding historical Air pollution data from Johannesburg,"
Where can I find historical Air pollution data from Johannesburg? I need hourly data (or a smaller resolution, such as 15 minutes, which is probabaly harder to find). Tried googling this online yet got no useful results.
The closest thing I found was this site, and it wasn't useful.
NOTE: by historical I mean from past years till today, 2015-2020 would be good for example.
","['data-request', 'weather', 'meteorology']",
Peer to peer communication dataset for research,"
I am looking for a peer-to-peer communication dataset, chat data, emails, phone calls, etc... any kind of conversation text between pairs of people for research. It would be much useful if the genders(or the names/nicknames) of both sides are labeled.
P.S. The language is not important. English, Spanish, French, German, Russian, Indian, etc... all welcome.
","['data-request', 'research', 'language', 'text']",
Credit-card fraud data set wanted,"
Recently I found this paper about the use of random forests to detect and prevent credit card fraud.
In this paper the authors use a dataset with more than 30 million records from a Chinese e-commerce company. Does anyone know if this specific dataset is available? I'm a grad in computer science and I'm currently studying this subject. This database will help me a lot.
","['data-request', 'china']",
Knowledge clusters,"
I've worked on a simulation of understanding the rate at which new concepts are found, and I'm looking for a dataset to test this on. I looked at this paper and they tested some of their hypotheses by developing clusters out of single chemicals annotated from MEDLINE publications. What they did is non-trivial and frankly out of the scope of my understanding. But I need something similar. I want to look at journal papers in some year range, and look at how many new concepts were found in that time period and how they are associated with each other. Because if a new concept is found in an area that is relatively new, it often leads to multiple new concepts found in that same general area in a short period of time, thus leading to a new cluster. This can be seen in the following figure from the attached paper.

As new chemicals related to DNA were found, slowly a cluster of DNA and Molecular Biology was formed. Thus, in the above figure, I'd look at the number of clusters and the number of nodes (chemicals) in each cluster at a year, say 1990, and then at say 1996. The number of new nodes (chemicals) found in that period would form my dataset, and I'd try to set my parameters such that my simulation finds all those nodes in the correspondingly correlated time period. Are there any datasets that allow me access to such information of concepts in the form of clusters? If not, is there a relatively easy way to form such a dataset of clusters?
",['data-request'],
How do I get the Url for a specific Medical Device Recall via API?,"
When I call the API to get information for a specific Medical Device Recall how can I get the URL for that specific recall?
f.e. when I call: https://api.fda.gov/device/recall.json?search=product_res_number: ""Z-0997-2015""
is there a way to find out the related URL: https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfRES/res.cfm?id=131452
Or is there a way to find out the id at the end of the URL?
","['data-request', 'api']",
Searching for a specific file name across websites on Wayback Machine,"
Is there any way to find all occurrences of some file on the entire internet, as captured by the Internet Archive? I want to wildcard-search for a filename.
Of course, this doesn't make sense with basic filenames like index.php, but say you are looking for OOo_1.0.3.1_Win32Intel_install.zip but cannot find it anywhere using regular live search engines – can the Wayback Machine help with that? https://web.archive.org/web/*/*OOo_1.0.3.1_Win32Intel_install.zip e.g. would not not return anything. But it looks like it should: There is https://web.archive.org/web/20150411035821/http://download.oldapps.com/OpenOffice/OOo_1.0.3.1_Win32Intel_install.zip.
And if not directly, maybe using the Python library? The documentation did not help out, neither did the Search Guide or the WM FAQ. Maybe there is a mirror for some kind of WA metadata database that you can download, so you can build your own queries? Did not find anything either.
","['web-crawling', 'html', 'archive.org']","I now contacted the IA directly and Mark Graham kindly told me that this is impossible, as there is no fts url index."
Data about credit card fraud,"
Does anyone have information about the ratio between fraud and valid credit card operations? I found data about the absolute number of frauds, value lost because of them, and so on, but the relation between fraud x and ok operations is pretty hard to find.
","['data-request', 'research']",
How do I find a list of all dictionaries available as XDXF?,"
The only reason I know about XDXF is that this dictionary mentions that it supports it: http://folkets-lexikon.csc.kth.se/folkets/om.en.html
Now I'm trying to find all other dictionaries, in many different languages, but primarily English, Swedish, Finnish, Norwegian, Danish, German, French, Dutch, Japanese, Korean, etc. I pretty much want them all. And several ones for each language, if possible, so that I can make a gigantic local database of them and never have to send any individual requests to external websites again, and make all kinds of queries which would not be possible unless hosted locally.
I would then be able to make a nice quick list of words in all kinds of languages based on what I input into my system.
However, I've spent significant time now and not found anything. Just the usual nonsensical, outdated source code repositories with cryptic, undocumented information which has nothing to do with what I'm searching for.
Other than spending weeks manually searching through every online dictionary and click around their websites only to find that maybe a couple of them have XDXF files for download, is there some way for me to get links to them in one location?
Note: https://en.wikipedia.org/wiki/XDXF has a teasing link called ""XDXF dictionaries repository"", but it actually links to no such thing.
","['data-request', 'dictionary']",
Free abbreviation dictionary for commercial use,"
Is there any abbreviations dictionary that I can use for free in a commercial application?
There are great sources of English abbreviations like

https://www.abbreviations.com/
https://abbreviations.woxikon.com/

that I used as a student, but back then I was not using them for commercial purpose.
One thing I like about those dictionaries (and that would be an additional bonus) is that they offer me a way to choose between possible expansions of a short form based on the domain, e.g., LOTR can be expanded Lord Of The Rings in pop culture, and to Legend Of The Rangers in military domain.
",['dictionary'],
What is the next step in the decentralization of education about data analytics?,"
Recently, ArXiv partnered with Github to host links to repos implementing theory contained in papers (possibly eliminating the need for universities and formal education).  What is the next step in making data more available and discoverable...perhaps convincing ArXiv to also request authors provide links to the data sets used by the code in their papers?
","['uses-of-open-data', 'internet', 'academia', 'git', 'research-papers']",
Database for Old Photo Restoration,"
Old Photo Restoration via Deep Latent Space Translation (https://paperswithcode.com/paper/old-photo-restoration-via-deep-latent-space)
I am part of a graduated semester project. Do you know if we can find a photo database related to this article? We would be interested in reproducing their work via programming. We need at least 1000 pictures for the training phase.
So far, we have already asked to provide us the data.
",['data-request'],
Local Accident Data,"
Is there somewhere I can get detailed information on real-time traffic accidents?
The data I need is accident location (zip code is best) and the names of the people involved.
","['usa', 'traffic']",
Road traffic per national road in the Czech Republic,"
I'm looking for road traffic count/volume (i.e. number of cars) per road in the Czech Republic. Something like this, although it should ideally be

from recent years;
a tabular dataset, not an image;
per national road (not a must, e.g. per detector is fine as well);
hourly data (yearly averages are also ok, if nothing else is available).

I searched for a while now, also on official channels like the Czech Statistical Office, but to no avail. The data should exist somewhere, since the National Traffic and Information Centre apparently measures volume of traffic. I don't know whether this data is published though and if so, where.
Any help is greatly appreciated!
","['transportation', 'traffic']",
Mismatch in Export/Import for countries in Comtrae,"
I'm trying to analyze export & import data by countries & their partners in UN Comtrade. As a check, I tried extracting data between China and US for one commodity = 850120.
My assumption was export data as reported by China to US and import data as reported by US from China would be equal. But it doesn't seem so.
China says it exported ""27,385,806"" and US says it imported ""61,328,903"". Would anybody know why there is a difference? My assumption is both are in USD. If that's not the case, where can I find what unit was used?
Here is the full data and this is the link I used. 156 is country code for China and 842 is for US. If you reverse them (between ""r"" - reported by and ""p"" - partner country), you can get the data for the opposite flow
https://comtrade.un.org/api/get?r=156&px=HS&ps=2017&p=842&max=5000&freq=A&cc=840682&type=C&fmt=json

","['global', 'trade', 'un']",
Getting SIC Codes for Companies,"
I have got a dataset with names of companies and I am trying to retrieve their SIC codes. Is there an API accessible via Python that'd allow me to do so?
","['api', 'business', 'industry']",
"Statistically who gets higher **average** income, an employed engineer or an IT startup founder?","
Starting your own startup is a great idea, you may become as rich as Jeff Bezos, Elon Musk, Bill Gates or Mark Zuckerberg. Wait... or may not. It of course depends on your skills and perspiration they say. And some mention luck.
If we look at all the IT engineers who are employees in Silicon Valley (or better in the entire US, UK, or EU) and all the IT engineers who were brave to become a startup founder (failed or not) and calculate the average employee income and startup founder income. What would be that figures.
In other words, whether being an employee or being a startup founder gives you a higher average reward as an IT engineer. Statistically is it worth running after that carrot called own startup as opposed to sitting in the office chair 9 to 5?
Does anyone know about any available datasets around this?
Apologies if I posted it in the wrong stackexchange, in this case please point me to a right one...
","['data-request', 'usa', 'uk', 'economics', 'europe']",
Data/information on ferrocyanide production,"
I am working in the modelling and environmental evaluation of redox flow batteries based on Anthraquinone and ferrocyanide. Currently I am having difficulties in finding information on how ferrocyanide is produced, for example as Potassium Ferrocyanide.
Does anyone know where I can find information or data concerning its production, if possible at an industrial scale.
","['products', 'environment']",
Finding historical London meteorological data,"
Where can I find historical London meteorological data at a minimum resolution of 15 minutes (and not just hourly data)? The data needs to be from a station close to the London bridge. I found that St. James park station is the closest one but I only found hourly data, from here for example: http://rp5.co.uk/Weather_archive_in_London,_St._James's_Park
Specific types I need from the weather data: Humidity, Temperature, Wind speed, Wind direction.
","['data-request', 'weather']",
How do I actually find non-garbage data?,"
For a very long time, I've been hunting for sources of data to process in my database. I've found that everything is either behind a pay wall and wants me to pay (lots of) money, which I don't have, or it's ""allegedly"" available but so well hidden behind an eternal maze of weird links and cryptic webpages (government websites) that it might as well not exist.
Only in an extremely small number of cases have I been able to actually find any kind of non-garbage data set for me to automate downloading and updating my database with, which can actually be used for anything.
I've found websites listing ""free APIs"". These are always complete trash. I've gone through them all and they are all ""novelty"" nonsense such as ""random joke"" or something useless like that. The kind of data I want is meaningful statistics and information which can actually be used for something.
Besides, ""APIs"" are fundamentally privacy-disrespecting even if free and even if they have some sort of useful data. I don't want to announce to the world or some external party what piece of information I want in real time; I want to have the whole dataset locally and make ""secret"" (local) queries on that, without anyone knowing what data I'm using/interested in.
Is there a real website which actually has collected real data sets of non-garbage data? I don't even mean that they need to have ""processed"" it in any way; just that they link to the sources where I can manually figure out how to grab and process it.
I'm not mentioning any specific kind of data here because my data needs are very general. In fact, I want to base whatever service I'm going to build on whatever data is actually available, as I can't just decide to do thing X, and then try to find data for it, since I can never find any quality/updated data for whatever really interests me. So instead, I hope to become inspired to build some sort of service by learning that some kind of data is actually available for me to process and present in some useful manner for people.
","['data-request', 'open-source']",
How to get building elevation and levels,"
Is there any API or DataSet available to know the Building elevation and levels based on lat and long. I need data for North America(USA)
","['geocoding', 'openstreetmap']",
"How are Wikipedia subcategories meant, semantically?","
Let's have a look at the category
https://en.wikipedia.org/wiki/Category:British_politicians
Theresa May is not in it. So let's see:

Theresa May is in Category:20th-century_British_women_politicians
which is in Category:20th-century_British_politicians
which is in Category:British_politicians_by_century
which indeed is in Category:British_politicians.

So those categories seem to be inclusive: the items of a subcategory are thought to be in the parent category as well.
However, then we have the following problem:

The 2019_Conservative_Party_leadership_election is in the category Category:2019_Conservative_Party_(UK)_leadership_election
which is in Category:Theresa_May
which also is in Category:20th-century_British_women_politicians

Uh, so this means that the 2019 Conservative Party leadership election is a British politician too?
So there seem to be two kinds of ""subcategory relations"":

this category is a subcategory, all its items belong to the parent category (Theresa May --> British politician)
this category is just related to that parent category (2019 election --> Theresa May)

Is that just messy, or am I missing something to distinguish between the two types?
",['wikipedia'],
Looking for Skills Taxonomy with Industry specific,"
Like O*NET database which have skills categorized on based on occupations defined by BLS Standard Occupations, is there any dataset similar that can provide skills categorized based on industries as well?
","['data-request', 'usa', 'metadata']",
What happens if federal statistical agencies and executive departments don't upload data regularly?,"
If federal statistical agencies in USA and executive departments of the US Gov don't upload unbiased data on open data platforms or in general don't release information on time, are they penalized? Is there any law which governs them? Are they terminated, what happens exactly?
","['data-request', 'usa', 'data.gov', 'research', 'research-papers']",
Estimate drug costs by RxCUI from NADAC data,"
I'm trying to estimate Rx costs using the National Average Drug Acquisition Cost (NADAC) dataset. Essentially I lookup drugs using the RxTerms API, which provides RxCUIs, strengths and forms and different display name for search terms. NADAC gives pricing by unit which may be GM (I'm assuming gram), ML (I'am assuming milliliter) and EA (I'm assuming each e.g. per pill or per vial etc.). The issue here is that sometimes the string provided for strengths and forms from RxTerms is a bit ambiguous. For example:
RxTerms data:

Name: Insulin analog, lispro (Injectable)
RxCUI: 242120
Strength & Form: 100 unt/ml Sol

NADAC data:

Name: INSULIN LISPRO 100 UNIT/ML VL
Pricing Unit: ML
Price Per Unit: 13.171067241379319

Here the pricing is in ML, but the strength is 100 units per ML solution (NADAC name indicates vial but that isn't helpful), but doesn't indicate the quantity held in the vial. I spoke to a GP to see if perhaps this meant the vial held 1 ML but he said he couldn't recall any 1 ML vials he's prescribed. Not definitive but then I compared it to other similar Rxs, like:
RxTerms data:

Name: Insulin analog, lispro (Injectable)
RxCUI: 1652639
Strength & Form: 100 unt/ml Pen Injector 3 ml

NADAC data:

Name: INSULIN LISPRO 100 UNIT/ML KWIKPEN
Pricing Unit: ML
Price Per Unit: 16.962141551724123

Here at least the size is indicated as 3 ML. How can I get the total units of the first example?
I can provide other examples of ambiguous strength & form strings if needed.
","['medical', 'drugs', 'prices']",
Unshareable Database in USA,"
Is there a specific list of data in the USA which includes what all is not to be shared on an open data platform to the public? If yes, where can it be found? It is popularly known as a 'negative list' as well.
","['usa', 'data.gov', 'uses-of-open-data', 'research', 'research-papers']",
Finding Open Source Data,"
I was wondering if anyone had any tips for finding the data I need... for one of my projects I need to find data showing grocery stores, shopping and other essential businesses in California (specifically the central coast).
Is there a way to get this data from somewhere like Google Maps?
",['open-source'],
Applicability of plant images from different continents,"
There are several plant/weed image datasets from various places, like Australia, Germany, Latvia
Please forgive my ignorance on this question, but what is the applicability of this data when implemented on a production system on a different continent, say North America for example.
My background is in computer vision and computer science and less in agriculture.  To me, weeds that grow in Europe/Australia will look different to weeds growing on the common lawns of a United States home.
Some plants have species that have the name of the continent in them!  So is the different in shape/color etc liable to make this data unusable in another environment?
","['agriculture', 'deep-learning']",
Finding POI across India,"
I'm looking for data containing point of interests or POI across India.
Only place name, location and state will be enough. I don't need details like it's location or it's shape.
Details like this will be good
Victoria Memorial - Museum - West Bengal
Data like this can be found from Google search but I'm looking for something like a database containing such infos.
Where can I get something like this for offline use ?
","['india', 'travel']",
Insulin Prices Particularly Novolog,"
I would like to data scrape a reliable source where I can get real time data about insulin prices.  I am using Python's BeautifulSoup and shoving the results into a SQL database that has the columns of Date, Vendor, and Retail Price. Or are there already reliable open data sources about this topic? I was currently reading reports about insulin trends and the people have these graphs; however, I often question where did they get their data.
","['data-request', 'uses-of-open-data']","Check these out, not real time, one updated monthly and the other yearly:NADAC gives you the wholesale prices I think. MEPS is a great source but requires a lot of digging and cross referencing different parts of the survey on a common key. As far as open data those are the best I have found for expense estimating. Also check out open FDA.Good luck!"
Administrative data system USA,"
I am conducting a research and I would like to know in detail what is the administrative data collection system in the USA, and are there any legal repercussions for state governments or executive departments if they don't submit quality data or not on time?
","['data-request', 'usa', 'uses-of-open-data', 'research']",
"Travel restrictions or quarantine regulations due to Covid19 (machine readable, if possible)","
I'm looking for datasets (or webpages) from one or many countries that lists travel restrictions and quarantine requirements for travelers entering the country.
For example, lists that countries publish to indicate for which countries travelers are required to enter quarantine upon their arrival.
","['data-request', 'medical', 'government', 'covid19', 'travel']",
State government data collection system,"
I want to know who collects all necessary administrative data in US state governments, is any particular office, or director responsible for handling, disseminating, and analyzing data? Also, are executive departments of the US government responsible for collecting state data?
","['data-request', 'usa', 'data.gov', 'government', 'research']",
COVID-19 - Austria - historical data of new infections per state,"
I'd like to analyze the development of COVID-19 cases in Austria by state, in respect to the designation of ""risk areas"" as defined by the Federal Foreign Office of Germany. According to that definition, ""risk areas"" are areas with ""more than 50 new infections per 100,000 inhabitants in the last seven days"" (PDF file provided by Robert Koch Institute). So, to assess if an austrian state may be in danger of being declared a ""risk area"", one has to compute the count of new infections in relation to the total population.
There's an open data set available at data.gv.at that enumerates the cases per state (""COVID-19: Anzahl der aktuell Erkrankten je Bundesland""), but only for the current day.
I've found a page that analyzes the case counts per state (coronatracker.at), but they don't provide raw data and they don't compute the count of new infections per seven days retrospectively.
So, does anybody know if there a dataset of new infections per austrian state for the (let's say) last three months?
","['data-request', 'medical', 'europe', 'covid19']","I wrote a python3 scraper for the https://coronatracker.at site that gets the individual states' data. The code is really a wrapper for the amazing pandas function .read_html(), which does basically everything by reading the table from the html.The CSV could be cleaned up (e.g. splitting some columns that contain multiple data points together 42.545 +191 (0%)), but you'll notice that there are individual Bundesländer (labeled as column ""state"") and also daily counts per state. It may not be the data you are exactly looking for, but at least now the raw data is ""available"". The data goes back to February, 2020.all states' data (csv, as of 27. Sept. 2020)formattedrawscraper (python3)formattedrawalso here for a reference:"
List / database of commonly used existing CLI executable names,"
Can someone recommend a list / database of commonly used existing CLI executable / command / alias / builtin / etc. names?
I want to write some CLI utilities, but I don’t want to have name clashes (e.g., names like git, hg, brew, grep, Java, cd, ls, ll, etc. are already commonly used).
I’m primarily interested in macOS / UNIX-like environments, but a list for Windows would also be helpful.
","['data-request', 'software']",
Data on IoT use,"
I am looking for an open/free dataset on IoT use across countries over the years, where I can create my plots or graps illustrating their growing use/diffusion. There exists some data on www.statista.com, but it is chargeable.
Any suggestions where I can find the data?
","['data-request', 'internet-of-things']",
"Political leanings on the county level, or state level?","
I've compiled some covid data, and I think adding some political leaning data might make it a little spicy. I've seen some maps of political leaning for counties, but I cant find a source. I'm looking for a data set that has counties (or states, preferably counties) that show their political leanings. Hopefully in a simple format, like +4 Democrat or +4 Republican.
","['government', 'politics']",538 has a pretty cool election forecast page:https://projects.fivethirtyeight.com/2020-election-forecast/you can get a direct download of the polling data: https://projects.fivethirtyeight.com/data-webpage-data/datasets/polls.zipthey also have a data page at github that links other CSVs and explains the data model: https://github.com/fivethirtyeight/data/tree/master/election-forecasts-2020
free REST API for daily end-of-day S&P 500 index,"
I am looking for a free API to retrieve the daily end-of-day S&P 500 index for the past year.
There are plenty of APIs which provide the individual stocks, but the indices are not for free. There are also many historic S&P 500 index datasets, but they do not cover the very recent couple of days.
","['api', 'finance', 'historical', 'time-series', 'stock']",By looking into yFinance source code I've found this query:https://query2.finance.yahoo.com/v8/finance/chart/%5EGSPCwhere %5E is ^ ( ^GSPC )
Free website for identifying influential or contentious US state and local court cases?,"
I am looking for free websites that contain (potentially partial) catalogs of state and local court cases in the United States, and allows me to filter and/or sort by any of the following:
The vote margin
Some kind of expert/subjective/automated/experimental measure of the case's influence
Some kind of objective measure of how often the case was cited
Some kind of expert/subjective/automated/experimental measure of the case's political contentiousness

Does anything like this exist? My intent is to be able to look for things like ""top 5 most politically sensitive cases in bla county superior court from 2000-2010."" Determinations like that would be deeply subjective, but maybe subject to some kind of systematic approach?
","['usa', 'government', 'database', 'legal', 'state']",
Uploading Project Data,"
I'm trying to upload project datasets (survey data). I have 30 to 40 excel files. They're not all formatted exactly the same way, because the survey design and platform were changed a few times during the project lifecycle. Can I simply drag these into the upload field? When I tried this with multiple files, DDL seems only to be previewing one of the files.
",['usaidopen'],
Wikipedia referenced articles in computer readable format?,"
A huge number of news related wiki pages contain article references (for example this article on the 2017 Equifax data breach) and I would like to obtain the following data from the references section at the bottom of the page:

The article title
The article url
The article publish date

There doesn't appear to be any way to obtain that data other than parsing the whole page. And the format seems inconsistent enough that doing so wouldn't be fruitful.
","['api', 'wikipedia', 'scraping']",
Looking for California sales tax data by zip,"
I'm building a store and I need to calculate the sales tax at checkout only for clients that reside in California. I looked for an API, but all of them charge a monthly fee. Seeing as I only need this for one state, I would be better off with a simple mapping based on zip codes. Any ideas?
","['data-request', 'data.gov', 'taxes']",
FEC API key form submit does nothing,"
I visit https://api.open.fec.gov/developers/ , fill out the form titled ""Sign up for an API key"", and press ""Signup"". The button briefly changes to ""Loading..."", then flips back to ""Submit"". Nothing else happens and I receive no email. I've tried Chrome 85.0.4183.102 and Safari 13.1.2 (15609.3.5.1.3).
","['usa', 'government', 'elections', 'federal']",
Voice audio dataset labeled with influenza-like illness or not,"
I was doing a machine learning project, assigned by my advisor. The project description is as follows - given an audio sample of a patient, we want to predict whether that patient to whom the audio sample belongs to, is suffering from influenza-like illness (ILI). Unfortunately, I have hit a roadblock at the very start, because I am not able to find any dataset or previous work related to my project. Basically, I want labelled audio samples of people suffering from ILI, if someone has them. I would also love if any of you would redirect me to other forums or sites where I can ask for datasets, and also if you know of any relevant related work. The idea was that people suffering from ILI would have sore throats, thereby having some differences in voice from normal speech, and we would like to see if we can exploit that.
","['data-request', 'medical', 'audio', 'covid19']",
Total Product Life Cycle API?,"
I am unable to find any endpoint(s) to fetch TPLC related details in the OpenFDA website or may be i've overlooked.
Is there is an API or other ways to retrieve TPLC related details, could you pls share ? Thanks In Advance. Also, Here is the TPLC website
URL: https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfTPLC/tplc.cfm
",['openfda'],
Dataset for belt detection (car front view) -data request-,"
I'm currently working on a seatbelt detection algorithm. I need videos/pics of front view cars taken by traffic cameras, would be better if the driver's face are shown.
","['data-request', 'data.gov', 'machine-learning']",
Is there a way to match ICD-10 Diagnosis Codes with available Rx treatments?,"
Ideally tabling both the generic and branded drug names.
","['uses-of-open-data', 'programming']",
"College Scorecard: Why are values of the variables in the series "" Percent completed within X years at original institution"" not strictly ascending?","
I've been looking at the values of COMP_ORIG_YRX_RT for a subset of schools (4 year schools in MI). I was examining the values of COMP_ORIG_YR8_RT, since that seems to match up with what's used for published graduation rates (is that right?). I would expect that the percent completed within 8 years would be greater than within 6 or 4 for each school. For Aquinas College (the one that caught my eye), the graduation rate on the College Scorecard interface is 58%. Can anyone explain these columns to me? Should I be using a different column for completion rate?

",['collegescorecard'],
Where can I get statistics about illness relationships with vitamins and minerals deficiency?,"
I would like to know where I can get a credible source of information about health.
I read a lot of information about what causing an illness a lot of information that somebody else claim its wrong, I am a computer scientist and I know how to get info from data, so I want a data set contains illnesses and and what is the diagnosis, or illness and what deficiencies in the Patients.
","['data-request', 'medical']",
People Dataset for 3D instance segmentation,"
I have multiple kinect cameras that I use to make a pointcloud of the scene. I want to perform Instance segmentation on the scene which will involve people. But I need a dataset for that, all the datasets I have looked at seem to be for outdoors or indoors but with no people in them. (like scannet)
Are there any multiview RGB-D datasets available that would involve people ? something like scannet but with people in it.
","['data-request', 'images']",
How many people use public transit in the U.S.?,"
To answer a question on Sustainability.SE, I am interested in finding data on how many people in the U.S. utilize public transit in a given year.
Most of the data I can find in the National Transit Data covers ridership, defined as rides taken during a time period. So if the period is one year and a person takes the bus twice a week, that counts as 104 rides. I want to know how many unique individuals use any form of public transit in a given year. A reasonable approximation with a defined methodology would be sufficient.
",['public-transport'],
Average monthly weather dataset for Europe,"
Is there a free dataset with monthly average temperature / rainfall / sunshine hours / humidity / wind figures for Europe going back 5-10yrs with geo coordinates?
","['data-request', 'weather', 'europe']",
Device Endpoint - Brand Name Mismatch,"
When we Query Maude Website for Report Number ""2024168-2020-03898"", the brand name is displayed as “ABSORB BIORESORBABLE VASCULAR SCAFFOLD SYSTEM”.
However, when we use the device endpoint and query the same report (URL below), the output brand_name is only “ABSORB”.
URL :
https://api.fda.gov/device/event.json?search=report_number:%222024168-2020-03898%22
Screenshots :
Website Search Query + Result:

API:

URL: https://api.fda.gov/device/event.json?search=report_number:%222024168-2020-03898%22

Will this be corrected or it will be like this and we continue to use it like this?
Is there a single place where similar data issues are reported?

Note: We got this Report Number when we tried to search for something else and there probably are many more such instances which have data mismatches between Website and API.
",['openfda'],
Land cover map of Germany and Netherlands,"
I am looking for a high resolution land cover map in Germany and Netherlands (ideally for the whole country, but local datasets are also welcome). I know that I can get some information from Open Street map or from the Copernicus products, but I am wondering if there is an open dataset with more details (spatial resolution < 10 m or thematic details that extend the pure land cover components, including e.g. crop types (or groups of crop types), biotopes types ) that I could compare with those products. So I am looking for national/regional product and not global/european products.
","['geospatial', 'land-cover', 'map']","Earlier this year the ""Land Cover Map of Europe 2017"" with 10m pixel size has been published, see http://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-2/Land-cover_maps_of_Europe_from_the_Cloud .
It is a pan-European map, yet potentially interesting for you due to its high spatial resolution.At country level, you find for Germany e.g. the following products:For Netherlands:Edit 12/2020: added new Germany 2016/2019 - Land cover maps"
Land cover map of Germany and Netherlands,"
I am looking for a high resolution land cover map in Germany and Netherlands (ideally for the whole country, but local datasets are also welcome). I know that I can get some information from Open Street map or from the Copernicus products, but I am wondering if there is an open dataset with more details (spatial resolution < 10 m or thematic details that extend the pure land cover components, including e.g. crop types (or groups of crop types), biotopes types ) that I could compare with those products. So I am looking for national/regional product and not global/european products.
","['geospatial', 'land-cover', 'map']","Earlier this year the ""Land Cover Map of Europe 2017"" with 10m pixel size has been published, see http://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-2/Land-cover_maps_of_Europe_from_the_Cloud .
It is a pan-European map, yet potentially interesting for you due to its high spatial resolution.At country level, you find for Germany e.g. the following products:For Netherlands:Edit 12/2020: added new Germany 2016/2019 - Land cover maps"
Road distance between all US cities,"
We are basically looking to find a database of road distances between all possible cities in the US, or maybe you can advise something we could do to calculate it ourselves.
",['usa'],The only available solution we found which suits our needs and can generate big amounts of distances with the distance matrix is using OSRM (Open Source Routing Machine) which we can host on our own.There is another service that can be hosted OpenRouteService which built on top of GraphHopper and allows to generate distance matrix too but it way less in size than OSRM.
Customs trade data of Brazil and China needed,"
I'm looking for customs trade data of Brazil and China.
For Brazil I need export of poultry meat (HS-code 0207)
For China I need import to country.
And all these data must contain such information as: name of company-exporter and consignee, quantities, value, price in USD, Incoterms, detailed description of the goods and country of origin.
I have already wrote to lots of companies providing customs data, but there was no one who can provide all the information requred.
Maybe anyone knows where to find these information and can advice me company, which supply data I described.
","['data-request', 'data-format', 'database', 'china', 'brazil']",
Can I aggregate and reformat publicly available data for teaching?,"
I work and teach in a field where public data is scarce (anatomical MRI processing). I planned to organize a few practical works for students this semester. I had a pretty hard time gathering publicly available data from different software suites/open projects to organize a consistent and motivating practical work. Now, my question is the following:
Given that all these data are available to download (examples of data: fsl.fmrib.ox.ac.uk/fslcourse (Section Data Files)) on the author/lab website, do I ""have the right"" to create ""my own data set"" from parts of this data and under what conditions?
The reason that pushes me to do so is that some of the data comes from different heavy archives with hundreds of unnecessary things, with heterogeneous naming from one source to another, and I would like to ""repackage"" only the needed data in a consistent and comprehensive way and make this repackaged archive available somewhere for my students.
","['medical', 'releasing-data', 'licensing', 'academia']",
Device API not returning recent data,"
Looks like the device end point for adverse events is not returning latest data or I'm missing something.
As on today (Sept 16th) when I trigger the below endpoint:
https://api.fda.gov/device/event.json?search=date_received:[20200801+TO+20200831]&limit=1000
{
""error"": {
""code"": ""NOT_FOUND"",
""message"": ""No matches found!""
}
}
However when I try the same via the website, we can see 500 records.
Refer image below for the filters Used while doing the search.

Sample Result: https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfmaude/detail.cfm?mdrfoi__id=10475104&pc=QBJ
Can someone help me understand what is happening here pls ? Thanks in Advance.
","['api', 'openfda']","openFDA is experiencing some technical difficulties with updating the
Device Event dataset, which is why it is slightly behind MAUDE. We
will fix it shortly and report back once done.UPDATE: The Device Event dataset in openFDA has been updated and this issue has been resolved."
Movie and Music Preferences,"
I am looking for a dataset that contains both music and movie preferences of users, preferably based on genres.
","['music', 'film']",
Database with list of generic ingredients and their nutrients?,"
I need a dataset with generic ingredients and their nutrition. I am familiar with USDA and other similar ingredients datasets but they are all polluted with a lot of brands and very long descriptions.
For example, if my user searched ""egg"" I want it to return just the ingredient object and the nutritional facts.
Using the USDA datasets I would find around 10 types of eggs... I am looking for something more simple or generic.
",['data-request'],
Crosswalk / Equivalence Mapping from HCPCS (Devices) to FDA Product Code,"
Is there any available mapping between the HCPCS-II codes associated with medical devices and the 3-letter FDA ""Product Code""?
So to be excruciatingly obvious...

The FDA Product Code for Cochlear Implant is ""PGQ""
The HCPCS-II code for roughly the same device class/group/type is ""L8614""

Is there a cross-walk or equivalence mapping dataset that will let me find ""PGQ"" given that all I've got is the ""L8614""?
","['medical', 'openfda']",
Trying to find historical building footprints or centroids,"
I'm currently doing a research project analyzing how cities evolve over time and were wondering if there were any good online databases for finding historical building footprints. I've been looking around for a while now but couldn't find what I was looking for. Any help would be greatly appreciated.
","['data-request', 'geospatial', 'city', 'openstreetmap', 'buildings']",
Where can I find databases in .rdf or in .ttl format,"
I have to make web application with rdf and sparql and I need database in rdf/xml or in ttl format but I can not find. I thought about music or movies or books database but I did'nt find if you know please tell me where can I find databases?
","['database', 'sparql', 'rdf']",
Is it possible to query Wikidata to get a list of things by item index?,"
Say, for example, that I wanted to know what the first 100 items are on WikiData (which I do,) without searching in WikiData Q1, Q2, Q3 and so on. Is there a way to write a SPARQL query to find all WikiData entries (either items or properties) associated with a certain numeric index, between 1 and 100? As far as I can tell it seems like SPARQL doesn't have for loops, so I'm not sure if there's a mechanism to generate this data.
",['wikidata'],
Cryptocurrency hourly historical prices,"
I have found a variety of resources that provide daily historical prices for cryptocurrencies. However, I can hardly find any places where I can download hourly historical prices. Can anyone point me to a good place? More specifically, I want to download or web-scrape the historical hourly prices of Sashimi and Ethereum.
","['data-request', 'prices', 'download']",
Seeking Green space layer for California,"
I'm looking for a data layer that can be used to display ""green"" spaces, which would ideally include parks (city, county, state, national), as well as golf courses and cemeteries.
Is there a single data repository that would contain all of these features?
I only need it for the state of California. I have found several government sites, but have not had too much luck so far. I'd rather not patch together dozens of layers from different sources if possible.
","['usa', 'research', 'openstreetmap']",
Current data through API,"
I'm trying to access current data for unemployment claims.  I don't get anything back after 2016.  I am filtering on week gt 2016-12-01.
",['labor'],
Shapefiles of the Great Wall of China and the Silk Road,"
I am looking for shapefiles of two Chinese landmarks.

Great Wall of China. Format: spatial lines. The sources mentioned in another post are apparently not available anymore.

Silk Road. Format: spatial lines, points or polygons.


Comments on maps that can be geocoded are also welcome.
","['geospatial', 'historical', 'geocoding', 'china']",
Looking for non-domestic building floor areas in Scotland,"
Is there an equivalent of the Valuation Office Agency Rating List for Scotland? I've looked on the SAA website, but can only find a way to download rateable values for individual properties. No floor area, no bulk download.
","['data-request', 'uk']",
Trajectories in network data set,"
I am looking for data sets that consist of trajectories mapped to a network. Instead of GPS location, each point should be a vertex in the network and a time step or interval.
I am looking for any hints to such data sets.
","['data-request', 'network-structure']",
Where can I get a reasonably small geojson file for the boundaries of Canadian provinces?,"
I have looked on kaggle.com and done a lot of Googling. The only thing I found was one that has 2000 vertices in the polygon for each province. That is too large to write to DynamoDb, which is what I need to do.
","['geospatial', 'canada']",
openFDA API seems to be missing NDCs,"
I have some NDCs that I want to search for on the openFDA API:
33992-8010-1
50058-100-08

...etc.
So this is what I've tried so far (all with base url api.fda.gov):

drug/ndc.json?search=product_ndc:""33992-8010""
drug/ndc.json?search=package_ndc:""33992-8010-1""
drug/ndc.json?search=product_ndc:""33992-8010-1""
drug/label.json?search=openfda.package_ndc.exact:""33992-8010-1""

...but nothing seems to work. All I get is this:
{
  ""error"": {
    ""code"": ""NOT_FOUND"",
    ""message"": ""No matches found!""
  }
}

However, if I use a different NDC, like 63653-1171-1, the query works fine. Is it possible that the NDCs I'm querying are just not in the database, or am I doing something wrong?
","['api', 'openfda']","The two NDCs you mentioned are indeed not in the database. openFDA generates its NDC dataset from the downloadable files available at the FDA, and we have verified the two NDCs are not present in those files, which is why they are also missing from openFDA.FDA National Drug Code Directory search does bring results for those two NDCs; however, they are marked as:(E): This information was removed from publication, because FDA has found inaccuracy in the data submitted by the firm.This is the reason the information is not present in the downloadable files."
Where can I find research papers on Data Science and AI?,"
Where can I find a free and open resource of categorized scholarly articles in the fields of Data Science/Machine Learning/Deep Learning/AI/Statistics papers, code, and evaluation tables?
","['machine-learning', 'ai', 'deep-learning', 'research-papers']","Browse State-of-the-Art3,076 benchmarks • 1,689 tasks • 2,719 datasets • 27,765 papers with codeAll data is licensed under the CC BY-SA license, the same as Wikipedia.
The vast majority of the data is either annotated by the community or by them. However, they also included data from other resources that are published under a compatible license, such as NLP-progress, EFF AI metrics, SQuAD, and RedditSota.arXiv is a free distribution service and an open-access archive for 1,757,455 scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics. Materials on this site are not peer-reviewed by arXiv."
Where can I find open source deep learning pretrained models?,"
Where can I find open source pre-trained deep learning models(source code optional)?
","['machine-learning', 'deep-learning', 'models']",
Why Does College Scorecard institution-level earning data stop are 2014-15 data file?,"
From examining the College Scorecard data, it appears that median and mean earnings data stop being reported after the 2014-15 data and the values are null for the 2015-16 through 2018-19 data files. Is this reported elsewhere? And does anyone know why it is no longer included in the Scorecard data?
I know program-level data were released in 2019, but these neither appear to include institution-level values nor can one create institution-level values because so many of the program-level values are privacy suppressed.
",['collegescorecard'],
openFDA decision_code field in PMA device API endpoint,"
I downloaded the PMA devices dataset from here
https://download.open.fda.gov/device/pma/device-pma-0001-of-0001.json.zip
However, It seems like the denied filings were not included since the decision_code field only reports the following strings:
APCB
APCV
APPR
APRL
APWD
OK30
If this is the case, is it possible to access the denied filings too?
",['openfda'],
Searching for live financial data,"
Searching for a live financial data source with fields:

Transaction date - date of the purchase, as exact as possible
Unique Account ID - ID that represents the unique entity making the transaction
Unique Stock ID - ID representing the stock purchased
Transaction Amount - amount spent in transaction

Non-negotiables include the above fields, and a live data source.
Doesn't need to be an entire market. Might be account transaction data from a broker like eTrade or Robinhood. Might be transaction data on one market segment like materials, or real estate. Might be a sample of one of the above.
Pursuing a theory that as the burden of entry for stock trading shrinks, stock values are determined moreso by public awareness than actual financial results. I'd like to run some type of RFM model using the data described to better measure and predict ""public awareness"" to predict stock fluctuations.
Open to and appreciate your thoughts/suggestions/comments.
","['data-request', 'finance']",
API or query tool for USGS Protected Areas Database of the United States?,"
Is there an API or query tool for something like this PAD-US system? I want to determine if GPS coordinates are public land or private land.  I could only see downloads or ESRI maps available.
PAD-US is America’s official national inventory of U.S. terrestrial and marine protected areas (List of National Geospatial Data Assets) that are dedicated to the preservation of biological diversity and to other natural, recreation, and cultural uses, managed for these purposes through legal or other effective means.
Link
","['land', 'usgs']",
Where can I find black owned small businesses that did not receive PPP loan?,"
I'm building a heat map of PPP loan data comparing black-owned small businesses that did not receive PPP loans vs white large businesses that received and returned the PPP loan. Then, analyzing the returned PPP loan time frame against minority-owned business closures in major cities. The results should be interesting!
","['data-request', 'business']",
Identifying a superyacht from date and location,"
A while ago, while vacationing in a sunny island in the Mediterranean, I saw a beautiful superyacht anchored off a bay. I would like to know the name of this yacht and who designed it.
I do not know if it is required that yachts of this size turn their AIS transceivers on.
Given the latitude and longitude of some reference point in this bay, a radius and a date, is it possible to find out a list of all vessels that were inside the circle centered at the given reference point and with the given radius on the given date?

Related:

API giving ship positions worldwide

Free source of AIS data (API)


","['data-request', 'database', 'oceanographic', 'location', 'ais']",
Is there a API or method to automatically upload apprentice On the Job Hours (OJT) to the DOL system instead of manually entering it?,"
Our HR department has to manually enter data for apprentice level employees who are participating in the apprenticeship program as part of the apprenticeship program rules.  Is there an API that our company's in-house developer can use to automatically have this information uploaded from our payroll to the Department of Labor system?
","['api', 'government', 'labor']",
Need help for Constructing Query String - device/event.json endpoint,"
I'm trying to get all the filters working for Maude DB via the device/event.json endpoint.
URL
The Filter in the website Brand Name matches to device.brand_name in the API.
Similarly, Need help to construct query string parameters for the below UI Filters

Report Number
Event Type
Product Problem
Product Class
Model Number

",['openfda'],
Database of given first names by country frequency and year,"
I have been able to source datasets of:
(i) given first names and their gender
(ii) given first names by country
e.g. https://github.com/MatthiasWinkelmann/firstname-database
But not given first names by their frequency within a country for a given year.
A great example would be the USA SSA database that Hadley included in the babyname R package - but that only includes USA.
Any ideas of similar data but for other countries?
","['data-request', 'global', 'names']",
Where do I get a Geolocation History dataset,"
I would like to do a mobility research over a well defined geographical area. In an ideal world, I would need a dataset containing anonymized geo-location information from date X to date Y of the users that moved across that region.
I was wondering if Google sells those data? After all, they collect it through the Google Location History, which (as far as I know) is also used to get real-time traffic data on Google Maps...
",['data-request'],"History of Locations of an android mobile in the month of October 2014The history of locations of each of the mobile can be downloaded from this link:
SourceThese data are interesting to perform geolocation studies associated with time.Format file: JSONIf you are willing to buy the data, you can find the below linkDataradeLocation data is information relating to the geographic coordinates of a person or object. It's mostly used by retailers and marketers e.g. in-store location optimization and location-based advertising. Datarade helps you find the right location data providers and datasets."
Where to find help creating a dataset,"
Is there a place one can ask for help for creating a dataset?
I'm writing a thesis and I am in desperate need of people drawing images for me since they need to be of a specific kind. I have even created a site where they are guided and the image can be uploaded.
I have already tried social media, asking friends and family, but the amount of images I got are nowhere near of what would be needed to train a model. I would also be willing to pay to get help, and I have already taken a look at amazon turk, but it is rather confusing and I'm not sure if I can use it.
","['data-request', 'images']",
Why would an inspection query data.dol.gov/get/inspection/... return a 200 with an empty response?,"
We are testing the use of the https://data.dol.gov/get/inspection/format/json/limit/100 service request and are seeing conditions where the response sometimes comes back with an empty response, but other times comes back with data. Is there additional documentation around how this API should behave? My understanding is that this call should return data consistently for each call.
","['usa', 'api', 'data.gov', 'government', 'labor']",
Missing pma_number in classification endpoint Aug2020 release,"
I downloaded the device classification dataset from here
Despite being listed in the searchable fields in the documentation, the openFDA field ""pma_number"" appears to be missing (at least in the Aug2020 release).
Also, does this dataset link the medical device identified with k_number with the facility is manufactured in? It is not clear to me the information about fei_number/registration_number. As an alternative, is it possible to recover information about where the specific medical device is manufactured?
",['openfda'],
What's the best small dataset to train a Recurrent Neural Network?,"
I work on a neural network library in C++ and I'm in the process of implementing recurrent neural networks.
I run my tests on a GitHub server on different datasets, Iris and Wine for simple unit tests, MNIST and Fashion MNIST for test the MLP, CIFAR-10 for test the CNN and I looking for some new dataset to train the RNN that I implement.
Do you have any idea of small datasets to train my RNN?
I'm looking for one or two small datasets that are easy to integrate into my tests in my continuous delivery process. About 30 seconds for 1 epoch with more than 70-80% accuracy would be ideal.
PS: I know I can use MNIST to simulate temporal data but having a ""real"" dataset would be better and more diversified.
",['machine-learning'],
"Options for analyzing twitter hashtag use by various factors - date of account creation, location, username strings and even defined user lists","
I am not sure if this question is better suited for data science but I'm mostly looking for an outline of what currently is or is not possible and a direction for where I should learn more.
My first interest is if it is possible to look at aspects of who is using a particular hashtag - location and date of account creation, But more importantly if it is possible to separately apply tags to accounts or have lists of accounts that are categorized pre-analysis or manually and see who is using a hashtag.
To explain further - I want to look at everyone who follows one particular account and see how many of them are using a particular hashtag - and then of those that are using the hashtag how many are new accounts? How many are from particular countries? How many have lots of numbers or particular strings in their user names? And how many compare to a list of previously identified trolls for example (or their followers)
I think up to maybe the strings in user names and previously id lists it is possible but I don't know the right words to use to look up what I'm trying to do.
","['api', 'tool-request', 'demographics', 'scraping']",
How would one leverage the OpenFDA API to obtain listing of all recalls associated with a specific CIED?,"
How would one leverage the OpenFDA API to obtain listing of all recalls associated with a specific CIED?  We have limited info on each device such as the model of implanted device and serial number.  We do not have manufacturing data or lot info.  Any pointers would be appreciated.
","['api', 'openfda']",
Is there an application or plugin for OSMAnd to retrieve trail signage and information?,"
Is the information written on trail signs publicly available in a central place so that when I am out hiking or biking on a trail and come across a sign, I could get the same information on my phone via an app or OSMAnd plugin?  Additionally, if it were to be available, it would be useful if it were downloadable beforehand either along a route or within a polygon.
",['historical'],
openfda: query to obtain links to 510(k) summaries,"
Using the api for the 510(k) database in openfda, I can search the statement_or_summary field and find all the rows (i.e. devices) with summaries.  But in the download, the api just produces the string ""Summary"" in that field.  In the actual FDA database, that string includes a hyperlink to a pdf document in FDA's database that is the actual ""Summary.""  I want to download the actual links so I can consult the summary itself.  How do I download the links to the pdf documents.  Those summaries are rich in information.
",['openfda'],
Data lake layers approach,"
I am working on an approach to creating a data lake using Cloudera.
My question is for an approach to be taken for the Curated/Gold layer.

RAW layer - All data from the source will be available in raw format and partitioned as per the data extraction key.

Gold layer / Curated Layer / Optimized layer - Here in this layer, the plan is after reading the data from RAW layer will do simple transformation on column values, transformation on file format changes to Parquet (partition, compression, enrichment) and then write as a parquet file using Apache Spark.
I am not planning to create a hive table in this spark job or use a hive query to create a parquet table.
Instead will create a separate impala query/hive query to read data from this file as per need.Idea is that there should be flexibility to query the data using any component - Impala/Hive/Presto etc.
Incase i create a parquet file using hive script and if need to read this data from Impala, then the Impala query compilation then hive query compilation and other required processing could be overhead.

Data serving layer: Here will create Hive HQL/impala scripts to read data from Gold/Optimized layer to read data.


What is your opinion in terms of storing data in gold layer- as a partitioned table using a hive or store as a partitioned parquet file and then read using any component?
",['big-data'],
Land sale data Singapore,"
I'm trying to get historical records of land sale in Singapore.
(For example, with the data it should be able to answer the question of whether Varsity Park sold land to The Stellar (or even vice versa)  at the west coast area. And the details of the sale.)
What are some good source/s?
","['land', 'singapore']",
API returns code not found,"
For a number of codes found in the National Drug Code directory the API returns code not found.
https://www.accessdata.fda.gov/scripts/cder/ndc/index.cfm
I have reviewed the API documentation and tried building a number of queries to try and look up information about a drug given the package ndc.  all return a code:""Not_Found"" error.
Here's a list of a few different api calls I have tried.
https://api.fda.gov/drug/label.json?search=package_ndc:%2225021-166-48%22
https://api.fda.gov/drug/ndc.json?search=package_ndc:%2225021-166-48%22
https://api.fda.gov/drug/label.json?search=product_ndc:%2225021-166-48%22
https://api.fda.gov/drug/ndc.json?search=product_ndc:%2225021-166-48%22
I have tried removing the hyphens, putting the search field in quotes, and adding a limit at the end with an &
Can anyone advise on how to get information about a drug with the API by ndc code?
",['openfda'],
How to know ATC Class 1-5 of a drug name in OpenFDA data,"
I am trying to use OpenFDA open-source data so that I can know ATC Class 1-5 of a drug name and the disease it can be used to treat for?
","['openfda', 'uses-of-open-data']",
Is there any GitHub pull-request dataset with labels information?,"
I also tried to get the labels for a pull-request using GitHub API, but that did not work as labels are not linked with the pull-request. Any idea? How can I get the PR comments labels for GitHub repositories?
","['data-request', 'metadata']",
Tagged dataset with photos for the race/ethnicity detection,"
Looking for the tagged dataset, because I would like to identify race / ethnicity by photo. I tried using the UTKFace dataset from Kaggle, but it outputs Hispanic and Arab people on images as other. My customer would like those ones as separate categories. Because UTKFace has only 4 tags - black, white, indian, other.
Do you have any datasets containing among other things ethnicity? Papers, links, or direction to search or something else would be appreciated as well.
",['images'],"Alright, I believe I found one:https://github.com/dchen236/FairFace"
Where can I find more detailed data on electrictiy usage in preferably hourly time resoultion for Norway?,"
I am working on a research project and I need to find detailed load profiles for electricity usage in industry (also which kind of industry), transport(also which kind) and household in Norway in an hourly or a better resolution.
","['data-request', 'energy']",
Is there such a thing as a JSON blob which has categorized *numerous* sites in a meaningful way?,"
I have a huge list of URLs in a database table. From these, I am able to extract the ""domain"", such as ""stackexchange.com"" or ""bbc.co.uk"".
I'd like to be able to get some standardized ""category"" label for each of these domains.
This means I'm looking for some kind of free resource online which has something like this:
[
    'stackexchange.com': 'Q&A service',
    'bbc.co.uk': 'News',
    ...
]

(I forget exactly what JSON syntax looks like since I always let my JSON parser deal with the parsing to a more native format.)
Is there such a thing? Perhaps it's provided by Mozilla or something for some kind of categorization project used in some way by Firefox, which I can ""hook into""?
","['database', 'json', 'categories']",
Where to find open tabular hyperspectral data for machine learning research?,"
Where can i find open datasets regarding "" Wheat/Maize Leaf Spectra with Associated water content, Potassium and Nitrogen Measurements"" for machine learning research i.e. hyperspectral tabular data collected from a field spectroradiometer along with chemical parameters.
","['machine-learning', 'agriculture']",
Source for U.S. government reports 1900-1950?,"
I am researching the history of the motion picture industry and seeking U.S. government reports and documents from major departments (especially Commerce, State) for the period of 1900-1950. I'm looking for online archives containing PDFs of that kind of material.
Is that material available in any academic databases, open data repositories, or other sources?
","['government', 'historical']",
Where can someone find a public dataset on where/which USPS postal boxes and sorting machines have been removed?,"
The USPS is removing sorting machines and mail collection boxes from several locations. I've seen this mapped but cannot yet find this data.

https://www.msn.com/en-us/news/us/internal-usps-documents-raise-questions-about-effectiveness-of-sorting-machines-removal-order/ar-BB181ZRG
","['usa', 'government', 'elections']",
Government Registered Companies Websites API,"
Can any buddy help me out to find the API of Government website of Registered Companies. please guide me easy way to find API FOR REGISTERED GOVERNMENT COMPANIES
","['api', 'government', 'companies']",
"Why do I get a ""Identifier not found in PMC"" error message when trying to convert a valid DOI that has a PMID?","
I read on https://pubmed.ncbi.nlm.nih.gov/30265128/:

PMID: 30265128 (PMID=PubMed identifier)
DOI: 10.1164/rccm.201806-1083IM

However when trying to convert the DOI 10.1164/rccm.201806-1083IM ot its PMID on https://www.ncbi.nlm.nih.gov/pmc/pmctopmid/ I get ""Identifier not found in PMC"":

Same issue with:

PMID: 29794847; DOI: 10.1097/SLA.0000000000002825
PMID: 30601258; DOI: 10.1097/SLA.0000000000003154
PMID: 31725892; DOI: 10.1093/eurheartj/ehz824

Why do I get a ""Identifier not found in PMC"" error message when trying to convert a valid DOI that has a PMID?
(Note that DOI names are case insensitive).
","['medical', 'pubmed']","From understanding this is because these papers aren't in PMC but only in PubMed. Which raises the question: How can I programmatically get the PMID from the DOI of a paper that isn't in PMC (i.e.. that doesn't have a PMCID)?Background reading: PMID vs PMCID: What’s the Difference?PubMed is an index of the biomedical literature. A PMID, also known as the PubMed reference number, is a number assigned by the NIH National Library of Medicine to papers indexed in PubMed. PubMed Central is an archive of full-text journal articles. The National Library of Medicine assigns a PMCID, also known as a PMC Identifier, to each full-text paper in PubMed Central."
Free database for heating degree days,"
I am searching for an online free database for heating degree days for including non-European countries on a yearly basis between 2015 and 2017.
I found several databases, but they are either expensive or only for EU countries.
","['database', 'climate']",
Data set for Recency Frequency Monetary (RFM) analysis,"
I am looking for datasets for RFM analysis - The goal of the analysis is to use the RFM variables to predict whether a customer will respond favorably (0/1) on a future campaign.
I am looking for a dataset that contains a response variable for a previous campaign. I have already looked at the Online retail and Online retail II datasets - I am looking for something similar, but with a response variable.
Additionally, I am okay with artificially creating a response column on the Online retail dataset as well, as long as it is not randomly generated, but statistically related to the customer's attributes in some way that would closely resemble the customer's actual behavior.
","['data-request', 'business', 'classification']",
"Where can I find data on Houston, TX property values for residential building?","
I am looking for residential property values in Harris County, Texas. Specifically, I am interested in the value of the buildings and their contents and not on the land value. Are you aware of any public source for this data?
",['data-request'],
Dataset for plant identification,"
I'm looking for a plant identification dataset (to train a plant identification system) that is free or not too expensive to use and has plant images, specifically garden plants. Just wondering if anyone came across such a thing? Or perhaps could you point me toward where to look for it?
So far I came across a few databases but they all are not free to use.
","['data-request', 'images', 'wikidata', 'biology']",
"Source for good administrative area boundary data US, MX, CA","
We are using SQL Server to calculate mileage breakdowns per state. It's a simple query to find length of intersection between path (polyline) and shape.
Data for US, MX, and CA were sourced from different public places. Now we got first issue where we see MX and US borders overlap like shown on image:

As you see shapes of TX and MX overlap. Now, this route happens to be in overlapped area and we get double mileage figures.

We need better data. Is there single source where we can obtain all 3 countries with no overlapping data/shapes?
","['geospatial', 'metadata']",
Census CPS monthly API?,"
Related to this other question: Centralized sources of *monthly* data accessible through API (or otherwise automated query)
Looking at https://www.census.gov/data/developers/data-sets.html, it seemed to me that the Census bureau does not yet have an API for monthly CPS data. In R, I couldn't find an api listed under listCensusApis() from censusapi , which reinforced my impression that there just wasn't an API for this data.
So I went through the ordeal of manually selecting variables using the data browser: https://data.census.gov/mdat.
Once I was done, I ended up on the final download page. To my surprise, on top of a direct dowload link, that page also included two API links:


So my questions are:

Is there or is there not an API for that data?
If there is, what are its name, query structure, etc.?
In particular, can I query it using getCensus from censusapi, and if so, how (what are the name and vintage format and can I obtain summary statistics by state or otherwise select a custom geography?)

","['api', 'us-census']",
Missing whitespace in label text values?,"
As context for this question, look at the response for NDA211172 (inotersen) from the label.json endpoint: https://api.fda.gov/drug/label.json?search=openfda.application_number.exact:NDA211172
I have an internal tool for tracking content changes between versions of labels per application ID. This one just changed version from 4 to 5 and got a new SPL ID (ec6ce482-951a-455f-aba3-f7cf8d42cd29).
The diff for the change in label shows a bunch of places where whitespace has been removed and created many places where words are incorrectly concatenated together. For example, look at the drug_interactions field
7 DRUG INTERACTIONS7.1 Antiplatelet Drugs or Anticoagulant MedicationsBecause of the risk
This has 2 places where words are missing significant whitespace: INTERACTIONS7.1 and MedicationsBecause
I'm guessing this is due to some data transformation process that isn't handling newline characters like \n and \r properly.
This is not a problem in older versions of JSON labels so I expect there must be some change over the past year that is incrementally introducing this bug in more and mover labels over time.
","['api', 'openfda', 'json']",Thank you for bringing this to our attention. We have created an issue in our GitHub repository to track resolution. We will post back on that link once the problem is remediated.
Centralized sources of *monthly* data accessible through API (or otherwise automated query),"
For teaching purposes (options for a class project), I am looking for sources of monthly data that can be programmatically accessed and downloaded into a high-level language (say R or python).
I am interested in any topic, ranging from geophysical to socio-economical all the way to financial, although I am particularly interested in socio-economical sources.
Ideally, the data should be as centralized and as global as possible. By that, I mean that I would prefer a single (or a few) stable sources providing access to a variety of data from all over the world than a long list of ""smaller"" providers each giving access to smaller and more local amounts of monthly data (e.g., one gateway for monthly climate data all over the world rather than a long list of individual weather stations each with their own API).
",['api'],"Quandl (economics and finance), FRED (economics), and UN Data (especially their MBS=Monthly Bulletin of Statistics Online site) are all excellent places to start."
merged election (voting precinct) data and census (block group/tract) data,"
Is there available a mapping between US voting precincts and census-recognized geographical units, like census block groups, or even to ZIP codes?
There are nice data sets now of US election results at the very granular level of the voting precinct (about 168k in the nation), e.g., at Harvard's ""dataverse"". I would like to merge this with census data. The difficulty is that ""voting precinct"" is not one of the census geographical units. Usually a precinct is made of ""census blocks"", and is something closer (but usually not equal to) a ""block group"" or maybe ""census tract"", I gather.
There is a 2017 journal article discussing methods of merging election and census data, with a summary here. It sounds a little involved, and a lot of choices need to be made. I was hoping that someone has done this for 2016 or other more recent precincts.
","['us-census', 'elections']",
Competitive Intelligence Data,"
I am interested in finding out how many people visit a competitor's store each day. When I look at my competitors business on Google Maps it tells me how busy their store is each hour for every day of the week. This data doesn't include counts so there's no information to be gained from scraping the webpage.
I am open to paying for this kind of data and if there was other data available such as where these people come from, demographics etc. I would also be keen to get this.
Do you know if Google or Facebook have access to this data and whether they 'sell' such data?
",['data-request'],
Open access finance data set,"
I am looking for a finance data set. Particularly, I am interested in EuroStoxx50
or indices like S&P 500, and DAX data sets.
","['data-request', 'finance', 'economics']","Investing.comGet free historical data for EU Stoxx50. You'll find the closing price, open, high, low, change, and %change for the selected range of dates. The data can be viewed in daily, weekly or monthly time intervalsS&P 500 stock dataHistorical stock data for all current S&P 500 companiesStock market data can be interesting to analyze and as a further incentive, strong predictive models can have a large financial payoff. The amount of financial data on the web is seemingly endless. A large and well-structured dataset on a wide array of companies can be hard to come by. Here they provided a dataset with historical stock prices (last 5 years) for all companies currently found on the S&P 500 index.The script used to acquire all of these .csv files can be found in this GitHub repository"
Corona virus - summary of analyses,"
There are many sites that contain some relevant data about the coronavirus. The question has been asked here and here, however, these are usually time-series data and some case-level data.
Is there however a summary of it? Someplace that summaries all of the odds ratio of various demographic attributes of the chance of death/hospitalization and the like? Or any other relevant metric?
","['data-request', 'covid19']","A partial answer, with hospitalization, for Germany only:Help finding data with hospitalization rates in other countries would be welcome:
what percentage of hospital beds are occupied by covid patients,
what % of critical care, how long ?.csv, code and some notes are under gist.github.com/denis-bz."
ProPublica's COMPAS Data | Feature Descriptions,"
ProPublica kindly provided the COMPAS Recidivism data in the github: https://github.com/propublica/compas-analysis/blob/master/compas-scores-two-years-violent.csv
Most of the features are clear from their name. But there are few variables like e.g., start , end, score_text, event etc..etc. which are not clear. ...What do these variables actually mean? Does anybody have any idea? Is there any place that I can find a description of the variables?
I have contacted many researchers all are saying ProPublica doesn't provide an official codebook for the data..which makes it really difficult to use it confidently.
The owner of the dataset doesn't bother to answer.
","['machine-learning', 'research']",
San Francisco Housing Data,"
I am a student with the Singapore Management University's postgraduate School of Economics. I am writing to seek your assistance in obtaining certain data on San Francisco’s housing market.
For our Econometrics project - we are looking into running a regression model to predict the housing prices in San Francisco. To do so, we would require datasets of houses in San Francisco city.
I am wondering if it is possible for you to share with us the raw data collected to arrive at these reports. Or others, to point us towards the person and organize we would be able to obtain it from.
We would require 10 years worth of monthly data:

Housing purchase prices in San Francisco
Per sq ft area of houses
Types of houses (house, apartment)
Number of bedrooms
Extra amenities (pool, tennis court)
Quality of neighborhood
Age of house
Size of yard
Location (from city center)

(For example, in Singapore's case, data can be found at data.gov.sg.)
","['data-request', 'prices', 'real-estate']",
Natural history / paleontology / geology dates,"
I am looking for a comprehensive dataset of natural history dates, for a deep interactive timeline.
I'm interested in the dates of fossils, geological eras, estimated times for the apparition of different taxonomies, such as life itself, multicelular organisms and so on.
I imagine I will have to combine several sources, but in any case I am not interested in detailed descriptions, only dates.
","['data-request', 'historical']","World Digital LibraryProvides data of 19,147 items about 193 countries between 8000 BCE and 2000.Timelines RevisitedA Design Space and Considerations for Expressive StorytellingAdditional Sources:I'm not sure if this helps but it might be worth taking a look at.There is a paper for extracting the historical events data from Wikipedia.  Extraction of Historical Events from Wikipedia"
How can I get daily web traffic data for years in a website,"
Recently I'm doing some research on holiday effect's on web traffic data and trying to predict it more precisely using data in previous year. I need to get daily or hourly web traffic data in a website for years. I only need some data like in 2020/08/03 page:www.google.com get 50 requests.
I have already get similar data from kaggle and wikipedia's pageview, and use its api to get hourly pageview data for every day from 2016 to 2020. However, my supervisor didn't think my job can work well on other websites. He thinks all my work is based on wikipedia's pageview data and holiday effects doesn't influence the behavior of a wiki.
So I try to find out more data like e-commerce website's pageview or other websites, but I failed. Is there any datas or logs that can help me?
","['data-request', 'uses-of-open-data', 'releasing-data']","I don't know if that's proper, but this question can go to an end cause I found two wonderful datasets. I'd like to publish them under this answer to help people in similar situation like me.The first is Website Analytics Daily Page Views from Open data DC, it contains daily pageview data from 2008 to 2020.Second is from City Website Google Analytics, it's a daily pageview data since November 2011 until now.Many thanks to those who publish pageview data to the public. And if anyone have similar pageview data, please answer this question to let me know it."
ISIC (Industrial Standard) classification Rev. 4 and ISCED classification,"
I would like to estimate country differences in earning for university graduates. I know I could use the real PPP GDP for that, but I would specifically like the average wage per country for someone who has a tertiary degree.
I have found the earnings data from the ILO, which is sorted into the ISIC classifications by occupation. However, I have no clue how to figure out who should have a tertiary degree with these classifications. Their documentation is not helpful at all. Does anyone have a dataset or an idea how to convert ISIC Rev. 4 (or older) classifications to ISCED classifications? Roughly is enough.
","['labor', 'gdp']",
Stock exchange dataset to use it with deep learning,"
I'm learning AI and I want to apply my knowledge in the stock exchange.
Do you know if there is a dataset to start training and testing my algorithm?
","['machine-learning', 'stock']","Huge Stock Market Dataset
Historical daily prices and volumes of all U.S. stocks and ETFsHigh-quality financial data is expensive to acquire and is therefore rarely shared for free. Here I provide the full historical daily price and volume data for all US-based stocks and ETFs trading on the NYSE, NASDAQ, and NYSE MKT. It's one of the best datasets of its kind you can obtain.The data (last updated 11/10/2017) is presented in CSV format as follows: Date, Open, High, Low, Close, Volume, OpenInt. Note that prices have been adjusted for dividends and splits.Top 10 Stock Market Datasets for Machine Learning"
Free grayscale images dataset with ground truth to pre-train U-Net used later into brain mri segmentation,"
I'm looking for a free image dataset to test my U-Net network.
I'm developing a brain mri segmentation algorithm and I need data to train it. This algorithm will segmentate brain tumors and I need a dataset with brain images and ground truth images.
Do you know if there is any dataset like the one I need?
","['data-request', 'machine-learning', 'images']","Multimodal Brain Tumor Segmentation Challenge 2019Imaging Data Description
All BraTS multimodal scans are available as NIfTI files (.nii.gz) and describe a) native (T1) and b) post-contrast T1-weighted (T1Gd), c) T2-weighted (T2), and d) T2 Fluid Attenuated Inversion Recovery (T2-FLAIR) volumes, and were acquired with different clinical protocols and various scanners from multiple (n=19) institutions, mentioned as data contributors here.All the imaging datasets have been segmented manually, by one to four raters, following the same annotation protocol, and their annotations were approved by experienced neuro-radiologists. Annotations comprise the GD-enhancing tumor (ET — label 4), the peritumoral edema (ED — label 2), and the necrotic and non-enhancing tumor core (NCR/NET — label 1), as described both in the BraTS 2012-2013 TMI paper and in the latest BraTS summarizing paper (also see Fig.1). The provided data are distributed after their pre-processing, i.e. co-registered to the same anatomical template, interpolated to the same resolution (1 mm^3) and skull-stripped.BRATS 2015: Brain Tumor Image Segmentation ChallengeLGG Segmentation DatasetThis dataset contains brain MR images together with manual FLAIR abnormality segmentation masks.
The images were obtained from The Cancer Imaging Archive (TCIA).
They correspond to 110 patients included in The Cancer Genome Atlas (TCGA) lower-grade glioma collection with at least fluid-attenuated inversion recovery (FLAIR) sequence and genomic cluster data available.
Tumor genomic clusters and patient data is provided in data.csv file.Additional Resources for Deep Learning/AI image processing"
"DOID , SYMP Ontology Sparql Queries","
I need to extract the list of diseases, categories, bodyparts and symptoms.
I've found several ontologies for that datasets.
Disease ontology, symptom ontology,  Bioportal and Wikipedia. But I don't know how to build  SPARQL queries correctly for extracting needed information.
Is there anyone that can help?
","['wikidata', 'sparql', 'ontology', 'semantic-web']",
How to get get Rto data using vehical no in android studio,"
How to get Rto data by vehical no in android studio any api available for get rto data ...
From where other apps are getting data.
","['government', 'india']",
Medical data sets,"
I am searching for medical datasets that include taking the dosage of a particular medicine and measurements of Bioindexes such as blood sugar or everything else. Can you guide me if you know?
",['medical'],
Offshore Wind Data,"
I have a question and I would be happy to receive any leads on it from you.
I need some yearly offshore wind data sets for a given location but for several many years (say past 20 years or so). I would be happy if the data is recorded uniformly at hourly or half-hourly frequency.
Would anyone be knowing any open data source for this?
",['data-request'],
Need data populated/inhabited areas for Madagascar,"
I am trying to analyze the number of schools per square kilometer in Madagascar, but only considering the number over inhabited areas. I have data on schools from the World Bank, but I can't find a reliable source of data for populated areas.
I have looked at the data on Open Street Maps but the extent and quality of the data varies a lot by sub-region. Some areas have many buildings and roads mapped while others do not. I lived in Madagascar for four years and I can tell that these gaps are due to missing data. I joined select land uses with a buffer around buildings to get an ""inhabited areas"" layer, but the measure of schools per area is also varying unrealistically (some places have more than 50 up to thousands of schools per square kilometer of calculated area).
Where can I find data on inhabited/populated areas to compliment or replace OSM? Are there any strategies this community has come across for finding or calculating measures of populated areas?
","['geospatial', 'population']",
OpenFDA Covid19 Serology Tests DB Created_On/Updated_On Fields?,"
We are looking to monitor data that is added/changed within the DB on a daily basis.  When looking at the results returned from the OpenFDA Covid19 Serology Tests API, it appears that in the metadata there is reference to when the DB was updated, but there does not appear to be a way to see the records within the DB that were actually updated.
For example...  As of today, there are 4180 results and the DB was updated yesterday.  There does not appear to be a way to identify which records within the database were updated or added as there is no record field for updated_on or created_on - only when the actual test was performed with date_performed.  As this test could have been performed some time before being added to the database, and probably does not correlate to when the test was added or updated within the db, we can't easily see what has changed.
{
  ""meta"": {
    ""last_updated"": ""2020-07-26"",
    ""terms"": ""https://open.fda.gov/terms/"",
    ""results"": {
      ""skip"": 0,
      ""total"": 4180,
      ""limit"": 4180
    },
    ""license"": ""https://open.fda.gov/license/"",
    ""disclaimer"": ""Do not rely on openFDA to make decisions regarding medical care. While we make every effort to ensure that data is accurate, you should assume all results are unvalidated. We may limit or otherwise restrict your access to the API in line with our Terms of Service.""
  },
  ""results"": [
    {
      ""control"": ""Pass"",
      ""lot_number"": ""COV1252003C"",
      ""igm_agree"": ""TN"",
      ""date_performed"": ""5/8/2020"",
      ""sample_id"": ""C0054"",
      ""iga_result"": ""NA"",
      ""igg_truth"": ""Negative"",
      ""pan_result"": ""NA"",
      ""igg_agree"": ""TN"",
      ""group"": ""HIV+"",
      ""igg_titer"": ""0"",
      ""igm_titer"": ""0"",
      ""igg_result"": ""Negative"",
      ""manufacturer"": ""Abacus Pharma International"",
      ""type"": ""Plasma"",
      ""igm_truth"": ""Negative"",
      ""igm_igg_agree"": ""NA"",
      ""days_from_symptom"": ""NA"",
      ""sample_no"": ""30"",
      ""antibody_agree"": ""TN"",
      ""device"": ""SARS-CoV-2 IgM/IgG AB Antibody Rapid Test (Immunochromatography)"",
      ""igm_igg_result"": ""NA"",
      ""panel"": ""Panel 1"",
      ""antibody_truth"": ""Negative"",
      ""pan_titer"": ""0"",
      ""iga_agree"": ""NA"",
      ""evaluation_id"": ""maf3257-a001"",
      ""pan_agree"": ""NA"",
      ""igm_result"": ""Negative""
    },
....

As we are looking to see what has changed, it would be nice if each record had something like searchable fields of ""created_on"" and ""updated_on"" so specific tests that were added/updated could be monitored instead of having to do a comparison of every record's field to find results that had changed from the previous update.
Are there any plans to add these fields to the database as it would make tracking changes much, much easier for external (and potentially internal) interested parties?
","['openfda', 'covid19']",
"How to get List of all diseases , categories , causes and symptoms?","
I am looking for a medical dataset. I Need a list of all diseases, symptoms, categories, causes, body part relations. I don't know how to get it. Actually I've found some semantic sources like  DO  and  SYMP ontologies. But I am not familiar with  SPARQL that is why I don't know how to extract needed information from them.
Also, I've found DIsgnet database. it is pretty good. But it doesn't hold the symptoms.
Need your suggestions.
How can I get these data?
","['data-request', 'medical', 'sparql', 'database', 'ontology']",
"OSHA Inspection Enforcement Data, Migrant Labor Inspection Variable","
Does anyone have more information about how OSHA classifies certain inspections as migrant labour inspections? The frequency of these migrant labour inspections seems low relative to the number of migrant labourers we have in the country, so I was wondering if there are additional criteria for an inspection to qualify as a migrant labor inspection. The webpage does not provide any additional information https://developer.dol.gov/health-and-safety/dol-osha-enforcement/.
",['labor'],
Would anyone know the 1993 zip code for Irvine CA,"
I need the zip code for 1993 Irvine, CA.  Would anyone know this?
","['data-request', 'usa']",
How can I access the EIN (Employer Identification Number) data?,"
Suppose we need a service that would determine if someone is a Business, be able to verify it from the Company Name and the EIN provided.
","['data-request', 'api', 'data.gov', 'business', 'irs']",
Where can I find statistics for Facebook and YouTube total views worldwide like those of Wikipedia?,"
I am working on a research program about social media traffic and my mission is to find official usage data for major platforms like YouTube, Facebook, Twitter, Wikipedia etc.
Wikipedia provides official Worldwide stats per year https://stats.wikimedia.org/#/all-projects
Does anyone know where I can find similar official source about Facebook, YouTube, and Twitter statistics?
Please note that both Youtube and Facebook provide some metrics worldwide about Monthly Active Users (MAUs) and Daily Active Users (DAUs) but my goal is to find yearly records about total page/video/tweet views like Wikipedia's
","['research', 'social-media', 'internet']",
OpenFDA Covid19 Serology Tests missing manufacturer?,"
-- Missing manfuacturer?:
The manufacturer Beckman Coulter, Inc. is not available in the data as can be seen here
https://api.fda.gov/device/covid19serology.json?count=manufacturer.exact
but it is listed here https://www.fda.gov/medical-devices/emergency-situations-medical-devices/eua-authorized-serology-test-performance
What is the reason that some data appears in openFDA and some does not?
-- Missing tests?:
Also, there are 110 samples for each of the manufacturers, 80 Antibody Truth Negative and 30 Antibody Truth positive. Can you explain this data distribution? It seems that the data that is available under openFDA is hand picked. If so, how/why is it chosen?
",['openfda'],"Unfortunately, we don't have answers to the questions you posted since openFDA merely processes & exposes the COVID data set that we receive via internal FDA channels. We would recommend that you contact the Center for Devices and Radiological Health at FDA directly with your inquiry as they are likely much better suited to answer these. Sorry about the inconvenience."
"Organization size, number of managers or officials, or organizational charts for organizations (NGOs, firms, etc)","
I'm interested in the size of organizations (ANY organizations), the number of managers and/or officials, salary/compensation, operating territories, and the organizational structure of the organization. For organizational structure, I mean something that could be represented as a network. This includes current and past data.
This data would generally be useful for researchers in the social sciences (that's me), so I'm keeping this question pretty broad. Are there open data databases or datasets for this anywhere? Are there sources which are not quite databases but which could be easily programmatically scraped to build a dataset?
Public and Regulated Companies (US)
The US Securities and Exchange Comission (SEC)'s online database, EDGAR, might contain some usable information, but I was unable to find anything obvious.
Governments (US)
I did find that a web search would bring up org charts for some US national departments, agencies, and so on, and some US states. Everything I have found would need a lot of human work to put into a usable data format, even with the assistance of some PDF or web scraping.
International (outside the US)
I looked at Canada's Innovation, Science and Economic Development (ISED) and Germany's BaFin, but they seemed to have no useful information.
Private Databases
I found a paper from the 80s where the researcher obtained data from Hewitt (which is now Aon Solutions). I suspect there are a number of large consulting firms (e.g. Deloitte) and also firms that sell title and pay information (e.g. Payscale, Glassdoor) that could have this information, or at least some of it.
",['network-structure'],
xbox achievement / trophy statistics?,"
Each Xbox game has certain challenges called ""Achievements and Trophies"". When one is achieved, a pop up appears on screen notifying the player. Along with the notification that the achievement as been made, the notification also displays the % of other purchasers of that game who also got the achievement.
Is this data (a list of game + achievement + % of players who achieve) publicly available somewhere (preferably as an API)?
",['data-request'],
Public datasets that show “cyclical” behavior,"
I initially posted this question here
https://datascience.stackexchange.com/questions/78139/public-datasets-that-show-cyclical-behavior
but was redirected here.  I am looking for any publicly available dataset that has a ""cyclical"" structure to it (limit cycles), in the sense that if I plot the data in a certain way, a loop becomes visible.  A good example of this would be the Lotka-Volterra predator-prey model, which has a very pronounced cycle, shown below.  Are there any other good examples that demonstrate this?

",['data-request'],
How Can I Find Public Datasets related to graduation rates from public high schools?,"
I am looking for data, preferably large public datasets, related to graduation rates from public high schools according to zip code across American states. Can you help me with them?
",['data-request'],
"From where do I get shapefiles for all the states in USA at Census Tract level with ""population"" or ""population density"" data too?","
I scoured the US Census site for any data like the population at Census Tract level, for the year 2019 or 2018, but I am unable to find it.
I can get plain shapefiles that do not contain any demographic information at census tract level, but then that's it.
For the state of Colorado, I got file which has population/population density data along with geometries at census tract level from ArcGIS from 2017 I suppose, but it does not seem to contain data for rest of the states.
Even if both the information are not together, but if they can me merged using two different data sets, that's fine too.
If you have worked with census tract level population data (2019 or 2018 estimates) then do let me know.
","['geospatial', 'usa', 'us-census', 'census', 'population']",
(Serious) Dataset of paedophilic Youtube comments (or similar)?,"
I think it would be useful to create a model that tries to predict whether a youtube comment is paedophilic - maybe the model should also take into account the channel name/description/front image.
It's not an easy task but at the moment I'm just looking for data.
I know it's a sensitive topic - but does anyone know of a dataset out there with the characteristics I need?
","['data-request', 'nlp', 'text']",
Where Can I find the Developers Survey Dataset?,"
Where can I find the yearly Survey dataset of Developers(developer experience from career satisfaction and job search to education and opinions on open-source software)?
","['data-request', 'survey']","Apparently here2020Nearly 65,000 responses fielded from over 180 countries and dependent territories, the 2020 Annual Developer Survey examines all aspects of the developer experience from career satisfaction and job search to education and opinions on open-source software.View Survey Results • Download Full Data Set (CSV)2019Nearly 90,000 developers took the 20-minute survey.View Results • Download Full Data Set (CSV)2018Nearly 100,000 developers took the 30-minute surveyView Results • Download Full Data Set (CSV)2017Nearly 64,000 developers took the surveyView Results • Download Full Data Set (CSV)2016Nearly 56,033 coders in 173 countries took the surveyView Results • Download Full Data Set (CSV)201526,086 people from 157 countries participated in a 45-question survey. 6,800 identified as full-stack developers, 1,900 as mobile developers, 1,200 as front-end developers, 2 as farmers, and 12,000 as something else.View Results • Download Full Data Set (CSV)2014The survey sample of 7,500 responses from 96 countries.View Results • Download Full Data Set (CSV)2013Nearly 10,000 responsesView Results • Download Full Data Set (CSV)2012View Results • Download Full Data Set (CSV)2011Morethan 2500 responsesView Results • Download Full Data Set (CSV)"
Datasets of labor union metadata and membership in the United States,"
I'm looking broadly for datasets that offer insight into labor union membership, participation and behavior in the U.S.
So far there's some good stuff in the Office of Labor Management and Standards financial reports data, but I can't find much else in the way of robust datasets about unions. There's also some interesting stuff on the Department of Labor developer site here, but it doesn't seem to touch on unions at all (other than one column in an OSHA dataset).
Are there any other datasets or bodies that accumulate public data on unions / labor participation in the U.S.? I'd specifically love any datasets that associate unions with specific industries or employee titles, but would welcome basically anything.
","['data-request', 'usa', 'government', 'labor']","Find summary statistics on NLRB activity, including decisions, court reviews, elections, unfair labor practices, etc.. (from 1936-2009)(Information about the database. The database must be requested.) The ILO has created a database on trade union membership. It contains data for 45 countries from 1990-Available in Excel files on request from the ILO Bureau of Statistics.Contains publicly available US data about labor and unions dating from 1983-2014 in an MSAccess database for easy manipulation. Available at Catherwood Library only. Ask for assistance at the ILR Reference Desk.Provides statistical data from U.S. government publications from 1973, state and private sources from 1980, and international organizations from 1983.This January release is the main government source for statistics on U. S. labor union membership and density.Source for information on membership and finances of individual unions. From the U. S. Department of Labor.The Union Membership and Coverage Database is an Internet data resource providing private and public sector labor union membership, coverage, and density estimates compiled from the Current Population Survey (CPS), a monthly household survey, using BLS methods. These statistics are provided by the BLS in its annual Union Membership survey, but due with less detail. Be sure to read the background information on Unionstats.com with its commentary on the accuracy of the sample.The Bureau of Labor Statistics (BLS) of the U.S. Department of Labor is the principal Federal agency responsible for measuring labor market activity, working conditions, and price changes in the economy. Its mission is to collect, analyze, and disseminate essential economic information to support public and private decision–making.and more....Data and Statistical Sources: Labor and Employment: Data SetsDatabases, Tables & Calculators by Subject (U.S. Bureau of Labor Statistics)ILOSTATThe ILO Department of Statistics is the focal point to the United Nations for labor statistics."
List of weigh stations in the US and their locations?,"
I'm wondering whether there is any open data out there that comprehensively lists weigh stations in the US and their latitude/longitude. Other vehicle inspection facilities would be interesting.
","['geospatial', 'government', 'transportation']",
German nouns gender source,"
I want to create some sort of spell checking program for German language, for which i need a database with all the words and their gender description(only their gender description) to cross reference every word.
Can anyone help me to find such database to download? i would like if it would be in rows and columns so i can later then import it into a sql database in order to use it more easily
I want to create some sort of spell checking program for German language, for which I need a database with all the words and their gender description(only their gender description) to cross reference every word.
Can anyone help me to find such database to download?
I would like if it would be in rows and columns so I can later then import it into a sql database in order to use it more easily
","['data-request', 'language', 'programming', 'database', 'dictionary']",
Public dataset of cardiac stress test,"
I'm looking for a public dataset of data gathered from a cardiac stress test (AKA a cardiac diagnostic test, cardiopulmonary exercise test, or CPX test). Does anyone heard of such a thing?
",['data-request'],
"Dataset of language families, sub-families and their relations other than Wikidata","
I am interested in language families such as Indoeuropean, Romance languages, Afroasiatic and so on, not individual families (although if the dataset includes languages it doesn't hurt).
Wikidata and Wikipedia have some of this information but it's quite incomplete and several different classifications overlap, which makes it difficult to form the groups.
I am looking to make a clean and more useful version of this:

","['data-request', 'language']",It seems that Glottolog data repository is the most comprehensive source of machine-readable data.Perhaps the easiest way to access the data is pyglottolog package.
"ACS. Best way to get all PUMA, all variables, all years?","
I am reviewing the tables at https://data.census.gov/cedsci/
But it seems like they are catering to people that want some columns or some locations/years.
But for my project I am looking to get every year available (I think ACS goes back to 1990 at PUMA level), for every PUMA, for every variable available.
This will allow me to run year-level regressions for the whole US with the high precision of geography.
","['us-census', 'census']",
COVID-19 Case Line Data Sources for US States,"
The state of Florida provides detailed information of each positive case in its jurisdiction.
https://hub.arcgis.com/datasets/FDOH::florida-covid19-case-line-data/data
which allows a more detailed analysis of hospitalization/icu/ventilation/fatality rates at the age level.
Is anyone aware of other states or similar dataset structure for other administrative units in America or around the world?
Below is the State of Florida's Case Line Data Definition Table for reference:

","['covid19', 'epidemic']",
Shapefiles for Paraguay,"
I am looking for the latest shapefiles of the whole Paraguay:

Soil type
Contour
Land use
Precipitation
Administrative boundary
Open green space
Built-up area

I have looked at it on the national geo-portal of Paraguay, but could not find it. I also have looked through other geo-portal.
Any suggestions?
","['data-request', 'geospatial']",
UN Comtrade Database: Trade value when no quantity reported,"
I am working on a project where I need the trade data for a specific type of generator and I'm using the UN Comtrade database. Some countries report no quantity (quantity code 1) but do report a positive trade value. I am thinking that they do import this type of generator but do not provide the quantity but I haven't found any documentation about this happening so I am not positive.
Does anyone know why there may be trade values that do not reflect the number of reported units?
Additionally, I'm confused by the actual reporting of trade values. This document (page 6) implies that CIF trade values and FOB values could be reported, depending on what the country does. However, I don't see any field that would indicate another trade value or if an import value is CIF or FOB. Could anyone shed some light on this?

","['trade', 'un']",
Units on the attribute table of GIS dataset - California Counties 2016,"
I am using California county Data from 2016, from the US census site
Dataset: CA_Counties_TIGER2016
Metadata: https://catalog.data.gov/harvest/object/8933496c-7da8-486e-aa66-64981962a3c5/html
What are the units of column Aland?
When I run statistics using Arcmap they show a sum of 403501101370 (which does not seem to match  California;s landmass when calculated in sq m, km, acres)

",['data.gov'],
What is the best free database to use to get prescription and otc drugs marketed in the U.S. and approved by FDA?,"
I'm working on a project to build a drug database that provides drug lookup and information (indications/use, side effects, interactions, etc.) and also provides pricing by pharmacy networks. So, apart from the drug database where can I get the registered Pharmacy network (NPI) and pricing data?
",['openfda'],
Possibility for exchanging QGIS project files,"
Is there a site or ""Service"" to exchange QGIS project files? Perhaps creation of one would be interesting for others.
For example, I have created a complex project for sewer managment. I want to see and compare what others in this field might already have developed to improve my project. But i also want to share my project, because someone else might find it usefull what i have done.
",['geospatial'],
Is there cleaner alternative of the original JAXA ALOS AW3D30 digital surface model (DSM) data?,"
The team from JAXA made a great job on DSM derived from ALOS-2. However, I find issues on data, e.g.:

satellite stripes footprints, elevation drops by 1 to 5 metres

rare, but obvious noise in data


Is there any version with cleaned/postprocessed global dataset, which deals with imperfections of AW3D30 data? (e.g. SRTM data were upgraded multiple times by various communities).
","['geospatial', 'global']",
Obtain high resolution data for Papua New Guinea-Madang Province (QGIS),"
I'm currently working with a dataset of contagious bird illness in Papua New Guinea (specific for the Madang Province) and I would like to plot it in a map and try to run a few models, however all the climatic and geographical data that I've managed to found is usually for larger scales.
Has anyone on the forum worked with Papua New Guinea in the past and knows where to find high resolution climatic layers of mean temperature/rain. Also landcover, NDVI and land-use layers?
Also, does anyone know where to find very precise river layers, including not only the main rivers, but tiny streams, ponds, etc?
","['geospatial', 'climate']",
Is it possible to download worldometer COVID-19 country data?,"
I want to download the raw data for COVID-19 cases in Sweden but can't find anywhere on worldometer to do it.
Does anyone know how to download the data as a csv file?
","['csv', 'covid19']",
Get product recall information from Open FDA based on the DI or UDI of a product in GUDID,"
Can UDI or DI codes on product packaging of Medical Devices be used to check for a recall status? Search results from GUDID for product information data, and Open FDA for Recall data, do show some correlation, but I can't see a link that would provide the recall information from the UDI code.
The GUDID result includes a three digit Product Code category which is also included in the Open FDA Recall, but this is not product specific.
Is it possible to get more accurate information such as the manufacturer of the product, and more exact details of the recalled items based on a product identifier.
Many Thanks
","['api', 'openfda', 'uses-of-open-data']",
Does OpenFDA have duplicate reports?,"
In an answer of this specific question on stack exchange:
What does some reports have the same safetyreportid?
It is stated that openfda has duplicates:
'Duplicate and incomplete reports are in the system: There are many instances of duplicative reports and some reports do not contain all the necessary information'
However, checking openfda site for the  duplicate field description:

The site states that openFDA shows only the most recent version (meaning there is no duplicates on the openFDA)
I am a bit confused whether the openFDA API data provides duplicates or not.
I would love to hear more clarification about this matter.
",['openfda'],
please can someone help me with (or where) i can find dataset about Student e-learning habit before and during Covid-19?,"
I'm looking for detailed data about Student e-learning habit before and during Covid-19
",['data-request'],
CORINE Land Cover - interactive map which allows to emphasize/display/look for particular class,"
Is there an interactive map with CORINE Land Cover data, which allows to me to find places with presence of a particular CORINE Land Cover class?
Interactive maps like this one exist: https://europelandcover.ourecosystem.com/interface/ , but I'd like to see, for example, examples of occurence of ""Complex cultivation patterns"" (CLC242) on the map...
","['geospatial', 'land-cover']",
historical annual average temperature by country (with data after 2016),"
has anyone come across a data set of all countries with historical average annual temperatures? The World Bank provided exactly this (see here), but has not updated it after 2016 - I would like to have the latest data until 2019.
","['data-request', 'geospatial']",
Are there any free datasets on Japanese company names available?,"
Are there any datasets that contains Japanese Company names?
For example, ASICS Corporation's Japanese company name is ""アシックス"". If the datasets contains other information about the company it is fine, as long as it has the company name in Japanese characters.
","['data-request', 'companies', 'japan', 'japanese']",
Media Contacts Database?,"
Is there an open media contacts database, a sort of free version of EasyMediaList.com?
","['data-request', 'media']",The Python script MondotimesScraper can collect data from Mondotimes.com.
Grammar for mathematics,"
I was wondering if there exits an grammar defining mathematical language. By that I mean the list of the tokens used and the syntactic rules.
",['language'],
Social class and text dataset,"
I am looking for a dataset of text (tweets, post, etc...) labeled with the social class or occupation of the person. Any ideas are welcome.
",['data-request'],
Canadian Industrial Data i.e. NAICS,"
I know that any time you register a business in Canada, you have to classify the business with respect to the North American Industry Classification System (NAICS).
I am interested in knowing how populated certain industries are. But for some reason I cannot figure out how to access the data in the NAICS.
Does anybody know where one can access such data?
","['data-request', 'government', 'research', 'business', 'canada']",
Sky segmentation data set or model for deep learning,"
Context
I am searching an open data set and/or a model ""ready"" (or close to be ready) to segment the sky out of outdoor images, e.g.:
Input:

Source; unsplash, Pascal Debrunner, Oeschinen Lake, Kandersteg, Switzerland
Desired output:

Question
Do you know some data sets or models on that topic?
Or better, meta-surveys on that question?
Info; the deep-learning backend will normally be tensorflow/keras based.
","['machine-learning', 'images']",
Complete dataset of NYC building units,"
I am looking for a dataset that shows the number of units in each NYC building. The most complete dataset on NYC buildings that I've come across so far is the PLUTO dataset, which is referenced by Kaggle as being:

a master record of the locations and characteristics of buildings in New York City.

However, the latest version of this dataset has 858k rows and according to other sources, there are > 1 million buildings in NYC.
Does anyone know why some buildings are excluded and if there is a more complete dataset to analyze the number of units in buildings?
","['data-request', 'buildings']",
Datasets with chronological variables for specific countries,"
I am doing some time-series forecasts.
The datasets that I am working on have the attributes year, month, day and hour, however, in order to deal with seasonality and holiday effects, I am looking for datasets to complement with chronological variables such as week day, holiday, week number, month number,... for specific countries (Portugal and Spain).
I am wondering where may I be able to access this kind of data, ideally historical (but for future periods is a plus).
","['time-series', 'calendar', 'portugal']","As I was seeing different problems regarding Holidays, I using two different approaches to build my own Holidays dataset, for the Iberian Peninsula.The scripts are available on this repo, on GitHub.• In this one, I have added the holidays dates manually.• In this one, I am taking advantage of Facebook Prophet.In the meantime, I have also found a library that seeks to help generating country, province and state specific sets of holidays on the fly, however there is still a lot of room for improvement."
What does the searchable field safetyreportid mean in openFDA drug adverse event api,"
In the openFDA website(https://open.fda.gov/apis/drug/event/searchable-fields), it said safetyreportid is ""The 8-digit Safety Report ID number, also known as the case report number or case ID. The first 7 digits (before the hyphen) identify an individual report and the last digit (after the hyphen) is a checksum. This field can be used to identify or find a specific adverse event report."" Sorry I was confused with some points of the definition.

What does checksum mean? Is that the version number?
I saw some case IDs with a hyphen (like '4322505-4') but some don't (like '10003310'), is it just because of the different format?

",['openfda'],
Datasets for Causal Inference with Continuous Covariates,"
I am interested in testing a causal inference and need a dataset with the explanatory variables mostly or, even better, all continuous; ideally a randomized control setting, too.
","['data-request', 'randomized-trial']",Challenges in Machine LearningHere you can find causality Workbench datasets Choose the one that matches your requirement. Most of the datasets were from the competitions or from the real-world data.
Longitude and Latitude coverage for the city of Porto,"
I would like to have an idea of precise coverage (extend) for the latitude/longitude of the city of Porto, Portugal.
This is in connection with my research that I need to filter out geolocation data for the cities of Porto (Portugal) and Beijing (China). Luckily, I found one for Beijing city here as ""ranges from 39° 27' to 41° 03' N and in longitude from 115° 25' to 117° 30' E"" which is what I want.
For the city of Porto, all I get is a one-point coordinates (41.1579° N, 8.6291° W).
","['data-request', 'geospatial', 'europe', 'geocoding', 'portugal']","If you need a precise border of the city of Porto in coordinates, then extract a city boundary. Check these pages Getting city boundaries from openstreetmap and Getting polygon boundaries of City in JSON from Google Maps API?If only a rectangular, it is a boundig box, and you can get it here Getting bounding-box of city.Both cases are also possible with overpass turbo.References:Overpass API/Overpass API by Example"
"Is there a more detailed definition of variables under the PCT_RACE category, such as PCT_WHITE or PCT_HISPANIC?","
The College Scorecard Data Dictionary simply describes the variables as the percent of the population from the students' zip codes that are of that race, of the students in the earnings cohort. Is this the average over all of the zip codes? The earnings cohort refers to earnings after college, so is this considering a student's zip code prior to or post-graduation? Any help is appreciated
",['collegescorecard'],
How can I import your database downloads into Elasticsearch?,"
I spent several hours unsuccessfully trying to import the drug json files that you have available in the downloads section into the latest release of elasticseach  (7.8.0). The download files don't appear to be elasticsearch export files. Do you have any instructions for importing your files into elasticsearch?
The purpose for importing into elasticsearch is to use wildcard queries. Since you are using an elasticsearch DB, it seems reasonable that you would support imports into a similar DB.
",['openfda'],
Searching downloadable ADS-B database,"
I'm looking for a downloadable ADS-B historical database preferably with a free option, like the one that OpenSky-Network offers. To my knowledge, unfortunately, the OpenSky-Network database doesn't provide ADS B data that complied with DO-260B, where the quality indicators (the NUC (Navigation Uncertainty Code) or NACp (Navigation Accuracy Code for Position) or NIC (Navigation Integrity Code) or SIL (Surveillance Integrity Level)) are also included.
Any suggestions on other websites that offer downloadable ADS-B historical databases that include the quality indicators?
","['data-request', 'historical', 'database', 'aviation']",
Order to Cash public dataset,"
I am currently working on a project where I need access to an Order to Cash(O2C) and Purchase to Pay (P2P) dataset. I managed to get a P2P dataset from here, but am struggling to data for O2C. I've gone through kaggle/google datasets as well as several govt databanks but without any success. Any ideas/help regarding locating an O2C/another P2P dataset would be very helpful.
","['data-request', 'finance', 'opencorporates']",
Food Ingredient API/Database,"
For a project I need a data source, where I can find informations about ingredients like lactic acid or E 901. The needed information is if the searched ingredient can cause food allergies, is vegan, vegetarian, kosher, etc.
I could not find something like this in the last hour, only recipe information by name and/or barcode.
Use case: Check if a list of ingredients for a food will be suitable for people with dietary restrictions.
",['food'],"Spoonacular's Food and Recipe API provides access to over 360,000 recipes and 80,000 food products. The API enables users to search for recipes using natural language (such as ""gluten-free brownies without sugar""). Users can visualize recipe nutrition and ingredient lists, analyze recipe costs, find recipes by nutritional requirements, favorite ingredients, or what's in the refrigerator, classify recipes, convert ingredient amounts, and even compute an entire meal plan. The service covers ingredients, recipes, food products, and menu items.
spoonacular Food API includes a Visualize Recipe Nutrition feature.spoonacularESHA Nutrition Database APIThe ESHA Nutrition API is designed to simplify the integration of your application with ESHA’s extensive food database and nutritional standards. Rather than developing and maintaining your own nutrient database, you can rely on ESHA for high-quality source data.How this worksWhen a user searches for a food item on your website or application, a list of selections meeting the search criteria is returned. The user selects the closest match, enters a quantity and measure, and adds the item to the list. From there, the user can view a nutrition breakdown of total Calories, Fat, Protein, and other nutrients.With, developers can design an application that accesses the ESHA database and nutritional standards. The application can search over 100,000 foods, build a recipe or food intake with the results, analyze up to 80 nutrients in seconds, and view client nutrient recommendations expressed as DRIs, DGAs, or RDIs.Extensive DatabaseOur database boasts over 100,000 unique foods, including raw ingredients, recipes, manufacturers’ foods, processing items, more.Food AnalysisAnalyze foods for up to 80 nutrients and nutrient factors – everything from Calories and Fats to MyPlate values.RecommendationsYou can analyze dietary intakes per nutritional recommendations specified by various standards such as DRI, DGA, and RDI.Food Database API DocumentationFood DatabaseThis API provides you with tools to find nutrition and diet data for generic foods, packaged foods, and restaurant meals. In addition, it employs NLP (Natural Language Processing) which allows for the extraction of food entities from unstructured text.Covered Use CasesParse requests: https://api.edamam.com/api/food-database/v2/parserEdamam’s Recipe Search API which features 1.5 million recipes -
All recipes contain nutrition facts and are tagged with diet, health, and allergy labels. Recipes are searchable by keywords and ingredients. There is a free plan available.The database is available for free noncommercial use and free commercial use for startupsMore Resources10 Most Popular Food APIsFood-Related APIsProgrammablewebAPIlist"
"Is there such a thing as a non-trash open (free) API or ""regular data dump""?","
I'm desperate to find something to make me money. For this reason, I've recently gone through huge lists of APIs available, and it seems as if 100% of the ones that don't charge you money are extremely low quality. For example, some API (also offering a data dump, which I studied) which was supposed to give area names and street names for many countries, lacked my street for my country. Incomplete, buggy and useless for relying on.
The other problem is that all of these free APIs that exist seem to do very pointless things, such as dispense a stupid joke or something. I want things like up-to-date, official information about a given address such as who lives there, etc.
Just about anything I would need or find useful in the least wants me to pay them money, which I don't have. I also have no desire to reveal my identity for any more companies with constant data leaks everywhere, so that's also a huge problem even besides the sheer monetary cost.
It really appears as if all worthwhile data is securely locked away behind thick paywalls with huge padlocks.
I'm trying to come up with some kind of system which fetches data from various free APIs (or possibly paid ones, if it turns out to be worth it), process it locally with some ""patented logic"" (the real work), and then publish it in a new form which is very valuable to somebody so that they will give me money for it.
You keep hearing about all this data that is allegedly available, but I don't see how I'm going to get hold of it since I'm not already rich.
","['data-request', 'api', 'uses-of-open-data']",
"datapusher log shows `403 Forbidden` error every-time, while `Updating` resource files in CKAN","
I'm using ckan 2.7.2 (Docker), Whenever I try to update any resource file (via GUI), Ckan is throwing an error i.e. 403 forbidden and data could not successfully upload to the DataStore. Because of that file preview is showing old content, although we are able to download the new updated file (with updated data). whether I try to upload(update) that file directly to DataStore by  Upload to DataStore option, it throws same error i.e. 403 Forbidden error.
below are the logs of datapusher.error.log file:
[Tue Jun 23 10:56:50.423279 2020] [wsgi:error] [pid 725:tid 140031474673408] Deleting ""<resource_id>"" from datastore.
[Tue Jun 23 10:56:50.469999 2020] [wsgi:error] [pid 725:tid 140031474673408] /usr/lib/ckan/datapusher/lib/python2.7/site-packages/requests/packages/urllib3/connection.py:340: SubjectAltNameWarning: Certificate for demo.ckan.org has no `subjectAltName`, falling back to check for a `commonName` for now. This feature is being removed by major browsers and deprecated by RFC 2818. (See https://github.com/shazow/urllib3/issues/497 for details.)
[Tue Jun 23 10:56:50.470014 2020] [wsgi:error] [pid 725:tid 140031474673408]   SubjectAltNameWarning
[Tue Jun 23 10:56:50.534169 2020] [wsgi:error] [pid 725:tid 140031474673408] Job ""push_to_datastore (trigger: RunTriggerNow, run = True, next run at: None)"" raised an exception
[Tue Jun 23 10:56:50.534185 2020] [wsgi:error] [pid 725:tid 140031474673408] Traceback (most recent call last):
[Tue Jun 23 10:56:50.534187 2020] [wsgi:error] [pid 725:tid 140031474673408]   File ""/usr/lib/ckan/datapusher/lib/python2.7/site-packages/apscheduler/scheduler.py"", line 512, in _run_job
[Tue Jun 23 10:56:50.534189 2020] [wsgi:error] [pid 725:tid 140031474673408]     retval = job.func(*job.args, **job.kwargs)
[Tue Jun 23 10:56:50.534190 2020] [wsgi:error] [pid 725:tid 140031474673408]   File ""/usr/lib/ckan/datapusher/src/datapusher/datapusher/jobs.py"", line 463, in push_to_datastore
[Tue Jun 23 10:56:50.534192 2020] [wsgi:error] [pid 725:tid 140031474673408]     delete_datastore_resource(resource_id, api_key, ckan_url)
[Tue Jun 23 10:56:50.534193 2020] [wsgi:error] [pid 725:tid 140031474673408]   File ""/usr/lib/ckan/datapusher/src/datapusher/datapusher/jobs.py"", line 199, in delete_datastore_resource
[Tue Jun 23 10:56:50.534195 2020] [wsgi:error] [pid 725:tid 140031474673408]     good_status=(201, 200, 404), ignore_no_success=True)
[Tue Jun 23 10:56:50.534196 2020] [wsgi:error] [pid 725:tid 140031474673408]   File ""/usr/lib/ckan/datapusher/src/datapusher/datapusher/jobs.py"", line 160, in check_response
[Tue Jun 23 10:56:50.534197 2020] [wsgi:error] [pid 725:tid 140031474673408]     response=response.text)
[Tue Jun 23 10:56:50.534198 2020] [wsgi:error] [pid 725:tid 140031474673408] HTTPError: CKAN bad response. Status code: 403 Forbidden. At: https://demo.ckan.org/ckan/api/3/action/datastore_delete. status=403 url=https://demo.ckan.org/ckan/api/3/action/datastore_delete response=<html>\r
[Tue Jun 23 10:56:50.534200 2020] [wsgi:error] [pid 725:tid 140031474673408] <head><title>403 Forbidden</title></head>\r
[Tue Jun 23 10:56:50.534201 2020] [wsgi:error] [pid 725:tid 140031474673408] <body bgcolor=""white"">\r
[Tue Jun 23 10:56:50.534203 2020] [wsgi:error] [pid 725:tid 140031474673408] <center><h1>403 Forbidden</h1></center>\r
[Tue Jun 23 10:56:50.534204 2020] [wsgi:error] [pid 725:tid 140031474673408] <hr><center>nginx</center>\r
[Tue Jun 23 10:56:50.534205 2020] [wsgi:error] [pid 725:tid 140031474673408] </body>\r
[Tue Jun 23 10:56:50.534206 2020] [wsgi:error] [pid 725:tid 140031474673408] </html>\r

Please suggest, how to fix this.
Thanks:)
",['ckan'],
What does some reports have the same safetyreportid?,"
I thought that safetyreportid is the unique identity of a report, but I found that some safetyreportid like ""5390497-5"" has two or three reports in openFDA when I search by API:
https://api.fda.gov/drug/event.json?search=safetyreportid:%225390497-5%22&limit=99
Could I ask why there are multiple reports with the same safetyreportid in openFDA?
",['openfda'],
Searching for datasets of face mask images,"
I am searching for open datasets containing images of humans (or human heads, with or without background) wearing face masks, preferably medical FFP masks.
Context/scenery is not important. Annotated datasets would be beneficial, but images only would also be highly appreciated.
Images should cover at least the complete head of a human wearing a face mask like this: 
","['data-request', 'images', 'faces']",
How do i filter the accident table (OSHA) by the load_dt field using API V2 curl methodology?,"
I am submitting the following url on the OSHA site, and it doesn't appear to filter the data properly.  My understanding is the below url should filter accident table by LOAD_DT column and the 2020-05-31 date is considered a start date.   Therefore, it would retrieve first 200 results for records that have a LOAD_DT greater or equal to 2020-05-31.  I am getting results where LOAD_DT = 2019-07-22.  Your help would be appreciated.
https://data.dol.gov/get/accident/format/json/limit/200/date_column/LOAD_DT/2020-05-31
",['labor'],
dataset of workout/bodybuilding QA,"
I am looking for a dataset of bodybuilding/workout/exercise Q&A in a machine-readable way.
For example:
Q: What kinds of exercises to train my chest at home?
A: Push up. (or any article, website)
Q: How to do the deadlift?
A: There are 3 different way to do the ...
","['data-request', 'sports']",
"Is there some kind of public, open, free, reliable database containing all ""product release dates""?","
I wish I could look up, locally, without ever making an external request, the release dates (for each region/country) for ""any commercially sold product ever"". For example, I could do:
SELECT product_name, release_date_usa, release_date_fr FROM products WHERE (creator_company = 'Nintendo' OR publisher_company = 'Nintendo') AND title LIKE '%Zelda%' ORDER BY release_date_usa DESC;

That would give me a nice list of each Zelda game released and their release dates for the USA and France, ordered by their release date in the USA.
I've many times had the need to do things like that, and if somebody from 1985 would somehow read this question from the future, they would say:

Are you kidding? You can't even do that in the year 2020? But... all of these TV programmes talk about how databases and computers will make everything wonderful and easy and free? How come you still don't have it so far into the future?

To make it crystal clear:
I'm looking for a regularly updated and high-quality (reliable, and with the correct product names) CSV/JSON file which I can regularly download as a single archive, update my local SQL database with and then make all kinds of queries on locally, as shown above.
Please let this exist. If it's too broad, I would be okay with ""just"" all video games and movies, but preferably, I want every single product ever released in any nontrivial amount.
","['data-request', 'historical']",
Standard longitudinal health dataset,"
I am looking for a specific type of a dataset in order to develop a statistical and/or machine learning model for health data. This dataset should contain histories of many patients with the diagnoses/procedures that they underwent and the corresponding time labels. I would like to hope that there is such a dataset (or similar) used for machine learning algorithms, which is freely available and not constrained by patient privacy issues, etc.
All suggestions will be greatly appreciated.
",['database'],
3D brain tumor datasets for classification,"
I am a research master student and I need the data to finish my thesis, I would like a MRI brain tumor dataset for classification, which contains certain classes from this list (malignant, benign, atypica, pituitary adenoma, pituitary cacinoma, craniopharvngioma, rathke's cleft cyst) Would you suggest a database please?
",['images'],"Brain Tumor Classification (MRI) with four Classes MRI images into four classesGitHub LinkThe folder contains MRI data. The images are already split into Training and Testing folders.
Each folder has more four subfolders. These folders have MRIs of respective tumor classes.The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) is a challenge focused on brain tumor segmentation and occurs on a yearly basis on MICCAI.
This dataset, from the 2015 challenge, contains data and expert annotations on four types of MRI images:Download HereBrain Tumor Segmentation(BraTS2020)Additional References"
How to retrieve infos about creators with sparql in wikidata,"
I'm trying to retrieve infos about birth and death corresponding to paintors with this query, however I have an empty result if I uncomment birth and death infos.
# added before 2016-10
# Recherche de tableaux avec images
#defaultView:Table
SELECT ?paintingLabel ?date ?movementLabel ?pic ?painter ?painterLabel  
                            ?painterGenderLabel ?painterCountryLabel ?birthDateLabel ?birthPlaceLabel ?deathDateLabel ?deathPlaceLabel  
        WHERE {           
  ?painting wdt:P31 wd:Q3305213. 
  ?painting wdt:P18 ?pic.
  ?painting wdt:P571 ?date.
  ?painting wdt:P135 ?movement.
  ?painting wdt:P170 ?painter.
  ?painter  wdt:P21 ?painterGender.
  ?painter  wdt:P27 ?painterCountry.
  #?painter wdt:p569 ?birthDate.
  #?painter wdt:p19 ?birthPlace.
  #?painter wdt:p570 ?deathDate.
  #?painter wdt:p20 ?deathPlace.
          
  SERVICE wikibase:label {            # ... include the labels
        bd:serviceParam wikibase:language ""[AUTO_LANGUAGE],en"" .
    }
}

#ORDER BY DESC(?time)
LIMIT 3

How could I modify this query to get these informations?
","['wikidata', 'sparql']",
Why is LO_INC_WDRAW_ORIG_YR2_RT greater than LO_INC_WDRAW_ORIG_YR4_RT?,"
The way I understand it, LO_INC_WDRAW_ORIG_YR2_RT is the number of low-income students that withdrew from the college within 2 years. There is also a variable for 3 years, 4, 6, and 8 years. I am confused because the maximum value goes down for larger years (in R, I have filtered ""PrivacySuppressed"" and ""NULL"" entries then arranged them in descending order by the LO_INC_WDRAW_ORIG_YR#_RT variables where # is 2, 3, 4, 6 or 8).
colleges %>% 
    select(INSTNM, LO_INC_WDRAW_ORIG_YR6_RT) %>% 
    filter(!(LO_INC_WDRAW_ORIG_YR6_RT == ""PrivacySuppressed""), 
                 !(LO_INC_WDRAW_ORIG_YR6_RT == ""NULL""),
                 !(is.na(LO_INC_WDRAW_ORIG_YR6_RT)), 
                 !(is.null(LO_INC_WDRAW_ORIG_YR6_RT))) %>% 
    arrange(desc(LO_INC_WDRAW_ORIG_YR6_RT)) 

Shouldn't the number of students that withdrew within 2 years be counted into the total for 3 years, and those be counted into the total for 4, etc, meaning the maximum value should go up rather than down?
",['collegescorecard'],
Library of ancient Linear A and Linear B text images?,"
Is there an open-data library of text\language images for ancient Linear A and Linear B languages?
","['images', 'language']",
What are some canonical time series data sets or data series?,"
I have a time series technique I want to try out.  Is there a list of canonical data sets or time series data that I should test my technique on so that I can see if the technique works?  For example, when it comes to ML, the IRIS and MNIST are some popular datasets that one should test, and there are benchmarks to exceed.
In R, I could generate any order Arima() using Arima.sim() function.  I plan to generate AR(1) and MA(1), probably ARMA(1, 1), AR(2), MA(2), and ARMA(2, 2), data.  Are there any other ones I should generate to cover the main types of data?  Maybe seasonal data or regression with time series error type data?  And finally, are there any popular real-life time-series data sets I should test the technique on?  The response can be either categorical or numerical.
","['data-request', 'time-series']",
Looking for a Geoda map with OECD countries,"
For my undergraduate thesis I must do a spatial analysis over the OECD countries, but I cannot find a map for them, due to them being so spread apart. Funny thing, even my spatial analysis teacher couldn't do it, so I am wondering if there is any way you know about doing it?
",['geospatial'],
OpenFDA Medical Device 510(k) other information than summary/statement,"
Is it possible to identify all 510k records of medical devices were a FDA review or clinical trials is available (e.g. https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfpmn/pmn.cfm?ID=K151502) using either the API, the dataset (https://open.fda.gov/apis/device/510k/download/) or any other database?
Records with a summary/statement can easily be identified by statement_or_summary in the provided dataset.
Update:
Just saw that the online search mask (https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfPMN/pmn.cfm) offers a box to filter results with clinical trials. Is this information also available with the api or the /device/510k data file?
","['api', 'openfda', 'government']","I'm Jack with the openFDA team. To my knowledge none of the fields in the openFDA 510k API flag the record as a clinical trial. There are no plans to add this at present.Thank you,
Jack Finch"
Looking for a motorcycle database,"
I've been looking for a while for a database (or API) containing information about motorcycles. Notament :

Brand
Model
Year of manufacture
If possible various technical information
And also if possible the different maintenance to be done on the vehicle.

The best would be a free base (because it is, for the moment, for a personal project). But why not later on move to a paid base but with more information.
","['transportation', 'database', 'open-source']","Bikes Price and SpecsThe dataset containing bike manufacturer, model, price and other specificationsVehicle dataset from cardekhoUsed Cars and motorcycles dataAdditional ResourcesNeed to web scrapPaid:Teoalida's Car Database
The most updated automobile database – Excel, CSV, SQL files for download"
Search the summary PDF 510k medical device of openfda,"
Is it possible to search specific terms within the summary or statement PDF of the 510k records of medical devices using either the API, the dataset or an online database?
I found a similar question (Open FDA - Medical device search -> summary pdf), however, the answer there does not fully answer my question if this is possible.
I loaded the dataset in R and tried to search the full text of the PDF but it looks like the full text is not stored in the dataset?
If it is not available, would it be reasonable to scrape it?
","['api', 'openfda', 'government']","I'm Jack with the openFDA team. At present the text of the summary PDFs is not included in the openFDA 510k API. We have no plans to change this yet, but I will bring it up with the team and look into adding this feature. As this would be a large feature addition, it will take some time to implement if it is determined to be a feasible and approved.Thank you,
Jack Finch"
"Is there a good source for construction projects (CBS, WBS) written in Microsoft .mpp format?","
I am looking into automating the conversion of data written based on CBS (Cost breakdown structure) to data that are written based on WBS (Work breakdown structure). To do so, I needed a good number of CBS-WBS 1 to 1 pair dataset. However, I could not find any openly available data yet. Does anybody know where I can find such data? Or where can I start the search from?
",['industry'],
List of all UK bank holidays for the last 100 years,"
I'm after a list of all bank holidays, ideally separate lists for England, Wales, Scotland, NI, that include Date, Bank Holiday name. I can find individual years' worth, or a decade or two, but I'm after a large data set for populating a data warehouse for analysis.
e.g.

'30 May 2016', 'Spring bank holiday'
'29 Aug 2016', 'Summer bank holiday'
'26 Dec 2016', 'Boxing Day'
'27 Dec 2016', 'Christmas Day (substitute day)'

",['uk'],
Text Dataset for Entity Recognition of personal data,"
I am looking for a data set to train and set up a personal information masking application. Is there a text data set available with the name, location, bank account numbers, SSN, Name, Ip address etc (either anonymized or masked, I am only interested in sentence structure and not the actual SSN or Bank account number)? I am trying to build an application similar to this https://presidio-demo.azurewebsites.net/
","['data-request', 'geospatial', 'english', 'text']",
Data Sources for Revenues of European Football Clubs? [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 3 years ago.







                        Improve this question
                    



Football industry revenue data. For instance, expense related data, accounts payroll, wage transfer data?
","['data-request', 'europe', 'football']",
Not able to find Endpoint URL and correct document for Sam.gov REST callout,"
Not able to find any proper document for sam.gov REST API.
Here is one example. I want the entire result in JSON or XML format so that I can use that in my system. I am not able to find the correct API URL for this.
",['labor'],
Where can i find project management system data?,"
I am searching for datasets related to project management system.Project planing details such as project name,milestones,tasks and time.
","['data-request', 'database']",
Looking for public dataset for stock market that is updated daily,"
I want to do some modelling and data visualization on historical stock data, including price, volume, financials, etc. Is there a public dataset available for stock price history? I looked at a few (Yahoo, Kaggle and Tiingo), but either they have a high cost, are missing some of the key financial information, or are not sure they would be reliable and up to date. Free would be preferred, also established and reliable. If not, what are some good options for collecting the data myself? Maybe web scraping, public APIs, etc. I plan to use this data in a machine learning project I am building.
","['data-request', 'machine-learning', 'stock']",
Where can I find Political Party Affiliation Data?,"
I would like to make a heat map based on political party membership density in (e.g., California 60% democrat, Kentucky 70% Republican, etc.), preferably at the county level.
Does anyone know of a source for this geography crossed with politics data?
","['geospatial', 'usa', 'politics']","MIT Election Data and Science LabThey state that ""Our lab is a clearinghouse for data sets that can fuel studies on elections and how they're conducted. Find election data and research tools produced by us and others.""Best place to find an election dataVoter Registration - By County and PartyUnited States Census Bureau In addition to the Voting and Registration estimates made available on this website, data users can obtain Public Use Microdata Files for elections that the U.S. Census Bureau has data for via DataFerrett, the Bureau's online data access application. The November CPS data files, and entire datasets, are accessible for free through the DataFerrett tool dating back to 1994. The CPS FTP site is another location for obtaining voting and registration data. Data users can also obtain CPS Voting and Registration data files from non-governmental websites. The National Bureau of Economic Research website contains voting supplement datasets starting in 1994. The IPUMS-CPS website maintained by the University of Minnesota includes voting supplement datasets starting in 1976.”NCSL"
Youtube Data API Limit requests,"
I'm working with an academic researcher on a project that involves sending a large volume of requests to the  Youtube Data AAPI. The problem we've encountered is that the 10,000 unit daily request limit is too small for our research project. We've tried submitting requests for a rate increase via Youtube's web form but the questions and material they expect are focused on commercial applications and usage of the API. The requests we've submitted so far have either been ignored or received automated responses for being incomplete. 
Does anyone have experience accessing Youtube metadata for academic research? Is there a better way to request a rate limit increase for the Youtube API for a research project? Does anyone have any guidance about the type of material needed to get a response from the Youtube team? 
","['api', 'video']",
Yawning or mouth open/close image dataset,"
I'm new to machine learning and having a hard time collecting dataset. I'm promise this is for study purpose only, no bussiness included.
","['data-request', 'images', 'faces']",
Most frequently used programming language commands in Python,"
I am looking for a dataset which lists the most often used commands for Python in terms of their relative frequency.
Sample result could look like:
| Function name| Relative Frequency 
|:-------------|-------------------:|
| function     |                12% |
| print        |                 8% |    
| apply        |                 3% |    

",['programming'],
Is there any way to filter the data to view only county level data?,"
This is for data.gov and thanks for answering the question.
",['data.gov'],
"As a broker, get real-time data from exchanges","
I would like to build something like ""tradingview.com"" for a private broker
I've been crawling the entire internet with the quest of ""Finding something that will actually fit that requirement""
I've learned a lot, trust me I knew nothing about stocks / exchanges / brokers / investment, now I have a very poor idea of everything however I just don't get to see the right path to get data as a broker as most of the APIs I've found are data for the investors not for the brokers.
Tradingview offers several brokers to buy/sell whatever investors needs however, as a broker, where do I crawl data from?
Do I have to call exchanges in order to get a license to get real-time data in order to create my financial instruments or should I just go to this article and start doing PoCs of API consumption and display some simple linear/area charts with highcharts should I go to this other website which seems to be a good place to find APIs but it does not look like what I need, also highcharts stock charts seem to be a good but there's several other websites that do offer some crazy charts like the ones available at tradingview.
Basically what I need is some guidance of how to get data as a broker from exchanges in order to build private financial tools available for this broker's clients.
Do not limit the budget let it hit the fan
I could scrape the hell out tradingview using websockets but I guess there might be a better way to get that data like a membership, agreement, or whatever is required from exchanges
","['api', 'finance', 'trade', 'stock']","I did something similar with a friend. We built a perl (but would work in python/R/etc) just as well, and stock by stock we used the Yahoo Finance API, which seems to have been removed in its earlier form, but through Rapid API you can access the same information. With the data we retrieved, we created a postgres database with the various stock price values each day (OCHL). We took some time to build up the data, so as to not violate the (at the time) terms of service of the Yahoo API.Also, just because data can be found on the internet, doesn't mean you can use it for your purposes. There may be copyright or fair use conditions attached to it.Just on your idea to scrape tradingview.com, I suspect it would probably be violating the terms of service of your membership, so be careful.Note: I have no connection social/financial connection with Rapid API."
Twitter dataset to train word embeddings,"
I'm working on a project related to manipulating word embeddings. In order to do this, I need to train them myself on twitter data. Given Twitter's policy, I am unable to find a suitable dataset. Does anyone have one or know where I can find one?
The dataset should:

contain public tweets
have no specific topic, just need lots of tweets
be pre-processed

","['data-request', 'nlp']",
Polish road numbers used with kilometric points,"
When Polish road authorities refer to a location along a road using kilometric points, they append an extra letter (S5a, S5b, S5c…) to the road number to refer to different stretches of the road with different zero points.
For example, on the S8 numbering restarts at 0 behind Zambrów-Wschód and counts upwards until just before Jeżewo (at approx. km 29.6), where the numbering continues with km 615.4. That stretch is referred to as S8n.
This is especially common on expressways, which are often former national roads, upgraded to expressway standards and rerouted around built-up areas. Often these bypasses got built first and numbering would restart at km 0. Some roads have as many as 16 different points marked as km 0, and in some places numbering restarts at zero after as little as 10 km, thus disambiguation is paramount.
Sometimes the road number with the extra letter is reported on the delineators (which also serve as location markers); the S8n is such a case. On other stretches of road, the road number is indicated without the letter (i.e. S8) and thus cannot be gathered by means of ground survey (or OpenStreetCam, Mapillary and friends).
Does anyone know where a list of these “extended” road numbers (with information on the stretch of road they refer to) can be obtained, under an ODBL-compatible license?
","['geospatial', 'poland']",
"Is there such a thing as a public, curated list of people who WANT to be e-mailed?","
I've always wanted to be able to send e-mails to a lot of people, for example to announce something.
However, there are ultra-strict rules for this and basically, you destroy your ""reputation"" if you ""buy a list"" of contact information and send them e-mails, as many will (apparently) ""mark as spam"" or not even open it, somehow resulting in penalties for your domain/IP address.
So, is there a database for free listing all the ones who do want to get e-mails? For example, news people who gladly will wade through a lot of junk to find a hot ""scoop"" before anyone else, or investors with a similar mindset, or just people in general who, in some manner, have announced that they are perfectly fine with receiving unsolicited e-mails and therefore will be safe to ""spam"" without risking any anger from them?
I've many times attempted to compile my own such lists by visiting the websites of numerous newspapers, but it quickly exhausted me and it just doesn't seem reasonable.
Of course, these people would still be using spam filters and manual blocks, so they would not get overwhelmed, just like I'm not overwhelmed due to my numerous blocks of junk senders. The few spam e-mails that do fall through are more than manageable.
","['database', 'csv', 'email']",
Data on which topics angel investors have been interested through the years?,"
I'm interested in knowing which topics angel investors have...well...invested in during the last years. Preferably in Europe.
This is because I want to prove that the ""going green"" movement is growing strong.
Do you know any dataset I can analyze? I only know pitchbook.com but it's paid.
","['data-request', 'economics']",
County list of Woodard's American Nations,"
I've been looking for a list of counties in each ""nation"" of Woodard's map of American Nations. However, I only found maps of it and certainly as a beginner in the field, I am unable to transform this map into tabular list of counties in each ""nations"". I've checked his website but latest comment from visitors in his post about American Nations was 3 years ago.
I'm wondering if anyone have the list of counties for Woodard's American Nations or if there's any cultural map similar to Woodard's that's as defensible as Woodard's.
http://www.colinwoodard.com/files/ColinWoodard_AmericanNations_map.pdf
","['geospatial', 'county']","I generated a table of US counties categorized by Woodard's American Nations as shown on that map. Here's how I made it:Note that this table only includes US counties. The ""nations"" boundaries on the Canadian portion of the map don't correspond with county boundaries. The boundaries on the Mexican portion of the map correspond to states, not counties. The Mexican states of Baja California, Sonora, Chihuahua, Coahuila, Nuevo Leon and Tamaulipas are part of the ""EL NORTE"" region."
"Seeking any free, mappable real-time data which updates frequently (UK based is nice, but not necessary)","
I am looking for a free data feed (with HTTP(S) API) which I can use for various demos:

something that I can map (both as markers and a heat-map)
and chart the values
real-time, and at least part of it should update often enough that someone looking at the page for 30 seconds (preferably less) will notice  change
UK based is ""nice to have"" (London only is also acceptable), I also like Singapore (where the government have a lot of open data), but will accept anywhere
a single datum suffices (with multiple values; e.g datum is train, values are all trains, multiple datums (data) would be different train companies)

Any ideas?
","['api', 'uk', 'real-time']",
Food API Endpoints - Query by FEI number?,"
we are trying to figure out how to query the Food API endpoint using the FEI number and pulling back Recall Enforcement and Adverse Events Reports. So far we cannot find any way to query this data using the FEI number. Does anybody know if this is possible?
","['data-request', 'api', 'food']",
Number of Hospitals in the US with emergency departments,"
How many US hospitals have emergency departments?
","['data-request', 'usa', 'medical']",
Central vs Outlying counties for US Metropolitan Areas list,"
Metropolitan Statistical Areas (MSAs) in the U.S. are comprised of counties. Within MSAs, the Census Bureeau makes a distinction between ""Central"" and ""Outlying"" counties: https://www.census.gov/programs-surveys/metro-micro/about.html
I have searched far and wide for a user friendly (data analysis friendly) list of counties that contains information for their central/outlying status within MSAs. Unfortunately, I cannot find anything resembling a spreadsheet or data table.
I did find a list in an OMB bulletin https://www.whitehouse.gov/wp-content/uploads/2020/03/Bulletin-20-01.pdf?# , beginning on page 41, that contains the relevant information, but I am unable to extract this information in a systematic manner.
Does a spreadsheet/data table of this information exist anywhere? 
","['us-census', 'county']",
Is the most up to date data from the US Census on ZIP Codes (ZCTAs) from 2010?,"
I grabbed ZIP Code Tabulation Areas (ZCTAs) from census.gov  and I'm a bit confused because the data for Zip Codes seems to be from 2010?  Is that right?
Do they not change frequently enough to warrant an update in the 2019 dataset? Or is there a more updated data set?
","['geospatial', 'us-census', 'geocoding', 'postal-code']","ZCTAs are created every 10 years for the Decennial Census. They are not representative of current zip code boundaries. Zip codes are created for mail carriers to deliver the mail, not for data analysis.here is some really good information about ZCTAs from the Census Bureau:
ZCTA GuidanceThis video also has some good information in it"
ASRI frequencies database for FBOs,"
Is there a database of ASRI frequencies anywhere? I've been looking, but can't find anything. I know there is an FCC database of frequencies, but all the frequencies ASRI applies for are under their own name, so it's not easy to figure out the business they are for. 
",['fcc'],"Aviation Spectrum Resources, Inc. (ASRI) is the spectrum manager for aeronautical ""company frequencies"" (128.825-132.0 and 136.5-136.975). ASRI licenses all the frequencies with the FCC and assigns them to other users, so unfortunately the FCC data only provides part of the story but it is a start. The primary users of these frequencies are airlines but they are also used by Fixed Base Operators (FBOs), corporate aviation bases, some medevac services, and other entities.Finding Air Traffic FrequenciesDatabase of Frequency Allocations"
Download CKAN Revisions,"
Is there anyway to download revisions of data from a CKAN database?
I have been able to retrieve a revision list, but it seems as though there is no way to download individual revisions.

Here is the revision list
Here is the package information

I can even pull individual revisions
This is a link to the current version
The ID 2538d7f1-391b-4733-90b3-9e95cd5f3ea6 is not a valid revision ID, and I am unsure where that ID comes from. Anyone happen to know how to through the CKAN API?
","['api', 'ckan', 'download']","In this case, 2538d7f1-391b-4733-90b3-9e95cd5f3ea6 is a resource ID, not a revision ID. In CKAN, package(dataset) contains multiple resources and each of resources contain either actual data(file) or link to the data.Revisions reflect metadata change over time. I.e, it tracks changes in dataset fields and resource fields, but do not track changes of the uploaded file. So, you cannot download previous versions of data(file).What you can do with revision is viewing the previous title, description, etc. of the dataset. For example CKAN <= 2.8 allows to append revision to dataset id/name and view the previous version in UI:
https://hub.mph.in.gov/dataset/covid-19-case-demographics@ca33a830-f8da-4728-a238-7daa01b5bed8But, generally, revisions have pretty restricted capabilities and they will be replaced with improved activity stream in CKAN v2.9"
Dataset of electro-mechanical data storage devices prices and storage capabilities,"
I am looking for a data set of electro-mechanical data storage devices prices and specs. In particular, I am interested in the prices of memory storage (e.g. Hard Disk, Solid State Hardisk etc. etc.) comparing the $/GB, writing reading speed, the maximum capacity and so on I did my own table. But I want to validate it against a dataset.
","['data-request', 'global', 'technology']",
CEFR for English words by level,"
Are there any open source data for English words by CEFR level? 
I found https://www.oxfordlearnersdictionaries.com/wordlists/oxford3000-5000 , which categorizes English words based on CEFR level, but it has license.
","['language', 'english']",
Incorrect Product Code in OpenFDA Recalls Database,"
I noticed that when I look at product recall ""Z-1973-2012"" in the OpenFDA Recalls database, it returns with a result containing Product Code ""CGA"".
However the same recall number on FDA's Recall Search site returns an entry with Product Code ""CHL"".
Are such issues known with the Product Codes in the OpenFDA Recalls database?
",['openfda'],
Where can I find machine readable transcribed text of the 2016 Presidential speeches and debates?,"
I'm looking for a machine-readable repository of transcribed Presidential debates and speeches from the 2016 general election. Structured data with a common format is desirable, as well as updates for the remaining speeches before the election.
","['data-request', 'usa', 'government', 'nlp', 'politics']",Text from the speeches are available at the UCSB Presidency websiteText from the debates available as well.
Product Warranty Database,"
Is anyone aware of an open database of warranties on products?
Ideally, the database would allow the warranties on the product to be looked up by manufacturer and model number.
This would be useful for helping people to track whether their products are still under warranty.

I'm highly doubtful that such a database exists for all manufacturers.  If it exists for a subset of manufacturers (e.g., electronics, home appliances, automotive, etc.) that could still be useful.
","['data-request', 'legal']",
dataset for specialization of bachelor degrees,"
I would like to know if there is any dataset that has the information about all education degrees and its specializations ? 
It need not be limited or it can be for USA.
","['data-request', 'data.gov', 'education']",
"Is ""event_key"" meant to be empty?","
If you review the raw data documentation and any accompanying research papers, you will be informed that ""event_key"" is meant to be an important field.
Master Event Data: A distinct master event data record will be present for each source reporting anevent. In other words, if a User Facility, Distributor, Manufacturer, and voluntary submitter all report an event, there will be four event records. These individual source records are related via the EVENT KEY. EVENT KEY is an internally-generated key which links multiple sources to a single event.
(https://www.fda.gov/medical-devices/mandatory-reporting-requirements-manufacturers-importers-and-device-user-facilities/manufacturer-and-user-facility-device-experience-database-maude)
However from both the API queries and text file downloads the event_key field seems to be completely empty. Documentation also has missing details to help answer the question. Hope to get a response on this!
",['openfda'],
Is it possible to search using multiple criteria,"
Is it possible to search OpenFDA using multiple search fields. Separately both terms work but I can't figure out how to search using both at the same time.
This is what I tried that does not work to search using rxcui and manufacturer_name.
$ curl https://api.fda.gov/drug/ndc.json\?search\=openfda.rxcui:860975\&search\=openfda.manufacturer_name\=NCS                                                                                  2.6.5

{
  ""error"": {
    ""code"": ""BAD_REQUEST"",
    ""message"": ""Invalid parameter: openfda.rxcui:860975""
  }
}%

The rxcui by itself works
$ curl https://api.fda.gov/drug/ndc.json\?search\=openfda.rxcui:860975                                                                                                                          2.6.5

{
  ""meta"": {
    ""disclaimer"": ""Do not rely on openFDA to make decisions regarding medical care. While we make every effort to ensure that data is accurate, you should assume all results are unvalidated. We may limit or otherwise restrict your access to the API in line with our Terms of Service."",
    ""terms"": ""https://open.fda.gov/terms/"",
    ""license"": ""https://open.fda.gov/license/"",
    ""last_updated"": ""2020-05-30"",
    ""results"": {
      ""skip"": 0,
      ""limit"": 1,
      ""total"": 92
    }
  },
  ""results"": [
    ...
  ]
}

The manufacturer_name by itself works
$ curl https://api.fda.gov/drug/ndc.json\?search\=openfda.manufacturer_name\=NCS                                                                                                                2.6.5

{
  ""meta"": {
    ""disclaimer"": ""Do not rely on openFDA to make decisions regarding medical care. While we make every effort to ensure that data is accurate, you should assume all results are unvalidated. We may limit or otherwise restrict your access to the API in line with our Terms of Service."",
    ""terms"": ""https://open.fda.gov/terms/"",
    ""license"": ""https://open.fda.gov/license/"",
    ""last_updated"": ""2020-05-30"",
    ""results"": {
      ""skip"": 0,
      ""limit"": 1,
      ""total"": 318
    }
  },
  ""results"": [
    ...
  ]
}

","['api', 'openfda']","Yes, you can use AND logical operator as described in the openFDA documentation. "
How can I access GAEZ potential yield rasters?,"
I need rasters of global potential yields for various crops globally for a research project. These rasters are available from GAEZ, as pointed out in the answer to this question. 
However, the GAEZ data portal, an Adobe Flash web app, does not work for me. I am not able to download the data rasters (though I am able to download data in an aggregated tabular format). I've tried clearing my cache, switching browsers, etc. I've also had colleagues try to download the data without success. I've emailed GAEZ repeatedly about this over the last few months and have not received any reply.
Does anyone either have this data downloaded and would be willing to share it, or have troubleshooting tips?
","['data-request', 'geospatial', 'agriculture']",It turns out there is a separate data portal maintained by the IIASA which has this data: http://www.gaez.iiasa.ac.at/
I need a dialogue dataset,"
Where can I find a dataset of 2 people chit-chat dialogues? I need the data to be of full conversations, from ""Hi"" to ""bye"" so to speak.
","['nlp', 'text']","You can take a look at ParlAI framework, it is designed for dialogue researches.The framework provides a set of dialogue datasets. Please find those with tag ""ChitChat"" and see if they fit your needs."
Unofficial Metacritic API — Chicken Coop,"
My team and I are building a website about video games that has affiliate links in it.
My question is about the Chicken Coop API key provided by rapidapi (https://rapidapi.com/valkiki/api/chicken-coop/details).
Is using Chicken Coop API key breaking any Terms of Use of Metacritic? Are there any alternatives?
Main goal is to get metadata about video games from someone and Metacritic Game Metadata has all the video game details plus their Metascores. (If You know any free alternatives that offer video game metadata and allow for commercial use, please let me know).
","['data-request', 'api', 'metadata', 'legal', 'games']",
What would be the best ontology evaluation tool to use to analyse and evaluate the Computer Science Ontology (CSO)?,"
A tool that can assess the effectiveness of the Computer Science Ontology (CSO) in the best possible way, by assessing metrics such as accuracy, completeness, conciseness, consistency, expressiveness and other key factors that can be analysed and evaluated to assess the overall effectiveness of the ontology in representing the computer science domain. 
I wish to evaluate the ontology on criteria such as accuracy, completeness, conciseness, consistency, expressiveness, computational efficiency and practical usefulness as a representation of the computer science domain.
","['tool-request', 'ontology', 'analysis']",
MIR (Music Information Retrieval) Corpus suggestions,"
I have been working on a project on MIR.
I have run my code on various datasets like GTZAN, DEAM, EmoMusic
Now I want to train my classifier in a different fashion, i.e. Classification on the basis of Emotion invoked by the song. I tried to use last.fm for this cause but it was not much useful.
Can some suggest me a dataset, where songs are classified on the basis of emotions (Not on the basis of genres pls)?
I know that there is Arousal Valence model, but after going through various Survey papers I have found that the classification using that model is not the best, is there any other mode? or a Dataset someone can recommend.
Thank you.
","['machine-learning', 'music', 'classification']","You are on the right path,so you can either use a dataset providing the valence and arousal levels as meta data or the emotions. The first type is more frequent and easier to find but if you are interested in labeled emotions you can use the circumplex model developed by James Russell also known as Russell's model to convert the valence/arousal levels to emotion labels. 

(graph source: Perceptually Valid Facial Expressions for Character-Based Applications, https://www.researchgate.net/publication/220061100_Perceptually_Valid_Facial_Expressions_for_Character-Based_Applications)Here are some of those datasets:As for the datasets with emotion labels:More can be found under: https://ismir.net/resources/datasets/"
Datasets of Historical Locust Attacks,"
Locust swarms are highly mobile and can fly across continents and destroy entire livelihoods in less than six hours, with adult swarms flying about 150km daily. A small (1km2) size swarm (approx. 40 million locusts) can demolish the equivalent amount of food that 35,000 people would eat in a day (Cressman et al., 2016).
Are there any datasets of Locust attacks that happened in the past 25-40 years with lat, long, country, state, area of the land, swarm size, etc.,
",['data-request'],
Datasets With Estimable Counterfactual for Causal Inference,"
I am working on a new causal inference method for estimating treatment effects and want to test it against current methods. I would like to find a dataset where the counterfactual is either observed in an almost identical unit (i.e. the same person at a later point in time, not a different person; I realize this is impossible for the exact same unit) or the set up allows for good estimation of the counterfactual. I've spent a while trying to brainstorm ideas, and would like some outside input. I think biological studies that involve genetically identical mice given and the Card-Krueger minimum wage data near the PA/NJ state line are potential examples.
","['data-request', 'research']",
Database of ships?,"
Is there a database of the ships that were built until now, containing the size, weight, displacement, cost, year of built, and optionally the amount of used materials?
It does not need to contain the data of [almost] all ships, but at least the representative sample.
","['data-request', 'transportation']","From this answer on Get the Data: http://getthedata.org/questions/262/list-of-ocean-going-oil-tankers-and-owner/ (provided by Kit Wallace). Note none of this detail seems to be open data (as per Open Definition).There are a number of commercial sources such as http://www.ship-info.com/ or restricted sites http://www.equasis.org/ sites with copyright data http://www.digital-seas.com/ but also some amateur sites (which I cant find now).http://www.shipais.com includes data about the ships it plots - eg. http://www.shipais.com/showship.php?mmsi=256933000 but I'm not sure where that comes from now. Worth investigating.The ITU holds public details about MMSI numbers in their MARS database which does hold some category data , but its limited - here is the data for tanker with the above MMSI and the database is only searchable by MMSI, name or callsign.The best source though you need to register and search by individual boat is equasis which contains full ownership details. According to the websiteFrance and the European Commission shared the cost of developing and running Equasis until 31 December 2001 when the maritime authorities of the United Kingdom, Spain, Singapore and Japan also agreed to support Equasis financially. The budget of Equasis is agreed and provided by the Equasis MoU members. It is anticipated that the use of this website will remain free for the foreseeable futureAlso:Marinemapper exports KML files, and seems to have links to a lot of information about the vessels themselves.Vesseltracker also provides data about a variety of ship types, although it's commercial and non-open."
Seeking demographic information for Non-US regions,"
I seek CSVs of census / other demographic data for countries around the world which are broken down as fine grained a manner as possible.
As an example of something close but not quite, the Statistics Bureau of Japan puts out these maps (https://www.stat.go.jp/english/data/chiri/map/c_koku/2015.html) but not the raw data (as far as I can find).
Where do I find similar data for as many countries as possible in a raw format?
","['demographics', 'census', 'global']",
How can I override this «Query is malformed: Bad aggregate» error message?,"
I'm working with a Wikidata query:
SELECT DISTINCT ?protected_area ?protected_areaLabel ?coordinate_location ?territorialEntity ?territorialEntityLabel (SAMPLE(?instance_of) AS ?instance_of) ?instance_ofLabel WHERE {
  {
    ?prop wdt:P31 wd:Q55978235;
      wikibase:directClaim ?claim.
    ?protected_area ?claim _:b1;
      wdt:P625 ?coordinate_location.
    OPTIONAL { ?protected_area wdt:P31 ?instance_of. }
    OPTIONAL { ?protected_area wdt:P131 ?territorialEntity. }
  }
  UNION
  {
    ?protected_area (wdt:P31/(wdt:P279*)) wd:Q473972;
      wdt:P625 ?coordinate_location.
    OPTIONAL { ?protected_area wdt:P31 ?instance_of. }
    OPTIONAL { ?protected_area wdt:P131 ?territorialEntity. }
  }
  #    SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". }

}


This gives a ""Query is malformed: Bad aggregate"" error.
Before using SAMPLE the query worked.
After some reading I considered the SAMPLE keyword would require grouping, so tried this:
SELECT DISTINCT ?protected_area ?protected_areaLabel ?coordinate_location ?territorialEntity ?territorialEntityLabel (SAMPLE(?instance_of) AS ?instance_of) ?instance_ofLabel WHERE {
  {
    ?prop wdt:P31 wd:Q55978235;
      wikibase:directClaim ?claim.
    ?protected_area ?claim _:b1;
      wdt:P625 ?coordinate_location.
    OPTIONAL { ?protected_area wdt:P31 ?instance_of. }
    OPTIONAL { ?protected_area wdt:P131 ?territorialEntity. }
  }
  UNION
  {
    ?protected_area (wdt:P31/(wdt:P279*)) wd:Q473972;
      wdt:P625 ?coordinate_location.
    OPTIONAL { ?protected_area wdt:P31 ?instance_of. }
    OPTIONAL { ?protected_area wdt:P131 ?territorialEntity. }
  }
  #    SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". }

}
GROUP BY ?protected_area ?protected_areaLabel


And again the same ""Query is malformed: Bad aggregate"" error.
I really don't know how to diagnose and obviously to fix it :-| 
","['wikidata', 'sparql']",
Where can I find stock index data going back since at least 1900 from many different countries?,"
I also need fundamental data on the indices. I would like at least monthly data. I would like to use the data for backtesting. I'm aware there's problems with spreads and transactions costs with doing backtesting with that data.
",['finance'],
open FDA Recalls API endpoint does not have same information as accessdata.fda.gov,"
I am trying to pull data from openFDA for a 2007 medical device recall. On the FDA website I can see all the details - https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfRES/res.cfm?id=64517 such as Manufacturer Reason for Recall. However, when using openFDA Device Recalls API, it appears that information isn't there. I went to see if the data is in Recalls Enforcement Reports, but that data appears be to only after June 2012. Is there an API to get the Manufacturer Reason for Recall for these older recalls; to match what can be seen on accessdata.fda.gov?
","['api', 'openfda']",As of today the openFDA Device Recall API can only provide a subset of data available for a recall; you would have to query Medical Device Recalls separately to get a complete picture. The openFDA team is aware of the issue and is looking for ways to remediate this. We will post back once a solution is in place.
Where can I find historical natural disasters by country?,"
I'm trying to find a dataset that contains number of historical natural disasters by country in the longest lapse of time possible. Would appreciate your help.
","['geospatial', 'global', 'climate', 'geohazard']",
How to get male/female split for particular household income range in the United States,"
Where is the best resource to get the most recent Male / Female split of household incomes above $80K+ (or similar) in the United States? 
This U.S. Census table has ""Female persons, percent"" but I'm not able to filter by household income, which is what is desired. 
Any help or tips appreciated! Seems like a straightforward question, but not sure which Census / government data explorer is most appropriate for this question. 
","['usa', 'us-census', 'income']",
cpu usage and power consumption of servers,"
I would like to have a structured dataset about CPU usage and power consumption of servers. The data should include CPU usage, power consumption.
","['data-request', 'data.gov', 'government', 'uses-of-open-data', 'time-series']",
What are the best sources to find labelled review data sets for text classification?,"
I have been searching for labelled review data sets for training for label classification. However it has been a bit surprising for me that I could find only sentiment classification data sets and nothing else.
I am not sure if am doing the search right. While I understand that the engine should be trained for our data, trying with some ready made labelled review sets would make the algo be ready faster.
Are you aware of any sources where I can obtain labelled review data sets for label classification? If a free one does not work, paid sources are also fine.
","['data-request', 'nlp', 'classification', 'text']","User Review DatasetsThese datasets below contain reviews from Rotten Tomatoes, Amazon, TripAdvisor, Yelp, Edmunds.com, and so on. Here are some of the many datasets available out there:Consumer Reviews of Amazon Products100K Coursera's Course Reviews DatasetMore review datasets from Kaggle"
Where are some good online covid 19 genetic datasets?,"
I want to carry out some research with covid19 genetic datasets that include people infected by corona virus and people that aren't infected by it. Does anybody know any good ones? My main purpose is diagnostics of a genome to detect a possible infection. 
","['research', 'covid19', 'genome']","here is one resourcehttps://www.covid19hg.org/The COVID-19 host genetics initiative brings together the human genetics community to generate, share and analyze data to learn the genetic determinants of COVID-19 susceptibility, severity and outcomes. Such discoveries could help to generate hypotheses for drug repurposing, identify individuals at unusually high or low risk, and contribute to global knowledge of the biology of SARS-CoV-2 infection and disease.Not sure exactly where the raw data is -- but maybe this ""results"" page, which has ""Download"" links on the bottom: https://www.covid19hg.org/results/"
Global/European maximum daily temperature forecast,"
I am searching for either global or preferably European maximum daily temperature forecasts (I don't care for any historic data). To give you an example:

I wake up in the morning and want to know the maximum temperature for today and for the next three days. For my application it would be best if the data is in any kind of GIS or geographic data format. I tried searching the ECMWF but to no avail.

","['data-request', 'geospatial']",
Dataset for code analysis,"
I am looking for a data set that contains source codes in different programming languages and it is tagged with bugs in the code.
",['data-request'],"MUSE Open DatasetsCode and CommentsThe code and comments dataset is a compilation of code blocks and their related comments from 106,304 different Github projects. A total of 16,115,540 code-comment pairs were obtained by running Doxygen on C, C++, C#, Java, and Python projects. One of the primary goals of this data set is to provide an association between source code and a description of that code. This allows one to perform tasks such as training a machine learning model to predict a comment for a given snippet of code. [5G]Code and BinariesThe code and binaries dataset is a compilation of source code projects and their related build outputs from 3,049 different Github projects. Over 30,000 build outputs were produced from C and C++ projects. One of the primary goals of this data set is to provide an association between source code and the build artifacts of that code. This allows one to perform tasks such as binary analysis or reverse engineering. [7G]Code and Static AnalysisThe code and static analysis dataset is a compilation of source code and their outputs from running the static analysis tool, infer, on 3,170 different C and C++ Github projects. One of the primary goals of this data set is to provide an association between source code and a static analysis of that code. This allows one to perform tasks such as predicing the static analysis output on source code. [11G]GH Archive is a project to record the public GitHub timeline, archive it, and make it easily accessible for further analysis.GitHub on BigQuery: Analyze all the open-source codeMore resourcesGitHub Releases Dataset of Six Million Open-Source Methods for Code Search Research"
earthquake usgs api filter by country,"
I am trying to get recent earthquake data using https://earthquake.usgs.gov/fdsnws/event/1/ api.
For example this url (https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=2020-01-01&endtime=2020-01-10&limit=50) returns, earthquake happened during 01st Jan 2020 to 10th Jan 2020. It returns earthquake happened all over the world. But, I want to filter this api for particular country like Japan, India..
Is there any way to filter earthquake usgs api data by country name?
","['api', 'city', 'json', 'usgs']",
Where can i find high dimensional data with a big sample size?,"
I would like to work with some tabular data to do some regression variable selection where the sample size and dimension (n and p) are both above large. Let's say n>800 and p>8000.
I have seen when p is large, but usually n will be quite small such as ~100.
",['data-request'],
Do we need to consider a duplicate report in openFDA adverse event database? (like patient and doctor both submitted reports),"
I am trying to search data with the drug name Hydroxychloroquine from the URL here from OpenFDA api
https://api.fda.gov/drug/event.json?search=patient.drug.medicinalproduct:%22hydroxychloroquine%22+AND+receivedate:%5B20200101+TO+20200513%5D&limit=99 [Edited]
There are 2918 relative results, will some results repeat? For example, if a patient and doctor both submitted their own reports independently. Or if multiple doctors were treating the same patient.
Thanks!
","['api', 'openfda']",
Detailed Noise level datasets,"
We are researching adaptive techniques for estimating longer-term soundlevels LAeq_T, from short-term soundlevels LAeq_tau. T is typically T=15minutes, and tau=1 seconds. To validate our approach we are in need of datasets of sufficient resolution.
Therefore we are looking for sound level / noise level datasets with high temporal resolution, that is LAeq at every 10 seconds or more often. The data should cover at least 24 hours in a single location, with multiple days being very advantageous.
Almost all kinds of environment are of interest, for example:

office/workplace
construction
industry/manufacturing
train/metro traffic
road traffic
airplane traffic
community noise. residential/urban
natural scenes / rural

",['audio'],
New financial tweet and news sentiment analysis dataset,"
Are there any datasets that contains financial tweets or news title and their sentiment polarity (negative, neutral, and positive) that is labeled by humans?
The datasets that I find on the internet and mostly kaggle are not labeled by humans (which may have mistakes) or are very old like 2013.
","['data-request', 'social-media', 'sentiment-analysis']",
Regular source for global carbon dioxide in the atmosphere,"
I am looking for a regular (daily, monthly) Level 3 source of present day CO2 in the atmosphere. I have looked through NASA AIRS and NASA GEOS data products and could not find data for 2020. I did find contemporary data through Copernicus, but it is too low resolution to use for a global map of carbon dioxide in the atmosphere, which is the goal.
I also researched the data sets at JPL's CO2 Virtual Science Data Environment and those with global data were outdated, except for the OCO-2 data, but it was too sparse and low resolution on a global level to use for these purposes.
","['data-request', 'global', 'environment']",
FAA Chart Supplement Database [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 3 years ago.







                        Improve this question
                    



Has anyone found while delving into the NASR subscription or the d-TTP databases information on the ELA/SEC boundaries? I am wondering where the chart supplements get their data in the upper right margin of each airport on which sectional and ELA they can be found? The API and ADDS the FAA has seems to be incomplete/under construction. The data seems to be there in the tables, but not human readable and the AIXD viewers are greek to me. Anyone else having better luck at extracting useful information for app design?
","['api', 'database', 'aviation']",
Datasets with pre and post coronavirus data,"
I'm looking for public datasets that have a sort of ""discontinuity"" in them. Ideally, this discontinuity should be Coronavirus, and we should see a change in the distribution of the data after this discontiuity.
Any references would be greatly appreciated!
","['data-request', 'covid19']","It's hard to define ""after"" since we are still in the middle of it. But the discontinuity surely exists between ""before"" and ""during"".I would suggest something global and clean (machine readable), like the Google Mobility Data, which is available as global or regional CSV files.https://www.google.com/covid19/mobility/The data shows how visits to places, such as grocery stores and parks, are changing in each geographic region.https://www.google.com/covid19/mobility/data_documentation.html?hl=en"
Accessing DOL State Unemployment Insurance Weekly Claims Data,"
I would like to access weekly data for unemployment claims through the DOL API (Department of Labor), listed here: https://oui.doleta.gov/unemploy/claims.asp
I'm able to get national data by using the pydol (https://pypi.org/project/pydol) interface but I'm not sure how to get it on the state level.
I appreciate all your help!
","['api', 'labor', 'python', 'odata']",
How Reliable are the Data,"
I am trying to search data with the drug name Hydroxychloroquine from the URL here from OpenFDA API
https://api.fda.gov/drug/event.json?search=patient.drug.medicinalproduct:%22chloroquine%22+AND+receivedate:%5B20200101+TO+20200513%5D&skip=1&limit=2
There are 2918 relative results, but I found that only 2637 (2207 are male, 430 are female, 0 are unknown) patients with 'patientsex' feature. Could I know why does that happen? Will some results repeated or a supplemental of a result that has already existed in the database?
",['openfda'],"Reporting a patient's sex is voluntary, which is why some adverse event records do not have that information."
English to Telugu and Telugu to English dictionary database,"
Data: Database of Telugu to English and vice versa language dictionary
Context: Need to make a Telugu to English and vice versa dictionary app.There should be quite some public domain dictionaries for Telugu language by now. The first one I can think of is C.P.Brown English to Telugu dictionary.
Region: Telugu is an Indian language spoken in Andhra Pradesh and Telangana states.
License: Any license that allows me to redistribute the data in an application. But when it comes to Indian dictionaries the only data that meets the criteria would be public domain since the copy of CC licenses and Open Data is not big in India.
Format: I am okay with Screen scraping as long as the license of the source allows redistribution. But I would want to screen scrape and the distribute it in an offline available manner, not screen scrape live in the end product
Authority: Preferably a database of a dictionary which has been published offline, but not mandatory.
Requirements: Non-image formats and plain text format, preferably in database format
Non-Answers: 
I searched for ""Telugu dictionary"" on the Internet Archive and there are a few dictionaries in scanned format, but many of them were modern dictionaries which were probably uploaded without the copyright holders' consent.
The few of them that were public domain are in image format and the words aren't always clear and the auto OCR didn't OCR the Telugu words and only OCRed the English words. The Telugu words are just gibberish.
","['data-request', 'language', 'india', 'dictionary', 'books']",
Workflow to backup SPARQL Endpoint to Git repository?,"
We want to provide version control to a small sized Virtuoso SPARQL endpoint but the workflow we use is quite cumbersome and always generates huge diffs for blank nodes because they get new IDs every time. 
My question: Is there a more efficient way than the following that also minimizes diffs for blank nodes?

Go to the http://myendpoint/conductor -> Database -> Interactive SQL, and execute dump_one_graph() for all graphs
Get the new dump from the server via scp
Unpack the dump .ttl.gz files.
Convert the dump files to ntriples.
Sort the dump files so that the diffs are minimized.
Replace the files in the repository with the dump files.
View the diff and perform partial commits with appropriate messages.

For steps 3-6, we use the following Python script:
import glob
import gzip
import rdflib
import sys
import os
import re

if(len(sys.argv)<3):
    print(""Usage: virtuoso2git infolder outfolder prefix"")
    sys.exit(1)

infolder = sys.argv[1]
outfolder = sys.argv[2]
prefix = sys.argv[3]
suffix = ""000001""

ttl = infolder+""/""+prefix+""*.ttl""
files = [f for f in [glob.glob(p) for p in [ttl,ttl+"".gz""]] for f in f]

if(len(files)<1):
    print(""No files found in folder"",infolder)
    sys.exit(1)

if not os.path.exists(outfolder):
    os.mkdir(outfolder)

for f in files:
    print(""Read"",f)
    outname = re.search(prefix+r""(.*)""+suffix,f).group(1) + "".nt""
    outpath = outfolder + ""/"" + outname

    if(f.endswith("".gz"")):
        stream = gzip.open(f,""rt"")
    else:
        stream = open(f,""rt"")
    turtle = stream.read()
    g = rdflib.Graph()
    try:
        g.parse(publicID=""/"" ,format=""n3"",data=turtle)
        print(""Write"",outpath)
        g.serialize(destination=outpath,format=""nt"", encoding=None)
        os.system(""sort ""+outpath+"" -o ""+outpath)
    except rdflib.plugins.parsers.notation3.BadSyntax:
        print(""Cannot parse file "",f)
        continue

The script is also hosted at https://github.com/KonradHoeffner/virtuoso2git but with small adjustments for our project.
","['sparql', 'git']",
How reliable is the data from College Scorecard?,"
I'm looking to use the College Scorecard API for an app. However, I had a few questions about it.
How do they collect the data?
How often do they refresh it?
How is it secured?
How reliable is it? / Do they have outages?
What security mechanism do they use?
",['collegescorecard'],
Mapping Between US SIC Code to UK SIC 2007,"
I've been tasked with mapping USA SIC code such as 59990903 - Retail sale of hearing aids, to the UK 2007 equivalent (47741).
However, the only docs I can find online are for USA SIC to NAISC codes translations, or US to the UK but for older editions in the 80s/90s where it seems to be only 4 digits rather than 8.
If there is a resource somewhere for this then you would be a lifesaver!
","['data-request', 'data.gov']",
From where can I obtain 2018 LiDAR Digital Surface Model for Texas?,"
I am looking for a 2018 Lidar DSM (not DEM) for Texas, US. Do you know any source from which I can obtain the data?
","['data-request', 'geospatial', 'usa']","Try OpenTopography.org, they index open LiDAR datasets from around the world (as well as hosting some of their own).Check out their data map to see extent.They show a lot of US national LiDAR datasets over Texas. These are available through the 3DEP program which is hosted on AWS S3. Important here is that AWS Public datasets are often ""requester pays"" for data transfer costs.Also, many may have the original LiDAR data instead of processed DSMs. If that's the case you can always generate your own DSMs using PDAL in Python."
Altitude data for european highways,"
Are there publicly available altitude data for the major european highways? I need the altitudes on the road surface, not in the surrounding area. I believe that the open DEM files (or SRTM data) shows the ""bare earth"" and they are not suitable for my needs. LiDAR data might be a good candidate but I cannot find public data for the whole of Europe
","['geospatial', 'uses-of-open-data', 'europe']",
Looking for dataset for testing address validation for Google maps API,"
So I implemented an address validation using Google maps API and looking for some dataset of valid addresses for testing. I already used Openaddreses data which is great and covers lots of countries, but for some countries ( Like Slovakia, Romania, Portugal, Estonia ) only 3 percent of data had valid addresses. 
I was wondering if anyone here had implemented an address validation before and let me know what kind of data source do you used for testing, I prefer if it's free service but if it's even a paid service, I appreciate it if you can let me know. 
","['data-request', 'postal-code', 'address']",
Where can I find income distribution data?,"
For any/many countries I'd like to find data on income distribution: for every amount of money, how many people earn that much income.
Alternatively, data representing wealth or other similar values would work as well.
Where can I find such data?
","['data-request', 'economics', 'income']",
Getting partial data from department of labor API,"
In trying get data from this API (I have a token..):
https://devtools.dol.gov/APISampler/Home/Index1?datasetName=OUI%20Initial%20Claims
It seems that I'm not getting all the data, the latest year I get is 2016. 
What am I doing wrong? 
def _get(url):
    response = requests.get(url)
    return response.json()

def get_data(url):
    data = _get(url)
    all_data = []
    while True:
        for r in data['d']['results']:
            all_data.append(r)
        next_url = data['d'].get('__next')
        if not next_url:
            break
        data = _get(next_url)
    return all_data

url = ""https://api.dol.gov/V1/Statistics/OUI_InitialClaims/unemploymentInsuranceInitialClaims""
all_data = get_data(url)

","['api', 'labor', 'python']",
Is there any place I can download historical traffic data?,"
Looking for historical traffic data, if possible in a GIS format. Looking for the country of India, if not anything larger. I know that's big but that's the scope of our study, so yeah. Any kind of help would be immensely appreciated.
",['historical'],
Postcodes for roads in London,"
I have asked this on GIS and been referred here
First time asking, couldn't see a starting point to read from. I'm doing a lookup by road name (London) to get the Postcode (first part W1 / WC1H etc), i'm a 1/4 through and it has taken days to do it manually, I really need to find a source where I can get London Road names and their Postcode, (would be better if I can get the A and B road designations) can someone point me to a resource and code I can use to preform a download that will ultimately go into Excel. I don't how to change / understand overpass to even make a start. I don't mind duplicates in the data I can clean that
i.e. STRAND, WC1, A4
","['data-request', 'uk', 'city', 'postal-code']",
Need dataset which contains total number of customers of each mobile tariff plans,"
I want the dataset which contains the total number of customers purchased a particular mobile plan.
","['data-request', 'telecom']",
Wind forecast over land accessible through python API,"
I would like to automatically fetch wind speed forecast data over my town with a python script.
I am looking for an available dataset and API to do so.
It is for a small personal project, so it is not demanding in terms of resolution and accuracy.
So far I have tried the following:

Windy has an API, but it seems to be javascript only.
https://api.windy.com/
I have tried the Copernicus Atmosphere Monitoring Service, but I only found wind speed reanalysis products, and no forecast.
https://ads.atmosphere.copernicus.eu/#!/search?text=&type=dataset
I have tried the Copernicus Climate Data Store, which seems to propose wind speed forecast datasets. But I couldn't download the data through their API, I am getting a ""Resource not found"" error, I have posted a comment on this Github issue:
https://github.com/ecmwf/cdsapi/issues/7
I have tried the European Centre for Medium-Range Weather Forecasts, but there doesn't seem to be wind speed forecast in their public datasets.
https://apps.ecmwf.int/datasets/

Any idea where to look? 
EDIT: 
The Windy point forecast API is accessible through HTTP requests via python, but it's not free of charge. I will investigate the models that they use (listed here: https://api.windy.com/point-forecast/docs)
","['data-request', 'api', 'weather', 'python']",
Seeking data that shows stay at home orders by United States county for COVID-19 crisis,"
I'm looking for GIS data that shows which US counties are issuing ""Stay at Home"" orders all across the US. It would also be helpful if the data included which types of businesses were allowed to be open, and what restrictions are in place (if any). I have found data broken down by state. I cannot find county data. 
Does anyone know where I can find this information? 
This is for a COVID-19 mapping web application. I need to access the data programmatically, so any data in JSON or csv format would be great.
","['geospatial', 'usa', 'covid19']",
How to read *_LOW_HN / *_HIGH_HN fields in NY Street Centerline Data?,"
I've been looking at the NYC Street Centerline (CSCL), in particular number ranges for individual street segments.
Quite a few look like this:
           ST_NAME L_LOW_HN L_HIGH_HN R_LOW_HN R_HIGH_HN
0               28  215-001   215-027  215-000   215-026
1           QUEENS  120-011   120-011        0         0
2               58   51-001    51-099   51-000    51-098
3           FOREST   68-049    68-099   68-050    68-098
4               69  110-001   111-099  110-000   111-098
5              105  107-001   108-099  107-000   108-098
6           BEACON   14-025    14-099   14-024    14-098
7               49  108-001   110-099  108-000   110-098

an I have a trouble to wrap my head around these values.
How do I read for example 08-001 or 14-025? How do these correspond to odd and even numbers?
Can someone explain this on an example?
","['geospatial', 'usa', 'city']",
NGVD 29 undulation layer,"
I am looking for NGVD 1929 undulation layer. So that I can convert my vertical datum from NGVD 1929 to WGS 1984. I was able to get EGM 2008 undulation layer in GeoTiff format. I was hoping to get the same for the NGVD 1929. 
",['geospatial'],
package_search query parameters includes both keywords and tags,"
When I queried a data catalog using GUI
https://data.noaa.gov/dataset/?q=fish&tags=California&sort=score+desc%2C+metadata_modified+desc
it fetched 42 records. 
I wanted to implement the same query through API using package_search function. While I was successful either using keywords or tags alone for my other query cases, I was not successful for this particular one that involved a combination of keywords and tags. 
For example, the query
https://data.noaa.gov/dataset/api/3/action/package_search?q=fish&q=tags:California&rows=1000
is successful, but fetches zero record, unlike the 42 records through search on the GUI (see the first query). 
I have met similar problem with data.gov. 
Any suggestion, where did I make a mistake in the API query?
","['api', 'data.gov', 'ckan']",
Where I can get daily temperature data for each country?,"
I am looking for daily temperature data for each country for each year. I don't need data for all the years but one of the most recent year i.e. 2018 or 019. 
Here is a similar question posted here but it is based on mean data rather than daily temperature data? 
How can I get temperature data for each Country (Annual)
",['data-request'],I think the information provided here: How can I get temperature data for each Country (Annual)proved to be sufficient for my purpose. 
Indian monthly climate data,"
Where can I find Indian district-wise monthly climate data indicators like temperature and humidity, which are open-source?
Also, it would be really helpful if somebody describes the procedure in which the above data can be downloaded.
","['data-request', 'india', 'climate']",
How to collect open data from certain branches?,"
When someone wants to build a database of for example all the groceries in the world or all the pharmacies in the world, how can you get this data.
Of course, someone would offer a database for a lot of money but is there something with Google business or anything like that where you can collect the data yourself?
","['research', 'business']",
Finding GIS data layers in Denmark,"
I am currently working on a university project that focuses on finding most suitable locations and equipping the Hørsholm Kommune with EV charging stations.
I am, however, not from Denmark and my danish group mates have never worked with GIS programs before.
This makes finding suitable data complicated. 
The data I would like to find as .shp file or at least as WFS layer would be:

Municipal boundary layers
Car registry distribution in the Municipality 
Population distribution in the Municipality
Municipal/ public buildings
Attractions/ Points of interests in the Municipality (like the harbor, castles, etc.)
Energy grid lines and capacities 
Parking spaces

I have already looked on multiple websites (https://kortforsyningen.dk, https://gst.dk, https://datafordeler.dk, and https://www.horsholm.dk/om-kommunen/kort-over-kommunen) to find the data. But without great success so far. 
Can anyone who has previously worked with data maps in Denmark show me where to look?
","['data-request', 'geospatial']",
"What are the public biosignals (ECG, etc) or imaging datasets of COVID-19 patients?","
I am looking for public datasets of COVID-19 patients with biosignal information (ECG, for instance) and/or imaging data (X-ray, CT scans). Found some CT scan datasets but with a low number of cases (~50).
Is there any dataset I might be missing?
","['data-request', 'releasing-data', 'covid19']",
historical pandemics and deaths dataset,"
I'm looking for Historical Epidemic & Pandemic Datasets to Analyze the spread of these infectious diseases, deaths, crisis etc.,
","['data-request', 'historical', 'epidemic']",
Dataset: time-series classification in social networks,"
I need a dataset concerning a task in social network time-series classification. Please let me know if you had any ideas.
","['classification', 'network-structure']",
Data help on major employers near private universities in U.S,"
I’m looking to find out which universities are near the regional or national headquarters of employers.
This is for a project to improve hiring opportunities for university graduates.
Would you please direct me to someone in our Department of Education who’s an authority on this?
",['data.gov'],
Where can I find task duration (estimate) data?,"
Scenario
In an endeavour to compare a basic regression with a more advanced Ensemble Network of classifiers, I am looking for (a) data(set) that contains:

Task description
Measured task duration
(Estimated task duration prior to starting task)

Attempts
I have built a scraper that analyzes the taskwarrior data pushed to public githubs, yielding 219607 [tasks- and task edits], of which 61284 unique tasks/task edits, of which 5105 unique tasks, of which 159 contain a start and completion date.
Furthermore I have contacted the authors of the study using a 2.6 million sample task duration database from Cortana and the study using a task database from 1989 consisting of 16000 tasks. The former is a propriatary dataset which I am currently not able to access, the latter has been lost by whom I was able to contact.
Question
Do you have any suggestions on where I can find a (large,5k+) dataset that contains task description and task duration information?

","['data-request', 'machine-learning', 'programming', 'education']",
"How would I acquire a list of correct and uniform contact information for ""important Bitcoin people""?","
I have no money to pay for any lists. I want something like:
Some Guy,someguy@gmail.com,1978,USA,male,CEO,https://binero.com/
Some Gal,somegal@yahoo.com,1995,UK,female,CEO,https://coolcoins.com/
...

Manually trying to first find all major Bitcoin websites and then trying to find out this info, or even just the e-mail part, is a nightmare. I've tried in the past. They actively hide the info. I didn't manage to compile any useful list.
Is there really no centralized place listing contact information and data for ""important people"" or ""key people"" in a given industry/context? I want this for many other things as well, such as ""key players in the retro video game community"", etc.
I must express that I find it maddeningly frustrating that nothing seems to be available in public. I have no ""secret connections"" so I never get access to any such ""secret lists"" and all the good stuff that's kept far away from the public. Sadly, I'm ""the public"". I just visit endless webpages with garbage/outdated/nonsensical data, or (more often than not) are trying to make me pay them money. I don't have money. It has to be possible without already being rich.
",['data-request'],
What is Edm.DateTime? [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 3 years ago.







                        Improve this question
                    



I'm using this dataset which has a 'Week' property. I can see its type is Edm.DateTime, but unfortunately I don't know this type.
How can I convert it convert to a timestamp or date?
Example:

/Date(-94176000000)/
/Date(1478304000000)/

",['labor'],
Datasets residing over the networks (multichannel data),"
Would you please share with me the data sets related to the classification task for the multichannel data or data lies over networks? (other than the data related to the brain applications).
Ideally I would the data to be a feasible application in real world.
","['data-request', 'network-structure']",
County level data on technical training/apprenticeships?,"
Not sure if this is the best place to ask this but has anyone ever worked with county-level data regarding technical training/vocational programs/community college certificates?
I'm looking for some dataset that might have summaries at the county level for any of these things like for example how https://www.doleta.gov/oa/data_statistics2016.cfm offers it at the state level. 
If this is the wrong place to ask please direct me to the social sciences analysis page?
","['data-request', 'education']",
Telecom Services Database,"
Does anyone know where can I find the datasets for Telecom Services like below
Fixed line voice
IP voice services
Internet access services
Ethernet services
Private IP services
Very-high bandwidth services
Legacy data services
Consumer pay TV services
Mobile services
Multiplay service packages
Cloud connectivity services
Low-power wide area

Any resources/references would be highly appreciated.
","['data-request', 'api', 'telecom']",
Are there any datasets on related scientific articles?,"
Are there any datasets on related scholarly/scientific articles? For instance, a dataset where a specific medical article is related to a ranked list of similar/related medical articles?
",['text'],
Badminton dataset,"
I am looking for Badminton data set. Olympics record or badminton world federation record will be good or any data related to badminton sport should be fine. If anybody have or can provide , it will be great help!!
",['sports'],Here are a few that I found on web :
NDC - SETID Mapping,"
I am interested in connecting the NDC data (brand_name, labeler etc.) to the FDA Label data (SET_ID). However, I'm struggling to find a dataset that would contain the mapping between the NDC code and the SET ID. Is there a crosswalk connecting the two?
",['openfda'],
Where can I find Sentinel L1C images (.SAFE) from 2015-2019 now that they are not available anymore on the Copernicus Open Access Hub?,"
I am looking for Sentinel images from before 2019 in L1C quality and .SAFE format, as I want to correct them with sen2cor in SNAP to convert them to L2A quality. Where can I find them now that they are offline & not available on the Copernicus Open Access Hub? The Hub took them offline, and they are currently not requestable. USGS Earthexplorer and Google Earth Engine only provide TIFFs and JPEGs. So far I have only acquired JSONs from Amazon Web Services (connected to Sentinel Hub), but learning Python might make me able to acquire .SAFEs .. 
Details: I am making a monthly NDVI timeseries from december 2015 - 2020 of my research location in Bolivia. I use Sentinel 2 L2A images for this, and Google Earth Engine. Because there are no L2A images before 2019 I will have to process L1C images myself and upload them to GEE.
Cheers
","['geospatial', 'climate']",
Where can I find wind speed and direction data for Pakistan?,"
I'm trying to link wind speed and direction to fire events from the NASA website.
Does anyone know where I can find such data?
Does anyone have any experience doing something like this?
","['data-request', 'weather', 'climate', 'asia', 'remote-sensing']",
Looking for datasets with hypothesized distributions,"
I have a question, for my bachelor's thesis I wrote a program that classifies what kind of distribution a QQ resembles most, I trained the model using synthetic data: I created the QQ plots by using the built in functions in R e.g. qqnorm(rnorm(100)) etc. I would like to test the model using real world data in order to do this I have to know what the hypothesized distribution of the data is and label the QQ plots accordingly. I am looking for datasets that may have the following distributions: normal, student t, gamma, chisq, uniform, poisson, binomial.
If you think that there's a different way to evaluate my model please let me now!
",['data-request'],
Looking for weekly death data by State/County/City,"
I'm looking for up to date weekly death rates in first the US (ideally EU and East Asia sources would be great too) that is tracked at a city/county level (implying state level as well). Something like EuroMOMO but the actual datasets.
","['data-request', 'geospatial', 'usa', 'europe']",
Looking for average economic impact of all Farmlands per acre in Florida or U.S,"
I am researching on road alignment optimization. The research goal is to find least cost road alignment between two given points, considering highway codes. One of major factors which I want to consider, is impact of alignment on economy. To present my methodology in a case study, I need actual geospatial data on economic impact of every farm or numeric data on average economic impact of all farmlands per acre in Florida or U.S, however data for Florida would be more accurate in my case. Do you have any recommendations?
","['geospatial', 'usa', 'economics', 'agriculture', 'cost']",
Where can I find major appliance failure data?,"
I am looking for data which gives details about when a major appliance like refrigerator, dishwasher, washing machine, TV failed and what was the cause. Further, details like 

When the product was purchased
When it failed 
Daily usage
If a repair was attempted 
How many repairs in past
Repair resolution

","['usa', 'machine-learning']",
Dataset for Telecom Mobile Tariff Plans,"
Does anyone know where can I find the dataset for Telecom Mobile plans preferably for Indian telecom service providers?
I need a detailed dataset where there are details of each attribute of tariff.
","['data-request', 'telecom']",
to which extend we can use the data of healthsite.io - can we use maps etc. too?,"
to which extend we can use the data of healthsite.io 
update:: well i guess that it is evident: 
since the data in Healthsites.io are indeed under the ODBL licence: https://github.com/healthsites/healthsites/wiki/Data
one can therefore indeed reuse the data he keeps the same licence and attribution.
in othher words: healthsites.io uses OpenStreet Map data and per ODbL,  every one is free to use this data in whatever way so far as he does attribute OpenStreetMap Contributors.  we can find out about OSM copyright here https://www.openstreetmap.org/copyright
Healthsites.io is a very interesting project which takes the collaboratively gathered data to a new level The latest project features along with cutting-edge use cases.
question:  To which extend i can use the data of healthsites.io - can i use the maps too?
can we use the data-extracts and the Maps too!? 
are they released under the: Open Data License (ODBL)
https://wiki.openstreetmap.org/wiki/Global_Healthsites_Mapping_Project
https://github.com/healthsites/healthsites/wiki/healthsites.io-license 

guess: Since the data is released under Open Data License (ODBL), have a look at the TLDR Legal for ODBL. 
that said: it seems like  we can use the data since it indeed fits the conditions of the license.
gueess that we can use:

Data extracts per country are available on Healthsites.io, which can be found by going to the map page and browsing the country list on the left panel. Clicking on the name of any country listed will show a dashboard for that country which includes a link for downloading the associated data as a shapefile.
can we use the data-extracts and the Maps too!? 

","['geospatial', 'openstreetmap', 'python']","Great question! The data license is the same as the ODbL of OpenStreetMap.﻿## ODC Open Database License (ODbL)The Open Database License (ODbL) is a license agreement intended to
allow users to freely share, modify, and use this Database while
maintaining this same freedom for others. Many databases are covered by
copyright, and therefore this document licenses these rights. Some
jurisdictions, mainly in the European Union, have specific rights that
cover databases, and so the ODbL addresses these rights, too. Finally,
the ODbL is also an agreement in contract for users of this Database to
act in certain ways in return for accessing this Database.https://healthsites.io/map"
Identifying State Parks in the PAD-US dataset (Protected Areas Database),"
I'm looking to map ""State Parks,"" and I found this phenomenal, but complex database. Has anyone ever worked with the PAD datasets before? (or know any easier way to map State Parks?) 
In the PAD download there are several included shapefiles, including: fee, easement, marine, proclamation, and designation. It sounds like there is overlap in the datasets. So far my best guess is to use the fee shapefile, filtering on access='open access' and designation='state historic or cultural areas' or 'state park' or 'state recreation area'. But I'm just not 100% sure if I've gotten everything this way. The total number of features returned is 8,065, which is close to the number noted at stateparks.org (8,565 for FY 2017), but it's still 500 features short. When I add in designation='state other or unknown' it brings the total up to 8,447. Although I suppose this number could have (and likely did) go down since the latest release of the data. Still, it would be nice to know the exact query I should be using. 
PAD-US Main Page
https://www.usgs.gov/news/mapping-public-lands-united-states
Data Download*
https://www.usgs.gov/core-science-systems/science-analytics-and-synthesis/gap/science/pad-us-data-download?qt-science_center_objects=0#qt-science_center_objects
*I downloaded the ""national shapefile""
I'm aware of all the following helpful documentation already:
Data Structure and Attributes 
http://www.protectedlands.net/pad-us-data-structure-attributes/
Metadata XML
https://data.usgs.gov/metadata/Science_Analytics_and_Synthesis/5b030c7ae4b0da30c1c1d6de.xml
PAD-US Data Manual:
https://www.usgs.gov/core-science-systems/science-analytics-and-synthesis/gap/pad-us-data-manual
Disclaimer:
“Any use of PAD-US data for showing recreational lands must be careful to show only those lands that have fee ownership and designations that are appropriate to recreational use – the PAD-US ‘Access’ attribute is a key tool for these applications, defining what is Open, Restricted/Permitted, and Closed for public access.”
Citation
U.S. Geological Survey (USGS) Gap Analysis Project (GAP), 2018, Protected Areas Database of the United States (PAD-US): U.S. Geological Survey data release, https://doi.org/10.5066/P955KPLE.
","['geospatial', 'usa', 'usgs']","I work on the USGS Protected Areas Database of the United States (PAD-US) as a cooperator from Boise State University. The queries you used make sense, although I would include the ""Designation"" feature class, as this feature class may include state parks and similar designations that overlap Fee owned areas. I would also exclude the public access query since some state parks and recreation areas may have access restrictions (such as seasonal closures, etc.).There may still be a slight difference in the number of state parks and similar areas than other databases, as we receive state data directly from state and nonprofit partners. Some state data is more up-to-date than others and we are continuing to improve data quality with each update. You can look at the ""GIS Source Date"" attribute to see how old the data is. Our nonprofit partner GreenInfo Network also has detailed information on data partners, which includes completeness estimates: http://www.protectedlands.net/data-stewards/. I also recommend reviewing their PAD-US help system, which includes detailed information on the different feature classes, FAQs, etc.: http://www.protectedlands.net/help/. Please feel free to contact me (my email is in my profile) if you have additional questions. It would also be great to hear how you are using PAD-US in your research/project."
US Wifi Hotspots,"
Looking for US Wifi open geospatial data; I read through all of the wifi tagged questions including database of wifi hotspots but feels like this is unique enough and could use some refreshing.
Here's a Google Doc of community effort so far and the tweet behind this question.
I'll add the content from the Google Doc with any answers received here.
Inspired by this map of Wifi in Virginia
","['geospatial', 'usa']",
Logistics data sources for data analysis work,"
Where can I find logistics data sets?
I look for data for my student to analyse in a bachelor thesis.
","['geospatial', 'transportation', 'public-transport']",
Locating a public data set to teach analysis of RDS data?,"
Respondent driven sampling (RDS) is a method for producing representative samples in hidden populations (e.g. IV drug users in societies with taboos around drug use), tiny populations (e.g., transgender individuals who make up a minute fraction of a general population), or populations for which there is no ready sample frame (e.g., people who almost always cook meals at home), from chains of referral into study participation, and incorporating information about chain length, referral numbers, and social network position to weight each participant's contribution to an unbiased estimate of characteristics of the target population.
Are there any publicaly available data sets introducing (1) the structure of RDS data, and (2) the analysis of RDS data? My interest is pedagogical, and for the training of doctoral level applied researchers.
References
Heckathorn, D. D. (1997). Respondent-Driven Sampling: A New Approach to the Study of Hidden Populations. Social Problems, 44(2), 174–199.
Gile, K. J., & Handcock, M. S. (2010). Respondent-Driven Sampling: An Assessment Of Current Methodology. Sociological Methodology, 40(1), 285–327.
",['data-request'],
Is there a dataset for object colors?,"
This dataset would be something like {""sheep"": [(""white"", ""95%""), (""black"", ""5%"")]}, since sheep are usually white, but sometimes black. Does such a dataset exist? 
",['data-request'],
Yelp Academic Dataset,"
I heard about the Yelp Dataset, I did not download it yet, I just need to know if the reviews about a specific service on this dataset are identified by the unique id of the person who wrote the review?
","['medical', 'machine-learning']",
Seven segment Scoreboard single digit dataset,"
I'm looking for a dataset with seven segment scoreboard display digits since I want to train a neural network to classify such digits. Right now I'm trying to create my own dataset but it would be a nice shortcut if I could use an already existing one. I've found some dataset with seven segment digits from LCD display's from calculators and such, but that's not what I want. I'm looking for single digits in seven segment font from e.g ice hockey or soccer scoreboards.
",['data-request'],
I am looking for data on election polling locations and more specifically how many people showed up to cast a vote,"
With the current debate of mail-in voting vs in-person voting, I want to get a handle on how feasible doing in-person voting would be if adhering to social distancing guidelines. help.
I couldn't find any datasets that would contain that information and wondered if anyone here in this group might help.
","['elections', 'polling']",
What's the best small dataset to train a Recurrent Neural Network?,"
I work on a neural network library in C++ and I'm in the process of implementing recurrent neural networks.
I run my tests on a GitHub server on different datasets, Iris and Wine for simple unit tests, MNIST and Fashion MNIST for test the MLP, CIFAR-10 for test the CNN and I looking for some new dataset to train the RNN that I implement.
Do you have any idea of small datasets to train my RNN?
I'm looking for one or two small datasets that are easy to integrate into my tests in my continuous delivery process. About 30 seconds for 1 epoch with more than 70-80% accuracy would be ideal.
PS: I know I can use MNIST to simulate temporal data but having a ""real"" dataset would be better and more diversified.
",['machine-learning'],
Using data on healthsites.io for small project,"
healthsite gathers data for open and complete approach to creating a global health facility data set by  leveraging the power of OpenStreetMap
question: in corona - pandemic times, can we takt the data for a little service site that maps the hospitals that are available for the public health.  in other words: can we access and get the dataset from healthsites.io to work on the set of  data to publish it to serve the folks in a. italy, or b. barbados or c. Senegal!? - with a little online-map project that makes use of the maps and data -we obtain form healthsites.io!? is this doable!?
answer: i guess so - since the data is under the Open Data Licence:  (see Open data collaboration https://healthsites.io/ Through collaborations with users, trusted partners and OpenStreetMap we will capture and validate the location and contact details of every facility and make this data freely available under an Open Data License (ODBL) )
is this correct - can we use the datase of healthsiters.io for a little (private) online project that serves the people in a. Senegal or b. Barbados. or c somewhere else!?
what do you thikn - can we do a little project with the dataset of helathisites.io
what if i want to work on the data of the set eg on Barbados or Italy.:

https://healthsites.io/map?country=Barbados
https://healthsites.io/map?country=Italy
https://healthsites.io/map?country=france

","['medical', 'uses-of-open-data', 'open-definition']","Since the data is released under Open Data License (ODBL), have a look at the  TLDR Legal for ODBL. From your description, it seems like your use of the data indeed fits the conditions of the license."
How to License Research Data,"
What are the Licensing concepts and attributes to be considered before releasing the data?
How to the license data?
","['uses-of-open-data', 'licensing']",
What Determines if a Drug appears on OpenFDA or Not?,"
I'm attempting to use OpenFDA to query a drug's package NDC and return information like manufacturer, brand name, and route.
I have the following query working, but noticed (during testing) I get no results for the 3rd below (Botox).  Is Botox intentionally omitted?  Am I doing something incorrect.  If I remove the exact match, and search, I do get results, but none appear to be for Botox (it finds other partial matches on the manufacturer segment of the NDC, etc.)
https://api.fda.gov/drug/label.json?search=openfda.package_ndc.exact:62332-464-31
https://api.fda.gov/drug/label.json?search=openfda.package_ndc.exact:0378-9320-32
https://api.fda.gov/drug/label.json?search=openfda.package_ndc.exact:0023-1145-01
Thanks
",['openfda'],"OpenFDA section is optional and is not guaranteed to be present for each drug label. 
In this case, there was some sort of matching error in the harmonization process, so no harmonized data was provided for that particular set_id.https://api.fda.gov/drug/label.json?search=set_id:485d9b71-6881-42c5-a620-a4360c7192abwe'll investigate further when we have new SPL data so that we can see what exactly is causing this matching error.
About the drug labeling overview please check here.
https://open.fda.gov/apis/drug/label/ "
Vehicle safety dataset,"
I’m working on an assignment for school about vehicle safety and I’ve found some useful summary statistics about traffic accident data in general but I’m specifically looking for studies into the effectiveness of driver assist technologies in reducing accident/fatality rates.
A dataset showing the following would be useful

type of cars involved in accidents 
driver assist / not
outcome of incident - injury/fatality

Even if you could just point me in the direction of a place where I can find detailed studies that would be much appreciated! :)
",['data-request'],"UK Road Safety: Traffic Accidents and VehiclesDetailed dataset of road accidents and involved vehicles in the UK (2005-2017)The dataset comprises of two csv files:Aggressive Driving DataAggressive driving can have a very bad outcome.Motor Vehicle Safety DataThe dataset contains information on the motor vehicle fatalities on U.S. roads with number of fatalities, crashes, number of injured persons and miles covered by vehicles. National Transportation Statistics presents statistics on the U.S. transportation system, including its physical components, safety record, economic performance, the human and natural environment, and national security. Transportation's safety record, giving data on accidents, crashes, fatalities, and injuries for each transportation mode and hazardous materials. Compiled and published by the U.S. Department of Transportation's Bureau of Transportation Statistics (BTS), National Transportation Statistics presents information on the U.S. transportation system, including its physical components, safety record, economic performance, energy use, and environmental impacts.BUREAU OF TRANSPORTATION STATISTICS(BTS)U.S. Department of Transportation"
Dataset for a Healthcare RecSys,"
i want dataset that contains ratings and/or reviews of doctors/Physicians by their patients, both doctors and patients must be identified by unique ID.. Is there any public dataset i can use for my Final Year Project?
","['medical', 'machine-learning']",
Brand personality and social media preference data,"
Where can I find a data set which predicts brand personality (Anbang 2016) from the social media data preferences e.g. Twitter
I'm planning to improve on the methods of the above paper.
","['data-request', 'machine-learning', 'social-media']",
Datex-II: malformed OpenLR?,"
My reading of Datex-II (as of version 2.3) is that OpenLR locations are specified roughly like this for linear features:
…
<SituationRecord …>
  <!-- description of the event here -->
  <groupOfLocations xsi:type=""Linear"">
    <linearExtension>
      <openlrExtendedLinear>
        <firstDirection>
          <!-- location reference points here -->
        </firstDirection>
        <oppositeDirection> <!-- where applicable -->
          <!-- location reference points here -->
        </oppositeDirection>
      </openlrExtendedLinear>
      …

Indeed I have seen Datex-II situation publications structured like this, and JAXB parses them nicely into the class scheme I generated from the XSD.
Now I am seeing feeds which have <openlrLineLocationReference> instead of <firstDirection>. Since the XSD appears to make no mention of that, JAXB ignores the <openlrLineLocationReference> element and the OpenlrExtendedLinear instance it returns contains no data (it has two members, firstDirection and oppositeDirection, both of which are null).
Is that incorrect data, or have I missed some part of the specs? (I see Datex-II 3.0 is out by now, but parsing the XSDs with JAXB failed—has this part of OpenLR been updated?)
",['data-format'],
Global sea/ocean polygons (with names),"
I am looking for a global dataset with the extent of seas and ocean in a vector dataset of polygons. I know that boundaries are sometimes fuzzy (maybe crisp boundaries don't really exist in some case), but I can manage this uncertainty. If I could have an attribute with the names it would be even better. 
The aim is to reuse this dataset in a research project where we would start by checking that sample coordinate are consistent (does the attribute of the sample match with the name of the sea/ocean in the map). Therefore we need polygons and not only lines or names. 
","['geospatial', 'creative-commons', 'oceanographic']","Take a look at Marineregions.org, specifically look under IHO Sea Areas. These are boundaries of oceans and seas as defined by the International Hyrdographic Association. When you go to download it you'll be prompted to supply a name and email address, but the site is non-profit and run by a marine institute in Belgium.I went ahead and downloaded it to take a look and think it will suit your needs. There are about 100 polygons that represent all the oceans and major seas. If you just wanted the oceans, you could add an extra column to the attribute table, invent an ocean ID, assign each sea to the closest ocean, and then dissolve / merge them using that attribute.My first thought was Natural Earth, but its primary ocean layer isn't broken up into polygons; the ranking layer is, but the shapes don't correspond to the actual oceans."
Applications or Datasets with massive number of time series,"
There are many applications which deal with multiple time series data such as stock market, climate change, etc. It seems most of them are dealing with a few number of streams up to 1000 series in real time. For example, I checked applications whose time series data sets are mentioned here, but they are not as large as I want. I am wondering if there is an application which requires to monitor tens of thousands streams in real time. It would be also good if it has a public data set of the series in a specific period.
","['data-request', 'time-series']",
Dataset for NLP Text Summarization,"
Looking for a dataset for NLP Text Summarization consisting of 

articles and their headlines
long news articles
summaries of articles
sentences extracted from user reviews on a given topic
interviews
long Conversations

Any of the above text database
","['data-request', 'nlp']",Kaggle is a great place to start. Here's one: https://www.kaggle.com/sunnysai12345/news-summary
Database of Motor Vehicles?,"
Is there a database of the Motor Vehicles that were built until now, containing the 

Model
Size
Weight
Price
Year of release
Power.
Model engine
Engine Capacity
Position of the engine.
Engine displacement.
Maximum engine speed.
Torque.
Fuel system.
Turbine
and optionally any other specifications

It does not need to contain the data of [almost] all the Motor Vehicles, but at least the representative sample.
Motor Vehicles registered in all countries or just registered in any one particular country is also fine.
","['data-request', 'transportation']","The datasets of motor vehicles are available in different formats, but it wouldn't be easy to find vehicles dataset, including all of these details. You can no doubt find these details in the form of distinct files from Kaggle or find all vehicle models, manufacturer, manufacturing years and other details related to models from this dataset https://www.back4app.com/database/back4app/car-make-model-dataset. This source allows fetching data into a variety of frameworks including PHP, Java, Python etc.However, to know about fuel, torque, maximum engine capacity, you would have to combine different files for web scraping. Or you can consider this reliable source https://www.teoalida.com/cardatabase/car-models-engines-dimensions/ but keep in mind, you can only find vehicles till 2016 here."
Where can we find a list of hazardous substance codes used in OSHA violation data?,"
We're trying to figure out how to make meaningful the responses in ""hazsub1"" through ""hazsub5"" in OSHA violation data. you can see the list of variables here
https://developer.dol.gov/health-and-safety/dol-osha-enforcement/
but for the life of us we can't figure out what 4-digit alphanumeric list of hazards the results corresponds to. Please help!
",['labor'],
European vehicle info based on licence plate,"
I'd like to be able to create a service such as regcheck.org.uk (getting vehicle info from licence plates), however, I'm unable to find any clue as to where their data comes from. Any chance of getting such data? For Europe, specifically.
","['europe', 'cars']",
Where can I find a dataset of voice phishing attacks? Or scam phone call logs?,"
I am conducting researches into a voice phishing attacks/scam phone call detection system using machine learning. However, I am facing difficulties finding an open dataset of voice phishing or phone calls logs I could work with.
Please, can anyone guide me to any related dataset? Or even suggestions on how to create such a dataset and deal with voice phishing?
Any opinions are welcome.
","['data-request', 'machine-learning', 'finance', 'audio', 'bank']","I think you are referring to voice spoofing, which can be part of the phishing process. In the context of voice, the term spoofing is more common in literature. Spoofing/ phishing can take various forms either by using a replayed audio (if only a password is required for example) or an advanced voice synthesis/cloning system etc. Therefore the datasets can differ in their structure depending on the research specifications. The following are some datasets used in anti-spoofing research: "
Data about drugs/medicine and outcomes,"
I'm am looking for some datasets that contain data about a specific disease - any disease (preferably with several known treatments). I need such datasets, that contain information about the patients, the treatment/medicine that they received, and the treatment's outcome. I've tried to look everywhere, but couldn't find anything.
","['data-request', 'medical', 'disease', 'covid19']",
public Normally-distributed data for teaching intro Stats,"
Background:
I'm teaching an intro course to stats, and this term, I have decided to use real-world public data sets to demonstrate the methods on, instead of synthetic data. I was surprised that I wouldn't find basic data such as height/weight/IQ of men and women (which are famously well-approximated by Gaussian). I do find parameters (mean/variance of weight of Americans, for example), but I don't want to synthesize a Gaussian based on parameters. Rather, I'm looking for actual data, so the students experience the noisy-ness of real data, and how approximations work. I have the same problem for finding non-Normal data, e.g., wealth distribution and other heavy-tailed ones. Parameters exist but I cannot find actual data sets.
TLDR:
For an introductory Stats course, I'm looking for publicly available data sets with medium-size sample sizes, i.e., $N=O(10^3)$ or $O(10^4)$. Preferably, with close-to-Gaussian distributions, but anything is useful. 
","['data-request', 'education']",
SPARQL to get Wikidata items that have no P18 image but have a Commons image depicting them?,"
Many Commons images depict Wikidata concepts.
How to find these concepts, in particular those that do not have an image (P18) property?
The request should output the URIs of both the Wikidata item and the depicting Commons image(s).
","['wikidata', 'sparql', 'wikimedia-commons']",
European Football Datasets PAST and Current Season,"
I've been trying to find player stats datasets but couldn't find one that includes goals scored, assists, etc. Does anybody know any site that provides such data for free or If I could get the last 20-30 years of European leagues data with match scores and also who scored in that game, something like this:
Barca 2 - 1 Sevilla

[Messi'70,Suarez'80 : Navas'23]

Something like this would be Awesome!! .... There are some that provide match scores like this but do not list the player names that scored in the match.
I want data to not only have names of scorers but also detailed info like possession stats, HT score, cards received, shots on target, saves and other stats. Even if you know datasets like this of just 5-6 years. please do mention.
Your little help will mean a lot to me.
","['data-request', 'sports', 'football']",
"Variables from NSLDS/Treasury that have been answered for all years, except the most recent two years?","
Does this mean they are no longer being provided, or that they are not ready to be included yet? 
Example: (HI_INC_COMP_ORIG_YR8_RT)
",['collegescorecard'],
Data on road traffic in Germany [duplicate],"







This question already has answers here:
                                
                            




Data of vehicle traffic

                                (3 answers)
                            

Closed 2 years ago.



I'm looking for road traffic data (e.g. average road traffic by day) or congestion data for German cities or other spatial units (e.g. a certain road or highway).  What would be important to me is, that there is some differentiation by time and spatial units (e.g. by day, week, month in city x or at road y). I'm not interested in highly aggregated figures such as annual averages. Ideally, I would look for (more or less live) data from traffic counts at some fixed points over time.
I know that there are automated counting stations operated by BASt, but I can only find data up to 2018 (and in not very useful format). There is also hourly information by road, but again only until 2018 as of today.
There also is an old question in the forum (from 2016) with a similar topic, but the answer is outdated.
Can anyone point me to some resources?
","['germany', 'traffic']",
Missing ACS Variables,"
Looks like a range of ACS variables regarding housing are missing for the ACS:
B06013_001E
BO6013_002E
BO6013_003E
BO6013_004E
and others in this group as well. 
What is one to do when they are missing? Contact the census? Look for updated variable names somewhere? Heres code to reproduce the problem:
import requests
import pandas as pd

HOST, dataset = ""https://api.census.gov/data"", ""acs/acs1""

get_vars = ['B06013_001E']
get_vars = [""NAME""] + get_vars

print(get_vars)

predicates = {}
predicates[""get""] = "","".join(get_vars)
predicates[""for""] = [""state:37"",""county:37183""]

print(predicates)

for year in range(2005, 2018):
    try:
        base_url = ""/"".join([HOST, str(year), dataset])
        r = requests.get(base_url, params=predicates)
        df = pd.DataFrame(columns=r.json()[0], data=r.json()[1:])
    except ValueError:
        print('decoding JSON has failed')

","['api', 'us-census', 'python', 'north-america']","While the Census modifies them as little as possible, the variable IDs in the ACS do change over time, as certain crosstabs can be dropped, others are added, and new variables are included. It's even possible that an ID can remain the same but the value associated with it can slightly change; for example categories that represent a range of dollar values may be adjusted over time to increase the range of a top-coded value, not frequently but possibly once within a ten year time frame. With each ACS release they document what has changed since the previous one. For example, here are changes to the 1-year ACS in 2018. In the API documentation, each iteration of a dataset is going to contain a description of that dataset, with links to geographies, variables, and examples. Here's a link to the 1-year 2018 series.If you want to pull the variable list into your script, you can build up dictionaries of variables over time and determine how consistent they are and if / when they change. To grab the variables for one year, you can do something like this:In choosing your tables, it's probably best to start with the present and work your way back. There were more changes in the early years of the ACS relative to later years."
repository of pretrained neural translation models,"
I'm looking for pretrained neural translation models, preferably for pytorch or tensorflow.
Pretrained models should be well documented. Ideally, the training should be reproducable with both data and hyperparameters being available.
Models should be reasonably easy to deploy (assuming you have knowledge in pytorch or tensorflow).
So far I've found:

fairseq, based on pytorch. As of April 2020 it is still under active development. Many pretrained models are available: https://github.com/pytorch/fairseq/tree/master/examples/translation
tensor2tensor, based on tensorflow 1. As of April 2020, it is recommended to use the successor trax. Some pretrained models are available: https://github.com/tensorflow/tensor2tensor
trax, based on tensorflow 2(?). As of April 2020, pretrained models don't seem to be available: https://github.com/tensorflow/tensor2tensor

While there are some pretrained models in these repositories, they seem to be mostly research projects.
As such, there are only pretrained models for a few select languages (which are used for competitive benchmarking).
I'm looking for an integrated collection of translation models across languages.
Unfortunately, I don't think that such a ressource exists. Maybe we can start collecting language pairs here. But please only answer if your pretrained model will be available for a long time (hosting needs to be secure) and if it is reproducible.
","['machine-learning', 'nlp', 'translation']",There are pretrained models available for currently 1472 language pairs: http://opus.nlpl.eu/Opus-MT/You also can ask multisource for a new language pair.Greetings from the translation space
How to Format API Requests to Loop through All Tracts in a County,"
I wrote this code to get specific ACS data for a set of years for all the tracts in Wake County (id 37187) in the state of North Carolina. I've read the census example of how to format the code to get it for certain counties, but haven't been able to figure that out with this implementation. What do I need to put in my predicates[""for""] variable to do this?
import requests
import pandas as pd

HOST, dataset = ""https://api.census.gov/data"", ""acs/acs1""

get_vars = ['B25045_001E', 'B25045_001M']
get_vars = [""NAME""] + get_vars

print(get_vars)

predicates = {}
predicates[""get""] = "","".join(get_vars)
#not sure how to add to this
predicates[""for""] = ""state:37""

# initialize data from collector

dfs = []
columns = [""ID"", ""Estimate"", ""Estimate_moe"", ""ID"", ""Year"", ""RMOE""]
for year in range(2011, 2018):
    base_url = ""/"".join([HOST, str(year), dataset])
    r = requests.get(base_url, params=predicates)
    df = pd.DataFrame(columns=r.json()[0], data=r.json()[1:])
    # add column to hold year value
    df[""year""] = year
    df['B25045_001M'] = df['B25045_001M'].astype(int)
    df['B25045_001E'] = df['B25045_001E'].astype(int)

    df[""RMOE""] = 100 * df['B25045_001M'] / df['B25045_001E']
    dfs.append(df)


nc = pd.concat(dfs)
print(nc.head)

","['data-request', 'api', 'us-census', 'python']","This is the code that ended up working for me. Also, see https://api.census.gov/data/2017/acs/acs5/examples.html for a large list of formatting examples. "
UK food nutrition data,"
I am building a small project based on building recipes and tracking nutrition. I want to be able to get correct data for foods that you can normally buy in shops in the UK by using the barcode. I am currently using Open Food Facts but I found that some of the data is incorrect or missing. Is there a better source that I could use?
Thanks
","['uk', 'food']",
Basic information about UK supermarket products,"
I am developing an application where a user will scan a barcode of a UK supermarket product. The application will then need to look up:

The manufacturer of the item
The product name
The package quantity

The only absolutely required of these is the product name, but the others would be helpful.
I have tried the Open Product Data and various other similar services, but none of them have records of the supermarket own-label products, only branded ones. I need to be able to look up supermarket own-branded products as well.
","['data-request', 'food']",
Dataset of real addresses?,"
I am searching for addresses with following components: postal code, contry, city, street name, house number.
Where I can get such a dataset. I need only 100 row in a csv file.
",['address'],You can try in Kaggle datasets. For example https://www.kaggle.com/openaddresses/openaddresses-europe contains the list of addresses in Europe per country.
GIS Data: French Colonial Cercles,"
Cercles and districts were administrative units in French colonial Africa. I am looking for GIS data on their boundaries. Hints on where to find adequate digitizable historic maps on those administrative regions are also welcome.
","['data-request', 'geospatial', 'historical', 'africa', 'france']",
Getting approach procedures and plates from FAA NASR data,"
I'm building a website that shows all important data for a given airport, navaid, etc, similar in content to this one and am trying to find the best way to get the data, starting with FAA data. 
I've found a number of sources for different parts of the data on different FAA websites, but I think the 28 Day NASR Subscription is the datasource I should be using. So, this brings me to three questions:

Is the NASR the best official source of the data I need?
I see DPs, ILSs, and arrivals, but where are other types of approaches, RNAV, VOR, etc. 
Is there any relationship between the data in NASR and the approach plates, airport diagrams, etc. the FAA creates?

For clarity, I want general airport information (name, location, etc.), and links to FAA approach plates, airport diagrams, etc. for that airport, but, I want this website to be usable for navigation, so I'll need to be able to know when data is expired/active, etc. as well.  
","['data-request', 'government', 'transportation']",
Corporate CSR expenditure by firm,"
Does anyone know whether there is a dataset containing annual CSR expenditures by major international companies? 
I'm aware of the Prowess dataset, which provides this info for Indian firms. However, I'm looking for a dataset that covers major international companies, i.e., those listed on US exchanges. 
",['companies'],
"Where can I find a time series dataset on patient waiting lists for hospitals (or, some other healthcare related time series dataset)?","
I found some on data.world which is a set of data from a conglomerate of hospitals in Ireland. However, this set is not useful to me because it is split between many hospitals for only a period of twelve months. There are many records but the time lags are too few (only twelve). I need a dataset of at least about 200 time observations, where each record is an observation at some time T, with each time interval being identical.
",['time-series'],
Movie data set with demographic information of users,"
I am doing movie popularity prediction using Long Short Term Memory networks model.
I am testing with MovieLens dataset with 100K and 1M ratings, which include demographic information of users. Below are the links of two datasets:
MovieLens 100K: https://grouplens.org/datasets/movielens/100k/
MovieLens 1M: https://grouplens.org/datasets/movielens/1m/
I am doing with these datasets because I would like to leverage demographic information of users (e.g., age, gender) for my model.
However, these datasets just collected data within a short period of time. Specifically, for the first dataset, it was collected during the seven-month period from September 19th, 1997 through April 22nd, 1998. For the second one, from 2000-2003, but almost data gathered in the first year.
Therefore any other movie datasets with user demographic information collected in a longer period of time will be appreciated. Thank you very much for your help.
","['demographics', 'film']",
Queensland Australia Hospital and Health Service Boundaries Covid-19 Database,"
I'm searching for a database (or spreadsheet) containing the number of Covid-19 cases for every Hospital and Health Service boundaries in Queensland, Australia. That is, the cases in Queensland Australia for each HHS Boundary.
The Queensland Government already issues the current breakdown for each Hospital and Health Service Boundary, but these are current cases. Further, there are daily media releases, such as this one,  which break down the Covid-19 cases per region. It would be possible to scour the media releases one by one, and create my own database. However, I was hoping someone has done that already. Especially since the media releases are not in a consistent format, particularly the early ones.
I would ultimately like to create a map showing the growth of Covid-19 in Queensland, Australia. I already have the HHS boundaries which I downloaded here. I just need the Covid-19 data to link with it.
","['medical', 'australia', 'covid19']",
Seeking rayon (district) level administrative boundaries for North Caucasus Federal District (Russia),"
I am doing a research project in which I need accurate rayon (district) level administrative boundaries for the North Caucasus Federal District of Russia (shapefile or geodatabase). Among other sites I have checked HDX, Natural Earth, DIVA-GIS, and GADM.
HDX unfortunately does not have admin boundaries for Russia. Natural Earth has admin boundaries, but they do not have subdivisions for Russia. The DIVA-GIS files are based on GADM. Other gis.stackexchange posts on Russian admin boundaries have suggested GADM or DIVA-GIS as a source (https://gis.stackexchange.com/questions/220160/map-of-russias-administrative-divisions) or specific republic map sources. 
So I ended up using GADM without issues until now. However, when attempting to match 2010 census data to rayons I found that there are missing some rayons and have a few major cities on the wrong side of borders.
For example, their map of the subdivisions of Karachay-Cherkess Republic is missing 2 rayons (Abazinsky and Nogaysky) which were created in 2006 and 2007 respectively.
Republic of Ingushetia had Dzheyrakhsky rayon missing which was created all the way back in 1993.
Another example: They have the Chechnen Republic with 12 rayon, but it should have 3 more: https://gadm.org/maps/RUS/chechnya_2.html
Does anyone know of a more accurate source for rayon level admin boundaries for the 7 Federal Subjects that make up the North Caucasus Federal District? Or for Russia in general?
","['data-request', 'geospatial', 'county', 'russia', 'district']",
"Need CSV data set with normally distributed column variable, to compare to known mean (requirements)","
I have literally been searching for such a dataset for two days. And I am going NUTS over this. I hope this type of question is welcome here.
I have an assignment that requires that I do a one-sample t-test on a normally distributed variable (generally known to be a normal distribution, with a reference), comparing that to a known/published mean. I need to provide links to the expectation of normality, the dataset, and the expected mean.
Other than that, it can be anything. Three links required.
Sounds simple.  Uhg.
I would go to the store and weigh 30 pears if the assignment allowed me to do that. And I would have been done with the entire assignment within 1 hour.
",['data-request'],
State Area for 2010 Census AREALAND variable not found,"
I was following this tutorial for requesting from the 2010 Decennial Census. It specifies the following code for printing a list of state names (""NAME""), state areas (""AREALAND""), and state total populations (""P001001""):
import requests


HOST = ""https://api.census.gov/data""
year = ""2010""
dataset = ""dec/sf1""


base_url = ""/"".join([HOST, year, dataset])

predicates = {}


get_vars = [""NAME"", ""AREALAND"", ""P001001""]

predicates[""get""] = "","".join(get_vars)


predicates[""for""] = ""state:*""

col_names = [""name"", ""total_pop"", ""state""]
r = requests.get(base_url, params = predicates)

print (r.text)

When I run the code I get the following error:
error: error: unknown variable 'AREALAND'
Looking at the 2010 Decennial Census Variable List I don't see 'AREALAND' listed. Has the API been changed since the tutorial was made, or am I making some other kind of error? The tutorial was published to YouTube on March 4th, 2020.
","['api', 'us-census', 'python']",
ECDC/PHE covid data clash,"
12 April's new daily confirmed cases for UK seem to be dramatically different: 

ECDC says 8719 (https://ourworldindata.org/grapher/daily-cases-covid-19?country=GBR), while 
PHE says 84279-78991=5288 (https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_the_United_Kingdom#Timeline).

Now, I know that there could be something different in the definition of ""new cases"" or in the way they are measured. 
What is exactly the difference due to?
Also, ECDC's data is quite alarming because it's a dramatic jump looking at ECDC's same data for the past days: should I be worried?
","['medical', 'covid19']",
"Data of covid-19 test per day, per country","
Similarly to a recent question on lockdowns, wonder if there is a machine-readable dataset of covid-19 testing per country/state/region. Testing rate largely affects the official number of infected, and thus of apparent fatality (Case Fatality Ratio). This data would be needed to explain mortality differences between region/nations.
","['data-request', 'medical', 'covid19']",OurWorldInDate site (that has excellent coverage of data around the pandemic) has asked the question two weeks agohttps://ourworldindata.org/covid-testingand now provide an answer:https://github.com/owid/covid-19-data/tree/master/public/data/testing
Can anyone recommend a comprehensive site to find Building Shapefiles for Sydney and its suburbs?,"
I am looking for a more comprehensive site for Building Shapefiles for Sydney and its surrounding suburbs which I can upload into QGIS. I have already downloaded the shapefiles from Geofabrik (https://download.geofabrik.de/australia-oceania.html) however there are chunks of areas missing (as seen from my attached image). Any help would be really appreciated.

","['geospatial', 'australia', 'buildings']",
Looking for land value data for anywhere in North America especially for Florida,"
I am researching on road alignment optimization. The research goal is to find least cost road alignment between two given points, considering highway codes. One of the major costs which needs to be considered, is right-of-way cost. To present the methodology in a case study, i need actual land value data or estimated land value or average land value for different land categories. Data for Florida have higher priority than anywhere else for me, since i have other needed data for my research for Florida. Any recommendation or introducing nongeospatial data could be helpful too.
","['data-request', 'geospatial', 'land', 'north-america']",Parcel data in the state of Florida is typically open and available.  Assessed values can be used but this isn't actual home values or cost of land for ROW.  That's a very different thing.1) https://www.fgdl.org2) https://geodata.myflorida.com/datasets/parcels-1
Performance data by school district (or by High School) in the US?,"
I am ideally looking for data that would give me performance by public school district (or by high school) in the united states, for example:

Average SAT / ACT Scores
Other national test scores (e.g. for elementary school students - does this exist?)
Graduation rates
% of students continuing to college
Number AP classes taken

I am also interested in secondary but related information

Demographics
Test scores by demographic
Student to teacher ratio
Average per pupil spending
Average teacher salary
Percent of students getting lunch assistance
School safety (e.g. gun safety) data
Size of school
Program information (e.g. band, debate, mathletes, etc.)

Where can I find some (or all!) of this data? 
","['usa', 'government', 'us-census', 'education']",
Seeking US Border Patrol Sectors shapefile,"
I am trying to find a shapefile containing the boundaries of the different border patrol sectors as shown here.
I have searched the US BP website and other sources/databases extensively. There are plenty of maps depiciting their border patrol sectors online (journalist sites even use them for mapping), so it's gotta be somewhere. Does anyone have any ideas?
","['data-request', 'geospatial', 'usa', 'data.gov']",
Harvesting Bulk Metadata from ArXiv and querying by date,"
Recently I've found the need to query a large amount of data from ArXiv for a project I'm working on. In particular, I want to retrieve metadata according to a time query (say starting 2015 to 2016). I've looked into two ways to handle this the ArXiv API (https://arxiv.org/help/api/index) and OAI-PMH (https://arxiv.org/help/oa/index). I don't think the ArXiv API is the way to go since they suggest using OAI-PMH for large a large amount of data. Eventually, I want to store the dates and some metadata in a list, I've used python to do this:
from datetime import date, datetime

URL = 'http://export.arxiv.org/oai2'
sickle = Sickle(URL)
records = records = sickle.ListRecords(
             **{'metadataPrefix': 'oai_dc',
             'from': '2015-01-01',
             'until': '2020-04-04',
             'ignore_deleted':False
            })

date_list, author_length_list, subject = [], [], []
for i, record in enumerate(records):
    print(record.header.datestamp, record.metadata['date'])


The problem I'm having is the data gets queried by the regular datestamp and NOT the earliest datestamp. This is highlighted by my print statement where I get 2015-05-13 for the datestamp (as it is queried properly) but 2007-03-31 for the actual date. Is there any way to query by the earliest datestamp instead of just regular datestamp? 
This may be relevant:
https://academia.stackexchange.com/questions/38969/getting-a-dump-of-arxiv-metadata I tried using metha-sync but it only allows for one day of data harvesting which doesn't work here ): 
","['data-request', 'metadata', 'download', 'search-engine']",So I sort of figured out the answer to my own question though there might be a better way to go about it. The earliest datestamp is not queryable (as far as I know) but since the most recent datestamp is queryable you should at least query by that. So then at the very least old entries which haven't been updated will get filtered out. Then you can get the actual date from the metadata and use a simple if statement to check if it is in our bounds. The reason for the time.sleep(50) part is so that we don't overload the ArXiv servers!
Benoa bay length?,"
Since indonesia spatial data infrastructure is terrible, how can I know the length in kilometre of Benoa bay of Bali island, Indonesia?
I tried to googled it and shockingly I didn't get any information about it.
",['data-request'],
windmill dataset in the Netherlands,"
Since the Netherlands is famous with the windmill, how come I can't find the spatial dataset of it? I tried to look at :
https://www.pdok.nl/
https://data.overheid.nl/
https://data.amsterdam.nl/
https://utrecht.dataplatform.nl/
http://rotterdamopendata.nl/
https://denhaag.dataplatform.nl/

Anyone knows where can I find it?
","['data-request', 'geospatial', 'europe']","Why not use OpenStreetMap data? You can use the man_made=windmill tagA traditional windmill, historically used to mill grain with wind power. This Overpass Turbo link will give you all windmills in the Netherlands. Note that this will include a fair amount of insignificant tiny windmills used to hose water from a canal in a polder, not the typical ""picture post-card"" type big ones that you can enter and may even have living quarters. Most of these can be detected by a ""name"" or ""description"" tag of ""Poldermolen"", but there is no guarantee this is accurate.Overpass Turbo query link for windmills in the Netherlandsscreenshot of sample results: "
National Congressional Districts vector tileset,"
Is there a vector tile set available online somewhere of US national congressional districts? I have been downloading shapefiles from the US Census bureau's shapefile repository, converting these to json with mapshaper.org and then converting to tile sets with MapTiler desktop. It would be way simpler to just find an existing prebuilt protobuf file online. It is generic data, so just figuring it may exist somewhere. Where should I look? No luck with a simple Google search.
","['data-request', 'geospatial', 'usa']",
Converting Wikipedia URL to Wikipedia Page ID,"
I've linked phrases in texts to entities in Wikipedia:
Going over the bridge, coming from Aliante Casino, you cant miss the nice 
view of the href=""http://en.wikipedia.org/wiki/Waterfall"">waterfall</a> 
that is at the forefron

Now, I would like to get raw text of each linked Wikipedia page. Since the number of Wikipedia pages to process is around 20k, I would like to perform the process offline.
I've downloaded latest Wikipedia dump in XML and extracted raw test using Wikiextractor, here's one line from it:
{
    ""id"": ""54551"", 
    ""url"": ""https://en.wikipedia.org/wiki?curid=54551"", 
    ""title"": ""Preston Tucker"", 
    ""text"": ""Preston Tucker\n\nPreston Thomas Tucker (September 21, 1903 – December 26, 1956) was an American automobile entrepreneur....""
}

It looks like Wikipedia dump used Wikipedia page IDs instead of URLS:
http://en.wikipedia.org/wiki/Waterfall
https://en.wikipedia.org/wiki?curid=54551

How can I convert from one to another?
",['wikipedia'],
Financial Corpus,"
I'll be delving into text mining applications for my master thesis and I need data for it. Ideally, I would need a corpora of texts/news articles from some single (or multiple) credible and authoritative source covering financial markets/economy and the like, spanning a time period as long as possible.
Does anyone know of datasets/corporas that would suit my requirements?
Any other possibilities/ideas to construct one such dataset using open resources?
I know this question has been already asked but the answers that were posted are not longer valid.
","['data-request', 'finance', 'corpora', 'stock']",
Known datasets for long document analysis,"
Are there good baselines datasets or benchmarks for similarities/retrieval of long texts (extremely long documents, books, etc.)? Although significant both academically and applicational, I cannot get a hold of any significant dataset nor remarkable papers from the last AAA conferences.
Daily Mail, CNN or IMDB reviews are too short for me.
Pairwise Multi-Class Document Classification for Semantic Relations between Wikipedia Articles(2020)
or
Graph Convolutional Networks for Text Classification(2018)
For example, state to work on long text, but only use the first paragraph of the article.
My direction would probably be Wikipedia or Arvix datasets, but I would be happy to hear your experience or to find a relevant baseline to compete against.
","['data-request', 'nlp', 'wikipedia', 'text', 'books']",
MAUDE data frontend vs API,"
I am trying to use the openfda API to get a view of the data in the front end.
This is an example of a front-end search:
https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfMAUDE/detail.cfm?mdrfoi__id=2094110&pc=OCE
mdr_report_key: 2094110
this is the API query I'm trying:
https://api.fda.gov/device/event.json?search=mdr_report_key:%222094110%22&limit=30
Examples of data that is missing from the API:

Frontend - Brand Name: EPICEL (CULTURED EPIDERMAL AUTOGRAFTS) GRAFT

Frontend - Device Sequence Number : 1

Frontend - 1 Device Was Involved in the Event


Essentially any device or report data (description of the event, I believe normally under mdr_text:[]) is missing from the search and does not seem to show up in the API query, even though it's the same mdr_report_key.
It looks like the front end joins together ""Followups"" to the ""Initial Report"" data. I was wondering how this is being joined on and how I can combine the data into something that makes sense? Should I ignore all Report_type: ""follow up"" records?
","['api', 'openfda']",
What measure can I use for rank order comparison of most-common n-grams in two sets of data?,"
I have a real dataset of sequences of events and a ""fake"" dataset generated using an lstm model. The two datasets are made up of the same vocabulary but are of a different length. I'm putting together an evaluation script to assess how similar the two datasets are, and one of the metrics should be a comparison of the ranking of the top 500 most frequent n-grams in the real data and the fake data. Seeing as the top 500 most frequent n-grams in the real data might be different to the ones in the fake data, I don't know what ranking measure to use that would give me a clear idea of how similar the two datasets are. Does anyone know of a measure that would allow for such a difference? I need one which treats the real dataset as the gold truth and compares it to the fake dataset. 
Any help would be much appreciated. 
",['nlp'],
English Dictionary with Syntax Classifications Download,"
I'm looking for an english dictionary with english words' meaning but also with grammar classifications e.g. Hi (exclamation).
","['english', 'classification', 'dictionary', 'ai', 'categories']",
1945 (spring) daily weather Germany,"
Perhaps understandably, I am having difficulty tracking down daily weather data for Germany in early 1945.
My specific interest is in daily temps and any other daily weather observations for January through March 1945, particularly for the area of Bonn or Cologne -- although I would be grateful even if such data were only available for Berlin.  My greatest interest is in the first three weeks of March 1945.
","['data-request', 'weather', 'historical', 'germany']",
Machine readable Community Mobility Reports during COVID-19 control measures,"
Google is providing PDF reports for regions to understand how mobility and crowding has changed during the Coronavirus pandemic.
https://www.google.com/covid19/mobility/
Each country/region has a PDF with sub-regions. For example, Switzerland: (PDF) https://www.gstatic.com/covid19/mobility/2020-03-29_CH_Mobility_Report_en.pdf
Where can I find this data that is easily machine readable?

","['data-request', 'covid19']","(my own repo) https://github.com/philshem/scrape_covid19_mobility_reports(more details)direct links to data (two formats, same info):CSV: https://raw.githubusercontent.com/philshem/scrape_covid19_mobility_reports/master/data/mobility_reports.csvJSON: https://raw.githubusercontent.com/philshem/scrape_covid19_mobility_reports/master/data/mobility_reports.jsonTableau Public dashboard (filter on country)https://github.com/nacnudus/google-location-coronavirusConvert the PDF files to SVG format, and extract the trend lines.Extract text from the PDF.Pair up the text with the trends.Code: https://github.com/kylemcdonald/covid-mobility-dataData: https://github.com/kylemcdonald/covid-mobility-data/releases/tag/2020-03-29Details: https://twitter.com/kcimc/status/1246505356471107585https://github.com/patrikpolyak/google_covid19_community_mobility_reports_datavery cool fetching script for all PDFs: https://github.com/patrikpolyak/google_covid19_community_mobility_reports_data/blob/master/fetch_pdfs.sh"
How to download Road map dataset of previous 20years,"
I want to download the Road map dataset of the previous 20years. How can I find the data and access that? I prefer Google Road map data.
",['geospatial'],
Is COVID-19 *projection* data publicly available?,"
I'm making a geographic visualization of some important COVID-19 data in the US (confirmed cases and deaths, mainly.) I've been asked to include projections for the future, and I'd prefer it if they were from real, epidemiological sources. Googling around, though, I can only find relatively high-level reports on these projections (like the PDF of the famed Imperial College study.)
Ideally, I'd like some of the raw projection numbers underlying these studies, with as much geographic granularity as possible (I recognize there's a sacrifice of precision as the model granularity increases, but I'm happy to accept it if I can find the data.)
","['medical', 'covid19']","IMHE (Institute for Health Metrics and Evaluation, University of Washington) is one resource providing COVID-19 projection data. Seems to be US States only.https://covid19.healthdata.org/projectionsCOVID-19 projections assuming full social distancing through May 2020As the pandemic progresses, we are working to incorporate new data about the virus in the US.Get the data: http://www.healthdata.org/covid/data-downloads"
Need a dataset for automobile insurance fraud,"
i need to apply deep learning to detect automobile insurance fraud.
Are there any data sets available?
",['data-request'],
Where can I find every international flight in the world of late?,"
With COVID-19 grounding mostinternational flights, the list is surely short, especially if restricted to long-haul flights. While https://www.flightradar24.com/blog/charting-the-decline-in-air-traffic-caused-by-covid-19/, the site doesn't seem to have details of the sort I'd like. OpenFlights seems to be even less useful for this purpose.
If I want a list of city pairs for the US, https://thepointsguy.com/news/april-long-haul-routes-american-delta-hawaiian-united-airlines/ largely suffices for April, though I'd have to search those city pairs to get details.
I am especially interested in a list for each day, or at least each week.
","['transportation', 'covid19']",
UAV dataset for machine learning,"
I am writing my master thesis about Unmanned Aerial Vehicles and the sensor-camera data. It will be used for navigation and obstacle avoidance. Does anybody know any sources that I can download some sample uav data with Radar, Lidar, proximity, accelerometer, gyroscope, etc... sensors that would be useful for prediction of the next action such as turn right, move up. My aim is to analyise the input sensor and video data to predict the next move.
","['data-request', 'machine-learning', 'video', 'sensors']",
Datasource with global cities/towns/villages with Englisch names and coordinates,"
In almost ever GIS project there is the need to map nearby cities and towns, often also small villages in rural areas.
Open Street Map (OSM) offers a lot of spatially explicit data including ""places"" containing the names of urban areas mapped in OSM. Unfortunately, not all places also have English names and a popular download site (Geofabrik) does not support the download of English Names. 
I would like to know if there is another free alternative that can be used and shows a high level of detail also regarding smaller settlements and which has coordinates or already comes in a GIS format (such as Shapefiles or geodatabase). 
","['geospatial', 'global']","One option would be the GEOnet Names Server published by the US National Geospatial-Intelligence Agency. It is a gazetteer of global place names that includes a variety of spellings in different languages, including the common English variants, plus longitude and latitude coordinates. It includes administrative divisions, cities and towns, concentrated settlements, and even physical / non-populated features. It's quite detailed. The interface can be a little tough to use, but you also have the option of simply downloading all place names for a particular country in a CSV file.For some reason I'm not able to access it today without getting some warning about a security certificate being expired. Normally you can access it here: http://geonames.nga.mil/gns/html/index.htmlOne quirk is that it does not include the United States or any US territories. A comparable source for these areas would be the Geographic Names Information Server published by the USGS: http://geonames.usgs.gov/apex/f?p=gnispqI wrote a post a while back that summarizes the differences between GEOnet and Geonames gazetteers if you want to see that for more details (Geonames is a crowdsourced alternative, also includes name variants, English spellings, and coordinates).For shapefiles for global mapping I often refer people to Natural Earth. Its cultural vector layers collection includes features for populated places, cities and towns, as well as boundaries for countries, internal subdivisions, and physical features."
Datasets for Fake news (Not Tweets and Facebook Posts),"
Can you please tell me where can I find good pre-labeled datasets with real and fake news, but not tweets and facebook posts? 
I found 4-5 on Kaggle, but I read that those are not real news (those are not real articles). I have also looked UCI ML Repository but those datasets are similar. 
Basically I need dataset that has 3 columns, ""title/headline"", ""text / paragraph text"" and ""label (true of fake)"". 
Label does not need to be boolean, it can be more than 2 values, but dataset needs to be labeled.
Also, I do not want twitter and facebook posts, im interested in news articles.
Can you tell me other websites where I can find datasets like this?
Can you share some links where I can download such a thing?
","['data-request', 'releasing-data', 'news']",
API for German Air Quality Data,"
The German „Environmental Protection Agency“ (Umweltbundesamt) provides air quality data for Germany on its webpage and it is also possible to download data as CSV. However, as far as I know, there is no option to programmatically download these data, e.g. via an API. Does anyone know about a source for German air quality data which can be accessed programmatically, e.g via an API?

","['api', 'germany', 'environment']","Although it's not documented, when clicking on a link for a CSV, I noticed that you can use the endpoint as your own API.So if we deconstruct the URL, we can create filters to pass to the web server, which will return a CSV. That's an API.To programmatically access this API, you would have your code pass variables to the endpoint and collect the results.I also noticed that you can replace csv with json in the URL to get a JSON responseTo get the metadata:The file that is returned Luftqualitaet_DERP020_Trier-Ostallee_2020-03-25_00-2020-04-01_06.csv contains some basic metadata in the filename.To get an actual file of metadata, To get the metadata, I had to go to the Network view of ""Developer Tools""https://www.umweltbundesamt.de/daten/luft/luftdaten/stationenThe URL of the JSON metadata seems to be:https://www.umweltbundesamt.de/api/air_data/v2/meta/json?use=measure&date_from=2020-01-01&time_from=1&date_to=2020-12-31&time_to=24&lang=de"
Whole word entity search on Wikidata,"
Wikidata wbsearchentities service seems perform prefix-based matching, e.g. searching for novel matches as expected:

novel : narrative text, normally of a substantial length and in the form of prose describing a fictional and sequential story

but for instance also:

novelist : writer of novels
Novellara : Italian comune

The documentation doesn't specify any special syntax for the search parameter: do we have a simple way of forcing whole-word matching?
","['wikidata', 'wikibase']",
Seeking dataset containing clutter layer of Mumbai,"
Where can I find the complete clutter data of Mumbai?
The clutter should contain information related to buildings,roads and water bodies.
","['data-request', 'india']",
"Data source(s) for deaths per day per country, or just for Germany","
I'm interested in analysing the number of COVID-19 deaths reported daily for each country against the total number of deaths daily for the same countries.
There's currently plenty available for COVID-19 related deaths, but for deaths in general I can only find per year.
I'm particularly interested in data for Germany to analyse whether they might be classifying deaths by proximate cause rather than ultimate cause, which would explain the extremely low number of deaths by COVID there compared to their very high number of infections and compared to most other countries.
But even apart from the German data, it would be of interest especially to help illustrate the seriousness of the current situation to skeptics who still don't take COVID-19 seriously.
","['data-request', 'medical', 'covid19']",
Where do I find the complete data of a completed football match,"
I am looking for a complete data of a match with the players.
Like who scored the goal and assisted it is available but what about

how many shots a player attempted
how many passes a player completed
positions of a player 
how many tackles a player made 
how many goals a GK saved, etc

","['data-request', 'sports', 'football']",
Where can I find website analytics logs for research?,"
I am doing some research into some machine learning algorithms that can be used to analyze website logs.
A friend gave me access to his Google Analytics, but all I see are reports and I am not able to see the actual logs. If I am not mistaken, google has put a high price on access to these logs (over 100K per year).
I am looking for open logs which record website events: UserId, TimeStamp, BrowserDetails, LocationDetails etc. Very close to Apache access logs, but with richer instrumentation to say more about each event.
Are there any website logs that are open and freely downloadable for research purposes.
","['data-request', 'machine-learning', 'internet']",
1940 US Census - indexed data?,"
I read a fascinating article about the census in the US, and especially the 1940 census, which is available online (since the 72 year period has elapsed).
I was able to search based on address (and cross streets), but was wondering if anything else has been indexed. For example, people's names.
There is some info about funded projects in 2012 to digitize the data (one : two : three), but I haven't found any portal or available dataset.

Art credit from the New Yorker article linked above. Artist: Tim Peacock
","['usa', 'us-census', 'census', 'demographics']",
API Access to OSHA Establishment Search,"
I have a use case where I need to be able to make an API request to retrieve inspection data for a given establishment. This is the page I can use to retrieve the data manually: https://www.osha.gov/pls/imis/establishment.html . I have not been able to find a relevant request in the API docs. Can someone point me in the right direction?
",['labor'],
COVID-19 Clinical Data or Statistics,"
Is there anywhere a database that includes case-level information on COVID-19 cases?
Such data would typically include patient demographics and/or health information, location, time of onset/testing, and case outcomes. 
Even data from one (or several) specific locations would be most helpful.
This question refers to case-level data. For aggregate data, see this question (COVID19 - Corona Virus data). 
","['data-request', 'medical', 'covid19']",
"USGS 3DEP DEM, what is an AWS ""Staged Product""? Can I access ""Staged Product"" data over S3?","
The United States Geological Survey (USGS) has available as part of the 3D Elevation Program (3DEP) a 1-arcsecond Digital Elevation Model (DEM) of the conterminous United States (CONUS) — see 3DEP DEM.
The data link points to Amazon AWS where data can be downloaded freely and anonymously, but this appears to not be an AWS bucket but rather a HTTPS index labelled ""Staged Products Directory"".  When searching the Registry of Open Data on AWS directly, I can only find the related but different USGS 3DEP LiDAR product, which is not available freely and anonymously but published as a ""requester pays"" bucket.
What is an AWS ""staged product""?  Are those USGS 3DEP DEM 1-arcminute data available through the AWS S3 interface freely and anonymously, or only through the https interface?  Are those ""staged products"" https links even permanent?  The https link is very slow; downloading one file, I only got a throughput of 190 KB/s, over three minutes to download a single 35 MiB file.
","['geospatial', 'api', 'data.gov', 'usgs']",
"While running ckan container, memory is increasing rapidly mainly because of `ckan_default` process","
While I'm running Ckan container, memory is increasing rapidly mainly because of ckan_default process. Is there any way to limit the  memory for ckan_default process? If yes, where it should be defined or at which location that setting is present? 
Or how can I limit the memory?
",['ckan'],
Consumer expenditure survey about food consumption,"
I'm confused about the data source about food consumption from the consumer expenditure survey. I find the survey data from the CES website, https://www.bls.gov/cex/pumd_data.htm#sas.
",['survey'],
"Demographics, particulary age distribution in Wuhan and Hubei province","
Are demographic data, specifically age distribution available for Wuhan and the Chinese Hubei province?
I would like to know if the age distribution is somewhat comparable with other urban areas across the globe. 
In particular I suspect that if migrant workers from surrounding rural areas  left their child in the care of grandparents, coupled with the one-child policy, the proportion of children would be smaller then in comparable urban areas elsewhere.
","['demographics', 'population', 'china', 'covid19']",
Seeking dinosaur data,"
Is there any open data concerning dinosaur discoveries? I am particularly interested in plotting them on a map, and showing date when clicked/showing all discoveries of a certain type/in a certain time period, from a certain era, etc
",['dinosaurs'],"The Paleobiology Database is a Creative Commons database that seeks to ""provide global, collection-based occurrence and taxonomic data for organisms of all geological ages.""  The data can be downloaded in CSV/JSON/RIS, viewed interactively with the PBDB Navigator, and accessed programmatically via the API of the PBDB Data Service "
data on maintenance costs in EPC sector,"
I have to do a PoC on PowerBI for predictive maintenance (both for unscheduled and scheduled maintenance).  
I saw this article about fluor and am looking for open data that would allow to discover similar insights : https://www.nsenergybusiness.com/news/fluor-to-deploy-ibm-watson-for-predictive-analytics-capability-for-epc-projects/
Do you happen to know any EPC (O&G, roads, tunnel, bridges, etc) 'asset management'/ ""maintenance cost' dataset  ? Alternatively, it could be also facility management. 
I came across a lot ""predictive maintenance"" dataset for manufacturing. It is mostly about fault fetection. Here we are more looking into maintenance cost, rather that ""fault detection"".
I don't know at all the EPC business, so any suggestion would be more than welcome!
",['uses-of-open-data'],
What is an effective way to share many geojsons that are a timeseries?,"
I currently have a long-running scrape that collects geojson data for Zürich bike-sharing. Each file is appended with a timestamp of when it was collected. The file structure doesn't change.
What's the best way to share multiple geojsons (timeseries)?
The data once packaged should be publicly available, but as individual files it's becoming cumbersome. 

Some options I've considered

(current solution) One big folder in git, with individual files

(good) Can be viewed on the map
(bad) Needs to be downloaded all together as zip or git pull/clone

One big file with individual rows per geojson? e.g. jsonlines http://jsonlines.org/ (always updating)

(good) Easy to parse
(bad) Many versions of the same file will exist

Individual zips, based on time range? (no updates to historical files)

(good) easy to understand and access
(bad) takes time to package files


—-
Update: 
Related question, but not a useful answer: https://gis.stackexchange.com/q/131920/112869
","['geospatial', 'releasing-data', 'json']",
Where to get the USA bill of lading datasets,"
I need the US import bill of lading datasets. I know that it's free but I only find data vendors, like import genius.
Where can I download or buy the RAW datasets without vendors? Directly from the US CBP?
",['data.gov'],
Why are some tract geometries duplicated in census data?,"
I have been writing a Python program to analyze the contents of shapefiles from the 2010 U.S. census, and I came across some odd duplication that I cannot explain. For example, in the 2010 shapefile data that describes census tracts in the state of Texas, shapeRecord(546) part 0 has a list of geographic points of a polygon that are identical to shapeRecord(547) part 1. These records correspond to geo ID 48159950200, Census Tract 9502 Franklin County, TX and geo ID 48159950100, Census Tract 9501, Franklin County, TX, respectively. This seems to suggest that the first part of census tract 9502 geographically overlaps with the second part of census tract 9501, and the corresponding population data shows that they have different populations.
Has anyone studying census shapefiles encountered such anomalies, and do they know what it means? Is it possible that the census counts the population of the same geographic area by different means and then assigns part of the population to one tract and a different part of the population to another tract?
","['geospatial', 'us-census']",
Review Helpfulness Datasets,"
My team is looking for a user review dataset which we can compare to one of these Amazon datasets
The dataset needs to include text reviews and a review helpfulness rating.
I know this is a long shot, but if anyone knows of a dataset we could use then that would be great!
",['data-request'],
Population in adminstrative units (ADM-1) of the world,"
Is there a compiled dataset of all administrative units (ADM-1) of the world with population data?
I know that https://www.geonames.org/ has the raw data, I am looking for a pre-compiled dataset
",['population'],
"Real-time vehicle fleet position data, United Kingdom","
I am a software developer. I want to advertise that I can build vehicle tracking apps. To that end, I will place a live demo on my web page.
I am looking for an API which I can query every 5 seconds or so to get the current positions of vehicles and update the map in real-time.
I want something UK based, preferably in London, but that's not a deal breaker; nation-wide would not hurt (and I may even be able to think of a few extra features for it).
I could use the London Underground or buses, I suppose. But if I am trying to market fleet tracking capabilities,  might it not be better to use an actual fleet? E.g DHL or something like that? Or, am I just overthinking it and is ""data moving on the map""  enough?
I would prefer something with data 24/7, so that people looking from other time zones won't see an empty map in the middle of the night. Taxis? Pizza delivery? Police cars would be great, but I doubt if they make their data public ;-) Hmm, maybe ambulances or fire engines?
In terms of requests to the API, maybe every 5 seconds, possibly every second, but I don't want a messy map, so maybe 5 or 10 vehicles (max 20 if UK wide). The API must, of course, be free for commercial use.
So, which imaginative API can you recommend me? Real-time  not recorded, data please.
","['api', 'transportation', 'location']",
Where can i get an API of all oil & gas wells in America?,"
I am looking for an API for oil and gas wells, including their name and location. I know each state has has this data for download but is there an API out there?
I know of some but they are at least $3,000+. Is there any that are reasonably price ones?
","['data-request', 'usa', 'api']",
English tenses exercises database (with answers),"
Where can I find english tenses database to add them into my learning app
",['english'],
What are common datasets used for collaboration recommendations?,"
I look for datasets that I can use for collaboration recommendation (i.e. co-authorship prediction). In other words, the dataset includes details related to authors and their publications.
I am wondering if there are any public datasets in this task or any state-of-the-art datasets? If so, what are they?
I am happy to provide more details if needed.
","['data-request', 'uses-of-open-data']",
Where can I find dislocated worker program participation data by US county?,"
Where can I find U.S. displaced worker data, particularly during the Great Recession? I found sets from 1995 to 2008 and 2015 to recent. However, I'm having trouble finding data for 2008-2014, particularly data at the county level. I would really like to see participation in dislocated worker programs by county. Does it exist? Any suggestions?
","['usa', 'government', 'education', 'labor', 'longitudinal']",The U.S. Census Bureau's Current Population Survey Displaced Worker Supplement contains this data. There exists biennial data from 1984 to 2018 on IPUMS CPS.
"Where can accurate information on the release dates of all video game consoles, peripherals and games were released be grabbed?","
I've long wanted to compile a private ""timeline"" consisting of various video game consoles, peripherals and games which I want to remember and quickly be able to look up when they were released. I also would like to see sales figures for these ""releases"".
Currently, I use Wikipedia, MobyGames, GameFAQs and VGChartz to manually check these things. It's extremely tiresome in the long run since I very often want to quickly check when this or that video game for SNES was released in Europe, or in the USA, or in Japan. Or how many copies it sold. Or what the exact spelling was for this or that console, and which day it was released in the PAL region. Or see them in relation to other games I care about, which I would only be able to do if I had complete data to construct my ""timeline view"".
Is there such a public, coherent database with reliable information in a sane format? For example, CSV or JSON.
The sites I've mentioned (except for Wikipedia) do not provide their information in any kind of parsable format, and actively block scraper bots. MobyGames has an ""API"" page which just tells you to contact them and beg for access, which I'm not interested in.
I'm looking for some resource which provides a list such as .../game_releases.csv:
""official full title"",""popular title"",""platform"",""publisher"",""EU release"",""AU release"",""US release"",""JP release""
""DOOM II: Hell on Earth"",""DOOM 2"",""PC"",""id Software"",1994-05-05"",""1994-05-05"",""1994-05-05"",""1994-05-05""
""Donkey Kong Country"",""DKC"",""SNES"",""Rare"",""1994-05-05"",""1994-05-05"",""1994-05-05"",,
...

And then ones called game_console_releases.csv and peripheral_releases.csv. Or maybe all combined into one.
To make it clear: I'm trying to find such a source from which to create my own local database of this data so that I can freely construct my timeline in the way I want it, with accurate and reliable data which I don't have to manually look up.
I'm mostly interested in this data for stuff released before the year 2000, since that's roughly when I feel video games died, but of course it doesn't hurt if it has fresh information as well!
","['data-request', 'database', 'json', 'csv', 'games']",
Where can I find hospital data on respiratory illness cases?,"
I'm looking to collect as much data as possible on respiratory illness cases as a proxy for presumptive positive COVID cases. Where can I find this data? 
",['medical'],
Dictionary of European Languages,"
I'm looking for a database that contains translations of words in different European languages (mainly Romance). The most important languages for my project are in order Latin, English, Spanish and French.
Here is an example of a format that would suit me perfectly.
lat;eng;esp;fra,...
domus,domo;house;casa;maison;...

","['data-request', 'language', 'dictionary']",
Where and how can I get dataset of patient narratives on the internet to predict diseases?,"
My aim is to create a trained model for predicting diseases. I need data set consisting of the following fields:

Causes of the Disease
Pathogenesis (the mechanism by which the disease progresses)
Age
Gender
Symptoms of the Disease
Damage caused by the Disease
Organ Type (e.g. Heart Disease, Liver Disease, etc.)

",['releasing-data'],
Dataset on coronavirus government countermeasures (per country/region/city?),"
I am looking for a machine readable dataset of what country has enacted what form of lockdown on what date, and possibly the ""type"" of lockdown (international travel/national and international travel, restaurants, schools, public offices etc.).

Note: See this question for aggregate case counts
","['data-request', 'medical', 'government', 'covid19']","There are now some fairly complete and up to date such datasets. 
An Oxford University group - Future of Humanity Institute - has gathered these data:https://storage.googleapis.com/static-covid/Containment%20measures/COVID-19%20containment%20measures.zipAlmost simultaneously, a different department, the Blavatnik School of Government from the same institution, has published a somewhat different take on the same data:https://www.bsg.ox.ac.uk/research/research-projects/oxford-covid-19-government-response-trackerBoth datasets are meant to be kept up to date. And of course there is the already mentioned dataset above by the Assessment Capacities Project (ACAPS), an independent information provider:https://data.humdata.org/dataset/acaps-covid19-government-measures-dataset"
COVID-19 Clinical Data or Statistics,"
Is there anywhere a database that includes case-level information on COVID-19 cases?
Such data would typically include patient demographics and/or health information, location, time of onset/testing, and case outcomes. 
Even data from one (or several) specific locations would be most helpful.
This question refers to case-level data. For aggregate data, see this question (COVID19 - Corona Virus data). 
","['data-request', 'medical', 'covid19']",
translation dictionaries for european languages,"
I'm looking for open translation dictionaries of european languages. Most important would be english-french and english-spanish.
This question is a direct analogon to:

Translation dictionaries. The title of this question very broad, but it has been most interested in english-japanese. And it has been resolved with a dataset on english-japanese
German - English dictionary. This question is specifically on english-german. 

I've already found:

dict.cc allows you do download dictionaries of their language pairs. The data looks great, very clean and with lots of entries. But you may only use it if your software is GPL (maybe possible) and if you don't bundle the data, but link back to the dict.cc site, for users to download it (huge problem, software should be self-contained).
extracting translations from wiktionary, like in this project. But the data is not that clean and creating it for other language pairs would be a considerable overhead in scraping/processing.

","['data-request', 'language', 'dictionary', 'translation']",
Dataset on coronavirus government countermeasures (per country/region/city?),"
I am looking for a machine readable dataset of what country has enacted what form of lockdown on what date, and possibly the ""type"" of lockdown (international travel/national and international travel, restaurants, schools, public offices etc.).

Note: See this question for aggregate case counts
","['data-request', 'medical', 'government', 'covid19']","There are now some fairly complete and up to date such datasets. 
An Oxford University group - Future of Humanity Institute - has gathered these data:https://storage.googleapis.com/static-covid/Containment%20measures/COVID-19%20containment%20measures.zipAlmost simultaneously, a different department, the Blavatnik School of Government from the same institution, has published a somewhat different take on the same data:https://www.bsg.ox.ac.uk/research/research-projects/oxford-covid-19-government-response-trackerBoth datasets are meant to be kept up to date. And of course there is the already mentioned dataset above by the Assessment Capacities Project (ACAPS), an independent information provider:https://data.humdata.org/dataset/acaps-covid19-government-measures-dataset"
Data resources for air pollution time series,"
I am trying to learn some Spatial Data Analysis before applying for a PhD in Environmental Epidemiology and Exposomics (I am a Computational Biologist). Therefore I want to work on a small personal project: I want to predict PM2.5 or PM10 concentrations starting from satellite data using Deep Learning.
For this I need a dataset of PM2.5/10 measurements. I read some papers on this topic and most seem to use daily averages from just a few stations (for instance, in NY (USA) there a just a bunch of stations measuring PM concentrations): I would like to have a more fine dataset (e.g., more stations per state). Obviously, I need to have access to historical data, but it does not matter the country or even the continent. As an example, the data from the World's Air Pollution: Real-time Air Quality Index are excellent in terms of coverage but limited in time. On the other hand, the datasets from the US EPA are excellent in terms of time-series, but limited in coverage. Are you aware of any open resource providing time-series data with good coverage that I could use?
","['data-request', 'geospatial', 'machine-learning', 'time-series', 'environment']",
Which SPEI time series should I use?,"
I'm using the SPEI index to obtain a measure of drought conditions for various countries, across a number of years. I just want one measure, per country, per year. I am unclear about whether I should be using SPEI-1, SPEI, 3, SPEI-6, or SPEI-12. I am planning on taking the average for the year, however, I've tested a number of locations and can see that the yearly average is rather different depending on which time-series (1,3,6, or 12) is used. I'm looking for the measure that gives the best overall picture of drought conditions within that year, can anyone help?
","['weather', 'time-series', 'climate']",
Torrent for Wikidata dump,"
I'm looking for Wikipedia (enwiki-latest-pages-articles-multistream.xml.bz2) and a Wikidata (latest-all.json.bz2 ) dumps. The files are quite large (the latter has ~47GB) and my internet connection tends to stop while downloading.
I'm looking for torrent files. I found one for Wikipedia, but I cannot find one for Wikidata. Is there any?
","['data-request', 'wikidata', 'wikipedia', 'bittorrent']",
Influenza/ILI activity by municipality or clinic,"
I'm looking for weekly data on all new cases at the clinic, city, or county level, for all previous flu seasons. Does anyone know where I can find such a dataset?
",['data-request'],
"Free, real-time, aviation data API","
Similar to my question Free source of AIS data (API), but for aviation.
I am looking for a free, real-time, API for positions of aircraft. Ideally near London City airport, failing that, UK airports; as a fall back, anything at all, as long as it is real-time. The more info about the flight that is available, the better.
","['data-request', 'uk', 'aviation']","The best that I have found so far is https://opensky-network.org/   It even offers antonymous access to data, but why not join? The REST API is at https://opensky-network.org/apidoc/rest.htmlThere is also https://uk.flightaware.com/commercial/firehose/, which also requires paymentsDitto, https://uk.flightaware.com/commercial/flightxml/ http://www.adsbhub.org/ is another that requires you to share your data to obtain access.As mentioned above, I have a similar interest in maritime data (AIS). It looks like my solution to my question Seeking the cheapest possible AIS receiver costing $60 / Eur 55 / £50 will allow me to share data and, thus, access that of others.A similar device (an ADS-B receiver) for aviation costs from about $18 / Eur 16.50 / £ 15, and that's just a quick glance; no doubt Ali Express & BangGood will be cheaper.These look excellent !! They get good reviews here. In fact, even though I can get free data without any hardware., these are so cheap that I will get one, just to play around with it.You get what you pay for, of course, but I live only 2 miles from a major river and a major airport, which should be good enough for proof of concept. Plus, of course, even a minimal data stream should be enough to show willing and allow you share the data of others with better rigs.Once I figure out how to set up the receivers and sign up to the APIs, I will update my answers to all related questions."
Background data ski areas,"
For an assignment, I'm trying to visualize a specific ski route. The sample is taken with a GPS tracker in Obergurgl & Hoghgurgl, Austria. I am using QGIS for this assignment. I could insert the trace using vector lines in QGIS. But now I want to add some background data, like streets, heights, buildings for instance. Does anyone know how to do so or where to find the appropriate data?
","['geospatial', 'ski']",
Face recognition for Lie Detection,"
Can anybody help find open dataset with Face recognition for Lie Detection with micro-movements detection?
For example i just want find datasets from any of this articles
http://web.eecs.umich.edu/~mihalcea/papers/perezrosas.icmi15.pdf
RU-FACS-1 database
https://inc.ucsd.edu/mplab/wordpress/index.html%3Fp=80.html
CASME database:
https://ieeexplore.ieee.org/document/6553799
",['data-request'],"The paper you posted a link to literally states:The dataset introduced in this paper is available upon request.and all of the email addresses of the authors are on the title page. In general, for specific and academic datasets, make the request to the researcher first.Note: one author has a download page, but it seems this dataset is not there. http://web.eecs.umich.edu/~mihalcea/downloads.html"
Seeking 800M or better resolution Annual Precipitation (at least two different years) raster data for four corner states or the Navajo Nation,"
I was wondering if anyone on here might know where I can find at least 800 meter or better resolution of Average Annual or Average Monthly Precipitation data, that would cover the 4 corners area (UT, AZ, NM, CO) or basically the Navajo Nation?
I am working on a Mule Deer Habitat Suitability analysis and this is the last set of data I need to do a comparison for a school project. 
I know PRISM data is at 800m resolution, but it's a 30 year annual average. Is there a way to extract a single year from PRISM?
I've been looking around for a couple weeks now.
","['data-request', 'geospatial', 'open-source']",
Ice thickness historical dataset around southern Alberta,"
I'm looking for a historical ice thickness dataset in southern Alberta (or its vicinity) to confirm test criteria for an electrical substation's equipment. For now, I am using the ""Radial Wet Snow
Accretion"" 50-years return value from AESO's map (see link below), but it's way conservative, and manufacturers either can't meet it or are reluctant to test for it (and this test is not budgeted).
I have found these datasets from Environment Canada but the one which might be applicable (1947 to 2002) is outdated, the stations don't all have names, and it's hard to correlate them with physical locations. I followed the steps suggested in this comment but even with a response, 2002 seems quite outdated.
There's also this weather map published by the AESO, but it's the result of a statistical calculation for transmission lines, not actual historical data. Plus, as mentioned above, it seems way conservative.
I'll keep looking and will report back if I find something interesting, but any help would be really appreciated.
","['weather', 'canada']",
Are two movies similar?,"
I'm about to evaluate how to good is my solution in finding similar movies: similar it terms of plot and genre
Is there any open dataset to evaluate my solution, with some permissible license, at least for educational purposes?
","['data-request', 'film']",
Seeking polygonal river data complete with river bed width,"
I am trying to find data of rivers that are not made of simple lines. I need polygon data so that the river bed is visible.
Is there any global or regional data source?
","['data-request', 'geospatial', 'hydrology']",
designing a vocabulary / ontology where classes have fixed constraints,"
Let's say that I have a class called ""Event"". Inside of this class there is a property called chanceOfSuccess which has the type QuantitativeValue. QuantitativeValue is a class that has min, max, and value properties.
Depending on the event, the min and max value can be different, but would have the semantic of constraining what the value of chanceOfSuccess should be and would be enforced in code.
How would I design this on the json-ld side?
One method would be to create a subclass of Event and create a property called chanceOfSuccess30_60. The min and max values could be parsed from the property name or the code could have an if statement which looks for chanceOfSuccess30_60 and knows to enforce a value of 30 to 60 on the value of chanceOfSuccess30_60. This would seem bad.
Alternatively, I would think it possible to define a subclass of QuantitativeValue, called QuantitativeValue_30_60, where min value is 30 and max value is 60.  A subclass of Event then has a property with the type QuantitativeValue_30_60. Code can then see it is dealing with an instance of a subclass of QuantitativeValue and know to look at the min and max value to constrain the value of the instance. However, this seems to be overly complex as it would require a subclass for every possible combination of min and max value and be no better then the first alternative.
A third alternative might be when creating the instance of an Event, to set the min and max value at that time. This would seem to be the best option, but would seem to shift to much responsibility onto the code creating and managing the instances.
The fourth alternative would be to use SHACL. In this case, for every subclass of Event, I would need to define an equivalent Shape instance which targets that class. This would seem similar to the second alternative, but instead of using the min and max value properties in QuantitiveValue to hold the constraints, the constraints are in the Shape instance. 
However, I am not certain as I am approaching this from a practitioner perspective and one who is just beginning to learn about these ideas.
Is there a fifth alternative I have not considered? 
Are one of these four the correct path? If so, again, what would the design look like from the json-ld side?
","['json', 'ontology', 'semantic-web']",
What characters are allowed in the search parameter of the NDC OpenFDA API request?,"
I'm having an issue where the NDC API returns errors when special characters are submitted in the search parameter.
I working on a product that contains a search box that allows the user to lookup medication information. The end users are not restricted right now in what they are allowed to enter into the search box. The information that they enter is surrounded in quotes because I want the users to search for the exact information. All spaces are turned into ""+"". Finally, any outstanding special characters are converted into their percent codes.
This is the code that we use to form the string
SearchText = Uri.EscapeDataString(SearchText);

if (!(this.SearchText.StartsWith(""\"""") && (this.SearchText.EndsWith(""\""""))))
{
    this.SearchText = ""\"""" + this.SearchText;
    this.SearchText = this.SearchText + ""\"""";
}

SearchText = ""generic_name:"" + SearchText + ""+"" + ""brand_name:"" + SearchText;

return string.Format(""?search=({0})+AND+listing_expiration_date:[{1}+TO+9999-12-31]&limit={2}&sort=listing_expiration_date:desc&skip={3}"", SearchText, DateTime.Today.ToString(""yyyy-MM-dd""), this.PageSize > 0 ? this.PageSize : 100, RecordStart);

When I test with random special characters thrown in, I get error 400 Bad Request responses from the API.
The OpenFDA website doesn't have any information about what characters are allowed in their parameters and I haven't been able to find any standard online. Does anyone know what characters are allowed in the parameters?
","['api', 'openfda']",
"Complete Germany city database with cities, villages and regions","
I am looking for a very detailed free or not free city database for Germany. I need information like state or village, region, latitude, and longitude, and population. I think Geonames is a bit messy and not very clean.
","['data-request', 'city', 'database', 'geocoding', 'germany']",
MEPS Priority Conditions ICD-10 Codes,"
Medical Expenditure Panel Survey has a list of priority conditions (A3-1, last page):
LIST OF CONDITIONS ASKED IN PRIORITY CONDITIONS ENUMERATION SECTION

Angina/Angina Pectoris
Arthritis
Asthma
Attention Deficit Hyperactivity Disorder (ADHD)/Attention Deficit
Disorder (ADD)
Cancer/Malignancy
Chronic Bronchitis
Coronary Heart Disease
Diabetes/Sugar Diabetes
Emphysema
Heart Attack/Myocardial Infarction (MI)
High Cholesterol
Hypertension/High Blood Pressure
Joint Pain
Other Heart Disease (not coronary heart disease, angina, or heart
attack)
Stroke/Transient Ischemic Attack (TIA)/Mini-stroke

I would like to filter out any non-priority conditions events then group by priority condition. The conditions are given in a table with ranges of 2-3 digit CCS codes. The latest (2017) MEPS data provides a reference to a mapping provided by HCUPS to convert the ICD10 codes to CCSR. However the CCSR codes in the mapping are 3 char + 3 digit. How can I get the groups of ICD-10 codes which map to a priority condition by the 2-3 digit CCS codes given in the MEPS conditions table?
EDIT:
I am looking for any reasonable method to group the events into those pertaining to one of the priority conditions.
",['medical'],
"Why doesn't my government, and governments in general, provide useful statistics in digital format?","
I live in Sweden, but this applies to all other countries as well.
I have a general interest in, and fascination of, statistics and working with data in databases. By far the biggest obstacle has nothing to do with technically dealing with the database software, writing SQL queries, or designing databases. Rather, the #1 problem is:
Nobody wants to provide useful data!
I have spent a significant part of the last 20 years searching for databases/data files of all kinds. Time and time again, I end up at a ""contact us for pricing"" webpage, or a ""Buy now for only $4,799!"" text. Oddly, this does not just apply to commercial entities, but also authorities.
Even though the Swedish government has been talking about ""open data"" and ""free information for all"" for a very long time, the actual reality is that virtually none of that juicy data is available for you and I to grab and use. Instead, they have multiple layers of ""red tape"", requiring you to pay through the nose for any kind of access, and in many cases, you aren't even allowed to pay for it unless you run a major corporation with special ties to the government. It's really bizarre.
The data they do allow you to look at is meaningless/shallow statistics, rarely if ever provided in a format which can be reasonably parsed by a computer and fed into my database for further analysis. The so-called ""open data for everyone"" often consists of nothing more than a bunch of formatted PDFs, useless for my purposes.
I'm not interested in static columns showing how many new people were born in 2020. I want a list of those people, with their names, genders, race, blood type, etc.
I realize that all data cannot be open without heavy abuse inevitably resulting from it. However, at least the Swedish government has this idea of ""public records"", where you are theoretically allowed to request all kinds of data. The problem is that they only allow you to do this in person, over phone or via e-mail, and you have to do it manually and only request at most three (3) ""units"" each time. In practice, this makes it useless.
If this information is allegedly ""public"", why are they so unwilling to actually make it available? I could send an e-mail to a Swedish government entity right now, requesting all kinds of information (including their full social security number) for a given person, and they will respond within 24 hours with it, no questions asked. I've done it many times. However, if I ask them for a Swedish_people.csv file with every person registered in Sweden and the same information I requested manually for one or up to three persons, they will refuse.
Major corporations are able to pay a lot of money to get access to their government APIs, but it costs a fortune and they wouldn't let me buy access to it even if I had the money (because I don't run a major company).
It doesn't make any sense to me. I wonder why they have these double standards, and how they can possibly charge money for ""public"" records.
A dream of mine would be to be able to do:
SELECT name, email_address, physical_address, passport_photo FROM people WHERE current_city = $1 AND gender = $2 AND age >= $3 AND age <= $4 AND civil_status = $5 ORDER BY distance_from_me DESC;

Of course, this is completely unrealistic, but you get the idea. I wish to have actual, curated records from (semi) trusted sources rather than having to play with the few, measly databases which are freely available to the public at no charge.
A perfect example of something very basic would be the telephone book. Back in the day, they sent out a complete book of every single person's name, telephone number and address to every household in the entire country. This was standard practice all over the world, I believe. A digital version of that would be a .csv file which I could just download from a government website at a static URL, always kept updated. Nope. Nothing like that. I'm forced to use these third-party, commercial websites where I get to enter individual people's names and send this information to the company in question. They are paying the government a lot of money to get this information, even though it could be made available for virtually no cost at all.
Why, since they used to provide this information in physical form, is it now unthinkable in the digital age?
","['data-request', 'releasing-data']",
"Data on car models, brands and type","
I'm looking for a database which is kept up to date (eg. monthly/quarterly updates) about cars. The dataset must contain the car brand, model and type (eg. SUV, coupe,...). All extra data is welcome. I would like to have the data at least on continent level, preferably world-wide. 
I'm comfortable with a free sample paying if I'm satisfied with the sample. 
",['cars'],"Car Models by Manufacturer, Category, and YearA dataset with car models categorized by manufacturer, type (SUV, Sedan, etc), and manufacturing year. A developer is able to clone, connect, and download the dataset in a JSON format (transform to CSV after downloading). The dataset is open-source and provides detailed information about motor vehicles manufactured in the US between the years 1992 and 2020.This Stack Overflow thread links to a database someone put together and hosted on GitHub, although it sounds like it's fairly incomplete."
Best GIS database for Brazil geological data,"
I'm looking for a database for the underground resources of Brazil, especially for the state of Minas Gerais. Do you have any to recommend?
","['data-request', 'database', 'brazil']",
Face data set with ca. 100-1000 images on each individual,"
I'm looking for a data set that has a larger number of images associated with 1 individual in a set to fine-tune a neural net for identification as a research project. Having 5-10 individuals is more than enough. So far, I've been trying with downloading celebrity images using different search engines (and icrawler), but most search engines give 60-80 images at best (with bing being the best so far with ca. 120).
","['data-request', 'images', 'faces']",
Current Population Survey (CPS) before 1962,"
I am trying to find monthly CPS data for years before 1962, which is the first year available through IPUMS. I checked on the NBER website but they only provide data from 1976 on. CPS should have been administered since the 1940s but I cannot find an online source of data for the first two decades. 
Do you know if they are available? And if yes, where?
","['data-request', 'economics']",
Unzipping the openfda data in R,"
I've downloaded all the url's for the different drug-event pairs, but they all end in .zip.
Does anyone know how to automate pulling the .json file out of these zip files without doing it manually for each one? I'm not sure how to unzip the files.
library(jsonlite)
# create a character vector of all 961 available download files
url <- ""https://api.fda.gov/download.json""
document <- fromJSON(url)
results <- document$results
drug_event <- results$drug$event
files <- as.character(drug_event$partitions$file)

# unzipping the files
file1 <- files[1]
temp <- tempfile()
download.file(file1,temp)
unz(temp, ""data.json"")

","['openfda', 'programming', 'json']",
South Africa inland lakes bathymetry/depth contours,"
Someone was able to find information or a database on bathymetry/contour lines for inland lakes in South Africa?
","['geospatial', 'research', 'africa', 'analysis', 'data-mapping']",
Tanzania Life Table,"
I am doing a survey on Life Tables of several countries and I can't seem to find that of Tanzania for all ages (not in ranges like it is in WHO website) . Does anyone know where it can be obtained?
","['data-request', 'research', 'demographics', 'africa']",
LCA API Download access,"
Is there an API for LAC applications that my company can access to download LAC applications? We currently use the website to logon and manual download the LAC applications
","['api', 'labor']",
Is there a database of book/movie character descriptions,"
For a machine learning task, I want to use book character descriptions to learn the possible properties of people of characters. Does anyone know a database of descriptions of book/movie characters? Real-life descriptions of people are also a possibility. 
","['data-request', 'machine-learning', 'text', 'books']",
Data source for global corona infection chains,"
Even though there is plenty of public data, I cannot find a source for the global infection chains of Corona. In other words,  I am interested in the data that shows from where each infection has been imported (e.g. country A's patient 0 has imported Corona from country B).
You can find information about that here and there in various news articles. However, I hope for a data source that can be used automatically.
","['data-request', 'covid19', 'visualization']",
Syntax error when the developer friendly name starts with a number,"
I’m having an issue with this line –
obj.results[0][2017].admissions.sat_scores.25th_percentile.math
It’s giving me a syntax error. I’m using Javascript and it seems to be having a problem with the number 25. This code works just fine – 
obj.results[0][2017].admissions.sat_scores.average.overall
Any line that reads admissions.sat_scores.[NUMBER] throws an error. What I'm I doing wrong?
","['api', 'collegescorecard', 'json']",
COVID19 - Coronavirus case data (country summary data),"
There are some very good sites showing the state of infections 'now', but I would like to find a data set of COVID-19 infections, deaths and number of tests by day and by country. These are the best I can find, but it doesn't quite meet what I'm after.

John Hopkins CSSE
Worldometer


Notes: 

There is another question about clinical data for covid19.
There is a community wiki answer to index the answers. You can answer there by editing, either adding a link to your answer, or a link to a ""link-only"" answer.

","['data-request', 'medical', 'global', 'covid19']",Index of Countries (community wiki)
"RDF schemas, ontologies for software libraries?","
Are there RDF schemas, ontologies for software libraries? Let's say I'm a Lisp programmer familiar with quicklisp. Or I'm a C programmer using numerical packages. Or a MS programmer using DLLs. Has any software libraries like these been ""semantic webbed"" with RDF triples? If not, where might I start? I'm guessing there exist XML or JSON data management for libraries, correct?
","['rdf', 'ontology', 'semantic-web']",
Global data about compulsory swimming lessons in schools or rates of population that can swim,"
I saw this post on Hacker News and was curious about a dataset that has information about countries and their approach to compulsory teaching of swimming.
There are many datasets about drowning rates (see my comment for links), but I'd like to correlate those to the prevalence of swimming lessons for children, either in schools or otherwise a government initiative. Or, percentages of population that can swim, by age groups if possible. 
Any machine readable format (even PDF tables) and any license is fine to get me started.
","['data-request', 'sports', 'education', 'global']",
"Is there a way to filter, so that I only get reactions where SUMATRIPTAN was listed as suspect drug?","
I'm trying to get the number of reactions for a certain drug, but only where the drug was classified as suspect drug (drugcharacterization=1).
I tried: https://api.fda.gov/drug/event.json?search=(exists:(patient.drug.openfda.generic_name.exact)+AND+receivedate:([20040101+TO+20170630])+AND+patient.drug.drugcharacterization=1)+AND+(patient.drug.openfda.generic_name:%22SUMATRIPTAN%22)
and https://api.fda.gov/drug/event.json?search=(exists:(patient.drug.openfda.generic_name.exact)+AND+receivedate:([20040101+TO+20170630])+AND+(patient.drug.openfda.generic_name:%22SUMATRIPTAN%22),that outcoes aren't different.
In this way,I can't get the number of reactions for a certain drug, but only where the drug was classified as suspect drug (drugcharacterization=1).
Is there a way to filter, so that I only get reactions where SUMATRIPTAN was listed as suspect drug?
",['uses-of-open-data'],
Looking For Land Emissions/ Soil Contamination Chemical Levels Data,"
I'm looking for any data showing soil/land emissions and/or soil contamination levels for the state of Pennsylvania. The only sources I found were on the EPA (using the TRI database) and this data source (https://mrdata.usgs.gov/ds-801/). 
Note: I'll also accept soil data for the USA as a whole as well.
","['data-request', 'soils']",
searching for clouds (in the sky) images big dataset,"
I'm looking for a big dataset of clouds (in the sky) ground based images. i need tens of thousands of images.
It is important that the images will be ground based and not from satellite/ flights.
I've tried to search and so far found datasets of hundreds/thousands of images, but not the amount I need.
I'll appreciate your help. Thanks!
","['data-request', 'geospatial', 'images']",
How do I download a Maharashtra Village Boundary layer .?,"
How to Download Maharashtra Village Boundary.?
",['geospatial'],
How do I access articles from the National Library of Medicine that have not been digitized?,"
I want to read a certain article in a scientific journal which I believe is stored at the National Library of Medicine, among other places. It does have a PMID. I looked at the instructions for obtaining a full article here: https://www.ncbi.nlm.nih.gov/guide/howto/obtain-full-text/ . 
The particular article I want to access does not have a ""Get full access"" icon anywhere, and I can only view an abstract. I can thus only assume that the article is only stored in printed form at the NLM and has not been digitized. In fact, I have looked it up on Worldcat and was told that it is available at the NLM, plus some other libraries. I have also been unable to find any contact information of the publisher.
How can I, who am not affiliated with a university or any organization, obtain either a print copy of the article or get a digital copy? Is there a way to request a digitization? According to Worldcat, the nearest library containing the journal with the article I seek is rather far away. Is physically travelling to the location the only option?
The scientific journal in question is Eksperimentalna meditsina i morfologiia, volume 12.
","['data-request', 'usa', 'medical', 'government', 'research']",
How do I access the admissions data from College Scorecard?,"
I think my api formatting is off, but I keep getting errors from: 
https://api.data.gov/ed/collegescorecard/v1/schools?fields=admissions.sat_scores&api_key=redacted
the error is {""errors"":[{""error"":""field_not_found"",""input"":""admissions.sat_scores"",""message"":""The input field 'admissions.sat_scores' (in the fields parameter) is not a field in this dataset.""}]}
","['api', 'collegescorecard']",
County-level data on religious affiliation and church attendance in US 1940-1960,"
Is there any county-level (or similar) data on religious affiliation and church attendance in the United States from 1940s-1960s?
","['usa', 'demographics', 'county', 'religion', 'historical']",
Dataset of explosion audio (or video with audio) recordings,"
Does anyone know if there is an audio dataset containing explosions? I'm trying to train a neural network in recognizing explosions sounds.
","['data-request', 'machine-learning', 'audio', 'video']",
Geo-coded Russian Cities Data,"
I need an open source geo-coded dataset for cities in Russia (global data would work fine also as long as it includes Russia).
So far the best I've found is the simplemaps dataset which has partial data (677 cities) for free or $199 for their full data (188,968 cities): https://simplemaps.com/data/ru-cities
Does anyone know of a dataset of Russian cities that is both comprehensive and free which includes coordinates (latitude and longitude)?
","['data-request', 'geospatial', 'russia']","At the suggestion of sboysel and Stanislav Kralin I explored two data sources that answer the question in different ways. The RU.zip file off of http://download.geonames.org/export/dump/ is more comprehensive in its inclusion and is better if seeking general populated places in Russia. In total it has 360,646 entries. Be advised that in addition it also contains Federal Districts, Oblasts, Republics, and Krai which may need to remove.The city.csv file from https://github.com/hflabs/city?files=1 has 1,118 cities and apparently includes only places that have officially been designated as a city by the Russian Federation. This is better when official designation matters."
"Seeking Building Shapefiles in New South Wales, Australia","

Is there a website with a comprehensive source for Building Shapefiles in New South Wales, Australia?  
I have downloaded the Shapefile from here https://download.geofabrik.de/australia-oceania.html however there are a lot of buildings missing (see image)
","['geospatial', 'openstreetmap', 'buildings']",
Open access P Band Radar data,"
Are there any sources for open access P Band radar data? I need it for a single city block in the Middle East, outside United States.
The Russian Aist 2D has a P Band SAR on board, but the data seems to be not free, therefore not open data.
","['geospatial', 'aerial-photography']",
Data sets for recommended nutrition with detailed information?,"
While there is enough data which give a rough approximated nutrition information, if you dig deeper, you find that depending on a mineral or vitamin there can be big differences for the recommended intake depending on sex, age but also metabolism say for pregnant/lactating women.
Also as it seems there are dozens of known nutrients relevant for health.
Therefore, is there an up-to-date data set where all this data is compiled?
","['medical', 'food']",
"Pre-existing data set - organizational performance, external and internal hiring of leaders, demographics","
I am looking for pre-existing data set (or sets) that has organizational performance, external and internal hiring of leaders, demographics. Even one of these areas would help.
tks
",['data-request'],
Satellite Video Remote Sensing data,"
Does anyone know of any satellite missions (open access or not) presently acquiring global Video Remote Sensing data? 
","['data-request', 'uses-of-open-data']",
Adding organization metadata to RSS/Atom feed?,"
What is the most correct / typical / popular namespace to associate an organization name, logo, and maybe website metadata with an RSS 2 (or Atom) feed entry? Can we just use https://schema.org/Organization for that? Organization can be understood as a creator of the entry or original creator (in reposting case) or maybe some more involved relation approximated with the association.
",['metadata'],"The best representation I've seen are mixtures of Microformats, Schema.org, and Dublin Core. Essentially, utilize the semantics that are best for your situation; it sounds rel=""author"" is what you are looking for in differentiating blog posts. Indie Web Camp's feed and A List Apart's feed are great examples of metadata in feeds.
Running them through pin13's validator exposes their semantics; not surprisingly, nothing renders in Google's ""Structured"" Data Testing Tool.  "
API either database on organic/natural products,"
While databases and API offerings around nutrition, foods and recipes are flourishing, I fail to find a machine readable data source for organic/natural products as food without relationship to the related products you can actually buy.
With nutrition data, I mean not only the typical triple ""carbs, protein , fats"" but the complete list of nutrients like vitamins and minerals and what not being important for human well being. 
",['food'],
How precise class names should be? [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 3 years ago.







                        Improve this question
                    



For example if our database is about the European Union, is calling the class containing countries inside the EU Country descriptive enough, even though it's not supposed to contain countries outside of the EU?
","['linked-data', 'rdf']",
How many crimes are alcohol-related vs. drug-related in the US?,"
I’m having a devil of a time finding any useful information on this subject. I want to know how many crimes were committed under the influence of alcohol vs. drugs (specifically meth, but few sources break such data down by drug type).
Note that I’m not asking about rates of crime per type of intoxicant, i.e. how likely a given alcohol user is to commit crimes vs a drug user. That would be interesting, but what I’m looking for is something like “X violent and property crimes were committed by people under the influence of alcohol last year, and Y violent and property crimes were committed under the influence of drugs” or “X% of crime is alcohol-related, and Y% of crime is drug-related.” 
Obviously I’m not interested in “consensual” crimes like, well, drug use, as all illegal drug users are committing these crimes by definition.
My expectation is that alcohol-related crimes will outnumber drug-related crimes, simply because there are many more alcohol users than drug users. But I’d like some basis for that belief. It doesn’t have to be unquestionable, just reasonable. But the best I can find is ""15% of robberies, 63% of intimate partner violence incidents, 37% of sexual assaults, 45-46% of physical assaults and 40-45% of homicides in the United States involved use of alcohol.” from Wikipedia (which cites a questionable source), and ""addicts using meth committed six million crimes in 2004” from FIGHT CRIME: INVEST IN KIDS, which also sounds pretty sketchy. But I’d take it, if both numbers could be compared to each other.
Interestingly, I have run across statistics about the relative criminality of drug vs. alcohol users, even though that’s not what I’m looking for, from the White House Office of National Drug Control Policy.
",['crime'],
Filtering Wikidata Search,"
Wikidata today is not only an ontology but also a catalog of publications: scientific articles, formal documents (law), etc. are registered, millions of Wikidata-items.  So, when using Wikidata's  search engine it is looking for  millions  of things that I not need.
How to say to Wikidata-search that I not need that?

Can I use the SparQL engine as search engine?
Articles are subclass of work (Q386724), so can I exclude that items and do a ordinary search for others?
","['wikidata', 'search-engine']",
computer science corpus for language model training,"
I am looking for a domain-specific computer science corpus of at least 20M words (preferable >50M words), for the purpose of training a language model in it.
Is there anything out-of-the-box that I could use? *I tried to look for the sciBERT corpus, but can not find how to access it.
","['data-request', 'machine-learning', 'nlp', 'text', 'ai']",
Mobile Home Parks,"
I would like to create a list of all mobile home parks in the US, including address, owner records, and number of pads.  How can I find a list of all mobile home parks by State and sorted by number of pads?
","['usa', 'data.gov', 'real-estate']",
Seeking 1890 County Shapefiles of Scotland,"
I am struggling to find the county border shapefiles for Scotland that came into effect in 1890. I keep finding ""counties before 1890"" when googling. So, the file I'm looking for does not include a Glasgow county as Glasgow was still split between Renfrew and Lanark.
Does anyone know where I can find this data?

","['geospatial', 'uk', 'data-mapping']",
Is there any public data source for LAS 1.4 or at least point format 4 or above?,"
I have looked at https://opentopography.org/tags/data.
The data I obtained from https://opentopography.org/tags/data was in 1.3. 
  Some one told that it should be available at usgs site but I felt lost at the site. If you had success in getting the aforementioned data at usgs or some other site please share your experience.  
",['geospatial'],"I was able to get it from 
 https://cteco.uconn.edu/data/download/flight2016/index.htmThere is drop down to select a city. 
I selected the first city Andover. 
On the right of the map a table with 4 columns heading appear.
The last column  has las data. 
I selected one element ( clocked on the link) from the last column. 
I popped up a window titled ""Results""> This window has two tabs: ""Town"" and ""Tile"". 
I clicked on ""Tile"" tab
Then there are links for Tiff , DEM etc . Among them is LAS.
I clicked on the LAS.
It downloaded a zip file.
By uncompressing the zip file, I got my las file. 
The version of the downloaded file was 1.4  and point format was 6. "
Doctors and Insurance Networks,"
Where can I find a database of doctors and accepted insurances? The closest I've gotten is https://npiregistry.cms.hhs.gov/api/ but while that includes what looks like insurers under the ""identifiers"" property, it doesn't mention specifically which plans are accepted. So it will list:
""identifiers"": [
    {
        ""code"": ""01"",
        ""desc"": ""Other"",
        ""identifier"": ""909101"",
        ""issuer"": ""PHYSICANS HEALTH"",
        ""state"": ""NY""
    },
    {
        ""code"": ""01"",
        ""desc"": ""Other"",
        ""identifier"": ""010126174NY01"",
        ""issuer"": ""ANTHEM HEALTH"",
        ""state"": ""NY""
    },
    {
        ""code"": ""01"",
        ""desc"": ""Other"",
        ""identifier"": ""1000016207"",
        ""issuer"": ""AFFINITY HEALTH PLAN"",
        ""state"": ""NY""
    },
    {
        ""code"": ""05"",
        ""desc"": ""MEDICAID"",
        ""identifier"": ""00296768"",
        ""issuer"": """",
        ""state"": ""NY""
    },
    {
        ""code"": ""01"",
        ""desc"": ""Other"",
        ""identifier"": ""0611880"",
        ""issuer"": ""UNITED HEALTH CARE"",
        ""state"": ""NY""
    },
    {
        ""code"": ""01"",
        ""desc"": ""Other"",
        ""identifier"": ""541254"",
        ""issuer"": ""AETNA SPECIALIST"",
        ""state"": ""NY""
    }
]

I know he is registered with Anthem Health but not whether he is part of the HMO network or some other network under Anthem. Also, the docs mention the ""identifiers"" property is limited to 50 items, what if all identifiers exceed 50?
There has to be a better way to get network information by provider. I could pay thousands a month to license the data if I had that kind of budget, but I don't, perhaps $100 or less per month but not what I've been getting quoted. Where could I find that kind of information without paying an exorbitant licensing fee?
",['medical'],
Is there research on taxi call times?,"
we are simulating future traffic in cities using small autonomous shuttles. To get more realistic we are looking for research on how long people are calling their taxi in advance.
Sadly my googling did not lead to any result so I am curious whether anyone out there has an idea where to look or even knows some papers.
","['transportation', 'research', 'traffic', 'public-transport']",
Interested in Workers' Compensation and Safety Violations data,"
Working with a major insurance client that is interested in data regarding workers' compensation and associated OSHA violations. Which data table within the OSHA API can provide this? 
",['labor'],
Where can I find a dataset with labelled articles by topic?,"
I am looking for a dataset containing articles (with article-text, or alternatively I am fine with only URLs too) and the corresponding topic label (i.e. politics, art, gardening etc.)
Any idea?
","['machine-learning', 'nlp']",
Free Datasource for DTM in Northwest Russia (Karelia),"
I'm looking for a Digital Terrain Model in the Karelia region (Russia) with a spat. resolution about 30m. (Also Contour Lines would be ok)
I read an article about the ""RuDTM2014"" https://www.researchgate.net/publication/309312124_RuDTM2014_New_digital_terrain_model_for_Russia_and_its_effect_on_the_prediction_of_mean_gravity_anomalies ,but there's no information about where to find the data. I checked out ALOS World 3D Data but this has too much noise in that particular area and the ASTER Global Digital Elevation Model has a bad quality. Using this datasource: http://viewfinderpanoramas.org/dem3.html#others gives only a resolution of approx. 40m.
Are there data sources in Russia which provide this data for free?
","['geospatial', 'russia']",
Open FDA API - LIKE search condition,"
I am interested in finding a syntax for the LIKE search condition.
The query syntax example is
https://api.fda.gov/drug/ndc.json?search=brand_name:aspirin
I have to enter the whole word (aspirin) for getting result.
Is there any way to get result with the part of the word (for example ""asp""), using symbols like % or %s for LIKE search?
Getting no result with this query
https://api.fda.gov/drug/ndc.json?search=brand_name:aspiri%
",['openfda'],
"Query Open FDA for application_number, ndc, and rxcui","
My apologies if this has been asked: I am new to using OpenFDA and am trying to query the database to obtain a list of the ndc and rxcui associated with a particular application numbers appearing in FAERS. More specifically, I downloaded faers and tried to query one of the application numbers appearing in the dataset, e.g. 21752. However, I obtained the error ""no matches found"" when searching for on a specific applications number, e.g. https://api.fda.gov/drug/event.json?search=20patient.drug.openfda.application_number:""2221752"". 
Is it possible to query openFDA event data to obtain the ndc and rxcui associated with a specific application number? 
","['api', 'openfda']",
"Where can I get word lists for Indian languages, specifically Hindi and Tamil?","
Is there a way to get word lists for Indian languages (specifically Tamil and Hindi), even for commercial use? It is for a game I am developing
","['data-request', 'language']",
Obtaining map of all public space of France,"
If possible through shapefile format (GIS), I'd like to get a map of all over Metropolitan France showing public space, id est public woodlands, public parks, roads, public lands, etc, owned by the State or by local authorities.
","['data-request', 'geospatial', 'france']",
Sport accident occurrences vs practitioner's skill level,"
I remember having read a few years ago something along the lines of:

injury risks among novice sports practitioners increase when they gain confidence -- due to a perceived skill level above their actual skill level.

To check that statement, I'm looking for some open data that associate accident events with the reported skill level of the practitioner. It doesn't matter if the skill level is assessed as some categorical (ex: ""novice/advanced/expert/pro"") or continuous data (ex: ""years of practice"").
Ideally, I would like data related to accidents in ""action sports"" like skateboard, roller, kitesurf, or alike where "" poor execution of the activity has to result in considerable risk of serious physical harm to the participant"" (to quote wikipedia)
I will use the data to plot a graph for illustration purposes. I will not perform a deep or formal analysis of them. So, moderately reliable sources should be acceptable. I would prefer data from European countries or North America.
FWIW, Isearch through Google and https://catalog.data.gov but I didn't find any dataset recording the ""skill level"" of victims of sport accidents. But I'm outside of my field, so I may have lacked the proper keywords.
","['data-request', 'medical', 'sports']",
Searching for a query-able nationwide data source of official german TK25 cartography numbers,"
I am looking for a single data source containing the so-called TK25 numbers, aka ""Messtischblattnummern"" (preferrably quarter-TK25). 
I want to intersect the TK25 data with vector data (e.g., a polygon of an area) and subsequently query another data source with the resulting TK25 numbers for their database content. 
I assumed a TK25 grid is out there, on an national level, but I could only find published data on state level. 
","['geospatial', 'openstreetmap', 'germany', 'federal']",
Csv format easy colums characteristic - type dataset for beginner R analisys,"
I had a look on kaggle but I did not find what I was looking for. I need a very simple data set, like the one of ""iris"" default pre-sets of R where you have differents columns with some characteristic of the plant such as length and so on and where the last column tells you the type of species. There is an analogous dataset, for example about rocks, where may be some columns tells a characteristic such as permeablity and so on, and the last column tells you the type of the rock. I need to practice an easy data analysis to be performed with R (for an exam). I could not find somethin like iris neither on the R dataset.
","['data-request', 'releasing-data', 'programming']",
"Where can I get a data set containing road length,road type(both) of Delhi,India","
I have a dataset that contains latitude, longitude(one pair) and road type of each road of a road network.
But I need road length for each road. So how can I get it?
","['data-request', 'geospatial']",
Georeferenced Köppen climate classification maps,"
Wikimedia Commons has a large collection of Köppen climate classification maps in its Category:Köppen-Geiger.  For example, Russia, Canada, or USA.  The formats available on Wikimedia Commons are (mostly) PNG and SVG, which are not georeferenced.  Is there any public source of Köppen climate classification maps in georeferenced formats, such as geotiff, so that I can load it into GIS software and combine it with other maps?
This would make it much easier to tell, for example, what part of British Columbia has BSk.
","['geospatial', 'climate']","Here a set of global 1‑km resolution Köppen-Geiger climate classification maps for the present day (1980–2016) and for projected future conditions (2071–2100) under climate change.Citation: Beck, H.E., N.E. Zim­mer­mann, T.R. McVicar, N. Ver­gopolan, A. Berg, E.F. Wood: Present and future Köp­pen-Geiger cli­mate clas­si­fi­ca­tion maps at 1‑km res­o­lu­tion, Sci­en­tif­ic Data 5:180214, doi:10.1038/sdata.2018.214 (2018).Web site: http://www.gloh2o.org/koppen/Data download (GeoTIFF + legend): 
https://figshare.com/articles/Present_and_future_K_ppen-Geiger_climate_classification_maps_at_1-km_resolution/6396959/2"
Can I put open source data on a public github repo?,"
I am using open-source data for a data sonification project and would like to put the data used for this project onto a public Github repo. Are there any legal issues with doing this? I am assuming not because it is open source but just wanted to make sure.
","['uses-of-open-data', 'releasing-data', 'legal', 'git']",
Is there any downloadable collection of websites' source code mainly HTML and CSS applied to it?,"
I am trying to train an AI model on styling HTML with CSS and lots of data would be useful rather than me trying to manually download specific websites using scripts/web crawlers.
Mainly looking for basic website functionality and styling, nothing too complex.
To be specific a collection with .html and .css(applying to that html via id or class name) would work best.
",['html'],
Anyone know of any open access satellite/aerial imagery that doesnt need a transformation for use in UK in ArcMAP?,"
I'd like some satellite imagery (high res a possible but not essential) for use in ArcMAP (10.7) without a transformation.
I have high res (to cm scale) survey data to work with, the basic imagery basemap is not accurate with a transformaiton to OSGB36.
","['data-request', 'geospatial', 'images', 'openstreetmap', 'remote-sensing']",
Daily precipitation data (mm),"
I am looking for a precipitation data (mm). I found one in published paper, I contacted the author but unfortunately, I revive no answer. I hope someone can help me with this data. Where can I find it, or similar to it? 
The daily precipitation data (mm) for the period January 1,1990 to December 31,2006,measured from four meteorological stations in the four municipalities, one station for each municipality of Akershus County in southern Norway.
",['data-request'],
Allergy dataset with symptoms and allergens,"
I'm looking for an allergy data-set which contains the allergy symptoms shown by a patient and the allergen caused that allergy.
","['data-request', 'machine-learning', 'medical']",
Is there a dataset for the flow of people?,"
Data: I am looking for an anonymised dataset for the flow of people I suppose one may know about it with the cell site or towers. I woul be especifically glad to get geojsons.
Context: I am looking for this to test the hypothesis that the biggest the flows the higher criminal rate you get.
Region:  in London, Paris or other big cities.
Format: I have a preference for geojson. Otherwise anything 
","['data-request', 'geospatial', 'time-series', 'telecom']",
Heavy-tailed data,"
Hi lately I was focused on theoretical modeling of heavy-tailed data. However, I find it hard to collect some classic heavy-tailed data for experiments. I wonder if there is any public and well-known (better if any) dataset confirmed to be heavy-tailed from Kaggle or some labs ? 
",['uses-of-open-data'],
Where can I find free and accurate Parcel data for counties in the US,"
I would like to know if it would be possible to find Parcel boundaries for counties in the US through Open Source resources (free). I am particularly interested in parcels for counties in the state of Florida. Counties of Hillsborough, Polk, Pasco,Pinellas,Osceola,Lake and Manatee.     
","['data-request', 'geospatial', 'us-census', 'openstreetmap', 'data-mapping']",
How can I return all School Names?,"
Per_page max 100, I want all pages, and not have to request page by page.  Can I get all pages, provide string of pages?  Seems like basics request.
",['collegescorecard'],
Netflix/Imdb Movie Genre Data Set,"
Is anyone familiar with a dataset I can use to model or segment users of a data set into movie genres for users based on time, day, the device used, geographic demographics in a data set? I have a data set I want to connect with external data that would give me a preferred movie genre for that user based on the factors mentioned, I tried to find something from IMDb or Netflix, thanks for looking.
","['data-request', 'machine-learning', 'uses-of-open-data']",
Database of half-life for each drug,"
Given a drug ingredient (e.g., as RxNorm ingredient code), is there a database that lists what is the half life of a drug. The database should have 1000+ ingredients. For example a small list is at wikipedia here https://en.wikipedia.org/wiki/Biological_half-life and the info is in drug infobox on wikipedia, but the user needs a comprehensive database.
",['medical'],
Seeking comprehensive open source for building shapefiles in USA,"

I am currently looking for a comprehensive source for Building Shapefiles in the USA, particularly New Jersey. I have come across a few websites e.g. geofabrik (http://download.geofabrik.de/north-america/us/new-jersey.html), http://osm2shp.ru/ , NJDEP Bureau of GIS (https://njogis-newjersey.opendata.arcgis.com/datasets/f9fafdbecf664dae9cfb9239aae83ce7_6 ) but all seem to miss out chunks of neighbourhoods.
","['geospatial', 'usa']",
Where can I find sample Lidar data for counties in Florida,"
I would like to find out where I could download Lidar data for counties in Florida
","['geospatial', 'data.gov', 'noaa']",
Where could I find road data for counties in the state of Florida,"
I would like to know about websites from I could download roads data for counties in the State of Florida. I was able to find Tiger shapefiles for each county in every state in the US. However the data is not very accurate especially when mapped with parcel data for these counties. Are there websites for the individual counties from where I could download the roads data. The data would need to include local county roads as well as interstate highways.
Counties I am particularly interested in are:
Hillsborough, Osceola, Pasco, Pinellas, Manatee, Polk and Lake.   
","['geospatial', 'us-census', 'transportation', 'data-mapping']",You can get this from Openstreetmap.  See Downloading data or Country and area extraction on the Openstreetmap wiki for details on how to do this.
Airline Distribution system Data,"
Appreciate it if anyone can suggest an online data source to capture the below information.
Airline | Country | number of Fleet | Number of Destinations | Airline PSS (Passenger Service System)
","['data-request', 'wikidata']",
How do I extract certain articles from Arabic Wiki Dumps?,"
I need to collect all articles that are about countries and continents in Arabic from Wikipedia. I was wondering how do I find these articles if I downloaded the latest wiki dump?
New to the field. Trying to learn something new every day.
","['wikidata', 'linked-data', 'wikipedia']","Here's the main page for Wiki{p,m}edia dumps:https://dumps.wikimedia.org/and the index of dumps:https://dumps.wikimedia.org/backup-index.htmland for Arabic Wikipedia you'd select ""ar"" and ""wiki"", for example:https://dumps.wikimedia.org/arwiki/20200120/ (note the datestamp)(if you wanted Arabic Wiktionary instead, it would be another dump: https://dumps.wikimedia.org/arwiktionary/20200120/)and the full dump of Arabic Wikipedia is here:Read here about how to parse the resultshttps://meta.wikimedia.org/wiki/Data_dumpsOr search through this forum for tips, for example:How can I download the complete Wikidata database?"
OpenFDA API Suspension effective 12/20/2019?,"
I'm wondering if anybody has any knowledge around the current suspension. None of the APIs have been updated since 12/14/2019, and the API status page currently reads, ""Currently, there is a temporary suspension of updates to the openFDA datasets. Please send inquiries regarding this matter to: open@fda.hhs.gov"" (this text was merged in to the github repo on 12/20).
I've reached out to open@fda.hhs.gov and haven't gotten a response.
Does anybody know what the suspension cause is, when it might be lifted, or what events would trigger it getting lifted? 
",['openfda'],
Open Source Data Visualization Schema,"
I want to capture the data needed to create a visualization (data, series names, titles etc.) in a way that is not tied to my end charting library. The goal being that I could capture the charting data in a common way and let the UI take these definitions and transform them to target charting library at runtime (d3, high charts etc.)
Does anyone know of a robust / flexible data visualization schema that I could use? 
","['releasing-data', 'visualization']",
Are multiple years of FAFSA data combined to determine demographic characteristics for cohorts?,"
If I'm understanding things correctly, many of the institutional demographic characteristics are based on most recent award-year FAFSA data. What is the source of demographic data for students within a given cohort? As I understand it, the earnings cohorts are constructed based on entry year, even though all included students may not receive aid (or submit a FAFSA form) in that entry year. Earnings data is disaggregated by family income. Is this income based on a student's first submitted FAFSA form, an average of all submitted FAFSA forms for each student in the cohort, or something else?
","['collegescorecard', 'demographics', 'aid']",
Is there an available open dataset containing the main science fields and disciplines?,"
I am working on an open-science platform where users can write projects about future papers.
When writing a project, they can add tags to it in order to help with its indexation. The related tags will be research fields, topics, and methodologies.
I am looking for a data set to use as a starter with the main scientific disciplines, and I wondered if there is one available. Is it?
",['data-request'],
Is there any dataset on all countries current and past government hierarchy/structure?,"
Possibly with data on the people and what responsibility they have/had.
",['government'],
Where can I upload a large image dataset?,"
I am applying for a grant, and one of the tasks we are seeking funding for is to make a large image database publicly available for users to train artificial intelligence (convolutional neural network) algorithms. We want a database where users can access and download the photos. After the photos have been augmented, we could potentially have over 120,000 images (taken from a digital camera) to share. This number would grow over time.
What are some good on-line sites where we could potentially upload this database?
","['machine-learning', 'releasing-data']","Some options for your use case:Use university web storage (this is easy but often these sites go stale or dissapear)Use public buckets from cloud provider (AWS, GCP). This often requires login, so it's not truly ""open"". Also, there are some costs associated to hosting data. This is also nice because users can use individual images (like an API), but download folders as zip.Use archive.org - you could create a Collection. If you want to know more, get in contact with them and see if your use case works with their platform.Use torrents (not really practical if the datasets are changing). No cost and preferred for massive datasets. Check out http://academictorrents.com/ for setting up the tracker."
propensity to pay in healthcare Datasets,"
I am searching for data-sets or data sources (free or paid) to do a propensity to pay model for healthcare industry. I found many solutions that offer complete solutions but whats interesting to me that they always include 3rd party data sources. I wanted to know where I can find such data, and where also can I ask.
","['data-request', 'medical']",
How to get the path details between two nodes in DBpedia in SPARQL,"
I want to check if two DBpedia nodes have a path using; 

dct:subject and skos:broader properties
without specifying properties

For instance consider the two DBpedia nodes http://dbpedia.org/resource/Cat and http://dbpedia.org/resource/Dog. I tried to use the following wildcard query to do it.
ASK {
  <http://dbpedia.org/resource/Cat> ((<>|!<>)|^(<>|!<>))* <http://dbpedia.org/resource/Dog> 
}

However, I get a memory error. I am wondering if there is a more suitable way of doing this in sparql.
I am happy to provide more details if needed.
","['uses-of-open-data', 'linked-data', 'sparql', 'rdf', 'dbpedia']",
Where can I find demographic data on ABC network shows?,"
Does anyone know where I can find data on ABC network shows (like Blackish on ABC Family)? I want to see how they're doing as a company and what their demographics numbers are.  
","['data-request', 'uses-of-open-data', 'metadata']",
What API Data is being used on these pages?,"
Can anyone tell me what API data is being used on the following sections of the College listing page?  I've attached screenshots.




",['collegescorecard'],
Historical data of what country a city belongs to over a historical period?,"
We run a sports history site and occasionally we run into issues where a person was born in Prague, but in 1887, and we wish to display the correct country at the time of their birth rather than at the current day.
We have used geonames extensively, but we need a historical geonames, where we could enter a current territory and a date and find the correct historical representation of that location.  I realize that things like city annexation etc might complicate this somewhat, but for now I'd be very happy with source that lists a city's country over time.
","['geospatial', 'historical']","The approach I would take is to get a current latitude and longitude of the city and then look it up in a collection of historical shapefiles such as the ones discussed here. You would have to do that query yourself using PostGIS or similar software, as I don't think a service exists for this."
FICO Score data & Data on FICO score changes due to Delinquencies,"
I am looking for 2 sources of data:

FICO scores (the larger the dataset the better)
How FICO scores change after an individual is delinquent on a payment (e.g. rent, credit cards, etc.)

I know that there are multiple factors for 2) so I am looking for a data set that indicates some kind of event, as well as the score before the event and the score post the event that triggered the drop. 
Interestingly, there seems to be a lack of this data out in the open. I have asked on several forums but all I find is anecdotal evidence. 
Does anyone have an idea where I could get these datasets?
Thank you!
",['data-request'],
Where one can find historical and\or actual europe shore height data?,"
So remember Venice floods? I wonder where one can find a record on historical and\or actual Europe shore height data (especially for north Europe)?
","['data-request', 'geospatial']",
Hazard and NIOSH Code and Information for Prescription Drugs,"
Is there an API endpoint via OpenFDA or some other source that will give me Hazard and NIOSH codes for a specific drug based on an NDC number or some other code?
For example, the drug WARFARIN SODIUM- warfarin tablet has a NIOSH code of NT3.
",['openfda'],There is currently no endpoint which includes that implements these codes. My apologies for the very delayed reply.
How to have the assess to clinical data(PROSPECT),"
I am learning causal inference and I want to use a very popular dataset(the dataset is created in 1999). I find the webpage of it and many papars citing it. However, I never ever to find the download link. I wish someone could help me about it. It is a dataset belongs to clinicaltrials.gov.
The website about Prevention of Suicide in Primary Care Elderly: Collaborative Trial (PROSPECT). The funniest thing is that the website allows me to download the query results instead of dataset of study.
The paper using it Reducing Suicidal Ideation and Depressive Symptoms in Depressed Older Primary Care Patients: A Randomized Controlled Trial
If you guys can give me some advice about it or provide me several causal inference dataset(experiment data and observational data), I will be very grateful!
",['data-request'],Is the dataset linked in this page?http://research.bmh.manchester.ac.uk/biostatistics/research/data/Data from this trial are available on the Biometrics journal website as supplementary material to the paper:Direct link: http://www.biometrics.tibs.org/datasets/060225CF_biomweb.zipArchive link: https://web.archive.org/web/20200131081512/http://www.biometrics.tibs.org/datasets/060225CF_biomweb.zip
Data on radio station tower locations in Africa,"
Hey I am wondering if it exists somewhere a public access dataset or map of radio tower location for African countries. I am interested in towers transmitting signals in AM/FM waves for radio stations. 
I would be particularly interested in Liberia but any other country could work. I would be looking for something like latitude and longitude, owner and signal range. 
","['geospatial', 'africa']",
Testing my code with NoSQL Telecom data,"
Where can I find data sets that can be used to test NoSQL databases? It's better if its applied towards the telecommunications industry.
I have already tried using tabular data but i feel like it doesn't accurately represent reality.
","['data-request', 'json', 'telecom']","It's not a big dataset, but you can useTelecommunications Towers and AntennasConnecticut General Statutes §16-50dd requires the Connecticut Siting Council to develop, maintain and update on a quarterly basis a Statewide Telecommunications Coverage Database that includes the location, type and height of all telecommunications towers and antennas in the state.json format details: https://catalog.data.gov/dataset/telecommunications-towers-and-antennas/resource/adfc775a-7b39-4cf9-aac6-ee36925e3393raw json data: https://data.ct.gov/api/views/n7zh-5dbr/rows.json?accessType=DOWNLOAD"
Where can I get Wild Animals population(World Wide) Dataset per region?,"
Where can I get all Animals population(World Wide) dataset worldwide as per region yearly??

Looking for the Wild Animals populations Dataset for Machine Learning & AI Research purpose.

","['data-request', 'animals']",
Exercise Muscle Group Database / API,"
Im looking for a database or API where I can pull the affected muscle groups for a given exercise, preferably with a score for each group indicating how much its impacted by the exercise. Any help or guidance is greatly appreciated.
","['api', 'sports']",
Seeking block group data for USA for analyzing population change over time,"
I'm looking for a place to get data in the Census block group format that is not aggregated.
Previously I tried to use the ACS 5 Year Survey, but their data aggregated five years so I was unable to analyze it because it had been aggregated.
My goal is to analyze change in population over time at the block group level to help find areas that have can growing and shrinking in size over time. Data can be in any format, although CSV or shapefile would be preferred. 
Does anyone have any suggestions?
","['us-census', 'demographics', 'population']",
Is there any open data business directory?,"
Is there any open data business directory ?
Ideally world wide.
I did tried to find but not much coming up, there are companies house UK data in csv file but not able to find anything worldwide and on massive scale
","['data-request', 'uses-of-open-data', 'business']",
"Website to clearly explain ""why open data"" to non-governmental stakeholders","
I haven't found a clear website that I could share with non-profit organizations or companies, about how their opening of data can be used by the community for transparency, marketing, good PR, building a community, 3rd party apps, etc.
The challenge is that opening data is done for different reasons by each stakeholder, so there is no one-size-fits-all answer to the question ""why open data?"".
This resource from OKFN very much focuses on governments: https://okfn.org/opendata/why-open-data/
This question focuses on governments as well: What are good examples of how open data is driving community development?
But are there more general examples of websites or documents that could appeal to other potential data-sharers such as companies?
","['uses-of-open-data', 'releasing-data']","This could be a useful resource:https://opendatatoolkit.worldbank.org/en/starting.htmlWhen government data are made accessible and re-usable, they enable individuals, organizations and even governments themselves to innovate and collaborate in new ways.With these main pointsTransparencyPublic Service ImprovementInnovation and Economic ValueEfficiencyand then lots of links for further reading, policy guidelines, resources, etc...
"
What is the hypernym field in DBpedia?,"
I saw that there is a field http://purl.org/linguistics/gold/hypernym in DBpedia.
For instance consider the DBpedia page http://dbpedia.org/page/Humanities. The http://purl.org/linguistics/gold/hypernym of it is dbr:Disciplines.
It seems like these details are extracted from a resource called gold. However, I could not find further details on it.
I am interested in knowing from where DBpedia extracts this details?
I am happy to provide more details if needed.
","['uses-of-open-data', 'linked-data', 'rdf', 'ontology', 'dbpedia']",<http://purl.org/linguistics/gold/hypernym> is a property from the GOLD linguistic ontology.See http://linguistics-ontology.org/gold/hypernym.  
LD+JSON Use for SameAs Product,"
Assume you have an eCommerce site from which you sell some product.  You also sell that product on Amazon.  What would be the SEO implications of using the sameAs property in your eCommerce site's ld+json to link to your Amazon URL as well?  Is this a valid practice and would you gain anything by it?
For example:
{
   ""@context"":""https://schema.org/"",
   ""@type"":""Product"",
   ""sameAs"":[AMAZON URL HERE],
   ""name"":""My Product"",
   ""image"":""myproductimage.jpg"",
   ""description"":""my description"",
   ""brand"":{
      ""@type"":""Thing"",
      ""name"":""Brand""
   },
   ""sku"":""SKU"",
   ""mpn"":""MPN"",
   ""offers"":{ ... }
}

","['linked-data', 'json']",
Where can I get Eagle Species images Dataset?,"
List of Eagle Species
Eagles are large birds of prey which are members of the bird family Accipitridae and belong to several genera that are not necessarily closely related to each other. Most of the more than 60 species occur in Eurasia and Africa. Outside this area, just two species can be found in the United States and Canada, nine more in Central and South America, and three in Australia. 

Looking for the Eagle species Images Dataset for Deep Learning & AI Research purpose.

Below are listed all the members of the eagle family.
Collected From
White-bellied Sea-eagle Haliaeetus leucogaster  LC
Sanford's Sea-eagle Haliaeetus sanfordi VU
African Fish-eagle Haliaeetus vocifer   LC
Madagascar Fish-eagle Haliaeetus vociferoides   CR
Pallas's Fish-eagle Haliaeetus leucoryphus  VU
White-tailed Eagle Haliaeetus albicilla LC
Bald Eagle Haliaeetus leucocephalus LC
Steller's Sea-eagle Haliaeetus pelagicus    VU
Lesser Fish-eagle Ichthyophaga humilis  NT
Grey-headed Fish-eagle Ichthyophaga ichthyaetus 

Snake-eagles
Short-toed Snake-eagle Circaetus gallicus   LC
Black-chested Snake-eagle Circaetus pectoralis  LC
Beaudouin's Snake-eagle Circaetus beaudouini    VU
Brown Snake-eagle Circaetus cinereus    LC
Southern Banded Snake-eagle Circaetus fasciolatus   NT
Western Banded Snake-eagle Circaetus cinerascens    LC
Crested Serpent-eagle Spilornis cheela  LC
South Nicobar Serpent-eagle Spilornis klossi    NT
Kinabalu Serpent-eagle Spilornis kinabaluensis  VU
Sulawesi Serpent-eagle Spilornis rufipectus LC
Philippine Serpent-eagle Spilornis holospilus   LC
Andaman Serpent-eagle Spilornis elgini  NT
Congo Serpent-eagle Dryotriorchis spectabilis   LC
Madagascar Serpent-eagle Eutriorchis astur  EN
Bateleur Terathopius ecaudatus
Black-chested Buzzard-eagle Geranoaetus melanoleucus    LC
Black Solitary Eagle Buteogallus solitarius NT
Crowned Solitary Eagle Buteogallus coronatus    EN
Crested Eagle Morphnus guianensis   NT
Harpy Eagle Harpia harpyja  NT
Papuan Eagle Harpyopsis novaeguineae    VU
Philippine Eagle Pithecophaga jefferyi  CR
Black Eagle Ictinaetus malaiensis   LC
Lesser Spotted Eagle Clanga pomarina    LC
Indian Spotted Eagle Clanga hastata VU
Greater Spotted Eagle Clanga clanga VU
Tawny Eagle Aquila rapax    LC
Steppe Eagle Aquila nipalensis  EN
Spanish Imperial Eagle Aquila adalberti VU
Eastern Imperial Eagle Aquila heliaca   VU
Gurney's Eagle Aquila gurneyi   NT
Golden Eagle Aquila chrysaetos  LC
Wedge-tailed Eagle Aquila audax LC
Verreaux's Eagle Aquila verreauxii  LC
Wahlberg's Eagle Aquila wahlbergi   LC
Bonelli's Eagle Aquila fasciata LC
African Hawk-eagle Aquila spilogaster   LC
Booted Eagle Hieraaetus pennatus    LC
Little Eagle Hieraaetus morphnoides LC
Pygmy Eagle Hieraaetus weiskei  LC
Ayres's Hawk-eagle Hieraaetus ayresii   LC
Martial Eagle Polemaetus bellicosus NT
Long-crested Eagle Lophaetus occipitalis    LC
Cassin's Hawk-eagle Aquila africana LC
Black Hawk-eagle Spizaetus tyrannus LC
Black-and-white Hawk-eagle Spizaetus melanoleucus   LC
Ornate Hawk-eagle Spizaetus ornatus NT
Black-and-chestnut Eagle Spizaetus isidori  EN
Crowned Hawk-eagle Stephanoaetus coronatus  NT

","['data-request', 'images']","iNaturalist is another good place to find photographs of biological organisms. You can easily filter for images with specified levels of copyright. This link will get you to a page with observations of genus Haliaeetus in the public domain (copyrights waived by the photographer under the CC0 designation):https://www.inaturalist.org/observations?photo_license=CC0&taxon_id=5303To download a photograph, click on the observation, then hover the mouse over the photograph and click on the i symbol to get to the page for that photograph. There you can download the photograph in various sizes (small, medium, large or original). Each observation can have more than one photograph.For other genera of eagles, replace taxon_id=5303 with For photographs with some copyright restrictions, replace photo_license=CC0 with photo_license= plus any of the following:For bulk downloads, use the export query builder."
Aquifers and borehole wells in the UK,"
I want to be able to plot aquifers and borehole wells in the UK. I need to find out how far each aquifer and borehole well is from surrounding buildings and infrastructure.
Is the only way to do this using a base map?
Is there a way of downloading all UK infrastructure into QGIS version 3.10.0?
","['geospatial', 'uk']",You could dig in Environment Agency Open Data on Data.gov.ukSee also this page for UK Groundwater ressourcesFrom comments: 
Retrieving names of drug that include spaces from specific adverse reactions,"
I am trying to extract the top 100 drugs related to the highest number of adverse reaction of a specific type.
For example, I would like to extract the top 100 drugs that have been reported as associated with the adverse reaction ""nausea"".
The query I use is the following: 
https://api.fda.gov/drug/event.json?search=patient.reaction.reactionmeddrapt:nausea&limit=100&count=patient.drug.activesubstance.activesubstancename 

The problem is that, for compound names that include a space, the two terms are reported as separate (e.g. ""HYDROXYZINE HYDROCHLORIDE"" is reported as ""HYDROXYZINE"" and ""HYDROCHLORIDE""). As a consequence, ""hydrochloride"" is obviously reported on top for most of the compounds just for being the most used solvent in compound names, but the list goes on also for multiple other solvents.
How can I extract the complete compound names from the query?
Thanks
",['openfda'],I'm Jack with the openFDA team. Your query is just missing one modifier: .exact. I'm posting a fixed version of your example below. My apologies for the very delayed response.https://api.fda.gov/drug/event.json?search=patient.reaction.reactionmeddrapt:nausea&limit=100&count=patient.drug.activesubstance.activesubstancename.exact
Where can I find GIS data of Haiti Earthquake damage from the assessments made in 2010?,"
Where can I find GIS data of Haiti Earthquake damage from the assessments made in 2010? All sources seem to be dead links or PDF maps with no source data. 
","['data-request', 'geospatial']",
Soccer data set with time stamps for goals,"
There are many open source data sets available on soccer match data, but I have come across none which offer time stamps for goals specifically.
If someone could provide such a data set, I will be very grateful.
",['data-request'],"football.db offers (historical) ""free open public domain football data"" including information on timestamps refined to the conventional minute level.  Example schema for matches:"
Are there any data-sets having multiple multivariate time-series with causal relations between its attributes along with their description?,"
I need to perform some data-analysis task. For that I need data-sets containing multiple multivariate(multidimensional) time-series. Along with that I also need the description of each dimension, so the domain knowledge can be used for analyzing the data.
","['data-request', 'uses-of-open-data', 'time-series']",
From where does Costco get data correlating license plate numbers and vehicle make and models?,"
International warehouse shopping chain Costco includes functionality in their tire department website to enter a vehicle's license plate number to automatically determine the vehicle's make and model.
What data sources are they using?  Are there any open data sources?
I suppose they could be using http://www.vehicleregistrationapi.com, but that service charges $0.18USD per lookup in bulk.  I somehow doubt Costco is paying a third-party company every time a potential customer performs a lookup on their website.
","['data-request', 'government', 'transportation', 'licensing', 'cars']",
Swiss municipality elevation (altitude),"
I am looking for elevation data for Swiss municipalities (Gemeinden). I'd like something simple that can be joined to other data sources, for example, as a CSV,
postal_code    municipality_name    elevation_meters
8000    ZÃ¼rich    408

(to make it simple, elevation can be median or average over the entire surface, or just the elevation as a central point).
If the data isn't available, then some steps to generate the dataset from open data would be an acceptable answer.

OpenElevation project would work, but it involves passing individual latitude/longitude pairs, and the current API (github) seems to have spotty service. Another option is Google's Elevation API, but that would also require individual requests.
The official regional portrait doesn't have elevation, nor does it have the latitude/longitude that I could use to look up each municipality.
Official maps has municipality shape files and elevation, but I don't see any data download option.

License: for a hobby project, so most licenses will work
","['data-request', 'geospatial', 'geocoding', 'switzerland']",
"How to download data more than limit of option ""limit"" and ""skip""","
I am using this api https://api.fda.gov/drug/ndc.json. But as per limitation, we can't pass limit more than 100 and value for Skip is 25000. 
But in the data, if we have more than 100K + record. How we can download entire data.
We are trying to creating a  code to fetch all NDC code while using this API. 
API used: ""https://api.fda.gov/drug/ndc.json?search=finished:true&limit=100&skip=25000"".
As a result, it provides Meta information:
{
  ""meta"": {
    ""disclaimer"": ""Do not rely on openFDA to make decisions regarding medical care. While we make every effort to ensure that data is accurate, you should assume all results are unvalidated. We may limit or otherwise restrict your access to the API in line with our Terms of Service."",
    ""terms"": ""https://open.fda.gov/terms/"",
    ""license"": ""https://open.fda.gov/license/"",
    ""last_updated"": ""2019-12-20"",
    ""results"": {
      ""skip"": 0,
      ""limit"": 100,
      ""total"": 105845
    }
here total records count is **105845**, however when I try to fetch the record by skipping first 25000, its works fine, but it throws an error when Skip value is greater than **25000** :

{

""error"": {
    ""code"": ""BAD_REQUEST"",
    ""message"": ""Skip value must 25000 or less.""
  }
}
","['api', 'openfda']",
Thunderstorm Weather Data,"
Where can I find the average number of days with thunderstorms for each month for different locations in the United States? Does anyone know or have any links they know where it tells you that
","['data-request', 'weather']",
Is there any API which can provide information on different animal species,"
I am working on a project (not a programming project) where we require a lot of information about different species such as average weight, lifespan, height, population numbers, endangered status etc.
I have been looking for an API to provide this information so that I don't have to manually search for it for over 100 species and I can't find anything that provides the information.
The best I have found so far is an API provided by the IUCN Red list, but this doesn't have all the information required (e.g. no lifespan data or weight)
Are there any APIs available which will provide this information?
",['api'],
Dataset for musical Instruments recognition,"
I am looking for a ""rich"" Dataset to Teach my model to separate Music instruments.. any Suggestions? I found the URMP Dataset but it doesn't have many files. I appreciate your help!!
","['data-request', 'machine-learning', 'audio']",
World dataset of hospitals,"
I am looking for a (global) dataset of hospitals: mainly locations, but if possible also names, sizes, number of beds. As far as I can tell, this does not exist yet, but perhaps there are good starting points!
","['geospatial', 'medical']","healthsites.io is an open data effort to map healthcare entities (hospitals, clinics, pharmacies, private practices, etc.) worldwide.  The data is drawn from OpenStreetMap and at a minimum provides the name and geographic coordinates of each healthcare entity.  There is a OSM data model for health sites, details provided here.  The data is released under the Open Data License."
changes in mimic iv - where to find details?,"
I see new repos created for mimic iv. Where can I find information about planned changes to mimic?
It is quite exciting to see a new version and users would be interested to hear more perhaps.
",['mimic-iii'],
"Does anyone have better maps for the east coast of the USA, or the entire USA to use with XASTIR directly?","
I have a fresh install of XASTIR running on a Pi 3, but the maps are pretty poor at showing details. Does anyone have any mapps they can share with me for my XASTIR system, that are better than what the program comes with?  I would like the USA, or the eastern side of the USA. I run an aprs system in Florida, so even Florida would be great. 
73'   Joe KQ4BX
","['data-request', 'geospatial', 'usa']",
Where can I get in-car-camera-data with speed?,"
I'm searching in-car-camera data set with vehicle speed at that time. If there is any place where I can get those data free?
","['data-request', 'cars', 'video']",
Rent and Housing Prices by Postal Code / Local Authority Code,"
I am looking for databases that provide information on the development of mean / median house prices and rents in European countries, particularly for UK, NL, CH und SE (rental market data). Do any of you have an idea where I can find something helpful, be it for free or not. I would very much appreciate your help!
","['data-request', 'europe', 'postal-code', 'real-estate']",
"Looking for “old” Parish & County Boundary Data set for Queensland, Australia","
The latest datasets from QSpatial no longer contain the Parish & County info. It is no longer used in Queensland. I am doing some research into historical mining activities and this dataset would be very helpful, so I don't have to create my own :) 
Does anyone have a copy of the 'old' Cadastral (DCDB) dataset that still contains the Parish & County columns?
","['data-request', 'geospatial', 'historical', 'australia']",
Benchmark datasets for regression on categorical features,"
There are a number of widely used benchmark datasets for machine learning algorithms available, but most of them are for regression or classification on numeric features.
I'm looking to test an algorithm that performs regression on categorical input features. Are there any readily available benchmark datasets that fit this description?
","['data-request', 'machine-learning']",A good place to start is browsing the UC Irvine Machine Learning Repository.  Note that you can sort by dataset task and attribute types.
Soccer data set with time stamps for goals,"
There are many open source data sets available on soccer match data, but I have come across none which offer time stamps for goals specifically.
If someone could provide such a data set, I will be very grateful.
",['data-request'],"football.db offers (historical) ""free open public domain football data"" including information on timestamps refined to the conventional minute level.  Example schema for matches:"
Request: food consumption and heart failure incidence dataset,"
I am looking for a dataset that would indicate peoples eating habits (I'm mostly interested in the types of food consumed) and heart failure incidence. Has anyone come across such dataset?
",['data-request'],
Where can I find Investopedia data set for download? [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 3 years ago.







                        Improve this question
                    



I want to train a NLP model based on investopedia data set but I am not able to find it.
","['data-request', 'nlp']",
Seeking household income district wise for entire India,"
I need to combine census data with household income data. I was able to obtain census data district wise for entire India and join it with the district-level shapefile, I need data on household income district wise for entire India.
","['census', 'india']",
Are version control storing solutions a good option to store Medical Imaging open data?,"
We are working on several medical imaging projects (i.e., BreastScreening, MIDA, and MIMBCD-UI) that deals with a huge amount of data. From medical images and data at the following modalities: (1) MammoGraphy (MG) in both CranioCaudal (CC) and MedioLateral Oblique (MLO) views; (2) UltraSound (US); (3) Magnetic Resonance Imaging (MRI); to (4) text; and (5) annotations. We already have formal protocols with the clinical institutions, as well as data agreements with both the National health data responsible committee and patients. Our purpose is to publicly share the presented data after scientific publication. As follows, we will show the list of our current data size.
Summarizations list of current data to store:

Breast Cancer Patients = ~400 cases;
Multi-Modality of Medical Images Dataset = ~1200 images;
Annotations Dataset = ~250 annotated cases;

The question is regarding how should we share this amount of information. Our first thought was to store it on a version control storing solution, such as GitHub or GitLab, for instance.
So we do the following question:
Are version control storing solutions a good option to store Medical Imaging open data?
","['medical', 'releasing-data', 'images', 'git']","I'd rather suggest trying the open science framework (https://osf.io), as the above is one of their claimed aims."
Seeking boundaries of administrative units of Ireland,"
I need to download a shapefile with the boundaries (polygon) of the administrative units (localities level) for Ireland. I have searched diva-gis and osm, but they do not have data to that level.
","['geospatial', 'ireland']",
Order receipt of bank transactions,"
I am looking for Pictures of order receipts of bank Transactions.
Optimally for Instruments like Shares, Options or funds.
Would be optimal if data Quality is good enough to be processable by ocr engines.
","['data-request', 'finance', 'bank']",
Package NDC Query,"
I am trying to query OpenFDA to get some data on the following product:
https://ndclist.com/ndc/52380-0001/package/52380-0001-3
I have tried querying 52380000103, 5238000013, 5238000103 and 523800013 with no luck.  I'm hoping there is someone here in the community that can shed some light on why I am not getting any results.
I also tried an FDB query for those of you who use First Data Bank with no results.
",['openfda'],"Bill,Here's are two queries that might work for you:Against the openFDA NDC SPL Data Elements APIhttps://api.fda.gov/other/nsde.json?search=package_ndc:52380-0001-3Against the openFDA Drug Product Labeling APIhttps://api.fda.gov/drug/label.json?search=openfda.package_ndc:52380-0001-3"
403 Forbidden accessing OSHA violations (X-API-KEY in header),"
X-API-KEY with key value in header of a request to https://data.dol.gov/get/violation, but still receiving 403 Forbidden ""Invalid API Key"" error. Is anything missing/incorrect in this request? Any help is greatly appreciated!

","['api', 'labor']",
How to find the variable in javascript which gives the positions of the competitors on the site sapsailing?,"
As part of my studies, I’m looking for a way to find the variable in the javascript representing the positions of competitors on this site to retrieve the data.
https://www.sapsailing.com/gwt/Home.html#/regatta/races/:eventId=2d42185c-c914-4042-814f-14108218b3a3&regattaId=HWCS%202020%20Round%201%20-%20RS:X%20Men
",['education'],
Elliptically Distrbuted Numerical Data,"
I  am doing a research about outlier detection in Multivariate Elliptically Shaped Numerical data and I have searched a lot for a matching dataset yet I couldn't find any. Any help will be appreciated in finding such dataset. 
I mean if you visualize the data (in two dimensions) you would see the data points form an elliptic shape.
","['data-request', 'research']",
Redistribute tweets without user id or tweet id,"
I have a dataset of tweets annotated by a group of people and I want to distribute it in Github without the user id or Tweet id, do you know if that possible?
only the tweet_text and the label.
Given that the work where I collected these tweets was accepted recently in a NLP research conference. Thus, I want to add a link for the dataset in the article.
","['releasing-data', 'social-media']",
satellite images - whole planet - on premise,"
I've been tasked with creating a satellite map server for whole planet which is hosted on premise. It needs to be satellite images at a higher resolution than sentinel 2 (https://s2maps.eu/) - You must be able to see the road
I've done lots of research, there is a lot of info, and some of it way out dated and new things popping up all the time
my question is
1) Is there a provider of med-hi res satellite images for free (or low cost, under $5000)
this will be used for commercial use so needs to support this type of license.
The data does not have to be current, 2017 or newer is acceptable
","['data-request', 'geospatial', 'images']",
Corpus suggestion for financial domain,"
I am looking for a financial corpus or any form of publicly available financial texts which is replete with technical terms and acronyms.
Any suggestion is appreciated
","['nlp', 'finance', 'corpora', 'text']",
Data on Medicare Advantage Plans,"
I'm looking for data on Medicare Advantage Plans: eligibility, cost, coverage, etc. Where can I find it/
",['data.gov'],
Seeking information about USGS Quadrangles dating back 1945?,"
I work for the US Forest Service and on my forest we have Map cabinet that has all the hardcopies (not digitial) USGS quadrangle that has years on them such as 1954, 1968 to now. The map cabinet is on our office and we will have more at another building that I am going through...
What I am trying to find information from these dates should I find online ?
Do you have the information that may be very helpful to me ?
I am working on map inventory to the Excel spreadsheet
","['data-request', 'geospatial']",
Is there an alternative to Google Maps to find GPS coordinates of a place in Germany?,"
For probably any place on Earth, you can search it in Google Maps, make right-click, pick the option ""What's here"" and you get GPS coordinates.

If I don't want to use Google Maps API, is there an alternative open API to get GPS coordinates by address? To be less broad, say in Germany?
","['geospatial', 'api', 'location']",
Contemporary Geo-referenced ethnic groups in Russia,"
I need geo-referenced data on ethnic groups specifically in Russia (global data would work fine also as long as it includes Russia). 
So far I can only find the GREG dataset: http://worldmap.harvard.edu/data/geonode:GREG_0vV. 
However, this data is based on the classical Soviet Narodov Mira or ""Atlas of the peoples of the world"" which was completed in 1964. The population movements that occurred with the fall of the Soviet Union with ethnic groups returning to ancestral lands after forced relocation, this data seems outdated especially in the periphery and Southern regions of Russia.
Does anyone know of contemporary geo-referenced ethnic group data for Russia?
","['data-request', 'geospatial', 'russia']","These Russia census bureau regional level data on nationalities may be what you need https://www.gks.ru/free_doc/new_site/perepis2010/croc/perepis_itogi1612-tom4.htm
Take p.4 https://www.gks.ru/free_doc/new_site/perepis2010/croc/Documents/Vol4/pub-04-04.xlsx
and there are more data from 2010 population census"
Solution Improvement,"
I need to improve the process of saving web data into a database.
Current process: 

Web data downloaded to a file
file uploaded to an online repository
distribution list emailed with access credentials
user in another institution receives access credentials and saves the file onto a shared network drive
user emails data processing team to make them aware the file is now in the usual location for data ingest
Data team executes ETL process to ingest data into a SQL DB

",['database'],
Terrain data for Germany [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 3 years ago.







                        Improve this question
                    



Hello experienced people!!
Being a student, I am in need of free of cost terrain data of Germany which is accurate too.
Actually my Task is to get terrain data for smaller size like a plot for a building anywhere in Germany and plotting that terrain in Autodesk Revit. My Ist priority is to to Use Autodesk Revit only but in between software like QGIS and Civil 3D could also be used for terrain modeling and then bringing that terrain to Revit.   
","['data-request', 'geospatial']",
How to get communes boundaries of Europe?,"
I am looking for an up-to-date communes administrative boundraries (LAU) of several countries in Europe (France + adjacent countries). I need it to be quite precise (less than 5m), since I intend to use it to retrieve commune names from a point (bus stop). I was thinking about OpenStreetMap and Overpass Turbo, but the coverage seems to be too wide to be processed, even country by country, here is one of my resquest : 
[out:xml][timeout:600]; (
  area['admin_level'='2']['name'='France'];
  rel['boundary'='administrative']['admin_level'='8'](area);
);
(._;>;);
out;

I also found :

[something interesting] on the eurostat website, but it is from 2013 ...
[Official LAU], but it not precise enough for my needs 
[GDAM data], but again, not precise enough

","['geospatial', 'city', 'europe']",
How do I get historical data from coinmarketcap.com?,"
If you scroll down on this page:
https://coinmarketcap.com/historical/20150503/
There is something that says: Total Market Cap: $3,863,780,096
Notice the date is given in the URL. How can I loop through all dates from 2013 to 2019 and get all this data. Can tip in crypto if anyone is interested in helping me.
","['data-request', 'web-crawling', 'python', 'scraping']",
Query regarding download of CNDDB data for the State of California,"
I would like to inquire about online resources from I could download CNDDB (California Natural Diversity Database) data for the State of California. The CNDDB is basically a repository of California's rare species and natural community types (https://www.wildlife.ca.gov/Data/CNDDB/About). I was able to find certain online links to where you can view the data however there were no options available to download this data as point/polygon shapefile or a file geodatabase.
","['data-request', 'geospatial', 'usa', 'data.gov']","Detailed spatial data seems to require a CNDDB subscription.You could put together quad level data (USGS 7.5 minute topographic quads) with this publicly available endpoint that lets you query what species are in a particular quad.For example, for quad 3811957: https://apps.wildlife.ca.gov/bios/rest/Cnddb.ashx?o=cnddbQuickView&p=QuadSpecies&q=3811957&a=1"
Online sources for elevation values and resources distribution,"
I'm looking for an open database from which I can download, for a selected area, both the elevation map (usually I use this one) and a map of the resources underground (ideally it should be oil or gas). As a resolution, between 30 and 90 meters would be perfect. Do you have suggestions on where to look? As a file format, I would prefer to work with .hgt, .flt or .hdr. 
",['geospatial'],"A reasonable approach would be to obtain layers of (1) elevation data such as SRTM and (2) natural resources and overlay them.For (1), see EarthExplorer and look under the section ""Digital Elevation"".  Note that the link you posted is likely your best best for the data in .hgt format.  For (2),  the U.S. Energy Information Administration has a set of maps and geospatial datasets (i.e. Shapefiles) on oil and natural gas resources.  Alternatively, the USGS National Geologic Map Database might have some useful data on land resources.  Under a broader definition ""resources underground"", the list of USDA ERS Natural Resources Datasets has several interesting sources for geospatial data on natural resources.  Note that since the specifics were omitted in the OP, I have assumed a geographic scope of the United States."
Is there a bigger discrete-valued dataset to train an AI to determine whether to play tennis based on weather conditions?,"
This table comes from Chapter 3 in Tom M. Mitchell. Machine Learning (free)

Is there a bigger dataset (discrete-valued) like this, to train a learner in making the PlayTennis determination?
The dataset should include: 

Outlook, as a concise weather forecast like sunny/overcast/rain/snow
Temperature, generalized like hot/mild/cool/cold
Humidity, generalized like high/normal/low
Wind, generalized like weak/strong
PlayTennis - the determination whether to play tennis or not, based on the other variables

",['data-request'],"My understanding is that PlayTennis itself is limited to 14 examples (see this version of the data on Kaggle), so if you wanted more you'd have to generate them yourself.If you're not bound to this specific dataset, there exist many alternative datasets with categorical features used in discrete classification tasks.  See that UCI Machine Learning repository.  Try filtering to ""Categorical"" and/or ""Mixed"" attribute types and ""Classification"" for the default task.  Some potential candidates datasets for your task (with mostly categorical features):Note that it would be up to you to define the model in any of these cases (e.g. the features inputs and target outputs)."
Knife crime in the UK/London,"
Knife crime is a big issue in London. The recent terrorist attack on Tower bridge is another dramatic example. I'm looking for open data on the location of these crimes in London or the UK. I don't know if that can be on any help Understanding the phenomenon. 

I've looked on https://data.police.uk/data/ but the categories is not accurate enough. Knife crime falls into the category Violence and sexual offences.
I've also looked at the office of national statistics website which as a page dedicated on it, but it rather looks like a sum up.

","['data-request', 'geospatial', 'crime']",
looking for database with companies and its SIC codes,"
I am building model to predict that is something similar to SICCODE.com, in search if I give ""apple inc"" as input, it gives me all related to apple with its sic codes and location.
apple inc       cupertino,ca, 95014        us
apple bank for savings      newyork, NY,10172       us

I looking for a database which contains all company names in US and its location and its SIC codes.
","['data-request', 'usa', 'industry']","The data exists but it is unlikely to be open.  From the U.S. Census Bureau (recall there is a crosswalk between SIC and NAICS codes)Title 13, U.S. Code, Section 9 (a) prohibits the U.S. Census
Bureau from releasing information on a specific business including
NAICS codes. Visit our Data Protection and Privacy Policy Web site to
obtain more information on Title 13. There are a number of private
research firms that provide NAICS codes and data for specific
companies, often for a fee. The U.S. Census Bureau cannot verify the
accuracy of the codes or data provided by these companies.An example of such a firm would be NAICS Association."
Methane and ruminant liveweight,"
I'm looking for data sets that have both methane data and liveweight of sheep/cattle. Ideally on an individual basis, but herd level is better than nothing.
","['data-request', 'biology', 'climate', 'agriculture', 'animals']",
Why is opencorporates considered open data when nothing can be downloaded?,"
I just discovered opencorporates.com, and they boast of being ""open data"" with these properties:

The database is not published
Downloading the data through the API 1 time in 1 year will cost around $1 million.

Those are some massive barriers to using the data.
Can you help me understad how opencorporates is ""open data""?
","['api', 'uses-of-open-data', 'open-definition', 'opencorporates']","That's a great question.  Seems like the data itself is under an open license but the company charges for API access to it, presumably for the effort they've gone to consolidate the data and for running the API service.  See the legal info https://opencorporates.com/legal/licence and in particular the ""The OpenCorporates database"" section of the page.  The OpenCorporates database is licensed under the Open Database
  License. A plain language summary of the ODbL is available on the Open
  Data Commons website.We source the information in our databases from government and other
  sources through a variety of means including: directly from government
  websites and APIs, from publicly available datasets, or through
  Freedom of Information requests. We spend a lot of time, effort, and
  even money in getting this data and turning it into a workable and
  highly usable resource.We do not claim any rights over the information we receive from our
  government sources, and attribute them whenever possible. This is
  known as the ""Contents"" in the ODbL license.We do however claim rights over our database of this information.What's interesting in that document is that there is mention of free API access in addition to paid access but I could not find any additional information access.We offer free access to our website and API, and also paid-for access
  to our API. If you have agreed to a paid-for contract for use of the
  API, these terms and conditions supplement that contract and, in cases
  of conflict, the wording of the paid-for contract will take
  precedence.I welcome edits to expand this answer and hope someone else can also give a better explanation."
"Why is so many ""PrivacySuppressed"" entries?","
After downloading ""Most Recent Data by Field of Study"" data, almost all the entries are ""privacySuppressed"". Does this mean that there's actual meaningful data to suppress or is it a cop out to not being able to provide actual data?
https://collegescorecard.ed.gov/data/
",['collegescorecard'],"It's standard practice -- and a good idea -- to suppress cells that have small numbers of observations.  Mainly for protecting the privacy of the individuals whose data are being reported, but also because statistics from small samples are unreliable due to their large standard errors.I've only looked at a few dozen schools' data.  It appears that the College Scorecard suppresses cells with 20 observations or fewer.  On the one hand, that's a larger minimum size than is usually used elsewhere (10 is a common number, but studies with small sample sizes might use 5 or even fewer).  On the other hand, recent research into ""differential privacy"" shows that even simple descriptive statistics with fairly large sample sizes can inadvertently reveal private information to a determined  investigator (or hacker)."
Trouble finding GIS annual climate data for Spain,"
I'm trying to get annual mean temperature and annual precipitation for Spain by province. I've tried going through NOAA, AEMET, and a few other resources but I'm having a hard time getting data in a format I can understand or utilize.
AEMET keeps giving me tar.gz files filled with a file that has no type. I haven't had any luck getting that into anything usable and don't even know if its supposed to be a shapefile, an .e00 or what.
I don't necessarily need the data in a GIS format. I just want something that I can easily convert or aggregate to a by province format which I could then join to a province shapefile I have. 
I saw this community linked in a GIS stackExchange answer and am hoping it can help me with this.
","['data-request', 'geospatial', 'climate']",
Clarkson Keystroke Dynamics dataset,"
I'm reading in this article (Shared Research Dataset to Support Development of Keystroke Authentication) that Clarkson university has released a dataset with user keystrokes and timing information. 
However, the link to the dataset has expired. Does anyone know where I can find this dataset?
","['data-request', 'computing']",
British pubs & restaurants : opening times and location,"
Google maps shows nearby pubs  and restaurants. But it does not show if they are currently open, which is frustrating at some times of day.
If I google search for the establishment, they often have the opening hours.
I would like to create a mash up of these, but doubt that google would appreciate me scraping its data.
Is there any open database of British eating & drinking establishments with  

type of establishment  
location (either address, preferably with post code) or lat/long  
opening hours

Even if it is incomplete, my main aim is to say ""if you walk there now, it will definitely be open"".
","['uk', 'restaurant', 'location']","In theory, OSM should store the data (although unlikely to be as actual as other non-open sources)https://wiki.openstreetmap.org/wiki/Key:opening_hourshttps://wiki.openstreetmap.org/wiki/Tag:amenity%3DrestaurantBulk download: http://download.geofabrik.de/europe/britain-and-ireland.htmlSee here for how to download bulk data and how to parse records to keep only certain keys/tags."
Looking for an API with average min / max temperatures per month for every country,"
I cannot find any open api data for the average minimum and maximum temperature on a monthly basis per country.
An example:
Country=Netherlands
Month=October
Min=5
Max=13
Any help would be greatly appreciated.
","['api', 'weather']",
Error in fda_fetch: Too Many Requests (RFC 6585) (HTTP 429),"
I am getting this error while having some tests with https://github.com/jonathanglevine/openfdashinyapps
What is the limit of requests per day?
If I provide account info with secret and token would I have the same limit of requests?
",['api'],
open data for plant disease?,"
I'm looking for an open data to use for detecting crop disease based on weather data. For example, to predict late blight disease for potato crop.
A dataset where given daily hourly temperature, humidity and rainfall there is a label that expresses whether the disease manifests or not
","['data-request', 'agriculture', 'disease']",
Where can I find labeled sentences?,"
I am looking for sentences csv labeled like this, or something similar: 
I am going to run a marathon., achievement
I miss my high school friend., friendship
I would like to lose 10 pounds, achievement


Are there any resources that have labelled data like this?
","['data-request', 'nlp', 'text']",
Datasets for Topic Modeling,"
I'm looking to try and use deep learning methods for topic modeling as opposed to the more traditional methods of lda and word embedding methods. However, I'm having trouble finding good labeled datasets for this task.  So far the best that I've seen is the New York Times Dataset which I can't use due to licensing constraints. I've also seen the 20News Dataset but it only has twenty categories so it probably won't scale well to other domains.
Are there any other good datasets out there that I'm missing that can be used for topic modeling?  I'm happy to use a dataset that isn't explicitly meant for topic modeling; as long as it has some sentences/paragraphs that are tagged or labeled that should be fine.
","['data-request', 'nlp', 'text']",
2010 Russian Census Data in English,"
I am doing a research project and would like to access Russian census data from 2010 that is broken down by region but I do not speak Russian. Does anyone know if this data is available in English? The 2010 data is available here in Russian: https://www.gks.ru/free_doc/new_site/perepis2010/croc/perepis_itogi1612.htm
","['data-request', 'census', 'russia']","I've only seen this data in Russian, unfortunately.
From 2010, you can find census population data on Wikipedia but it's also in Russian.  The link is here. Note that you can try the English translation of this page by clicking the English link under Languages header in the left sidebar.If you need help with translation of titles of regions, please do not hesitate to contact me."
Manufacturing locations of cotton swabs,"
I was wondering if the manufacturing locations of cotton swab brands/ companies had been curated. For example where are q-tips manufactured? USA?
","['data-request', 'geospatial', 'products', 'industry']",
Dataset of allergies,"
I'm looking for a dataset containing the following:

for each country, for each allergy types, number of humans affected by the allergy.
if possible, break down per gender and age.

","['data-request', 'medical']",
Where can I find some open data about public transport flow?,"
I am just finding some data about public transport flow which may meet these requirements as follows:

It contains the flow per hour at a place in one city such as the number of passengers at the bus stop in London at 11 am.
the flow change over time and different areas in a city.

",['public-transport'],
Finding image dataset of color-blindness charts,"
I had an idea to train a CNN to classify numbers seen on color-blindness charts like the one seen below.

I have Google for such dataset but did not find anything. How should I approach this?
","['data-request', 'machine-learning', 'images', 'classification']",
Frequently updating data for Singapore,"
This sounds vague, because it can have many, many possible answers (I hope), but I will accept any of them.
Basically, I want to demo a product, which has an eInk display (plus WiFi and BlueTooth), to a company in Singapore:

To give them an idea of how it can be used to display their data, I would like to display some Singaporean data, maybe population, or similar.
The catch is that I want it to updated every second or so, displaying the temperature wouldn't be much good as it rarely varies.
I don't care what the data is, so is it on topic to ask for some Singaporean data which changes every second or so and has a gratis HTTP(S) API? I would like something to grab their attention and get them wondering how we can use this (cheap) device.
","['api', 'singapore']",Singapore offers an API for pollution levels (among 13 other real-time APIs)try it in their docs page: https://data.gov.sg/dataset/psior with curlor with the browser: https://api.data.gov.sg/v1/environment/psi(not sure if any of these 14 real-time APIs are actually enough real-time)
Land cost data of the region Caucasus,"
I am using the R package 'prioritzr' to identify new possible conservation areas in the lesser caucasus for different species.
One main data input to solve the problem is the average land cost per grid cell (planning unit).
So far I did not find any data about land cost in the region of the lesser caucasus.
Also trying different approaches by using the GDP in combination with population densitiy and landuse classes did not lead to a satisfying outcome. Simply by mulitplying these values led to a very high difference between min/max which resulted in a not usable dataset for the problem-solver.
Do you have any suggestions how to get land cost information about the region in the lesser caucasus or do you have other approaches how to solve the problem?
","['data-request', 'geospatial', 'economics', 'land']",
Seeking shapefiles for mapping innovation districts,"
The Brookings Institution has been promoting Innovation Districts as a useful geographical concept since 2014 (for example here and here). I should think that mapping Innovation Districts precisely would be part of that research and indeed some maps are shown here and there. However, I have not been able to find a unified source of shapefiles for US Innovation Districts (even though the research has focused on the US). Maybe the sources vary city by city or maybe shapefiles are not systematically available even for the cities covered by the initial study. What are sources of shapefiles for all Innovation Districts or failing that sources for existing ones?
","['data-request', 'geospatial', 'usa', 'district']",
Looking for an endpoint to retrieve warning letters,"
You can search for warning letters https://www.fda.gov/inspections-compliance-enforcement-and-criminal-investigations/compliance-actions-and-activities/warning-letters
","['data-request', 'openfda']",
Ski resort's lifts status and trains length API,"
Im looking for API that contains Europe's ski resorts data that include lifts and trails status, max/min altitude, ski pass information etc.
this is the closest thing that i have found:

http://docs.clientservice.onthesnow.com/docs/index.html

but they are not responding to my emails so can't create an account and get access.
","['api', 'ski']",
Carbon emissions data for UK companies (and beyond UK too),"
I am searching for a carbon efficiency reporting for UK government. To my understanding this data should have been reported in the past as per the CRC scheme in this or similar pages. However it appears as data has been removed. Anybody knows where to find this data, or any other data source on carbon emission by companies?
","['data-request', 'government', 'uk', 'europe', 'environment']",
Free Database of Uniform Commercial Code (UCC) Data?,"
I am looking for Uniform Commercial Code (UCC) data to download and sift through. I would be most interested in Article 2 and 2A which is sales and leases, respectively. This is also known at UCC-2 data. 
Does anyone know where I might find a database of UCC-2 data, by U.S. state, for free?
","['data-request', 'download']",
Units in Structure - Census,"
When assessing the US census data's housing characteristics by occupied housing, it provides a breakdown by Units in Structure. My question is should I look at the total units in a 2 unit apartment structure and divide by 2 to determine number of buildings that are 2 units or is the number listed the total number of buildings with 2 units. 
Based on the snapshot below the total number of buildings with 2 units = ?

","['us-census', 'census', 'documentation']",
Where can I find economic multilateral treaty data?,"
I am doing a project on multilateral treaties and am having trouble finding a data set on multilateral economic treaties. I am looking for data with signature and/or ratification dates. Does anyone know of a dataset or website that holds this? Here is an example webpage with the necessary data but for only 1 treaty:
So far I have only found good aggregated information on bilateral or plurilateral treaties. The World Trade Organisation's Regional Trade Agreements' database is a good example of this
","['data-request', 'economics', 'global']",
High frequency public health or health care data,"
What public data are out there that contain health or health care events or outcomes (mortality, encounters with health care providers, etc.) and are available at a daily, weekly, or monthly frequency over relatively small geographic units? 
","['data-request', 'medical']",
Traffic density data source,"
Data: I am looking for traffic density for a given place, preferably averaged over a given area for the last year. Traffic density is defined as the number of vehicles per unit length of the roadway. 
Context: We're building an non-profit application that lets a user choose a city to live based on multiple factors, including traffic density. My assumption is that critical traffic density, that leads to traffic congestion, has impact both on commute time and quality of neighborhood. For instance, this is traffic density map from TomTom Traffic Index. I placed arrows to show cities with high, medium and low congestion at the moment:

Region: This is for large and small cities and villages only in Poland, Europe.
License: This will be a non-profit application and we're building only a MVP, so at this stage we don't want to invest any money. Any free for non-commercial use license would be good.
Format: . It can be both structured (e.g. via JSON, CSV file or API) or not well-structured source. I am not afraid of screenscraping. Preferably, that should be a source we can query on regular, but not necessarily frequent basic (yearly) to update our estimates.
Authority: I do not have limitations here. Most of the data providers in this domain comes from anonymous GPS devices and are collected through routing applications like TomTom or Google Maps.
","['data-request', 'transportation']",
How to interpret geological data for Africa,"
I am currently working on a project where I need a geological map of Africa for groundwater potential. I have downloaded the Surficial geology of Africa from the U.S. Department of Interior (map URL). I need assistance on how to interpret the data.
","['geospatial', 'data.gov']","This is not an answer.I downloaded the ""geo7_2ag.zip"", unzipped it, ran ogrinfo -al on the geo7_2ag.shp file and learned the following:The shapefile contains 11,977 polygons, each tagged with a GLG value.There are 44 different GLG values. Some of these are: DS, H2O, Mi, O, S_dMost of these values are explained in geo7_2ag.shp.xml and appear to represent geological eras. For example, ""DS"" means ""Devonian-Silurian"", ""H2O"" means ""Water (River or Lake)"", ""Mi"" means ""Mesozoic Igneous"", and so on.The data is imperfect. The ""Cm"" and ""O"" values in the shapefile are not in the XML file. The ""JI"" and ""KI"" values are spelled with a capital ""eye"" in one of the files and a lower case ""ell"" in the other.The geo7_2ag.e00 contains 4 layers of data:an ""ARC"" layer with 25,285 line stringsa ""CNT"" layer with 11,978 pointsa ""LAB"" layer with 11,977 pointsa ""PAL"" layer with 11,977 polygonsAccording to https://gis.stackexchange.com/questions/54730/e00-file-structure these data layers are intended primarily to transfer data between formats and are probably not important for you, the end user.As a general note, gis.stackexchange.com might be able to help more with further questions, and you might look into qgis, a free tool to help interpret and manipulate geographical data."
API documentation still accurate?,"
My students and I are trying to access child labour statistics data from the Sweat and Toil dataset, with the endpoints as described on https://developer.dol.gov/others/sweat-and-toil/, and using the format as described at https://developer.dol.gov/beginners-guide/#apiv2.
When trying (in Python) to do so with code like the following:
response = requests.get(""https://data.dol.gov/SweatToilAllStatistics"", headers={'X-API-KEY': 'KEYREMOVED'})

we get a 404. For some other data sets in Sweat and Toil (and other v2 datasets we've tried), we get a 403 with the following response:
{
    ""status"": """",
    ""error"": ""Invalid API Key""
}

But when I use this exact same API key on some v1 API datasets, e.g.,
response = requests.get(""http://api.dol.gov/V1/DOLAgency/Agencies/?KEY=KEYREMOVED"") 

it works fine, so I actually don't think ""Invalid API Key"" is the true issue here. The same issue occurs when attempting this with curl. Any help anyone might be able to offer would be much appreciated.
","['api', 'labor', 'documentation']",
Common text data sets in form of panel data,"
I want to test machine learning tasks on time-divided textual data set. For this purpose, I want to use a common text data set which is already validated and ""good"" for use. I already found a Web of Science data set from this source:

K. Kowsari, D. E. Brown, M. Heidarysafa, K. Jafari Meimandi, M. S.
  Gerber and L. E. Barnes, ""HDLTex: Hierarchical Deep Learning for Text
  Classification"", 2017 16th IEEE International Conference on Machine
  Learning and Applications (ICMLA), pp. 364-371. doi:
  10.1109/ICMLA.2017.0-134

Unfortunately, the data set does not include data about the time of the publications, which I really need for my algorithms. Can anyone recommend a common textual data set for me which is divided into time windows?
","['data-request', 'nlp', 'text']","In addition to the answer by @Erwan, I came acrossBoth are curated lists of text datasets for NLP tasks.  A few datasets that may fit your requirement of temporal variation:Since you're looking for datasets that have been used in previous NLP studies, I suggest searching these lists for data from Kaggle competitions or academic papers."
Tagged images of bald and balding men,"
Is there an image dataset of bald and balding men? Best would be classified/tagged images with labels like ""bald"", ""not bald"", ""early balding"", ""etc"".
Related links:
https://matthewbilyeu.com/blog/2019-03-21/the-boombox-incident
my source & comments: https://news.ycombinator.com/item?id=19462007
similar question: https://opendata.stackexchange.com/a/14060/1511
","['data-request', 'images', 'faces']","There is the Category:Bald men on Wikimedia Commons, right now with 525 images."
how to download mivia Road audio event dataset,"
I want to download the Mivia Road audio event dataset. I have already registered on the website a month ago but they are not responding, my project's last date is 10th November so can anyone give me that data?
link: https://mivia.unisa.it/datasets/audio-analysis/mivia-road-audio-events-data-set/
","['data-request', 'audio']",
Is there a toy dataset which is not linearly separable in 2d and linearly separable in 3D?,"
This figure is to illustrate a hyperplane

Is there a toy dataset could be used to draw this kind of figure with Python?
in other words, is there a dataset which is not linearly separable in 2d and linearly separable in 3D?
",['data-request'],"You could generate such a dataset using Python.  A simple approach would be to generate a set of (x, y) coordinates, partition the set, then assign a distinct value for the z coordinate for each partition.  An example with 100 points divided into 5 linearly separable partitions:Plots of the data in 2 and 3 dimensions:
"
Database with categorised cloud (meterology) pictures,"
I would like to ask if there is a database of Cloud Pictures
classified by type.
Example:
The following Picture would be classified in the category: ""Cirrus uncinus"".

","['data-request', 'meteorology']","Zhang, Liu, and Zhang (2018) share the data from their paper in this GitHub repository.  From the README:The CCSN dataset contains 2543 cloud images. According to the World
  Meterological Organization’s genera-based classification
  recommendation, we divide into 11 different categories： Ac, Sc, Ns,
  Cu, Ci, Cc, Cb, As, Ct, Cs, St. It is worth noting that contrails have
  consideration in our dataset. Representative sample images from each
  category are shown below. Ci = cirrus; Cs = cirrostratus; Cc =
  cirrocumulus; Ac = altocumulus; As = altostratus; Cu = cumulus; Cb =
  cumulonimbus; Ns = nimbostratus; Sc = stratocumulus; St = stratus; Ct
  = contrail. CitationZhang, Jinglin, et al. ""CloudNet: Ground‐Based Cloud Classification
  With Deep Convolutional Neural Network."" Geophysical Research Letters
  45.16 (2018): 8665-8672."
Download shapefile with electric substation data at state or county level for the United States,"
I would like to know about where I could find electric substation data for states in the US, that can be downloaded as a point shapefile or file geodatabase feature class. I am particularly interested to find substation data for the states of California, Nevada and Arizona. I am searching for data that would show information about the substation status, max-min voltage, NAICS code and possibly number transmission lines passing through these substations. I was able to find multiple resources for California 'https://data.ca.gov/dataset/california-electric-substations' and 'https://catalog.data.gov/dataset/california-electric-substations-64b59/resource/21777503-daec-4b66-b52e-3b582d066f8e?inner_span=True'. However was not able to find any data for Nevada or Arizona
","['data-request', 'usa', 'data.gov', 'government']","Homeland Infrastructure Foundation-Level Data: Electric SubstationsThis feature class/shapefile represents electric power substations
  primarily associated with electric power transmission. In this layer,
  substations are considered facilities and equipment that switch,
  transform, or regulate electric power at voltages equal to, or greater
  than, 69 kilovolts. Substations with a maximum operating voltage less
  than 69 kilovolts may be included, depending on the availability of
  authoritative sources, but coverage of these features should not be
  considered complete. The Substations feature class/shapefile includes
  taps, a location where power on a transmission line is tapped by
  another transmission line. The following updates have been made since
  the previous release: 7,144 features added, geographic coverage
  expanded to include Guam, Northern Mariana Islands, and Virgin
  Islands."
Where can I find a list of all gov websites and their associated official social media accounts?,"
All gov sites from national level down to town/village level. And their official social media profile handles. Is there such a dataset available?
","['government', 'social-media']",The DIY way would be to to compile the lists of websites with a bit of internet searching:https://www.nclc.org/for-consumers/us-government-websites.htmlhttps://www.usa.gov/federal-agenciesand then from each page source scrape social media accounts
using barcode value to lookup drug information,"
I am trying to build a query tool that takes a scanned barcode (NDC) and looks up the drug information in the openFDA.    I have a package for Latanoprost Ophthalmic Solution with a package code of 2420846325, which I think translates to 24208-463-25.  Using Postman with my api-key, I submit a GET such as: 
https://api.fda.gov/drug/ndc.json?api_key=&search=product_ndc:24208-463-25
However, this returns the product ""Carvedilol"" and not Latanoprost like I would expect.  
When I use the Search page (https://www.accessdata.fda.gov/scripts/cder/ndc/index.cfm), selecting the ""NDC Code"" type from the drop down menu and providing 24208-463-25 for the code, I get the results I was looking for.  I do notice that the online query returns a product ndc value of 24208-463 which returns the correct result when I use it in my GET call.
I am hoping you can tell me if the package code is being ignored with the online tool and should I also drop that package code when I make my API calls?
Thank you for your help.
",['openfda'],
Aggregate Willmott and Matsuura Temperature Climate Data on Country Level,"
I'm looking for monthly, mean temperature data on the country-level since 1900 (or at least 1950) for which the temperature is weighted according to population density.
The common database for the spatial temperature is by Willmott and Matsuura here: http://climate.geog.udel.edu/~climate/html_pages/download.html#T2017
The population grids typically come from this site: https://sedac.ciesin.columbia.edu/data/set/gpw-v4-population-density-rev11/data-download
So I downloaded the Willmott-Matsuura temperature data which is a single gz-file. My question: How can I aggregate the Willmott-Matssura temperature data on the country-level using R? 
Is there an open code for this, or has someone else maybe done it? (It's a common dataset in the literature)
Thanks for any advice!
","['geospatial', 'programming', 'geocoding', 'climate']",
Where can I find FDA approval SPL drug data?,"
I am doing a study on approval label drug data for prescription drugs and want to get a a large dataset of the approval label for a drug. I will be then comparing this with later versions of the drug label data. Is there a database where this is easily accessible? I have been using dailymed but it seems to just keep a random collection of older versions. 
The only option I am aware of at this point is manually downloading every single PDF from https://www.accessdata.fda.gov/scripts/cder/daf/ which seems like a mammoth task.
Is there an easier way here?
",['openfda'],
"Is there a freely available, no restrictions listing of public companies (US or otherwise)?","
I am wondering if there is a freely available dataset of publicly traded companies (US or otherwise) with zero restrictions on use of said data? (A site like OpenCorporates does not meet the conditions of my question, as it seems you have to pay for a license, depending on how you use the data.)
A Wall Street Journal article from 2017 says there are 3,671 public companies in the US.
","['finance', 'companies']",
Salient Object Detection Evaluation Data and Test Sets,"
I'm working on salient object detection and for evaluation of my proposed method I should compare it with other methods and models (as all do!). I just found that it isn't necessary to test every single method on several data sets. It seems that some of the top researchers in the field established a Website (Salient Object Detection Leaderboard) and made those data publicly available. However, there is an important problem here. The data are uploaded in pan.baidu and we cannot download it from outside of the China. Any solution for that?
","['data-request', 'images']",
Download Drugs & Interactions Database UK,"
I am looking to download a database of Drugs, Warnings & Interactions for the UK. Is this information freely available? I was in contact with one company and they wanted €3000 per year. The DailyMed Web Service seems like a good service but only for the USA. I am based in Ireland so UK or Ireland would do.
","['data-request', 'medical']",
A dataset for univariate nonparametric regression,"
Where can we find a publicly accessible real-life dataset for univariate nonparametric regression? A reviewer asked us to include an example with some real data. The problem is that there should be some way to estimate the ""quality"" of approximation in order to compare our method with known approaches. Otherwise what would be the profit in including real-life dataset computations?
",['data-request'],
How to get the different plan prices according to house income from the finder api,"
How to get the different plan prices according to house hold income from the finder api
looks like I could not find an field name ""HouseHold"" in the schema.
https://finder.healthcare.gov/api/finder_api_v3.0.xsd
","['api', 'healthcare-finder-api', 'income']",
Knowledge-base of typical/notable values of attribute,"
For processing English language, we use semantic networks, such as ConceptNet, to check various relations (e.g., part-of, used-for, etc.) between objects (typically nouns).
We are curious about knowledge-base concerning typical or notable values of an attribute. We attach some examples.

typical values of a traffic light: red, orange, green
typical values of an operating system: Windows, Linux, Mac, Android, etc.
notable values of age: 18/21 (age restriction), 50/60/70 (celebration)

","['nlp', 'english']",
Is there a place to pull satellite imagery based on latitude and longitude?,"
Is there a freely available service to call, via API, and pull satellite imagery using latitude and longitude coordinates?  Something akin to Google Maps. It doesn't have to the latest image, just a general image in the last few years?
","['geospatial', 'api']",
Where can I find a dataset of social bots from other source than twitter?,"
It's easy to find datasets of bots (fake accounts) from twitter, but I can't find similar datasets of bots from another social media (like facebook, instagram, reddit, linkedin...)
Is there any published?
","['data-request', 'social-media']",
Dataset of international football games,"
Where to find dataset for international football games, last 8 years? Which includes match details (goals, attempts, possession, pass, shots, etc.), something like here: https://www.football-data.co.uk/data.php, but for international games.
Prefered format would be csv or xlsx, but other formats are also ok. 
","['data-request', 'football']",
"IPEDS IDs on ""Preliminary Loan Debt Data By Field of Study""?","
Frustratingly, the Program Debt Data found here does not include a column for IPEDS ID and the NAME column is not a 1:1 match with INSTNM from the other scorecard data. Does anyone have a version that includes either? 
",['collegescorecard'],
Frequently-updated satellite images of Amazonia/Brazil,"
I want to do time analysis of satellite images from the Amazonia/Brazil. I'm looking mainly for optical images. Ideally, such dataset would be frequently updated (every month or week). I don't need the finest resolution since I'm looking for <~square-kilometer features, resolutions in the decameter~hectometer range would be enough.
Then the question is: is there any frequently updated/released, open image set to explore online?
","['images', 'brazil']",Here are some links from government agencies:http://www.inmet.gov.br/sateliteshttp://www.dgi.inpe.br/catalogo/http://www.dgi.inpe.br/CDSR/https://www.redemet.aer.mil.br/?i=produtos&p=imagens-de-satelite
I am trying to find shp for zipcodes for Europe. Is there a site to find those data?,"
I am trying to find shapefiles, in which there are data for the zipcodes for Europe countries. Is there a site maybe that I could find the specific data?
","['europe', 'postal-code']",
"List of software projects ""open sourced"" by private companies","
I am interested in a dataset listing software projects that started as closed projects within private companies but were at some point relicensed and released to the public.  At a minimum, I'd like to know the name of the project and the date when it was released as OSS.  My starting point is the Wikipedia list List of formerly proprietary software.
","['data-request', 'software', 'open-source']",
How to Retrieve Minimum Wage Data,"
I am trying to find minimum wage data in the API as it is shown on this page: https://www.dol.gov/whd/minwage/america.htm#stateDetails. 
I know that there is the https://data.dol.gov/get/publications_view data table, however, is there a way to search this table for minimum wage data?  Should I be looking somewhere else?
Also, it would be a bonus if I could get minimum wage data at the city level, as I know cities like Pasadena, CA have a high minimum wage than the rest of the state.
","['data-request', 'economics', 'labor']",
Does Population estimates in American Community Survey 5-Year Data (2009-2017) includes international migration as well?,"
Does Population estimates in American Community Survey 5-Year Data (2009-2017) includes international migration as well? or is it based on residence status. 
","['us-census', 'census']",
Does Wikidata offer inferencing/reasoning?,"
I would like to use RDFS level inferencing in some queries posed in the Wikidata Query Service which uses SPARQL. Does it support inferencing/reasoning? If so, in what kind? For example, is it Forward Chaining?
","['wikidata', 'sparql']","You can test that by inspecting the results of executing a query that assumes reasoning. For example, subclass of in RDFS is a transitive property. Therefore, querying for subclass of author, should return both its direct and indirect subclasses. Try it:When I executed it, it returned 28 results. However, finding the subclasses of writer, which is a subclass of author, returns 71 results, more than the author. Try it:This means that inferencing is not supported at the time of writing this answer, since when searching for author subclasses, it should have returned the subclasses of writer too (and its subclasses' subclasess etc.).One workaround is to use, property paths. For example, entering the below query, even without inferencing, will return all subclasses of author in any level. Try it:By appending * to the wdt:P279 property, means a sequence of 0 or more subclass of properties.Conducting a short research on the web, I have found two sources: [1], [2], from Wikidata, that are about the support of reasoning and inferencing. It is a really useful feature and I hope we will see it in the future."
Reaching flood victims for a survey,"
I want to send a small set of survey questions to recent flood victims in the US.
- Where do I start in order to get a mailing list?
- Are there organizations that will forward the survey link to the victims' emails (or phones/social media accounts, etc.) even though they may not share the contact information with me?
","['usa', 'survey', 'geohazard']",
Where can I download a full international drug names dataset?,"
Please advise where can I download a full international dataset of drug/medicine names?
I need a csv or db file with names
","['data-request', 'medical', 'drugs']","The World Health Organization maintains a list of International Nonproproprietary Names (INNs) for drugs in Latin, English, French and Spanish. You can download this list at https://www.who.int/medicines/publications/druginformation/innlists/RL82_pre.pdf"
looking for data to develop machine learning algorithm for ranking,"
I am looking for data to develop ranking algorithm e.g.: let's say we have horse racing data, we have horses data(height, weight etc.) and their places in races against other horses - goal is to create ranking of these horses (assumption is that this data is from short period of time and horses parameters didn't changed too much during this period)
of course it don't have to be horse-related data but you know the idea I guess
","['data-request', 'machine-learning']","Rank movies from the movielens open dataset based on artificially generated user data.Dataset SummaryMovieLens data sets were collected by the GroupLens Research Project
at the University of Minnesota.This data set consists of:The data was collected through the MovieLens web site
(movielens.umn.edu) during the seven-month period from September 19th,
1997 through April 22nd, 1998. This data has been cleaned up - users
who had less than 20 ratings or did not have complete demographic
information was removed from this data set.For code, reference steps are available on Github in a Jupyter notebook format."
Data set with known camera parameters,"
I am looking for a data set containing images of pedestrians/cyclists with a static backgrounds and given camera calibration information (intrinsic and extrinsic) for a scene. I have already found EPFL and UvA Multi-Person Tracking from Overlapping Cameras Benchmark Dataset, but need something else.
","['data-request', 'machine-learning', 'images']",
How to Convert https://tangrams.github.io/heightmapper coordinates to decimal latitude longitude,"

how to convert This:
9.70833/36.7798/-478.5508
to
decimal latitude longitude to see this location on google maps
https://tangrams.github.io/heightmapper/#9.70833/36.7798/-478.5508
my first question on this site
please help
","['geospatial', 'openstreetmap', 'conversion']",
Writing a query to obtain soil data from lat/lon in USA?,"
I would like to access soil data by lat/lon. It looks like this is the US soil web service here.  However, I am not sure how to set up the query, the Help page should be helpful but is 100's of pages long. Can anyone give me some pointers for setting up a python script to query a soil database? 
R looks like it has a decent interface, maybe I will have to learn R.
","['data-request', 'geospatial', 'usa', 'python']",
data from NOAA Magnetic Field Calculators (IGRF) for multiples longitude and latitude spacing,"
I would like to retrieve data from NOAA Magnetic Field Calculators (IGRF) for multiple locations by using longitude and latitude grid spacing; say every 5 degree latitude and every 10 degree longitude for the entire globe. Please can advise? 
","['data-request', 'geospatial', 'research', 'noaa']",
API for DOL jobs site data,"
Is there an API available for the job listings that appear at Seasonaljobs?
",['labor'],
Seeking open source service for points of interest near by/within airport,"
Is there open source api for reverse geocoding the restaurants or hospitals near by or within a given airport?
","['geospatial', 'geocoding', 'open-source']",
Freemium video game data for churn analysis,"
I'm looking for video game player analytics data, ideally from a game with the ""Freemium"" payment model, in order to predict player churn. This analysis would benefit from features such as:

Date of signup
Individual records for each game session along with date/time and player ID
Playtime per session
Purchases made (if any)

Any additional details regarding the in-game actions would be a bonus and likely improve the analysis.
",['games'],
Open data for software requirements,"
I'm looking for a plattform where I can receive machine readable requirements for an application like a cms (for example firstspirit):

Required memory
Required hard disk capacity (depending on number of editors, number of projects, number of pages)
Java versions
Database 
Installation

For example:
GET http://requirements.io/api/requirements/firstspirit/8.x.x.json
{
    ""name"": ""firstspririt"",
    ""version"": ""8.x.x"",
    ""requirements: {
        ""os"": [""ms-server"", ""debian""],
        ""java"": 11,
    }
}

`
","['data-request', 'api', 'uses-of-open-data', 'metadata']",
Bounty Programs for Open Source Projects,"
I am interested in data that contains bounties or paid rewards for specific programming tasks in open source projects.  Ideally, the data would contain a description of the task, the amount of the bounty, task status (e.g. open, in progress, complete, etc.), and a link to task homepage or public repository.  I'd also like to distinguish between bug bounty programs typically offered by private firms and platforms that price issues in public respositories (e.g. Gitcoin, IssueHunt, BountiesNetwork).  I am interested in both but I would prefer OSS bounty platforms.
","['data-request', 'programming', 'software', 'open-source']",
Is there a dataset/Statistics about Hotel?,"
Is there a dataset/Statistics about Hotel?
For example, How many companies that run hotel business? How many properties does AccorHotels have, how many properties does Aman Resorts have, etc? How many rooms are there in each property? min, max, average price etc.
This wiki gives some hint although much more information may need a  crawler.
",['data-request'],I would start here:Also check out this question/answer: Looking for Hotel prices dataset
Structured data for Nobel Prizes,"
There is already a Kaggle dataset (CSV) for Nobel Prize winners, but it hasn't been updated since 2016. Is there any up-to-date or official structured dataset for Nobel Prize winners?
The Kaggle columns are exactly what is needed.
Year
Category
Prize
Motivation
Prize Share
Laureate ID
Laureate Type
Full Name
Birth Date
Birth City
Birth Country
Sex
Organization Name
Organization City
Organization Country
Death Date
Death City
Death Country

For non-commercial purposes.
","['data-request', 'research', 'global']","As mentioned on the Kaggle page, there is an official API from nobelprize.orghttps://nobelprize.readme.io/With 3 endpoints:If you put in no parameters, with the ""Try it out"" section, you can get CSV or JSON outputs for the entire dataset.Direct links to CSV:Prize: http://api.nobelprize.org/v1/prize.csvLaureate: http://api.nobelprize.org/v1/laureate.csvCountry: http://api.nobelprize.org/v1/country.csv(Replace .csv with .json for that format.)"
Taking attribute from multiple points within a set distance,"
QGIS Question: I have a list of point features each with a unique ID. I need to run a fixed distance buffer on all 70,000 points to establish which points are within a fixed distance of each other than return the unique IDs for each point. These need to be within columns in the attributes table. 
So point 1 (id-A) might have point 9 (id-x) and Point 87 (id-c) within 1 km. I need the attributes table of point 1 to list id-A, then id-x then id c, all in columns for export to excel where I can concentrate them with comers in between.  
",['geospatial'],
Time-series data for causal inference task,"
I am looking for a suitable dataset for causal inference in time-series data. 
The biggest issue I am facing at this stage is to find a dataset suitable for experiments, in the sense that the causal relationships among the variables are well-known and hence they can serve as a validation for the method I am implementing.
Is there any available open dataset of the above-mentioned sort?
The only thing I have been able to find on the internet is the NCEP reanalysis dataset in which some of the causal relationships are clear, but many others are not.
Furthermore, I tried to construct a synthetic dataset but I am not sure that it will recover the complexity I need for accurately testing my method, do you have any suggestion about it?
","['data-request', 'time-series']","I found a dataset which seems to be exactly what I was looking forCausal Effects in Time SeriesIt provides sales' data for 100 products and 1000 promotions, moreover it is endowed with a 1000 x 100 matrix in which each element (promotion, product) is a number describing the causal relation."
What does “lower status” mean in “Boston house prices dataset”?,"
scikit-learn comes with Boston house prices dataset. One of the features is LSTAT, which means ""Percentage of lower status of the population"". 
What does ""lower status"" mean there?
Does it mean something like ""low incoming""?
","['data-request', 'python', 'documentation']","From dataset documentation in Table IV of Harrison & Rubin (1978), LSTAT is defined as:Proportion of population that is lower status = 1/2
  (proportion of adults without, some high school education and proportion of male workers classified as
  laborers). The logarithmic specification implies that
  socioeconomic status distinctions mean more in the
  upper brackets of society than in the lower classes. Source: 1970 U. S. Census Harrison Jr, David, and Daniel L. Rubinfeld. ""Hedonic housing prices and the demand for clean air."" Journal of environmental economics and management 5, no. 1 (1978): 81-102."
Where would I be able to obtain or purchase GeoJSON data for Manhattan submarkets?,"
GeoJSON data contains arrays of coordinates that create polylines (like borders). You can find geoJSON data for the 50 U.S. state borders, for example. I would like proper geoJSON data for this: https://www.scribblemaps.com/create/#/id=HfPjzTz28R&lat=40.76084989&lng=-73.98615251&z=14&t=mbb_road
Does anyone know where I would find or commission this? It's going into a Kotlin-based web endpoint that creates maps.
","['geospatial', 'openstreetmap']",
"Are there 506 different towns in ""Boston house prices dataset""?","
This code is to load the housing data from the scikit-learn library.
>>> from sklearn.datasets import load_boston
>>> boston_dataset = load_boston()
>>> len(boston_dataset.data)
506

First feature is CRIM which means ""per capita crime rate by town"".
Does it indicate that there are 506 different towns in ""Boston house prices dataset""?
","['data-request', 'machine-learning']","TLDR: No, there are only 92 distinct towns. There are 506 Census Tracts. You can run  getattr(boston_dataset, ""DESCR"") to get the description of the dataset. 
While it does not directly contain the information that you want, it does tell you:This dataset was taken from the StatLib library which is 
  maintained at Carnegie Mellon University.The Boston house-price data of Harrison, D. and Rubinfeld, D.L.
  'Hedonic prices and the demand for clean air',
  J. Environ. Economics & Management,
  vol.5, 81-102, 1978.   If you can get a copy of the paper, you will find in it the line:The physical changes in NOX concentrations in each of the 506 Boston SMSA
  census tracts were calculated for 1990 using the Transportation and Air Shed
  Simulation Model (TASSIM ).If you go to the Statlib site: http://lib.stat.cmu.edu/datasets/ 
You will see datasets called boston and boston_corrected. It appears that the data in sklearn.datasets is the boston set.  The boston_corrected data contains a field for the town.  My count is that there are 92 distinct  values in that field."
Benchmark datasets to compare Data Envelopment Analysis (DEA) models,"
I'm studying the effects of some data transformations over the technical efficiencies resulting from a DEA model. To do that, I'm looking for a benchmark dataset which has at least three variables with fifty observations each.
In my research I found some datasets, as in [1], [2] and [3],
but all with broken links.
Does someone know some reference dataset to conduct experiments with DEA models?
",['data-request'],
How to find the country with the northernmost population?,"
I became interested in the question of which country has the most people living most northernly. I am posting this question here because I don't know where to find sources for that.
I don't mean a country with a large city near or above the arctic circle. Rather, if you take the average longitude of the nation's population --  the average latitude of each citizen's residence (as nearest an approximation as you can)-- which country would have the nothern-most average latitude. I suspect that country is Finland, but I would like to find some way to empirically verify this suspicion.
","['geospatial', 'population']","One word answer: IcelandOne sentence answer: Subject to the methodology and caveats below, with an estimated 2020 poulation center latitude of 64.336, Iceland has the northernmost population center among soverign nations, with Finland coming in second at 61.715, and Norway coming in third at 61.049https://sedac.ciesin.columbia.edu/data/sets/browse?facets=theme:populationunder ""UN WPP-Adjusted Population Count, v4.11 (2000, 2005, 2010, 2015, 2020)"" and ""National Identifier Grid, v4.11 (2010)"" respectively, I wrote bc-pop-center.pl and bc-pop-center-parse.pl in https://github.com/barrycarter/bcapps/tree/master/COW/ to compute the national centers of population.As https://en.wikipedia.org/wiki/Center_of_population#Definitions notes, there are several ways to compute center of population, each of which may give different results. I used ""the mean centre, also known as the centroid or centre of gravity""The full results are in the files ""bc-pop-centers-no-deps.csv"" and ""bc-pop-centers-with-deps.csv"" in https://github.com/barrycarter/bcapps/tree/master/COW/ where the former treats dependencies as belonging to their parent nations, and the latter treats dependencies as separate nations.If dependencies are counted as separate nations, the Svalbard and Jan Mayen Islands has the northernmost center of population at 78.596 latitude, with Greenland at 66.070 coming in second. Iceland is then third.If dependencies are counted as separate nations, the Falkland Islands (Islas Malvinas) are southernmost at -58.083 latitude, but the other southernmost centers of population belong to sovereign nations.The sovereign with the southernmost centers of population are New Zealand with -39.374 latitude, Uruguay with -34.073 latitude, and Chile with -34.059 latitude.There are 933,120,000 gridpoints (of 30 arcseconds by 30 arcseconds each) of varying size total on the Earth. The Holy See of Vatican City covers only 1 of these gridpoints, whereas the Russian Federation covers 41,463,394 gridpoints. Because each gridpoint does not have the same area, it's a coincidence of sorts that these are also the smallest and largest countries by area.The national grid data treats dependencies as separate countries, so I used https://spreadsheets.google.com/ccc?key=pJpyPy-J5JSNhe7F_KxwiCA&hl=en (which geonames.org's countryInfo.txt file lists as being a source of dependent countries) to convert. This list does not appear to be complete, and my results reflect this. For example, New Caledonia is actually a dependency of France and Curacao is a dependency of the Netherlands. I briefly tried to add to the google spreadsheet, but only got as far as these two examples before giving up.The line starting with FR/NL refers to Saint-Martin, which is apparently not sovereign, but co-owned by two nations. In theory, Andorra should be listed as ""ES/FR"" as it belongs to both Spain and France (for 6 months a year each), but I treat it as a separate entity.According to geonames, Antarctica has a permanent population, but, since it is not owned by any nation (and since the gridded population data doesn't cover it), it does not appear in my results. If it did, it would by far have the southernmost center of population (at the Amundsen-Scott base, which is only a few hundred feet from the South Pole).The national and population grid data is based on 30 arcsecond by 30 arcsecond grids, so the latitudes and longitudes are accurate only to 1/120 degree, so I give only three digits of precision above, though the files use full floating point precision, but, of course, the accuracy is still limited.The national grid data uses three letter country codes, which I converted to two letter country codes using https://www.iban.com/country-codes which I converted to bc-cc2cc3.csv in https://github.com/barrycarter/bcapps/tree/master/COW/I live streamed solving this and the recordings are available on my bccoding playlist at https://www.youtube.com/watch?v=s2gmWhW0QZY&list=PLQiTKaefaTLpfUVJETwWX31IxLypqA7xy with titles ""National centers of population (or something)""This was actually my second approach. My first approach was to use populated places in geonames, but this misses a lot of non-urban areas. My partial writeup for this approach is at: https://github.com/barrycarter/bcapps/tree/master/COW/README.cocMy writeup for the approach I am using here is at https://github.com/barrycarter/bcapps/tree/master/COW/README.coc2 ; it includes this answer and a more thorough explanation of the columns in the CSV files mentioned earlier."
Monthly Gold and Oil prices going back to 1920s,"
I am trying to find Monthly prices or returns for Gold and Oil going back in time until 1920s. Yearly data is available, but I wanted to check if someone has come across monthly time series too.
","['data-request', 'historical']",
Looking for foot pressure database collected from pressure sensors,"
I am working on a project where I need foot pressure data that a person put on his foot while walking, running, or doing any other practice. I searched a lot in the search engines and I couldn't find anything. The data could be collected from pressure sensors or pressure mats.
I would be grateful if any of you know of such a database and can share it with me.
","['data-request', 'medical', 'uses-of-open-data', 'wikidata']",
Is there a comprehensive geocoding DB available?,"
Ideally I want a database that contains all points on the earth down to about 3m by 3m square and a corresponding street address if one exists (might be a many to one relationship).
Does such a DB exist, and, if so, which is the most comprehensive?
","['data-request', 'geocoding', 'database']",
Location of all mountain peaks of the world,"
I'm looking for something like this page of Wikipedia:
https://en.wikipedia.org/wiki/List_of_mountains_by_elevation
but with coordinates so that I can load the resulting file in a GIS. 
Does somebody now if there is a global mountain peaks database?
","['data-request', 'geospatial']",
How to access data from catalog.data.gov using API's?,"
I am new to APIs and am having problems in accessing data from catalog.data.gov. I have successfully used the below code to search my dataset of interest, but can't figure out how I can fetch the data for the collection ""Monthly Traffic Volume Trends"". I am interested in getting all the 154 datasets in this collection. Please guide me through this
import urllib3
from urllib.parse import quote
import json
import pprint

# Make the HTTP request.
http = urllib3.PoolManager()
response = http.request('GET','http://catalog.data.gov/api/3/search/dataset?q=""monthly_traffic_volume_trends_may_2002""&rows=10')
# Use the json module to load CKAN's response into a dictionary.
response_dict = json.loads(response.data)
# Check the contents of the response.
result = response_dict['results']
pprint.pprint(result)

","['api', 'data.gov', 'ckan']",
Searching for Directed acyclic graph data,"
I need some DAG graph for my research. The representation of the graphs is needed to be in edge-list representation. 
","['data-request', 'uses-of-open-data', 'programming', 'computing']",
Acquiring Indian Land Conservation Data,"
I am working on a project which assesses the potential for energy development in India. Where could I acquire data which shows areas where the Indian government would likely not permit development? I can see that there is relevant data available on Bhuvan (https://bhuvan.nrsc.gov.in/bhuvan_links.php#), however I have difficulties interpreting the data availability.
If anyone has any resources for finding this sort of data (conserved lands, national parks, protected lands, etc.), please let me know.
","['geospatial', 'environment']",You can get that data from the World Database on Protected Areas (WDPA) from UN Environment and the International Union for Conservation of Nature (IUCN).  The geospatial data for India is available for download as Shapefile or CSV here.
Are there any free news APIs? [duplicate],"







This question already has answers here:
                                
                            




Are there free APIs for searching news articles that I can use to collect trend data in news coverage?

                                (8 answers)
                            

Closed 3 years ago.



Over the past few years, I have managed to find all sorts of excellent data sources across the web, almost always for free, including static data (e.g. .csv), but also plenty of free APIs, for example finance, weather, sport etc. 
But I have not been able to find a free news API. 
Question
My question is: where can we find a free and simple news API, with a preference for 

As many news articles as possible
Going back as far as possible

What I've tried
It is well known that Google is an excellent aggregator of news. However, it is notoriously difficult to web scrape (they have a paid news API - not a free one).
","['api', 'news']",
Help a beginner with Mimic III,"
I am a beginning user of the MIMIC III database, and I would like to query the database to get a list of all patients in Mimic III that have had a blood transfusion (ICD 9 code 9901 - 9905). Does anyone know of a tutorial that might help me do this query?
",['mimic-iii'],
Available dataset containing private/confidential documents,"
I'm looking to build a classifier that can label documents as private or public based on their content and need to find a suitable dataset that contains private/confidential/secret/sensitive documents.
It's fairly easy to understand that they are hard to find since they contain 'private/confidential/secret/sensitive' information. However, most datasets I have discovered have had the important parts redacted or cleansed.
Anyone have any suggestions for a dataset or even a place to look for such a dataset?
","['data-request', 'machine-learning', 'classification', 'text']",
Data sets to predict/classify using machine learning [duplicate],"







This question already has an answer here:
                                
                            




Clinical dataset for machine learning

                                (1 answer)
                            

Closed 3 years ago.



I'm looking for a data set that I can use to predict/classify using machine learning methods like SVM, trees, logistic regression, etc.
I would love something related to health/medicine, so I could use methods to detect early-stage diseases for example. But other areas are good too.
","['data-request', 'medical']",
Sample of movie plot summaries,"
I'm looking for datasets about cinema in the US. In particular, I need a representative sample (as much as this can exist) of 

Movies that were properly released and seen in theatres in the US
Released between 1950 to today
Plot summaries
Country of production
Year of release

I found this great resource from IMDB, but I can't find the plot summaries and countries of production.
Is it possible to extract/scrape this data from Wikipedia/DBpedia/IMDB? 
","['data-request', 'film']",
Calculating MOE for Net Migration,"
I'm trying to replicate how the ACS calculates their MOEs for Gross Migration and NetMigration from the latest 2013-2017 County-to-County Migration flow data. I followed their guidance/methodology for approximating a MOE for derived estimates for Gross Migration but got different results from what was published in their data table. Does anyone know how to calculate a MOE for Net Migration? or how the formula/methodology to replicate gross migration MOE?   
",['us-census'],
data.gov: Request for insight into relationships of Topics / Categories / Organizations etc,"
I have just started exploring data.gov and want to ensure i understand relationships under a Topic.
If I pick a topic, then it lists # of datasets mapped to the topic. Then we have Categories, Tags, Organizations, Publishers and Bureaus. I can infer the following:

A dataset mapped to a Topic can show in another Topic as well
Datasets published by an Organization add up to the total data set for the topic


What is the purpose of Categories under a Topic? A subclassing below Topic?
Is Organization, Publisher and Bureau any linkage that can be inferred?
Is there a metrics download where I can get stats on the above constructs? I did download a metrics file but it has stats on agency/ subagency and datasets. Eg: Topic of Finance = 102 datasets. Is this metric and others like these downloadable?

","['data.gov', 'categories']",
Business register in Austria,"
I've tried to search for company register with API for registered businesses (including companies and self-employed people) in Austria, but with no luck. Does anybody know, if is there any?
","['data-request', 'finance', 'europe', 'opencorporates']",
Query wikipedia links,"
I'm using the following query to receive label and description of all Wikidata-entries with geo-location in a geo-bounding box:
SELECT DISTINCT ?place ?placeLabel ?placeDescription ?location WHERE
{
  SERVICE wikibase:box
  {
    ?place wdt:P625 ?location.
    bd:serviceParam wikibase:cornerWest 'Point({0} {1})'^^geo:wktLiteral.
    bd:serviceParam wikibase:cornerEast 'Point({2} {3})'^^ geo:wktLiteral.
  }
  SERVICE wikibase:label { bd:serviceParam wikibase:language '{4},en,fr,es'. }
  ?place(wdt:P31/wdt:P279*) wd:Q618123.
}

This works fine, but now I would like to also have the link to the wikipedia article included in the result. I tried to modify the query to:
SELECT DISTINCT ?place ?placeLabel ?placeDescription ?location ?article WHERE

but it doesn't work, articles are not returned. Any idea, how this works? 
Edit: after all the useful hints from you guys, here is the version, which works fine now:
SELECT DISTINCT ?place ?placeLabel ?placeDescription ?location ?article WHERE
{
  SERVICE wikibase:box
  {
     ?place wdt:P625 ?location.
     bd:serviceParam wikibase:cornerWest 'Point({0} {1})'^^geo:wktLiteral.
     bd:serviceParam wikibase:cornerEast 'Point({2} {3})'^^ geo:wktLiteral.
  }
  SERVICE wikibase:label
  { 
      bd:serviceParam wikibase:language '[AUTO_LANGUAGE],en,fr,es,{4}'. 
      ?place schema:description ?placeDescription ; rdfs:label ?placeLabel. 
  }
  # all places with a location
  ?place(wdt:P31/wdt:P279*) wd:Q618123.

  # include wikipedia links
  ?article schema:about ?place.
  FILTER REGEX(STR(?article), '.wikipedia.org/wiki/').

  # optional, only places containing string in label
  FILTER CONTAINS(lcase(?placeLabel), '{5}').
}

","['wikidata', 'wikipedia']","The query service does not know that your variable ?article means that you want a Wikipedia article. You have to also ask for it in the actual query. One way to do that is to add these lines in the query:The first line queries for all the the sitelinks that the item have. The second one filters out those that go to other projects than Wikipedia, for instance Wikimedia Commons. So here is an example that might work for you:"
"Seeking lists (in array form) of latitude, longitudes for streets and other places?","
I am trying to get an array of latitude and longitudes so that I can test line making on an app. My issue though is finding lists (in form of array) of latitude and longitude. This is an example of what I am looking for:
[ [ 37.33523566, -122.03254863], [ 37.33521504, -122.03254905 ], [ 37.33519572, -122.0325498 ], [ 37.33517518, -122.03255055 ], [ 37.33515083, -122.03255349 ], [ 37.3351212, -122.03256229 ], [ 37.33507162, -122.0326037 ], [ 37.33503868, -122.03265072 ], [ 37.33500926, -122.03272188 ], [ 37.33497737, -122.03281282 ], [ 37.33494812, -122.0329212 ], [ 37.33492222, -122.03304215 ], [ 37.33489242, -122.03318372 ], [ 37.33485843, -122.03334424 ], [ 37.33482105, -122.03350886 ], [ 37.33477977, -122.03369603 ], [ 37.33474691, -122.03389325 ], [ 37.33470894, -122.03411085 ], [ 37.33467638, -122.03432425 ], [ 37.33464561, -122.03455442 ], [ 37.33461946, -122.03478727 ], [ 37.33460316, -122.0350347 ], [ 37.33458564, -122.03529395 ], [ 37.3345628, -122.03556217 ], [ 37.3345597, -122.03583308 ], [ 37.33454847, -122.03611286 ], [ 37.33454218, -122.03638578 ], [ 37.33454235, -122.03666775 ], [ 37.33453849, -122.03695223 ], [ 37.33453874, -122.03724626 ], [ 37.33453652, -122.03753997 ], [ 37.33452613, -122.03783266 ], [ 37.33451917, -122.03813827 ], [ 37.33451284, -122.03845141 ], [ 37.33450379, -122.03875937 ], [ 37.33449629, -122.03908048 ], [ 37.33448791, -122.03941089 ], [ 37.33447622, -122.0397398 ], [ 37.33447068, -122.04007348 ], [ 37.33446519, -122.04041597 ], [ 37.3344584, -122.04077831 ], [ 37.33445283, -122.04113765 ], [ 37.3344499, -122.04149924 ], [ 37.33444604, -122.04187567 ], [ 37.33444843, -122.04226334 ], [ 37.33444952, -122.04265083 ], [ 37.33445363, -122.04302852 ], [ 37.33445945, -122.04342255 ], [ 37.33446146, -122.04380955 ], [ 37.33445832, -122.04420408 ], [ 37.33445442, -122.04458579 ], [ 37.33444763, -122.04496063 ], [ 37.33444244, -122.045341 ], [ 37.33443657, -122.04571727 ], [ 37.33441708, -122.04607568 ], [ 37.3343947, -122.04644121 ], [ 37.33436235, -122.04681002 ], [ 37.33431797, -122.04716524 ], [ 37.33426985, -122.04751058 ], [ 37.33420971, -122.04784191 ], [ 37.33414287, -122.04818683 ], [ 37.33406324, -122.04853007 ], [ 37.33398776, -122.04886543 ], [ 37.33390604, -122.04921638 ], [ 37.3338288, -122.04956959 ], [ 37.33375445, -122.04992666 ], [ 37.33367998, -122.05028306 ], [ 37.33360693, -122.05063996 ], [ 37.33352458, -122.05100549 ], [ 37.33344889, -122.05137547 ], [ 37.33336511, -122.05174034 ], [ 37.33328787, -122.05209673 ], [ 37.33321101, -122.05246948 ], [ 37.33313411, -122.05283635 ], [ 37.33305632, -122.05318781 ], [ 37.33298105, -122.0535463 ], [ 37.33290406, -122.05391527 ], [ 37.33282486, -122.05427997 ], [ 37.33275353, -122.05462472 ], [ 37.33268517, -122.05498531 ], [ 37.33260475, -122.05535361 ], [ 37.33252881, -122.05571688 ], [ 37.33245639, -122.05608208 ], [ 37.33238246, -122.05644652 ], [ 37.33236209, -122.05682698 ], [ 37.33232211, -122.05719234 ], [ 37.33229772, -122.05757204 ], [ 37.332289, -122.05795133 ], [ 37.33228724, -122.05833354 ], [ 37.33230505, -122.05871525 ], [ 37.33233606, -122.05909629 ], [ 37.33238246, -122.0594718 ], [ 37.33244004, -122.05984991 ], [ 37.33251376, -122.06021989 ], [ 37.33260198, -122.06059221 ], [ 37.33270432, -122.06095339 ], [ 37.33282574, -122.06131389 ], [ 37.3329513, -122.06167465 ], [ 37.33307736, -122.06203541 ], [ 37.33320782, -122.06239181 ], [ 37.33333498, -122.06274686 ], [ 37.33346293, -122.06310662 ], [ 37.33358639, -122.06346075 ], [ 37.33370957, -122.06381723 ], [ 37.33383844, -122.06417204 ], [ 37.33395407, -122.06452986 ], [ 37.33405917, -122.06489607 ], [ 37.33414928, -122.06526437 ], [ 37.33422447, -122.06562781 ], [ 37.33429383, -122.06600055 ], [ 37.33435409, -122.06636961 ], [ 37.33440019, -122.06674461 ], [ 37.33442928, -122.06711736 ], [ 37.3344465, -122.06749672 ], [ 37.3344543, -122.06787986 ], [ 37.33444654, -122.06826065 ], [ 37.33442613, -122.06864035 ], [ 37.33439537, -122.06901468 ], [ 37.33435661, -122.06939204 ], [ 37.33430397, -122.06976336 ], [ 37.33424182, -122.07013275 ], [ 37.33417438, -122.07050306 ], [ 37.33410968, -122.07087404 ], [ 37.33403923, -122.07123245 ], [ 37.33396475, -122.07160897 ], [ 37.33389384, -122.07197743 ], [ 37.33382775, -122.07235512 ], [ 37.33375801, -122.07272963 ], [ 37.33369775, -122.07309474 ], [ 37.33363907, -122.07346522 ], [ 37.33359159, -122.07381886 ], [ 37.33355651, -122.07417592 ], [ 37.33353728, -122.07453283 ], [ 37.33353065, -122.07488445 ], [ 37.33353363, -122.07523112 ], [ 37.33355228, -122.07558936 ], [ 37.33358308, -122.07595104 ], [ 37.33362663, -122.0763056 ], [ 37.33368006, -122.07665613 ], [ 37.33374934, -122.07700482 ], [ 37.33382825, -122.07735141 ], [ 37.33392322, -122.07769942 ], [ 37.33402871, -122.07804543 ], [ 37.33415037, -122.07838406 ], [ 37.3342805, -122.07872034 ], [ 37.33442102, -122.07904631 ], [ 37.33457244, -122.0793639 ], [ 37.33473735, -122.0796747 ], [ 37.33492184, -122.07997503 ], [ 37.33511119, -122.08026077 ], [ 37.33531428, -122.08054952 ], [ 37.33552177, -122.08082252 ], [ 37.33573891, -122.08110667 ], [ 37.33595575, -122.08138403 ], [ 37.33617167, -122.08165962 ], [ 37.33638536, -122.08193111 ], [ 37.33659906, -122.08220411 ], [ 37.33680278, -122.08247812 ], [ 37.3370055, -122.0827595 ], [ 37.33720302, -122.08304213 ], [ 37.3373963, -122.08332863 ], [ 37.33758129, -122.08362627 ], [ 37.33775509, -122.08392617 ], [ 37.33793145, -122.0842275 ], [ 37.33810893, -122.08454124 ], [ 37.3382842, -122.08484542 ], [ 37.3384549, -122.08515152 ], [ 37.33862249, -122.08545696 ], [ 37.33879885, -122.08577472 ], [ 37.3389669, -122.08608946 ], [ 37.33913576, -122.08640269 ], [ 37.33930008, -122.08670293 ], [ 37.33947623, -122.08701088 ], [ 37.3396502, -122.08732093 ], [ 37.33981846, -122.08762326 ], [ 37.33998434, -122.08792937 ], [ 37.3401493, -122.08824042 ], [ 37.34031484, -122.08856086 ], [ 37.34046597, -122.08886286 ], [ 37.34061718, -122.08917878 ], [ 37.34077165, -122.08949679 ], [ 37.34092739, -122.08983097 ], [ 37.34107194, -122.09015057 ], [ 37.34121879, -122.09045668 ], [ 37.34137909, -122.09077234 ], [ 37.34154237, -122.09108423 ], [ 37.34171403, -122.09138934 ], [ 37.3418947, -122.091676 ], [ 37.34208941, -122.09195687 ], [ 37.34229154, -122.092223 ], [ 37.3424959, -122.09246482 ], [ 37.342708, -122.092712 ], [ 37.34291352, -122.09295692 ], [ 37.34312416, -122.09320284 ], [ 37.34332805, -122.09343444 ], [ 37.34353735, -122.09368045 ], [ 37.34374576, -122.09392 ], [ 37.34394974, -122.09415478 ], [ 37.34415677, -122.09439031 ], [ 37.34434595, -122.09463741 ], [ 37.34453978, -122.09489641 ], [ 37.34472464, -122.09516438 ], [ 37.3448932, -122.0954383 ], [ 37.34505141, -122.09572596 ], [ 37.34520782, -122.0960117 ], [ 37.34534964, -122.09631924 ], [ 37.34548953, -122.096638 ], [ 37.34562364, -122.09695274 ], [ 37.34576798, -122.09727888 ], [ 37.34590884, -122.09760787 ], [ 37.34604924, -122.0979434 ], [ 37.34619047, -122.09828781 ], [ 37.34633112, -122.09862728 ], [ 37.3464786, -122.09896549 ], [ 37.3466164, -122.09929791 ], [ 37.34676434, -122.09963352 ], [ 37.34690805, -122.09997509 ], [ 37.34705171, -122.10032243 ], [ 37.34719244, -122.1006624 ], [ 37.34733473, -122.10099349 ], [ 37.34747663, -122.10131879 ], [ 37.34762491, -122.1016513 ], [ 37.34777737, -122.10196336 ], [ 37.34794036, -122.10227399 ], [ 37.34812405, -122.10257499 ], [ 37.34831482, -122.10286198 ], [ 37.34851318, -122.10314001 ], [ 37.34872189, -122.10340186 ], [ 37.34894824, -122.1036539 ], [ 37.34918436, -122.10389589 ], [ 37.34941931, -122.10411164 ], [ 37.34966435, -122.10431859 ], [ 37.34991623, -122.10451573 ], [ 37.35016915, -122.1047086 ], [ 37.35042203, -122.10490214 ], [ 37.3506804, -122.10509685 ], [ 37.3509353, -122.10529449 ], [ 37.35119518, -122.1054944 ], [ 37.35145376, -122.10569934 ], [ 37.35170078, -122.10589849 ], [ 37.35194528, -122.10610938 ], [ 37.35218349, -122.10633762 ], [ 37.35240938, -122.10656821 ], [ 37.35262907, -122.10682025 ], [ 37.35283833, -122.10707414 ], [ 37.35304318, -122.1073468 ], [ 37.35322775, -122.10761167 ], [ 37.35340125, -122.10789012 ], [ 37.35357644, -122.10818206 ], [ 37.35373217, -122.10847987 ], [ 37.35388229, -122.10878137 ], [ 37.35402763, -122.10909116 ], [ 37.35416275, -122.10941512 ], [ 37.354285, -122.10973833 ], [ 37.35439853, -122.1100721 ], [ 37.35450989, -122.11040469 ], [ 37.35460422, -122.11074625 ], [ 37.35470108, -122.11109678 ], [ 37.35478615, -122.11144128 ], [ 37.35486926, -122.11178469 ], [ 37.3549592, -122.11213723 ], [ 37.35504792, -122.11248818 ], [ 37.35513836, -122.11282957 ], [ 37.35522226, -122.11317885 ], [ 37.35532071, -122.11352779 ], [ 37.35543424, -122.11386968 ], [ 37.35555758, -122.11420421 ], [ 37.35568444, -122.11452423 ], [ 37.35583234, -122.11484701 ], [ 37.35598347, -122.11516142 ], [ 37.35614335, -122.11546778 ], [ 37.35630592, -122.11577145 ], [ 37.35647419, -122.11607907 ], [ 37.35667204, -122.11636489 ], [ 37.35687073, -122.11663286 ], [ 37.35707534, -122.11689874 ], [ 37.35728082, -122.11715581 ], [ 37.3575003, -122.11741087 ], [ 37.35772158, -122.11764607 ], [ 37.35796495, -122.11787221 ], [ 37.35821377, -122.11808519 ], [ 37.35846644, -122.11829223 ], [ 37.35872263, -122.11848501 ], [ 37.3589945, -122.11866179 ], [ 37.35928216, -122.11883998 ], [ 37.35955814, -122.11901575 ], [ 37.35983897, -122.11918616 ], [ 37.36011952, -122.1193553 ], [ 37.36040727, -122.11952001 ], [ 37.36069305, -122.11969553 ], [ 37.3609743, -122.11986677 ], [ 37.36126096, -122.12003751 ], [ 37.36154377, -122.1202173 ], [ 37.36181958, -122.1204183 ], [ 37.36207862, -122.12062282 ], [ 37.36233305, -122.12084385 ], [ 37.36258266, -122.12108055 ], [ 37.36281941, -122.12133444 ], [ 37.36303768, -122.12160442 ], [ 37.36324345, -122.12188572 ], [ 37.36344328, -122.12218294 ], [ 37.36362588, -122.12248745 ], [ 37.36380169, -122.12279364 ], [ 37.36396061, -122.12310285 ], [ 37.36410876, -122.12341793 ], [ 37.36424153, -122.12374717 ], [ 37.36436332, -122.12407817 ], [ 37.36447237, -122.12441747 ], [ 37.36457081, -122.12476867 ], [ 37.36465673, -122.12512859 ], [ 37.36472923, -122.12549681 ], [ 37.3647884, -122.12586327 ], [ 37.36483488, -122.12623861 ], [ 37.36486694, -122.12661646 ], [ 37.36488463, -122.12699926 ], [ 37.36489573, -122.12737863 ], [ 37.36489494, -122.12775531 ], [ 37.36489561, -122.12814457 ], [ 37.36489536, -122.12851823 ], [ 37.36490102, -122.12889651 ], [ 37.364913, -122.12927755 ], [ 37.36492641, -122.12966111 ], [ 37.36495642, -122.13002966 ], [ 37.36500231, -122.13039762 ], [ 37.36505801, -122.13076299 ], [ 37.36513495, -122.13112023 ], [ 37.36522619, -122.13147671 ], [ 37.36533088, -122.13182204 ], [ 37.36543834, -122.13217241 ], [ 37.36554852, -122.13253006 ], [ 37.36565505, -122.13287858 ], [ 37.36576171, -122.13322476 ], [ 37.3658664, -122.13358057 ], [ 37.36597474, -122.1339342 ], [ 37.36607239, -122.13427694 ], [ 37.36617599, -122.13462026 ], [ 37.36627984, -122.13496408 ], [ 37.36637342, -122.13530514 ], [ 37.3664761, -122.13564763 ], [ 37.36657341, -122.13598643 ], [ 37.36667454, -122.13633075 ], [ 37.3667825, -122.13667173 ], [ 37.3668918, -122.13700784 ], [ 37.36700588, -122.13734664 ], [ 37.36714083, -122.13768569 ], [ 37.36728357, -122.13801602 ], [ 37.36743034, -122.13834434 ], [ 37.36759001, -122.13866201 ], [ 37.36776176, -122.13898061 ], [ 37.36794754, -122.13929619 ], [ 37.36813371, -122.13959391 ], [ 37.36833646, -122.13988803 ], [ 37.36854278, -122.1401674 ], [ 37.36876231, -122.14043713 ], [ 37.36898397, -122.14069152 ], [ 37.36921459, -122.14094005 ], [ 37.36945654, -122.1411796 ], [ 37.3697059, -122.14141823 ], [ 37.36994839, -122.1416339 ], [ 37.37019243, -122.14186189 ], [ 37.37043777, -122.14209172 ], [ 37.37068524, -122.14231367 ], [ 37.37092857, -122.14253931 ], [ 37.37117332, -122.14276269 ], [ 37.37142067, -122.14297886 ], [ 37.37167049, -122.14320232 ], [ 37.37190954, -122.14341883 ], [ 37.37215601, -122.14364204 ], [ 37.37240005, -122.14386038 ], [ 37.37263743, -122.14409064 ], [ 37.37287229, -122.14430781 ], [ 37.37311268, -122.14451887 ], [ 37.37336271, -122.14472699 ], [ 37.37361371, -122.14495984 ], [ 37.37385134, -122.14517802 ], [ 37.37409077, -122.14540877 ], [ 37.37433481, -122.14563986 ], [ 37.37457281, -122.14588663 ], [ 37.37481249, -122.14611939 ], [ 37.37503792, -122.14636347 ], [ 37.37527039, -122.14662055 ], [ 37.37550207, -122.14687494 ], [ 37.37572427, -122.14713511 ], [ 37.37595557, -122.14739872 ], [ 37.37618545, -122.14766024 ], [ 37.37641444, -122.14792309 ], [ 37.37664016, -122.14817958 ], [ 37.37686895, -122.14843858 ], [ 37.37709618, -122.14869624 ], [ 37.37732484, -122.14894979 ], [ 37.37755308, -122.14919429 ], [ 37.37778312, -122.14944148 ], [ 37.3780272, -122.14968145 ], [ 37.37828075, -122.14990349 ], [ 37.37854172, -122.15010976 ], [ 37.3787954, -122.15030297 ], [ 37.37906991, -122.15049139 ], [ 37.37933964, -122.15066314 ], [ 37.37961188, -122.15082139 ], [ 37.37989138, -122.15096748 ], [ 37.38018479, -122.15110721 ], [ 37.38048092, -122.15123277 ], [ 37.38078049, -122.15133956 ], [ 37.38107985, -122.15143117 ], [ 37.38139635, -122.15151398 ], [ 37.38170908, -122.15158724 ], [ 37.38201841, -122.1516569 ], [ 37.38232167, -122.15171758 ], [ 37.3826398, -122.15178036 ], [ 37.38294604, -122.15184264 ], [ 37.38325235, -122.15190458 ], [ 37.38355637, -122.15196543 ], [ 37.38386583, -122.15203945 ], [ 37.38417047, -122.1521117 ], [ 37.38447544, -122.1522008 ], [ 37.3847595, -122.15231454 ], [ 37.38505698, -122.15241395 ], [ 37.3853594, -122.15250213 ], [ 37.38560981, -122.15272559 ], [ 37.38587685, -122.15289608 ], [ 37.38612831, -122.15307537 ], [ 37.386369, -122.15330226 ], [ 37.38660109, -122.15352321 ], [ 37.38681491, -122.15376042 ], [ 37.38703695, -122.15399578 ], [ 37.38723661, -122.15426073 ], [ 37.38741594, -122.15453155 ], [ 37.38758433, -122.15481075 ], [ 37.38774539, -122.15510789 ], [ 37.38789928, -122.15540746 ], [ 37.38803876, -122.15572505 ], [ 37.38816025, -122.156047 ], [ 37.38827425, -122.1563775 ], [ 37.38837114, -122.1567204 ], [ 37.38845823, -122.15706146 ], [ 37.38852302, -122.15740629 ], [ 37.38858496, -122.15776739 ], [ 37.38863873, -122.158132 ], [ 37.38869141, -122.15849049 ], [ 37.38875059, -122.15884924 ], [ 37.38880101, -122.1592167 ], [ 37.38885423, -122.15958014 ], [ 37.38890729, -122.15994434 ], [ 37.38896215, -122.16030945 ], [ 37.38901726, -122.16067063 ] ]

I have tried using onthegomap.com but they export only in GPX and I have been unable to convert it to something like above.
Are there any databases for this or any websites that may facilitate this?
","['data-request', 'geospatial']","(From comment)(if I understood correctly,) any geojson will be close enough to the format you are looking for. For example:https://raw.githubusercontent.com/datasets/geo-countries/master/data/countries.geojson"
Categorized social media posts dataset,"
I'm looking for a dataset of categorized posts from social media (preferably twitter) the posts shall be labeled with something like: sport, politics, economy, art, etc.
","['data-request', 'social-media']",
US Interracial Marriages,"
I'm trying to find data that:

is from the US AND
from 1980 AND somewhat recent (within ten years) AND
Interracial Marriages--Race/Ethnicity of the two people involved

I'm trying to look on the Census site but it's  getting overwhelming. 
","['data-request', 'us-census']",
Datasets for emotion recognition in German dialogues,"
I am currently working on the topic of emotion recognition in German dialogues (Speech). So far I only managed to find a single dataset related to this topic: Berlin Database of Emotional Speech. 
Is anyone aware of similar open-sourced datasets that I can use?  
","['data-request', 'language', 'germany', 'audio']",
Daily calorie intake and body weight dataset,"
I'm devising a mathematical method to filter out weight fluctuations from daily weight measurements. To validate the method, I would require a dataset containing daily weight measurements and calorie intake information from a population. Ideally, the dataset would also include body fat measurements (any of these would be helpful: bioimpedance, skinfold caliper, underwater weighing, DEXA, BodPod, etc.)
Is anyone aware of an open dataset containing such information?
","['data-request', 'medical']",
Is there any kind of database that saves citations together with the text that they are attached to?,"
Let's say I have a paper A that cites a paper B. Two explicit citation in paper A might look like this:

Recently it has been shown that electrons exists [reference to paper B].

and

Electrons have a mass of 9.10938356(11)×10−31 kg [reference to paper B].

What I'm looking for is a database that would contain entries like this
{
    ""source"": ""ID_of_paper_A"",
    ""target"": ""ID_of_paper_B"",
    ""text"": [
        ""Recently it has been shown that electrons exists"",
        ""Electrons have a mass of 9.10938356(11)×10−31 kg""
    ]
}

If there is no such database, is there any hope to extract this kind of information using some form of web scraping? Considering the amount of papers that sit behind paywalls, I have the suspicion this would no be feasible.
",['academia'],
Informed Consent Language,"
Is there a requirement to include language explaining the Open Data Policy (de-identified data will be shared publicly) in the informed consent document if the data is being collected as part of human subjects research and will be uploaded to the DDL?
I've heard reports that this is a USAID requirement but I've not seen any documents or publications stating this requirement. 
According to 45 CFR part 46, when data set is rid of identifiers, it no longer considers the dataset to contain human subjects and consent for use of that data is not required. 
We have been including this language because other recipient organizations have told me it is required but I'd like confirmation. 
",['research'],
Availability of location-based sleep datasets?,"
I am interested in spatial patterns of sleep quality (e.g. differences between neighborhoods in the same city, or even streets).
Is there any interesting sleep dataset that contains the location?
I am aware of the datasets listed at the National Sleep Research Resource, but they don't include any geographic data.
Did anyone have luck getting data obtained with apps like Sleep Cycle for research? They publish aggregated statistics, but it seems that getting the data is not possible (which is understandable given the sensitivity, but I am still hoping for any related dataset).
","['geospatial', 'medical']",
psychological / patient dialogue data for nlp analisys,"
I search data for chatbot for psychological task.
I found some source about it:
https://berkeleysciencereview.com/nlp-for-psychotherapy/
Where can I find data with dialogue of psychologist and client in session
to create chatbot (using deep learning) which can communicate with client?
","['data-request', 'medical', 'nlp']",
Can we still submit data after the grant ends?,"
We currently submit data collected from a USAID-funded weather station.  We installed it as part of a grant.  As I understand, we have access to submit to the DDL because we have an active grant.  After the grant is over, can we continue to update the data asset with the weather data?
",['usaidopen'],
Italy's microdata sources,"
Italy has a huge problem with individual-level data. ISTAT provides some data but on specific topics and rarely they are year-to-year data. INPS has some other data but only regarding labor market. 
If one wants to do economic/social research about Italy   and needs individual-level data, where he should look? Which are the best sources of microdata about Italy? I am thinking about data on education, health, crime, ...
","['data-request', 'demographics', 'italy']",
Is there a free publicly-accessible repository to store datasets derived from experiments?,"
I had obtained some results based on sensor data obtained from experiments that I had conducted.
In the interest of allowing others to reproduce or improve on my work, is there a way to make this data available online in a way that is free and publicly-accessible?
",['releasing-data'],"From here, it shows the following table of data repositories.Open Science Framework, Zenodo, and Mendeley Data are the most viable options for free data sharing. With the other options either not being completely free nor accessible to everyone."
OpenFDA End Point Updates,"
With respect to the US Food and Drug Administration's API, I haven't seen the endpoints updated since 8/12/19.  Did something change or is this common?  I've noticed the endpoints refreshed fairly regularly over the past 6 months.
","['api', 'openfda', 'releasing-data']",
What bible translations into different languages are public domain?,"
It’s hard to find them, wondering if we could collect them here.

Amharic
Tibetan
Chinese
Greek
Inuktitut
Cheyenne
Pashto
Etc.

",['books'],
Open Translations of Documents,"
I just put together some open translations of an open document. It has the english version and several other languages.
I'm wondering if there is anything else like this that is open. Some free documents that have translations into multiple languages. I can imagine the Bible is, but I'm not sure the translations are free and open (if they are please correct me). I have seen constitutions in the source language perhaps translated into English, but other than that I can't think of any.
Wondering if one could put together a list of some of the documents which have at least a one or a few translations which are also free / open / public domain.
",['translation'],
Database of welcomeness towards tourists,"
Context
In order to solve overtourism and generally improve tourists' experience, I want to add to my travel app a feature which suggests alternative destinations where tourists are more welcome.
For instance, a user wanting to climb the Everest would be suggested other mountains that offers the same experience while being more resilient to mass-tourism. A user going to a small Italian village that has become overcrowded due to social networks trending would be suggested similar villages that on the opposite are struggling to attract enough tourists to sustain local activity.
Need
To measure welcomeness to tourists, I am looking for such databases:

General opinion of year-long local residents about tourists, ideally as a number from 0 (not welcoming) to 100 (most welcoming).
How hard the local tourism promotion board is trying to bring tourists, ideally as a number from 0 (not trying to attract tourists) to 100 (trying the hardest).

At village/neighborhood granularity, ideally for the whole world but national databases are OK too.
Bonus
Bonus if residents opinions statistics are divided into: tourists from the same ethnicity, tourists from the same country, other tourists (in order to track potential racism/xenophobia).
Bonus if promotion board statistics details whether the board wants to increase/decrease some types of tourists in particular (for instance, I have heard that some Hawaii tourism authorities are trying to discourage budget-conscious tourists from visiting).
","['data-request', 'survey', 'travel']",
Dataset for sports actions,"
I have a deep learning task where I have to recognize sports actions related to a specific sport (e.g. football, football, basketball, volleyball) using the YOLO algorithm. What can be a good dataset? At the moment I have tried with UFC but with poor results
","['data-request', 'sports']",
Where can I get a dataset of ultrasound images?,"
I have a machine learning task that i wish to pursue - disease detection by ultrasound image analysis. For the task i will need labeled(diseased or healthy) ultrasound images dataset. Please suggest how and where can i get it.
",['data-request'],
Does anyone know where I can find a list of geodetic benchmark locations for all of Canada?,"
Does anyone know where I can find a list of geodetic benchmark locations for all of Canada?
I am looking for a few specific control monuments in Arctic Canada with accurate coordinates
","['geospatial', 'canada']",
Find all Wikidata items whose image (P18) URL contains a certain word,"
I am trying to find all Wikidata items whose P18 property is an URL that has the word ""Montage"" anywhere in its filename.
Example:

I managed to find items by their complete P18 filename:
SELECT ?item
WHERE 
{
  ?item wdt:P18 <http://commons.wikimedia.org/wiki/Special:FilePath/Montage%20Columbus%201.jpg>.
}

But now I would like to add wildcards to that. My attempts with * and contains/regex all failed.
How to achieve that?
","['images', 'wikidata', 'sparql']",
College Scorecard: determining how representative data is of the overall undergraduate body,"
The Question
The College Scorecard Documentation Report repeatedly mentions that some data only represents undergraduates that are recipients of Title IV federal aid:

Most of the metrics of institutional performance described in this appendix—those based on data in the NSLDS, or matched earnings data for students appearing therein—are based on undergraduate students receiving federal aid. Moreover, institution-specific measures of debt, default, and repayment are based on the subset of students with federal loans.

What is the best way to determine the concrete subset percentage used for a given measure? Is it a ""cohort"" column, like Number of students in the family income cohort?
If so, why do the cohort sizes vary so drastically? The family income cohort size is usually about 10-20%, while others are much higher.
Finally, why is the earnings cohort size (COUNT_ED) always NULL?
A Broader Problem
I'm investigating this question because I want to determine how representative some data fields are of the entire undergraduate body. For example, the data shows that Harvard is incredibly economically diverse: its median family income is $33.07K! This is very hard to believe, and I'm trying to explain this phenomenon. Is there a better way to do this?
","['usa', 'education', 'collegescorecard', 'metadata', 'demographics']",
Data on amount of students per university (and subject) in Germany,"
Is there open data on the amount of students per university (and subject) in Germany?
I found some data on ""Hochschulen"" which seems quite outdated: https://de.wikipedia.org/wiki/Liste_der_Studentenwerke_in_Deutschland. Optimally the data should be able to be updated automatically.
","['data-request', 'academia']",
data with video to text transcription,"
I search data and script (java, python) where from video, text is transcripted into documents.I.E recognize speech from video to text
i found this
https://github.com/Naki21/google-speech-to-text
but as i can see, it is google API and most likely it is paid and
it is not a fact that the quality will be acceptable.
Because the task is difficult, therefore I am looking for  free script where with video the text is recognized into  text document. 
Is there sometrhing about it on github or kaggle?
because even if the quality is poor, at least it is for free
","['python', 'video']",
Ontology for theme of a text,"
I'm looking for an ontology that describes the theme of a text (eg. ""finance"", ""leisure""). A text can have multiple themes. Preferably the ontology would also have room to store a match percentage:
{
    ""theme"": ""finance"",
    ""match"": ""96.2%""
}

I looked at foaf:theme but it appears to be deprecated and doesn't allow any extra properties.
","['rdf', 'ontology']",
Allergies Dataset,"
I was wondering if there is a dataset that contains a user and the different (food) allergies the user has or doesn't have. So something like:
       Food1  Food2  Food3   ...
User1    0      1      0
User2    1      0      0 
User3    1      1      1 
...

I've looked at various datasets, but they all seem to represent a population, not an individual user.
Any suggestions would be very much appreciated!
","['data-request', 'food']",
SPARQL get all the data before it reaches timeout,"
I am trying to get all the city names of all countries in the world using this below query. Whenever I execute this below query it returns this message ""Query timeout limit reached"".
Is there any other way to get all the data before it reaches timeout limit?
SELECT ?country ?countryLabel ?city ?cityLabel
WHERE
{
  ?city wdt:P31/wdt:P279* wd:Q515;
        wdt:P17 ?country .

  SERVICE wikibase:label { bd:serviceParam wikibase:language ""[AUTO_LANGUAGE],en"". }
}
ORDER BY ?country

","['wikidata', 'sparql']",
MIDI files on Archive.org,"
I'm looking for a large dataset of MIDI files or a machine learning project. Is it possible to filter for a specific file type on archive.org? In my case MIDI (.mid) files.
","['music', 'download']",
Request for Image Dataset of Animal Skin Disease,"
I was wondering if there is a dataset that contains an image of animal skin disease, need it for training dataset for my final project to detect scabies in animal skin.  I couldn't find it anywhere.
",['data-request'],
"Looking for DEM, DTM, DSM for northern England","
I'm looking for DEM or similar (DSM, DTM) from which to make a slope map to identify suitable paragliding hills in an area of northern England - the Yorkshire Dales.
I would like to be able to resolve cliffs over 10m, so the higher the resolution the better.
","['data-request', 'geospatial', 'uk']",
Find most-depicted Wikidata items that have no image,"
Wikimedia Commons has a new feature where a picture can have metadata saying it depicts a given Wikidata item.
For instance, https://commons.wikimedia.org/wiki/File:Grandpark_Plaza.jpg depicts https://www.wikidata.org/wiki/Q11303 (skyscraper).
My question: How to find the Wikidata items that:

Are used as a ""depicts"" value by a lot of Wikimedia Commons files
Do NOT have a P18 (image) property

It is tricky because it involves two Wikibase servers: Wikidata, and the Structured Data on Commons (SDoC)'s Wikibase server. I am open to any solution, SPARQL or not, hosted or not, open source or not.
","['wikidata', 'sparql', 'wikimedia-commons', 'wikibase']",You can do a federated query with the Wikimedia Commons endpoint and the Wikidata endpoint. The query below does take a while to complete - though.Short link: https://w.wiki/5MyH
"Free, Limitless GeoJSON APIs for nation shapes?","
I am looking for some API endpoints that return GeoJSON shapes for each nation. I am not interested in downloading shapefiles. I need some lightweight (not super accurate) nation shapes for every nation that I can call frequently to overlay on a map webapp. 
","['geospatial', 'api', 'json', 'openstreetmap']",
Per Diem Rates - CSV file download (data.gov),"
I have a couple of questions related to the Per Diem Rates information that inventory.data.gov provides.

We have been downloading your Per Diem rates CSV file from the following links in the recent past, but the link now (I have been trying since yesterday) gives me a ""404 Not Found"".

This was the link we have been using in the past:
https://inventory.data.gov/dataset/ad729937-b245-4eec-a88d-b72eb36d8106/resource/8ea44bc4-22ba-4386-b84c-1494ab28964b/download/perdiemreimbursementrates.csv
Is there another/changed link for the older CSV version?
I am aware of the other page/link which gives an Xls file:
https://www.gsa.gov/travel/plan-book/per-diem-rates/per-diem-files
but the data layout is completely different, and more so it doesn't give Zip Code-related information. On the other hand, the CSV Version gives the information in the way it can be used for what is needed. It is just not the data formats (CSV v/s Xls) that are the issue for us, but the data content as a whole that is an issue with the Xls file.

We have also been using the Per Diem API to get rates. This is the link we have been using:
https://inventory.data.gov/api/action/datastore_search?resource_id=8ea44bc4-22ba-4386-b84c-1494ab28964b&limit=300000&filters=%7B%22FiscalYear%22:%222019%22,%22Zip%22:%2292692%22%7D

This API has been having some issues since the last couple of days that we have been monitoring it:
""Access denied: User  not authorized to read resource 8ea44bc4-22ba-4386-b84c-1494ab28964b"", ""__type"": ""Authorization Error""
And today it has been giving an ""Internal Server Error"" off and on.
We are aware that GSA is now offering a new API for the Per Diem rates.
https://open.gsa.gov/api/perdiem/
We would like to know if the older API (from inventory.data.gov) will continue to be offered for Customers who would like to use it.
Can you please help or guide me to some contact at inventory.data.gov who can answer the related questions?
",['data.gov'],
Seeking Population Dataset of provinces in Europe?,"
I applied the following function of the R Tmap package:
library(tmap)
data(NLD_muni)

NLD_muni$perc_men <- NLD_muni$pop_men / NLD_muni$population * 100

tm_shape(NLD_muni) +
  tm_polygons(""perc_men"", palette = ""RdYlBu"") +
  tm_facets(by = ""province"")

if you check the data inside the Tmap package with 
data(package=""tmap"")

You see a dataset called NLD_muni. It has detailed data of all provinces in the netherlands with its population.  I need a dataset like this (provinces + population) for further countries in Europe.
Where I can find such a dataset?
","['geospatial', 'europe', 'population']",
Where to find negative image dataset for Haar Cascade,"
Where can I get an image dataset with negative images for using with a Haar Cascade algorithm for image detection?
I would like to make an application to detect the basketball basket.
","['data-request', 'images']",
Dataset for German domain names (.de),"
I'm looking for a new DNS domain in Germany (.de) for a new service.
It would be very helpful to search .de domains using wildcards (regular expressions), e.g.
mysuperservice[0-9]+.de
mysuper-[a-z]+-[0-9]+.de

Since I did not find such a public service, I am looking for a open data dataset with .de domain names.
I'm only looking for domain names, not for contacts or other information about domains.
Ideally the dataset should be up to date (not too old...).
I found this question on Stack Overflow, but it is rather old and is covering all top-level domains, not just a single domain.
","['data-request', 'internet', 'germany']","Here is all I need (thanks to @philshem):https://github.com/tb0hdan/domainsThis repo containes crawled domain names, top level domains as well as subdomains.It's a good start for my searching purpose."
What is a good example of a hybrid data-set which has over 5000 entries?,"
I'm looking for a dataset which has the following properties:

Has more than 5000 entries
Has both numerical and categorical data
Is publicly available, free of cost
I want to test an algorithm, and I have been testing it on the Titanic dataset, but it has too few entries. I am looking for more examples of the same.

As a followup, is there an online resource which keeps tracks of all publicly available datasets with salient details (the type of dataset, number of entries, origin, etc) at one place?
Thank you!
",['data-request'],
Back and front images for clothing,"
I am developing an AI application for clothes designing.
To train the model we need front and back images of clothing (T-shirts, formal shirts, pants etc.) drawings/designs.
Like this:


I want a dataset of 5000 front and back images of clothes.
","['machine-learning', 'images', 'fashion']",
Seeking 20th Century railroad ( 1900s to Today ) GIS data,"
I am seeking GIS or geospatial data that has the oldest railroad in the United States, or more specifically in the state of Colorado.
Must have come from the beginning of 1900s to present.
","['data-request', 'geospatial', 'download']",
Dragonfly Migration Worldwide,"
Looking for a dataset that holds sightings of dragonflies worldwide, preferably by species.
Should include date and Long/Lat and go back at least 5 years.
This could be from multiple sources where localised datasets are available so might need to combine into one answer
","['data-request', 'geospatial', 'biology']","iNaturalist has worldwide observations of biological organisms. You can do a bulk download here. This data is not strictly ""open"", because login is required. However it is free to register.Use this query to download observations of Suborder Anisoptera (Dragonflies): quality_grade=any&identifications=any&taxon_id=47927There are currently 357100 observations of dragonflies, going back at least as far as 2000. The observations are identified, sometimes only to genus-level, often to species level. Identification is done by a combination of image recognition software and crowd-sourcing. Identification is more reliable (but still not 100% accurate) if you narrow the query to ""research grade"" observations. Most observations have photographs, so if you are an expert you can correct some of the identifications yourself.Here are the instructions for bulk downloads from iNaturalist's FAQ:How can I download data from iNaturalist?Anyone with an account can export data from iNaturalist as a spreadsheet in csv format. You can start from the Explore page and click download in the lower right of the filters box. Or you can go directly to the export page (https://www.inaturalist.org/observations/export).If you plan to publish a paper using iNaturalist data, we recommend downloading iNaturalist data from the Global Biodiversity Information Facility because they will issue a citable DOI (see below for more details).
  Source: https://www.inaturalist.org/pages/help#export"
Publicly available dataset for failure prediction in servers,"
Is there any open dataset available for anomaly/resource contention failure prediction in servers. It should have different timeseries features like CPU, memory usage etc. Along with a label indicating the type of failure.
",['time-series'],
Free GIS data that doesn't require attribution for printing on products,"
I'm keen to make some products to sell with map graphics printed on them. As these are physical products (eg tshirt etc) I don't want to include the attribution in the design.
Is there a good source of GIS data available for commerical use without attributions?
Most require some sort of attribution. I'm talking pretty basic data such as country outlines, road lines, but would also love contours, lakes etc.
Free of course would be good.
US property outlines can require attribution
","['geospatial', 'uses-of-open-data', 'openstreetmap']",
Finding zoning GIS maps/shapefiles of US online,"
I need the classification of residential, commercial and mixed areas of cities in the US as defined by mayor councils. Where can I find the zoning GIS maps/ shapefiles online?
","['geospatial', 'usa']",
Getting updated list of US Zip Code with latitude and longitude?,"
I have the old list of US Zip Codes which is missing some of the zip codes.
How can I get the Updated list of Zip Codes in CSV format?
","['data-request', 'usa', 'postal-code']",
psychotherapy video session,"
I am looking for real video sessions of psychotherapy on real people, and not just video lectures with theoretical material.That is, a video case study of work with various problems (depression, phobia, PTSD, anxiety, loss of loved ones, and so on).
Are there any such sessions in the public domain?
","['data-request', 'video']",
Theewaterskloof Dam Bathymetry,"
I am trying to find bathymetry for Theewaterskloof Dam, South Africa, in GIS format. Almost any resolution will do. Bathymetry latest before 2000 at least or the latest one is also good. Where can I start searching? I have tried a few sites and links. No luck though!! 
","['geospatial', 'africa']",
Mapping of drug names to generics,"
Dataset: Obtained from FDA AERS
I would like to map the drug names to its generic name.
Example: Arthritis Pain, Aspir 81, Aspir-Low, Bayer Childrens Aspirin etc
would be mapped to aspirin
Is there a dataset where such mappings are available(preferably in CSV format) so that it is possible to iterate through the FDA AERS dataset and replace the drug name with their generics.
",['openfda'],
Looking for malware detection dataset,"
I'm looking for malware detection dataset. I have found some but they have very few features from the pe headers, which is not helpful for detecting malware as APIs/resource .... It would be better if there is raw files and i extract the features myself in a server.
",['machine-learning'],"we created Windows API calls sequence of metamorphic malware. In our research, we have translated the families produced by each of the software into 8 main malware families: Trojan, Backdoor, Downloader, Worms, Spyware Adware, Dropper, Virus.
https://github.com/ocatak/malware_api_class"
ERA5 reference time zone,"
I am using temperature information from ERA5 reanalysis hourly data on a single level, and I am confused about time reference.
If I download global temperature data for a specific day and time (for example, 2000-08-08 07:00) is this UTC or is it adjusted to the local time of each point of the grid? In other words, will I be looking for 07:00 in the US and also for 07:00 in Germany? Or they are referred to UTC, and in the US I will be looking for nighttime temperature while in Germany it will already be morning?
","['weather', 'climate']","UTC (Coordinated Universal Time) is the only way that makes sense for a global dataset. Using local timezones would be an absolute nightmare for exactly this reason. I found several references to UTC in the ERA5 data documentation. 'time' in analyses
  Each analysis has a validity time, i.e. the time the data values refer to (not the time when the analysis was computed). All validity times are in hours UTC. source'time' in forecasts
  Each forecast starts with the atmospheric conditions at a specific 'initialization time'. In ERA5 a new forecast is computed twice a day, with initialization times of 06:00 and 18:00 UTC. In the ERA5 data archive, for forecasts, 'time' (and date) refers to the initialization time.I didn't anything that explicitly says they used UTC throughout, but the documentation is hundreds of pages long and I didn't read it word-for-word. If anyone manages to find specific confirmation whether all the times in this dataset are in UTC, please provide a direct link. "
Getting *current* members of US Congress via the GPO API?,"
The Government Printing Office API What's Available site links to the Congressional Directory, but the most recent CD available appears to be the 115th (2017-2018).  Does anybody know if this is intended behavior, or if there is another GPO collection that contains listings for the 116th Congress (2019-2020)?
","['usa', 'api']","Posed this question as an Issue on the GPO GitHub repo, got this as an answer:This has not been added to the system yet. Once the volume has been printed, it will also be added to govinfo and made available via the API.The U.S. Code section indicates that this is to be printed and distributed ""as early as practicable"". My understanding is that information is still being compiled.The first edition of the CDIR for the 115th Congress was made available in June 2018."
Business term abbreviation dataset,"
I'm looking for a list containing common abbreviations for business terms. For example, ""revenue"" --> ""rev."". 
I found this post but that links to common acronyms and abbreviations.
A friendly format would be great, but even if I could scrape to collect this stuff that would be helpful.
(Of course, the problem of converting a given word into an abbreviation seems like a very extensive NLP project, which I'd like to avoid.)
",['data-request'],
"Seeking GIS datasets that has the degree, minutes and seconds world longitude and latitude","
I am seeking a GIS datasets that has the longitude and latitude that I really need badly that has the degrees, minutes  and seconds .... I am aware that there is 1 degree, 5 degree, 30 degree and 45 degrees.... I do not want them...
Where do I find them ? I have looked around on the internet and didn't find it....  
","['data-request', 'download']","I'm not aware of any such existing datasets, but you can make your own layer in either QGIS or Arc.  Search for ""create fishnets"" in GIS Stack Exchange.  BTW, a worldwide layer at your granularity will be immense, approaching 4 billion(!) polygons, which probably explains why you didn't find one. You may want to create such a layer at a regional scale instead."
Seeking soil depth data for Washington State?,"
I need to make a map of Whitman County showing different classes of soil depth available in Whitman County.
I have been searching this data in SSURGO and the Web Soil Survey Database. The only thing close to this that I can find is ""Depth to any restrictive layer"", but I cannot find the actual soil depth data anywhere I look.
If ""Depth to the restrictive layer"" and ""Soil depth"" are not the same thing, where can I find soil depth data?
",['soils'],
average (annual) salaries for occupations in the UK,"
I have occupations like this:
Joiner
Fitter
Smelter
Electrician 

and would like to obtain rough average (annual) salaries in the UK. Is anyone aware of such dataset(s)?
","['data-request', 'uk', 'europe']",
Where can I find a good Pokemon database file?,"
Im developing a Pokedex with Android and I need a good and complete Database file with all Pokemon and related data (abilities , moves , evolutions , natures , breeding , items.. ) . Is there any decent .db file ?
",['database'],
openFDA - how do I get the brand name of a generic drug,"
I need to build an api that can get the brand name of a generic drug,  some generics have several hundred records, using pagination to go through this and parsing the data is not practical for my needs, is there a way to directly get the brand name of a generic using openFDA API
https://api.fda.gov/drug/ndc.json?search=brand_name:""atorvastatin""+AND+finished:true&skip=100&limit=100
",['openfda'],"I don't think there is a currently available openFDA API that you can directly query and be guaranteed to get back - in a single record - a list of all possible brand names. In some cases, you may get only one matching record for your query. For example, the following query against the openFDA drug product label endpoint returns a single matching record:  https://api.fda.gov/drug/label.json?search=openfda.generic_name:%22ATORVASTATIN%20CALCIUM%20TRIHYDRATE%22&limit=100But for other generics, to find all the brand names, you will have to parse through multiple records in the response if you are using one of the current openFDA APIs."
Paragraph Similar Pairs Dataset,"
I have been working on a project where I need to find whether two paragraphs convey the similar meaning. Same as Quora Question Pairs on Kaggle, but instead of questions, paragraphs. But I could not find any dataset for that. So I tried using Google Translate by taking a paragraph translating it into several layers of language and then finally translating back to English. So these two paragraphs are similar and then taking some random pairs as not similar. E.g. translating a paragraph from English to French, then from French to Spanish then from Spanish to English again. The problem is that these two paragraphs are so equal. So can you please link me to some dataset for this?
","['data-request', 'language']",
"San Francisco 311 Open Data, what does ""mobile"" mean under the category ""cases by channel""?","
I'm checking out the San Francisco 311 Open Data (https://sf311.org/information/reports), but wanted to know what does ""mobile"" mean under the category ""cases by channel""? 
SMS Text? Whatsapp? Call? App? 
",['uses-of-open-data'],
"Gem, gemstone, crystal, rock, minerals image and other properties dataset","
I'm looking for datasets that contain images of crystals, gems, rocks and the like.

My most important goal is to have the crystal name and its image so I can make a machine learning classifier for them from images.
A secondary goal is to have its other properties, like hardness, and metaphysical properties.

Format ideally: SQL database, or something easily parsable
Have only found
this one
with only 4000 images so far, so anything would be helpful
","['data-request', 'images', 'classification']",
IMDB Award Data,"
I was looking for award data (oscars? golden globes?) on this site: ftp://ftp.fu-berlin.de/pub/misc/movies/database/frozendata/
I saw this https://www.imdb.com/event/ev0000292/1963/1/?ref_=ev_eh and thought ""oh the ftp site may have an ""event"" one but there isn't one listed. Can anyone assist?
",['data-request'],
Is there a large database of unique surnames and their (origin) language?,"
Let me explain the phrases I use in my request:

large: I'm looking for multiple languages (especially european languages if this constrain helps) and at least 2K surnames per language. But the more the better.
database: I expect that there is somewhere a machine readable file (json, txt, xml, ...) with all the names and languages or a zip file with many such files.
unique: I'm not interested in how popular a surname is, I'm just interested in which surnames belong to a given language. Also variants of names are welcome.
surnames: I want surnames or what comes closest to a surname in the language the name comes from.
(origin) language: Even though there are many german speaking people named ""Nguyen"" this name shall not be classified as ""german"" but as ""vietnamese"".

I already looked at several places and found the following unsatisfying results:

Multinational list of popular first names and surnames?: This question is a good starting point but it aims for the popularity of names and the answers are more about first names. Also because it's about the popularity of names it is about where names are being used instead of where they come from.
heise.de: From the answers of the aforementioned question I got this list of first names which is pretty close to what I want - but these are first names not surnames.
Wikipedia: These lists are way too short but I like that the names are broken down to countries.
Namespedia: This site seems to have a large database of surnames but I can't access them easily. I would have to write a crawler to go through the entire website.

Is there a database that meets all my requirements?
","['data-request', 'language', 'global', 'names']",
Datasets based on casual conversations for chatterbots,"
I am building a chatterbot that can answer questions related to tennis. I wish to know if there any any available datasets than can answer casual questions like ""How are you"", ""How is the weather today"" so on and so forth. 
Edit 1: I am using Python and MongoDb
","['data-request', 'nlp', 'python', 'ai']",
I'm looking for a dataset which provides information about gas leak in a pipeline,"
I am currently doing a project on gas leak source localisation in pipelines for which large number of data is required but i have not got a good dataset from other sources.So i would like to know if a dataset is available or any gas leak simulation platform is available for me to work.the data must have the location of the leak and the concentration of the gas that was leaked and a minimum of 1000 values is required for training it.Most sets only show location and do not specify leak concentration.I have not been able to get my hands on industrial data regarding these pipeline leaks.
",['data-request'],
Verifying data accuracy on earnings by family income,"
In the May 2019 collegescorecard data there are slightly over 150 institutions that report mean earnings 10 years after attending for the highest family income of $75,001+ (MN_EARN_WNE_INC3_P10) as being lower than earnings for the lowest family income $0-$30,000 (MN_EARN_WNE_INC1_P10). This goes against intuition although it is possible that some of this is correct. Is there anyway to verify the extent to which MN_EARN_WNE_INC3_P10 < MN_EARN_WNE_INC1_P10 can be true? Some of the differences are in excess of 50%.
",['collegescorecard'],
Any good resources for book rating data?,"
I'm writing a python script that collects book ratings and analyses them using bayesian statistical models. I only need numerical ratings (e.g. percentiles, stars, 10 point scale). Any other attributes of the review are extraneous. It is important that I have the number of ratings per rating level and not just the total number of ratings and the average rating. For example, if the book has been given a rating of 4.3 out of 5 stars with a total of 5,000 ratings, I need to know exactly how many of those 5,000 ratings are 5 stars, 4 stars, 3 stars, ect.
So far I've only found this kind of detailed information on Goodreads. I've looked into scraping amazon but this seems clunky given that the desired information is stored on separate pages and would require 5-6 page scrapes per book.
Does anyone have any suggestions as to databases or websites where this kind of rating information for books is available either through an api or scraping?
",['data-request'],
Which examples of real-world situations follow the Cauchy distribution?,"
I am doing a project focused on the Central Limit Theorem, and in one part of it I want to use real data to see how the histogram approximates to a normal distribution. I also want another part which features data for which it does not work (i.e the sample mean does not follow a normal distribution) but I have not been able to find any. Any suggestions? I wrote in the title the Cauchy distribution because it is a well-known example, but any other which may work is fine. I have already looked for data such as annual maximum one-day rainfalls or light luminosity, but it hasn't worked so far.
",['data-request'],"The Cauchy distribution has infinite variance, so you are not going to find simple, real world examples.  However it is possible to mathematically construct examples.One possibility:  The ratio of 2 normal distributions where the mean of the denominator random variable is 0 will follow a Cauchy (or at least Cauchy like (it has been a while since I was in a theory class)) distribution.The location (x-coordinate) of the vertex (max or min) of a parabola is -b/(2a) where a is the coefficient on x-squared and b is the coefficient on x.  So if you fit a parabola to data that is really linear, then the estimate of the vertex location should follow a Cauchy.Here is some R code that does a simulation based on this:Rerunning this code with a larger sample size (n) does not narrow the distribution like it does with finite variance distributions.For showing when the CLT does not work, I would look at something very skewed instead of the Cauchy and just show that while in theory a big enough sample size will result in normality, ""big enough"" is very big.  Consider a binomial based on a very rare event, e.g. the number (or proportion) of people in your sample that have disease X (or trait X) where the probability of each individual having X is 1 in 1,000.  With a sample size of 5,000 (a ""big"" sample in most basic stats textbooks) the sampling distribution is still obviously skewed and not yet normal.Here is a line of R code to show this with simulated data:"
Drivers license and motor vehicle registration data for professional drivers,"
Is there a known API to pull driver's license data and MVR data for professional drivers, such as those working for freight forwarding companies?
",['api'],
Seeking a geospatial data of 1908 PLSS?,"
I am seeking geospatial data that has the PLSS Public Land Survey System (PLSS) in the United States and I need a 1908 one?
","['data-request', 'geospatial']",
Dataset for stock indices including ticker symbol and sector,"
For Dax30 there is a great (small) dataset including all firms of index (DAX30), the corresponding ticker symbol and sector:
https://de.wikipedia.org/wiki/DAX -->Zusammensetzung (first three columns)
Name    Symbol  Branche 
Adidas  ADS     Bekleidung  
Allianz ALV     Versicherungen  
BASF    BAS     Chemie  

Question:
Is there an equivilant dataset for S&P500, EuroStoxx 600, MSCI world, etc.
","['data-request', 'finance', 'stock']",
"Datasets with x,y coordinates of ball, puck and other sports balls/projectiles","
I want to train TrackNet more because its accuracy is not that good.  
TrackNet Gitlab repo
The tracked tennis ball wobbles unnaturally on tosses for serves, etc.  
So I figured that following the intuition of tensor2tensor and other transfer learning schemes of training TrackNet on other sports or other projectile videos and images where the x,y coordinates of the object being tracked on the 2D video frame are provided.  
I am probably going to use VGG annotator to create more tennis specific data and post in on Github but in the meantime if anyone knows of any public datasets out there, please let me know.  
","['data-request', 'sports']",
Historical precipitation for every place in the USA,"
I am here to seek historical precipitation data that displays every area in the United States, but specifically in southwest Kansas on the grassland. Here is the screenshot I am sharing.
With:
We would like to find an interactive map that can display in 7, 12, 24 or so hours, or at least a day or so in the past 30 days...
Can you suggest a website?

",['data-request'],
Where to find Medical data Survival analysis?,"
I have difficulty finding an open-access medical data set with time to an event variable to conduct survival analysis. Where can I find a multivariate data set, preferably with a few hundreds of observations?
Besides those that come with JM R package.
","['data-request', 'medical', 'uses-of-open-data', 'research', 'analysis']","Survival Data SetsHeart transplant dataData on 69 patients receiving heart transplants. Taken from ""The
Statistical Analysis of Failure Time Data"" by Kalbfleisch and Prentice,
Appendix I pages 230-232 from stalib data depository.Ovarian cancer dataChemotherapy after surgical treatment. 26 women with minimal residual
the disease was randomized to cyclophosphamide with or without adriamycin.
Survival time in days, status (0 = censored), treatment (2 = combined), age
in years. Example 4.9 in D. Collett, Modelling Survival Data in Medical
Research, Chapman & Hall, 1994 (pg 141)Cervical cancer dataSample of 30 patients from a randomized study of radiotherapy with and without a new radiosensitizer. Based on data from the MRC Working Party on
Advanced Carcinoma of the Cervix, Radiotherapy Oncology 26:93-103, 1993.
Analyzed in and obtained from MKB Parmar, D Machin, Survival Analysis: A
Practical Approach, Wiley, 1995. Group = treatment (2 = radiosensitiser),
age = age in years at diagnosis, status: (0 = censored)
Survival time is in days (from randomization).Primary Biliary CirrhosisThe data set found in appendix D of Fleming and Harrington, Counting
Processes and Survival Analysis, Wiley, 1991. The only differences are:
age is in days
status is coded as 0=censored, 1=censored due to liver tx, 2=death
the sex and stage variables are not missing for obs 313-418and more"
Realtime or regularly updated gravitational dataset(s) for Earth?,"
I need access to regularly updated gravitational readings from gravimeters around the globe. 
Is there any such available dataset?
","['data-request', 'geospatial']",
Image Dataset for basic human actions,"
I need to find an image dataset of human actions including sitting, walking, falling, and standing.
Although I searched, I could only find video datasets.
If anyone could share an image dataset with mentioned categories, I would really appreciate it
","['data-request', 'machine-learning', 'images']",
UDI Dataset JSON parsing efficiency TANKED after July 07 (Using Azure Data Factory),"
I'm finding that my ability to parse the JSON using Azure Data factory is not possible after file updates on July 07. The process, which took 10 minutes previously now takes 50+ hours.
Is anyone esle experiencing an issue with a certain download file or have similar problems with Azure Data Factory?
I believe I have isolated the problem to file content itself, as all other system parameters remain constant.
Was there any issue with the new submissions / updates to the dataset? This happens on 510k to a smaller extent - as there are very large arrays in the JSON.
Is there a way of identifying the largest arrays in the full UDI endpoint?
",['openfda'],
Transfer from one 4-year college to another 4-year college,"
I am trying to understand how students who transfer from one four-year college to another are counted in earnings data--I understand they are counted by their original institution, but do they also show up in earnings data for the institution that they transfer to?
",['collegescorecard'],"I have forwarded your question on to those familiar with the data and this was their response: Earnings for the student would be counted at both institutions if they
  were federally aided at both institutions. If a student was aided at
  the original school, then transfers and doesn’t receive Title IV aid
  at the new school, they would not be identified at the new school
  through the cohort construction process.  The end of page 36 and top
  of page 37 in the data Documentation Report provide more
  information on this topic."
Famous datasets that fits well with Mixture Models,"
I am looking for some ""famous"" (i.e. citable as a paper) datasets that has been successfully fitted by a Mixture Model of any kind. Ideally, it would be better if such paper also have a link to a github repository with the code used to run the experiments. 
",['data-request'],
How come there are missing entities in this SPARQL query?,"
I was interested in listing all books,
so I wrote:
SELECT ?book ?url WHERE {
?book wdt:P31 wd:Q571 .

OPTIONAL {
  ?url schema:about ?book .
  ?url schema:inLanguage ""en"" .
  ?url schema:isPartOf <https://en.wikipedia.org/> .
}}

but somehow this cute book which I read in the past ""The Little Prince"" was missing, although
Q25338 it appears in wikidata.
The Wikipedia page exists too:
https://en.wikipedia.org/wiki/The_Little_Prince
I searched for it in the results, and couldn't find it.
So how come I can't see this book?
Are there any explanations?
","['wikidata', 'sparql', 'wikipedia', 'rdf']",
Podcasts: Where can I find the average duration of episodes in a series?,"
It is easy to export an opml file from a podcast app. That provides me with information such as this. 
<outline text=""This Week in Google (MP3)"" type=""rss"" xmlUrl=""http://feeds.twit.tv/twig.xml""  htmlUrl=""https://twit.tv/shows/this-week-in-google"" />  

Is there a database or a method by which I could pull (or lookup or calculate) the average (or median) duration of each episode?
","['data-request', 'media']",
Methane emission free satellite imagery for seminar finals?,"
I am looking for a downloadable satellite imagery that provides methane emission data in the Middle East region (Jordan, Israel, Egypt, Lebanon and Syria). So far I have not been able to find any service or satellite with information open to the public. Next I plan to perform analyzes in the ENVI \ ERDAS program in order to make adjustments against the existing imagery. I would be happy to receive a reference to reliable sources.
","['data-request', 'geospatial', 'environment']",
Where can I find data to create small sample drug database?,"
For my diploma thesis I want to build an application to control medicine dosage and to do this I think about making sample database with like 1000 medicines with info most importantly about a dosage (4 times a day, every 4 hours...) and composition.
Does anyone know about some webpage that could easily provide me with this kind of information? I think about scraping it with Python. Or maybe somewhere there is already a sample database created like this.
Also, I think about making feature about what elements in medicine composition can be dangerous together. Something like: that you can't take some 3 medicines together. Maybe someone know and could recommend some webpage, article, maybe algorithm that could provide me more knowledge about this subject.
","['data-request', 'medical', 'python', 'drugs']",
How to choose which weather data to use in a time series?,"
I am conducting an air pollution case-crossover analysis and I'm in the midst of adding in pertinent weather variables. I cast a wide net and downloaded data from NOAA, National weather service and a few other sources. The problem is that for each variable, there are multiple versions of it. For example, we have maximum temperature, minimum temperature, apparent temperature, etc.
Are there any diagnostics I can employee to work out which variables I can use in my time series? Is there also any agreed upon variable? For example, is there literature out there confirming that perhaps Tmin should generally be used for such an analysis? Any resources or studies you may able to direct me to would be really helpful!
","['weather', 'time-series', 'climate']",
Understanding data discrepancy between NDC and annotated OpenFDA data,"
When comparing the NDC drug data at 
https://www.fda.gov/drugs/informationondrugs/ucm142438.htm and OpenFDA annotated data at https://open.fda.gov/apis/drug/ndc/download/  , I observed that the  FDA dataset has 150,000+ entries, while NDC has around 130,000 entries. 
I also had a look at the relevant code of openfda  over here: 
https://github.com/FDA/openfda/blob/master/openfda/annotation_table/combine_harmonization.py 
OpenFDA seems to rely mainly on NDC product.txt , but clearly, it seems to have has more data than NDC. 
Could anyone shed more light on why there seems to be data discrepancy? 
",['openfda'],
What is the difference between resource and category of DBpedia,"
My initial understanding of DBpedia was that resources are lower level entities and categories are higher level entities. Since categories are higher level, I thought that they do not have a corresponding resource page. 
However, today I realised that every entity in DBpedia has a resource page. However, now I am not clear why category pages are there when every DBpedia entity has a resource page. 

Example of a resource: http://dbpedia.org/resource/Support_vector_machine
Example of a category: http://dbpedia.org/resource/Category:Support_vector_machines

My question is, what is the difference between resource and category in DBpedia?
I am happy to provide more details if needed.
","['uses-of-open-data', 'linked-data', 'rdf', 'dbpedia']",
Open data for creating music,"
I am looking to create a track based on some medical data, assigning each value to a given scale (say pentatonic scale).
I need to find some medical data that's accessible and preferably in an easy to manipulate format. 
","['data-request', 'medical', 'music']",
Looking for electric vehicle charging station time series data,"
I am looking for time series of the electrical output of an electric vehicle charging station per hour, along with the number of electric vehicles that arrive at that charging station per hour. 
Is there any available?
","['data-request', 'time-series', 'energy']",
Online Dictionary for Scraping,"
Does anybody know if there is an extensive online dictionary other than Wiktionary that lists many words on a single page, as opposed to having to search for a single word?
None of the online dictionaries that I am aware of actually display lists of words for some reason.
","['language', 'web-crawling', 'english', 'dictionary']",
Are there any open data sets with sexist/racist/violent sentences?,"
I'm looking to make a ML model to attempt to determine if a given sentence/paragraph fits certain parameters. Right now the main one I'm looking at is particularly harmful sentences, so content that exhibits racism/sexism/violence or threats. 
I'd also like to be able to determine other things, but for now these are my main priority.
Are there any public data sets, or even ideas for things I can scrape in order to get this data? Here's an example of what I'd like to be able to get after cleaning the data
Content, Sexist, Racist, Violent
Someone needs to teach these pigs a lesson., 0, 0, 1
The batter crushed that ball!, 0, 0, 0

At the same time I'd rather let violent statements pass the filter than limit freedom of speech. So I'd like to be a little conservative with the model and want to make sure to be careful with its training. I'd rather minimize false positives instead of false negatives. So if possible I'd like to get data that contains similar language but doesn't fit the description such as
Black people are more likely to commit crimes., 0, 0, 0

I'm trying to censor messages where I can, so I'd also need a quite large data set in order to cover as many edge cases as possible.
",['data-request'],
Is there any institutions monitoring the scientific instruments performance?,"
In the last years, I've collected a lot of data from the datasheet of instruments used in surface metrology. That is useful for benchmarking the instruments we are developing. But I find strange that performances of instruments so important for the society are not monitored and made available from some institutions. And actually, the specs may be inaccurate. So my data are potentially biased by the adoption of different parameters and their calculation...
Am I missing something? Is there any register of the specs of the scientific instrument?
",['data-request'],
Seeking country boundaries shapefile which is pre-1980?,"
I am looking for a shapefile with the country boundaries as they were when Czechoslovakia existed as a country. 
Is there any online open source resource where I can find historical country boundary shapefiles? 
","['geospatial', 'historical']",
Are 6-digit CIP codes available with associated Schools for College Score Card,"
I'm looking for a specific dataset.
In the Data Catalog there is a large set of data through the College Scorecard, this data includes a listing of 2-digit CIP codes and the number of offerings by school.
Is there similar data but for more specific CIP codes? Looking to find this same list but split into individual 4 or 6 digit CIP codes. 
Essentially looking to have a list of college majors that are available at each school.
","['data.gov', 'education', 'collegescorecard']",
Location and data of wind turbines,"
Where can I find a geo-database of wind turbines for electricity/power production, including their location, capacity (max power), construction year, and other details?
","['data-request', 'geospatial', 'energy']","the USWTDB (US Wind Turbine DataBase), as seen on hackernewsThe USWTDB combines a 2014 USGS data set (48,956 wind turbines, including decommissioned and duplicate turbines) with a 2017 LBNL data set (43,827 wind turbines) and includes regular updates from AWEA’s WindIQ as well as the Federal Aviation Administration (FAA) Digital Obstacle File (DOF) and Obstacle Evaluation Airport Airspace Analysis (OE-AAA). The USWTDB is updated as frequently as quarterly as new data become available and will lag installations by approximately one quarter.Raw data (links for shapefile/geojson, CSV, geo-web-services)Viewer:If you zoom in, individual turbines have a tooltip:License:Map services and data downloaded from the U.S. Wind Turbine Database are free and in the public domain. There are no restrictions; however, we request that the following acknowledgment statement be included in products and data derived from our map services when citing, copying, or reprintinghttps://opendata.swiss/en/dataset/windenergieanlagen2The “Wind energy plants” geodata document the current situation regarding wind energy facilities in Switzerland. All data are based on information provided by the power plant operators and are intended to function as information material for the general public.Data downloadWMS"
Is there a way to get all counties in an MSA?,"
Is there a way to get the list of all counties that are part of an MSA/CBSA?
According to this hierarchy, I don't see an obvious way: https://www.census.gov/newsroom/blogs/random-samplings/2014/07/understanding-geographic-relationships-counties-places-tracts-and-more.html
I tried this:
https://api.census.gov/data/2015/acs/acs5?get=NAME&for=county:*&in=metropolitan+statistical+area/micropolitan+statistical+area:27260

But got this error:
error: unknown/unsupported geography heirarchy

Is there any other way of getting this info?
Thanks in advance for your help.
",['us-census'],"Core Based Statistical Areas (CBSAs), Metropolitan Divisions, and Combined Statistical Areas (CSAs) 2018-09
FIPS Metropolitan Area (CBSA) Codes - 2000 Census Documentation
Bonus CMS's SSA to FIPS CBSA and MSA County Crosswalk"
Why does the Census API not return fields/vars when it says it should?,"
I am trying to retrieve the unemployment data for various US metros. The fields I am interested in are:
DP03_0009E
DP03_0009M
DP03_0009PE
DP03_0009PM

I know these fields exist as I am to query the metadata for the table and see these fields are present. For e.g.:
DP03_0009E :  {'label': 'EMPLOYMENT STATUS!!Civilian labor force!!Unemployment Rate', 'concept': 'SELECTED ECONOMIC CHARACTERISTICS', 'predicateType': 'int'}
DP03_0009M :  {'label': 'EMPLOYMENT STATUS!!Civilian labor force!!Unemployment Rate', 'concept': 'SELECTED ECONOMIC CHARACTERISTICS', 'predicateType': 'int'}
DP03_0009PE :  {'label': 'EMPLOYMENT STATUS!!Civilian labor force!!Unemployment Rate', 'concept': 'SELECTED ECONOMIC CHARACTERISTICS', 'predicateType': 'int'}
DP03_0009PM :  {'label': 'EMPLOYMENT STATUS!!Civilian labor force!!Unemployment Rate', 'concept': 'SELECTED ECONOMIC CHARACTERISTICS', 'predicateType': 'int'}

But When I try to retrieve these fields using the API for specific geographic region, for e.g. Dallas, I get a error: unknown variable 'DP03_0009P
Here is the call:
https://api.census.gov/data/2015/acs/acs1?get=NAME,DP03_0009E&for=metropolitan+statistical+area/micropolitan+statistical+area:19100

What am I missing? Any help would be much appreciated.
","['api', 'us-census', 'census']","Your current call: https://api.census.gov/data/2015/acs/acs1? will be requesting detailed table data.To request from a data profile, which includes DP03, please use this prefix instead: https://api.census.gov/data/2015/acs/acs1/profile?For instance, in your example, this url seems to be pulling the information you are looking for: https://api.census.gov/data/2015/acs/acs1/profile?get=NAME,DP03_0009E,DP03_0009M,DP03_0009PE,DP03_0009PM&for=metropolitan+statistical+area/micropolitan+statistical+area:19100Side note: Apparently, you can also get all of the variables contained within DP03 if you use this one as well: https://api.census.gov/data/2015/acs/acs1/profile?get=NAME,group(DP03)&for=metropolitan+statistical+area/micropolitan+statistical+area:19100"
Difference between Recall Enforcement Report and Recall Report?,"
I notice there are two types of recall datasets: Recall Enforcement Report and Recall Report. And I downloaded both of them. There are overlaps of recall events and related information, but they are definitely not the same. Could someone advise what's the difference between these two datasets? Which one if more accurate and up to date?
",['openfda'],
"Is there any chance that I can find shapefiles of buildings in Qingdao, China?","
We are starting a new research project in China and I've been looking for shapefiles of buildings in Qingdao, China. The closest thing I can find is buildings of Beijing. But I need Qingdao, not Beijing. 
It seems like I will have to use satellite images to generate the buildings through machine learning pattern recognition. Which I would rather not do because I don't know how to do that.
Anyone got any tips?
","['geospatial', 'transportation', 'china', 'buildings']",
Area size for GADM subdivision 2 areas,"
On https://biogeo.ucdavis.edu/data/gadm3.6/gadm36_shp.zip you can download administrative areas for the whole world. Each country has several administrative subdivisions (gadm36_0 - gadm36_5), where gadm36_0 is country level and gadm36_1 is state level. I am working with gadm36_2 data (which corresponds to counties in the U.S. e.g.). I was wondering whether there were area (administrative unit) sizes (in square kilometers) for the whole dataset available? One could calculate them using GIS-programmes. Though, doing so is tedious as you basically have to change your projection (CRS) for every local calculation.
Any ideas? 
","['data-request', 'geospatial']",
Any dataset of tower crane sensor data,"
Are there any datasets available for tower crane sensor data? I need this data for my project. I searched around on the web but could not find any dataset specifically for that.
","['data-request', 'sensors']",
Google Directions train timetable coverage by country,"
I'm trying to figure out which countries in Europe that Google Directions has full coverage for with regards to train timetables.  
I found this section: https://maps.google.com/landing/transit/cities/index.html but it isn't easy to understand (Multi-Region seems to mean both ""many regions/cities in a country"" and ""the entire country"") and in some cases the expected output given the list doesn't match the actual output of Google Directions.
Is there any other, better mapping of train timetable coverage by country in Google Directions out there? Or any resource that can help me determine if Google Directions has full coverage of a country's train timetable(s)?
","['metadata', 'public-transport']",
"Is there any API, tool, websites that i can find how many German people moved to United States in recent 10 years?","
I need to do geographical population analysis on how many German people recently moved to US and started to living there, especially to the California. I know US government has open data policy but so far could not find any relevant api, tool, websites related with my problem.
I already checked this website https://www.census.gov/topics/population.html, and this page https://www.dhs.gov/immigration-statistics/nonimmigrant
","['data-request', 'usa', 'uses-of-open-data', 'python', 'germany']",
medical notes dataset [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 4 years ago.







                        Improve this question
                    



I am working on a project title chronic disease prediction using Artificial Intelligence. I am looking for medical notes data. if anyone have access please provide it. I have seen some links on keggle but they are not providing access. I need data as some patients go to hospital/doctor and said I am having following symptoms/allergy/I have been to these operation/I am alcohol consumer like and the result should be found he/she is suffering from x of disease. If anyone has any data like this please share.
",['medical'],
GUDID / Device Registration Common Data Element,"
Is there a field or data element common to both the UID and the device registration databases in FDA?  I'm trying to tie the two together but can't seem to find a common field.
","['openfda', 'database']",
Gridded population data by income level,"
I am looking for a geospatial dataset with population density by income level, ideally spatially disaggregated. so each pixel has the population count or desnity of [0-1$/day],[1-2$/day], [2-4$/day] ... [Jeff Bezos $/day]
I found the following data at a country level:

any leads?
UPDATE: I found the following resources:
link1
link2
","['geospatial', 'income']",
Where can I get historical data on monsoon or sea wind?,"
I am trying to find some GIS historical data on monsoon.
I have tried a few places which give data on the weather forecast, temperature, and rainfall. But, I was thinking if there is a better data source that could potentially measure the path of monsoon. 
I think the historical data on sea wind (speed and directions) might be helpful as well. 
Also, I would appreciate you could suggest me better proxies (and source) that I could use to study the monsoon.
",['geospatial'],
Where to find number of objects in space per altitude?,"
What I want is the sources to plot a graph such as the figure 3-3 on this page but:

Containing all objects whose size is greater than 10cm (including operational satellites)
Raw numbers (the best would be a list containing for each observed object apogee and perigee of the described orbit)

Where can I find such a list?
",['space'],
Where can I get a food ingredient database or API,"
I'm currently working on a project that requires the use of an ingredients database or API. In my app I have some strings and I want to know if that string is belongs to an ingredient name. I'm just wondering if there are any free database and APIs that can help me achieve what I want to do?
","['api', 'database', 'food']",
Seeking IBA shapefile for Denmark?,"
I am looking for the shapes of important bird areas in Denmark, but cannot find it online. Have made a request to Bird Life, but have not heard from them yet.
So, anyone got a copy that they can share with me?
",['geospatial'],"Important Bird Areas are part of The World Database of Key Biodiversity Areas. The terms and conditions of use clearly state that redistribution is not allowed. See the relevant section quoted below:4. No reposting and/or redistributionExcept as provided in this section 4, all forms of reposting, and any sub-licensing, reselling, or other forms of redistribution or communication to the public of the KBA Data in their original format, either whole or in part, alone or combined with other data, are strictly prohibited without the prior written permission of the KBA Secretariat. You may not repost, or redistribute to any third party, the KBA Data in whole, or in part, by any means, including (but not limited to) electronic formats such as internet postings, web downloads, through web services, through interactive web maps that grant users download access, KML files or through file transfer protocols, electronic mailing, faxing, archiving in a public data, redistributing via a computer network, digital storage, memory stick or other electronic media or device, except as may otherwise be expressly permitted by the KBA Secretariat in writing.If you wish to provide a service through which KBA Data are otherwise made available for reposting or otherwise made available for redistribution, you must obtain written permission by contacting the KBA Secretariat directly using the contact details below in section 16. You agree to direct all requests from third parties for access to the data you obtained from The KBA Website to the KBA Secretariat at the address stated in section 16.Notwithstanding this clause, and subject to the requirements of third-party content providers, donors and licensors, KBA Partners agree to grant BirdLife permission to license KBA Data for commercial use on their behalf via the Integrated Biodiversity Assessment Tool (IBAT), with the understanding that income thus generated will be allocated transparently in accordance with Art VI.H.m."
Looking for dummy data aka passport images or other IDs,"
We're training a machine learning tool to recognize passport and drivers license information as part of screening them for public benefits, we're trying to find samples of false/dummy passport and other IDs to train the mode on. Do these exist anywhere as open government/corporate data?
","['images', 'passports']",
Seeking Policy Restrictions Data in London and South East?,"
I am researching various GIS data sources for London (UK). I was wondering whether anybody can give me pointers of where to get aggregated planning and policy restrictions data i.e. data that shows what you are allowed (or not allowed) to do in certain areas. E.g Flood plain, green space etc.
I can see that that there are separate data sources for Greenbelt (English Local Authority), AONB (ESRI Open Data), Common Land (DEFAR), Flood Plain (EA), also each Local Authority (LA) will have it's own data. However, what I ideally need is an aggregated resource.
","['data-request', 'geospatial', 'uk']",
Historical National Drug Code Package Data Availability,"
I am wondering how I may be able to access historical NDC Directory File data?
An example of the type of data I’m looking for would be for NDC Package Code 0002-3004-75, or Prozac Weekly.  In the current directory files (as of 2019-06-17), the Product NDC is available as 0002-3004 within the product file, but there is no associated package file data.  After looking around, I found this resource at hipaaspace.com, which lists all of the information related to this code and notes that this NDC package code is deprecated, which I suspect is why it's not in the current directory files.
I’m interested in the historical data because I’m trying to map NDC package descriptions to the NDC package codes for a trend analysis my team is performing.  I took a look at the openFDA API, but it didn’t appear the package code information was available there, either.
The example query I used via the openFDA site is:
https://api.fda.gov/drug/ndc.json?search=product_ndc:""0002-3004""&limit=10
but this also shows ""packaging"": [].
Again, this is only provided as an example.  I'm interested in obtaining the NDC Package Code for all codes in the package file that are also contained in the product file, whether the package code is deprecated or not.
","['openfda', 'drugs']","We don't keep the products that are discontinued in the searchable database.  If you file an FOI request we can provide a dump of discontinued products from 2009 to present (this is the beginning of the electronic submissions).where FOI = Freedom of Informationand the associated request link.For $90 hipaaspace.com has an NDC Database dating back to 2012, with much of the same data elements."
Looking for soccer match raw data,"
I'm looking for soccer match data. Not summary data; I need in-game raw data that contains

who passed a ball to whom
all players' positions for every second

It does not matter which game it is. I need it for study and am ready to pay for it if needed.
","['data-request', 'sports']",
Ice Age Glaciers Question,"
I am looking to find GIS data about the Ice age glacier's history around the Russia and Alaska area aka the Beringia Sea ...
Not sure how to find them but does anyone here have the information on that can I obtain the data?
","['data-request', 'geospatial', 'historical']",
Global water mask binary raster,"
I am looking for binary raster data, which indicates whether a granular pixel on a world map is covered by water or not. This should be data with relatively high resolution, where e.g. a river or a lake is assigned a zero (water) and some parcel of land is assigned a 1 (land) (or the other way round). 
However, I do not need this for the oceans in order to limit the size of the dataset.
I found e.g. this paper: https://tandfonline.com/doi/full/10.1080/17538947.2015.1026420 but cannot find the dataset itself. 
I also found this data: http://glcf.umd.edu/data/watermask/ but the links provided on the website do not seem to work and I cannot find it anywhere else.
The two datasets use resolutions at 30 meters and 250 meters. The good thing about such a small-scale resolution is that it also covers rivers and that is what I am searching for.
EDIT:
I also found the following dataset: https://daac.ornl.gov/ISLSCP_II/guides/combined_ancillary_xdeg.html
However, the resolution of that dataset is about 1km and therefore a little bit too coarse. It does not really cover rivers but only major lakes. 
",['data-request'],"If anyone is interested in similar datasets: I found a nice compilation of different datasets, which can be used for population studies (among others). The data is compiled at resolutions 100m and 1km and includes information about the water surface (also as dummy variable): 
https://www.nature.com/articles/sdata20171#t3If you scroll down to the end of the article, you will find links to the Havard dataverse including the respective files (Table 3 provides further information). "
"If there is a list of ""cultures"" to download somewhere","
I am wondering if there is a list similar to the ISO country codes but for cultures. Specifically like this:
chinese
japanese
american
russian
etc.

Whereas the country codes list it like this:
China
Japan
...etc.

",['database'],
How to find the wikidata ID of a DBpedia concept?,"
I have a set of DBpedia concepts and would like to get the corresponding wikidata IDs of them. 
For example, consider word2vec. The wikidata ID of word2vec is wd:Q22673982.
Currently, I have the following two questions.

Are all DBpedia concepts associated with its relevent wikidata ID?
How to get the wikidata ID associated with DBpedia using sparql?

I am happy to provide more details if needed.
","['uses-of-open-data', 'research', 'wikidata', 'rdf', 'dbpedia']",
Non commercial use of nfl team logos from Wikipedia,"
I am about to publish some use cases for an open source visualization I did for hierarchical data.
One use case is sports data, e.g. visualizing the super bowl play by play. I would like to use the team logo images from Wikipedia for that with proper attribution.
Can I do that or is there a different way to do it ?
","['images', 'licensing', 'wikipedia']","Ask your lawyer. (Or don't, depending on how serious your project is. No one is going to sue you about a hobby web page showing some logos.) Most logos are copyrighted and the owner has not given permission for such use, but depending on what jurisdiction you operate in, there might be exceptions such as fair use that allow you to use them without permission. There is also trademark law to consider, but that typically does not prevent use of the logos as long as they are not misleading (e.g. implying some sort of relationship between you and the team) or commercial."
Open source weather database for predict crop disease?,"
I have started to work on forecasting models for precision agriculture. My goal is to train a model which uses temperature, relative humidity, and rainfall to predict when late blight (Phytophthora infestans) epidemics are not likely to occur. Similar to the Fry Model or Negative Prognosis Model for potato production
I am looking for a dataset of weather data linked to crop diseases. 
","['data-request', 'machine-learning', 'python', 'agriculture']",
"Canada, USA - fuel stations, grocery stores","
I am looking for free data where fuel stations and grocery stores are located in Canada and the USA, that can be exported/downloaded in any format (csv, shp, json, txt, kml, ...).
Do you know of any databases, services, open data? I already had a look at Open Data Canada, which does not provide anything regarding these layers.
","['geospatial', 'usa', 'canada', 'north-america']",
SPARQL - Filter wikidata identifiers,"
Query below gives me all programming languages entities, with their statements.
Problem is that I don't need identifiers now, but these IDs might become necessary. I was just gonna model database return with toJSON, but this became hard since I can't easily filter them at my queries
I think all of them are instances of Q18614948 - Wikidata property for authority control 
I don't want to remove them, I need a way to identify them, like add a flag or a different label if wd has this class
SPARQL query:
SELECT ?tipoLinguagem ?tipoLinguagemLabel
       ?subtipoLinguagem ?subtipoLinguagemLabel
       ?linguagem ?linguagemLabel
       ?wd ?wdLabel ?ps ?ps_Label ?wdpq ?wdpqLabel ?pq_ ?pq_Label
WHERE {

  ?tipoLinguagem wdt:P279 wd:Q629206 .
  ?subtipoLinguagem wdt:P279 ?tipoLinguagem .
  ?linguagem wdt:P31 ?subtipoLinguagem .

  ?linguagem ?p ?statement .
  ?statement ?ps ?ps_ .

  ?wd wikibase:claim ?p.
  ?wd wikibase:statementProperty ?ps.

  # NOT WORKINNG
  BIND(
    IF(?wd wdt:P31 wd:Q18614948)
    AS ?isIdentifier
  )

  OPTIONAL {
  ?statement ?pq ?pq_ .
  ?wdpq wikibase:qualifier ?pq .
  }
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"" . } 

} ORDER BY ?linguagemLabel


Example of identifiers from js entity page:

","['wikidata', 'linked-data', 'sparql', 'semantic-web']",
"where can I find a data set on US's political ideology, i.e. democrats, republicans, socialist, anarchist..etc?","
where can I find a data set on the US's political ideology, i.e. democrats, republicans, socialist, anarchist..etc? I need to calculate the percentage of democrats, republicans, libertarian, socialist, anarchist..etc, from the overall US population
","['usa', 'population', 'politics']",
Availability of PGx Biomarker data for drug labels?,"
Is the Pharmacogenomic Biomarkers in Drug Labeling available through the OpenFDA system?
If not, are there any plans to make this data available? Seems like this would be an easy thing to model and make available.
","['openfda', 'releasing-data', 'drugs']",At this point openFDA has no plans on making Pharmacogenomic Biomarkers available in Drug Labeling. 
Wikidata SPARQL - get company entities and the location of their headquarters,"
I'm having trouble extracting location attributes of company HQ's. 
My query: finds all companies or sub-classes, and returns some basic properties such as ISIN and URL, and the Headquarter location. 
I have tried to use this example to extend the Headquarter part of the query to return location information such as city, country, and coordinate latitude and longitude. However I am getting stuck on pulling the values or labels through.
Thank you
SELECT
  ?item ?itemLabel ?web ?isin ?hq ?hqloc ?inception

# valueLabel is only useful for properties with item-datatype
WHERE 
{
  ?item p:P31/ps:P31/wdt:P279* wd:Q783794.

  OPTIONAL{?item wdt:P856 ?web.} # get item
  OPTIONAL{?item wdt:P946 ?isin.} # get item
  OPTIONAL{?item wdt:P571 ?inception.} # get item
  OPTIONAL{?item wdt:P159 ?hq.}  

  OPTIONAL{?item p:P159 ?hqItem. # get property
           ?hqItem ps:P159 wd:Q515. # get property-statement wikidata-entity
           ?hqItem pq:P17 ?hqloc. # get country of city
           }

  ?article schema:about ?item .
  ?article schema:inLanguage ""en"" .
  ?article schema:isPartOf <https://en.wikipedia.org/>. 
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". }    
}
LIMIT 10

","['wikidata', 'sparql', 'rdf']",
Atopiclair does not appear on any FDA list I can find,"
Atopiclair is on drugs.com:
https://www.drugs.com/cdi/atopiclair.html
Here's where it's not (on fda.gov):

The FDA CDER DB:
https://www.accessdata.fda.gov/scripts/cder/daf/index.cfm
The Medical Device DB:
https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfRL/rl.cfm
The National Drug Code Directory:
https://www.fda.gov/Drugs/InformationOnDrugs/ucm142438.htm

Is the drug listed anywhere on fda.gov?
","['usa', 'openfda', 'drugs']","This document from fda.gov (saved via the Wayback Machine) states: This clinical study was compiled using Sinclair Wound and Skin Emulsion product as submitted in 510(k) # K024367. Atopiclair"" is the working name for Sinclair Wound and Skin Emulsion in this study. Searching fda.gov for the working name provides some results I could be wrong about using the working name, if so, please let me know."
ope8_id verse id in API request,"
I have a standing API query that has been using ope8_id for data requests, but recently it has stopped returning data; I was wondering if ope8_ids can no longer be used in requests or if the call has changed?
For example:
Using regular ID for Boston College
api.data.gov/ed/collegescorecard/v1/schools?id=164924&api_key=XXXXX 

returns data
My standing query using ope8_id for Boston College:
api.data.gov/ed/collegescorecard/v1/schools?ope8_id=212800&api_key=XXXX 

returns no data.
I was wondering if anyone had similar issues?
","['api', 'collegescorecard']",
REST API for getting informations about celebrities,"
Is there any REST API that provides informations about ""famous"" people (Scientists, Writers, Philosophers, Politicians, ...) ?
In my case I need the following infos: 

Photo,
Full Name
Born & Died dates,
Nationality
Profession(s)
Brief

",['api'],
2016 and 2020 USA Polling Metadata,"
In 2016, polling was fatally flawed especially in the US general presidential election. One mistake was in sample selection. 
At least one 2020 DNC primary election poll has had statistically insignificant samples to represent those under 50, which makes me wonder how much has really changed since 2016.
I would be interested to find metadata on primary and general election polls in 2016 and primary election polls in 2020. Specifically metadata on sampling selections and other polling features that may indicate if and how polling methods have changed or remain flawed. 
Data for the expected 2016 and 2020 voter demographic turnout would also be useful to see how representative the polling sample selections are.
","['data-request', 'usa', 'politics', 'polling']",
"Looking for football (soccer) player data with salaries, heights, weights info","
I'm looking for dataset for all top world players or european players or though players of UEFA Champions League. So I'm intresting in multinational data (no for just one national ligue). I need table that in all cases contain: salaries, heights, weights.
","['data-request', 'sports', 'football']",
Seeking Traffic Analysis Zones (for city of Shenzhen) in computer readable format?,"
I'm looking for (something like) shapefiles of Traffic Analisys Zones in the city of Shenzhen. If there are several I would like to get most recent, but any would serve the purpose.
","['geospatial', 'traffic']",
Which pub sells which beer in the UK?,"
Does anyone know of a reliable source of up to date data? 
Especially for craft beers & real ale, rather than Fosters/Carlsberg, etc, although data on those is welcome too (and whisky, now that I come to think of it).
",['uk'],
"Database of pictures deleted from Wikipedia/Commons, and the reason for their deletion","
Hundreds of pictures are uploaded to Commons everyday, and among them many get deleted for various reasons (copyright infringement, obscenity, selfies, etc).
For machine learning purposes, I need a representative sample of thousands of these deleted pictures.
For each picture:

The picture itself, or at least a thumbnail of it.
The deletion reason

Is there such a publicly accessible database somewhere? If possible reasonably recent.
","['data-request', 'wikimedia-commons']",
List of all http sites in the world,"
I've tried inurl:http but it takes forever to get even a bunch of sites right and I have to think of new keywords everytime to get the sites.
Is there kind of a directory I could use to get the address of all the sites on the public web?
","['data-request', 'internet']",
Exporting data from https://taggs.hhs.gov?,"
https://taggs.hhs.gov offers a great comprehensive database of all grants awarded by the HHS (Department of Health & Human Services, US).
Their ""Award Search"" engine is effective and convenient. However, I cannot seem to xls or csv (or anything else really) from the Award Search.
Say, for example, that I am looking at the keywork ""Hepatits"": http://tinyurl.com/yylzooc5, which returns 4788 items.
The ""Quick Help"" says  

""You may export data by choosing one of the four Export Group options: Microsoft Excel, Adobe Portable Document Format (PDF), Microsoft Word Rich Test Format (RTF), or Comma Separated Value (CSV) format. You will find four export options in the upper right corner of the data window. Exports are limited to 10,000 rows. The last export option allows the ability to generate a sharable URL that can be emailed or messaged for sharing the data results.""

Since my search contains only 4788 items, I guess I should be fine.
I can see the export buttons in the top-right corner,  which looks like this:

When I click on one of the buttons, for example the xls one, a little bar appears right beside it, but nothing else happens, even if I wait for a while.

I've tried with three different browsers, to no avail. The only button that does work for me is the last one that creates the shorturl link to my search (which I used above). None of the other ""export"" buttons works.
I have also tried smaller searches (e.g., http://tinyurl.com/y6e8xbs6) thinking that maybe each item would take up more than one row (??), but I get exactly the same behavior I described above (small line appears beside export button, but nothing else happens, even if I wait for a while).
My questions are:

Am I the only one who's unable to export data from https://taggs.hhs.gov, or do other people face the same issue (maybe export is geo-restricted??)?
If someone manages to export data from there, can they explain what I am doing wrong?
If no one manages to extract data using the built-in export tools, can someone suggest a hack?

","['usa', 'medical', 'download']",
"How was the variable ""T4APPROVALDATE"" generated in College Scorecard Data?","
My question is about the variable ""T4APPROVALDATE"" in the most recent cohort data. It indicates the date that the institution was first approved to participate in Title IV aid programs. According to the dictionary, it was derived from FSA. How was it generated? Why there are about 455 institutions participate in Title-IV (OPEFLAG=1) but have ""NULL"" ""T4APPROVALDATE""?
",['collegescorecard'],
UN Global Comtrade Database,"
UN Comtrade database, the major source of bilateral trade data online, has a free query tool: 
http://comtrade.un.org/data/
However, the API limits the number of requests per hour and the size of each request. 
I was wondering if anyone has the full database saved somewhere to download as a mirror (or someone has a token available to access bulk downloading)? Writing a timed script is rather burdensome, so I would prefer not to do that.
","['data-request', 'economics', 'trade', 'un']",
Where to get lists of kaomoji (Japanese emoticons)?,"
Where can I find a downloadable database of Japanese-style emoticons (顔文字, kaomoji, ""face characters"")? The database should ideally be free.
Examples of kaomoji are: {^.^}, (°Д°), (◕‿◕).
","['data-request', 'text', 'japan', 'japanese']",
Unexpected results from query,"
If I check the FDA's Drug Shortage page the first item on the list is a product with a generic name of: Abciximab (ReoPro) Injection.  If I click on the link provided there is a column called presentation that shows an NDC number of 57894-200-01.  If I query the FDA's api with the following query I get no matches found.
https://api.fda.gov/drug/label.json?search=package_ndc:""57894-200-01""&limit=1

If I download the FDA's NDC directory from https://open.fda.gov/apis/drug/ndc/download/ and search the text for 57894-200-01 I do get a result and 57894-200-01 is a valid package ndc number.  Why am I getting ""no matches found"" on my query?
","['api', 'openfda']","the reason why the first uri doesn't find the product is that the product_ndc is 57894-200, not 57894-200-01.So, https://api.fda.gov/drug/ndc.json?search=product_ndc:%2257894-200%22 returns product data.It seems unclear to me how to structure the second query.Best regards."
Seeking free basemaps for offline use in GIS?,"
Situation: I will be traveling in the next months and therefore, I have created a bunch of geolocated POIs and other layers, such as campgrounds, attractions, hiking trails and so on. I want to use these layers as my own information source either within a GIS (ArcGIS, QGIS) or building a web app with Leaflet. I can use the layers as .shp, .kml, .csv, .json, or any other vector format.
Problem: I need to use the data offline, as I often won't have Internet access. The main problem is, that I need any kind of offline base map, when visualizing my data. For OSM data, only vector data of layers are provided that can be downloaded.
Do you know of any other sources?
","['geospatial', 'openstreetmap']",
Where can I find data about alternative medicine use?,"
I am looking for data about alternative and complementary medicine (CAM) use. I need something as detailed as possible. In this moment, I am looking for whatever country has complete and detailed time series.
I am aware of data about US (link) but I was looking for some other country.
","['data-request', 'medical']",
Database of Android APK checksums,"
Android APKs are often restricted by regions, for instance an APK is available in Korea but not in Nigeria, for obscure marketing and narrow-mindedness reasons. That leads many Android users to download APKs from a wide range of dodgy APK download sites.

Problem: Intducing spyware/malware in an APK is easy, and many of these download sites do it.  
Solution: Verify the checksum of the downloaded APK. Unlike APK themselves, checksums are legal to publish.

Request: I am looking for a database of checksums of APK files.
Requirements:

Checksums of most popular apps present on Google's Play Store
For as many versions as possible of each app, at least the most recent version (some lag is acceptable)
Using any popular secure checksum algorithm such as SHA1
Searchable by application name or namespace

","['data-request', 'software']",
Fortune 500 companies websites sitemap,"
What is a good source, or approach, to collate a list of Fortune 500 companies websites sitemap URL (either to sitemap.xml or their sitemap webpage)?
","['research', 'business', 'companies']",
"Seeking 2016 Census tract based Census Data for City of Toronto, Canada","
I have gone through all the links that have been posted over the stack exchange forum and other forums. I did go through Statistics Canada and found what I needed. But this data is in the row form and not the usual column forms. Example:

Can anyone guide me to how this can be transformed or some source where this is already transformed? 
I have already tried to get access to CHASS data center and do not have anyone I know who can help me with access to it. 
Source : https://www12.statcan.gc.ca/census-recensement/index-eng.cfm?HPA=1
","['data-request', 'census', 'data-format', 'canada']",
Vessel/ais traffic data of the most congested areas of the world,"
For my research project, I need vessel traffic data of the most congested regions of the world for the past five years.
I searched for that data here but couldn't get what I wanted. So far I've found historical data for the US coast, the Australian seas and from the Indian government.
I've also looked at the vessel traffic services (marinetraffic, vt explorer, fleetmon....) but obviously they are commercial services, and even if they provide a free service, it is very limited where you can barely get the data of one vessel for a very limited time-span.
I also wonder if any of you did contact those commercial vessel traffic services, and request their historical data (for free) for a research project with no commercial intention. If so, how was their response?
","['data-request', 'api', 'transportation', 'traffic', 'ais']",
NCAA Football Coach Salary Data,"
Is there anywhere I can find historical data‚ say over the last 30 years, on NCAA football coach salaries? Charles Clotfelter seems to have this, at least for some schools: https://twitter.com/rjisungpark/status/1133536944003137536
See also https://sports.usatoday.com/ncaa/salaries/ for 2018 only.
","['sports', 'football']",
APIs / Services that can link product names to their UPC/SKU codes,"
I have an ever growing database of products that users on my site are entering themselves. The input form for users to submit their products (as part of a troubleshooter forum) is very quick to encourage forum posts so when products are defined just a type, brand and model name are requested.
The result is that I have a large database of products which are not connected to official manufacturers UPC / SKU codes. I want to improve my site by using APIs that retrieve images for products, obtain pricing etc but these all request such codes.
So before I can go ahead with that plan I clearly need to find a way to try and improve the quality of my data. Does anyone know of a way to update this old data through some kind of service that can product match based on strings names?
","['api', 'products']",
I am looking for i-Lids dataset for AVSS 2007,"
I am looking for the i-Lids dataset for AVSS 2007 but I am unable to find it online. The link for the data on the official website is broken. More specifically, I am interested in the abandoned baggage (AB) data, which have been used extensively in the literature.
I have only found a youtube video for the ""easy"" scenario (AVSS AB Easy).
Does anybody know where I can find the i-Lids AVSS AB data or have a copy that they could share?
","['data-request', 'machine-learning', 'database', 'video']",
Free source of AIS data (API),"
The automatic identification system (AIS) is an automatic tracking system that uses transponders on ships to locate them. There are also databases that provide information about the ship — size, type, owner, registration, etc.
I need real-time data, preferably for the River Thames or the English Channel. Failing that, Singapore, Hong Kong or any major European (preferably German) river or port. Does anyone know of a free API to access any of this data?
","['data-request', 'geospatial', 'api', 'transportation', 'ais']",Live AIS data for most of the globe is available from https://aisstream.io for free.The catch is the data is delivered via WebSocket and not a raw tcp connection. There are a few examples in their github of using the api with various languages such as javascript and python.
Global Historic GIS Data,"
This is a basic question concerning data availability. I am looking for global historic geo-spatial data covering the past 2,000 or 3,000 years. Variables of interest are biomes, temperature, precipitation, soil characteristics, mineral deposits, rivers etc. The data should come as multiple cross-sections rather than 3,000 year averages. Frequencies of not more than a few hundred years would be great.
As you are all well aware, geography is not constant over time. Human activity and a changing climate alter biomes, rivers dry up and are re-directed, mineral deposits are used an eventually exhausted, temperature and precipitation follow global and regional trends.
Paleoclimatology is an interesting field modeling long-term changes. Geo-spatial data on temperature and precipitation of the past few million years is freely available online. That is great, but this data is with its estimates usually averaged over a few thousand years not what I am looking for. I need a shorter time horizon with a higher frequency, as outlined in the first paragraph. Something like HYDE data for other variables.
There are estimates for small regions or individual countries for different points in history. That does not help as I need a global scale. Merging these smaller puzzle pieces together to create a global picture is often difficult as definitions, assumptions and map quality vary widely.
Projects like DARMC, AfricaMap, HYDE, PaleoClim and WorldClim have done a great job in putting together geo-spatial data in easily accessible formats at the larger geographic scale for different points in human history. However, there is still a lot missing.
I'm looking for any data sources that meet the following requirements:

Format: Any geo-coded/geospatial format. It can be points, lines, polygons or raster grids.
Spatial Extent: cover approximately the entire planet (or at least major regions) 
Time Frame: covering the past 2,000 or 3,000 years in multiple cross-sections rather than 3,000 year averages. Frequencies of not more than a few hundred years would be great.
Topic: related to any of these or similar paleoclimate variables:


Biomes
Temperature
Precipitation
Soil characteristics
Mineral deposits
Rivers


I am looking forward to your suggestions. Any comments are welcome.
","['geospatial', 'historical', 'geocoding', 'climate']",
Looking for taxonomy for skills databases?,"
I am looking for taxonomy databases or datasets other than ""O*Net"" which can have skills (Tools and technologies). Added to the above, I am also looking for taxonomy which can have skills from pharma and medical fields. 
I also need to identify skills in job description which describe the abilities, (For example , ""good communication skills"", ""speak English and Spanish"", ""effectively communicate with customers""), is there any taxonomy by chance?
","['data-request', 'uses-of-open-data', 'metadata']",
Seeking shapefile of Boston in 1630?,"
I found this map on Reddit and was curious if anyone knows how it was made.
See Modern map of Boston compared to original 1630 shoreline.
I think I could make it if I had a shapefile of the 1630 map.
Does anyone know how I could get that?

","['geospatial', 'usa']","Cool question and nice map...I did a reverse image search and found a blog post from 2011, the same year as the map's creation, which has lots of technical details:https://www.digitalcommonwealth.org/search/commonwealth:7h149v32xAlso has a 74 MB GeoTIFF download in the right menu barGeoTIFF seems to be a useable format for converting to shapefiles or other GIS formats:direct GeoTIFF downloadGDAL GeoTIFF docsBlogpost about displaying GeoTIFF in QGIS"
Geographical center of countries,"
Can anyone help me find a list of the geographical centers of all the countries of the world? Preferably without calculating them from other data.
",['geospatial'],
Seeking historical tileset 1939-1945?,"
I want a Mapbox tileset that shows the world as it was during the Second World War.  This includes the boundaries of countries, roads and cities and their names, etc.
If no such resource exists, I will need to find the data to make one myself, but I don't know where I should look for this information.  Hopefully I don't have to draw a map of Europe by hand in Mapbox Studio! Any suggestions would be greatly appreciated!
","['data-request', 'geospatial', 'historical']","Here are a few sources I found by searching for ""historical geospatial data."" This is not an exhaustive list. I encourage you to do the same search, and if you find other sources please post them as an answer.For Historical Country Boundaries, check out this post on GIS Lounge. Most of the date ranges are outside your target timeframe, but there are a couple that might have data for Europe 1939-45:World Historical GIS Data: 2000 BCE to 1994 CEWhile the site is now defunct, Oracles, Thinkquest.org site consolidated a series of country boundary data into shapefiles.  Created as an educational site in 1996 and acquired by Oracle in 2002, the site went defunct in 2013.  Thanks to the Wayback Machine, the shapefiles of country boundaries spanning between 2000 BCE and 1994 CE can still be downloaded.  The data itself should be used with caution and only for small scale projects.  Created by students, the archived disclaimer page explains that the data has a spatial error of roughly +/- 40 miles and the best available information, especially for the oldest years, is not the most reliable.Download: Historical country GIS data from ThinkquestBritain Historical GISThe site A Vision of Britain through Time from the the University of Portsmouth has made historical boundary information for counties, parishes, and constituencies for England, Wales, and Scotland available for download in shapefiles format.  The data downloads cover a variety of timeframes in the 1800s and 1900s.  The county information is available for free download but the constituencies and parishes are offered under restricted downloads.Download: A Vision of Britain through TimeRT Wilson's excellent free GIS data archive has links to these datasets that mention historical data. Not all of them specify a date range, so you'll have to visit the individual sites to see if they have WWII-era data.Historical infrastructure (roads, railroads, etc) seems like a much bigger ask. I suspect that the best you can find will be images of maps. OldMapsOnline.org is a great source of georeferenced scanned historical maps. If they don't have what you want already georeferenced, it may be waiting in line for someone else to georeference it. So while you're there visit the ""get involved"" link and help out by georeferencing a few old maps. When I recently helped georeference several maps, one of them was a German WWII-era map of a city in Great Britain, which included critical infrastructure like major roads, railroads and bridges."
Is there any publicly available Radiology dataset for NLP (Natural Language Processing) purposes?,"
I'm looking for publicly available Radiology reports data collection which I can use to proceed with my research. Do you happen to know some?
","['data-request', 'medical', 'nlp']",
SPARQL query to get capacity of event venues from Wikidata,"
I am trying to query Wikidata to find out the capacities of all event venues in specific geographic regions (US urban centers). They have this service for querying: Wikidata Query Service
The answer in the related question below gave this query as an example for getting the capacities of arenas:
SELECT ?arena ?arenaLabel ?maximum_capacity WHERE {

  SERVICE wikibase:label { bd:serviceParam wikibase:language "" 
   [AUTO_LANGUAGE],en"". }

  ?arena wdt:P31 wd:Q641226.
  OPTIONAL { ?arena wdt:P1083 ?maximum_capacity. }
}

I tried to modify it a bit to get the capacities of event venues, not just arenas, but I don't get any results:
SELECT ?venue ?maximum_capacity WHERE {

  SERVICE wikibase:label { bd:serviceParam wikibase:language "" 
   [AUTO_LANGUAGE],en"". }

  ?venue wdt:P31 wd:Q7463935.

  OPTIONAL { ?venue wdt:P1083 ?maximum_capacity. }
}

I think the issue partly is that wd:Q7463935 says 'Category' so maybe 'wdt:P31' = 'is instance of' is not the correct way to phrase this. 
Any ideas are much appreciated. 
Related Question: Capacity/attendance information for US event venues
","['wikidata', 'sparql']",
Where can I get data on the number of hours worked by Americans?,"
I don't necessarily need microdata on the number of hours worked, but I would like to see some data on the percentile scale. I can't seem to find anything except for averages, which are not what I'm looking for.
","['data-request', 'usa', 'population']","I assume you've already found averages at Current Employment Statistics, FactFinder, or the American Time-Use Survey. I don't see any percentiles there. I don't know of any ready-made tables from BLS or Census that include percentiles for hours worked, so unfortunately you will probably need to create your own tabulation using microdata from CPS PUMS or ACS PUMS. Be aware that this does require significant expertise in working with weighted survey data and knowing which records to filter out by labor force status etc."
Award Recipients' Birthdays,"
I started this with a class project but I want to add items to my movie award database. I got super excited when I saw this: Where to get IMDb datasets but there wasn't birthday information in any of the data sets. Can someone help me find where i can get these data from IMDB? 
I also saw this ftp.fu-berlin.de/pub/misc/movies/database/frozendata and I appreciate the bio data but can't weed through all of that for just Birthday and (maybe) location.
Thank you
","['data-request', 'film']",The R Code below worked. Might be a bit cumbersome but it did the trick:
Full address list for city Radebeul (Germany),"
For a city of Radebeul, located in the federal state Saxony in Germany, I am looking for a list with all addresses, something like
id | Street                | Nr  | PLZ   | City
1  | Meißner Straße        | 266 | 01445 | Radebeul
2  | Heinrich-Zille-Straße | 25  | 01445 | Radebeul
.  | ...                   | ... | 01445 | Radebeul

What are those options/sources of data?
I somehow think about deploying overpass-turbo or Nominatim as was suggested in this thread Return all elements associated with address - Overpass API. But perhaps there are other free/open solutions which will somehow differ from OSM data basic.
There was also an idea to extract all points (keeping in mind a certain category/amenity) and all buildings as polygons from OpenStreetMap (e.g. using QGIS, as described in this thread Searching and Downloading OpenStreetMap Data), making geocentoids out of buildings, then defining ($x, $y) for each building feature  and each point, and finally put all that coordinates into one common list and proceed via geocoding engine, like HERE Geocoding API or Python Geocoder by means of reverse geocoding.
I am aware of this question is partially related to the ""geocoding"" topic but I am wondering if I can somehow extract the full list of all addresses, something like a reference list from the geocoding library/solution. Unluckily some resources for Germany were demolished, found in this topic Mass Geocoding Requests for Germany?.
Unfortunately, the Radebeul city portal does not provide such data. Additionally, the data from Deutsche Post probably costs much money.
","['geospatial', 'germany', 'address']","Currently there are 8596 data records with addresses available for the city of Radebeul.The Adress data for For Saxony (Free State of Saxony) in Germany can be downloaded in zip-format from the following link:https://www.geodaten.sachsen.de/downloadbereich-hauskoordinaten-4172.htmlThe inside of the archive includes several files:A file with addresses ""adressen.txt"" looks as following:More about the structure of txt-file with house coordinates can be found in the PDF document attached below.Columns (#12 and #13) that represent coordinates are projected in EPSG:25833.References:"
Current movie data in area,"
I want data of all the current movies that are playing in or around a given zip code, with the locations and showing times. Is there any database with this level of detail?
How does a service like Fandango get this information? Do they have deals with all the local movie theaters who push the data to Fandango? Or do they pull the data from some other source?
",['film'],
reliable spanish word empeddings (word2vec output format),"
I'm looking for spanish word vectors (preferably word2vec output format) to use in a scala nlp application. I've tried the ones on https://github.com/uchile-nlp/spanish-word-embeddings, but they are either in the wrong language, missing headers (not the desired word2vec output format) or for some reason I'm not able to load the model correctly. I'm using word2vecscala (https://github.com/trananh/word2vec-scala) to load the vectors. Any recommendations would be much appreciated.
",['nlp'],
Seeking mosaicked global DEM?,"
I would like to know if there is already available mosaiced* DEM (digital elevation model) raster for the entire globe? 
On this site, they provide this data from the Shuttle Radar Topography Mission but it does not include the Arctic. 
*Mosaiced means multiple raster images are stitched together.
","['data-request', 'geospatial']",
List/database of organizations,"
Is there a list/database of corporations/organizations in the world or in the US? I saw opencorporates but it is paid and not free. Wondering if there is something freely available.
","['data-request', 'opencorporates']",
Data for credit debt of loans for neural networks train,"
Where I can find the data for training the neural network to classify people(will or not give back the loan) for automated web services of loans and(or) banks. Where the decision to give a loan is made based on not only demographic characteristics, salary and so on common parametes...
but by  the behavior of clients on the site, as well as the substitution of information, such as the IP address or proxy server.  I.E.data for determining that the man gives false information about himself using stolrn ip, cookies, IDs and phones and so on.
","['data-request', 'machine-learning']",
"Why is there an extra ""0"" at the beginning of every UPC code in openFDA?","
When I compare images of the package label UPC barcodes with these codes the zero isn't there. Having written an application that stores and uses pharmacy item UPC barcodes, I can assure you the scanned barcodes do not have this extra ""0"".
",['openfda'],
average ingredients for each drug in each year for a specific manufacturer,"
I want to count the average number of ingredients in each drug produced by a specific manufacturer in each year.
The results I want should be like this:
year | drug_names | avg_number_of_ingredients

2018 | drugA,drugB | 21

Can someone please help.
What I have done so far?
I have tried different queries here : https://open.fda.gov/apis/drug/label/example-api-queries/
but unfortunately, the maximum I can do is count some field following some conditions like the query below:

https://api.fda.gov/drug/label.json?search=effective_time:[20110601+TO+20121231]&count=openfda.brand_name.exact&limit=1

What I want is to group manufacturers and count their drugs per year.
Thanks.
","['openfda', 'programming', 'python']",
I am attempting to locate DrugID or DCode information,"
Does anyone know where to obtain DCodes or DrugIDs in the OPEN FDA product? I get practically everything I need except this.
",['openfda'],
Where can I find image dataset for crop yield prediction?,"
I want to reproduce the work from the research paper Crop Biometric Maps: The Key to Prediction by
Francisco Rovira-Más and Verónica Sáiz-Rubio, but I need the right dataset for that. Where can I find it?
","['data-request', 'images', 'agriculture']",
Where can I get a list of new businesses that are created in the US? [duplicate],"







This question already has an answer here:
                                
                            




Looking for database of US companies

                                (1 answer)
                            

Closed 4 years ago.



I'm interested in new businesses in my area. Is there a way to get a list of new (physical) businesses that are created in my area, either as they open shop or ideally, even before? Any gov API that can do this? This is in the U.S.
","['api', 'business']",
How to distinguish between human and animal bones in Wikidata?,"
The two topics

https://www.wikidata.org/wiki/Q16343  (Clavicle)
https://www.wikidata.org/wiki/Q835986 (Baculum, Penis bone)

are both instances of Q265868 (Bone). However, the clavicle is a human (and animal) bone, whereas the Baculum is afaik not a human bone.
How can I distinguish human bones from non-human bones? Is there a Wikidata property for this?
",['wikidata'],
Quote request dataset /sentence templates,"
I'm making a quote-bot which requires NER/extraction of suburbs/postcodes/states in Australia, which, perhaps unsurprisingly, seems harder to find than equiv for US etc. 
Example utterances would be:
""Hi i want to ship 3 boxes from [suburb1] [postcode1] to [suburb2] [postcode2] they're 1 by 1 by 1m and 2kgs""
or 
""How much to send from [suburb1] [state1] to [suburb2] [postcode2]""
I have a dataset of all the locations/postcodes etc so really all i need is a good sized set of diverse sentence templates for these sorts of requests. 
I have purposely avoided discussing my reasons for approaching it this way vs other ways (i.e. pattern/fuzzy matching) because it doesn't seem the right SE website for it, but suffice to say I have explored a variety of options.
The main hurdle in this approach is that the number of suburb/postcode pairs, 16k, is far larger than the number of example sentences i can think of. In a lot of cases i really do need to show the model the suburb at least once as some are very weird/unique. This means i am re-using sentences a lot and i fear this will lead to overfitting, hence the desire for a larger diverse set of template sentences. 
Part of the issue is that, for example in the first sentence, there are ordinals which are postcodes and which are not (quantity). I need datasets which include both these kinds of things so i can have it ignore the non-postcodes
",['data-request'],
Have any dataset of the forum about football?,"
I want some data like:  

I need some data from the European Football League Forum, for example: discussing the Champions League, Premier League players, matches, etc;
I want to do some nlp tasks in the European Football Forum(English);
any format is ok, maybe json is better.

",['football'],
Device Product Code API call,"
I'm trying to return medical device ""product_code"" data, but the following two URLs do not work. For example, I'm trying to get data on the product code, ""DXN"" as listed here:
https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfPCD/classification.cfm?ID=822.
Any thoughts on what is missing? 
// 2x NON-FUNCTIONAL CALLS:
https://api.fda.gov/device/510k.json?search=openfda.product_code:dxn
https://api.fda.gov/device/510k.json?search=product_code:dxn
","['openfda', 'medical']",
How to use wikidata property paths?,"
Given a term/concept, I want to decide if it belongs to computer science. For that, I am checking if the concept has a property path to computer science node. In other words, I am checking whether computer science is an ancestral concept.
For this purpose, I am using the following wikidata query.
SELECT DISTINCT ?item {
VALUES ?searchTerm { ""word2vec""}
SERVICE wikibase:mwapi {
    bd:serviceParam wikibase:api ""EntitySearch"".
    bd:serviceParam wikibase:endpoint ""www.wikidata.org"".
    bd:serviceParam wikibase:limit 3 .
    bd:serviceParam mwapi:search ?searchTerm.
    bd:serviceParam mwapi:language ""en"".
    ?item wikibase:apiOutputItem mwapi:item.
    ?num wikibase:apiOrdinal true.
}
?item (wdt:P279|wdt:P31) ?type
filter exists {?type (wdt:P279|wdt:P361)* wd:Q21198}
}
ORDER BY ?searchTerm ?num

However, the query gets timeout. 
Therefore, I would like to know if there is another way of solving my approach.
I am only interested in concepts that reaches computer science node using 8 or less hops. For example, is it possible to get all the nodes related to computer science node in 8 or less hops before, and then use this node list as a vocabulary to validate the concepts. Please let me know if my explaination is not clear.
I am happy to provide more details if needed.
","['uses-of-open-data', 'research', 'wikidata', 'sparql', 'rdf']",
Which is the best choice of getting bonds data from?,"
I have to find some data of Germany, Greece 10 years bonds and risk premium from 2017 up to now. I found some sources,

https://countryeconomy.com/bonds/germany

https://www.bloomberg.com/quote/GDBR10:IND

https://www.investing.com/rates-bonds/germany-10-year-bond-yield-historical-data


but there exist some differences between them. For example, in the first site, the yield on 05/09/2019  was given -0.04%. In Bloomberg, it was given -0.05%.
Which one is trustworthy? Does anyone know the reason for which this difference arises? Is there any other source that I can check?
","['data-request', 'finance']",
Where to find an actual bigdata with Variety and Volume?,"
I am exploring the field of BigData analytics. I am basically interested in dealing with two V's: Volume and Variety. I am not able to find a decent data which has a Volume enough to be called a big data along with the Variety in the same dataset consisting of images and text both. I have tried searching on various websites where we usually search for datasets.
",['big-data'],"It's a pretty vague question, but one data source with variety of data would be the Twitter feed. The data can grow as ""voluminous"" as you want, and you can use the data in a ""variety"" of ways. For example:volume - download billions of tweetsvariety - use the various types of data that comes with social networks. Graph/network machine learning on the links between accounts or the biological-like spread of retweets.Image analysis on what images/figs are shared, or profile imagesText mining on the actual tweet text, such as sentiment analysisGeographical analysis with geo-tagged tweetsetcHere's an overview of what data and metadata comes with a tweet.Search through here and others about Twitter datasets and API access. If you have a specific question that isn't a duplicate, feel free to ask a new question."
"what does those 2 types of values in column ""Age"" exactly mean in “horse-colic.data” dataset?","
I am learning horse-colic dataset.
there are 2 types of values in column 2, 1 and 9.
dose that mean a record (a horse) is 1 year old or 9 years old?
",['uses-of-open-data'],
Where to find census data for many countries?,"
I'm working on a GIS project and could really use your help. I've been googling all day but haven't had any luck. Where can I find:

list of all countries with reputable census data and link to the data
list all the statistical boundaries per country with census data 

","['data-request', 'geospatial', 'census']",
"Request for Feed The Future, Baseline Population Based Survey - Ethiopia","
I am working on an MSc thesis titled women empowerment in agricultural productivity and marketed surplus: In case of Ethiopia. How can I access the data of Feed The Future, Baseline Population Based Survey - Ethiopia collected in 2013 and is there a second wave of the same data?
",['data-request'],
Social media data sets for data science and exploration?,"
I'm looking for some open data sets of social media apps (messaging app, networking app, user sharing app, etc...) that I can use to practice modeling and visualizing within the context of social media products. 
",['social-media'],
Movie plots and reviews dataset,"
Is there any dataset with movie plots and reviews (not only rating)?
I have had a look at the existing dataset, but they contain only one of the two (i.e. only plots or only reviews).
I would be interested in similar datasets for books.
","['data-request', 'film', 'books']",
Capacity/attendance information for US event venues,"
Can you think of a source for data regarding the capacity (number of seats or people that can fit in the venue) of different venues in the US, ideally large urban centers like NYC, LA, Chicago etc?
Venues in this case means locations dedicated to holding events of all sorts, such as sports arenas, theaters, music halls, business conference centers, even bars and restaurants.
I am looking for any data that would either directly or indirectly point to how many people each venue can hold, with priority on large US urban centers.
","['data-request', 'usa', 'buildings']","If you have a handful of stadiums and arenas only, then you might find a list online that suffices. For example, from Wikipedia global or US only.If you need wider coverage, and also for many types of buildings, consider the following two options:Option 1: Wikidata, with as an example some variation of  arena (Q641226) and maximum capacity (P1083)try it!If this is helpful, but you need some Sparql help for refining the query, you can ask a new question here, or at the Request a Query page.Option 2: OpenStreetMap has a tag for leisure=stadium as well as keys for capacity and seats.You can use the Overpass-turbo tool to develop a query, and since it's not massive amounts of data, probably export from there, too.try it!You asked about:... sports arenas, theaters, music halls, business conference centers, even bars and restaurants.I think option 1 may be better for sports arenas, theaters, music hallsand option 2 may be better for business conference centers, even bars and restaurants.My opinion would be to to cast a wide net with OSM data for various categories, and then use the existing link to Wikidata objects. For example, in OSM, the Barclay Center has this tag: wikidata=Q807966"
Dataset for English word trigrams,"
Does anyone know where to find such a dataset? There is Google's Ngram viewer but it is too big to be useful. I'm looking for something smaller. Perhaps with only the 100k most common English words and with most punctuation stripped.
","['data-request', 'language', 'english']",
List of the banks worldwide,"
Could you guys help me to find a dataset with a list of the banks worldwide (or list of European banks at least). Doesn't matter which format it will be (JSON, XML, SQL). The main problem: I need a banks list with SWIFT/BIC and (the most important thing) with an internal country codes: eg, for Germany it's 8 numbers code (like 37040044), for Czech Republic - 6 numbers (like 0800), for France - 5 numbers (like 20041).
","['data-request', 'bank']",
"CKAN : ValueError: VDM only works with SQLAlchemy versions 0.4 through 0.9, not: 1.1.2","
Do I need to upgrade the package vdm to make it compatible with sqlalchemy version greater then 0.9? 
This is a CKAN question.
","['ckan', 'python']",
Dataset form 5500,"
I am curious if form 5500 is included in any current datasets or will be included in the near future. I certainly have a workaround for this, but an API call to the dataset would be much more direct.
",['labor'],
Wikidata SPARQL How to speed up this query?,"
I have come to this query, which retrieves wikipedia and wikidata info from a wikipedia title:
SELECT ?wikipediaId ?wikipediaTitle ?wikidataId ?desc ?imageUrl
(GROUP_CONCAT(?instanceOfS; SEPARATOR="";"") AS ?instancesOf)
(GROUP_CONCAT(?subclassOfS; SEPARATOR="";"") AS ?subclassesOf)
(GROUP_CONCAT(?partOfS; SEPARATOR="";"") AS ?partsOf)
(GROUP_CONCAT(?instanceOfLabel; SEPARATOR="";"") AS ?instancesOfLabel)
(GROUP_CONCAT(?subclassOfLabel; SEPARATOR="";"") AS ?subclassesOfLabel)
(GROUP_CONCAT(?partOfLabel; SEPARATOR="";"") AS ?partsOfLabel)
WHERE {
  SERVICE wikibase:mwapi {
    bd:serviceParam wikibase:endpoint ""en.wikipedia.org"".
    bd:serviceParam wikibase:api ""Generator"".
    bd:serviceParam mwapi:generator ""links"".
    bd:serviceParam mwapi:titles ""Albert Einstein"".

    bd:serviceParam mwapi:prop ""pageprops|description|pageimages"".
    bd:serviceParam mwapi:piprop ""thumbnail"".
    bd:serviceParam mwapi:pithumbsize ""300"".
    bd:serviceParam mwapi:pilicense ""any"".

    ?wikipediaTitle wikibase:apiOutput mwapi:title.
    ?wikipediaId wikibase:apiOutput ""@pageid"".

    ?item wikibase:apiOutputItem mwapi:item.
    ?desc wikibase:apiOutput ""@description"".
    ?imageUrl wikibase:apiOutput ""thumbnail/@source"".
  }
  BIND (COALESCE(?item, """") AS ?vItem)
  OPTIONAL { ?vItem wdt:P31 ?instanceOf }
  OPTIONAL { ?vItem wdt:P279 ?subclassOf }
  OPTIONAL { ?vItem wdt:P361 ?partOf }

  BIND (STRAFTER(STR(?vItem), STR(wd:)) AS ?wikidataId)
  BIND (STRAFTER(STR(?instanceOf), STR(wd:)) AS ?instanceOfS)
  BIND (STRAFTER(STR(?subclassOf), STR(wd:)) AS ?subclassOfS)
  BIND (STRAFTER(STR(?partOf), STR(wd:)) AS ?partOfS)

  MINUS { ?vItem wdt:P31/wdt:P279* wd:Q17442446 }
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"".
    ?instanceOf rdfs:label ?instanceOfLabel.
    ?subclassOf rdfs:label ?subclassOfLabel. 
    ?partOf rdfs:label ?partOfLabel. }
} GROUP BY ?wikipediaId ?wikipediaTitle ?wikidataId ?desc ?imageUrl

It takes 13s for Albert Einstein, and 35s for Brazil.
I don't expect this to work too much fast, but I am sure this can be speeded up. I have read that the labels should be outside from this select, but even without the labels, the code still pretty slow. I have read that some sort of WITH blocks could help, but I haven't found too many examples.
What are the best ways to speed this up?
","['wikidata', 'sparql']",
How to get a list of vendors/brands that supply Walmart.com,"
I am trying to figure out the best way to compile a list of vendors or brands in the Walmart.com eCommerce store. 
Would the best way to go about this be scraping their website or is there another way to retrieve this information? 
",['data-request'],
Looking for suggestions of sources for data science project,"
I'm currently taking a first step into Data Science, and studying a specific computational method, I'm a math student, but I'm looking for reliable data sources, and if related to biology (e.g public health numbers) or information spread (this one i guess is harder to evaluate, but maybe like spreading of news or sharing of information on internet) it would be very appreciated.
My point here is where to look up for this kinda of data, in a reliable manner, and preferably for free.
Any suggestions are welcome!

As suggested: 
Data: Mainly data from numbers of case of disease in a region over time, or sharing of fake news (nothing correlated i know but not sure yet which path to pursue)
Context: Trying to correlate data via some kind of regression, so for modeling some specific situations, method is developed but looking to try it on  real data, and it would be better if a large amount data is available.
Region: Preferably in Brazil, but at this moment any region should be enough.
License: Very situational whether willing to pay for it or not, if for free it is easier to start a work.
Format: Will problably use it on Mathlab or Phyton, so right now just raw data in txt or any format like this should do it
Authority: Not really open to dubious data
Non Answers: I did look for it on governamental sites from Brazil, it has some data but wanting other sources also (still acepting hints on websites from Brazil, might not have looked for all possible sources yet).
","['data-request', 'government', 'medical', 'internet', 'brazil']","I think this is a good candidate for the UCI Machine Learning Repository, which is often used here as a resource: link to threads.With the ""View All Data Sets"" view you can filter and find specific, prepared and cleaned data sets. For learning this is quite beneficial, because there will surely be others developing with these data sets. Each data set is labeled with what kind of analysis is suggested, for example ""_regression / numerical / multivariate _"".Additionally, by exploring with the portal and trying various filters, you'll get familiar with the terminology of data science and machine learning.Example usage:Click on ""Regression"" on the left menu bar, and you get this view: http://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=tableThen click on ""Numerical"": http://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=num&area=&numAtt=&numIns=&type=&sort=nameUp&view=tableKeep playing with the filters until you find a good one that looks like fun to explore.For example, here's the data set ""Fertility""100 volunteers provide a semen sample analyzed according to the WHO 2010 criteria. Sperm concentration are related to socio-demographic data, environmental factors, health status, and life habitswhich has these technical properties:You can also search the repository with custom search terms, like this search for Brazil."
Typical Weather Averages by Lon/Lat,"
I would like to build a local dataset of monthly averages for rainfall, sunshine hours, temperate (C/F) for all the major cities of the world.
I have all the lon/lat's stored for all the cities I need in SQL, so what is the best way to mine this data?
The links to the monthly Global Historical Climatology Network files seem to be broken, and I wouldn't quite know the best way to parse them.
So say we took 2018 as an example; I just want something like this 
I can consume an API if there is a free one; but it also looks like what Weather Underground offers; 
https://www.wunderground.com/history/monthly/gb/hounslow/EGLL/date/2018-1
I know its a lot of data I need, but I really need to find a free source for this data ideally, or at worst one which wont cost hundreds of dollars.
Can anyone help?
","['api', 'weather', 'historical']",
"High-resolution, hyperspectral satellite imaging?","
I am hoping to expand my (biology-focused) research to include satellite data. For this, I'd need satellite imaging that includes multiple values in the visible spectrum (specifically, above 490nm) and extends slightly into the infrared (710nm). I have tried MERIS and Hyperion, but the resolution was insufficient (my area of interest is a lake ~300m x 55m). I've had a brief look at Worldview 2/3, but the spectral bands seem too wide.
Does anything like this exist, and is it freely available for research use?
","['data-request', 'geospatial', 'images', 'biology']",
Consumer Expenditures by Census Tract,"
Does anyone know how to source Consumer Expenditures (CEX) by Census Tract? 
I know that the Bureau of Labor Statistics offers CEX by Metropolitan Area and Region but I can't seem to figure out how to get the data by Census Tract.
","['uses-of-open-data', 'us-census', 'census', 'spending']",
Wikidata Sparql Getting properties from a Wikipedia generator list,"
I am trying to get the properties that the linked pages from a wikipedia page have.
SELECT ?item ?wikipediaTitle ?target WHERE {
  SERVICE wikibase:mwapi {
    bd:serviceParam wikibase:endpoint ""en.wikipedia.org"".
    bd:serviceParam wikibase:api ""Generator"".
    bd:serviceParam mwapi:generator ""links"".
    bd:serviceParam mwapi:titles ""Arduino"".
    bd:serviceParam mwapi:prop ""pageprops"".

    ?wikipediaTitle wikibase:apiOutput mwapi:title.

    ?item wikibase:apiOutputItem mwapi:item .
  }
  ?item wdt:P31 ?target.

  SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". }
}
LIMIT 1

w.wiki/3Ue
However, this query always timeout, even with the LIMIT 1. The problem line is the ?item wdt:P31 ?target. Any way to fix this?
Also, assuming that it is working. It will generate one line for each P31 found. Is there any way to make all properties fit one single line? Maybe concatenating them and separating with "", ""?
","['wikidata', 'sparql']",
Medical dataset for creating questionares (in csv/rdf formats so that I can import them into Neo4J directly),"
I want to create a graph database of medical information in the form of entity nodes connected by relations and was wondering if any csv datasets existed that would allow me to directly import the data into Neo4J.
","['medical', 'csv']",
How to identify general medical terms using Wikipedia/DBpedia/WikiData,"
Given a list of medical terms, I want to identify and remove the general (less granular) terms.
For example consider the below mentioned word list:
 - kartagener s syndrome 
 - disease treatment
 - human 
 - blood 
 - ischaemia
 - acute respiratory distress syndrome
 - hospital 
 - adrenergic blocking drug 
 - finger 
 - symptom 
 - therapy
 - extracorporeal membrane oxygenation 
 - hand

I mean word such as;
 - human
 - blood
 - disease treatment
 - hospital
 - finger
 - symptom
 - therapy
 - hand

as general/less granular terms.
I tried to detect these terms using the following two statistical measures.

frequency: i.e. I assumed the more frequent the word in the corpus
is, the less granular it is 
IDF (Inverse Document Frequency)

However, since they are only statistical measures and does not consider the meaning (semantics) of the word, it worked poorly in my dataset.
I tried to use wikipedia categories to filter these terms. However, I could not find a proper way of using categorical details to facilitate my problem. Therefore, I am wondering if there is any way to detect general terms using wikipedia (or its variants such as DBpedia, Wikidata etc.)
For those, who would like to check a long list of concepts, I have attcahed a long list herewith: https://docs.google.com/document/d/1BYllMyDlw-Rb4uMh89VjLml2Bl9Y7oUlopM-Z4F6pN0/edit
NOTE: I am not expecting the solution to work 100% (if the proposed algorithm is able to detect many of the general concepts that is enough for me)
I am happy to provide more details if needed.
","['uses-of-open-data', 'research', 'linked-data', 'rdf', 'ontology']",
Childlessness rate by country,"
Does anyone know where I can find a table or map of the childlessness rate by country for both men and women? Historical comparison of data would also be desirable.
","['data-request', 'historical', 'demographics']",
Open repository of political logos/images,"
I'm looking for political logos (images). Images should be able to be bulk downloaded, if possible. I've found a source from the US, but I'd like to collect from other countries/regions.

","['data-request', 'images', 'politics']","One source for the US (2018 election) ishttps://www.politicsanddesign.com/The first of its kind, this collection consists of every campaign logo from the 2018 election for United States Congress. The archive is a tool to explore trends and typologies that reveal themselves only when viewed in aggregate.(they offer a bulk download on demand, and I'll post a link to the export here, if its license permits.)Example screenshot:"
Seeking reservoir data set for UK?,"
I was looking for reservoir data to understand who owns which reservoir, could not find it over the internet. 
Anybody knows where I can find it?
","['data-request', 'geospatial', 'uk']",
Statistics about Extensible Metadata Platform (XMP) implementation by smartphone cameras,"
I am writing an Android photo sharing app, and pondering whether I should implement Extensible Metadata Platform reading from pictures taken by the smartphone/tablet/device's.
If almost no smartphone writes XMP data, then I don't need to waste my time implementing that.
So, I would welcome any data about XMP implementation in smartphones. Ideally the percentage of smartphone-taken pictures that embed XMP data, ideally per year and per country. Single numbers such as ""the XYZ phone/OS embeds XMP and had a X% market share in Indonesia in 2015"" are welcome too.
","['metadata', 'photographs']",
Source of multilingual chat/online/contemporary corpus data?,"
I need to develop autocorrection and prediction for mobile keyboard app that will work for some 8-10 most common Latin languages + Russian (English, German, Spanish, Portugues, French, ...). For start, I need NLP corpus for each of those languages.
Ideally all corpora should be from same source and match at least some of these criteria:

Written language, typos removed.
Large enough: at least 10 million words, the more the better
Texts typed in online chats, emails, forms, apps... Or similar. Should include language typically used in those situations.

I have no need for syntax or other tagging, raw texts (optionally tokenized) are just fine. I can pay reasonable price.
Any help or even a pointer into resource is greatly appreciated!
","['data-request', 'nlp', 'language']",
Wikidata Query: How to retrieve the normal (non-verbose) JSON?,"
We can download the results of a Wikidata Query as ""JSON file"" or ""JSON file (verbose)""
Example link of random query: http://w.wiki/WQ.
I am developing a javascript software which retrieves some data from the Wikidata Query. But when I get the JSON, it is the same as the ""JSON file (verbose)"", but I really don't need/want all the other data that comes together.
Which argument should I pass in the URL to get the non-verbose JSON?
","['wikidata', 'sparql']",
Where to find USA river basins data shapefile?,"
I need the shapefiles of all river basins polygons of USA. I need these boundaries:

in order to create river basins map in combination with DEM data.
","['geospatial', 'usa', 'hydrology']","Those are the HU-2 (2-digit Hydrologic Units) boundaries from the national Watershed Boundary Dataset (WBD). Sometimes you'll see them referred to as HUC-2 instead of HU-2 (HUC = Hydrologic Unit Code).
It should be possible to download this data for the entire continental US as a single dataset. However...It's very easy to get the metadata for this dataset. The metadata is available here, here, here and here. Some of the metadata pages also allow you to download the metadata as an XML file.It's more difficult to get the actual data. According to the metadata page, you can download the WBD data through the National Map viewer. But as far as I could tell, the national WBD dataset is not actually available through the map viewer right now. I went through the steps to download the national WBD dataset, but nothing was listed on the ""data products"" page.The 2-digit Hydrologic Unit boundaries are available separately for each watershed. For example, the Missouri watershed boundary is one single download called WBD_10_HU2_Shape.zip. This file contains:Here are direct links to all the 2-digit Hydrologic Units in the United States, in shapefile format. You can re-create the national WBD layer by stitching together the WBDHU2 layer from each zip file. Looking at the image you posted, you may want to include some smaller subwatersheds along the east coast, Gulf coast and in the Rocky Mountains. I don't see any obvious pattern to which watersheds are color-coded separately, so you'll probably have to manually select the ones you want from the different HUC levels. Pro tip: the larger the HUC number, the smaller the watershed, ie HUC-2 watersheds are the largest, and HUC-16 are the smallest.These are the download links that I got by going through the National Map Viewer. I hope they work for you, but I'm not sure if they're temporary/personal links or permalinks. If they don't work, you'll have to go through the National Map Viewer yourself. Follow the steps illustrated below to find these layers in the National Map Viewer interface.
You can also see the various HU layers on ArcGIS.com, including previewing them on a map and linking to them as a MapService.Note: If anyone wants to edit this question and put the HU-2 layers in numerical order, and/or look up and add the watershed names, that would be great.UPDATE: I found a direct download source for Watershed Boundary Dataset and Lines for HUC2-12. They're subdivided by HUC-level (HU2, HU4, HU6, etc.) Each file contains the Hydrologic Unit boundaries for the entire nation; you can also download HUC2-12 as one zip file. Thank you USDA National Resources Conservation Service, you really one-upped the USGS this time."
How to fetch data from open fda API with multiple query parameters using +AND+,"
I am using below API query to fetch recalls for food by city AND termination date range.
but it doesn't seem to work 
https://api.fda.gov/food/enforcement.json?search=city:%22Westminster%22+AND+termination_date:[2011-01-01+TO+2014-01-01]&limit=3&skip=100
but if I update the query with just (+ : it acts as OR condition) : 
https://api.fda.gov/food/enforcement.json?search=city:%22Westminster%22+termination_date:[2011-01-01+TO+2014-01-01]&limit=3&skip=100
then i get the results. 
Seems that the '+AND+' function doesn't respond properly, as there is data already present with the filter I am using with +AND+ query.
Please help.
","['api', 'openfda']",
Wikidata SPARQL get current VALUES index,"
I have the current SPARQL code:
SELECT ?currentQid ?propQid ?targetQid WHERE
{
  VALUES ?current {wd:Q5 wd:Q6 wd:Q7 wd:Q8 wd:Q9}
  VALUES ?prop {wdt:P31 wdt:P279 wdt:P361}
  BIND (STRAFTER(STR(?current), STR(wd:)) AS ?currentQid)
  BIND (STRAFTER(STR(?prop), STR(wdt:)) AS ?propQid)
  BIND (STRAFTER(STR(?target), STR(wd:)) AS ?targetQid)
  ?current ?prop ?target.
}
ORDER BY ASC (?currentQid)

(w.wiki/3Gn)
Which outputs
currentQid  propQid  targetQid
    Q5        P31    Q55983715
    Q5        P279   Q154954
    Q5        P279   Q215627
    Q5        P361   Q1156970
    Q8        P31    Q331769
    Q8        P31    Q60539479
    Q8        P279   Q16748867

However, I wanted to also have the current index of the value, so I can correctly attribute the values to the array's item when I get the JSON.
How could I get the following table?
index  currentQid  propQid  targetQid
  0        Q5        P31    Q55983715
  0        Q5        P279   Q154954
  0        Q5        P279   Q215627
  0        Q5        P361   Q1156970
  3        Q8        P31    Q331769
  3        Q8        P31    Q60539479
  3        Q8        P279   Q16748867

","['wikidata', 'sparql']",VALUES are unordered; SPARQL list syntax is also not allowed in VALUES. The simplest option is explicit ordering:Try it
Gini indices of wealth for each country,"
Where can I find a colored World Map (A choropleth map) with the various Gini indices of wealth for each country (not Gini indices of income)?
I have searched the Internet and could only find the latter. The Gini index varies between zero and one to show economic disparities between citizens.
","['data-request', 'geospatial']",
Face dataset with different ages for same individuals,"
for my thesis i need a face dataset where the same person is available at different ages, and possible in more real-life-like photos rather than portraits.

Data: i'm looking for a free to use dataset of faces with possibly
multiple photos of the same person at different ages, and more
real-life-like photos rather than portraits. 
Context: showing how the
face-recognition services i tested for my thesis (AWS, Azure and
Google) aren't reliable enough to be integrated in a Smart
Conversational Agent for Recognition. 
License: free, with the
possibility of showing 10-20ish of the pictures in my thesis Format:
whether it's a database with a prebuilt table, a simple zip, or even
a set of links to individual pictures, it doesn't matter. The latter
(set of links) would actually be more helpful since the web service i
made to interface myself with AWS-Azure-Google uses links, but it's
not a requirement at all. 
Authority: doesn't matter, i just want my
degree ahahahah


The purpose of the project is testing AWS, Azure and Google's face recognition services to identify the same person across multiple photos (with one or more people) in a wide age difference, to eventually include facial recognition in a conversational agent for reminiscence.
I already tested enough with random photos to know the result (that is none of these services is reliable enough to identify the same person with a wide age gap and with little training), but i need a dataset for which i can have the rights to use in my thesis.
Is there any online and freely available?
I've checked some of the ones listed here but they all seem to have only portraits with no group photos nor any significant age gap for the same person.
",['faces'],
Population data as grid,"
I'm looking for world/europe/switzerland population data with a grid format. For example, 1km squares and then the population in that gridpoint.

I found one source, http://www.diva-gis.org/gdata

Subject: Population
Description: Population density (old)
Source: CIESIN, 2000. Global gridded population database
Format:   Grid
Resolution: 30 seconds

But I'd like to know if there is anything more updated, and perhaps different file/db formats. The above source file format is:

Vector data are stored as ESRI shapefiles Grid (raster) data are stored as DIVA gridfiles

That site's file format docs are down, but here's an archive.
","['data-request', 'geospatial', 'demographics', 'europe', 'global']","From NASA's Socioeconomic Data and Applications Center (SEDAC), I found this dataset: Gridded Population of the World (GPW), v4.Resolution:Date:Population input data are collected at the most detailed spatial resolution available from the results of the 2010 round of Population and Housing Censuses, which occurred between 2005 and 2014.All estimates of population counts and population density have also been nationally adjusted to population totals from the United Nation’s World Population Prospects: The 2015 RevisionThe input data are extrapolated to produce population estimates for the years 2000, 2005, 2010, 2015, and 2020. Format:The raster data sets are now available in ASCII (text) format as well as in GeoTIFF format. Five of the eight raster data sets are also available in netCDF formatData License:licensed under the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0)"
Seeking data for spatial interpolation,"
Can someone point me to a Kriging dataset? If it is natural data, it would be very great! (Such as rainfall, porosity, soil density, atmosphere-concentration, etc. ), temperature observations. Or if someone has some dataset they have used for Kriging in the past, could you please share?
","['data-request', 'geospatial']",
Total distance of Cycling routes in European Cities,"
I managed to find a lot of stats about cycling in Europe, however, not what I was looking for.
I need an open dataset with the total length of the cycling routes in each European City (or at least some of them)
For example,
City, TotalLength
London, 84km
Berlin, 72km
Paris, 34km
....

",['transportation'],
Where can I find open source Medical Image Datasets for capillary Segmentation?,"
Where can I find open source medical datasets for Nail fold capillaries?
","['data-request', 'medical']","Open-Access Medical Imaging repositories are available all over the internet. A list of Medical Imaging datasets is provided by Giorgos Sfikas on his medical-imaging-datasets repository. Here, you will find several ""search-engines"" for medical data. Nevertheless, it could be interesting to follow both Stephen R. Aylward's list of repositories and the SICAS Medical Image Repository. I hope that helps too."
is there a dataset/database contains false and true negative and positive statistics for some specific disease?,"
I would like to compute a set of statistics consists of 4 following items:

false negative
true negative
false positive
true positive

Is there a public dataset/database for some specific disease could be used for this?
","['data-request', 'medical', 'disease']",
Does the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) definitely disappered?,"
A rather simple question:
I can not find a 2018 (neither a 2019) ImageNet Large Scale Visual Recognition Challenge (ILSVRC) for this particular dataset: http://www.image-net.org/challenges/LSVRC/
It seems there is no information about the future of this challenge on this webpage.   
I wonder if it has been definitely discarded because of too good results from competitors nowadays?       
If yes, what are the other challenges that motivate scientific research in image classification or recognition tasks today (2019)?    
Last available year was 2017: http://image-net.org/challenges/LSVRC/2017/ 
","['classification', 'imagenet']","As stated in their last new from the 2017 challenge webpage:
http://image-net.org/challenges/LSVRC/2017/index#news :Jul 26, 2017: We are passing the baton to Kaggle. From now on, all
  three challenges(LOC-CLS, DET, VID) will be hosted on Kaggle!it's now hosted on kaggle directly:
https://www.kaggle.com/c/imagenet-object-localization-challenge
It's also written on their home page normally (but I wasn't able to read it for some days): Check out the ImageNet Challenge on Kaggle!http://image-net.org/"
Shapefile of Russian forest zones,"
I want to download a shapefile of forests in Russia by forests zone. Ideally a joint shapefile of forests and Russian administrative regions.
Can you give me a link to it?

","['geospatial', 'russia']",
Why does the data on website not match what is returned from the api,"
I am trying to get data similar to what is shown on https://www.fda.gov/Safety/Recalls/default.htm using the api, but I am seeing a lot of discrepancies. 
For example when I use the following api call: https://api.fda.gov/food/enforcement.json?search=recalling_firm:%22safeway%22&limit=100 then I see a total of 10 results returned. If I do the same search on the recall website using ""Safeway"" as the keyword, I only see 5 results returned. What am I missing to get these data sets to match up?
I also see in the food api endpoint searchable fields that the openfda object is listed as searchable, but it always returns empty when when using the food api. Is there another way to get the brand name for food items using this api?
Thank you for your help!!!
","['data-request', 'api', 'openfda']",
API to get Get UK street name from post code,"
I am looking for a simple, reliable and free (gratis) API which will return any corresponding UK street name for a UK postcode (preferably with no registration or key required). I am looking to generate test data, so I just need any of the potentially several street names in the postcode.
I welcome the API returning additional information (lat/long, etc), but that info is not necessary.
This is for demo where I am generating dummy, but somewhat realistic, data. I have a list of UK cities with a Lat/Long for each (city centre? Or main post office?), add small fudge for randomness, get the post form the lat/long, then get a street (any street) that corresponds to the post code. It's for a quick knock up MVP where no one will check to that level of accuracy. They just want to see pins on maps with tooltips.
","['api', 'geocoding']",
Where I can get the full list of San Francisco Bay Area Tech Companies?,"
There already a SiliconValleyMap, but I want to create a San Francisco Bay Area Tech Companies Map. Where I can find the company list?
","['geospatial', 'openstreetmap']","Many Bay area companies are included in the SV map, despite its name.You can access the raw data as a json (archive)Data model looks as follows: "
Open database for various DB servers,"
For benchmarking and testing, I am looking for an open SQL database that can be installed in various database servers (e.g. Postgres, MySQL, etc).
",['database'],"One good option for RDMS (relational databases, aka SQL) is the Chinook Database, which is based on an iTunes library.Chinook is a sample database available for SQL Server, Oracle, MySQL, etc. It can be created by running a single SQL script. Chinook database is an alternative to the Northwind database, being ideal for demos and testing ORM tools targeting single and multiple database servers.Supported Database ServersMySQLSQL ServerSQL Server CompactSQLitePostgreSQLOracleDB2DownloadsIf you want to use the data from your own iTunes library, then replace the file ChinookDatabase\DataSources_Xml\Source\iTunes Music Library.xml with your version.Downside seems to be that most scripts are for windows, although the .sql database statements can be loaded directly.License: MIT(my source)"
what type of data is needed to learn machine learning create logo,"
Can anybody suggest, what type of data is needed to  learn machine learning create logo.What variables should I take to train a neural network? The bigger, the better.Can someone have experience and be able to prompt on what data to train. I.E. What data i should collect?
","['data-request', 'machine-learning', 'images']","The entire framework is outlined hereLLD - Large Logo Dataset - including training dataset downloadsTraining Generative Adversarial Networks (GANs) for logo synthesis on such multi-modal data is not straightforward and results in mode collapse for some state-of-the-art methods. We propose the use of synthetic labels obtained through clustering to disentangle and stabilize GAN training. We are able to generate a high diversity of plausible logos and we demonstrate latent space exploration techniques to ease the logo design task in an interactive manner.Code repositoryLicense:Please notice that this dataset is made available for academic research purposes only. All the images are collected from the Internet, and the copyright belongs to the original owners."
Does Wikidata contain the data from the Wikipedia {{distinguish}} template?,"
Wikipedia uses the {{Distinguish}} template for pages whose subject is easily confused with another subject. For example, the two Congo countries are frequently confused with each other, so their Wikipedia articles warn the user:

This establishes a N-M-relationship between Wikipedia subjects.
Are these relationships somehow available in Wikidata?
",['wikidata'],
Wikidata SPARQL with optional qualifiers,"
I am trying to adapt the Mona Lisa exercise in the Wikidata SPARQL tutorial so it will show all the materials used and where they apply.
If I simply do:
SELECT ?painting ?paintingLabel ?material ?materialLabel 
WHERE
{
  ?painting p:P186 [ ps:P186 ?material].
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""[AUTO_LANGUAGE]"". }
  FILTER (?painting = wd:Q12418)
}

Link to this query.
then I will see the 3 materials that make up the painting.
If I now edit that query to include P518 (applies to part), I only see the 2 materials that have the P518 qualifier:
SELECT ?painting ?paintingLabel ?material ?materialLabel ?appliesTo ?appliesToLabel
WHERE
{
  ?painting p:P186 [ ps:P186 ?material; pq:P518 ?appliesTo].
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""[AUTO_LANGUAGE]"". }
  FILTER (?painting = wd:Q12418)
}

Link to this query
How can I handle the fact that the P518 qualifier is optional?
","['wikidata', 'sparql']",
Sharing machine learning models of a confidential dataset,"
Please share your thoughts about using machine learning models from confidential datasets. For example, I have a classification model I trained using sklearn. In general, can I use the model for similar purposes? Or does the owner of the confidential dataset automatically own the model too?
I've read that it depends on the library and dataset used whether information about the data can be inferred or not. I know for sklearn models, it cannot be. Can you please give me more examples as well?
I may seem to ask for legal advice but no, I just want to know more about this area. I'm not affiliated with any tech lawyer either, and I think that goes too far for a simple informal discussion.
",['machine-learning'],
Time series dataset for forecasting,"
I am looking for time series dataset that I can use for forecasting. I prefer one that comes with monthly values.
","['data-request', 'time-series']",
machine learning for computer virus detection,"
I search any dataset(s) which use to train machine detect computer virus.
Has anybody example data  for it?
","['data-request', 'machine-learning']","Microsoft provides a dataset for malware prediction on Kaggle. The dataset and more information can be found at 
https://www.kaggle.com/c/microsoft-malware-prediction/data"
HTTP Response Codes,"
For a data visualization, I'm looking for http response codes. There are many sources of this dataset, but I'm looking for

machine readable (JSON preferred)
reliably updated (so that my dataviz is always updated as well)
reliably hosted (so I can use the file as a web-service)
official (from some consortium or something)

","['data-request', 'api', 'internet']","One possible ""official"" source is from the Internet Assigned Numbers Authority (IANA)https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtmlFormats:XMLHTMLTXTCSV"
Basic Use of openFDA Animal & Veterinary API,"
Will FDA be offering any additional training materials regarding use of its recently introduced openFDA Animal & Veterinary API?  Although I've read the 'How to use the API' instructions, the system is not intuitive.  No matter how I try to build a query to search the veterinary drug adverse event database, I encounter error messages such as:
{
""error"": {
  ""code"": ""NOT_FOUND"",
  ""message"": ""No matches found!""
  }
}

","['api', 'openfda']",
Which is the best way to work with NCBI data obtaining online partial information from the whole,"
I was trying to create a database from NCBI Nucleotide bank. I did a query which gave me 1124 results.
From each single result I was wanting to obtain only the items realted to  Accesion Country and isolation.
Here is what I get from the NCBI
LOCUS       MH973850                 410 bp    DNA     linear   PLN 03-MAR-2019
DEFINITION  Cryptococcus neoformans isolate OA2 internal transcribed spacer 1,
            partial sequence; 5.8S ribosomal RNA gene, complete sequence; and
            internal transcribed spacer 2, partial sequence.
ACCESSION   MH973850
VERSION     MH973850.1
KEYWORDS    .
SOURCE      Cryptococcus neoformans
  ORGANISM  Cryptococcus neoformans
            Eukaryota; Fungi; Dikarya; Basidiomycota; Agaricomycotina;
            Tremellomycetes; Tremellales; Cryptococcaceae; Cryptococcus;
            Cryptococcus neoformans species complex.
REFERENCE   1  (bases 1 to 410)
  AUTHORS   Abaci Gunyar,O., Yoltas,A., Haliki Uztan,A. and Yamac,M.
  TITLE     Isolation and Identification of Cryptococcus neoformans from the
            soil samples taken from inside and outside of Nigde Duzkir (=
            Aladaglar) cave
  JOURNAL   Unpublished
REFERENCE   2  (bases 1 to 410)
  AUTHORS   Abaci Gunyar,O., Yoltas,A., Haliki Uztan,A. and Yamac,M.
  TITLE     Direct Submission
  JOURNAL   Submitted (24-SEP-2018) Biology, Ege University, Genclik Caddesi,
            Izmir 35040, Turkiye
COMMENT     ##Assembly-Data-START##
            Sequencing Technology :: Sanger dideoxy sequencing
            ##Assembly-Data-END##
FEATURES             Location/Qualifiers
     source          1..410
                     /organism=""Cryptococcus neoformans""
                     /mol_type=""genomic DNA""
                     /isolate=""OA2""
                     /isolation_source=""Soil sample""
                     /db_xref=""taxon:5207""
     misc_RNA        <1..>410
                     /note=""contains internal transcribed spacer 1, 5.8S
                     ribosomal RNA, and internal transcribed spacer 2""
ORIGIN
        1 aggatcagta gagaatattg gacttcggtc catttatcta cccatctaca cctgtgaact
       61 gtttatgtgc ttcggcacgt tttacacaaa cttctaaatg taatgaatgt aatcttatta
      121 taacaataat aaaactttca acaacggatc tcttggcttc cacatcgatg aagaacgcag
      181 cgaaatgcga taagtaatgt gaattgcaga attcagtgaa tcatcgaatc tttgaacgca
      241 acttgcgccc tttggtattc cgaagggcat gcctgtttga gagtcatgaa aatctcaatc
      301 cctcgggttt tattacctgt tggacttgga tttgggtgtt tgccgcgacc tgcaaaggac
      361 gtcggctcgc cttaaatgtg ttagtgggaa ggtgattacc tgtcagcccg
//
What I want to obtain from the whole data
VERSIONMH973850.1

JOURNAL   Submitted (24-SEP-2018) Biology, Ege University, Genclik Caddesi,
            Izmir 35040,Turkiye

FEATURES             Location/Qualifiers
     source          1..410
                     /organism=""Cryptococcus neoformans""
                     /mol_type=""genomic DNA""
                     /isolate=""OA2""
                     /isolation_source=""Soil sample""
                     /db_xref=""taxon:5207""
     misc_RNA        <1..>410
                     /note=""contains internal transcribed spacer 1, 5.8S
                     ribosomal RNA, and internal transcribed spacer 2""
Which is the best way to accomplish this?
","['programming', 'python', 'biology']",
DRASTIC Method - Dataset,"
Data: I need a dataset including 7 layers to conduct the DRASTIC method as part of a master research. These 7 Layers include:

Depth to water layer
Recharge map
Aquifer Media type
Soil map
Impact of vadose zone map
Hydraulic conductivity zone layer
Topography (DEM)

Context: I am going to create an assignment for a student with DRASTIC METHOD.
Region: Any region in the world.
License: I can keep the dataset conficential and not shared on the web. 
Format: Shapefiles, geodatabase, raster formats acceptable by ArcGIS or QGIS
Authority: there is no specific authority for the data. Any source welcome.
Requirements: Data format should be acceptable with common GIS tools
",['geospatial'],"Some of these datasets are available for the entire US, or for many locations in the US. Most of them are provided by the USGS (US Geological Survey), except for soil data which is provided by the USDA (US Department of Agriculture). Hydraulic conductivity and groundwater recharge are only available for limited areas, so first find an area where they overlap, and you should be able to get the other data. The High Plains aquifer is the only area I found with all these datasets, but there may be others if you look for them.Groundwater recharge data: https://water.usgs.gov/ogw/gwrp/activities/HydCompData.htmlSoil data: https://www.nrcs.usda.gov/wps/portal/nrcs/detail/soils/survey/tools/?cid=nrcseprd1407030If any of those layers comes as point data and you need it as a raster, ArcGIS and QGIS are both capable of interpolating point data into raster data.This page with water budget data seems like it might be helpful even though it's not one of the specific categories you requested."
where could one download one minute climate archive？,"
I have been searching for an archive of one minute climate data. I found bad-quality data from NOAA. Some period data is missing.
Data available through this form needs a fee of $90 for just one city. 
Where else to download one minute climate data?
","['data-request', 'weather', 'time-series']",
Conversation logs open data,"
Is there any open data on conversation logs?
I am looking for open data on conversation logs, yes between individual people. Ideally private chat logs. I am considering using a bot to scrape a website like Omegle which has a ""ask a question"" mode letting two users discuss a topic, but It would be easier if someone recommended a open data set to me.
Just for elaboration, I am doing some things with topic modeling, so This would be useful for my study.
",['nlp'],
How to download an online ArcGIS Feature Layer without an ArcGIS license?,"
On ArcGIS.com, there are many thousands of vector layers available as ""Feature Layers."" For example, Active_Volcanos_WFS.
Access to Feature Layer is provided in the following ways:

View it online in Map Viewer, which you can do without a login or Arc license.

Open the layer in ArcGIS Desktop, which obviously requires a product license. I assume this connects to the layer through the web feature service rather than downloading the source data.
There's also a URL, which from my limited understanding I believe is a Web Feature Service URL, eg 
https://dservices1.arcgis.com/0MSEUqKaxRlEPj5g/arcgis/services/Active_Volcanoes_WFS/WFSServer?service=wfs&re
(I've not succeeded at adding any layer to QGIS from one of these service URLs, either as a WFS or ArcGISFeatureServer layer, but that's a separate question.)

Is it possible to download an online ArcGIS ""Feature Layer"" in any geospatial vector format (shapefile, geojson, geopackage, CSV with WKT or other-formatted geometry column, etc.) with open-source software? Or are they available online only?
I found a Geoprocessing Tool called Download ArcGIS Online Feature or AGS Feature/Map Service, but it appears to be something you need ArcGIS to run. But the existence of that tool implies that it's possible...
","['geospatial', 'uses-of-open-data']",
Curated list of politician's social media (Twitter),"
I found this great list from 2017 for all the Twitter handles for the 100 US Senators and 428 of the US members of the House.
https://gwu-libraries.github.io/sfm-ui/posts/2017-05-23-congress-seed-list

115th Congress: House
115th Congress: Senate

I am looking for similar lists, or meta-lists, and for countries, states, regions, etc. The more curated (updated, up-to-date), the better. Could be Twitter or other social media (Facebook, Instagram, etc).
","['data-request', 'social-media', 'politics']","Global@twiplomacy's world leaders list is a start but more importantly, they have a number of curated lists.  Every Politician has social links for politicians.  List of current heads of state and government/twitter-list - Archiveteam North AmericaPolitwoops US Politwitter Lists (Canadian Gov) US Senator Twitter Accounts, 115th Congress (Historical) EuropeEU certainly have lists that could be used. Switzerland AustraliaNotes:"
Where can I find a dataset of academic conferences?,"
I'm looking for a dataset of academic conferences containing, for each of their editions, as many following field as possible:

impact factor (+ optionally any other qualitative assessments)
field (optionally subfield + keywords related to it)
number of papers/posters/demo submitted and accepted
location
date
number of attendees
whether it was recorded (audio/video)

","['data-request', 'research']",
Where can I find grid file of the Netherlands for R,"
I'm looking for a grid file (ideally 5x5 km) of the Netherlands, because I want to do kriging interpolation in R. 
Where can I find that?
","['data-request', 'geospatial', 'programming']",I found it myself already here. This is the kind of grid I meant.
Where to find Norwegians waterlines and water bodies shp?,"
I am searching for a shapefile containing waterbodies and waterlines (rivers, etc.) in Norway, ideally at scale 1:50 000. 
I have found a great resource of topographic map here: https://kartkatalog.geonorge.no/metadata/kartverket/n50-kartdata/ea192681-d039-42ec-b1bc-f3ce04c189ac but my downloaded data contain a raster of topo map and vectors, which do not contain river lines neither river bodies.
 
I have also found a WMS service for topo data: https://openwms.statkart.no/skwms1/wms.topo4.graatone? which contain the rivers (""Elver"", ""Vannkontur""), but I can not modify the style of those data neither simply overlay it on my map. 
Please, how can I access the river and water bodies data from Norway? My study area is near Østfold. Unfortunately, I am not a Norwegian speaker. 
","['data-request', 'geospatial']",
Download Table from PRR drug Research tool,"
I used the PRR drug research tool: https://openfda.shinyapps.io/RR_D/ 
When I select a drug name it lists me by default the top 50 drug event combinations with PRR & ROR values. 
In the R shiny app there isn't any download button being designed. 
How can I download the table with PRR & ROR values? 
",['openfda'],
Which data processes are applied on FAERS data,"
I am trying to understand if the FAERS data are processed in OpenFDA similarly to what is done in softwares (RxLogix, ORACLE, CVW), meaning: 

Have the FAERS data been checked for duplicates with duplication
removal?
Have the MedDRA PT been mapped to the latest version of the MedDRA
dictionary?
Have the drug names been cleaned?

I couldn't find any answer to these questions from OpenFDA website or from the article from Kass-Hout et al J Am Med Infrom Assoc 2016; 23: 596-600.  
Please don't hesitate to redirect me to any formal documentation for any of these 3 questions above.
",['openfda'],
home energy consumption dataset,"
I am a Ph.D. student of power system engineering. I'm studying about home/building energy management in my thesis, and I need the dataset of building appliance and equipment energy consumption, that has the following features:

Energy consumption of each home appliance and other equipment such as lighting, heating and cooling systems, and etc. must be recorded in a fraction of an hour at all times of the year.
Home/building preferably should have a renewable energy source (such as PV), and its electrical power generation must be recorded for the whole year.
Certainly some people should live in this home/building and the equipment is turned on/off by the human (computer simulator should not turn on/off the equipment), because human behavior is important for the research.

Where can I find such a dataset?
","['data-request', 'energy']",
Historical hourly solar generation data in California,"
In 2013 the California Independent System Operator (CAISO, the bulk electric grid operator) published this image, dubbed it ""the duck curve"", and took the internet by storm (or, at least the part of the internet that tracks trends in renewable electricity generation):

Here's an explanation of the duck curve from Wikipedia:

[The] curve comes from the Net Load (""the difference between expected load and anticipated electricity production from the range of renewable energy sources""). In certain times of the year (namely Spring and Summer), the curves create a “belly” appearance in the midday that then drastically increases portraying an “arch” similar to the neck of a duck, consequently the name “The Duck Chart.”

Essentially, solar electricity production causes a reduction in net energy demand in the mid-day (the belly). Later, sunset coincides with increased demand, causing a sharp ramp (the neck). This effect is shown in the graph with 24 hours of solar and demand data on March 31.
This image generated lots of interest and people are still talking about it today -- lots of search results in the past year are still showing the same image.
But the most recent actual data on the chart is from 2013, and the duck shape was created by the projected net load curves from 2014 through 2020.
I tried to find some recent data from CAISO to see where things stand. To do this, I'll need hourly historical demand and solar production data, in order to calculate net load. 
CAISO's OASIS tool includes historical load data, but as far as I could tell solar data is only included lumped with wind, and only goes back to 2016.
Is there another data source where I could find the historical hourly solar generation for the state of California?

I posted this question previously on electronics.se, but it was closed. Folks on meta there advised I re-post here.
","['usa', 'energy']","I'd read the Wikipedia article, but seeing the chart blown up in philshem's answer sent me looking for the data source, which luckily is linked in the image attribution. Renewables and emissions reports on CAISO's market operations site includes a *.txt file with hourly generation data by day for all renewable energy sources in the state, going back to 4/20/2010.As mentioned, the hourly historical demand data can be found on CAISO's OASIS tool (under ""System Demand"" > ""CAISO Demand Forecast"" and filtering for ""Market/Process"" > ""ACTUAL"").Using these two data sources I was able to recreate the duck curve showing actual data for 2012 through 2019:The interesting thing to note from this chart is that while the ""belly"" of the duck has been getting fatter as predicted, the ""head"" is not getting higher -- net load in the late evenings has been trending down over the last three years."
Index of percentage of the population working from home or independently by county,"
I would like to know which counties have the higher percentage of people working from home, or self-employed with a decent income. I wonder where I could find a decent chart with rankings corresponding to these
",['data-request'],
"Utility network spatial data of any kind, anywhere","
I am looking to find as many sources for utility network datasets as possible. Most preferable would be some that are at the city/town scale. This could be anything from water to electricty to gas to fibre optic to sewer to anything. It can be from any city or town anywhere in the world, as long as it has information in individual features and preferably forms an actual connected linear network.
The reason I am looking for this is to find potential samples for use in the Utility Network ADE, a data format which is supposed to be able to handle any and all utility networks.
A good example of the kind of data I am looking for is the various networks provided by Nanaimo, Canada:

Water network
Stormwater network
Sanitary sewer network

Any data format is acceptable as long as it has a spatial component (.shp, .kmz, geojson, sqlite, geopackage, whatever)
","['geospatial', 'network-structure']",
"Is there a database of medical clinics, hospitals, etc. and when and where they were established?","
I'm looking for data on every type of medical clinic, including hospitals, urgent care clinics, doctors' offices, etc. There are several other questions that are similar, e.g. this one and this one, but those deal with Europe. Furthermore, although data sources like Google Maps and Open Street Maps will include the location/coordinates, they don't include information on when the clinic/hospital was established. These dates are essential for my analysis.
","['data-request', 'medical', 'business']",
"Dataset with a few thousands unique faces, with minimal variation in pose, lighting, background","
I need a dataset for face generation using autoencoders/GAN's.
The problem with datasets (such as the FFHQ, CelebA, etc) which use cropped and aligned in the wild face images is that these have significant variation in features such as expression, direction in which the face is pointing, framing, lighting, background, accessories on the face, etc. 
These features are not relevant to facial generation (atleast the way in which I want my model to be trained). What I'm looking for is something similar to the approach used in this video. The author uses his high school's yearbook in which there is little variation in the irrelevent features I mentioned before as everyone looks at the camera, in front of a neutral background, with the same pose.
However, I can't access the author's yearbook (for obvious reasons) and I would suspect the number of images would be too little anyway.
I am looking for a few thousand images, with non face-related features controlled. I suspect no dataset satisfying all these conditions would exist, but I'm hoping I can find the next best thing. The closest dataset I found for my application was the US Adult faces dataset, which has about 10,000 unique images of individuals, with an oval cut-out blocking most of the background.
",['faces'],
"Breast cancer data using Fine Needle Aspiration test or ""FNA”","
I am a statistical modeller. I am looking for a breast cancer dataset with these features:

age
sex 
shape and texture of the cells.

I need the number of observations to be between 200 to 2000.
",['data-request'],One clean and ready dataset is from UCI Machine Learning Repositoryhttps://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29Unfortunately it doesn't have age and sex.Another source of the same data is Kagglehttps://www.kaggle.com/uciml/breast-cancer-wisconsin-datayou may want to ask on that dataset's discussion page about getting similar data with patient age/sexhttps://www.kaggle.com/uciml/breast-cancer-wisconsin-data/discussion
"How to filter drugs by date , ex : marketing start date , or , listing_expiration_date","
I am using the REST API Endpoint 
 https://api.fda.gov/drug/ndc.json?search=finished:true&limit=1
how to i  filter the drugs based on the created date or marketing start date etc..
",['openfda'],You can do so by adding necessary filter conditions to the search query parameter just as you're doing it with finished:true. Please consult this page for a detailed description of the query syntax.
Sewer and Water GIS Data,"
Is there such thing as a national or statewide GIS data set for existing sewer and water lines?
","['geospatial', 'usa', 'real-estate']",
Meaning & Availability of HSI indicator,"
Hello [collegescorecard] folk. I'm writing to see if I can get a closer - deeper look at the hsi indicator variable.
Two questions:
1) I'm seeing that it is available for 2005, only? I might be looking at that incorrectly. Am I right/wrong/other on the availability of that indicator over time?
2) In other data sources I understand that hsi indicators sometimes indicate that the institution is eligible for the formal HSI designation... not that it has received the HSI designation. So, the HSI indicator here in [collegescorecard], is it an indicator of eligibility? Or, is it an indicator of having received the designation?
",['collegescorecard'],
Seeking US PLSS GIS data: Township Range Section,"
Question:
I have struggled to find a good/verifiable source for high quality PLSS data (USA Public Land Survey System). BLM publishes a national PLSS dataset, but in my experience working with it, that dataset is very rough and poor quality. I have found this very useful document listing much better State-based PLSS GIS datasets, of varying flavors and quality, does anyone know if there is a national standard for integrating these state files, or making them into a better national dataset?
Brief overview of why this data is important:
The PLSS system is national survey grid created by USA General Land Office (now Bureau of Land Management), that created initial property boundaries for much of the interior continental USA. Many land conveyance records still reference this system, but do not provide GPS coordinates, which is why it is important to have a good GIS dataset for modern land title research. Each State has its own baseline, which means that different US States have slightly different origin points (vertical datums). Since the different States used different origin points, it would make sense to have a national standard around developing this data so that the different State authored files line up.
Sidenote:
I have previously asked a similar question on the GIS Stack Exchange, but that was focused on finding data, whereas this question is more in regards to the metadata integration of those State files
","['geospatial', 'government']","The FGDC Cadastral Subcommittee, which coordinates US national cadastral and land records information, has these resources on their website:Cadastral Data Standards and Guidelines Cadastral Data Standards and Guidelines: Cadastral MetadataCadastral Publication Metadata Guidelines (Direct link to download a PDF)"
How to get all generic names in the API (drug label),"
I want list of all generic names in the api.fda. I have this end point query giving me first 1000 generic names. 
https://api.fda.gov/drug/label.json?count=openfda.brand_name.exact&limit=1000
Thats only 1000. How do I page through all of it. Can anyone please help?
","['data-request', 'api', 'openfda']",
Face dataset for predicting past and future face,"
I would like to develop a program that will output past and future face images, if a face image is supplied as input. That is, when I supply an image, the system should:

Recognize the face in it.
Calculate the approximate age from the input face image.
Output two face images, one with 10 year (just saying) younger from the current age and the other 10 year older.

To train my machine learning program I need a face dataset having multiple face images of people sorted according to age. 

Region - covers the whole globe.
License - licenses that will allow experimental development, testing.
Format - Files should be in image format (any format is acceptable), with the age of the person in filename. (Any other data format satisfying this criteria is accepeted).
Authority - Any authority is fine.

","['data-request', 'machine-learning', 'images', 'faces', 'ai']",
Seeking a recommendation for an elevation or altitude site,"
What is a good website to find an elevation or altitude ?
Must be able to upload my kml/kmz to the site for review .
Must have Latitude, Longitude and elevation or altitude 
I have personally used Google Earth Pro. 
","['data-request', 'geospatial']",
Seeking images of oil-level meters,"
I want to do some research on meter numerical identification. Where can I find information about the meters similar to the one shown below?

Where I can find other images of meters similar to the image above?
","['data-request', 'images']",
List of top 10k websites and their favicons,"
I'm looking for a database, CSV files of top websites with favicons, and possibly additional data (Subdomains, etc.)
I found this, but it only includes a list of domains: 
https://github.com/opendns/public-domain-lists/blob/master/opendns-top-domains.txt
",['data-request'],"I just discovered another way to get favicons. Google keeps them cached, and you can access like this for each of your domains:where your script would need to loop over domain=$variableupdate: here's a python script to download all the favicons. They come as 16x16 png files. You'll need a folder 'images/' where you run this code. And you'll need to ""bring-your-own"" CSV file of domains.gist link"
Data for Monte-Carlo simulation of evolution used in an article,"
An open access article in BMC Bioinformatics entitled ""PhyloSim - Monte Carlo simulation of sequence evolution in the R statistical computing environment"" (DOI: 10.1186/1471-2105-12-104) refers to the results of a Monte-Carlo simulation. Can anybody help find the data from the article?
","['data-request', 'biology']",
Open GIS data for SE Asia - Political and Administrative Polygons,"
I am looking for city and neighboorhood level (and other administrative divisions) data for as many countries in SE Asia as possible. It must be free to access and use. Trusted/official data is preferred (i.e. local, municipal, national governments, universities).
Specific countries and the administrative levels include:
Cambodia: (Section (ខណ្ឌ khan), Quarter (សង្កាត់ sangkat), Commune(ឃុំ khum), Municipality (ក្រុង krong), Village (ភូមិ phum).      
Indonesia: City (Kota), Distrik (district), Desa (villages, Kelurahan (urban communities), Rukun Tetangga (neighborhoods) and Rukun Warga (???).
Malaysia: District (Malay: Daerah; Jajahan in Kelantan and Bahagian in Sabah and Sarawak), Muhkim.  
Taiwan: Neighborhoods within villages, towns and cities.
Vietnam: Ward, (Phường), District-level town/Town (Thị xã), Ward (Phường) Commune (Xã), Commune-level town/Township (Thị trấn)
I have grabbed what I can from Open Street Map, Geonames, and http://www.diva-gis.org/ but I'm looking for what is listed above. 
I have taken suggestions Stack Exchange questions (http://freegisdata.rtwilson.com/) I have also looked at https://opendatainception.io/ (awesome website, check it out).  
I am looking for vector data only (polygons, points, lines). Thoughts? Ideas?
","['geospatial', 'government', 'asia']",
SIC Extension by Dun & Bradstreet?,"
Dun & Bradstreet (DnB) company data uses US SIC for company classification (although that's obsoleted by NAICS). SIC is available in many places, even as RDF.
However, D&B have also elaborated a SIC extension (adding 4 digits to the original 4). Does anyone know if it's available somewhere? Given it's only nomenclature data I hope it won't need a commercial license, but I've heard DnB even license the use of the DUNS number...

Thanks for the Padukah dataset! However, I can't figure out what coding system it uses. Eg Row 14 has these codes:

75204 Pet Washing & Grooming
29103 Reptiles
599930    Pet Shops

Can you relate it to either:

SIC: https://en.wikipedia.org/wiki/Standard_Industrial_Classification#List_of_codes
NAICS:
https://www.census.gov/cgi-bin/sssd/naics/naicsrch?chart=2017

","['companies', 'classification', 'industry']",
How to identify general terms using LOD?,"
I want to identify general medical terms such as human, patient, hospitals, drugs using LOD (e.g., wikipedia, dbpedia, wikidata etc.). In other words I am referring to medical terms that are less granular as general terms. 
This give a clue that these terms should reside somewhere in the top of LOD's category hierarchy (more closer to medicine category). However, I was unable to find a way of doing it using SPARQL (https://stackoverflow.com/questions/55083424/how-to-get-the-number-of-hops-to-a-category-in-sparqlwrapper-in-dbpedia?noredirect=1#comment96917150_55083424)
Therefore, I thought that it would be great to get expert recoemmendations about the ways I can identify general terms using LOD?
I am happy to provide more details/examples if needed.
","['uses-of-open-data', 'research', 'linked-data', 'rdf', 'ontology']",
Flixster dataset,"
Where can I find the Flixster dataset referenced by most social recommender system papers? Most of the papers reference this now-dead link ... http://www.cs.sfu.ca/~sja25/personal/datasets/ . Does anyone know where the data can now be located?
",['data-request'],
Datasets for daily maximum and mimimum temperature of a specific geographic area?,"
I am looking to perform some modeling for agricultural research that would provide an insight into the daily maximum and minimum temperature of a specified growing region. 
The question becomes: what datasets or products would I use to to model this? 
I have looked into satellite imagery (specifically MODIS and LANDSAT), however I have run into issues with cloud cover or the frequency in which data is collected by the various satellite products (3-4 times a month with LANDSAT, daily with MODIS but without any meaningful way to remove cloud cover) 
I am looking to strike the adequate balance between high-resolution and frequent, reliable data to then convert into something I can overlay in google earth engine. 
So now I am looking to NOAA products, more specifically the National Digital Forecast Database. Are there any other products that offer higher-resolution? How frequent is the data set collected? 
I am also having trouble trying to figure out what the WMO headings mean for this product tool. Again, I am looking for daily maximum and minimum temps for a specific region. 
Any help or suggestions is much appreciated. 
","['data-request', 'uses-of-open-data', 'weather', 'noaa']",
Locating detailed average global rainfall and temperature data for use in QGIS,"
I'm looking for average/yearly global rainfall and average/yearly temperature data that can be synced up to terrain and elevation maps I currently have in QGIS. High accuracy is not crucial (any year, or even multi-year would be fine), but I want something a little better than the tiny maps I've found online. QGIS seems to like tif files but I've been unable to locate any with rainfall or temp. 
I actually need these for a non-GIS related project (not scientific either), but it seems like I can use QGIS to ensure the maps are overlaid accurately, and to convert to greyscale values. (So if there are any large enough png or even jpg images which could be converted to greyscale, that would work too.)
Attached is an example (with elevation data) of what I want for the final product, scaled down drastically. The actual size is a 22,000 by 8,000 png with a transparent background (black would work too). 
Edit - I'd also be willing to try and generate something using just numeric data, if it's available anywhere...

","['data-request', 'weather']",
Can government datasets be posted on the Internet for readers of a computer book?,"
I am teaching an analytics course, writing a book on R, a free statistical package. The book will show how to use R while analyzing government datasets at the Data.gov site. 
I would like to rest assured that book readers get the dataset.
I am thinking to ask readers to download specific datasets from the site. In case the datasets disappear from the site, I would like to make them available in some other ways like posting them on the Internet.
I believe I can use government datasets in my book. But I am not sure whether I can post the datasets on the Internet. I would also appreciate it if you inform me of a better way, if there is, than posting them.
",['open-access'],
How do I find out if a government building is owned by the government or leased? [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 4 years ago.







                        Improve this question
                    



I am trying to find out if the US Department of Veteran Affairs Austin Outpatient Clinic is leased by the government or owned outright. Where do I find this information?
",['data.gov'],
Where can I find historical rainfall and temperature data for individual weather stations in the US?,"
I'm reading a journal paper that uses historical rainfall and temperature data for the United States, starting in 1900. The paper says

The [National Weather Service Cooperative] COOP Network consists of more than 20,000 sites across the United States and has monthly precipitation observations for the past 100 years

Are these data publicly available? I'm looking for these historical rainfall and temperature data, for every individual station, in a machine-readable format that I can use to map stations and their corresponding data to US counties.
I am not looking for forecasts, and it's not clear to me which sources of weather data actually have data going back this far. The NOAA pages usually list data starting in 1981.

The paper is

Ramcharan, Rodney. ""Inequality and redistribution: evidence from US counties and states, 1890–1930."" The Review of Economics and Statistics 92, no. 4 (2010): 729-744.

Unfortunately, the private data provider that compiled these data (Weather Source) no longer offers them. They told me this directly when I contacted them.
","['weather', 'historical']","Containing  observations  of  one  or  more of  the  above  elements  at  more than  100,000  stations  that  are  distributed  across  all  continents,  the dataset is  the  world's  largest  collection  of daily  climatological  data. [...] Station  records,  some  of  which extend  back  to  the  19th  century,  are  updated  daily  where  possible  and  are  usually  available  one  to  two days  after  the  date  and  time of  the  observation. NOAA: GHCN (Global Historical Climatology  Network)-DailyThis is from the documentation of the Daily Summaries. They provide access via FTP to all available stations and their data that exist. I checked a few stations and found some data going back to e.g. 1964 etc."
Is there an API to get the legality of alcohol (or legal drinking age) by geo location?,"
I need to make sure alcohol isn't advertised to underage users or in countries / regions where alcohol is illegal.
Ideally using MaxMind geo codes but I'm sure I could map from any geo system.
","['geospatial', 'api', 'legal']","One option is to use a Github repo (fork your own) that other users can contribute to, which will help keep it up to date. https://github.com/aihpos/drinkingage/blob/master/drinking.csvAlthough for regulatory purposes, this may not be sufficient. Also, this is a really nuanced topic, so may be tough to capture with 100% coverage.For example, Switzerland:18 for spirits 16 or 18 for beer and wine depending on the CantonAny csv can be turned into a json API, although this example is a bit overkill."
Internet speed in the united states,"
I am trying to find geolocated internet speed data. What data sources are available? 
I've found: 

FCC data: problematic because it's provided by ISPs.
Measurement Lab: Open source testing by measurement lab but there's some concern about accuracy. 

Ultimately, I'd like to use the data to create some metrics on internet speed by geography (city, state, county, zipcode). 
","['data-request', 'internet']",
Historic weather data - With clouds resolution,"
I'm looking for a dataset that holds hourly/daily cloud coverage rates at different heights.
I need the data to a geo reference too, preferably United States data.
Any thoughts?
","['data-request', 'geospatial', 'weather']",
non functional requirements dataset,"
I am developing a machine learning project which analyzes requirement specification and categorizes the non-functional requirements into categories like database, web socket, backend technology, etc. I'm planning to use topic modeling and LDA to categorize into these categorizes but I wasn't able to find a proper dataset for this. If someone can help me out, I would highly appreciate this. Training data set for Software Quality Requirements (Non-Functional Requirements). 
","['nlp', 'classification']",
Subsea Pipeline Data for the North Sea,"
I have been looking for a vector file containing sub sea pipeline data in the North Sea, without much success. Any hints? (I have to be clear, pipelines only -no cables-)
","['data-request', 'geospatial']",
Funding resources for GIS Open Data creation?,"
The gist:
I have been doing some historical map research for a recent project, which led me to discover a very cool folio of high-quality surveyor maps of the Mississippi River from the 1880s. Research and conversations with a couple map librarians at New York Public Library and LSU about the maps, leads to conclude that a WMS/Open Data compliant, georeferenced dataset has not yet been created for this extensive folio of archival cartographic work.
Core question
For the project, I have successfully georeferenced a couple of the map-images. I think it would be awesome to georeference the full-set, however this is far outside the scope of my project. There are over 160 images to digitize & georeference, and I was wondering if anyone can think of any good non-profit, academic or grant funding for creating GIS open data layers?
","['geospatial', 'images', 'openstreetmap']","Check out Old Maps Online: https://www.oldmapsonline.org/. They have an interactive map of the world, which you can use to locate georeferenced historic maps.They have many more old maps that are waiting to be georeferenced. Anyone can volunteer to help georeference them. An organization can bulk-upload un-geoereferenced maps to their collection.Once a map is uploaded and georeferenced, anyone can view it for free without needing to register. The privacy policy is here.If you went this route, the maps could (eventually) be georeferenced by volunteers, so you would only need funding to pay for the time you spend digitizing and uploading them. I'm not sure how long it would take if you left it to happen organically, but it might be pretty easy to recruit some student volunteers, eg from local universities.Another source of information that you might not have thought of, would be the Upper and Lower Mississippi River Conservation Committees (UMRCC and LMRCC, respectively). Historical maps are a bit outside their core objectives (see below), but they might know about some funding opportunities.Promote preservation & wise utilization of natural & recreational resources of the Upper Mississippi River. Formulate policies, plans, & programs for carrying on cooperative surveys and studies. Provide recommendations to governing State bodies in support of the objectives of the UMRCC.-The LMRCC ... provides the only regional forum dedicated to conserving the natural resources of the Mississippi’s floodplain and focuses on habitat restoration, long-term conservation planning and nature-based economic development."
"Is it possible to link drugs, with protein targets, using OpenFDA?","
I have a set of protein targets. The absolute ideal return for these targets for me, would be a .tsv file that looks like this:
target_name    fda_approved_drug
target1        drug1
target2        -
target3        drug2
target3        drug1

I was trying to link drug to target proteins with openFDA. I found the instructions to use OpenFDA here, but I can't work out if this is possible using this API?
I want to add in code to show an example what I was thinking, but I can't find it so my idea would be something like this: I have a list of UniProt IDs (I can convert if necessary), and then if I could write something like:
for i in list_of_targets; do: fda_api --target_protein i --drugs ;done >> list_of_drugs_and_targets

Is this possible? As a side note, I primarily code in python, I'm wondering if there's a pythonic way of doing this?
","['api', 'openfda', 'python']",
Autonomous vehicle prices versus year,"
I would like to know where I can find a graph of the estimated price of fully autonomous driverless vehicles versus the year in which the vehicle is sold.
Does anyone know where I can find this data?
",['data-request'],
Employment rate among people taking antipsychotics by country,"
Is there any data on the employment rate among people taking antipsychotics by country?
Given the debilitating effects of these drugs, I would expect them to be close to zero almost everywhere.
Not to mention that most of these people will be confined to bloody mental hospitals.
","['data-request', 'medical', 'demographics']",
Separate Continent Shapefiles,"
I am looking for polygon shapefiles of 7 continents available separately (Africa, South America,North America,Asia,Australia,Antarctica,Greenland). I have got single polygon shapefile for all the continent which I am not interested in.
Hope someone can share the sites where I can get these. 
",['geospatial'],you can find them here and download them as a shapefile (or other format) in the Export tab.Hope this helps
Eurostat metadata via API,"
Eurostat, the agency managing statistics related to the European Union, has an API for accessing its statistics. The data is accessed in different forms e.g. the actual dataset/observations and data structures (the available filters for a dataset). Whilst I have been able to access these via a JSON/XML REST API, I am led to believe that you can also access metadata about a statistic, meaning descriptive information such as metric description, collection method etc. Here is an example of this type of information that Eurostat provides on the web:
https://ec.europa.eu/eurostat/cache/metadata/en/gov_10dd_sgd_esms.htm
The question is whether there is a REST (either XML or JSON) API to access this metadata information. And if so what is the query syntax?
I have spent the last weeks reading any guides available by Eurostat and also from SDMX, the standard used by Eurostat to collect and store the data but I can't figure out how to access the metadata.
","['data-request', 'api', 'europe', 'rest']",
openFDA: Is there any way to match NDC data in different format?,"
I'd like to know whether or not there is a possible way to match NDC codes in different formats by using openFDA API like Recall Enforcement Reports. For example,  matching 0187-0798-30 with 0187-079-830 but without the hyphen, it is the same number.
","['api', 'data.gov', 'openfda', 'data-format']",
What is the status of VAERS?,"
What is the status of the US government Vaccine Averse Event Reporting System (VAERS)?
Is there also a JSON file containing links to all downloadable files for automating the download of the data?
",['openfda'],
Estonian named entity recognition data,"
I'm looking for estonian named entity recognition data. Till now I am unable to find one. Although Estonia has 90% of it's Govt services online, I can't find their NER data anywhere. I tried estnltk, but that library has a C++ code compatibility issue which is to be solved in future releases, and I can't use any command from the library.
","['nlp', 'language']",
Where can I find lists of predator-prey relationships?,"
There are many web sites that define predator-prey relationships and give a small number of examples.  I also saw this post Where can I find biological time series data? but that seems to be more focused on the number of predators vs the number of prey as a time-series. I just want the relations like 
pelicans eat trout; 
trout eat mullet
eagles eat rattlesnakes
rattlesnakes eat mice
mice eat beetles

But I would like this for a large number of animals.  Does anyone know of a long list?
","['data-request', 'biology']",
Expand Wikidata SPARQL query to self-join,"
I have this query to get the population of cities and the country they belong to:
SELECT ?city (?population as ?city_pop) ?country ?countryLabel ?continent ?continentLabel ?cityLabel
WHERE {
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""[AUTO_LANGUAGE],en"". }
  ?city wdt:P31 wd:Q515.
  OPTIONAL { ?city wdt:P1082 ?population. }
  OPTIONAL { ?city wdt:P17 ?country. }
  OPTIONAL { ?city wdt:P30 ?continent. }
}
LIMIT 10

But how can I expand this query to also return the population of the entire country?
I've added this statement to the query
OPTIONAL { ?country wdt:P17 ?population. }

but then I get timeouts.
Bonus: I think getting the continent name for ""country"" instead of ""city"" would be more reliable, too.

Actually, my final query will be to return the most-populated city in each country, with the following structure:
city_name, city_population, country_name, country_population, continent_name

Here's a query from the tutorial that gives the max populated city in a country, but similar issues expanding to get the entire country's population in the same row
SELECT ?country (MAX(?population) AS ?maxPopulation)
WHERE
{
  ?city wdt:P31/wdt:P279* wd:Q515;
        wdt:P17 ?country;
        wdt:P1082 ?population.
}
GROUP BY ?country


For the record, I've tried the downloads at Geonames but I find some inconsitencies: for example, ""city"" population of Singapore varies from ""country"" population of Singapore when there is only one city in Singapore (from two files, perhaps from two sources).
","['wikidata', 'sparql']","This query was answered on Wikidata's great ""Request a query""https://www.wikidata.org/wiki/Wikidata:Request_a_query/Archive/2019/02#Largest_worldwide_cities_per_country_-_final_tweaks_on_an_aggregate_querysolution onesolution two"
How to get the birds daily observations data from different stations of any region,"
I searched many websites and I cannot get the correct solution. If anyone have the answer, can share with me.
","['data-request', 'geospatial', 'time-series']",
How to output only English labels in SPARQL query?,"
I don't understand why this SPARQL queries produce duplicates:
SELECT DISTINCT ?WikidataItem ?itemLabel
WHERE {  
  ?WikidataItem rdfs:label ?itemLabel. 
  ?WikidataItem ?label ""Mozilla Firefox""@en.  
}
LIMIT 5

Try it here.
Is it producing a row of output in every language? How can I change my query in order for it to produce only the single result in English?
Update
I'm still confused about how to solve my problem, since I perhaps oversimplified my example. I actually am using FILTER(CONTAINS(LCASE(?itemLabel), ""firefox""@en)) among other things to limit my query. How do I output only the English language label for each entry?
","['wikidata', 'sparql']",
Distribution of number of people having money M in their bank account [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 4 years ago.







                        Improve this question
                    



Not sure whether to post this here or have my post migrated to personal finance and money SE, please recommend.
I would like to know, where I can find, for each country, the graph of the following data distribution:
On the x-axis, money amount, in thousands dollars or other currency.
On the y-axis, for graphs (a), (b), and (c), number of people, having, for the given year, on average, (a) that amount of money in their bank accounts, (b) that amount of money invested in financial instruments, and (c) that amount of money in property such as real estate or car assets.
This would allow you to assess in full detail your financial situation relative to that of others.
Thanks.
","['data-request', 'tool-request']",
Acces to Sugar & Sweeteners USDA reports,"
I work with investments related to commodities and I would like to have access to the following report:
""LMC International: Sugar and Sweeteners Market Report""
Could you help me to get access to that?
",['data.gov'],
Web application functional requirements dataset,"
I am developing a machine learning project which analyzes requirement specification and categorizes the functional requirements into categories like database, web socket, backend technology, etc. I'm planning to use topic modeling and LDA to categorize into these categorizes but I wasn't able to find a proper dataset for this. If someone can help me out, I would highly appreciate this.
for an example 
data should be stored in a secured and scalable store ==> database
a large number of user requests should be handled ==> backend 
or

database

data should be stored in a secured and scalable store
search should be fast

front end

easier technology solution to maintain the user interface
","['data-request', 'machine-learning']",
Frequency of professions in cities data,"
I would like to know, is there any database out there, that will list, given a country and city, a list of professions followed by number of people working in that profession, to any degree of detail. So you could see the whole distribution of employment into particular jobs for any given city.
If so, this could help get an idea of what people did in each city, and perhaps also help decide where you wanted to go live when relocating.
Would be nice to be able to have this data also for suburbs of cities.
Thanks.
","['data-request', 'database', 'data-portal', 'big-data']",
Image Dataset on Corrosion of Metals,"
I need an Image Data set on Corroded Metals due to rust. I was searching for it but am unable to find one. Is there any open Dataset of Corroded Metal Images 
","['data-request', 'images']",
Does anyone have an open data source on opinions about the replication (reproducibility) crisis in science?,"
I asked a question on the Academia Stack Exchange about surveys of scientists asking their opinions on the replication crisis (also called the reproducibility crisis). It was suggested to me there that asking the question here might find something. So here goes!
I am specifically looking for survey data covering the replication or reproducibility crisis as it appears in various fields of science. I am aware of the general survey of scientists published in Nature.
What I am looking for are any additional surveys for other specific fields/areas of scientific research. While I have found other types of studies, those do not give me the opinions of the working scientists themselves. Opinions are what I am looking for right now.
I am particularly interested in a survey covering the field of psychology. This field has produced a lot of work related to this topic: articles on research methodologies, questionable research practices, statistical issues, and so on, but little that I can find on the opinion of the psychological researchers themselves.
Are there any surveys?
",['survey'],
Help in downloading dataset from Microsoft Research Open Data,"
I want to download the Microsoft Speech Corpus (Indian languages) dataset from https://msropendata.com/datasets/7230b4b1-912d-400e-be58-f84e0512985e
If I follow the instructions they tell me to use AzCopy (or Azure Storage Explorer), but when I use the URL that is generated, an error is shown. I tried to shorten it to https://msrodrdataset001.blob.core.windows.net/microsoftspeechcorpusindianlanguages and it shows that the location is empty , can someone guide me a little on how to download this dataset. 
I don't want to deploy to Azure.
Edit
My URL links https://msrodrdataset001.blob.core.windows.net/microsoftspeechcorpusindianlanguages?sv=#####&sr=c&sig=#####&st=####&se=####&sp=rl
I Hope my format is good enough as I don't really know if any of those values are actually security keys except the sig , and that my description is good enough.
When I use this for AzCopy with Source and Dest, 
the error is
[2019-02-18 20:25:01][ERROR] The syntax of the command is incorrect. Invalid SAS token in parameter ""Source"". The syntax of the command is incorrect. Invalid SAS token in parameter ""Source"".
'sr' is not recognized as an internal or external command,
operable program or batch file.
'sig' is not recognized as an internal or external command,
operable program or batch file.
'st' is not recognized as an internal or external command,
operable program or batch file.
'se' is not recognized as an internal or external command,
operable program or batch file.
'sp' is not recognized as an internal or external command,
operable program or batch file.

When I take out the extra parameters
[2019-02-18 20:26:25][ERROR] Error parsing source location ""https://msrodrdataset001.blob.core.windows.net/microsoftspeechcorpusindianlanguages"": Source with location type Blob doesn't exist. For more details, please type ""AzCopy /?:Source"" or use verbose option /V.

I emailed Microsoft but they haven't replied yet, and was hoping someone here would be experienced with working with Microsoft Research
","['data-request', 'download']",
Dataset of lines at n miles from the coast,"
I'm using Folium to generate some interactive maps with ocean data. One of the restrictions I am facing is that the objects, I plot has to be at-least at 5, 6, .., n miles from the coast, hence I am looking for points or lines that meet the criteria.
Where can I find such a data? 
","['data-request', 'geospatial', 'python', 'oceanographic']",
Service returned HTTP Response Code (College ScoreCard),"
I am using the url below to query in a Java Program:
https://api.data.gov/ed/collegescorecard/v1/schools.json?school.degrees_awarded.predominant=2,3&_fields=id,school.name=boston%20college,2017.student.size,2017.school.degree_urbanization,2017.admissions.admission_rate.overall,2017.admissions.sat_scores.average.overall&api_key=*****

However, I keep getting the error:
Server returned HTTP response code: 400 for URL
Not sure if anyone could help.
",['collegescorecard'],
How can I find a large dataset of medical images for cancer classification?,"
I am looking for a large image dataset >20K images to be used for cancer classification algorithm.
Where can I look given that all publicly available datasets are maximum 1K in size which is much less than what I need?
Image resolution does not matter as well as body part as long as all the images are of same resolution and body part.
Images should have benign/malignant labels as ground truth. 
Dataset should be half malignant and other half benign or close match. 
","['data-request', 'medical']",
Can I publish analysis of semi open data,"
If data is open for personal non commercial use, can I analyse that data and blog about it?
I'm part of a community that uses Zend as its paltform. The API is open so I can read all the community posts, and the site TOS allows personal use of that data. I'm planning to analyse the community posts and blog about my findings - ie what subjects are important, how many posts over time that kind of thing. 
There's nothing in the TOS which precludes this, but there is a lot of restrictions around not republishing the content. My plan isn't to republish the content, only my derived analysis from that content.
",['legal'],
Where to find 3D building footprint covering all USA?,"
Does anyone know where I can find a complete vectorial database of the 3D building footprints (x, y, z, or building height) of the USA? At a cost or free.
","['geospatial', 'usa', 'buildings']",
French/English word database for a hangman game,"
I'm currently developing a Hangman game in English for a French website that teaches English. I'm looking for a database containing a set of English words, preferably common nouns or verbs of more than 5 letters, and ideally their French translation. TIA
","['data-request', 'education', 'english', 'french']",
How to connect to States from the shape file?,"
I have a spatial file of the congressional districts of the US, however, the states are numbered in an unknown form. I have searched through all the other files but have found no key or description of the numbering of the states. Am I missing something?
Here is the link where I downloaded the files.enter link description here
",['geospatial'],
Dataset of diesel consumption by US state and year,"
Need a dataset, for diesel consumption by US state and by year, going back to 1990 if possible. 
","['data-request', 'usa', 'transportation']",
Cigarette smoking rates at city level,"
I'm looking for international cigarette (or tobacco) smoking rates at the city level. So far I've only seen international rates at the country level. Great would be global rates at the city/regional level, but first choice would be South America, and if at the country level: Peru or Colombia. Second choice would be Pakistan or India.
","['data-request', 'medical', 'demographics', 'south-america']","If I move away from the first choice countries, Peru or Colombia, my next choice would be India or Pakistan. For India, I did find a WHO report (PDF) that has smoking rates of states, from 2016-2017.AND, if I truncate the web address, I find a list of available countries:https://www.who.int/tobacco/surveillance/survey/gats/(but no Colombia or Peru)"
"Ontology for QoS, i.e. download/upload speed, throughput","
There are lots of papers, but don't publish their actual ontology, only give you figures/graphs (i.e. QoSOnt, OWL-QoS).
Is there a properly hosted ontology with an actual owl file and namespace defined? like
https://www.w3.org/2005/Incubator/ssn/ssnx/ssn#Latency
But I still need download/upload speed, throughput.
I have searched on
https://lov.linkeddata.es/dataset/lov/terms
http://schema.org
","['standards', 'rdf', 'ontology', 'computing', 'semantic-web']",
Dataset about the kinds of scientific experiments published,"
I'm looking for a dataset that has information about the categories of scientific experiments performed for a given year.
I assume this may be information contained in abstract metadata, but I'm not sure where to get this dataset either.
",['data-request'],
Newfoundland Geospatial data source,"
I am looking for a source of geospatial data for Newfoundland, Canada comparable to Land Information Ontario (LIO) in Ontario. We are in need of mapping at scales 1:20000 (metric) and larger scales and the available CanVec federal datasets are too course for our purposes (~1:50K). Ideally, I would like to obtain LiDAR or equivalent topography as well as ortho-imagery, hydrology, transportation and other basemap data.
Google search doesn't seem to reveal any useful sources: https://opendata.gov.nl.ca/ (confusing site with no extensive data catalog/download options)
https://gis.geosurv.gov.nl.ca/ (links to very basic interactive maps and links to federal data)
","['data-request', 'geospatial', 'canada', 'download']",
How many visitors from a specific country visit a specific destination?,"
In my case I want to know how many people from Argentina visit Orlando.
I found several sources (UN DATA,UNWTO) that distribute information which specify the country of origin and country of destination. But I need city-level granularity for the destination location.
",['travel'],
Datasets for autonomous driving contains labels for classification,"
I'm looking for Datasets for Autonomous Driving that contains labels for classification. Specifically, I'm looking for Dataset that has labels indicating if there is pedestrians in the image or not.
I want to create classifier which can identify if the image contains pedestrians (some people).
Anyone familiar with such dataset?
","['data-request', 'classification']","Berkeley DeepDrive currently hosts the world's largest self-driving dataset, with 100,000 video sequences.However, you should bear in mind that if you wish to download all of the data (including the videos), then the total file size will be over 1000 GB. If you are just looking to download the Info part of the dataset, then that will be just under 4 GB."
DDL - Socrata - Grant of Rights,"
The terms of use of Socrata “grant of rights” clause caught my attention as it gives Socrata and its affiliates unlimited rights over what users submit to the DB:

A.    Grant of Rights. During the term of this agreement, User grants
  Socrata and its affiliates a nonexclusive, royalty-free, perpetual,
  irrevocable, fully sublicensable, right to use, reproduce, modify,
  adapt, publish, translate, create derivative works from, distribute,
  analyze, perform and display User Content in connection with the
  Service and to provide service to its users. User understands that
  once User Content is provided, Socrata and content users have a
  limited ability to control or delete such content.

It is our understanding of 2CFR200.315 that federal government has the right to obtain, reproduce, publish, or otherwise use the data produced under a Federal award and authorize others to receive, reproduce, publish or otherwise use such data for Federal purposes. However, the Socrata language requests federal award recipients to grant all the above-stated rights under section A. of the Terms of Use to Socrata and it's affiliated. 
Could you please explain how USAID is managing the flow down datasets to Socrata affiliates and if there are any protections against modifying datasets by 3rd parties?
","['usaidopen', 'socrata']",
Extracting data from PDF tables with multi-line rows: tabula,"
I am trying to convert large tables in PDF form to CSVs. I was wondering if there are recommendations for how to extract tables in which rows span multiple lines as in the tabula example here? My own data are somewhat simpler in that there are no subheaders, but the same issue arises - rows spanning multiple lines. Thank you in advance for your suggestions! This is what I've tried on the example given above:
library(""tabulizer"")

# specify filename
file <- '~/Desktop/atipp_coordinators_govt_agencies.pdf'

# read file
out1 <- extract_tables(file, output = ""data.frame"",
method = 'lattice', pages=2)

Unfortunately, the multi-line row is read into separate rows.
","['conversion', 'pdf']",
Where can I find land utilisation data,"
I need to find a database describing the land use for a given latitude and longitude. Examples of land use types: farming lands, urban areas etc.
","['geospatial', 'land']",
Crime data @ Zip code level?,"
I mainly need property-type crimes but all crimes will work. I'm mainly looking for downloadable crime data that is at the ZIP5 level if possible. The more granular the better. The next best would be county I think.
However, I am looking for a dataset that applies to the entire US. There seem to be crime stats for specific cities but that won't really work for my use case.
","['data-request', 'uses-of-open-data', 'demographics', 'postal-code', 'crime']",
Data Set with more than 800 obs and more than 20 features to compare MLmodels accuracy,"
I'm looking for a data set (ideally a csv file) that contains more than 800 obs and more than 20 variables statistically significant to compare nearest neighboors, linear/logistic models, penalised linear/logistic models, trees, random forest models results such as quadratic error, misclassification error, ROC curves, AUC…
I took a look on kaggle's dataset best rated but I always have an issue (not enough variables, not enough variables statistically significant, not enough observations, name of the variables not specified so visualising them or analysing them is meaningless).
Any help would be highly appreciated
","['data-request', 'machine-learning']",
Kazakhstan hydro datasets,"
I am looking for river and lake data-sets for Kazakhstan region. I have already got data from osm_geofabriks. Are there any other sites which will offer me data-sets?? The format of the data-set can be .shp or .csv.
","['data-request', 'geospatial', 'asia', 'hydrology']","Natural Earth Data has Rivers and Lake Centerlines and Lakes and Reservoirs.The USGS Earth Explorer will let you download data from anywhere in the world. Type ""Kazakhstan"" into the place search criteria box, click over to data sets and type ""hydro"" into the data set search box. The dataset called GTOPO30 HYDRO1K is a hydrology raster. There's a download that covers all of Asia (Entity ID: GT30H1KAS). There's also a data set called ""SRTM Water body data.""Update: Roshualine found that GTOPO30 HYDRO1K shapefile just had a polygon with no attributes. They ended up using a subset of the Kazakhstan region from Natural Earth."
Seeking topographical data for northern Taiwan to make sense of peak-to-peak photos in 3D?,"
I've been hiking in the mountains around the Taipei/Keelung area for years and have lots of photos of distant peaks from other peaks. I'd like to build a 3D surface mesh of the topography so I can play with it in Python and maybe Blender to make sense of it (personal use).
Are there publicly available topographical data for northern Taiwan that I could use to do this? 
Ideally in some tabular format so that I wouldn't have to install stand-alone software in order to use. A python package is no problem. I don't mind massaging or interpolating from one coordinate system to another myself, as long as it's not too complicated.
I'm looking for resolution of something of the order of 5 meters vertically an 10 horizontally, but there's no specific hard requirement.
","['data-request', 'geospatial']","update: There is an extensive list of open sources of topographical data of Earth provided in this thorough answer.This will do the trick for me, although my application is non-critical."
How to find Novartis medicines in openFDA drug labelling data,"
I am trying to look at the Novartis medicines on openFDA open data on drug labeling for a given period.
I tried this:
https://api.fda.gov/drug/label.json?search=spl_patient_package_insert:""Novartis""& spl_product_data_elements&effective_time:[20110601+TO+20181231]&limit=1

But I end up getting an error: 
{
    ""error"": {
    ""code"": ""BAD_REQUEST"",
    ""message"": ""Invalid parameter:  spl_product_data_elements""
  }
}

What am doing wrong? What is the correct field to get Novartis?
","['openfda', 'drugs']",Here is the corrected query:You need to use +AND+ instead of & and _exists_ to ensure a particular field is present in the document. More information about the syntax of openFDA queries can be found on our website.
Towards reconstructing intelligible speech from the human auditory cortex dataset,"
Recently I read in the article Towards reconstructing intelligible speech from the human auditory cortex that scientists have learned to transform brainwave into sound. 
Is it possible to find data on which the regression model they mentioned there was performed? Or any other similar data.
","['data-request', 'medical', 'research', 'biology']",
Slow moving auto parts data (public) from a US automobile company: where to find it?,"
I have found multiple papers which use this dataset (because it's apparently public) to set benchmarks in forecasting but they don't mention where it can be found. I have done some searching on my own and haven't been able to find it. Any help would be appreciated.
Some of the papers are:
Deep AR paper by Amazon
Another one by Hyndman et. al.
Another one by Amazon
","['usa', 'cars']",
Twitter dataset with 125K nodes and 2M edges,"
Where can I get Twitter dataset with 125K nodes and 2M edges that show relationships between users?
An edge from user i to user j means user j follows user i.
","['data-request', 'social-media', 'network-structure']",
Is digital Ortophoto of Hungary publicly available?,"
It's quick and easy question regarding available WMS services in Hungary. I'm searching available Ortophoto or topographic images for Hungary but without any luck.
I must say that I'm having difficulties navigating through Hungary GIS data as I'm not native Hungarian speaker but in my search I've stumbled upon Hungarian Geoportal and if I understood correctly one must pay for ortofoto and topographic images.
Are there any publicly available WMS services that includes orthophoto and/or topographic maps?
","['data-request', 'geospatial', 'uses-of-open-data']",
Historical data of languages spoken in country by percent population?,"
I am looking for a dataset that contains the languages spoken in each country  and their respective percentages of the population, going back as far back into the historical record as possible.
I know the CIA World Factbook has entries of the form Afghanistan: Languages: Dari 80%, Pashto 40%, etc.
Their archive has percentages going back as far as about 2008 and their archive in general only goes back to about 2000. Anything that has data like this for before 2000 would be great. Even if not all countries are included, e.g. just the big ones like China, US, Germany ,etc.
","['historical', 'language', 'demographics', 'population', 'longitudinal']",
How to check whether a word is abbreviated or not using Python? [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 4 years ago.







                        Improve this question
                    



How do I check whether a word is abbreviated or not in a dataframe column using Python? For instance, I need to detect the value ""U.S.A."" as an abbreviation.
Is there any dictionary present for this?
","['machine-learning', 'language', 'python']",
Seeking Commuting Zones (1990) shapefile?,"
I am hoping to have a shapefile for commuting zones (CZ) for the year 1990 to use in ArcGIS. 
Where can I obtain this data?
USDA ERS provides commuting zones and labor market areas for 1990, but it is not in the format of a shapefile. Is there data that follows similar information as their excel file in the shapefile format?
","['data-request', 'geospatial']",The Health Inequality Project has Commuting Zone Boundaries (1990 Definition) that look extremely similar to the USDA ERS LMA for 1990. LMA (Labor Market Area) were used prior to Commuting Zones in 2000.  
Source of telemetry data from games,"
I'm building model to predict behaviours of players. I'm looking for external source of telemetry data from games.
Have you any idea where can I get this kind of data from?
","['data-request', 'api', 'games']",
CKAN Hierarchy extension breaks the home page,"
I've installed CKAN from package on Ubuntu 16.04.5, following the documentation
https://docs.ckan.org/en/2.8/maintaining/installing/install-from-package.html
I've installed the scheming extension
https://github.com/ckan/ckanext-scheming
I've then tried installing the hierarchy extension
https://github.com/datagovuk/ckanext-hierarchy
Now the main page, the My Datasets Dashboard, and the My Organization Dashboard all display Internal server error.  Everything else in CKAN appears to work: creating organization, and datasets, etc.  If I disable the hierarchy extension, the error goes away.  I believe it to be cause by not correctly configuring the scheming extension to work with the hierarchy extension.
In the documentation for the hierarchy extension, it states

In order to make hierarchy works with ckanext-scheming you need to enable just hierarchy_display and then use corresponding form_snippet in your org_schema

So I have tried to do that
Plugin settings
in /etc/ckan/default/production.ini
## Plugins Settings

# Note: Add ``datastore`` to enable the CKAN DataStore
#       Add ``datapusher`` to enable DataPusher
#               Add ``resource_proxy`` to enable resorce proxying and get around the
#               same origin policy
ckan.plugins = stats text_view image_view recline_view scheming_datasets scheming_organizations hierarchy_display

# Scheming
scheming.dataset_schemas = ckanext.scheming:my_dataset.json
scheming.organization_schemas = ckanext.scheming:my_org.json
scheming.presets = ckanext.scheming:my_presets.json
scheming.dataset_fallback = false

Org Schema
I have a schema defined for organizations
in /usr/lib/ckan/default/src/ckanext-scheming/ckanext/scheming/my_org.json  
This is based on the org_with_dept_id.json example provided with the scheming extension, except I've added the following field for the hierarchy extension.  For both my org schema and dataset schema, I can see the additional fields, so the scheming extension appears to be working.  For orgs, I can see the parent org field, so the hierarchy extension appears to be working, except for the broken pages mentioned above.
{
  ""field_name"": ""not_used"",
  ""label"": ""Parent organization"",
  ""display_snippet"": null,
  ""form_snippet"": ""org_hierarchy.html"",
  ""validators"": ""ignore_missing""
}

Logs
I can't see anything useful in the logs
in /var/log/apache2/ckan_default.error.log
After a restart, and hitting the main page of the application, this is what the logs show:
[Fri Jan 25 22:36:28.606575 2019] [wsgi:error] [pid 23931:tid 139651816699648] 2019-01-25 22:36:28,606 INFO  [ckan.config.environment] Loading static files from public
[Fri Jan 25 22:36:28.661878 2019] [wsgi:error] [pid 23931:tid 139651816699648] 2019-01-25 22:36:28,661 INFO  [ckan.config.environment] Loading templates from /usr/lib/ckan/default/src/ckan/ckan/templates
[Fri Jan 25 22:36:28.883789 2019] [wsgi:error] [pid 23931:tid 139651816699648] 2019-01-25 22:36:28,883 INFO  [ckan.config.environment] Loading templates from /usr/lib/ckan/default/src/ckan/ckan/templates
[Fri Jan 25 22:36:30.789607 2019] [wsgi:error] [pid 23930:tid 139651841902336] 2019-01-25 22:36:30,789 INFO  [ckan.config.environment] Loading static files from public
[Fri Jan 25 22:36:30.841870 2019] [wsgi:error] [pid 23930:tid 139651841902336] 2019-01-25 22:36:30,841 INFO  [ckan.config.environment] Loading templates from /usr/lib/ckan/default/src/ckan/ckan/templates
[Fri Jan 25 22:36:31.055650 2019] [wsgi:error] [pid 23930:tid 139651841902336] 2019-01-25 22:36:31,055 INFO  [ckan.config.environment] Loading templates from /usr/lib/ckan/default/src/ckan/ckan/templates

Has anyone got both of these extensions to work together?  Are there other logs I should be looking at?  Did I miss something in the documentation?  I'm at a loss, please help.
",['ckan'],"The problem is that the CKAN Hierarchy Extension does not work with CKAN 2.8 and higher. It has nothing to do with the installed Scheming Extension, nor the way it was configured.The issue is detailed here:
https://github.com/datagovuk/ckanext-hierarchy/issues/25There is a pull request with a fix, but it hasn't been accepted yet:
https://github.com/datagovuk/ckanext-hierarchy/pull/26After installing a version of the extension with the pull request applied, everything works correctly."
Is there a central source for real estate shape files for across the US?,"
Is there a central source for shape files for real estate across the US.  Most counties will provide shape files via the county appraisal district.  But there are over 3,000 to request.
","['data-request', 'geospatial', 'usa']",
"Location (lat, long) of cell towers across the USA","
Does anyone know of any complete database of cell tower locations with the following information?
Lat, long of cell tower
MCC, MNC, LAC, Cell ID
Range
Signal strength

I have checked out the data from Open Cell ID, RadioCell, and Mylnikov and they seem to be incomplete. Some lat-long is randomly placed on an empty open field.
Any help is greatly appreciated.
","['data-request', 'geospatial', 'usa']",
Distribution of people diagnosed with dementia by age,"
I am looking for a chart that shows, for each age, percentage of the population of that age that has been diagnosed with dementia and given prescription drugs for dementia, as part of a histogram that shows age in the x-axis. On the y-axis, I would like the bar charts the histogram to show both the number of patients diagnosed with dementia for the first time duty that year, as well as number of patients having dementia during that year or any of the previous years.
Thanks.
","['data-request', 'medical', 'demographics']",
Weather maps api's,"
I would like to produce some global weather maps. Air temperatures, wind speeds, ocean swells etc
I know I can download the GRIB files and interpret them directly from NOAA. However this is quite resource intensive for my needs!
Do you know of any other weather map api's aside from Openweathermap.org?
(https://openweathermap.org/api)
","['api', 'weather', 'noaa']",
Dataset with common dialogues,"
I'm looking for datasets with people's dialogues, just everyday communication.
Example: 

How are you?
  Fine, thank you, and how are you?

","['data-request', 'social-media', 'text']",
Influence of the genetic and biological factors on child's gender and twins,"
I am interested in genetic factors as well as any other biological features in the parents that affect the sex of the newborn child, as well as the prevalence of twins.
Something like this format:

If there is no such data, studies about the influence of any factors on sex and twins are welcome too.
","['data-request', 'medical', 'biology']",
Comparisons data for typical language input speeds,"
I am looking for some statistical comparison data of typical input speed ranges of text input methods for English language in terms of characters per minute or words per minute comparing:

voice typing
typing at a regular full PC keyboard
typing by swiping on phone keyboards such as gboard, Swype, and Swiftkey, using predictive text
typing by swiping on phone keyboards such as gboard, Swype, and Swiftkey, without using predictive text
typing in phone keyboards without swiping with two fingers, using predictive text
typing in phone keyboards without swiping with two fingers, without using predictive text
typing in phone keyboards without swiping with one finger, using predictive text
typing in phone keyboards without swiping with one finger, without using predictive text

and anything else helpful, in terms of input methods and related information, including other languages, if known.
Thank you for your help.
Gboard and Swype or Swiftkey
Note, some resources on Google such as this one and this one list the average keyboard input speed at about 30wpm for texting whereas 40 wpm for keyboarding, but doesn't display the data I looking for.
",['data-request'],
Percentage of the population taking antipsychotics by country and year,"
I was wondering, for each country, and for the pay twenty or so years, what percentage of the population is on antipsychotics by country with diagnoses such as schizophrenia, bipolar disorder, personality disorder, or attention deficit hyperactivity disorder, and would like to know the percentage of adults and children, as well as average stay in hospital as a means of forced psychiatric confinement for each of these.
","['data-request', 'medical', 'demographics', 'database']",
School Boundary,"
I need to find individual school boundaries (primary for the State of California). 
There are maybe 2 or 3 similar questions to this one (here and GIS exchange), but no answer down to the single school. 
We can find the district boundary, and that is helpful. But not individual schools inside that broad district boundary. 
We can also find the boundaries of each physical school location (as opposed as to attendance boundary). 
Any suggestion would be greatly appreciated. 

Update images from files downloaded from The National Center for Education Statistics' Education and Geographic Estimates. 

And what they call elementary:

That site, to the best of my knowledge, does not go down to individual schools. 
","['geospatial', 'data.gov', 'data-mapping']",
Wikidata - Filter or Detect or Get incomplete date,"
I've the following query 
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

SELECT ?item ?itemLabel ?dod ?dob WHERE {
  ?item wdt:P570 ?dod.
  ?item wdt:P31 wd:Q5.
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""es,en,it,fr,de,cs,[AUTO_LANGUAGE]"". }
  OPTIONAL { ?item wdt:P569 ?dob. }
    FILTER(?dod < (NOW()))
FILTER (?item IN (wd:Q4173012))
}
ORDER BY DESC(?modified) DESC(?dod) ?item

that in the example provided (Q4173012) returns four multiple values because has date with incomplete data, for example ""2019"" for date of death, that returns 2019-01-01. I need to filter these cases, I could do it if only get the 2019 so I can know that is an incomplete data, in order to not confuse those records that actually born or death on 01-01
There is some way to convert this query to get the specific data as is shown in wikidata or filter this behavior? Because for incomplete data in wikidata is shown good:

I hope I can be clear, my english is not so good. Thanks in advance and sorry for my english.
","['wikidata', 'sparql']",Data model TimeTry it!
Traffic camera video datasets,"
Before you refer me to this question, I must specify that I am looking for Video datasets, not still images. All links on that question refer to still images. Most cities/government websites provide one frame per minute or so. Are there sources with at least 15 FPS videos out there? 
It doesn't have to be live video, in fact it would be easier for me if it came as a single-file dataset with one JPG file per frame or one video file per feed. 
The UA-DETRAC challenge dataset is one good example, but it is rather limited in size (it has 40 video sequences), and I'm looking for more data. Are there other good sources?
EDIT: to be clear, by traffic camera I mean a camera that is on a high point and that looks at the passing traffic. The cameras cannot be inside of cars, otherwise I would use KITTI and other similar datasets. 
","['data-request', 'traffic', 'video']",
Where to easily find # of employees for a large group start-ups?,"
I am looking for a free database or something else that provides the number of employees for mainly start-ups for some research. A range of Number of employees would also be helpful, but I would prefer an exact number.
I know I can find the number of employees on LinkedIn, but I am trying to do this for a large dataset, so going through every single company page, wouldn't be my preferred solution.
Does anyone have another database/solution for this? Thank a lot in advance!
","['data-request', 'api', 'companies']",
Open Football (Soccer) Player Valuation Database,"
I'm looking for an open database of football player valuation.
From transfermarket, the closest I got is this: 
https://www.transfermarkt.com/spieler-statistik/marktwertkarriereende/marktwertetop?position=&land_id=0&plus=1 
However it is quite limited in size (only has 250 players on it).
I'm OK with other variables but the variables I'm most interested in are:

Player Name 
Max Valuation
Player Position

","['data-request', 'football']",
How to produce a list of all words of a given Language from Wiktionary?,"
Say I want to produce a list of all Latin words from the English Wiktionary (because Wiktionary in English contains the most complete dictionary for Latin, and perhaps for every language). 
More precisely, I want to produce a list of every entry that corresponds to a Latin word. These entries have one thing in common, namely, that the website address has the following type:
https://en.wiktionary.org/wiki/<word>#Latin

For instance, sensorum. The key here is that 1) the domain is the English wiktionary (en.wiktionary) and 2) the website ends in #Latin.
Based on other answers (e.g. here), I found out there is a directory containing all pages of the English wiktionary here. But this does not, as far as I can see, separates by language. The ""main"" file (nwiktionary-latest-all-titles.gz) contains a list of around 7 million objects (words?). This might be the full list of pages in English. I want only those pertaining to a certain language.
There seems to be related posts here and here but I cannot make sense of the answers for my own case. There is also this resource to extract items from Wiktionary, but haven't figure out how to use it for my purposes yet (I used it for extracting lists of categories here but not all words in Wiktionary are indexed into categories).
Anyone can provide some hints on how to do it? 
PS: if this is off-topic, please suggest where this might fit better.
","['download', 'wiktionary']",
NOAA integrated surface database hourly cloud cover and precipitation,"
I am using RNOAA R package isd to download NOAA integrated surface data for a meteorological station (2016 data for Heathrow in London) for the purpose of air quality dispersion modelling. The modelling requires hourly wind speed, wind direction, humidity temperature, precipitation and cloud cover.
Wind speed, wind direction, humidity and temperature seem to be straightforward and can just be extracted for use. The problems are with cloud cover and precipitation. 
For the cloud cover, the column ""GA1_coverage_code"" gives a range of values from 1 to 8 and then 99 and N/A. I gather the N/A means data are not available and 99 means missing data. I contemplate there should be 0 in the column. The other column ""GF1_coverage"" only gives 0, 9, 99 and N/A. I am wondering whether combination of the two columns should give a complete cloud cover dataset. However, i am not sure. anyone could throw some light on this?
For the precipitation, the dataset column ""AA1_depth"" gives precipitation readings for every 6 hours, 0, 6, 12, 18. my understanding is that at 0 and 12, the data give 6h cumulative precipitation for the previous 6 hours and at 6 and 18 the data give 12h cumulative precipitation for the previous 12 hours. I think I can write a code to interpolate the 6h resolution into hourly data. However, is there any code available for use? 
You help would be greatly appreciated.      
",['data-request'],
Data dump of ZIP codes to Carrier Route IDs and the centroid (lat/long.) of the Carrier Route,"
I am trying to find an open database (or cheap commercial) that I can download; perhaps a CSV that would have all centroids of carrier routes for a ZIP code.
There are roughly fifteen Carrier Routes per postal ZIP Code, see the image for an example (though the example shows a carrier route polygon; I only need the centroid). In the image, for example the ZIP code 60625 has CXXX carrier routes.

I thought this mapping would be available at the Census Bureau site (because they have ZIP code boundaries) or USPS, but it is not...
There are about 600,000 carrier routes in the US, according to this blog.
","['data-request', 'geospatial', 'postal-code']",
Share of students in/out of state,"
I'm looking for data on what share of students are in- or out-of-state, for each college/class. I'm guessing colleges do report this as it is covered in other reports from the NCES (for example, the Enrollment and Employees in Postsecondary Institutions reports). However, I can't seem to find any fields in the College Scorecard data documentation pointing to this.
Any ideas on whether it is possible to get this data?
","['data.gov', 'collegescorecard']",
Size of incoming freshmen class,"
I'm looking for the size of the freshmen class of each college/year. I thought at first that I could use the D100_4 field, but then realized that this actually represents the size of the freshmen class 6 years earlier. Am I correct in thinking that the data I'm looking for is not currently included in the raw data? If so, is there a reason for that? Do colleges not report the size of their freshmen class each year?
","['data.gov', 'collegescorecard']",
Retrieve the Supplier details using FEI number?,"
a. Can we retrieve the Supplier details using FEI number, in any of the APIs? 
b. Are there any datasets or APIs available to query information under Cosmetics?
c. Are there any open APIs to fetch data available in the below URL https://datadashboard.fda.gov/ora/fd/fser.htm
",['openfda'],
"openFDA - Open APIs to access Import Alerts, Import Refusals, Warning Letters & Inspection details","
Does openFDA have APIs to access Import Alerts, Import Refusals, Warning Letters &  Inspection details for a Supplier?
",['openfda'],
The Meaning of Patient Identifiers in AI Clinician Paper,"
I am trying to reproduce the results given in the paper The Artificial Intelligence Clinician learns optimal treatment strategies for sepsis in intensive care. 
A MIMIC-3 dataset has been used to generate an AI clinician to suggest a treatment for sepsis patients. The authors shared some patient identifiers under Supplementary Data 1 part at the end.
At the beginning I thought these were subject_id 's of the patients since they fall in the same range but although the authors shared 17083 id 's, only 7934 of them matched a subject_id in MIMIC-3. Moreover, under Supplementary Text and Figures part at the top of Figure 1, the total number of patients without any elimination is given as 61532 which matches the number of rows in ICUSTAYS table. 
The problem is, the icustay_id's within the table are within a different range compared to the shared id's but I believe there must still be a connection between two. So if anyone tried to reproduce the results before, could you please tell me what the shared id's correspond to?
I also tried eliminating the patients with the criteria they have given but still I cannot obtain the same numbers.
","['medical', 'mimic-iii']",
Social data about people in the US,"
I am not from the USA, but I see a lot of discussions about race and racism in  the USA and whether skin color is an indicator for crime, education, divorce and that sort of thing. I do not have political agenda (though I am sure that color in itself can hardly be a causality for anything), but I would like to make the multivariate analysis myself to get a better understanding about the topic. I do not trust the statistics (either way) from those guys in the talk-shows. Are there detailed datasets that I could analyses? I would prefer more fine-grained data, since I fear that aggregated data already is influenced by political agenda (either way). I am happy about data from any country, but I guess the USA is one of the more diverse countries on earth. 
",['data-request'],
Seeking shapefiles for US Census Block Groups?,"
I would like to use this US deprivation index (https://www.neighborhoodatlas.medicine.wisc.edu), which is based on Census Block Groups. Where can I find the corresponding shapefiles? 
","['usa', 'census']","Based on their FAQ https://www.neighborhoodatlas.medicine.wisc.edu/ it looks like they are using 2009-2013 American Community Survey data. In which case, it is best to use the 2013 version of the block group shapefiles from the US Census Bureau, per https://www2.census.gov/geo/pdfs/maps-data/data/tiger/How_do_I_choose_TIGER_vintage.pdf For ACS data, use the TIGER products for the last year in the range
  for the ACS estimates. For example, if using ACS 2007-11 estimates,
  use 2011 TIGER products.**You can read their (Singh GK or Kind AJH, Jencks S, Brock J, et al.) methodology papers for additional details as to how the US Deprivation Index was created.You can download the Block Groups (note there's also an option to download via FTP) from https://www.census.gov/geo/maps-data/data/tiger-line.html.  Select the year and geography type.The Neighborhood Atlas site also has a download section which requires registration. It is possible that they offer shapefile downloads of their results."
Looking for Spatio-temporal Datasets,"
A spatio-temporal dataset is a dataset which contains latitude/longitude and also time variables.
I got a spatio-temporal dataset on this site. The dataset contains 1077 rows of data. The problem is, the size of the dataset is too small.
If anyone has another link to a spatio-temporal dataset with big size and CSV format and also free, please help.
","['data-request', 'geospatial']",
Open database with public art?,"
I’m looking for an open database of art in public space. 
I’m aware of a few localized initiatives, with different levels of openness, but is there an open database that aims to collect all art in public space?
",['space'],
Table of imports and exports by value from country to country,"
I am looking for a list that lists for each world country, the total amount of imports and exports to and from that country, in some currency, as well as a table that has in its x,y position the entry listing the total amount of imports and exports from country x to country y.
Where can I find this data?
Thanks.
","['economics', 'economy']",
Downloadable photos of smartphones,"
I'm working on a project which the main goal is to help on smartphone sales. It displays prices, specs and photos. Prices and specs i got covered, but i'm having trouble with the photos.
The main issue is that the ones i have (another employee downloads them from various sources) do not have the same height and width, and when i try to adjust them using css, most of the time they get blurry or really stretched.
Is there a place where i can find smartphone photos that have the same width and height among them?
",['images'],
"In the OpenFDA database, is trade name the same as brand name?","
i wanted to get the trade name of a drug, but in https://api.fda.gov/drug/label.json?search=openfda.generic_name:Amoxicillin i get brand_name.
so can someone please confirm, that brand_name refers to trade name?
Because as per above link, generic_name and brand_name are same.
",['openfda'],
Can we get the dosage list for a drug,"
How can we get the dosage list for a particular drug. we have the key ""dosage_forms_and_strength"" but it gives a single string not in a list format.
I need to bind a dropdown for dosage information for a drug 
",['openfda'],
USA Southern Border Vehicular and Pedestrian Obstacles,"
Is there a GIS source that contains the location and type of obstacles along the USA Southern border?  Additional meta data would be great as well; when it was install, dimensions, materials, number of repairs, and so on.
",['geospatial'],
Update: Did the U.S. Government shut down take US Census API offline?,"
Did the US Census API just now go offline because of government shutdown? https://api.census.gov was working as recently as 4-5 am this morning. But now its not working (at least for me). 
UPDATE: So I discovered that you can't access the year ""2017"" for the ACS, which was possible yesterday. But you can access 2016 and 2015. 
Example: https://api.census.gov/data/2017/acs/acs5/subject?get=  will fail
https://api.census.gov/data/2016/acs/acs5/subject?get= will work
Is this normal for how they update the data? I figured they wouldn't be updating the site since the gov shut down (and they say so on the website).
",['data.gov'],
Canonical form for romanizations of Arabic town names in Syria,"
Is there a Python package or database source which would allow me to go from various romanizations of Arabic town names in Syria and Iraq to a canonical romanization?
Here is an example where the left romanization is one kind used by a US Government record collection and the other appears in a Syrian government press release.  The Government names seem to be more well known and look-upable than the names used by the Syrian Government.  I would like to find a canonical reduction of the two into a single reliable name:

Al Bāqāt::al-Bakat
Al Ismā‘ilīyah::al-Ismailiya
Arjul::Arjal
Batrānah::Batrana
Bīshah::Bisha
Buraydah::Barda
Burj ‘Izzāwī::Burj Ghazawi
Burj Subaynah::Burj Sabna
Buslah::Bassila
Buwayḑah al Kabīrah::Bouaida Kabira
Buwayḑah aş Şaghīrah::Bouaida saghira
Ghurayrīfah::Gharirfa
Jabal al Mudawwar::Jabal al-Madwar
Jafr Manşūr::Ja’far Mansour
Jubb al Khāfī::Jub al-Khafi
Jubb at Tīnah::Jub al-Tina
Judaydah::Jadida
Kafr Ḩawt::Kafro Hoot
Khanāşir::Khanaser
Khirbat al Ma‘ājīr::Khirbet al-Muaijer
Madāyin Kabīrah::Madaen Kabir
Munbaţiḩ::Munbateh
Rasm al Bās::Rasm al-Bassas
Rasm al Karkūr::Rasm al-Karkour
Rasm Shawkān::Rasm Shoukan
Rujaylah::Rjaila
Şuwayyān::Soyan

",['geospatial'],"Although the data will likely will require some additional tweaking; OpenStreetMap has what you're looking for. For example, in this query run in the Overpass tool that I ran for you of all placesthat are classified as a city in OSM (note: query may take several seconds to load on your computer; you're probably best off exporting it immediately to run the query, then export to your computer).The value for the name tag will have the place's name in the local language that is usually used for common signs and is also often the lingua franca for that particular place. But, and what you're looking for - many places will also have an additional name: tag that represents the town's name in that particular language, as shown in the above image. OpenStreetMap (OSM) is a crowdsourced dataset so there may be many places that do not have an English or canonical romanization; or there may be some places that you'd consider to be a small village but OpenStreetMap has it tagged as a city; there may even be towns that are missing. Criteria for defining a place in OSM is here but these are highly recommended best practices and users who add the data may not necessarily exactly follow it. If you're comfortable with python, I'd recommend using the overpass wrapper to fetch the data; or you could use the overpass tool that I mentioned above, export into geojson and then convert into postgis, a postgresql library that supports geospatial functions. "
Not able to view private datasets in CKAN using Nginx,"
I have installed CKAN v2.7.2(served under HTTPs using Apache web server),Nginx using docker. The task I am doing requires me to mount ckan on /ckan mount point, thus have added
ckan.root_path = /ckan/{{LANG}}

Also, I can access CKAN using Nginx only. CKAN is working properly using Nginx reverse proxy server,But there are three minor issues :

I am unable to view private datasets successfully,whereas public datasets work perfectly fine.Whenever I login with admin account and try to view private datasets- it shows 404 Not Found error as below:


Additionally,in the preview section for private datasets,if I login through the same admin account as shown in yellow color(shown below) then I am able to preview the private datasets successfully.A different thing altogether!! 

After this the dataset gets previewed.
I did try some changes in the configuration of Nginx but it didn't worked.Also,How can I view the Private datasets without logging IN as defined above,as I think this is not correct way of accessing CKAN using Nginx because whenever I clear the cache and to view private datasets,I always have to login in the preview section which I think is totally incorrect.

Update: 1
These were differences in request headers: 
On Left side- Requests, before I am unable to view the datasets
Right Side - When I login in the preview section as shown above and view the private datasets successfully.

Update 2:
Sharing the Nginx default.conf file for CKAN :
      location /ckan {
            proxy_pass https://CKAN-IP:5000;

            proxy_set_header X-Url-Scheme $scheme;
            proxy_set_header Host $host;

            rewrite ^/ckan/ckan/(.*) /ckan/$1 permanent;

            proxy_cache cache_ckan;
            proxy_cache_bypass $cookie_auth_tkt;
            proxy_no_cache $cookie_auth_tkt;
            proxy_cache_valid 30m;
            proxy_cache_key $host$scheme$proxy_host$request_uri;

            limit_rate 25M;
    }


Apache.wsgi script file
import os
activate_this=os.path.join('/usr/lib/ckan/default/bin/activate_this.py')
execfile(activate_this, dict(__file__=activate_this))

from paste.deploy import loadapp
config_filepath=os.path.join(os.path.dirname(os.path.abspath(__file__)), 'ckan.ini')
from paste.script.util.logging_config import fileConfig
fileConfig(config_filepath)
_application = loadapp('config:%s' % config_filepath)

def application(environ, start_response):
  environ['wsgi.url_scheme']=environ.get('HTTP_X_URL_SCHEME', 'https')
  return _application(environ, start_response)


Moreover,I think that while viewing private datasets,my request goes from Nginx to Admin user,which is not logged in and hence is unable to find that resource which is private,thus displays Error 404 Not found above. 

Update 3:
The Logs of Apache for CKAN are as follows:
 [Fri Jan 11 06:21:46.242529 2019] [wsgi:error] [pid 2178:tid 
 139975718889216] 2019-01-11 06:21:46,242 DEBUG [ckan.logic] check 
 access OK - dashboard_activity_list user=admin

 [Fri Jan 11 06:21:46.283912 2019] [wsgi:error] [pid 2178:tid 
 139975718889216] 2019-01-11 06:21:46,283 DEBUG [ckan.lib.base] rendering 
 /usr/lib/ckan/default/src/ckan/ckan/templates/snippets/home_breadcrumb_
 item.html[jinja2]

 [Fri Jan 11 06:21:46.285169 2019] [wsgi:error] [pid 2178:tid 
 139975718889216] 2019-01-11 06:21:46,285 DEBUG [ckan.lib.base] rendering 
 /usr/lib/ckan/default/src/ckan/ckan/templates/package/snippets/
 resources.html [jinja2]

 [Fri Jan 11 06:21:46.292565 2019] [wsgi:error] [pid 2178:tid 
 139975718889216] 2019-01-11 06:21:46,292 DEBUG [ckan.lib.base] rendering 
 /usr/lib/ckan/default/src/ckan/ckan/templates/snippets/social.html [jinja2]

 [Fri Jan 11 06:21:46.294569 2019] [wsgi:error] [pid 2178:tid 
 139975718889216] 2019-01-11 06:21:46,294 DEBUG [ckan.logic] check access OK 
 - package_update user=admin

 [Fri Jan 11 06:21:46.295155 2019] [wsgi:error] [pid 2178:tid 
 139975718889216] 2019-01-11 06:21:46,295 DEBUG [ckan.lib.base] rendering 
 /usr/lib/ckan/default/src/ckan/ckanext/datastore/templates/package/snippets
 /data_api_button.html [jinja2]

 [Fri Jan 11 06:21:46.299369 2019] [wsgi:error] [pid 2178:tid 
 139975718889216] 2019-01-11 06:21:46,299 DEBUG [ckan.lib.base] rendering 
 /usr/lib/ckan/default/src/ckan/ckan/templates/package/snippets/
 resource_views_list.html [jinja2]

 [Fri Jan 11 06:21:46.307521 2019] [wsgi:error] [pid 2178:tid 
 139975718889216] 2019-01-11 06:21:46,307 DEBUG [ckan.lib.base] rendering 
 /usr/lib/ckan/default/src/ckan/ckan/templates/package/snippets/
 resource_views_list_item.html [jinja2]

 [Fri Jan 11 06:21:46.314911 2019] [wsgi:error] [pid 2178:tid 
 139975718889216] 2019-01-11 06:21:46,314 DEBUG [ckan.lib.base] rendering 
 /usr/lib/ckan/default/src/ckan/ckan/templates/package/snippets/
 resource_view.html [jinja2]

 [Fri Jan 11 06:21:46.338195 2019] [wsgi:error] [pid 2178:tid 
 139975718889216] 2019-01-11 06:21:46,338 DEBUG [ckan.lib.base] rendering 
 /usr/lib/ckan/default/src/ckan/ckan/templates/snippets/license.html 
 [jinja2]

 [Fri Jan 11 06:21:46.339502 2019] [wsgi:error] [pid 2178:tid 
 139975718889216] 2019-01-11 06:21:46,339 DEBUG [ckan.lib.base] rendering 
 /usr/lib/ckan/default/src/ckan/ckan/templates/package/snippets/
 resources.html [jinja2]

 [Fri Jan 11 06:21:46.340241 2019] [wsgi:error] [pid 2178:tid 
 139975718889216] 2019-01-11 06:21:46,340 DEBUG [ckan.lib.base] rendering 
 /usr/lib/ckan/default/src/ckan/ckan/templates/snippets/social.html[jinja2]

 [Fri Jan 11 06:21:46.341363 2019] [wsgi:error] [pid 2178:tid 
 139975718889216] 2019-01-11 06:21:46,341 DEBUG [ckan.lib.base] rendering 
 usr/lib/ckan/default/src/ckan/ckan/templates/snippets/
 language_selector.html [jinja2]

 [Fri Jan 11 06:21:46.345452 2019] [wsgi:error] [pid 2178:tid 
 139975718889216] 2019-01-11 06:21:46,345 INFO  [ckan.lib.base]  
 /dataset/vfvfvfv/resource/1db088cc-2805-4c20-887c-f2f2ed91630e render time 
 0.209 seconds

 [Fri Jan 11 06:21:46.438541 2019] [wsgi:error] [pid 2178:tid 
 139975710496512] 2019-01-11 06:21:46,438 DEBUG 
 [ckan.config.middleware.pylons_app] Pylons route match: {'url': 
 u'base/images/nav-active.png', 'action': u'view', 'controller': 
 u'template'} Origin: core

 [Fri Jan 11 06:21:46.438661 2019] [wsgi:error] [pid 2178:tid 
 139975710496512] 2019-01-11 06:21:46,438 DEBUG [ckan.config.middleware] 
 Route support answers for GET /base/images/nav-active.png: [(False, 
 'flask_app'), (True, 'pylons_app', 'core')]

 [Fri Jan 11 06:21:46.438755 2019] [wsgi:error] [pid 2178:tid 
 139975710496512] 2019-01-11 06:21:46,438 DEBUG [ckan.config.middleware] 
 Serving request via pylons_app app

 [Fri Jan 11 06:21:46.447920 2019] [wsgi:error] [pid 2179:tid 
 139975718889216] 2019-01-11 06:21:46,447 DEBUG 
 [ckan.config.middleware.pylons_app] Pylons route match: {'lang': u'en', 
 'action': u'i18n_js_translations', 'controller': u'api', 'ver': u'/1'} 
 Origin: core

 [Fri Jan 11 06:21:46.448081 2019] [wsgi:error] [pid 2179:tid 
 139975718889216] 2019-01-11 06:21:46,448 DEBUG [ckan.config.middleware] 
 Route support answers for GET /api/i18n/en: [(False, 'flask_app'), (True, 
 'pylons_app', 'core')]

 [Fri Jan 11 06:21:46.448141 2019] [wsgi:error] [pid 2179:tid 
 139975718889216] 2019-01-11 06:21:46,448 DEBUG [ckan.config.middleware] 
 Serving request via pylons_app app

 **[Fri Jan 11 06:21:46.450241 2019] [wsgi:error] [pid 2179:tid 
 139975718889216] 2019-01-11 06:21:46,450 DEBUG [ckan.logic] check access OK 
 - site_read user=

 [Fri Jan 11 06:21:46.453059 2019] [wsgi:error] [pid 2179:tid 
 139975718889216] 2019-01-11 06:21:46,453 INFO  [ckan.lib.base]  
 /api/i18n/en render time 0.003 seconds

[Fri Jan 11 06:21:46.503467 2019] [wsgi:error] [pid 2178:tid 
139975718889216] 2019-01-11 06:21:46,503 DEBUG 
[ckan.config.middleware.pylons_app] Pylons route match: {'action': 
u'resource_view', 'view_id': u'a663fdda-ce6f-4ac2-b872-a646f488feff', 
'controller': u'package', 'id': u'vfvfvfv', 'resource_id': u'1db088cc-2805- 
4c20-887c-f2f2ed91630e'} Origin: core

[Fri Jan 11 06:21:46.503593 2019] [wsgi:error] [pid 2178:tid 
139975718889216] 2019-01-11 06:21:46,503 DEBUG [ckan.config.middleware] 
Route support answers for GET /dataset/vfvfvfv/resource/1db088cc-2805-4c20- 
887c-f2f2ed91630e/view/a663fdda-ce6f-4ac2-b872-a646f488feff: [(False, 
'flask_app'), (True, 'pylons_app', 'core')]

[Fri Jan 11 06:21:46.503652 2019] [wsgi:error] [pid 2178:tid 
139975718889216] 2019-01-11 06:21:46,503 DEBUG [ckan.config.middleware] 
Serving request via pylons_app app

**[Fri Jan 11 06:21:46.511546 2019] [wsgi:error] [pid 2178:tid 
139975718889216] 2019-01-11 06:21:46,511 DEBUG [ckan.logic] check access 
NotAuthorized - package_show user= ""User  not authorized to read package 
1c10b0c0-2a2b-46e1-abc5-ff61f6794f8c""

I found the logs starting with ** the reason for not display of resource whereas in above logs at some places for check_access it shows admin.Only at this place there is no user(admin is a sysadmin user at ckan)
","['ckan', 'python']",
"Search population, zipcode by city from US census API","
I am trying to fetch zip code, city name and population in a single file from this api, But can't get it right.
Below one gives me population per city, but no zipcode
https://api.census.gov/data/2015/acs5?get=NAME,B01001_001E&for=place
Below one gives population with zipcode, but no city name. 
https://api.census.gov/data/2015/acs5?get=NAME,B01001_001E&for=zip+code+tabulation+area
Basically what I want is to combine this two file, but couldn't manage it from the API doc 
","['api', 'us-census', 'postal-code', 'population']",
Mapping table for old Swiss municipality codes,"
This is Swiss related question:
I have two datasources, from 2000 and 2018, which I have to join using the Swiss municipality (BFS) codes. Within those 18 years difference, many municipalities fusionend and I am looking for a dataset to map old codes with new ones.
Does anyone know where I do find a mapping file/dataset? 

first dataset: https://shop.swisstopo.admin.ch/en/products/landscape/boundaries3D (2018)
second dataset: https://www.pxweb.bfs.admin.ch/pxweb/de/px-x-4003000000_123/-/px-x-4003000000_123.px (2000)

","['data-request', 'europe', 'switzerland']",I finally found a dataset:
"Seeking Dominion Land Survey data (for Alberta, Saskatchewan, and Manitoba) to overlay in Google Earth?","
I am new to this type of work, and thought that it would not be at all difficult to find a repository of DLS data (as a .kmz, .shp, etc. file) depicting township, range, and section boundaries that I could load directly into Google Earth.
I managed to find this sort of data for Alberta, but the boundary detail is less than what I am looking for.
","['data-request', 'geospatial', 'government']",
Song lyrics database/API,"
Whwre can I find database/API with song lyrics in English?
I want to find specific song by part of lyric.
",['music'],Maybe try musixmatch's api. According to their site  - the api contains more than 14 million lyrics in 50 languages.
OS platform porting are included in term 'Derivatives' in Creative Commons?,"
Taken this license for reference:
Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) 
(similar question)
Quote:

Share — copy and redistribute the material in any medium or format
NoDerivatives — If you remix, transform, or build upon the material, you may not distribute the modified material.
You do not have to comply with the license for elements of the
  material in the public domain or where your use is permitted by an
  applicable exception or limitation.

It seems like self-contradictory and confusing. Should below situation mean that it’s a 'Derivative'?

Keep the original content (data), no addition, no deletion.
Port into different OS platform.
Different GUI (platform based) but mode of operations remain the same.
Proper credited to original author.

Please exclude the situation of 'contacting author, he might be happy if you do work for him'.
","['legal', 'software', 'creative-commons']",
Vocabulary alignment in LDflex,"
From https://ruben.verborgh.org/blog/2018/12/28/designing-a-linked-data-developer-experience/#ldflex-feeling: 

If you are dealing with a different type of data, you cannot use them. This is odd, since Linked Data can model anything.
  They assume that objects have a specific set of properties. This is a major restriction, since Linked Data enables arbitrary data shapes.

I don't use LDflex, so my ""issue"" is just theoretical, musing about the citation from your blog post:
say, I want to query RDF profiles, where one profile uses foaf and the other uses schema as namespace for the name property - how would you access the data? Tricky ""vocabulary alignment"" via one jsonld-context is not allowed, for json-keys have to be unique:
 {
  ""@context"": {
    ""name"": ""http://foaf.org/name"",
    ""name"": ""http://schema.org/name""
  }

Because of this it's probably also not allowed to write two context.jsonld with one key referencing two different properties. 
In other words, what to do to get this SPARQL, resp. how to get the idea behind it:

 SELECT ?friend ?name   WHERE {
  { ?friend foaf:name ?name. }
  UNION { ?friend schema:name ?name }.
}

","['linked-data', 'json']","The long-term answer here is reasoning based on ontologies.A JSON-LD context alone indeed won't get us there. However, the ontological equivalence between foaf:name and schema:name can allow the LDflex internals to derive the SPARQL query you provide in the example. Currently, only the simple SPARQL query without union would be derived.However, this is the long term only; there are still quite some things to tackle (notably shapes) before we should dive into reasoning."
Seeking benchmark dataset for election prediction,"
What benchmark datasets are used for election prediction? Can anyone provide me a link to access such benchmark collection for future research work? 
","['data-request', 'machine-learning', 'elections']",
Does the UNGEGN release their country names localized in a format that's not a PDF?,"
I'm looking for the information released by the ""United Nations Group of Experts on Geographical Names"" (UNGEGN), currently all I can find for the latest conference (E/CONF.105/13) is linked on this page,

E/CONF.105/13 (pdf)

Is there a release that is not in PDF form so I can load it into a database? This PDF is almost impossible to parse. My parser is on hundreds of lines and there are still a slew of corner cases.
","['standards', 'un']",
Where does ISO 3166 get the names and translations of the countries?,"
From ISO 3166 Maintenance Agency, 

The purpose of ISO 3166 is to define internationally recognised codes of letters and/or numbers that we can use when we refer to countries and subdivisions. However, it does not define the names of countries – this information comes from United Nations sources (Terminology Bulletin Country Names and the Country and Region Codes for Statistical Use maintained by the United Nations Statistics Divisions).

However, in the ""United Nations Group of 
Experts on Geographical Names"" I see this mentioned,

The most recent list of country names approved by the Working Group was submitted on behalf of UNGEGN for the Eleventh UN Conference on the Standardization of Geographical Names in August 2017. It is available as E/CONF.105/13.

But in E/CONF.105/13 I don't see them define Palestine anywhere. How did it and others get into ISO 3166? Where is the authoritative source for the names in ISO 3166 -- is it the standard, the ISO Working Group, or the UN? And who standardizes the translations?
",['standards'],
Height and Age - Children and Adults,"
I would like to get height and age data for individuals of all ages. 
This previous question Age, Weight and Height dataset
Lists several datasets for adults and a dataset for children. Google shows a few others that are also either all children or all adults. But I specifically want to look at the shift from the growth years to non-growth as an adult. Of course, I could combine data sets, but it is not obvious that the populations from different surveys would be comparable. Is there a single data set that covers both children and adults?
","['data-request', 'medical']",
Leipzig Districts and Parts of Districts in GIS-format,"
For a city of Leipzig (in Germany) I am looking for City Districts and Parts of City Districts in geospatial vector data format, that can be later loaded into GIS software, e.g. shapefiles, KML, GeoPackage etc. or anything that can be easily converted.
So far the best data is provided by OpenStreetMap, see overpass turbo.
My attempts to find free data failed after investigating the following sources:

Open Data (Offene Daten) der Stadt Leipzig
Leipzig Data website
Ortsteile und Bezirke von Leipzig in OpenStreetMap einpflegen
Open Data - Freie Daten und Dienste des BKG

I have seen the related thread, but it does not fulfill my request:

Postal codes and city districts worldwide for download

Any hints?
","['geospatial', 'city', 'germany', 'district']",
What are Outlink categories of Wikipedia,"
I am wondering if it is possible to view outlink categories of a given article in Wikipedia? For example, consider the Wikipedia article about 'Data Mining'. What are the outlink categories of ""Data Mining"" article and how to find them in the Wikipedia page?
According to the paper ""Using Wikipedia knowledge to improve text classification
""; the outlink categories and their count of ""Data Mining"", ""Machine Learning"" and ""Computer Network"" are as follows.

However, I still could not discover how they obtained these outlink categories and their counts. Please help me.
","['data-request', 'uses-of-open-data', 'wikidata', 'wikipedia']","Just get the list of linked articles, get the categories for each and sum up. If you want to do it with the official API in a single request (well, single sequence of requests because the data will be too large for one response so you'll have to use query continuation, it would look like this:https://en.wikipedia.org/w/api.php?action=query&format=json&prop=categories&titles=Machine%20learning%7CComputer%20network%7CData%20mining&generator=links&clshow=!hidden&cllimit=max&gpllimit=max"
Limiting a SPARQL Query to Lastest Point in Time,"
I'm trying to get information on Prefectures in Japan out of Wikidata. I succeeded to read the population statement, however there are occasionally several values with different point in time fields.
SELECT ?itemLabel ?population ?date 
WHERE {
   ?item wdt:P31 wd:Q50337;
         p:P1082 [pq:P585 ?date; ps:P1082 ?population];

   SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". }
}

I'm was trying to get a single row per prefecture using groups, but to no avail. How do you select the lastest point in time?
","['wikidata', 'wikipedia', 'sparql']",Try itIf you really need GROUP BY:Try itWith Blazegraph's named subqueries:Try it
"What is the UN ""Global Code""?","
The UN on the ""Standard country or area codes for statistical use (M49)"" makes mention of ""Global Code"". It's 001 for every entry in the table. The ""Global Name"" is likewise ""World"". What is the Global Code, and is it defined for anything that is not 001? By extension is there a ""Global Code"" for anything that is not ""World""?
","['classification', 'un']",
Can the United Nations Terminology Database (UNTERM) be downloaded?,"
Currently the United Nations hosts the United Nations Terminology Database at 

https://unterm.un.org/UNTERM/portal/welcome

Do they provide a data dump of this anywhere?
","['data-request', 'un']",
Determining time zone and daylight savings time from latitude and longitude?,"
I have about 5,000 weather stations with its' lat, lon coordinates.
I would like to determine which Time Zone they fit into and whether they observe daylight savings time.
The sample of data looks as follows:
Austin, TX: 30.183, -97.68, US Central Time, DST = Yes
Phoenix, AZ: 33.3, -111.667, US Mountain Time, DST = No

I'm only interested in the US, Canada, and Mexico.
Any and all ideas are appreciated. I'm opening to writing code to calculate this, but would prefer if there is some open dataset that may already exist that I could reuse.
",['geospatial'],
Hotels data for analytics,"
I'd like to ask where can I get hotels data such as addresses, images, descriptions, coordinates, facilities, reviews? I've read this thread, but couldn't find any appropriate ways for today. Note: we're planning to use data only for analytics and building our own recomendation system, so our customers won't have access to this data, therefore we don't match most of the requirements for affiliate programs.
Any suggestions on some API or other web resources to get this data?
","['data-request', 'machine-learning', 'database']",
Bulk download Sci-Hub papers using a list of URLs,"
I wonder whether it is possible to bulk download  papers with Sci-Hub using a list of urls stored as file. i want to automate the download because i need 1570 article
","['download', 'pdf', 'open-access']",
Mean earnings from the college scorecard dataset,"
In the College Scorecard data set there are three variables that define a working_not_enrolled earnings:
[1]
earnings.6_yrs_after_entry.mean_earnings.dependent_students
(Mean earnings of dependent students working and not enrolled 6 years after entry)
[2]
earnings.6_yrs_after_entry.mean_earnings.independent_students
(Mean earnings of independent students working and not enrolled 6 years after entry)
-and-
[3]
earnings.6_yrs_after_entry.working_not_enrolled.mean_earnings
(Mean earnings of students working and not enrolled 6 years after entry)
I was thinking to combine both dependent[1] and independent[2] student data to get the overall mean earnings of all students which I thought would be the same as the last variable[3], but it isn't.
So which is the ""true"" mean earnings for all students here?
","['data.gov', 'collegescorecard']",
Are there any meaningless photo data sets?,"
I am looking for a dataset. All I want is just a background photo. It can be a building, a river, or a house. But it must be a natural picture, not a drawn picture. Is there such a data set? It would be better if it contained various environments.
",['machine-learning'],
State and country codes like ISO 3166-1 and ISO 3166-2?,"
I know there are two specs that essentially catalog the entire planet into the political region/subregions, with internationalization

ISO-3166-1 which has 2-letter, 3-letter, numeric, and country names.
ISO-3166-2 which has subdivision names and their abbreviations

So,

Is there any open distribution of these? I know you can buy the spec, but I know you can also implement it into a product. Are there any products that leak the spec out? Are there any draft distributions of ISO-3166-[12] like there are with the SQL spec?
Is there anything that rivals these specs that is also internationalized that I can use in an open source product?

","['usa', 'standards', 'county', 'state']",
Is there a government database that tracks police-use of deadly force?,"
I'm looking to find all casualties with officer involvement, whether they were detained, tasered, or shot. Is there any official government source that tracks this and makes the data public?
I see the Bureau of Justice Statistics tracks this with their ""Arrest-Related Deaths"" using ""Arrest-Related Death Report (CJ-11A)"". But I can't find the list of CJ-11A filings in the United States? Are they public?
","['usa', 'police']","Not yet; the FBI announced they will launch one in 2019-01.
There are a number of fourth estate/civic activist databases, but no authoritative, government database, that I am aware of."
"Where can I find the list of NCIC assisiged ""Originating Agency Identifier""?","
From the docs, provided on the National Incident-Based Reporting System (NIBRS) user manual,

An Originating Agency Identifier (ORI) is a unique nine-character identifier the National Crime Information Center (NCIC) has assigned to each LEA in coordination with the CSO. The Uniform Crime Reporting (UCR) Program uses this identifier to indicate the contributing agency. Data Element 1 is mandatory in each NIBRS submission.

But there is no information on where I can get the list of Originating Agency Identifiers, and I don't see it on the Downloads Page. Where can I find that list? Preferably authoritative from a government site, that I can redistribute?
","['usa', 'database', 'crime']","It's available at the Crime Data API end point, you have to first request a data.gov api key then you can access it onThis is documented on the GitHub project crime-data-api, and the official Crime Data API page.On Dec 20, 2018, the result of the API call is 7.7MB of JSON.Go to the Crime Data Explorer page under the section ""Explore by location and data set"" and click on the link under the map,"
Listing of United States Police Departments?,"
Is there a list of the US Police Departments maintained at a federal level? I know the DOJ is supposed to be over them all? Does it maintain any such list, or any other federal agency?
","['usa', 'police']",
Solr not working while running CKAN over HTTPs using nginx and apache,"
I am running CKAN v2.7.2 over HTTPs using Apache and have configured Nginx-reverse proxy to access CKAN.Thus,I am accessing CKAN using Nginx only.
All the three components (CKAN,Apache,Nginx are running on docker).
The CKAN page is being loaded however,I get the following error logs in apache ckan_default.conf.error.log
raise ConnectionError(e, request=request)
[wsgi:error] [pid 93:tid 139753652762368] ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=8983): Max retries exceeded with url: /solr/ckan/select/?s

ERROR [pysolr] Failed to connect to server at 
'http://127.0.0.1:8983/solr/ckan/select/?sort=score+desc%2C+metadata

Traceback (most recent call last):
File ""/usr/lib/ckan/default/lib/python2.7/site-packages/pysolr.py"", line 366, in _send_request
File ""/usr/lib/ckan/default/lib/python2.7/site-packages/requests/sessions.py"", line 501, in get
return self.request('GET', url, **kwargs)
File ""/usr/lib/ckan/default/lib/python2.7/site-packages/requests/sessions.py"", line 488, in request
resp = self.send(prep, **send_kwargs)
File ""/usr/lib/ckan/default/lib/python2.7/site-packages/requests/sessions.py"", line 609, in send
r = adapter.send(request, **kwargs)
File ""/usr/lib/ckan/default/lib/python2.7/site-packages/requests/adapters.py"", line 487, in send
raise ConnectionError(e, request=request)
ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=8983): Max retries exceeded with url: /solr/ckan/s

",['ckan'],"You cannot reach solr from ckan because they are running in two different container on the same virtual network.If you run a container, a bridged network will be created by default.If container share the same network (like when you usually run containers with docker-compose, you can connect from one to the other using the name of the last one.In your case, you should probably connect to http://solr:8983/solr/ckan."
Lyrics with timestamp for development,"
We are developing a mobile app to follow along songs and lectures with transcript.
Because we need to follow the audio with the transcript we decided to use LRC format, specifically the Enhanced version. This should work fine in the final product, but where can I find an example of this type of file?
I don't mind the content of the audio. I need just a sample enhanced lrc file to develop the app and make a MVP version
","['data-request', 'music']",
Cannot get data from FPDS atom feed using pyfpds,"
I have a script which uses the pyfpds wrapper (https://github.com/18F/pyfpds) to extract contract data from the FPDS Atom Feed (www.fpds.gov).
Following is the code I have and this used to work till last week. Presently, this doesn't work if I have a date field filter in the get() method. 
from pyfpds import Contracts
from datetime import datetime, timedelta

def main():
    c = Contracts()
    print(""\nSearching in PIID: ""+piid)
    yesterday = datetime.strftime(datetime.now() - timedelta(2), '%Y-%m-%d')
    records = c.get(agency_name=""SECURITIES AND EXCHANGE COMMISSION"",last_modified_date=yesterday)
    c.pretty_print(records)
# end of main()
if __name__ == '__main__':
    main()

The code works without any issues if I remove the date field filter from the get() method.
I also tried with other date fields such as signed_date and created_on, and it doesn't make any difference.
Is there any specific change in FPDS Atom Feed which prevents the date filters in the requests?
","['usa', 'api', 'government', 'python', 'federal']",
Where can I find labeled but unsegmented time series datasets?,"
Almost all datasets in the UCR archive contain only time series sequences that are segmented and scaled to the same length, which is unrealistic. Are there any time series datasets that are not segmented but labeled?
",['time-series'],
Seeking USA congressional district to county relationship files?,"
This must be a common enough problem that other users have come across it. I've finagled my way around inconsistencies and dropped observations, but now I'm reaching out to see if anyone knows of a 'holy grail' type spatial dataset.
I am in search of USA congressional district to county relationship files going back to the 1980s. While many components of said files are available online via the US Census Bureau (https://www.census.gov/geo/maps-data/data/cd_national.html), they do not release them for every year.
I've tried combining different online sources (combining this CD dataset (http://cdmaps.polisci.ucla.edu/) with the atlas of historical county boundaries (https://publications.newberry.org/ahcbp/)) in a GIS environment; however, inconsistencies in the shapefiles (see here:

lead to too many (or too few) relationships.
Does anyone have such a file on hand or know where I could obtain it?
","['data-request', 'geospatial', 'usa', 'government']",
Free poker game database,"
I'm looking some free data to make data mining research about texas holdem poker game.
What I'm expecting is some kind of log file containing information about what players had in hand, how they betting, and what actions they took. 
What I already found are following links but actually doesn't satisfied me:
https://poker.stackexchange.com/questions/881/publicly-available-poker-stats - in this topic there are mendtioned tree links:
1.http://web.archive.org/web/20110205042259/http://www.outflopped.com/questions/286/obfuscated-datamined-hand-histories - probably the closest log list that I'm looking for, but lack of information about cards, only actions provided
2.https://archive.ics.uci.edu/ml/datasets/Poker+Hand - containing only information about cards, no actions mentioned
3.http://poker.cs.ualberta.ca/irc_poker_database.html - I downloaded data, but have no idea how to read this
What I actually looking for would be combination of information provided in links 1 and 2 
I haven't found any others sources of data over the internet. It don't have to be data from recent years or anything, Just to have big amount of instances.
Any help will be appreciate.
","['data-request', 'research', 'database']",
How to get specific wikipedia data?,"
I only want to use the link structure and articles’ content of Wikipedia. Therefore, I want to downlaod the dump that contains only the following details.

articles content
link structure (i.e. re-directed page, out-link categories, disambiguation pages etc.)

Is there any link where I can download them directly?
","['data-request', 'uses-of-open-data', 'wikidata', 'wikipedia', 'rdf']","Data dumps are at https://dumps.wikimedia.org/enwiki/20181201/ (currently). Article content (source code) is in the pages-articles files (e.g. enwiki-20181201-pages-articles.xml.bz2 is all pages in a single file, enwiki-20181201-pages-articles1.xml-p10p30302.bz2 is page IDs 10 to 30302, enwiki-20181201-pages-articles-multistream.xml.bz2 is a single file with many separate bz2 streams). If you need all pages you are probably better off with the single-file plain bz2 format. Note the data might be in the TB range after uncompressing.Link information is available as SQL dumps from the same page (towards the end of the list, files with templatelinks, imagelinks, redirects etc. in the name). These are 1:1 dumps of the corresponding MediaWiki tables so see DB schema information for details.If you need the page content as HTML, your best bet is probably processing one of the Kiwix dumps (they are in ZIM) which contain a stripped down version of article HTML."
List of proposed census years in Africa,"
Is there a list of proposed census implementations for countries in Africa? I see that Kenya has one coming up next year. I haven't found much by searching for other countries by name. 
","['census', 'africa']",
Is there a Creative Commons collection of country maps in SVG format with corresponding country code?,"
For a little hobby project I am looking for a collection of SVG files of maps of all countries in the world separately with the country codes included in the SVG or filename. It would have a structure like this:

AFG.svg
ALB.svg
...
ZMB.svg
ZWE.svg

It would also be nice to have a projection that keeps the size of the countries realistically since I will use them to compare pairs of countries.
I have looked on the following places:

https://www.jasondavies.com/maps/countries-by-area/ Don't know if it can be used for non-commercial purposes and the countries do not contain the country code.
https://www.amcharts.com/svg-maps/ Doesn't have a package containing all the countries, also does not have the country code.

I also found a couple more resources which contain the whole world as one SVG or separate countries but no collection with all of them with country codes included.
Is there a resource which offers use for non-commercial purposes SVG of countries with a way to identify them by country code?
","['data-request', 'geospatial']","mapsicon is a free collection of maps for every country in the world, available in 11 sizes or in SVG.
The maps are named after the official two-letter country codes defined in ISO 3166-1. Basically, that means the United States are named US, Canada is named CA, etc.
If you need to access all those countries programmatically, here is a gist containing all the countries as well as their ISO code: https://gist.github.com/djaiss/2938259""  There's also:
Simple World Map: a simple and lightweight SVG world map, annotated with two-letter country code standard ISO 3166-1 alpha 2. This map is one SVG, not individual SVGs.
and
Marked-Up SVG World Map: an SVG world map marked-up with ISO 3166 country codes. Path (path) and group (g) elements are annotated with cc attributes containing their country codes.  "
Road network data for Pakistan,"
I am trying to make a detailed map of roads in Pakistan road. I have already used sources like OSM, DivaGIS, but they don't give me enough detail (amount of point, polyline and polygon features).
Can anyone guide me to more accurate data?
Can we download the road network of Google Maps maybe?
Even any kind of script to scrape data would do the trick.
","['data-request', 'geospatial']","Facebook's MapWithAI initiative builds off of existing OSM data. I cannot speak to the quality of the data, but you can find the data and information on how to download it here."
EAN transaction data set,"
I'm looking for a real set of shop transactions data contain EAN code (https://en.wikipedia.org/wiki/International_Article_Number)  as transaction item. Community, can you help?
","['data-request', 'shopping']",
Why is the Open World assumption so central to the semantic web?,"
The semantics of RDF is known to be based on the open world assumption. What does that mean? How does that show up in the RDF Semantics? And why does it help in data integration?
","['rdf', 'semantic-web']",
(How) Was SPARQL influenced by erotetics?,"
Erotetics is the logic of questions and answers. The field has been developed over the last hundred years and is nicely summarized by (Wisniewski 2015). 
How, if at all, was SPARQL, the RDF query language, influenced by the research in that field?

Wisniewski, Andrzej. ""Semantics of questions."" The handbook of contemporary semantic theory 3 (2015): 273. (pdf)

","['sparql', 'rdf', 'semantic-web']",
Topographic map data for countries,"
I am looking to create a d3 powered topographic map of a handful of countries. Topographical features across entire countries can be intricate and plotting them can be resource-intensive, because we are going over each locus across the entire surface area of the country. Since d3 is a client side library, I will be limited in the resolution I can plot in -- a page with many elements will be very slow or even crash-prone. For these reasons I will not be needing the most granular topographic data. Though, I suppose I can also use binning or other transformation to make things manageable.
To my knowledge satellite data is favorable for topographic cartography. However, the NASA or European space agency websites don't have any means of downloading this data. I'm not sure if there is a free data option at all or if I'm just inept at navigating their fancy website and deciphering all the smarty-pants ""rocket-science"" terms. 
Question
NASA or otherwise, is there an open data resource for plotting-from-scratch a reasonably detailed topographic map?

It would be nice if the resource was already categorized by country, but I'm willing to slice the desired geographic region manually if need be (I imagine this will be a big headache though)
intended use case is for a 2-dimensional d3.js map

","['data-request', 'geospatial', 'data.gov']",
What do dashed and solid brown lines mean in open street map?,"
I am talking about the dashed and solid brown line you can see here (live OSM version):

For the dash brown line, according to the legend it means ""track"". For the solid brown line, I can't even find a key.
What does ""track"" mean in this scenario?
Could it mean track you walk on? If it does, why isn't it a ""footway""? Or is it for vehicles, which makes it a different kind of track, than the various footways there are?
What I am trying to do is essentially find unpaved roads or tracks, where I can drive with my car for fun. I have identified the brown lines as potential indicators of such roads, but am curious if this also indicates footways. Or if it only indicates footways. And also if there even is a way to tell which road is paved and which not by looking at the map.
Edit: I found this information: https://wiki.openstreetmap.org/wiki/Key:surface and I found an app, which, if you give it a destination it will tell you how much % of the way is paved and how much ""other"". So the information seems to be available, but I still don't know how to find out if a particular road is a road and is unpaved? 
","['geospatial', 'openstreetmap']","You can check out the underlying data, which can help to understand what is what, and if you know the area, what may be mis-tagged.Mostly solid. Even mixture of hard and soft materials. Almost always an unpaved track.Interesting, at the end of the dashed line there is a ""turning circle"", according to the map at least.track is more fitting than residential for the roads through the vineyards And these tags (link) which include cobblestone:"
Seeking Help for getting climate variable data,"
I am working on Agro-Meteorology for two semiarid Districts of my Province (Telangana, India)(Deccan Plateau of South India). I tried my best to find Relative Humidity/Dew Point Temperature from most of the Global Climate data providers across the web, but failed to find the exact search. I want it to calculate Throntwaite Equation. Can anyone suggest me how and where can I get it. My choice of spatial resolution is minimum 0.1 degree, temporal resolution is 1 month and duration from 1979 to present.
","['climate', 'agriculture', 'meteorology']",
Is there a dataset for historical US towns and roads?,"
I need to map US settlements/towns/cities from colonial times through roughly 1900, for example Bath, NC founded 1705 at lat/lon. The minimal data I'm looking for would contain:

Name of town or settlement, e.g. ""Bath"".
Name or identifier of colony or state, e.g. ""NC""
Founding year, e.g. ""1705""
lat/lon coordinates (not complete polygon of extents - I just want to put a dot on a map and want to keep the size down)

Even better would be multiple entries per town over the years with population estimates, but that's not critical.
I'm also interested in mapping early road networks, but realize that's likely a different dataset.
Anything like that out there? Thanks!
","['geospatial', 'usa', 'historical']","Wikipedia has a List of North American settlements by year of foundation, formatted as a sortable table. You can sort this list by country, and copy-paste the United States section into a spreadsheet. This data set contains the following fields:It does not have lat/long coordinates. However, lat/long data for cities is readily available. I list a few sources below. You can use GIS software to join the two data sets based on the settlement name.Data.gov has the Place (National) and City and Town Boundaries datasets.ESRI provides USA Major Cities as a point layer, and North America City Areas as a polygon layer.USGS provides a layer called USGS Small-scale Dataset - Cities and Towns of the United States 200402 Shapefile.Natural Earth provides a world-wide layer of towns and cities called Populated Places.The historical population data you want is probably on the Census Bureau website somewhere. I spent a while looking for it, but they sure don't make it easy to get to. I suggest you post that portion of your data request as a separate question with the census tag.The one source I found for population data is a report from the Census Bureau called POPULATION OF THE 100 LARGEST CITIES AND OTHER URBAN PLACES IN THE UNITED STATES: 1790 TO 1990, which includes data in tabular form."
Are there any multi-type public datasets out there?,"
Does anyone know of any good public datasets for supervised learning that would contain data where instances are described with different types of data (ie. timeseries data, categorical data, images, ...)
The types of datasets I have in mind are:

a dataset where each example is described with an image and some numerical features
a dataset where each example can be described with timeseries data and some categorical features
a dataset where each example is described with multiple images (ie. the image taken from two different angles)

An example would be a dataset of daily closing stock price data associated with news sentiment for that particular day.
I'm aware that it's possible to construct a dataset like that on my own with some scraping but I'm wondering whether there are any public datasets out there that serve this purpose.
",['data-request'],
Historical international US phone calls prices by country and year,"
Is there any dataset of historical international US phone calls prices by country and year (likely since 1946)?
","['data-request', 'historical', 'prices', 'telecom']",
Get list of all wikidata properties used to link to an item,"
The first part of my question is, is there a SPARQL equivalent of the ""What links here"" link? E.g. as described at https://opendata.stackexchange.com/a/5271/20321
I tried:
WHERE {  ?item wdt:?property wd:Q1174 . }

which gave a syntax error, and:
WHERE {  ?item wdt:* wd:Q1174 . }

which doesn't give an error, but only returns one row: the item in the query!
The second part of my question is how can I get a list of all unique properties that are used to link to the item of interest? This is the bit I'm interested in, as I suspect there will typically just be 1 or 2 properties used for 99% of the links, and that any others are probably mistakes, that are good candidates for fixing to improve data quality.
","['wikidata', 'sparql']","The first part of my question is, is there a SPARQL equivalent of the ""What links here"" link? The second part of my question is how can I get a list of all unique properties that are used to link?Assuming you are interested in truthy statements only:(try it)and(try it)respectively.UpdateIf you want to use the label service with items that have large number of incoming links, you should place it outside of the inner query.Try it!"
Data Flows from USAID Projects to Missions to Agency Level,"
Where can I find information about how data flows from individual USAID-funded projects (typically implemented by contractors) to the USAID Missions and ultimately to Agency-level databases and reports?
",['usaidopen'],
Allergy/Pollen Count Data Set by US city/county/census tract,"
I am looking for a dataset containing allergy rates or pollen counts for cities/counties/census tracts. Ideally, the dataset would include rates of specific kinds of allergies, or for pollen counts, track the counts by species that are known to cause seasonal allergies.
","['data-request', 'medical', 'environment']",
Where can I find historical hourly cloudcover/skycover data for specific coordinates in Northeast America?,"
I am looking for historical hourly weather data, specifically cloud cover for specific coordinates. 
I have used Darksky API and it gives cloudcover as a value between 0 and 1, but I do not trust their model for coming up with these values. 
I have tried to look for any dataset from national weather services, but their websites are so confusing that it is super hard to find one. 
I am looking for the data from a reliable source that gives me cloudcover as a value between 0 and 1 or in terms of NWS skycover forecast terms (clear, mostly clear, partly cloudy, mostly cloudy, cloudy). 
","['data-request', 'usa', 'weather', 'climate']",
Focal length of both front and back cameras of popular smartphones,"
I need such a database of smartphones cameras:

Each smartphone in the database must have the focal length of BOTH the front camera (typically used for selfies) and the back camera (typically used for landscapes/etc, also called rear camera)
The most popular smartphones should be covered. My goal is to cover like 70% of the current world users, the more the better. By the way, many users have rather old smartphones.
Each smartphone should be identified with some identifier that can be found in the EXIF of the photos it takes. Other metadata about the phone is not necessary (I can remove what I don't need).
Open data: freely reusable and embeddable into Apache2-licensed software

","['products', 'sensors', 'technology']",
"High-resolution GIS datasets of groundwave conductivity of the United States, besides the FCC?","
The FCC publishes a map of estimated groundwave conductivity of the United States, but the resolution is quite low:

Are there any GIS datasets that include groundwave conductivity at a higher resolution and with more precision? I've already converted the map into a shapefile, so I don't just need the map in GIS format.
",['geospatial'],
Trade tariff data request,"
I am looking for historical import tariff data for trade between countries (US and EU, Gulf, China ) to validate one model. 
","['data-request', 'data.gov', 'trade']",
"Alternation (""OR"") searching","
This seems like a trivial thing, but I can't seem to get basic alternation when searching for databases, eg. crime OR court. I briefly looked at the API to see if there was a way to do it through that, but couldn't find anything there either.
I expected this to produce results, but it doesn't:
https://catalog.data.gov/dataset?q=crime+OR+court+OR+justice+OR+pretrial+OR+judicial
","['data.gov', 'ckan']","AFAIK, at least one : should be used in order to enable advanced search on CKAN:https://catalog.data.gov/dataset?q=title:abracadabra+OR+crime+OR+court+OR+justice+OR+pretrial"
Downloadable list of all majors across U.S. schools/colleges?,"
I am looking for a downloadable list of all MAJORS across U.S. schools/colleges and across education levels (Highschool, Undergraduate, Graduate, Masters, Phd, Doctorate, Certificate/Short Term)
I have found a few sites where I can search for a particular major on the site's database, but I am looking for a downloadable list, preferably in spreadsheet format such as xls or csv.
Thanks!
","['usa', 'education', 'database']",
Any open dataset for Geopolitical queries and answers?,"
I'm searching for queries/questions and answers that can be run and tested on top of the ICEWS and GDELT dataset, so that I could detect whether the query inference engine returns all the expected answers using F1 or precision/recall curves. 
","['data-request', 'big-data', 'unstructured-data']",
London Fare Zones spatial data,"
Does anyone know if the London Fare Zones are available as a spatial data set?
An example of a spatial data set would be:

Shapefile
KML
GeoJSON

","['geospatial', 'uk', 'public-transport']",
Wikidata: How to represent British Hong Kong's under Japanese occupation?,"
Between 1941 and 1945, British Hong Kong (then a colony) was occupied by the Japanese, see this Wikipedia article.
However on British Hong Kong's Wikidata page, there's no mention of the Japaneses occupation whatsoever. It seems like it was a British colony or dependent territory from  1841 to 1997.
I'm willing to contribute to Wikidata to fix this, but what's the best way to model this short-term occupation?
",['wikidata'],"As far as I know, there are no methodological guidelines for how to model those things on Wikidata.
Rerardless Wikidata, modelling of such geopolitical endurants/perdurants/aggregates might be fairly complex.Option 1Create a separate ""Japanese-occupied Hong Kong"" entry (similar to Vichy France).Split British Hong Kong into ""British-occupied Hong Kong"" and ""British-reoccupied Hong Kong""
(similar to French Third Republic and French Fourth Republic).Thereafter, one should split into two parts all 26 Wikipedia articles...Option 2Option 3Your question is widely applicable.Perhaps you could propose the ""occupied by"" property."
Full Text Scholarly Resources,"
Most of scientific paper sources provide some basic metadata about the paper (authors, publish date, DOI, etc) and sometimes the abstract and a link to the PDF of the paper. However, converting PDF to some structured data format like XML is a very tedious method,error prone and not scalable. After some research, I found some sources like CORE (https://core.ac.uk/services#dataset), Elsevier (https://dev.elsevier.com/sc_apis.html) and Springer (https://dev.springernature.com/) which provide the full text of the paper in XML or HTML format which is very usefull for data mining processes.
Are there any other scholarly sources which provide the full text of the papers in a format like XML or HTML ?
","['data-request', 'api', 'research']",
Historical data on forests and land use in the United Kingdom [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 4 years ago.







                        Improve this question
                    



EDIT: I have posted this question to the history.SE after a discussion on that site's meta.
Are there any sources of historical land use/land cover data for the United Kingdom? I'm specifically interested in datasets that, for each point/area in the UK (ideally, at as a high a resolution as possible), list whether the land was forest, urban, agricultural/cultivated, etc. for the time period 1800-1900.
There are modern versions of these data, e.g. the Corine land cover data, which have been addressed in other questions, but nothing historical.
The Ordnance Surveys supposedly include some data like this for the years 1842 onward, but actually looking at the list of years in which each county was mapped shows that the actual data is mostly much later.
https://maps.nls.uk/os/6inch-england-and-wales/
","['data-request', 'geospatial', 'uk', 'land']",
Seeking vector file of extent of flood plain of 2010 Pakistan Floods?,"
I am looking to locate a shapefile or any vector file that can be used for analysis I am conducting of change in size of cropland in the Punjab region of Pakistan. The file of interest would reflect the area that the floods that took place in Pakistan 2010 and would provide me the ability to differentiate areas that were directly affected by the floods from ones that were not.
I have tried several outlets such as the Humanitarian Data Exchange and requesting it from several organization without any luck. I may have overlooked platforms where this data would be available that is why I am here for this help.
","['data-request', 'geospatial', 'geohazard']",
Get random city of any country,"
I am looking for an public Rest API which I can consume and get random city name at every time.
No inputs (like country). City can be any size, it can be a village, town, city..
","['api', 'city', 'rest']","I've developed and host an online city database called GeoDB Cities which should fit the bill. Here's how I would implement a Random-City-Name feature:Do an initial query to get the total count of all available cities. The results are chunked by pages, but each result also contains metadata about the total count of cities. You need to extract metadata.totalCount from the JSON. (You can safely cache this value.)GET http://geodb-free-service.wirefreethought.com/v1/geo/cities?hateoasMode=offGet a random number from 0 to (totalCount - 1) in the previous step (results are zero-based). Go here for an excellent example of how to do so in Java. The code in other languages should look similar. This will represent your offset result into the data.Do another GET query to get a single offset result, where OFFSET is zero-based. Extract data.name from the JSON.GET http://geodb-free-service.wirefreethought.com/v1/geo/cities?limit=1&offset=OFFSET&hateoasMode=offThe free instance is limited to cities with populations of at least 40000, but that might be fine for your purposes."
NASA's Space Datasets,"
I am looking for data on the spatial positions of planetary bodies, asteroids, stars, galaxies, etc. In doing that I was led to HORIZONS which requires you to use telnet to command-line step through querying for data! I was hoping there would be an FTP or CSV somewhere but haven't found anything.
That got me here to ask about what major data sets NASA offers. I'm sure they have hundreds or thousands of small data sets, updates, and variations of collections of such, but I'm not looking for a list of all that. I just would like to know what (and where) the major data sets are.
From my understanding so far, there are:

HORIZONS. (I am not sure if this FTP is the same dataset, which would be great). I think this includes all planets, including Jupiter and whatnot, which the ""Geosciences"" data below doesn't (maybe because Jupiter is a gas planet instead of rock).


highly accurate ephemerides for solar system objects ( 789751 asteroids, 3542 comets, 190 planetary satellites, 8 planets, the Sun, L1, L2, select spacecraft, and system barycenters ).

Lunar Data FTP (and description). I think this is just a map of the surface of the moon using LiDAR.
Other Planet Geoscience Data FTP. I think this is mainly for Mars, Venus, Mercury, Moon, Earth, and Asteroids. (Doesn't mention planets like Jupiter and whatnot).
ATMOS data (and FTP). ""Atmospheric Trace Molecule Spectroscopy"". Not really sure what this is.
data (and FTP). ""Physical Oceanography Distributed Active Archive Center (PO.DAAC)"".
https://fermi.gsfc.nasa.gov/ssc/data/access/
https://neo.sci.gsfc.nasa.gov/about/ftp.php
https://earthdata.nasa.gov/earth-observation-data/near-real-time/download-nrt-data
https://pmm.nasa.gov/data-access/downloads
https://cdaweb.sci.gsfc.nasa.gov/pub/software/cdawlib/0MASTERS/
ftp://ftp.nnvl.noaa.gov/
https://heasarc.gsfc.nasa.gov/db-perl/W3Browse/w3table.pl?tablehead=name%3Dugc&Action=More+Options
ftp://legacy.gsfc.nasa.gov/
... Not really sure what else. I know there are the images available, but mainly looking for the data.

I am specifically wondering if there is any data on the positions of the galaxies, but not sure if NASA has that (would be helpful to know if they do or don't).
",['astronomy'],
Looking for shape files for major museums in the US.,"
I have found some individual cities' data but not somewhat comprehensive country wide data. It doesn't have to be perfect, but it would be nice to have most major museums. 
","['geospatial', 'glam']",
PETS 2007 Dataset,"
Does anyone know if the PETS 2007 Dataset (http://www.cvg.reading.ac.uk/PETS2007/data.html) is still available anywhere? Their FTP server and HTTP server seem to not be working. 
",['machine-learning'],
3D shapefile or pointcloud data for stars/galaxies in observable universe,"
I have seen animations of the universe / galaxies such as this where the galaxies / clusters are like specks in a 3D / volumetric cloud, which you can zoom into and they get bigger and then zooming into the galaxy you get the individual stars, etc.
Part of that is probably application development, but I'm wondering if there are any standard and/or open data sets (perhaps from NASA or something like that) that has the 3D positions of all of the stars and galaxies and stellar structures we've observed in the universe, or what the closest thing is to this.
","['data-request', 'geospatial', 'astronomy']",
Indigenous land shapefiles for world,"
I am not too sure where there are ""tribal"" or ""indigenous"" peoples in every part of the world, but what I am thinking about are:

Native American tribal lands in the United States.
South American tribes in the Amazon areas.
Other potentially non-Amazonian South American tribes (not sure about this, but I think I remember learning about Argentinian tribes).
Australian Aboriginal tribes
Central/Southern African Bushman tribes.
Canadian Aboriginal tribes (Inuit/Eskimo are all I barely know of)
Papua New Guinea (though not sure they have lands)

Those are the only tribal peoples I am somewhat introduced with.
What I would like to see, but am unfamiliar with whether or not tribes (so to speak) exist in these areas, are in these areas:

Central American tribes (maybe Mayan, Zapotec, Aztec are considered tribal and have lands).
China/Tibet
Japan, etc.
Indonesia
India, etc.
Other parts of Africa, etc.
Papua New Guinea
Northern Russia/Tundra areas (Caucasians I think, though not sure if they consider themselves tribes with tribal lands).

Basically I am wondering if any data (shapefiles specifically) exist on the lands of these (potentially) tribal/indigenous peoples. I have found a complete map of tribal lands for the United States, but not for the other ones I listed in the first list, nor these potential tribal groups I listed afterwards.
This looked promising but the link doesn't seem good.
","['geospatial', 'global', 'land']",
Common but out-of-the-ordinary file formats,"
I am wondering what some file formats are that are out of the scope of ""normal"" file formats you typically find on the web. The ""normal"" file formats I'm not considering in this post are:

Image formats like png
Video formats like mp4
Compression formats like zip
Audio formats like flac
Document formats like pdf
Source code formats like xml, js, rb, java, etc.
Plain text formats like txt
Data formats like csv

Some ""out of the mainstream"" file formats that I am looking for in this post are things like these (the few ones I know about):

FASTA format for nucleotide sequences
Mass Spec formats
Mol file format for 3D chemical structures.
KML and Shapefile formats
RDF and JSON-ld

Basically I just know a few file formats in the fields of Biology and GIS/mapping. A few others that might fit this ""out of the ordinary"" concept are SQL dumps or database dumps, or logfile formats like syslog.
I am just wondering if one could list any major common yet out of the ordinary ones (out of the ordinary mainly because they are in specialized fields), such as those from these fields, or other fields not mentioned.

Physics
Other Chemical/Biological/Genetic ones (for example, I will have to see if there are MicroArray formats, or Gel Electrophoresis)
Medicine/Hospital tools for their visualizations or records.
Point clouds
Earth science / Geology / GIS that I have missed
Astronomy data formats.
Major video/audio ones that may be easily missed (like maybe closed captioning is a format, I don't know).
Standard metadata formats (not sure about these if they are file formats yet).
Sports records.
Financial stuff formats.

Again, I'm only wondering for the major ones that are out of the ordinary that you would encounter as common in these (or other major) industries. I know there are thousands of file formats haha, so not looking for a comprehensive list or anything, just mainly want to get introduced to the major ones that are out of the ordinary but common. Instead of specific formats it could just be classes of formats too, that works as well. Thank you.
","['geospatial', 'medical', 'sports', 'data-format', 'biology']",
shapefiles of the electoral zones of Rio de Janeiro,"
I'm looking for the shapefiles of the electoral zones of Rio de Janeiro in 2018. Does anyone know where I could find it?
","['data-request', 'geospatial']",
Farm/Cropland data,"
Been looking through this but haven't found anything related to shapefiles mapped to crops on land. In particular I am wondering if there is data on the plots of land mapped to the specific crops on the land, down to the scale of a county/town/village across the world. If not, what the major sources are and where the specific / detailed town-by-town ones would be if there's not a central source like the USGS or USDA (like if I should just look at the nation websites for each place, or whatnot).
Other searches I've done:

https://catalog.data.gov/dataset?metadata_type=geospatial&ext_prev_extent=-142.03125%2C8.754794702435618%2C-59.0625%2C61.77312286453146&q=farm&res_format=ZIP&res_format=CSV&ext_bbox=&sort=views_recent+desc&ext_location=
https://catalog.data.gov/dataset?q=crop&sort=views_recent+desc&res_format=ZIP&res_format=CSV&ext_location=&ext_bbox=&ext_prev_extent=-97.119140625%2C7.667441482726068%2C-86.748046875%2C16.25686733062344

This looks like one small piece, but just for a specific year and place, and I don't think it's free/open.
","['agriculture', 'land']","Census of Agriculture (Ag Census) has this data, but you are going to have to put it together.
It goes down to FIPS Code level, so basically localities, and you'll need County Level data, plus the shapefiles."
Site that provides up to date list of programming languages/frameworks to open source repositories using it?,"
When you are learning how to program in a certain language or with a particular framework, it is very useful to have an actual real-world example of that project being used somewhere in the open source community.
Has anyone stumbled across a particular updated website or online resource that provides OSS source code links (like github, sourceforge, etc) to programming languages / frameworks?
This would be especially useful for software engineering professionals who need to learn a new language/framework and want to skip the ""Hello World"" and get right to something useful.
","['uses-of-open-data', 'programming']","Open Hub has something almost exactly like this, although I don't think there are specific pointers that say ""we use this code, like this, here"".  Firefox's profile profile shows  some of the data they provide for open source projects.  Github's annual State of the Octoverse provides some level of details about what you are asking to."
"Are there any available lexical databases for English, containing predicate-argument (relation-role) information?","
I am looking for a database (something like WordNet) containing predicate-arguments information (also known as relations-roles). I.e. what are the arguments of a given predicate?
For example,
loves(lover, beloved)
'loves' is a predicate/relation; and 'lover' and 'beloved' are the predicate's typical arguments (relational roles).
I am familiar with WordNet, but it contains mainly information about hypernyms and hyponyms.
Are there any available databases containing such information? If there are, it would be perfect if they could be accessed through Python!
","['python', 'wordnet']",
Are USAID datasets available for download?,"
I just signed up for an account to the DDL. I've tried to access three datasets and receive the same message in each instance; ""You do not have permission to view this dataset"". I've tried logging out and back in and receive the same message. Are all datasets posted to the DDL available for download and if so, am i receiving this message in error?
",['usaidopen'],"Hello Charles and thank you for your question.  Not all datasets on USAID's Development Data Library (DDL) [https://data.usaid.gov/] are publicly available for download.  Some are designated as private, intended for internal USAID use.  Please email dataservices@usaid.gov to request access to specific non-public datasets on the DDL and the team will begin work on your request.Best wishes,
Morgan Daniels"
Sources for detailed LIDAR-based ground cover classification data? (USA/New York State),"
Does anyone know of a source of processed LIDAR data that shows heights/elevations of the understory and of the tree-tops at around 1 meter horizontal resolution?  I'm also looking for density maps1 for the understory (ideally 0 to 2 meters AGL).  So far I've only been able to find bare earth DEMs for the area I'm working in (New York State, USA).
Here's the data I've found so far:

New York State LIDAR point clouds
New York State LIDAR-derived bare-earth 1m DEMs
LIDAR point clouds (United States) (search for Elevation Source Data (3DEP) - Lidar, IfSAR)

1 e.g. returns per square meter less than 2 meters above ground level
Something like this (B & C) is  what I'm looking for: 
Credit: EROS Fire Science Team, Earth Resources Observation and Science Center. Public domain.
https://www.usgs.gov/media/images/understory-eros-lidar
","['data-request', 'usa']",
Chess PGN with time control,"
I'm looking for PGN that has time control containing all FIDE classical chess games.
If that cannot be found then I would like PGN of FIDE classical games for high rated players that have time control, most PGN I've seen do not include the time. The data has to be free or for a negligible price since it's for a side project.
","['data-request', 'sports', 'games']",For example:43rd World Chess Olympiad 2018 (September 23 - October 6): 5000+ gamesWomen's World Chess Championship Tournament 2018 (November 2 - 23): ~140 gamesWomen's World Chess Championship Match 2018 (May 2 - 29): 10 gamesSee also FIDE Calendar.
Open API for occupations and skills,"
I'm looking for an API or other service with a taxonomy of occupations, skills and so forth in a structured or unstructured description.
",['labor'],
"Total Return of US S&P 500, last 50-years","
While price data is easily available, total return data is a bit difficult to find free/open sources for. I am not looking for some massive data set that goes back to Galilean times, or covers small caps in tiny economies. I just need last 50 years or so of US S&P 500 or similar large cap stocks.
","['data-request', 'usa', 'finance']",
Tallinn APC & AVL data for public transport,"
I am looking for automatic passenger counts (APC) and automatic vehicle location (AVL) datasets for Tallinn public transportation system. Any ideas where I can find them? 
Or if there are no such data publicly available are there any other cities that make such datasets publicly available? Are there any other interesting datasets to research public transportation as a whole?
Any ideas?
","['government', 'transportation', 'city', 'public-transport']",
NMMAPS availability?,"
The National Morbidity, Mortality, and Air Pollution Study (NMMAPS)
was a large national study of air pollution and health in the United States. The  study examined 108 cities spanning the years  from 1987 to 2000. 
However initially it was available at Health and Air Pollution Surveillance System (iHAPSS), after 2011 it was removed from the site.
Could you advise where from can the NMMAPS data be obtained?
","['geospatial', 'medical', 'time-series', 'environment']",
Code and data for FAO/GAEZ crop suitability,"
Is the underlying data and code used to construct the crop suitability measures from the FAO/GAEZ (http://gaez.fao.org) available anywhere? Or for any similar crop suitability measures?
",['agriculture'],
MS Outlook versions for corporate users,"
I am trying to find what proportion of corporate Outlook users use which desktop version of MS Outlook or Office 365.
That's it, really. Does anyone know?
",['email'],"This page is undated, but Google returns it from a search of the last year. It says Today, one out of every five corporate employees uses an Office 365 cloud service"
Road vehicles database,"
I'm looking for a regularly updated road vehicles database (cars/trucks/motorcycles etc). It should contain:

Manufacturer 
Name
Year
Dimensions (Length and width and if height is included it would be great, in metric units preferably)
Few pictures (Optional)

If the database can include all road vehicles ever manufactured, or the popular ones, that would be awesome. I would prefer to download a SQL/CSV file or whatever. 
It would be great if the database is updated regularly and Have a REST API, so that if the  car I'm looking for cannot be found in my database, I can check the original database  for updates. It would also be great if the database have a known release schedule so that I could run cron to fetch updates periodically.
","['data-request', 'cars']","You never said if seek for a free or you feel comfortable with a paid database? Anyway, i am currently working with one data provider - mainly using the database for the engine displacements of Land Cruisers.The data is in XML, not CSV but i guess it could be converted.New, old, regular brands from around the world, concept and prototypes included; 2-3 times a day updated; there's an option for images, i think but you have to ask;Check the technical parameters offered. Here's the demo "
Where can I download a raster or shapefile of hillshade of the US?,"
I need a basemap to show topography or hillshade of the U.S. but I cannot use the internet so none of the web services or basemaps will work. There has to be some way to get simple topography or contours as an offline file...
","['data-request', 'geospatial']",
downloading cctv video or live video,"
Is it possible to download long CCTV footage, or even better streaming it live? So if you want for example to write a program that recognizes objects from a video that would be possible.
Long CCTV videos are needed in order to develop the prototype. Live streaming is preferred in order to determine the efficiency of the algorithm in real time. 
It would be nice if the cctv videos are categorized, cctv for a business, cctv for the highway, cctv of people, cctv of cars, etc. 
So it would be nice if I can pick the location of the cctv and what it is filming for the most part. The data should be free or for a negligible price. It  
","['data-request', 'real-time', 'video']","Based on my comment, you can use live webcam feeds instead of official CCTV. Or even live youtube streams.Consider using insecam.org as your source. License unknown.The world biggest directory of online surveillance security cameras. Select a country to watch live street, traffic, parking, office, road, beach, earth online webcams. Now you can search live web cams around the world. You can find here Axis, Panasonic, Linksys, Sony, TPLink, Foscam and a lot of other network video cams available online without a password. "
Historical Walmart Stores Data set,"
I'm trying to capture a historical list of Wal-mart stores. I need store ID, store name, longitude, latitutde, address, city, state, zip, services, store opening date, and store closing date (if the store shut down). I'm trying to connect to the Wal-mart API but not able to get an access key. I work in R. Any help would be awesome.
Thanks.
","['data-request', 'historical', 'programming']",
Words and Frequency/Probability of Spelling Mistakes,"
Data Request
I am looking for some data that contains English words along with the probability that a person will spell it incorrectly.
The probability depends on various factors. However, a simple measure would be frequency of wrong spellings divided by the total frequency of the word.
Alternatively, the data can also be of a word with a class denoting its likelihood to be mistaken.
Context
I want to create a basic NLP project in which I will generate a prediction - given a word, what is the probability of wrongly spelling it.
Region
An US/UK based English variant would be appreciated, although other combinations are also good.
License
Open data.
Format
A CSV based format would be appreciated. Some examples are given below.
Word,Frequency,FrequencyOfErrors
apple,100,2
asphyxiated,54,14
...

OR
Word,ProbabilityOfError
apple,0.02
asphyxiated,0.26
...

However, it is not necessary, and a general program-friendly format would suffice.
Authority
Data provided by some reliable source, for example, an academic body, would be good. Crowdsourced data would also be sufficient.
Requirements
There should be a large number of words - 20,000 or more.
The individual words should have moderately high frequencies of occurrence - 50 or more.
Non-answers
I found this topic which provides age of acquisition of various words. However, I believe there is very little correlation between making a spelling mistake and knowing the word.
","['data-request', 'english']",
Concordance between ISIC Rev 2 and either SIC industries or NAICS industries,"
I have a big dataset, with variables at the industry level. This dataset is presently at either the NAICS 1997 classification, or the SIC 1987 classification. I want to merge this dataset with an existing dataset which contains industry level data at the 3 digit ISIC Rev 2 level. The former (either NAICS or SIC) contain 400+ distinct sectors, whereas the ISIC contains only 28. As such, there should be a many to one mapping from either of the former to the ISIC Rev 2. I am unable to find concordance tables between either the NAICS or SIC to the ISIC Rev 2 (specifically 3 digit) classification. 
Any help is much appreciated. 
",['industry'],
Per capita surface area for (car) transport since WWII,"
It is an obvious phenomenon that the surface area each person 'requires' for transport has been increasing over the past decades (with growing wealth), because we have more cars.
I'm interested in the actual figures since the second World War.
How much surface area per person is taken up by roads, parking spaces, etc. In 1950, 1960, etcetera?
Notes:

I'm only asking for cars because I think the space taken by other forms of transport is very small in comparison
I'm especially interested in Europe or my country, the Netherlands, but do not exclude other regions
Any data format is fine
Related: A similar question for living space.

","['data-request', 'historical', 'transportation']",
Where could I find U.S. county-level data on the number of smartphone users?,"
I'm looking for panel data at the county, city, or state (worst case) level for the United States showing the number of smartphone users or the size of the smartphone market in these locations. This could be expressed in either absolute counts or as percentages. Ideally, I would want historical data from 2017 or 2016 to 2008, but anything since 2010 would also work. 
Alternatively, I am also looking web device usage data at comparable levels. That is, a look at what type of devices were used to access the web. This, too, would have to cover the same time periods.
I am also open to commercial data sources, but would prefer open data. The closest answer I have found so far was this: Cellphone vs Smartphone usage? but it still doesn't fully answer the question.
",['data-request'],
What business cases can be solved with open data machine learning models? [closed],"







Closed. This question is opinion-based. It is not currently accepting answers.
                                
                            











Want to improve this question? Update the question so it can be answered with facts and citations by editing this post.


Closed 2 years ago.







                        Improve this question
                    



I am not sure if this question is on-topic or not:
Do you know of any business case where open data machine learning models can be useful? If so, can you point to the open data and the business case it provides?
I am asking this question, because I was thinking about open data and machine learning and how data scientists who create such models can profit from it.
I created a small prototype marketplace for machine learning models to sell and buy pfa, pmml or onnx models: https://machine-learning1.sharetribe.com/infos/about
I thought to pose this question to the data science community so that others can provide some guidance on what can be done with open data and machine learning.
Thanks for you help. Also I am not sure how to tag the question.
",['machine-learning'],
How can I increase the number of results returned?,"
The following request: 
https://api.data.gov/ed/collegescorecard/v1/schools?fields=school.name,school.city,school.state,school.zip,school.carnegie_size_setting

Returns just 20, how can I get all 7175?
{
  ""metadata"": {
    ""total"": 7175,
    ""page"": 0,
    ""per_page"": 100
  },
  ""results"": [
   ....

","['data-request', 'data.gov', 'collegescorecard']",
Seeking GIS data (points) for the Giza pyramids including Z-value for the tops of pyramids,"
I am not even sure if this data is publicly available or not, but  I am looking for something like this that has been surveyed with a z value (don't care what vertical datum).
It doesn't matter the formats or spatial reference, as long is it is defined.
 
","['geospatial', 'historical']",
How can we install CKAN on Windows using IDE?,"
I wanted to install CKAN using IDE such as Eclipse+ Pydev on Windows. Is there any documentation/Steps for the same ? How will we connect Apache Solr and PostgreSQL when using Eclipse + Pydev IDE ?
What dependencies may be required to make it work?
",['ckan'],
Looking for US percentage of population overweight or obese over last 50 years,"
I've seen other charts that reference data from the CDC, but I haven't found anything useful on their site, and they don't return emails.
Thoughts?
","['data-request', 'government']",
Need road condition data for the Washington DC area,"
I am taking a data science class and we are supposed to develop our own final project idea.
The general context of the idea I am considering is that there is a group that meets once per week. Based on various features, I would like to see if it would be possible to predict the attendance. One factor, which may be difficult to obtain, that would affect attendance would be the road conditions. For example, several days after a big snow storm or during one, the attendance would be affected. I figure there is a chance such data would be available, as it would be for the Washington DC metro area, but I am not sure where I might find it.
","['data-request', 'weather', 'transportation', 'traffic']",
Looking for gis data on world linguistics by location,"
Looking for geospatial information on linguistics. 
Looking for world wide data with national and subnational data. Data should include what regions speak which language(s). 
Does this data exist?
","['geospatial', 'language']",
Administrative boundaries for historical political entities?,"
Similar to Seeking administrative boundaries for various countries?, do you have any data sources for historical political entities, and their administrative sub-units?
Data from any continent, any period in time works.
Edit: Some examples of shapefiles I would like to have:

Kingdom of France and its duchies & counties: example.
The British Isles: example.
List of states under the Holy Roman Empire: example.

","['data-request', 'geospatial', 'historical', 'politics']","NHGIS has historical data for the United States
Great Britain Historical Geographical Information System (GBHGIS)
The Great Britain Historical GIS (Main)
GBHGIS Data Access
National Heritage List for England (NHLE) Listing Data
The US  National Historical GIS
The China  Historical GIS
Chinese Civilization in Time and Space
Taiwan History and Culture in Time and Space
The Belgian Historical GIS
The Historical GIS for the Netherlands
Historical GIS Germany
Russian Historical GIS
Japan Historical GIS
China Historical GIS The Digital Atlas of Roman and Medieval Civilizations (DARMC)
Historical GIS Data resources listing via David Rumsey Map Center
Historical GIS Research Network
HistoricalGIS.org via Wayback Machine
Pleiades - Digital Ancient World Historical Atlas
ORBIS: The Stanford Geospatial Network Model of the Roman World
CShapes - historical maps of state boundaries and capitals in the post-World War II period
European GIS-data-infrastructure on historical national and regional administrative boundaries and historical place names
Historical World Atlas Repository has global data starting from 2000 BC. "
Can I use another database instead of PostgreSQL in CKAN?,"
After visiting the official documentation of CKAN, I was unable to find why are we using a PostgreSQL database in CKAN from its inception.
Is there any way to use another database with CKAN?
","['ckan', 'database']",
Where to find the Public Water System's companies' annual survey report?,"
We are looking for the aggregate data for all US water companies' annual survey. This may also be called Consumer Confidence Report.
We are looking for the detailed findings like the hardness of the water or the pH level.
",['usa'],
Seeking shapefiles on publicly owned land in UK?,"
Where can I find shapefiles of land owned by the National Health Service (NHS), Local authorities, universities and Ministry of Defence (MOD)?
","['data-request', 'geospatial', 'uk']",
Identifying conventional vs natural drugs,"
Is there a way to identify which drugs are Conventional (Allopathic) drugs vs which drugs are Natural (Homeo, Ayurvedic) drugs from open FDA drug label repository?
","['openfda', 'products']",
European Postal Shipping Costs,"
I am looking for datasets or ideally public APIs which would provide an estimate for postal shipping costs between 2 countries in Europe.  
For example, given object size/dimensions/weight --> return an estimate for the costs of shipping it, between any 2 countries (or just between country A and B - it would be a start for me).  
Does anyone know of such a service or where could I look further? (searching brought me to several such resources but for US only - I am specifically interested for the EU).
",['europe'],
Crime Data in Canada,"
Does anybody have any idea where I might find data regarding crime in Canada or whether or not this data even exists?
","['geospatial', 'government', 'city', 'crime', 'canada']",
"Where can I find city zoning district in Dallas, Texas data?","
I need some open data source where I can download zoning areas of Dallas,  Texas. I have tried to find it using official city GIS data, using ArcGIS online but not even close to find that. 
","['geospatial', 'uses-of-open-data', 'city']",
Davis-Bacon wage dataset,"
Is anyone aware of a method or source for exporting Davis-Bacon wage information as a csv dataset? 
https://www.wdol.gov/archdba.aspx
Assuming you have a particular DBA WD number you are interested in (e.g. WA36) and you wanted to see the relevant wage data across a multi-year time period. 
","['data-format', 'csv']",
How do I get my data indexed by Google Dataset Search?,"
Google now offers Dataset Search (beta)
https://toolbox.google.com/datasetsearch

Dataset Search enables users to find datasets stored across the Web through a simple keyword search. The tool surfaces information about datasets hosted in thousands of repositories across the Web, making these datasets universally accessible and useful.

How can I get my dataset indexed there?
and specifically, if I don't want to host the data myself:
Are there any data platforms/portals that allow user uploads and will automatically index my dataset?

(related: top-voted question A database of open databases? and the Dataset Search answer)
","['data-request', 'releasing-data', 'metadata', 'search-engine']",The easiest way to make your dataset eligible to be included in Dataset Search results is to upload it to a repository that adheres to metadata standards used by Dataset Search. There are many such repositories. You can try the following:If you don't want to use an external repository you will need to embed metadata on the webpage you host that describes the datasets. More information on this here.
Looking for word frequency data for the Google Books ngrams,"
I have downloaded all the single words from Google Books ngram data (http://storage.googleapis.com/books/ngrams/books/datasetsv2.html) and I could write code to aggregate it all generate word frequencies. However I have seen it mentioned (e.g. https://www.frontiersin.org/articles/10.3389/fpsyg.2011.00027/full) that Google has published word frequency data besides all the raw words. I am unable to find this data. Does anyone know where I can find already computed word frequencies for the Google Books data? 
","['data-request', 'language', 'english']",
OpenFDA - Differences Between Dashboard and API Results,"
I want to find the numbers of cases of each adverse effect for some drugs in the FAERS database. I am using Keytruda as an example.
I ran the API to count the adverse events for Keytruda: https://api.fda.gov/drug/event.json?search=patient.drug.openfda.brand_name:keytruda&count=patient.reaction.reactionmeddrapt.exact
and then looked up Keytruda on the FAERS Dashboard to verify I was using the API correctly, but the results did not match.

For instance, for the adverse event ""malignant neoplasm progression"" the API returns 2100 cases while the Dashboard returns 1613 cases. While most of the counts are higher in the API, some (like ""Product use in unapproved indication"") are lower.
What explains the difference between the numbers of cases between the API and the Dashboard? Does the dashboard do some additional processing? Or am I wrong in assuming they are pulling from the same data set?
","['api', 'openfda']","The discrepancy is explained by the fact that you are querying against the harmonization openfda record in openFDA, while FAERS itself does not have such concent: FAERS Dashboard is likely pulling data based on medicinalproduct value.This query will bring you closer to the Dashboard:https://api.fda.gov/drug/event.json?search=patient.drug.medicinalproduct:keytruda&count=patient.reaction.reactionmeddrapt.exactStill not an exact match, however. Unfortunately, we have no insight into the Dashboard and do not know how it was built, which is why it is hard for us to give a 100% accurate answer."
KEEPA API Experience,"
I'm trying to pull historical prices and BSR from about 3,000 ASINs on Amazon, but need something built to interface with Keepa's API.  Does anyone have any experience with this?  If so, is there a software program that can be licensed? Or does it have to be customized third-party software?
","['api', 'json', 'python']",
Public dataset with job satisfaction and six digit NAIC classification,"
Does anyone know of any datasets that have any measure of job satisfaction and six-digit industry classification (NAIC)?
",['data-request'],
What CKAN integration/plugins are available for connecting to Hortonworks/HDFS/etc.?,"
I'm curious as to what options are available for integrating CKAN with external data sources as well as external data catalogs specifically as it relates to: Hortonworks / Cloudera / Hadoop / HDFS / Hive / HBase / etc.

Are there methods for pulling data from Hive/HDFS into CKAN and serving up the data from within CKAN?
Are there methods for pointing to or referencing external data catalogs such as Apache Atlas from the Apache Hadoop stack/ecosystem?

Related questions I found:

https://stackoverflow.com/questions/49976622/what-kind-of-sources-can-integrate-ckan
What kind of sources can integrate CKAN?

",['ckan'],
Public dataset for spanish news articles with title and content,"
I am wondering if there are any public datasets of news in SPANISH similar to this dataset.
Which consists mostly of ENGLISH news. There is a similar question already answered here.
However, I require the news to be in Spanish.
","['data-request', 'machine-learning', 'nlp']",
OpenFDA: Programmatic/Machine Readable Biologic License Application Data,"
Is there a way to programatically (or manually) download the biologic license applications data in a machine readable format?
Here is a PDF that at the bottom has the 2015 approvals, https://www.fda.gov/downloads/Drugs/DevelopmentApprovalProcess/HowDrugsareDevelopedandApproved/DrugandBiologicApprovalReports/NDAandBLAApprovalReports/UCM486442.pdf
but I don't see those BLA applications in this data (link at bottom of page).
https://www.fda.gov/drugs/informationondrugs/ucm079750.htm
Thanks!
",['openfda'],
Q: Boolean Structure,"
I'm looking for help to construct a search with multiple parameters. Is this possible? I'm basically performing this search to try to catch reports that may have been labeled with the incorrect product code. I believe this report should show results for a couple reports with DQY product code and 246 results, but right now it is only giving 243 results.
https://api.fda.gov/device/event.json?search=date_received:[20130401+TO+20180430]+AND+device.manufacturer_d_name:(Jude+Medtronic)+AND+device.device_report_product_code:DRC+device.brand_name:(Needle+AND+(Transceptal+Brocken+BRK)))
Please let me know if more info is needed.
Edit 10/20/2018.
After testing my claim, I've realized the brand_name field is exact, and requires the search terms to be in parentheses. The following is my successful search:
https://api.fda.gov/device/event.json?search=date_received:[20130401+TO+20180430]+AND+device.manufacturer_d_name:(Jude+Medtronic)+AND+(device.device_report_product_code:DRC+device.brand_name:(%22needle%22+AND+(%22transseptal%22+%22brockenbrough%22+%22brk%22)))&limit=100&skip=0 
",['openfda'],
"Hazard Maps shape files that are not in NAMRIA, LiPAD, and PhilGIS (Philippines)","
Where should I find those updated shapefiles necessary for creating Hazard Maps? 
I'm about to create Hazard Maps for San Pascual, Batangas, Philippines but I am having a hard time looking for resources.
As of now, I only have shapefiles for:

Flood Susceptibility Map  
Rain-induced Landslide  and
Storm Surge.

","['geospatial', 'openstreetmap', 'geohazard', 'data-mapping']",
Wikimedia Commons API image by category,"
I'm trying to retrieve a list of urls of images in Wikimedia Commons from a particular article. I want to either search article by category and retrieve images from them, or filter images by category. I've tried including incategory:category_name in the titles string of images and article searches as well as [[Category:category%20name]] and Category:category_name to no avail. I'm given the impression it's possible, and the advanced search functionality within Wikipedia would imply so, but how to achieve this through the API is not clear.
Specifically, I'm interested in grabbing these images through the Mediawiki API.
","['images', 'wikipedia', 'wikimedia-commons']","Yes, Wikimedia Commons exposes MediaWiki API.Basically, your query should be the following:https://commons.wikimedia.org/w/api.php
?action=query
&list=categorymembers
&cmtitle=Category:Watercolor%20paintings
&cmlimit=100
&cmtype=file
&format=jsonThe API:Categorymembers module can be used as a generator.If you need real URLs of images (not their File: titles), pass results into the API:Imageinfo module:https://commons.wikimedia.org/w/api.php
?action=query
&generator=categorymembers
&gcmtitle=Category:Watercolor%20paintings
&gcmlimit=100
&gcmtype=file
&prop=imageinfo
&iiprop=url
&format=jsonIf you need all 1,723 images (which is more than 500), read about generators and continuation."
Methodology for comparing FEC campaign finance data to congressional votes,"
I am trying to compare a database of campaign finance contributions to candidates with a database of congressional votes and see if I can unearth any causal relationships between campaign finance sources and legislative action.
Causal relationships are difficult to establish of course, because it is not necessarily obvious whether a donor is supporting a candidate who agrees with their policy objectives, or is offering money to change a candidate's policy objectives. There are many many practical difficulties with determining the sources of campaign financing, which I will ignore for the purposes of this question.
Therefore, my primary assumption is that campaign finance contributions from a given source would have a strong correlation to a certain voting block for a piece of legislation relevant to their interests.
Suppose we take a list of campaign contributions from the following PACs to federal congressmen and senators:

American Healthcare Association PAC
Boeing PAC
AFLAC PAC
GlaxoSmithKline PAC
American Academy of Family Physicians PAC (FamMedPAC)
Eli Lilly and Company PAC
Lockheed Martin Employees PAC
And we run an analysis of all congressmen and senators' votes on only one piece of legislation, something healthcare-related like the Affordable Care Act. We would expect that Lockheed Martin and Boeing's contributions to have a comparatively little causal relationship on a representatives' vote, and the rest of the PACs (which are healthcare-related) would have a strong relationship, either with a vote for, or a vote against, the legislation.

How would you run this analysis? Linear Regression seems silly because a vote is a binary yes/no value.
",['openfec'],
Connected components of Facebook,"
On the basis of publicly available data, is it possible to reasonably estimate:

The size of facebook.com's largest graph-theoretic connected component, where two users are connected if and only if they are friends?
The number of connected components?

","['api', 'social-media', 'network-structure']",
Where can I find Argentina Admin 3-4 & City .shp?,"
I am able to find Admin 0-2 Boundary data from HDX, however, I cannot find a data source for admin3-4 polygon boundaries for Argentina.
Can anyone point me in the correct direction?
","['data-request', 'argentina']",
Can we use DBpedia for identifying Polysemy of words?,"
I want to detect words with Polysemy in a given text in descending order. That the word that has multiple meanings should be in the top of the list, and words with least Polysemy should be in bottom.
In other words, I want a list of words with the number of ""meanings"" for each word (i.e. with highest Polysemy).
Is there a way to do it using DBpedia or any other resource in open data cloud?
","['uses-of-open-data', 'rdf', 'dbpedia']","First, I assume all NLP-related aspects are subtracted from your question.DBpedia is considered as belonging  to the Linguistic Linked Open Data Cloud (interactive SVG), but I'd suggest to try more specialized resources, e. g. RDF version of BabelNet.One can't retrieve the whole list of English words with the number of meanings on the public endpoint.
Probably one could download a dump for local querying.For relatively small sequences of words you could write something like this:Try it!Results of the above query:""Senses"" of ""drop"" in BabelNet 4.0."
How soon will UN Relief and Works Agency for Palestine take effect?,"
Where can I find information about how much money UN Relief and Works Agency for Palestine receives from the United States currently? Does the president have the power to cut off aid immediately, or does he need the approval of Congress to do that? If aid for the UN Relief and Works Agency for Palestine is already legislated, how long is that funding set aside, and how often does it need to be renewed?
","['data-request', 'usa', 'research', 'usaidopen']",
Are there any GIS crime datasets open to public?,"
I am wondering if there is any online resource where GIS crime data are freely available to public. I am interested in shapefiles representing, for instance, neighborhoods, census tracts, location of (say) shops, banks, ATM, and the like, and location of crime events (theft, burglarly, etc).
I am interested in those kind of data just to produce simply visualizations and/or attribute or spatial queries, with the aim to show the (basic) use of GIS in the analysis of crime data.
Ideally, the level of detail should be the city, but regional o super-regional levels would work as well.
","['geospatial', 'crime']","There are numerous instances of GIS crime data available to the public, at least in the US, probably too many list and/or no one has done an entire audit of the Criminal Justice open data space.The overwhelming majority of these datasets are at the local level, on the locality's gov site and/or the locality's criminal justice agency's site (if they aren't the same; most are). For example, Richmond, Virginia's police department shares its data on Richmond's government site. Some even have dedicated data portals specifically for Police/Criminal Justice data, though CJ is a stretch here: the vast majority of them are focused on where crimes occur, which are part of CJ, but there is much more to CJ then that. Furthermore, no crime dataset I've ever come across includes white collar crimes, so they are all inherently flawed. Not to mention that most of them don't publish data about internal affairs and/or complaints about them. I'll get off my soapbox, just needed to make those points about how flawed Criminal Justice Data is in America.Here are a few from Virginia:
Crime Incident Information Center - Richmond Police
Newport News Police Open Data and NNPD Daily ReportsThese datasets are what you seek however, they aren't 100% usable, as they need to be geocoded for GIS. That is almost the de facto standard I have seen around the Commonwealth and assume is the same for the rest of the nation. If you need help geocoding, there are a number of options out there, but in these cases, which tend to be smaller batches, I almost always default to using Google Spreadsheets and a Google Apps Script that does the geocoding for free, in the browser.Here are some datasets that fit what you seek exactly:
Arlington County has always done a great job at sharing open data (though their latest approaches to FOIA make all of this suspect), and they geocode their locations for you, Arlington County Police Incident Log as well as provide necessary GIS data overlays one would need to dive more into their data, like Arlington County Police Districts Boundary Map.Data.gov offers a crime tag you can search, which can shed some light into which localities are sharing and what they are sharing, however at this point I'm not sold that their is any main hub for GIS Criminal Justice data, hence the focus on localities here.DOJ and FBI have their massive datasets and some do indeed have GIS data included, I've just always found them...lacking, to say the least. That said, looking at the FBI's UCR Crime Data Explorer, I just snagged Virginia's 2017 dataset, and it does have a locations CSV.
edit - You'll have to figure out the GIS portions, as I said these are incredibly lacking.Here's FBI UCR GIS datasetLastly, if this is for the US, simply approaching your local Law Enforcement Agencies and/or local government is not necessarily a bad idea. Numerous GIS datasets have been released in this approach from what I've seen, some via FOIA, but most from simply engaging the officials and asking clearly/directly for what they want."
"Publicly aviailable data sets, training and commerical usage","
If you train a machine learning model from publicly available (Open) data sets such as COCO or VOC (which have there own respective licenses concerning commercial usage), can you use that model for commercial purposes regardless?
","['machine-learning', 'licensing']",
Open data sets and commercial usage,"
If you train a machine learning model from publicly available (Open) data sets such as COCO or VOC (which have there own respective licenses), can you use that model for commercial purposes?
","['machine-learning', 'licensing']",
Wikidata on all Trump's executive orders,"
I'd like a wikidata query that returns all executive orders signed by President Trump.
This query gets all executive orders:
https://query.wikidata.org/#SELECT%20%3Forder%20%3ForderLabel%20WHERE%20%7B%0A%20%20%3Forder%20wdt%3AP31%20wd%3AQ1338798.%0A%20SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22%5BAUTO_LANGUAGE%5D%2Cen%22.%20%7D%0A%7D
I think it should be possible by using the executive order number and limiting the executive orders to one with a number above 13764.
",['wikidata'],"Try:on Wikidata Query ServiceHowever, apparently many of Trump's executive orders currently do not have Wikidata items and therefore won't appear in the results, e.g. Executive Order 13819, so you might want use other sources like List of executive actions by Donald Trump."
Unsolved murder GIS datasets,"
does anyone know if there are any datasets published regarding unsolved serial murders within the United States? 
",['crime'],
Data from minimal human decision-making tasks,"

Data: The results of studies in which people were asked to make the same sort of decision many times (say, at least 30 times), and in each case the decision has to be somewhat arbitrary because the subject isn't being rewarded for anything, nor is there a right answer. For example, subjects might be asked to press one of two buttons, or to push a joystick in one direction or another. Ideally, the dataset would have not just each subject's choice on each trial, but also other contextual information such as reaction time, cursor movements if the subject is using a computer mouse, etc.
Context: I'm a statistician and psychologist interested in predictive models of decision-making, and I'd like to try my hand at predicting decisions, within subjects, in a task where the decision to be made is essentially arbitrary. I hope that by so doing I can learn about the tricker factors involved in more meaningful decisions.
Region: Any.
License: Preferably free-as-in-freedom.
Format: Preferably free-as-in-freedom.
Authority: Any.
Requirements: No other requirements.
Non-answers: There have been many studies in which subjects are asked to generate random sequences, as by pressing one of two buttons with the goal of making the choice of button as random as possible. I'm interested in cases where subjects aren't told their choices should be random. The fewer instructions and cues on how subjects should choose, the better.

",['data-request'],"I'm now conducting such a study, which I call Donkey. The data is freely available under the ODbL and the DbCL."
Where do I get data on newly formed businesses in the US?,"
Is there a gov API or dataset that I can get, on newly formed businesses? Data like biz name, address, tax ID, owner name, type of business (restaurant, laundromat...) etc?
","['data-request', 'usa', 'business']",
Using OpenCorporates API to return officers of a company,"
I have a list of a few thousand company LLC names and jurisdictions from states around the US. I would like to use the OpenCorporates API to search for the company in the relevant jurisdiction and return the names of the company’s officers (I realize that the officer's data is not available in every jurisdiction).
From the API documentation and a little testing, it seems like this isn’t currently possible. The “GET companies/search” call returns much of the information I’m interested in, but not the officers for the company. And “GET officers/search” doesn’t allow me to input the company name or ID as a parameter.
Has anyone been successful in getting officer names by searching company name or ID? I've been using the following case as an example:
Company page (has officer info): https://opencorporates.com/companies/gb/05217588
API (no officer info):
https://api.opencorporates.com/v0.4/companies/search?q=28+beer+road&jurisdiction_code=gb
API documentation is here: https://api.opencorporates.com/documentation/API-Reference
","['api', 'opencorporates']",
Wind Speed Map of US,"
I source wind statistics data that i can use to create Max, Min, Mean wind speed maps for the entire US.
I need to download it as a shapefile, geotiff or geojson.
","['geospatial', 'usa', 'weather']",
US Fire Hydrant locations data,"
I am looking for the location of fire hydrants all over the US.I'm particulalrly interested in Rhode Island, Massachusetts, Maine, New Hampshire. 
","['data-request', 'geospatial', 'usa']",
Historical USA weather forecasts,"
I'm looking for a historical USA (specifically Chicago, IL) weather forecast dataset. Temperature forecasts would suffice, though the more data, the merrier. I know this has been asked a lot of times in the past, but nothing worked for me. Here's what I found so far:

Both links in the accepted answer to this question are broken
DarkSky API can't provide historical forecasts, but only historical observations and future forecasts
NOAA's Weather Prediction Center archives only provide pictures (either GIFs or PDFs), with no textual temperature forecast data
The data in this question doesn't seem to suit my needs (not sure how to parse some of it, and the parts that I have been able to parse don't contain historical Chicago forecasts). The answer to that question is relevant only to Europe, and I need USA weather forecasts
The best thing I could find was NOAA's Archive Information Request System and Iowa State Mesonet. Both provided historical weather forecasts for Chicago, but they were both very coarse and verbal. For example, the following paragraph appears in a huge text file: "".TODAY...Cloudy. Showers likely in the morning, then a chance of showers in the afternoon. Highs around 70. Northeast winds 10 to 20 mph. Chance of precipitation 60 percent."" This thing would be difficult to parse, and would probably not be worth it because it just says ""Highs around 70"".

So is there anywhere from which I could get historical data that:
1. Contains Chicago temperature forecasts
2. Is easy to parse (e.g. in csv format)
","['data-request', 'weather', 'historical']",
Dataset about variation in human body weight during the day,"
I need a dataset that monitors the variation in human body weight at different parts of the day, preferably of Indian/South Asian population. I did an comprehensive research and pulled some relevant research papers.
The research paper Day-to-day variations in body-weight of young women is pretty old. Do we have newer research that includes data taken at multiple times a day?
I know the DHS has good datasets but I could not find the dataset I am looking for.
Preferably I want a dataset of people who were currently loosing weight.
","['data-request', 'india', 'asia', 'north-america']",
How to determine the elevation of the average citizen of a given region?,"
In a recent course on steam systems for heating and humidification in buildings, we were instructed to use the atmospheric pressure at sea level as a starting point for calculations related to pressure, temperature, and enthalpy of steam at various points in a given system.
In other areas of building design we use averaged values from censuses and recorded weather data, so why not do the same for elevation?
Is there a data source which contains (or which could be used to obtain) the average elevation of a citizen of a given region, such as nation, state/province, or county? 
Obviously if I know the city of a proposed or existing building I can easily look up the elevation there, but when analyzing proposed buildings, or averages of buildings in a given region, mean elevation won't do -- the population-weighted mean would be more appropriate.
","['data-request', 'population']",
NOAA Satellite Data API?,"
Is there an API to access live (or semi-live?) data from NOAA satellites, such as the GOES-R series? I've been searching for weeks, and I know there are ways to manually access data through website file systems, but I'm looking for something more like, for example, the NASA Mars Rover Photos API, or even just a data stream.
","['api', 'weather', 'noaa', 'space']","Where are you searching? The NOAA and all of its child departments/organizations provide a plethora of satellite and API datasets, including satellite datasets accessible via API. The list below is a tiny sampling of all three; I cannot stress enough how much more data there is. NOAA is basically a cornucopia of satellite/API datasets.  API Web Service - weather.gov
Web Services API (version 2) Documentation | Climate Data Online (CDO) | National Climatic Data Center (NCDC)
NCEI Data Service API User Documentation
Tides & Currents Web Services
Advanced Data Access Methods | National Centers for Environmental Information (NCEI) formerly known as National Climatic Data Center (NCDC)
NCDC Satellite Data
NCEI Satellite Data Services
NCEI Satellite Oceanography Group
NCDC's ArcGIS REST Services Directory "
How to download a subset of the reports based on a specific indication of query term?,"
I understand that for performance purposes in my case it will be better to download the data rather than accessing it through the public API. On a practical note I am only interested in a subset of the FAERS reports, for example, only those reports that have Alzheimers disease as an indication or key word. Is that possible.
How can I download a subset of the reports based on a specific indication of query term?
","['openfda', 'download']",
Metadata on scientific articles (economics) conditional to set of queries,"
I am looking for an API/software (free or open source) able to download metadata on scientific articles (economics) according to a set of queries (e.g., words in the title/abstract, keywords, JEL code, year of publication, and journal).
This has to be seen in the perspective of a systematic literature review. 
The IDEAS/Repc (multisource) database contains the information I am looking for, however, I do not get how to systematically download the data.
","['data-request', 'api', 'research', 'metadata', 'bibliometrics']",
How can I get all churches in the USA,"
I'm looking to get info on all churches across the US. Specifically, I'd love to get:

Their address
Denomination
Active/Not
Contact Info (website, email, phone)

and any other info I can get.
",['usa'],
Shanghai Stock Exchange data API,"
A friend asked me to develop a data product around Shanghai Stock Exchange data for him.
I don't think either of us realized that 

Google Finance's API is defunct
Several others only have 1 stock representing a composite of that entire market
Quandl charges a minimal price of $360 for their version of the data

Is there anywhere that would at least let me have some of the data to play with, before making a major investment?
","['finance', 'china', 'stock']","It turns out that you actually can get this data from Yahoo! Finance, but you just need to know the numeric representation of the Chinese ticker symbols of interest.It also requires you to know the exchange in China as that info is not provided (so, for instance, you have to know that the Shanghai stock codes begin with a 6, so if you see one with a 0 or a 2 in the first character that's actually the Shenzhen exchange not Shanghai). In the example above I appended "".ss"" to reflect that."
How to input my API Token into Openrefine,"
I am trying to use Opencorporate's reconciliation service in Openrefine. I have a paid API Token/Key.
Where would I input my API Token/Key?
",['opencorporates'],
Searching for adverse reports related to quality only reported in 2017,"
I'm trying to search for the number of adverse reports related to ""quality"" within the query and only for the year 2017.  I've tried this query
https://api.fda.gov/drug/event.json?search=receivedate:[20170101+TO+20171231]+AND+patient.reaction.reactionmedrapt:%22quality%22
and several others but everything I've done comes up with 0 results and I know there are some within 2017.  I'd like to get down to be able to identify down to pharm_class_epc:""vaccine"" ,""protein"", ""peptide"", and others also.  
But any help with constructing this query to pull data from 2017 first would be a great help.
","['api', 'openfda']","You simply have a minor typo in the field name, i.e. reactionmedrapt should be reactionmeddrapt. After correcting the query returns results as expected: https://api.fda.gov/drug/event.json?search=receivedate:[20170101+TO+20171231]+AND+patient.reaction.reactionmeddrapt:%22quality%22"
Open DICOMweb data,"
I'm developing a university course that has the goal of students building their own DICOMweb viewer in Python using GTK and https://dicomweb-client.readthedocs.io/en/latest/. Unfortunately the data stored in https://dicomcloud.azurewebsites.net is broken. All images referenced through the UID-links in studies and series are missing.
There is also
https://www.dicomlibrary.com/
but they don't provide a standardized DICOMweb-interface but only individual downloads.
Note that the server
https://dicomcloud.azurewebsites.net
used in
https://dicomweb-client.readthedocs.io/en/latest/usage.html#examples
is buggy as discussed in this thread.
",['medical'],
Satellite image data that allows input of a lat/lng and returns radius around coordinates,"
I'm looking for a dataset of satellite image data of the USA that would allow me to enter a lat/lng center and get the satellite image of the area around the center.
I can currently use the Google Static Maps API but their licensing does not allow me to create products off their images which is a requirement. I am looking for open source satellite images that I can use to create new features for a dataset without any licensing restrictions.
","['geospatial', 'usa', 'images', 'aerial-photography']",
Is there public database about subsidiaries of companies?,"
I have a list of suppliers I need to consolidate. I want to make explicit that company A is a brand or a subsidiary of company B.
I tried to see if Wikimedia or other public sources listed on Google Dataset have a structured database with this information, with poor results.
Thanks to Open Data Stack Exchange, I know OpenCorporates, but they don't provide easy-to-grab CSV or JSON unless you use the API. I don't know anything about http APIs yet. (I guess I will learn about it if there is no other way.) That's only my problem, but there's more. Sometimes the link between companies is not explicit. For exemple, I know Rexroth is owned by Bosch, but apart from the name, I couldn't have known if I didn't know Bosch was also a company.
Is there such a database listing companies and their subsidiaries and/or their brands, at a CSV or JSON format?
Are there any that are free?
Are there any that are open?
","['data-request', 'companies']",
Where can de-identified Electronic Health/ Medical Record (EHR/EMR) datasets be acquired?,"
Looking for sources of available de-identified EHR/EMR datasets that would be suitable as a benchmark to compare against existing datasets.
This would be similar to what is available from QResearch: https://www.qresearch.org
This is for a US-based project though, so US sources would be ideal.
","['data-request', 'medical']",
Historical shapefiles for cities in the United States?,"
I'm looking for historical shapefiles of city boundaries in the United States, for the time period 1920 - 1950. I know these won't be available for every city, especially small ones, but I'd like as many as I can.
Other questions, like this one deal with MSAs and CBSAs, which I don't think existed at the time. If all else fails, I can use those.
Other resources like the National Historical Geographic Information System (NHGIS), Duke, and the Newberry Library don't seem to have these either.
","['geospatial', 'historical']",
Old Epinion Dataset,"
I'm looking for the old Epinion dataset. The dataset includes 22166 users and 355754 social connections. It was available on http://www.public.asu.edu/~jtang20/datasetcode/truststudy.htm. But I can not find it on the internet.
More broadly, I am looking for a dataset which contains: user-item rating, user-user connection, and user-user trust matrices. unfortunately, the Epinion dataset on the trustlet.org website does not contain user-user connection. It is appreciated if you could help me finding the dataset.
","['data-request', 'social-media']","The old Epinion dataset is available from this archived version of the page you have linked to:  UpdateCurrently, Jiliang Tang works at Michigan State University (and not at Arizona State University).
New versions of the Epinion dataset are available here."
Where to Find MP (U.K.) Allowances?,"
I'm trying to find the breakdown allowances of Members of Parliament of the United Kingdom, but I've been unsuccessful so far.
For instance, Scottish Parliament releases this data in great detail on their website which allows you to see each expenditure claimed by each MSP and some other details too.

",['data-request'],"This information is available from the Independent Parliamentary Standards Authority, although their website seems to be down at the moment. MPs’ Expenses.info republishes the information in a format that is quite similar to that used by the Scottish Parliament. As an example, you can see claims made by Jacob Rees-Mogg. Note the date selector at the top of the page that allows you to see claims for previous years back to 2010."
Good easy to use api with a dataset for exam,"
I'm teaching a course in app development at bachelors level (3rd year college/university). Each year the students exam is to make an app which have some basic functionality and targets an open API. For example an app that can search imdb api, show movies, rate etc.  This year I am looking for a new open dataset/api online which i can give out in the exam.
Preferably there should be no requirement for registration, and there should be a couple of ""easy to use"" requests you can do to get JSON data back from http requests done against the dataset.
The domain can be anything that you can concievably write an app with some basic functionality against. Of course the license should be allowed for personal use, but these are private assignments that won't be publicly shared.  Previous years i have used the imdb open api, and a crypto website api. 
","['data-request', 'api', 'json']",
Are there any open datasets with raw eyetracking data?,"
I need to train a neural net classifier for different types of eye movements, and there seems very little data available on this.
","['data-request', 'machine-learning', 'research']",
Where can i find Public Datasets related to Astronomy and other fields?,"
I'm planning to do some research. Therefore, Appriciate if you could kindly help me to find out Astronomical datasets.
","['data-request', 'research', 'astronomy']","Have you seen in the news that Google released a brand new Google Dataset Search yesterday. It is a very convenient way to search for datasets, and overall it looks very promising. "
Are the Local Government Area wards of New South Wales available in a vector format?,"
I'm looking for a vector (i.e. GeoPackage, shapefile, Geojson etc etc) format dataset of the wards in New South Wales. These are the electoral districts for the Local Government Areas. 
An example of the boundaries I'm interested in can be seen [here] in purple.(http://pastvtr.elections.nsw.gov.au/LGE2017/inner-west/map.htm?showMap=true&mode=PP&ID=LG1701-057&fullname=Inner%20West&ward=)s
I'm aware of this site but the data doesn't quite match the official source when comparing counts of wards by LGA.
","['data-request', 'geospatial', 'elections', 'australia']",
Why is this NDA not available in openFDA?,"
I'm working on a project that annotates FDA label text. We're trying to use the openFDA API to get information about specific NDA IDs. I'm trying to query information about NDA206038 using the /search endpoint. I get a 404 response.
However, when I look in Drugs@FDA: https://www.accessdata.fda.gov/scripts/cder/daf/index.cfm?event=overview.process&varApplNo=206038 I get a valid page with all sorts of data.
Why is this particular NDA not available through openFDA? Is there a document somewhere that lists what types of labels are not indexed in openFDA?
",['openfda'],"The drug you are referring to -- ORKAMBI® (lumacaftor/ivacaftor) -- apparently has changed its dosage form. Approval of a new dosage form of a drug requires a new NDA. The most recent NDA approval for this drug is NDA211358, and openFDA will include only the most recent NDA number by design. The following query will return the results you would expect: https://api.fda.gov/drug/label.json?search=openfda.application_number:NDA211358. "
Geo coordinates of upazilas in Bangladesh,"
In order to add markers in map, I need geo coordinates of upazilas (upazila offices) in Bangladesh. Something like this GitHub repo bangladesh-geo should do my job, but unfortunately the SQL tables have longitude and latitude of districts only, not of upazilas (i.e., sub-districts).
Does the Internet have such a database? Or can anyone help me write a script pull coordinates in CSV, JSON, etc. format?
","['geospatial', 'geocoding', 'county']","Wikidata contains upazilas' coordinates from Wikipedias and GeoNames:Try it!For some upazilas, Wikidata contains coordinates from several sources. The query returns pair of coordinates from all sources. Ask on SO, if you need only one pair of coordinates in that case.P.S. I don't know, whether these points are upazila offices, or upazila centroids, or something else..."
Where can I find comprehensive and current lists of international naming disputes,"
I'm looking for any comprehensive information on naming disputes. Outside of Wikipedia (also not a bad source) I haven't found anything. Some examples: Persian Gulf vs. Arabian Gulf, the East Sea vs. Sea of Japan vs. Sea of Korea etc., Guayana Esequibo vs. all provinces administered by Guyana.
","['geospatial', 'politics']",
Cannot find record of administration of Ipratropium Bromide in MIMIC-III,"
I am interested in the looking at the effects of respiratory medications and am having trouble tracking down the administration of Ipratropium Bromide. You can see from this count from the prescription table that it is almost as common a prescription as albuterol (another drug administered via nebuliser):  
|           drug_name_generic           |  count |
| --------------------------------------| -------|
|       Albuterol 0.083% Neb Soln       |  22300 |
|        Ipratropium Bromide Neb        |  18838 |

However, while albuterol administration has a very clear chartevent associated with it:
|              label             |  itemid |          value         |
| -------------------------------| --------| -----------------------|
|  Small Volume Neb Drug/Dose #1 |  227570 |  Albuterol 0.083% unit |
|  Small Volume Neb Drug/Dose #1 |  227570 |   Atrovent 0.02% dose  |
|  Small Volume Neb Drug/Dose #1 |  227570 |  Albuterol 0.083% unit |

(sample from a join of chartevents and d_items) I have not been able to find any similar item in chartevents for Ipratropium Bromide. There is itemid 446, which has some values that look like it might have references to Ipratropium Bromide:
|         label        |  itemid |   value  |
| ---------------------| --------| ---------|
|  Micro-Neb Treatment |   446   |   alb/ip |
|  Micro-Neb Treatment |   446   |  alb/ipr |
|  Micro-Neb Treatment |   446   |  ipa/alb |

but there isn't nearly enough to acount for the Ipratropium Bromide prescriptions. 
Is there another table, or some other chartevent in which the administration of this drug might be recorded?
I have spoken to a medical colleague and they say that the administration of a nebuliser should be recorded somewhere.
Thank you for your help; apologies if this isn't the appropriate forum for this question.
",['mimic-iii'],
Industries which maintain their own versions of common data?,"
We have a product for the Australian mortgage brokers which is a centralised database of all lender/bank loan products. We do this because every large broker group must update their own version of the loan product data because the banks/lenders are too lazy to provide their loan product data in a common format like XML/JSON/etc. The banks feel that just having the information on their websites is support enough for the broker groups which is wrong and crazy.
So our product allows the broker groups to all maintain/update the same data repository which makes mistakes or omissions far less possible.
Does anyone know of other industries which also have the same inefficiencies and would benefit from a centralised data repository?
","['finance', 'ontology']",
"Is there an open database of middle, and high schools outside of the United States (international)?","
For a project I am looking for a database of middle and high schools outside of the United States.. something similar to that of NCES or CCD. We need a list of these and an unique identifier such as the ones used by the College Board or such. 
","['data-request', 'academia']",
where can i find product packaging information data?,"
where can i find the dataset about world products packaging components information? For example, the packaging of coke-cola is label, plastic bottle and plastic cap. where can i find such information which is saved in csv file?
","['data-request', 'data.gov', 'uses-of-open-data', 'releasing-data']",
Slope map of Singapore,"
Do you have any idea for a repository of readily available shapefiles for Singapore, specifically slope.
",['singapore'],
Marriage rate among different age groups in European countries?,"
I'm looking for data to list the marriage rate of all or most of European countries by different age group. For example:

Sweden 25-29 32%
Sweden 30-34 65%
Sweden 35-39 82%
Denmark 25-29 35%
Denmark 30-34 70%

....
It would be better if it is split by gender. But as far as I search on the Internet, it seems common that in European countries, the marriage rate is calculated by the total number of marriages in the year divided by 1,000, which is not I'm looking for.
So is there any such statistics on European countries (possibly EU)?
","['data-request', 'europe']",
Energy Costs Over Time by Source,"
I'm looking for a comparison I can make between ""traditional"" energy sources and solar energy. This is remarkably difficult to find. 
I would to have data on energy cost by source over time (in the years, i.e. 20 yeras would be great). 
Ideally, I'd like to show how much solar energy has to come down in price before it is cheaper than, say, gas and the rate at which this has been currently happening. 
Any advice would be appreciated. 
","['data-request', 'energy']","The Excel file is a bit complicated, but one source of this data comes from the NREL 2018 Annual Technology Baseline (ATB)Download like to Excel file (with macros).Each Sheet in the file is for a specific energy source:These sheets also have future projections for each technology. You can find previous years at their archive. The most useful way to compare technologies is probably LCOE - Levelized Cost of Energy ($/MWh).The data from ATB and some others has been aggregated by OpenEI.org and is available as the Transparent Cost Database, both with an online viewer and as a CSV or Excel data download."
IoT dataset of event detection which contains seasonal factor,"
I am looking for a dataset which is related to IoT data. Specifically, when there are any events detected, the IoT device will record that event immediately. And it should have the seasonal factor: there would be more events detected in some specific periods of the day than the others.
For example, there is an IoT device which will record any person passing through the gate, then in the daytime, there would be more than in the night time.
What I really want is not the detail of the event, but the statistics on the number of events detected on continuous time windows of the day. This is related to time series-formed dataset.
Thank you in advance :-)
","['data-request', 'time-series']",
Open online searchable book review database,"
In my quest for a story identification I'm looking for a publicly available searchable database of book reviews such as published in newspapers and magazines.  I've found several such databases, such as through gale, Boston College, and the New York Public Library, but it appears all require membership.  Is there any such database publicly available?
I'm interested in answers covering either English, Dutch, or multilingual solutions.  I can search Dutch newspapers online (until 1995).  This will (presumably) cover book reviews published in those newspapers, but (as far as I know) does not offer an easy way to search for only the reviews.
","['data-request', 'historical', 'text']",
US Government Spending,"
Where can I find a summary of historical spending of the US federal government?
I am not interested in budgets, I am interested in knowing what was actually spent.
","['usa', 'government', 'spending']",
How to find USA Water Hardness shapefiles?,"
I want to find USA water hardness shapefiles. I have searched for it from here: https://www.epa.gov/waterdata/waters-geospatial-data-downloads but without success. Is there any good data source from where I can download these boundaries?
",['geospatial'],
Where is a large list of declarative and imperative sentences,"
For a project I need a bunch (+500 each) grammatically correct sentences (English) that are declarative (basic or simple), imperative (command), and interrogative (question) (sorted by group or separate). Getting a list of questions was fairly easy but getting the declarative and imperative sentences are much harder. I've gone through just about ever grammer site and copied and pasted their examples sentences and came up with few of my own. But I only got about 200 max for each. So is there a large list of these sentences (preferably not combined) that I could use or some post where everyone that wants to post short list of these sentences (I've seen some posts on other sites asking for examples, but like a really large on of these)? Sorry if this is the wrong place for a question of this sort.
","['data-request', 'language']",
How to get old top news?,"
I am not sure this is the right forum to ask.
For a machine learning training, I need a dataset of old top news by keywords that can be organized by date. From where I can download it? I have seen that Google News API can provide only real time news.
","['machine-learning', 'news']",
Is it fair use to use figures from ArXiv preprints on Wikipedia?,"
Apologies if this isn't the right exchange. I'm not sure where this question should live.
There are some science figures from Arxiv papers that I think would greatly enhance a Wikipedia page on the subject the papers deal with. I'm curious on the copyright of using these images for this purpose.
To upload to ArXiv, the submitter agrees to one of the following:


grant arXiv.org a non-exclusive and irrevocable license to distribute the article, and certify that he/she has the right to grant this license;


certify that the work is available under one of the following Creative Commons licenses and that he/she has the right to assign this license:
  Creative Commons Attribution license (CC BY 4.0)
  Creative Commons Attribution-ShareAlike license (CC BY-SA 4.0)
  Creative Commons Attribution-Noncommercial-ShareAlike license (CC BY-NC-SA 4.0);


or dedicate the work to the public domain by associating the Creative Commons Public Domain Dedication (CC0 1.0) with the submission.


It's my impression that there are only doubts about screenshots from an article in the first category above. Is it within fair use to use figures from Arxiv preprints on Wikipedia or some other non-commercial, educational platform?
If articles need to be taken on a case-by-base basis, how do you go about finding out if one can use the article's figures?

ArXiv license policy
","['uses-of-open-data', 'images', 'wikipedia', 'academia']",
Restricted and allowed roads for heavy duties in Chicago,"
While manipulating osm file of Chicago to find the optimal path using A* algorithm there are surely some segment roads which are restricted for heavy duties. Where can I found this information (a shapefile or a dataset) ? Which segements are allowed for heavy duty and which segments aren't? Any help please?
","['geospatial', 'chicago']",
Dict not able to return data from college scorecard API,"
So I've been working on a page which displays a school's name, url, city, state, zip, and student size via College Scorecard API but I'm getting tons of errors instead. However, the program is able to read the JSON data just fine. For example, when I run this:
key = ""key_string_here""
url_base = ""https://api.data.gov/ed/collegescorecard/v1/schools/""

# Makes a get request to collegescorecard API

r = requests.get(""https://api.data.gov/ed/collegescorecard/v1/schools/? 
school.operating=1&2015.academics.program_available.assoc_or_bachelors=true&
2015.student.size__range=1..&school.degrees_awarded.predominant__range=1..3
&school.degrees_awarded.highest__range=2..4&id=240444&api_key=api_key_here"")

school = r.json()
  for item in school:
      url = (""https://api.data.gov/ed/collegescorecard/v1/schools?""
             ""school.operating=1&2015.academics.program_available""
             "".assoc_or_bachelors=true&2015.student.size__range=1..""
             ""&school.degrees_awarded.predominant__range=1..3""
             ""&school.degrees_awarded.highest__range=2..4&id=240444&""
             ""api_key=""+key+""&fields=school.name, school.school_url,""
             ""school.city,school.zip,school.state,2015.student.size"")
req = urllib2.Request(url)
response = urllib2.urlopen(req)
response2 = response.read()
json_data=json.loads(response2)
print response2

I get the correct data:
{""metadata"":{""total"":1,""page"":0,""per_page"":20},""results"":[{""school.n
ame"":""University of Wisconsin-Madison"",""school.zip"":""53706-1380"",""sc
hool.state"":""WI"",""2015.student.size"":29579,""school.school_url"":""www.
wisc.edu"",""school.city"":""Madison""}]}

However, when I try to parse the JSON data in a dictionary, like this:
params = dict(
    school_name=""University of Wisconsin-Madison"",
    school_url=""www.wisc.edu"",
    city=""Madison"",
    state=""WI"",
    zip=""53706-1380"",
    size=""29579""
)

resp = requests.get(url=url, params=params)
data = resp.json()
print data

I get this in response:
{u'errors': [{u'input': u'city', u'message': u""The input parameter '
city' is not known in this dataset."", u'error': u'parameter_not_foun
d'}, {u'input': u'state', u'message': u""The input parameter 'state'
is not known in this dataset."", u'error': u'parameter_not_found'}, {
u'input': u'school_url', u'message': u""The input parameter 'school_u
rl' is not known in this dataset."", u'error': u'parameter_not_found'
}, {u'input': u'school_name', u'message': u""The input parameter 'sch
ool_name' is not known in this dataset."", u'error': u'parameter_not_
found'}, {u'input': u'size', u'message': u""The input parameter 'size
' is not known in this dataset."", u'error': u'parameter_not_found'},
 {u'input': u'53706-1380', u'message': u""The provided zipcode, '5370
6-1380', is not valid."", u'parameter': u'zip', u'error': u'zipcode_e
rror'}]}

What am I doing wrong? How can I fix this problem?
","['data-request', 'api', 'collegescorecard', 'python']",
List of all different data license types and their respective restrictions?,"
I was hoping someone knew where I could get a master list of licences commonly used for datasets and the restrictions that each license imposes. Something like
{
    ""Public Domain"": {
        ""commerically_available"": True,
        ""required_attribution"": False
    },
    ""CC-0"": {
        ""commerically_available"": True,
        ""required_attribution"": False
    },
    ""PDDL"": {
        ""commerically_available"": True,
        ""required_attribution"": False
    },
    ""CC-BY"": {
        ""commerically_available"": True,
        ""required_attribution"": True
    },
}

etc. I've done some searching but haven't found anything structured, just web pages like this (https://help.data.world/hc/en-us/articles/115006114287-Common-license-types-for-datasets) which are helpful but still need to be processed.
",['licensing'],Since I was unable to find what I was looking for I ended up compiling the list myself and made it available as a public gist on github: https://gist.github.com/jhallard/2d26452b391908c607280d69b0462a5alet me know if anything there is incorrect and feel free to add to it if a license in question is missing
Open Source Information about Colleges and Universities,"
I am working on a project building a database of college and university information. I am looking for open-source information that has stats on schools but also general descriptions about the schools. Do you know of any?
","['data-request', 'collegescorecard', 'database']",
Medical Device - multiple FEI numbers associated with a single 510(k) number,"
In the device 510(k) endpoint data (downloadable JSON file on OpenFDA), a single 510(k) number is associated with multiple FDA Establishment Identification (FEI) numbers, and I am not being able to figure out how those multiple FEI numbers are associated with a single 510(k) number. I would greatly appreciate your help.
Below are some more details on how I collected/parsed the data and an example.
I have downloaded the device 510(k) endpoint data (JSON file) from the OpenFDA website (link here), and parsed it in R software, using the ""jasonlite"" package (R code for importing the json file below):
library(readr)
library(jsonlite)
data_flat_510k <- fromJSON('device-510k-0001-of-0001.json', flatten = TRUE)

The device 510(k) endpoint data has 29 fields (i.e., columns), including 510(k) number, device name, applicant name and address, etc. One of these fields is ""openfda.fei_number"" which is a ""list"" of the FEI numbers associated with each 510(k) number.
For example, the list of FEI numbers associated with a single 510(k) number ""K840424"" is: ""1048014, 3002808374, 3003915875, 3009211636, 1000587249, 2518902, 1000138054, 1282497""
So, the 510(k) number ""K840424"" has 8 FEI numbers. If I look this 510(k) number up in the Device Registrations and Listings database (also available/downloadable on OpenFDA), it shows only one medical device establishment, and thus, only one FEI number (which is one of the above listed FEI numbers).
Again, I can't figure out how these FEI numbers are associated with this single 510(k) number, and I would appreciate your help!
",['openfda'],"openfda is the ""harmonization"" record, and for medical devices harmonization revolves around product_code. So in the example you provided the 8 FEI numbers correspond to the product code of KNZ, not directly to the 510(k) number. More on this here: https://github.com/FDA/openfda/blob/master/openfda/device_harmonization/pipeline.pySorry about the confusion."
Where I can find all settlement boundaries for United Kingdom?,"
I'm looking for a dataset containing settlement boundaries for United Kingdoms.
In short example I'm looking for a dataset that would allow me to draw something like the following (orange line):

(source)
","['data-request', 'geospatial', 'uk']",
Large classification dataset,"
I am very curious about a very large classification dataset approx. 1e9 samples and 1e4 classes. However, I cannot find any. Could you recommend me some?
",['classification'],
Accelerometer dataset for car crash detection,"
I'm trying to find an open-source dataset for car crash detection using sensor data including accelerometer. Is there any open-source dataset available? Basically I want to detect car crashes only using non-car information, such as accelerometer data from a smartphone mounted on a car.
I was told about FARS, but wasn't really sure if this is what I want. I couldn't find a accelerometer dataset there.
","['data-request', 'cars', 'sensors', 'accelerometer']",
"Multimodal, numerical and changing time series data","
Similarly to this question I am looking for time series data sets that show some extent of change in the feature distribution(s) over time.
The requirements that I have regarding the data set are that it has:

measurements of some numerical feature(s) over time 
more than one measurement per time point 
some change in the distribution over time, so the distribution in the beginning is different from that at the end (timewise)
(ideally) a multimodal feature distribution (=multiple peaks)
More than 10k samples

Besides this there are no restrictions regarding  aspects like the region, origin or context of the data.
There are many stock exchange and energy grid load data sets that simply have one measurement per time point, so these aren't really relevant to me.
I was looking around a bit and I figured that maybe environmental or biological data sets might fit, for example the concentration of a compound in sampled plants or something like that.
I'd be thankful for suggestions, references or even just keywords that might help me find such data.
","['data-request', 'time-series']",
When will the drug events api (https://api.fda.gov/drug/event.json) be updated with 2018 Q2 data,"
I see that on the FDA adverse events reporting (FAERS) public dashboard the data is already as of June 30, 2018 whereas on the API its still as of March 31, 2018.
https://api.fda.gov/drug/event.json?search=receivedate:20180101+TO+20180813&count=receivedate
or 
https://api.fda.gov/drug/event.json?search=receiptdate:20180101+TO+20180813&count=receiptdate

{
       ""time"": ""20180329"",
       ""count"": 288
     },
     {
       ""time"": ""20180330"",
       ""count"": 237
     },
     {
       ""time"": ""20180331"",
       ""count"": 20
     }
   ]
  }


","['openfda', 'drugs']",
"Not able to return data other than category ""school""","
For example this url returns an error:
https://api.data.gov/ed/collegescorecard/v1/schools?api_key=&fields=student.enrollment.all,school.name&school.state=AL

error: {""errors"":[{""error"":""field_not_found"",""input"":""student.enrollment.all"",""message"":""The input field 'student.enrollment.all' (in the fields parameter) is not a field in this dataset.""}]}

But this url works:
https://api.data.gov/ed/collegescorecard/v1/schools?api_key=&fields=school.name&school.state=AL

{""metadata"":{""total"":96,""page"":0,""per_page"":20},""results"":[{""school.name"":""Troy University-Online""},{""school.name"":""Strayer University-Huntsville Campus""},{""school.name"":""Virginia College-Montgomery""},{""school.name"":""University of Phoenix-Alabama""},{""school.name"":""ITT Technical Institute-Mobile""},{""school.name"":""The University of Alabama""},{""school.nam.......

Are there some limitations on which fields you can return that are not documented?  Am I doing something wrong?
","['data-request', 'api', 'collegescorecard']",
Previous versions of the dataset from the Yelp Dataset Challenge,"
Yelp periodically released data they have collected and encourage people to compete in a data analysis competition. The data for the current competition can be downloaded  here.
In the FAQ they state that they do not distribute versions of the dataset from older competitions. I was curious if anyone knew of anywhere on the web where I can find older versions of the dataset? 
",['data-request'],
Largest cities in the UK? [duplicate],"







This question already has answers here:
                                
                            




Looking for a list of major cities of the world

                                (5 answers)
                            

Closed 4 years ago.



I am looking for an up to date list of say the largest 25 cities in the UK by population. 
Searching around on Google, most lists seem to be a few years outdated, and some don't even specify last updated dates. Where is the most reliable source to find an up to date list of the largest cities in the UK by population?
Example from http://www.citymayors.com/gratis/uk_topcities.html which unfortunately doesn't specify a date:
London  7,074,265   49.12
Birmingham  1,020,589   49.42
Leeds   726,939 49.43
Glasgow 616,430 47.73
Sheffield   530,375 49.73
...

There are other websites such as http://worldpopulationreview.com/countries/united-kingdom-population/cities/ which also don't specify any updated dates ...
",['uk'],
Dataset with categorical features that take more than 1000 different values,"
I'm looking for a dataset that has some properties:

it has at least one feature that is categorical and that takes more than 1000 different values (when I say 1000, it's an order of magnitude, it can be 900)
these features' values have a meaning in english (like city names, ingredients, auto parts...)
it has to contain a target value so that it would be possible to make predictions that have some meaning

I'm looking for a dataset like this because I want to test different methods to handle categorical data (one-hot-encoding, embeddings, knowledge graphs...) and do some benchmarks.
I already found one dataset that correspond to what I am looking for, but I would love to have a choice between several. Here it is: https://www.kaggle.com/c/whats-cooking-kernels-only/ 
I looked on Kaggle, OpenML and several ""Awesome lists"" of datasets on GitHub, but I did not find anything except the one dataset I talked about.
",['categories'],"Ok, I found some datasets on Kaggle.Here are some examples of datasets that I have found that correspond to my criteria:"
Where to get big volumes of academic papers with citations,"
I'm developing a final degree project and the first step would be to get a big amount of (public) academic papers with citations included. The purpose of the system is to calculate bibliometric indexes based on citations (that's why citations must be included in the data set). The thing is I'm struggling to find a way to get this dataset. I would really appreciate some help or advice on where to get it. It doesn't matter the subject of the papers. Thanks.
",['publications'],
OBD II Sample Datasets,"
I'm trying to find sample datasets of OBD II data. OBD II is a data standard for automobile on-board diagnostics,  
I'd like a huge set with lots of journeys but right now I will settle for anything.
Looking to get something for testing before i invest in a simulator like this.
","['data-request', 'cars']",
Where can I download QRU-1 dataset?,"
In the paper QRU-1: A Public Dataset for Promoting Query Representation and Understanding Research, writers introduce that dataset. I want to download it but when I search for it there is no result. Even the download link in the paper is not working. Where can I find it? 
","['data-request', 'machine-learning', 'research', 'search-engine']","The dataset is not available for download on the SIGIR workshop website, but is still available on the Microsoft Research website: check this link."
starttime bigger than endtime at inputevent_mv table MIMIC-III,"
Way at  inputevent_mv table (MIMIC-III), there are 100 rows were their starttime is bigger than endtime?
SELECT * FROM mimiciii.inputevents_mv where (starttime-endtime)> interval '1 minute' 
",['mimic-iii'],
Wind Speed / Dir and Gust Speed US Pacific Southwest,"
I am looking for wind speed, wind direction, and gust speed (optional) data for the Pacific Southwest region of the US - more specifically for the Northern California region including Napa, Lake and Sonoma counties. The time range would be for the 2017 year, with a temporal resolution of 3 hours, and a spatial resolution of at least 5km. 
I understand this type of data can be modeled from observed readings at weather stations across the US, and it is fine if the data is derived model data. I have looked into some data and I came up with the following list (sourced from NOAA):

https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/service-records-retention-system-srrs
https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/north-american-regional-reanalysis-narr
https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/national-digital-forecast-database-ndfd & companion dataset https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/national-digital-guidance-database-ndgd
https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/climate-forecast-system-version2-cfsv2

I hope to get my hands on more regionally focused data - specifically for the region I am looking into.
","['data-request', 'meteorology']",
File Encoding for NHTSA/OHI data,"
I am trying to do some analysis on data sources from this site.
When I try to load it with pandas, I get a few different variants on the unknown byte error, depending on which encoding I use.
For example:
UnicodeDecodeError                        Traceback (most recent call last)
pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._convert_tokens()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._convert_with_dtype()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._string_convert()

pandas\_libs\parsers.pyx in pandas._libs.parsers._string_box_utf8()

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbf in position 729: invalid start byte

During handling of the above exception, another exception occurred:

UnicodeDecodeError                        Traceback (most recent call last)
<ipython-input-10-ad328034813f> in <module>()
----> 1 flat_cmpl = pd.read_csv('FLAT_CMPL.txt', sep='\t', encoding='utf-8')

~\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\pandas\io\parsers.py in parser_f(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)
    707                     skip_blank_lines=skip_blank_lines)
    708 
--> 709         return _read(filepath_or_buffer, kwds)
    710 
    711     parser_f.__name__ = name

~\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\pandas\io\parsers.py in _read(filepath_or_buffer, kwds)
    453 
    454     try:
--> 455         data = parser.read(nrows)
    456     finally:
    457         parser.close()

~\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\pandas\io\parsers.py in read(self, nrows)
   1067                 raise ValueError('skipfooter not supported for iteration')
   1068 
-> 1069         ret = self._engine.read(nrows)
   1070 
   1071         if self.options.get('as_recarray'):

~\AppData\Local\conda\conda\envs\tensorflow\lib\site-packages\pandas\io\parsers.py in read(self, nrows)
   1837     def read(self, nrows=None):
   1838         try:
-> 1839             data = self._reader.read(nrows)
   1840         except StopIteration:
   1841             if self._first_chunk:

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader.read()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._read_low_memory()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._read_rows()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._convert_column_data()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._convert_tokens()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._convert_with_dtype()

pandas\_libs\parsers.pyx in pandas._libs.parsers.TextReader._string_convert()

pandas\_libs\parsers.pyx in pandas._libs.parsers._string_box_utf8()

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbf in position 729: invalid start byte

I've tried a few different options including utf-8, utf-16, and ascii and a few others with no luck.
Do any of you know what the right encoding is for these files or how to find it?
",['data-request'],
Beijing Traffic Data,"
I'm looking for a reliable source for traffic data in Beijing. In some papers that I've read, a particular dataset is mentioned. From the articles:

""The traffic network is located between the Second Ring Road and Third Ring Road in Beijing.""
"" 2-min travel speed data collected from three remote traffic microwave sensors located on a southbound segment of a fourth ring road in Beijing City.""
"" a dataset consisting of probe vehicle data collected in the urban network of Beijing, China, during one week from June 1st (Monday) to 7th (Sunday), 2015""
""north-east transportation network of Beijing""

I've searched the internet to find this dataset of vehicle speed in Beijing and found the following links in Chinese:
http://jtw.beijing.gov.cn/
http://cgs.bjjtgl.gov.cn/chgs/Main.jsp
Unfortunately, Chinese is not my native language and I cannot explore these sites easily.
Can someone fluent in Chinese explore these sites and see if I can request traffic speed data of previous months? Can I email them and request this data?
Also, here is a contact and some emails in this link:
http://www.bjjtgl.gov.cn/jgj/96629/index.html
","['data-request', 'transportation', 'traffic', 'china']",
Seeking list of residential buildings (API / DB) for USA,"
I'm developing an app where the user will choose some area on the map and then obtain list of residential buildings addresses belongs to it.
For now I think about this flow: get bounding box coordinates of selected area -> get list of streets (using OSM) of the area -> get list of buildings for each street (using Zillow) -> check is building coordinates belong to selected area.
Maybe there is any downloadable DB of all residential buildings of USA or one-solution API where I could get all buildings by single request?
","['usa', 'openstreetmap', 'address']",
Overlapping intervals of inputs at inputevents_mv table for same icustay_id and itemid,"
In the following example after I discarded from rows that were ""Rewritten"" I still have rows (for the same drug at the same ICU admission) that their time period is overlapping. so, I want to know if the patient received several different rates of the same drug at the same time or it is an error at the data?
(to be more specific, does he received at 16:15-17:49 -> 60 ml (49+10) or just 10 ml?)
SELECT icustay_id,itemid,starttime, endtime,amount,rate,ordercategorydescription,statusdescription FROM inputevents_mv
where icustay_id=200001 and itemid=220949 and statusdescription <> 'Rewritten'
ORDER BY starttime
Thanks
",['mimic-iii'],
Where can I find detailed data about crimes in Italy?,"
Where can I find detailed data about crimes committed in Italy? The data set should contain at least the following variables:
Type of crime:
Year:
Municipality: 
Criminal:
Victim:
Ethnicity of criminal:
Nationality of criminal:
Age of criminal:

Ps I guess it may not be possible have all these pieces of information in the same data set. It would be ok to point me to two different data sets (one with crimes data and another with census data). Then I think I should be able to create the tables I need by using the right SQL joins.
","['crime', 'italy']","try to look at this link:
https://www.istat.it/en/justice-and-security?data-and-indicatorsunder the ""Data And Microdata"" tab.Here you can find a lot of information that may fit what you're looking for.I don't know if you're italian but ISTAT is the italian institute for statistics.Hope you can find this useful!"
Querying Sparql dataset and caching results locally,"

During querying LOD datasets (using Sparql queries), we could face connection or server problems. Is there a reliable strategy that helps us to get data is a reliable way ?  I'm looking for a tool (in java) that helps to schedule querying tasks so that when an interruption occurs, the task will be re-run again until getting all data ?
I generally use Jena library to query remote Sparql dataset and use retrieved data to do some stuff. Is there a mechanism to automatically cache returned data so when I re-query the dataset with same query, data is retrieved from local cache instead of remote dataset endpoint.

",['sparql'],
ACS - Census Block Groups with 0 households?,"
I'm looking through some ACS data on # of households by block group in Santa Clara County. Block Group 2, Census Tract 5002, Santa Clara County, California has 0 households, despite having a population estimate of 737. This is true for the five-year estimates from 2013, 2014, 2015, and 2016. 
I thought Census block groups had a population requirement (except for bodies of water, which would be block group 0)? 
Any advice or explanation would be appreciated.
","['usa', 'us-census', 'census']",
Average Gross Rent,"
I need an aggregate value for rent using a collection of Census Tracts from the American Community Survey 5-year estimate.
The universe for Aggregate Gross Rent (B25065) is listed as ""Renter-occupied housing units paying cash rent"", yet there's not table that contains a total for that universe. Would it be safe to use the Renter Occupied column from Tenure (B25003) to calculate an average gross rent even though the universe is ""Occupied housing units""?
","['data-request', 'uses-of-open-data', 'us-census']",
Where can I find labelled data for handwritten Chinese characters?,"
I would like to write a simple project that can recognise different written Chinese characters. Now I have been searching various web pages and other sources for a sufficient database to use.
While there are several databases offering free data to use, most of the data is not labelled. The closest to a success I have come was from this web page: http://www.hcii-lab.net/data/onHCCTestdataset/onHCCTest.html
On this web page I found ""labels"" and ""data"", however the labels seemed to far outnumber the data. So I can't be sure, if the files are related.
It would already be enough for me, if I had a data points and a labels files I could process (somehow) - the processing aspect of the data shouldn't be the difficult part. It also does not have to be ""much"" data - I don't have to have enough data so that any and every Chinese characters can identified.
In fact my expectation for the project aren't high - it's intended to be just a project I do for fun over my summer holidays. It's more important to me, that I can try and utilise Machine Learning algorithm for a hobby (Chinese) and in the end have something that works.
","['data-request', 'text', 'china']",
Who is reporting salary after attending?,"
Where do the salary after attending numbers come from if the school isn't reporting them? Who is surveying graduates 10 years out? 
",['collegescorecard'],"It is not a survey; it is from SSN-linked tax records for students who received federal aid. According to the College Scorecard documentation (scroll down and expand ""Earnings""):To measure the labor market outcomes of individuals attending institutions of higher education, data on cohorts of federally aided students were linked with earnings data from de-identified tax records and reported back at the aggregate, institutional level."
Rehabilitation Facilities & Substance Abuse Clinics GIS data in Grand Rapid City MIchigan,"
Looking for GIS data for the 57 locations on page 35 of this PDF
https://www.grandrapidsmi.gov/files/assets/public/departments/planning-department/cannabis-data-compendium-7-18-18.pdf 
","['geospatial', 'drugs']","You can see the data from that report on this interactive map.If you have the patience you can click on each point and get its address and x,y coordinates (presumably in Michigan state plane coordinate reference system). Or, you can contact the city planner and request that data. "
How people perceive themselves?,"
since i'm not sure if my question is as specific as expected by Stack* audience, I would like to explain a little what I would like to get.
I'm looking for a database, dataset or some data source where I can find information about how people feel about themselves. 
Suppose that we are dealing with some ""how I feel about *"" test where there are questions which answer falls in a range between ""not so much"" to ""yes, indeed"".
Imagine questions like: 

""Do you think you're liberal?""
""Are you fine with meeting people from different countries?""
""Do you think you can manage unexpected situations?""
""Do you value the support of your family?""

and so on...
Suggestions?
",['data-request'],
Ontologies on the notarial domain,"
I am completely new to ontologies and have been doing some research on representing notarial deeds in the historical domain (ie: old acts) using ontologies and RDF to create a knowledge graph.
I am having a hard time finding an ontology on this particular domain. Did anyone encounter such ontologies?
Usually in such documents one will find parties involved in an event such as a will, donation etc... These will include also dates, items involved and relationships between the parties. I thought about creating the ontology myself but I don't want to reinvent the wheel if something already exists
",['ontology'],
US hiring data 1947-2018,"
I'm looking for US hiring data at national level from 1947 to 2018. I'm interested in data similar to what the BLS website has available for after 2000.
","['data-request', 'usa']","The Job Openings and Labor Employment Survey (JOLTS) was launched in the year 2000, so there isn't any older data from this source.This survey replaced an older one called the Labor Turnover Survey, which lasted from 1954 to 1981. This data was published in a report from the BLS called Employment and Earnings on a monthly basis. But if you pick one from each decade the report has an annual time series that covers the previous ten years. They're archived by the St Louis Fed here:https://fraser.stlouisfed.org/title/60Here's an example of the last report that contained that data, from 1982: https://fraser.stlouisfed.org/files/docs/publications/employment/1980s/empl_011982.pdfThis isn't great as there are two decades missing and the methodologies are a bit different. I went through a copy of the stats abstract from the mid 1990s to see if there was something comparable for the years in-between for hires or turnover, but didn't see anything.Another possibility would be to use the Current Employment Statistics, which is a much longer series that stretches back to the 1930s (which Barry mentioned and linked to). The JOLTS page has documentation that high lights the difference between the two datasets:https://www.bls.gov/jlt/joltsdivergenceinformation.pdfIn short:""The Job Openings and Labor Turnover Survey (JOLTS) measures hires and
  separations on a monthly basis. If separations are subtracted from
  hires, the difference represents an implied employment change. The
  Current Employment Statistics (CES) survey provides net employment
  change. The JOLTS implied employment change and the CES net employment
  change are conceptually similar and are expected to track well with
  each other over time.""So it's a compromise. Net change is not the same as hires, but if you go with the CES you can get a long time series. Or you use JOLTS with the definition you want and a shorter time series, with the option of digging out the LTS data from those reports to extend the series a few decades with a gap in between."
GovData.de license zero-2-0,"
Does this license have to be passed on (I don't have the technical term), if the licensed data is used or passed on?
https://www.govdata.de/dl-de/zero-2-0

Data licence Germany - Zero - Version 2.0
Any use is permitted without restrictions or conditions.
The data and meta-data provided may, for commercial and non-commercial
  use, in particular

be copied, printed, presented, altered, processed and transmitted to third parties;
be merged with own data and with the data of others and be combined to form new and independent datasets;
be integrated in internal and external business processes, products and applications in public and non-public electronic
  networks.


(Example data: search for zero-2-0 on http://www.geodatenkatalog.de)
","['government', 'licensing', 'inspire']",
Recent dump of names from facebook.com/directory?,"
For years all names of all Facebook users were listed at
https://www.facebook.com/directory.
Even without the links to the profiles themselves, it was a very useful dataset of diverse names and versions of the same name around the world.
In 2010 a security researcher scraped it and made it available as a torrent.

171 million names (100 million unique) ... limitation is that these are only users whose first characters are from the latin charset.

It grew significantly in size and diversity between 2010 and 2018, when it was deleted (This page isn't available) without warning, presumably in connection with political issues around user data.
Is there a relatively recent version available?  It could be incomplete if randomly sampled.
","['nlp', 'language', 'social-media', 'names', 'security']",
Where can I find website analytics logs for research?,"
I am doing some research into some machine learning algorithms that can be used to analyze website logs.
A friend gave me access to his Google Analytics, but all I see are reports and I am not able to see the actual logs. If I am not mistaken, google has put a high price on access to these logs (over 100K per year).
I am looking for open logs which record website events: UserId, TimeStamp, BrowserDetails, LocationDetails etc. Very close to Apache access logs, but with richer instrumentation to say more about each event.
Are there any website logs that are open and freely downloadable for research purposes.
","['data-request', 'machine-learning', 'internet']",
Data set on trust in the Internet of Things?,"
I've looked everywhere for a data set on trust in the Internet of Things (IoT) and found nothing.
The articles I've read either didn't mention the data sets used or the data sets were not public. I even emailed two publishers for their data set and they didn't help me.
Does anyone know of a good source for open data sets on trust in IoT?
","['data-request', 'survey', 'internet-of-things']",
"Data centers: Looking for dataset on location, capacity, company / owner and year of establishment","
I am looking for a dataset on the location, capacity, company / owner and year of establishment for data centers (eg. of Google, Amazon, Facebook). 
Any suggestiosn are welcome. 
",['uses-of-open-data'],
"Points of Interest for France, Spain, and Italy?","
I`m planing trip to Europe am looking for points of interest data for some regions I will be visiting. 
Does anyone know of a source for POIs in KLM/KMZ/GPX or any other format with coverages for Spain, France, whole region of Alps, and Italy?
","['data-request', 'geospatial', 'openstreetmap', 'data-mapping']",
Multidimensional Data Stream,"
I am looking for a dataset containing multidimensional data streams. More specifically, data points such as:
(x1, y1, z1), (x2, y2, z2), (x3, y3, z3), ...
which are ordered or have time-stamps.
When I search, I usually find time-series data which is a sequence of a single attribute. For example: stock price of a company or temperature of a room.
However, I need an extended version of that which has more than one attribute. For example, something like a sequence of (temperature, pressure, volume) or (number of requests, cpu usage, bandwidth usage) matched together.
The only thing I have found is Intel Lab Data (http://db.csail.mit.edu/labdata/labdata.html). The issue I have with it is that it is very hard to interpret any result that you get from analyzing it.
","['data-request', 'time-series', 'real-time']",
"Where to find data to explore the ""Rescorla-Wagner model""?","
The Rescorla-Wagner model (wiki link description): "" (""R-W"") is a model of classical conditioning, in which learning is conceptualized in terms of associations between conditioned (CS) and unconditioned (US) stimuli."" and is bases the dynamics of the changes in behavior according to a simple agent update which covers every agent in the group. There can be found implementations to produce the effect (simulate) sim link or analyze a dataset which is governed by this effect code using tensorflow. 
Where can datasets be found that have been used to investigate these dynamics? Or are there compatible datasets which are available for investigations similar to this?
The methodology requires a set of actor which have connectivity between themselves in a network sense, and a state value which is defined as a bounded number that is continuous or discrete. 
","['data-request', 'social-process']",
Customer Service (Call Center) Audio datasets,"
I am looking for audio/video samples of conversations between customer service agents and customers. 
The background noise and accents are not a problem here so long as the conversation is in English. The dataset must be in an audio/video format and not in written text transcripts.
I expect the conversation between the customer service agents and customers to be revolving more around frequent questions and some new questions.
For Example :- What is the status of my claim number ? (Frequently asked one)
","['data-request', 'machine-learning', 'audio']","Audio datasets of call center recordings are hard to find as those are usually privately owned and subject to various privacy laws (which differ from one country to another). Unfortunately, it is unclear what are you trying to do with the data and consequently it is hard to give you accurate suggestions that fits your search.  Therefore, depending on your use case you might be able to find -behaviorally- similar datasets. If you are interested in Speaker diarization/ Recogntion over the telephone then datasets like the CallHome database and the CallFriend database -by TalkBank should be sufficient to replicate call center calls (a two-way conversation, sampling rate = 8kHz, telephone noise included)In case you need to do Speaker verification over the telephone, a dataset of calls-recordings of one individual should be easier to handle and that can be also done using the same -previously mentioned- datasets by separating each sample into two samples (separate speakers, from stereo to mono). However if you are interested in Speech Recognition over the telephone, then you will need more than a couple of audio recordings. Note that you will need a lot of transcribed datasets (with a sampling rate = 8kHz) and there aren't many out there. This is not an easy task and is indeed an ongoing research area. Moreover, most existing tools for speech recognition are conceived for 16kHz data but there are a couple of decent 8kHz pre-trained models like the CMU Sphinx model here. Alternatively, you can use 16kHz data to train for 8kHz recognition  using some transformation like the ones uggested in the following papers: Speech conversion from clean conditions to telephone onesTelephone speech recognition using simulated data from clean databaseFrom the formulation of your question, I suspect you are trying to detect the nature of the call inquiry. This is -to my limited knowledge- a two-steps procedure. First you need to know what is being said? Secondly, what is it about? Of course, you can try using extracted vocational features to predict the nature of the call but I doubt that you will get decent results. For the call natures, I suggest looking for call logs as those are easier to find. Good luck!Disclaimer:
Please mind the licenses of these datasets and the TalkBank Ground Rules. 
The TalkBank data is subject to the CC BY-NC-SA 3.0 license and CMU Sphinx is under the BSD-style license."
OpenFDA query - wanting one section,"
I'm rying to eventually populate a spreadsheet with only the dosage_and_administration section for like 2000 medications. I created a query for this:
https://api.fda.gov/drug/label.json?search=openfda.substance_name:acetaminophen+AND+exists:dosage_and_administration
However all the other headings show up every time and I can't focus the query on just dosage_and_administration section. Is this possible? 
",['openfda'],
Distance between different places in USA,"
For me to include in my project, I am looking for some API which can recognize the places and give the output as the distance between two places. 
Is there any database that consists of distance matrix between all places in the USA ? 
API something similar to Distance Calculator, which is able to recognize all the places and give the distance output for free. Google API is being charged. As per this link, I cannot enter geo coordinates, I can enter only the place name, it should be able to recognize and find the distance. 
","['data-request', 'geospatial', 'usa', 'api']",
Commercial use of a model derived from NC-licensed data?,"
Say you want to use data to train a machine learning model to solve some task. What if the data is published under a Creative Commons license with the Non-Commercial module? Clearly, you cannot put the data to direct commercial use, like linking it with other data and selling it.
However, can you use the model in a commercial setting, if it was derived from those CC-NC data?
I found only one remotely relevant interpretation in the CC FAQs:

Commercial purposes: If you are conducting text and data mining for
  commercial purposes, you should not mine NC-licensed databases or
  other material.

However a statistical model derived in a machine learning process from a data set is not exactly data mining, IMHO. Also, the should is very vague.
","['machine-learning', 'licensing', 'creative-commons']",
Mapping PUMA codes to county,"
I'm looking for a mapping between PUMA codes (Public Use Microdata Area from the American Community Survey) to county. UMichigan has this mapping (linked from this), but there's no date so I'm not sure if it's still relevant.
","['geospatial', 'us-census', 'county']",
Realtime Power Outages Global/North America [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 4 years ago.







                        Improve this question
                    



Does anyone have, or know of, any sort of real-time source of power outages globally? Or at least in North America. Everywhere I can find is just a local power company or proprietary. 
Either a Compiled Map or API would be fine.
","['data-request', 'energy', 'real-time']",
Large English text corpus,"
I am interested in studying a few specific questions on entropy of different properties of English text. For instance, what is the entropy of capital letters in English? This might tell you something about what letters are more likely to start sentences, or be used in abbreviations or proper nouns.
Does anybody know of a good English text corpus that is readily digestible by a computer program (i.e. plain text) and covers as broad a range of ""types"" of writing as possible? I am on the fence as to whether I want to focus more on modern English writing or attempt to look at English writing over the last couple hundred years as a whole, so either type of dataset would be fine by me.
Thank you. And please let me know if this belongs on another SE.
","['data-request', 'english', 'corpora', 'text']","Project Gutenberg offers 57.000 free books, available in different formats. Among them, utf-8 encoded plain text with minimal formatting.The NLTK comes with access to a range of corpora. Among them, a selection from Project Gutenberg, and a chat corpus (if you are looking for more colloquial use of English). Beware of the varying licenses that apply.If Wikipedia turns out to be a good in your estimation, consider using the WikiExtractor, which can turn a Wikipedia dump into plain text files with minimal formatting."
Data on radio towers and radio stations in the US,"
Where can I find historical data on radio towers and radio stations in the United States? For example, the latitude/longitude, tower height, and transmitting power of every tower that existed in 1930, 1940, etc.? 
Alternatively, are there datasets of historical coverage of radio stations? As in, for a certain latitude/longitude, all the radio stations that they (may have) received as of a certain date? The historical element is very important here. I'm not looking for recent data or data after 1970.
","['data-request', 'historical', 'technology']",
Dataset of Luna and Emperor Moths,"
To implement a classifier, I require labeled data.
The features I require in the dataset are the mass of the moths and wingspan.
Additional features antenna size and wing color(s) would also be useful.
Luna Moth : https://en.wikipedia.org/wiki/Actias_luna
average wingspan: 114 mm
Emperor Moth: https://en.wikipedia.org/wiki/Saturnia_pavonia
average wingspans: 60 mm (males) and 80 mm (females)
I also need the mass param for the other axis.
","['data-request', 'ontology']",
Facebook Mypersonality dataset,"
I want to have access to a database for Facebook Photos dictionary that contains 17,2mn records (photo_id,owner_id, created_time). 
At this time, the owner of the dataset has decided to stop sharing the data further and I do assume that the external researcher which already have a legal copy before this restriction can continue their work based on that we did not get any note saying against this. Therefore, I decided to find a way to map this missing profile pictures dataset from the available datasets using Facebook graph API. 
So far, I have copies for two datasets. One contains Facebook users self-reported personality test (BIG5 Personality Scores.zip) and the other one contains a users race prediction-based profile picture (Race labels.zip). The authors say that all of the tables contain an anonymized user id (32 characters) that can be used to match users between tables.
So, if the same id is being found in the two databases, can I assume that the two separated records are for the same user? at this point, can I then use this mapped id to crawl the original facebook profile picture? 
","['data-request', 'uses-of-open-data', 'social-media', 'web-crawling']",
Looking for open imbalanced datasets,"
I'm looking for imbalanced classification datasets to experiment with using synthetic data, ideally with a minor class of less than 10%. Does anyone know specific ones? Should be open to the public with no limitation of use.
",['data-request'],"Most multi-class datasets can be turned into skewed binary classification datasets.
For example, the default scikit-learn digits dataset contains ~10% 1 and ~90% not-1 images.That being said, the UCI Machine Learning Repository hosts many datasets that are skewed, one that's quite skewed is this SMS spam dataset: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+CollectionAnother organisation that hosts free but not open datasets is kaggle, one of their datasets that's very skewed is the following:
https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge"
Census Tracts for Puerto Rico,"
I'm looking for digital data for Puerto Rico. Specifically census tract shapefiles from the 1990 & 1980 census. TIA
","['geospatial', 'us-census', 'census']",
Seeking historical traffic data matching OpenStreetMap dataset?,"
I'm using San Francisco dataset offered by OpenStreetMap and I'm trying to get the optimal path using the pgr-astar function of PostgreSQL.
I want to find the historical traffic data of San Francisco roads (roads congestion with time slots), that corresponds to the format of the dataset generated by the map so I can calculate the optimal path based on the historical traffic information of each road segment.
Where can I get this data?
This is the dataset of San Francisco, where a road is divided into many segments.
 
I found many sites that offer the traffic information but it doesn't match my dataset ( without accurate information of the road segment). 
","['data-request', 'geospatial', 'usa', 'traffic', 'openstreetmap']",
Journal Acceptance/Rejection dataset with timeline,"
I am looking for a dataset to answer this Academia Stackexchange question:
Are rejections usually quick?
I know some conferences/journals in field have been collecting datasets on the review process, which has resulted in some datasets like 
Paper Reviews sentiment analysis data set
To answer this question though, I need a dataset that has more details on the timing, e.g. submission date, reviewer assigned date, review complete date,
as well as if it is an accept or a reject.
","['data-request', 'academia']",
Is Open Government data ever restricted to use within the country of origin?,"
As the effort to collect, QC, organize and publish an open government dataset is usually funded by taxpayers, I have always imagined a government would prefer to only offer such data to its citizens for free and charge users from other countries. As is mentioned by @closetnoc on this question on webmasters, the government does sell the data too, as packaged in physical storage formats.
Upon downloading foreign datasets and searching for these policies however, I have never encountered such restrictions; they seem rare if they exist at all. Still, I haven't been able to find any terms of usage or literature that talk about access outside the border. If indeed this practice is rare, I'm curious as to the rationale. Is it too unsavory to paywall ""open data"" for any reason? Would the profits be too slim perhaps, with most traffic coming from domestic machines anyways? I am also interested in exceptions to this free international access.
","['government', 'legal', 'global']",
Looking for corpus of Geographic Data,"
I was wondering if anyone has a lead on a corpus of geographic locations? City names and coordinate pairs would be ideal. I'm training a chatbot and I'd (ideally) like it to be able to pick up on locations in the chat and then display a map if requested. For example, if the words ""I'm headed to Chicago"" were typed, the chatbot could render a map of Chicago. Wishes and wants aside, if y'all do know of one or how I could make one, I'd appreciate it.
Thanks
","['data-request', 'geospatial']","There are probably lists, so if you are looking for single regions or languages, then this answer may be a bit much, but...You can download the entire planet from Open Street Maps (OSM) and then filter out the relevant tags (see this answer). In your case you would filter on place, see this example filter:Your geocoordinates will actually be a multi-polygon, but that's OK because you can either simplify to a geopoint (e.g. use the centroid), or show the entire polygon range in your map.Instead of planet.osm you can also do this for illinois.osm, or whatever region you want."
Looking for corpus of Geographic Data,"
I was wondering if anyone has a lead on a corpus of geographic locations? City names and coordinate pairs would be ideal. I'm training a chatbot and I'd (ideally) like it to be able to pick up on locations in the chat and then display a map if requested. For example, if the words ""I'm headed to Chicago"" were typed, the chatbot could render a map of Chicago. Wishes and wants aside, if y'all do know of one or how I could make one, I'd appreciate it.
Thanks
","['data-request', 'geospatial']","There are probably lists, so if you are looking for single regions or languages, then this answer may be a bit much, but...You can download the entire planet from Open Street Maps (OSM) and then filter out the relevant tags (see this answer). In your case you would filter on place, see this example filter:Your geocoordinates will actually be a multi-polygon, but that's OK because you can either simplify to a geopoint (e.g. use the centroid), or show the entire polygon range in your map.Instead of planet.osm you can also do this for illinois.osm, or whatever region you want."
Is there a dictionary containing Arabic first and names and their English equivalent?,"
I have an Arabic and English spreadsheets containing people's information including first and last names.  I have no identifier I can use other than those names, no unique ID or anything.
At the most basic level, I'm looking to see if there's a dictionary containing Arabic first and names and their English equivalent
""ali"": ""علي""
If there are better dictionaries that take into consideration the different ways people write their names, it would be even better
a[""إلياس""] = [""elias"", ""eli', ""elie""]
But I'm okay with the most basic dictionary, something is better than nothing
","['data-request', 'names', 'dictionary', 'translation']","It seems there are some commercial databases, but if you are brave and don't need an exhaustive list for 100% coverage, you could use Wikipedia articles for Arabic peopletop level : List_of_Arabic_given_namesmid level : Abeer bottom level : Abeer_HamzaOther top levels : Category:Arabic_feminine_given_names, Category:Arabic-language_namesWikipedia is available as a dump, so you wouldn't need to scrape. You could also switch back between AR and EN or other languages, which would give you URLs with the person's namehttps://ar.wikipedia.org/wiki/%D8%B9%D8%A8%D9%8A%D8%B1_%D8%AD%D9%85%D8%B2%D8%A9Actually, a Wikidata/Sparql query would probably work, but I can't help much more than that.Take a look at this question for getting city names in different languages.And this slightly modified query."
2 category intersection with PetScan not working?,"
I'm trying to create an intersection between two categories on Wiktionary using PetScan (http://tools.wmflabs.org/catscan2/catscan2.php), but I can't get it to work. What I've read says it should be possible to do, so I'm pretty sure the error is user-generated! (ie; I don't know what I'm doing.)
Basically I want to generate a list of entry links that are tagged in both of the following categories:
https://en.wiktionary.org/wiki/Category:Japanese_terms_spelled_with_kanji_with_kun_readings
https://en.wiktionary.org/wiki/Category:Japanese_terms_spelled_with_kanji_with_on_readings
The first has 2009 subcategories and the second, 1035 subcategories.... way too many to check manually. If someone could help me out, I'd really appreciate it. Thanks.
","['wikipedia', 'wiktionary']",
Where to get realtime stock market data legally,"
Can anybody point me to some service (free or paid) where my software can get real-time market data for analysis without recurring to web scraping? I'm interested in Latin American stock markets
","['data-request', 'finance']",
Where to find myPersonality Dataset?,"
MyPersonality Project is a Facebook application used to predict personality based on an online questionnaire. Dataset consists of status updates from 250 users, which already labeled into Big Five personality dimensions. All posts from single user ID appended into one long string which considered single document. Final dataset is in the form of 250 documents from 250 users.
I want to build multi-label classification model on this dataset , but cannot find the dataset . Please help..
",['data-request'],
Numerically order SPARQL results that are external identifiers but actually all numbers,"
I wrote this query to list Wikidata items that have an RFC identifier:
SELECT ?rfcId ?itemLabel ?classLabel ?item
WHERE 
{
  ?item wdt:P31 ?class.
  ?item wdt:P892 ?rfcId.
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""[AUTO_LANGUAGE],en"". }
}
ORDER BY ?rfcId

A minor problem is that they are sorted in an alphabetic way: 1, 10, 100, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 101, etc.
I tried using ORDER BY xsd:nonNegativeInteger(?rfcId) but it does not work, probably because the property is defined as an ""external identifier"" rather than as a number.
Can I modify the query to sort results in numeric order (1,2,3,4,5,6,7,8,9,10,etc)?
","['wikidata', 'sparql']","As tipped by Stanislav Kralin and Barry Carter, ORDER BY xsd:integer( is the solution:https://tinyurl.com/yazaeneq"
Automatically extract road points from a point cloud,"
My goal is to extract points belonging to a road from a point cloud that has geospatial annotations. I wonder if there exists some openly accessible database/tool with exact coordinates of a road's edges?
",['geospatial'],
"Where can I find publicly available economic data (American) on consumption, business spending, etc. for 1900-1950, by county/region?","
I'm not very familiar with data sources in the United States, but is it possible to find ""standard"" economic data, like household expenditures, average/median household income, average/median business spending, etc. by county for the time period 1900 - 1950? It doesn't have to be every year, but every 5-10 years would be helpful.
I saw this question that suggests the ACS and Decennial Census for more recent decades (like back to 1990), but I'm looking for historical data.
","['usa', 'historical', 'economics']",
GIS Data for Illinois Electric Distribution lines and Substations,"
I am looking for the Ameren and ComED's distribution lines and distribution substations. They are the 2 largest electrical utilities in Illinois. I know the HLIFD data has Transmission lines and transmission substations, but these are 2 different types of systems. 
","['data-request', 'geospatial', 'usa', 'energy']",
download and convert the data of the Medical Device Adverse Event database,"
I'm trying to convert the data from this database to a format like csv or sql database. The goal is to analyze this data with R later. I would like to store them in a local database to be able to analyze all the values. How can I implement this the easiest? I have already made a few attempts but without success.
","['openfda', 'download']",
Ordered admissions,"
Considering the date shift procedure adopted in MIMIC-III (add a random offset for each patient), is there any way to identify ordered admissions or ordered patients records?
My intention is to split the dataset into two even halves, to be able to compare them, however, it must be ordered for this purpose.
",['mimic-iii'],
Drug label information does not include all approved drugs (kymriah and yescarta missing),"
It appears as though some drug labels are missing.  I just want to know if I'm missing something obvious?
Specifically I cannot find either Kymriah or Yescarta searching by their brand or generic name.  Both drugs were approved in 2017.  I have downloaded the complete label dataset from https://download.open.fda.gov/drug/label/drug-label-000X-of-0007.json.zip and confirm that neither terms appear in the complete dataset at all. 
Example search:
https://api.fda.gov/drug/label.json?api_key=XXXX&search=kymriah
edit: I have confirmed that the kymriah label XML files are present on the SPL S3 bucket:
s3://download.open.fda.gov/data/spl/11dc1c28-0cf5-4290-b499-eb5391a232c2
s3://download.open.fda.gov/data/spl/22dc1c28-0cf5-4290-b499-eb5391a232c2
s3://download.open.fda.gov/data/spl/60770743-9a0b-4793-a4c7-8ebcd2d02080
edit after answer:
To expand Denis Krylov's answer.
The SPL processing pipeline uses SPLDocuments.csv as the master list for drugs to process and import into OpenFDA.  The file can be retrieved as follows:
aws s3 cp s3://download.open.fda.gov/data/spl/change_log/SPLDocuments.csv .
If we were to execute:
head SPLDocuments.csv
We would get something like the following:
""Document Id"",""Document Type"",""Load Time""
7b8f583f-8df4-4aea-bec8-206598ecfefe,""HUMAN PRESCRIPTION DRUG LABEL"",20180402100037
bac17f46-9dfa-4e00-a047-02067e450f84,""Indexing - Substance"",20170928145900
The SPL processing pipeline only takes items that contain 'human' in the second column (document type).  As of today, there are 18 products which contain ""cellular therapy"" as the document type.  These are currently ignored by openfda, although its not clear if this is by design or not.
",['openfda'],Cell therapy drugs aren't indexed by openFDA. Please see the relevant code here: https://github.com/FDA/openfda/blob/master/openfda/spl/pipeline.py#L90
Data for spare parts for large machines/equipments,"
Data request
I am looking for a data-set that contains information about the sales of spare parts after the original machine/equipment has been sold for a B2B environment. The data ideally should contain following information. I have taken example of car. 

Part Type/Name (Spark Plug, side mirror) 
Part quantity (2 side mirrors or 1 gear box)
Price and cost of the parts if available
Information about original product (product type, model, product cost etc.)
Severity level  (Clutch wire could have a high severity level, horn may have medium severity etc.)
Labor amount associated to fit the part
Whether part is covered in insurance/warranty etc. 
Dealer information (number of product repaired daily or anything else etc.)
Margins of dealer on the spare part
More information (please read the context)

Context
I am trying to analyze the optimal pricing for spare parts for a B2B context. To see if manufacturer can increase prices to improve revenues/profit. 
Region
Any Region of the world is fine. 
License
Just for my own analysis purpose, I will not use it anywhere. So any license which allows me to analyze the data freely is sufficient. My objective is to familiarize myself with such kind of data and analysis.
Format
Most preferable would be a CSV or multiple .CSV along with information on the keys. Basically anything that can be easily read in R will work
Requirements
Data should be at transaction level, basically, one observation for each transaction. 
",['data-request'],
Is there a free historical database of US corporate yields or spreads by maturity buckets?,"
I have US corporate spread data by maturity buckets going back to the 90s but am looking to go back much further, to the 60s. Does anyone know of a freee database which contains that information?
","['data-request', 'usa', 'historical']",
Search queries on open data sites,"
What are people searching for on open data sites?
Just like Google Trends, I am looking for some statistics or even just examples of what search phrases people are using on https://catalog.data.gov/dataset or any other open data sites.
",['data-request'],
Where to find datasets for creating carto vl maps?,"
Is there any way to download example datasets like nyc taxi and origin-destination data? (Like those that show flight paths from and to some cities) I think it'd help me greatly if I could somehow get those data and try to create VL animations on my own.
","['data-request', 'geospatial', 'uses-of-open-data']",
Vital statistics of the United States (early 20th century),"
The US census bureau published annual volumes in its series ""Vital Statistics of the United States"" between 1890 and 1930. 
Each report is available as a pdf here:
https://www.cdc.gov/nchs/products/vsus/vsus_1890_1938.htm
Has anyone digitized these records?
","['us-census', 'historical']",The National Historical Geographic Information System has digitized Vital Statistics from 1915 through 1970.
Famous people API,"
I'm looking for an API for retrieving data about famous people, and most preferably to retrieve info about inspirational famous women in the last 100 years. Can you please tell me where to start looking? Is there any good REST API that I can use??
","['api', 'rest']",
Seeking examples of Open Data in formal journalism Standards & Practices,"
As an arbitrary example, note this page is CBC (Canadian Broadcasting Corporation) Radio's Standards & Practices on Investigative Journalism. Note the section on Data Journalism (which is silent on Open Data).
I'm looking for a similar document online for any major media outlet that clearly addresses Open Data in the contemporary sense. 
Perhaps the example states something like: ""When Open Data is used relating to a story, we provide a link to the data and the license, in accordance with the stated licensing terms of the provider"". (I'm not a journalist but hopefully readers will get the idea. I'm coming at this from the Open Data perspective.)
Ideally, it might even say ""We ask about Open Data as a part of normal protocol. If data is provided, but not as Open Data, we disclose that the story contains data which is not Open Data"". 
",['journalism'],
Seeking Election Voting Data for Constituencies for Karnataka State Elections for 2013 and 2018,"
I require data pertaining to the number of votes for each candidate in their specific constituency in the state of Karnataka for 2013 and 2018 elections.
I have surveyed the Indian Election Commision website, however, I cannot find anything for 2013.  
","['india', 'elections']",I found the below link for results of state and general elections:http://lokdhaba.ashoka.edu.in/LokDhaba-Shiny/
How to find a list of all dairy farms in the New York State?,"
I work for Cap Vert Energie, a French company which has a branch in New York. Our activity consists in developing photovoltaic installations. Thus, we search for infrastructures in the New York and Massachusetts states on which we can put solar panels. More precisely, we look for Dairy farms, sheep farmers and goat farmers so we can maybe put solar panels on their roofs. 
Does data.gov or other sites have this kind of data?
","['data-request', 'data.gov']",
Where can I find a large log dataset?,"
Where can I find a large log data-sets? I am looking for the actual raw logs where I can perform some regex parsing. But I need a large data-set, I previously used SotM 34 that has around 260000 log lines, and also SotM31 that has around 4 million log lines, but that's not enough because my algorithm process the last one in 13 seconds, so I need some log lines that has around 10 million log lines or so.
Bests 
",['parsing'],
Has anyone created an RDBMS database for NOAA weather data?,"
We are interested in the weather data published by NOAA via Data.gov The site offers the ability to download data as PDF or CSV files. Has anyone created a real RDBMS (MySQL, SQLite) database out of the data? Is that available as an open-source resource?
",['noaa'],
"using openfda.brand_name.exact:""Tylenol"" case sensitive","
I have recently come across openfda.brand_name.exact. It is getting the results where the brand name has to match exactly, i.e. also case sensitive. For example, the query 
api.fda.gov/drug/label.json?search=openfda.brand_name.exact:""infants%20Tylenol""&limit=30
gives results but if i change the brand name to ""infants tylenol"" (small t), it won't return any results. Is there any way to query for exact brand_names, but with case in-sensitivity? 
",['openfda'],
Data for all lakes on Earth?,"
Is there data available for all lakes on Earth? Even just a list of names would be nice; metadata is also welcome. 
In this case, a lake is any enclosed body of water with a surface area between some arbitrary limits. Maybe someone already wrote a script that can provide such an output?
Wikipedia has a couple of lists, but they have a lower limit, i.e. small lakes are not listed.
","['data-request', 'geospatial', 'metadata']",
Seeking data for image fusion of satellite and UAV/ drone data?,"
I'm new to Remote Sensing and Data Processing, and interested in fusion.
Where do I find georeferenced data that can be fused together?
It can be either of the following:
Satellite image and drone image (multi/ hyper spectral)
Satellite image (multi/ hyper spectral) and spectroradiometer data (quantitative)

For satellites, I think I can go with Landsat images, but which one should I use/ where do I find the corresponding second data to fuse together.
","['geospatial', 'images']",
use cases and datasets for manufacturing industry,"
Sorry for such a question. I am new to machine learning. I have gone through some machine learning tutorials.
I currently have a dataset from manufacturing sector which include sensor data, process data etc. 
Actually I have been given a task to find parameters that can help company produce the least amount of scrap.
The data is coming every minute and include parameters like timestamp, number of parts produced, correct_parts_number, incorrect_parts_number,product_type,machine_status
Can someone help me to know which model should I go for and what should be the approach. I think number of attributes are less. Or if someone can share a simple dataset that is helpful in manufacturing industry to reduce scrap percent. So that I can get an idea.
","['data-request', 'machine-learning', 'analysis']",
one US zipcode for two cities what should i default to?,"
Can a zipcode contain more than one city. For example, it seems that Foster City, CA and San Mateo,CA both share the same zipcode: 94404.  
i have a data dump that labelled ""San Mateo"" as a primary city, and ""Foster City"" as an 'acceptable city'.  which is why I was confused...who determines San Mateo is a primary city.:p
i even noticed Google defaults to the 'primary city' of San Mateo when searching only for the zipcode 94404

",['postal-code'],"Yes, a zipcode can cover more than one city. As Barry Carter said in a comment, a zipcode can even cross state boundaries. I'm fairly sure that that ""primary"" and ""acceptable city"" are not official designations. I think the only real way to know the meaning of those definitions is to ask the publisher of the data you are using."
how to open and read .alarms files in MIMIC II,"
I have a question about the .alarms files in MIMIC-II. I am not familiar with the .alarms file type and I could not find information about this on the internet. Could someone let me know how best to open and read these .alarms files? I have tried different programs but always only some of the texts are shown correctly.
",['mimic-iii'],
Filter wikidata results with 'around' service,"
Is it possible to use the ""around"" service as a filter, for example to search for a place name in a country and limit results to those within a given distance of a known point.
For example, limit results of the following search to those within 50km of
""Point(-98.966111 19.310278)""^^geo:wktLiteral 
SELECT distinct ?item ?itemLabel ?countryLabel ?geom

WHERE { 
    SERVICE wikibase:label { bd:serviceParam wikibase:language ""[AUTO_LANGUAGE],en"". }

  ?item rdfs:label ""Santa Catarina""@en ;
   (wdt:P31/wdt:P279*) ?itemType ;
    wdt:P17 ?country .
    ?country rdfs:label ""Mexico""@en .

  # human settlement | archaeological site  
  FILTER (?itemType = wd:Q486972 || ?itemType = wd:Q839954) .

  # coordinate location
  OPTIONAL {?item wdt:P625 ?geom . }
}

","['geospatial', 'wikidata']",
MIMIC-III medication order frequencies,"
So is it true that there is no information of the frequency of medications ordered in MIMIC? The prescriptions table just has the dosage of each administration and the days the prescription was ""active"", but no indication of the frequency (e.g. daily, bid, q8 hr, prn, etc). I understand that there's the option of looking for the item id in inputevents and trying to deduce the frequency from that, but it won't tell you if the doses were ordered separately or scheduled (two one-time orders or one twice-daily order). 
Is this true? If so why was the frequency part of the Rx lost from the prescriptions database?
",['mimic-iii'],
Gender pay gap dataset,"
I'm looking for detailed data from which I can explore the gender pay gap, I'm not looking for any country in particular, but the more the better. 
The important point for this is how detailed the data is: age, occupation, college degree, hours worked a week...
Basically, I'm giving for granted that there is a pay gap and I want to look into the reasons for this.
If there are datasets already available for this, awesome! 
If not, I'm looking for pointers to make an efficient search.
EDIT: 
I was pointed to this site:
https://nces.ed.gov/programs/digest/2017menu_tables.asp
Which contains quite good data, the issue here is that the format of these tables is pretty messy, the number of columns is not fixed and for some cases there is more than one field for each cell (E.G: standar error) and when converted to .CSV there are empty columns in the middle, is not imposible to work with this data but it can be very time consuming to fix all the files to start an EDA.
https://nces.ed.gov/programs/digest/d17/tables/dt17_502.30.asp

",['economics'],
Looking for spatially referenced aerial photos,"
I am trying to find a source of spatially referenced aerial photos that can be analyzed with ArcGIS or R. I cannot use Google Earth because I have nothing to georeference it to. I know they are out there but it has been years since I have used to program. Specifically, I am looking for Napa County, California.
","['data-request', 'geospatial', 'usa', 'aerial-photography']",USGS' Earth Explorer is an excellent resource for this type of imagery (unless the US Govt is on shutdown). In this case I would look for NAIP imagery in your area of interest.
Area income data for percentiles other than the median?,"
I'm looking for data similar to the Area Median Income, except that provides information about other percentiles. For instance, what are the 10th or 90th percentiles of income in my county?
I saw that HUD releases data that calculates ""percent of AMI"" for various percentages. But 10% of the median isn't the same as the income of those living in the 5th percentile.
Any leads?
","['usa', 'us-census', 'economics', 'income']",
Is there any pro wrestling dataset available ?,"
Is there any open data-set available for pro wrestling? Something like matches info, ppv data or even start ratings for matches helps. Wrestling promotions could be wwe/wwf, njpw, roh or impact/tna wrestling.
","['uses-of-open-data', 'sports', 'database']",The Internet Wrestling Database is a free resource of professional wrestling information. http://www.profightdb.com/tos.html
Apartment locations in Pennsylvania?,"
I'm working on a project to find apartments within 30 mins of work location. I wish to know all the apartments in Pennsylvania. Where can I get this info from. 
I checked https://data.pa.gov. But couldn't find it.
","['geospatial', 'usa', 'real-estate']",
Where can I find publicly available data on American dietary habits and food intake during the Great Depression?,"
I'm looking for detailed data on American dietary habits during during the Great Depression and WWII era, specifically 1930 - 1945. Were there any surveys that collected detailed information, at a household level (ideally with demographic characteristics too) about the foods and other items that Americans consumed?
","['medical', 'historical', 'food']",
Data on charging station for electrical cars,"
I am currently looking for data sets on charging stations for electrical-powered cars in Berlin, Germany. I checked the Berliner Senat Website but found only this http://fbinter.stadt-berlin.de/fb/berlin/service.jsp?id=re_ausbau_der_ladeinfrastruktur@senstadt&type=WFS&themeType=spatial
While this is interesting, it contains only information about charging stations in different states of planning and authorization, but not actually stations where one could charge a vehicle.
Where could I find data on electrical charging stations in Berlin for import in GIS software?
",['geospatial'],"You could query OpenStreetMap with amenity charging_station.https://wiki.openstreetmap.org/wiki/Tag:amenity=charging_stationFor example, you could use the Overpass API: http://overpass-turbo.eu/s/zBb.Run the query and click ""export"" to download the data.
"
Looking for dataset of the coordinates of the UK NUTS Levels,"
I cannot find the coordinates of the UK NUTS levels. There are resources which tell what the name and the code of NUTS regions are. But they do not provide what are their coordinates! I need a dataset which should include the NUTS name and the lat/long that surround the area.
Data can be in any standard formats, e.g. CSV or Geojson. 
","['geospatial', 'uk']",
NDVI Imagery for Iran,"
I'm trying to find a good source of NDVI imagery (vegetation), but I'm struggling to find proper high resolution imagery for Iran. 
Does anyone have references to NDVI imagery (at sub-10m resolution) for 2012-2014?
","['data-request', 'geospatial', 'uses-of-open-data', 'images', 'land-cover']",
Where I should store (public) dataset for opensource project? [duplicate],"







This question already has answers here:
                                
                            




How can I reliably host and share large data sets?

                                (7 answers)
                            

Closed 5 years ago.



I have a project. It's basically doing 2 things:
- collect data
- do something with the data
The codeI use is open source and available on GitHub.
The crawler that collects the dataset works slow (400 pages per minute), and the resulting dataset will big: 40 million records, more than 2000 MB.
I assume that the dataset could be useful as a stand-alone object. May be somebody will do something else with the data and the person will not have wait 100 days to collect it again, if I share it.
Where can I store this data, to make it available for any person and to keep it free of charge without abusing GitHub?
History of the dataset changing would be a nice feature...
",['uses-of-open-data'],"What makes you think storing data on GitHub is an abuse of GitHub?
It most certainly is not. GitHub showcases Open Data repositories as one of its features.
So use GitHub, you already are anyways.
If GitHub simply will not do, check out datahub.io, data.world, or data portals that are specific to the type(s) of data you have been collecting.  If size is the issue and you aren't comfortable with breaking the data up into multiple zips to get around GitHub's sizing issues, then Dat data and Beaker Browser seem like another possible solution for you."
Requesting Workplace accident data from the UK Government,"
In the U.K. the Health and Safety Executive collects workplace accidents and fatalities data. They publish aggregated summaries but not the raw data. 
How and to whom do I request the raw data?
","['data-request', 'government', 'medical', 'uk']","Probably the easiest way is to make a freedom of information request via WhatDoTheyKnow.com. You will have to be very careful, however, to phrase your request in such a way that they cannot reject your request on the basis that the data might allow you to identify a living individual. You can avoid this problem by making sure your request is tightly focused on the data you want for your project. For example, if you want to look at whether rates of accidents vary across days of the week in different industries, you should request only those fields that you need for each incident (e.g. the industry and the date of the accident), while not requesting the location of the accident (since you might be able to combine that with the date to identify a person). More detail about how to make a good FOI request is available.One benefit of using WhatDoTheyKnow over making an FOI request by email is that other people will be able to see (and use) any data you get. If you're not comfortable with that (e.g. because you're a journalist and you want a scoop) then you may prefer to make the request by email."
Crosswalk between FIPS codes and Wikipedia articles about U.S. Census Places,"
The English Wikipedia includes an article for nearly every U.S. Census Place. Has anyone published a crosswalk from FIPS codes of these places to Wikipedia urls?
Is this something that would be possible with wikidata?
","['data-request', 'us-census', 'wikipedia']","Is this something that would be possible with Wikidata?Yes, this is possible:Try the  following query:If you need FIPS 6-4 codes instead of FIPS 55-3 ones, replace wdt:P774 with wdt:P882."
mouth image dataset - with tagged teeth,"
There are many face image datasets for image recognition, but I'm looking for one that focuses on images that show the mouth, and are tagged with if the face is showing their teeth or not.  Could be smiling or making a face like Jack Nicholson in The Shining.
I'd also take a selfie image dataset, and then I could do the teeth-tagging myself.



","['data-request', 'images', 'faces']",
Seeking free vector data on road type in Africa,"
I'm looking for a database on African roads, but I want to know what type of road this is (paved, tarred, and so on) in order to assess not only the quantity but also the quality of the road network.
Does anybody know if a database of that kind already exists?
","['data-request', 'geospatial']","You can get road data from OpenStreetMap: https://wiki.openstreetmap.org/wiki/ShapefilesThe road data will often include information on the surface, i.e. whether it is asphalt, gravel, or dirt.OpenStreetMap data are freely available and editable, but they are crowd-sourced. There is no guarantee of completeness, especially in regard to road's surface type."
API to find Latitude and Longitude based on Unique Well Identifier(UWI) info Canada,"
I'm looking for an Open Source API to find out Latitude and Longitude based on provided LSD or Section or UWI info of Alberta and BC province of Canada.
Any help.
","['geospatial', 'api']",
How do i collect mult temporal satelite imagery?,"
I am doing a project on change detection on remote sensory images over India.
I need images of the same place on two different time instances.
However i am only able to find images of certain place in a particular time (not selected by me).
","['data-request', 'geospatial', 'data.gov', 'images']","You can access multiple years of Landsat data here: https://earthexplorer.usgs.govSentinel data can be found here: 
https://earthexplorer.usgs.gov
And this post explains how to access the data: 
https://gisgeography.com/how-to-download-sentinel-satellite-data/Landsat has global coverage and decades of data, but you may want to be careful that the data you are accessing has the same satellite footprint / spatial resolution. The newest data, of higher ewsoluation, can be matched to the 30m resolution of older data by resampling the Imagery if you want to use a consistent spatial resolution. "
Data on Lobbying Expenditures: Net Neutrality,"
I found this really interesting graph at sunlightfoundation.com.

I would like to do one of my own, just with a few style tweaks and updated for 2018, or at least 2017. I checked the source's website, but found no raw data there. Perhaps by ""source"" they meant they were the ones who put the graph together? I would imagine they must have got their numbers from somewhere.
Question: Is there an open resource for lobbying expenditures? I presume I could then narrow the selection down by topic. I am basically only interested in Net Neutrality lobbying data at the moment.
","['data-request', 'usa', 'government']","Apparently they used data from OpenSecrets. Access to their data is available at https://www.opensecrets.org/open-data. Mentions of net neutrality in lobbying reports, 2005-2013; Sunlight Foundation using OpenSecrets.org dataOpenSecrets"
Get subgraph connecting two resources,"
What is the best strategy using SPARQL queries over DBpedia to retrieve the subgraph that connects two resources ?
",['dbpedia'],
Clam image dataset to an image classification,"
I´m trying to classify images of 3 clam species:
Ruditapes Decussatus 

Venerupis Pullastra 

Ruditapes philippinarum

I've read that you can scrape from Google Images; but as you can see, I do not think that Google's differentiation with respect to these species is reliable enough. And the ton of images to train can be really tedious to separate manually.
Does someone know a dataset that can be used; or a pre-trained network?
",['data-request'],
Shapefiles of 20th Century British Railways,"
I'm looking for shapefiles of the British railway network from any time between 1900 and 1970 (before many of the railways were closed). There are many historical GIS sites (such as GBHGIS and Vision of Britain) but none of them seem to have any railway data.
","['data-request', 'geospatial', 'historical', 'transportation', 'public-transport']",
Estimated use of condom over time and it's effectiveness on HIV?,"
I'm looking for data to compare the use of condom among people (percentages) over time, and then in the same place and the same time, the number of people infected with HIV.
What I need exactly:

The number of people in one given population (or globally).
The number of them infected with HIV (or other STDs).
The use of condoms during the same period in this population.
If possible, I want to see the outbreak of the disease.

I don't really care about which population, it's just for testing an epidemiologic model.
","['data-request', 'medical', 'disease']",
Where can I get the Beijing ring road traffic data (speed of vehicles)?,"
In some papers, it is used the Beijing ring road traffic data. 
I searched the internet, But I didn't find the dataset.

For example, in a paper, it is noted:

""Beijing is the capital of China and one of the largest cities in the world. At present, Beijing is encircled by four two-way ring roads, that is, the second to fifth ring roads, and has about 10,000 taxis to serve its population of more than 21 million. These taxis are equipped with GPS devices that upload data approximately every minute. The uploaded data contain information, including car positions, recording time, moving directions, vehicle travel speeds, etc. The data were collected from 1 May 2015 to 6 June 2015 (37 days).""


How can I get them? Is there a site to download it?
Or do you know a good data set instead of it that contains the speed of vehicles?
Thank you
    ","['data-request', 'transportation', 'traffic']",
Dataset for clothing,"
I'm looking for a dataset for at least one product segment with at least 1000 records and with attributes like:

product name, 
product price, 
shipping type (free or customer paid)
monthly sales ($)
geographic region
no. of customers who bought the product, 
customer type (new or existing) 

",['data-request'],
Books and Supplies,"
""Books and Supplies"" is a component of the Estimated Cost of Attendance. I would like to get only the ""Books and Supplies"" data for a given institution from the ""College Scorecard"" data.
","['education', 'collegescorecard', 'books', 'cost']",
climate station data -not gridded data,"
I am look for monthly temperature and precipitation data for various countries. Ideally the data would be for period 1981-2010, but other would also be fine.
I know this site: https://www.metoffice.gov.uk/research/climate/climate-monitoring/land-and-atmosphere/surface-station-records
but it has only temperature-data
edit 8.6.2018:
https://www.dwd.de/DE/leistungen/klimadatenwelt/klimadatenwelt_node.html
has some data, but for period 1961-1990
",['climate'],"Finally I found some useful links for station-based data for period 1981-2010:
data for Austria:
https://www.zamg.ac.at/cms/de/klima/informationsportal-klimawandel/daten-download/klimamitteldata for Germany:
https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/multi_annual/mean_81-10/data for switzerland:
https://www.meteoswiss.admin.ch/home/climate/swiss-climate-in-detail/climate-normals/climate-diagrams-and-normals--per-station.html?region=Tabledata for USA:
https://www1.ncdc.noaa.gov/pub/data/normals/1981-2010/data for Australia:
http://www.bom.gov.au/jsp/ncc/cdio/cvg/av?p_stn_num=015528&p_prim_element_index=0&p_comp_element_index=0&redraw=null&p_display_type=statistics_summary&normals_years=1981-2010&tablesizebutt=normaldata for Canada:
http://climate.weather.gc.ca/climate_normals/results_1981_2010_e.html?stnID=1641&autofwd=1"
Seeking globally available road data for medium-scaled maps (1:200.000),"
I am seeking open data of roads for medium scaled maps (1:200.000, 1:500.000 up to 1:1.000.000). For the whole world, at least Indonesia and Africa. 
I know I could use OSM streets and somehow generalize them. But for my purposes this would be too time-consuming. 
","['data-request', 'geospatial', 'transportation', 'africa']",
Downloading Public Building(s) Lat/Log,"
Currently, I am working on a project that requires information for public buildings.
I was wondering what options are available to find the address and lat/log for each individual public building within a city? My project compiles of all individual departments within a city within a county. So I need the ability to see everything from a county and each city department within that county. 
For example, all schools, parks, fire stations, police departments, city hall, etc. for the City of Columbus Ohio.
","['data-request', 'geospatial', 'geocoding']",
Precinct Name Change Across Time,"
I am looking for one or several sources that record changes in precinct names across time in the US (at least after the 2000s). 
I have looked on individual states' webpages, as well as other website such as this. I can only find current names/codes of precincts but not the corresponding codes of those precincts that may have split or joined others across time. 
For example, no county has the same number of precincts and precinct names in 2000 as it does in 2018. I am interested in knowing, say, whether a precinct called 1-1 in 2000 is the same as one called 1-1A in 2018 in a given county. Any leads would be much appreciated.    
","['usa', 'us-census', 'elections']","The best source that I know of for precinct shapefiles is https://github.com/nvkelso/election-geodata. From this data, you would be able to identify whether a precinct has the same geography between elections and the same name, or whether either the geography or name has changed."
Poverty estimates from Census API,"
I am trying to complete a project for a local nonprofit I work with. I am trying to use the Census API to pull in certain estimates in each of the counties they work in.
I am trying to pull in poverty estimates at the tract, sub-county, and county levels. The data I need is in the S1701 dataset under the American Community Survey. It seems that I can't find the variables I need to call the data through the API.
For example, I need the estimate for ""Population for whom poverty status is determined"". I can't find the variable I need in any of the tables listed here.
I am new to all of this. If anyone has any advice, that would be appreciated.
","['usa', 'api', 'census', 'economy']",
Faces dataset with/without mustaches,"
I'm looking for a dataset with faces with a label that indicates if the face contains a mustache. I already discovered that CelebA has those kinds of labels but haven't found another one.
","['data-request', 'faces']","The Face and Gesture Recognition Research Network (FG-NET) aging database should, among others, contain this kind of labels.
I found a download-link in a comment on researchgate (www.researchgate.net/post/Does_anyone_have_a_working_link_to_the_FG-NET_ageing_database_or_any_other_ageing_database/amp)"
Non-obvious real-world datasets for observational causal inference,"
I am working on a project involving inference of causal direction from purely observational data, and not time series (given several assumptions, of course). I've been using the CauseEffectPairs database to validate my method, but the ground truth in these datasets is based on the obviousness of true causal direction (e.g. altitude causes air temperature, age causes income). However, causal inference would be useful in the real world if it could identify a true causal direction in cases where it is not intuitively obvious.
Let X and Y be collections of L observations of variables with dimension n and m, respectively. I want to evaluate my method on datasets with the following characteristics:

There exists a non-confounded causal relationship between X and Y.
The causal direction is not obvious. That is, reasonable mechanisms could be proposed both for the case where X causes Y and for the case where Y causes X, such that an experimental intervention would be necessary to choose between the two hypotheses.
There exists experimental evidence that identifies the true causal direction (i.e. there's a ground truth).

The data can be continuous, discrete, categorical, mixed, etc.
For example, a dataset containing years of education and income at age 30 for some sample of US citizens would meet the first two criteria: 1) There is a clear correlation between education and income. 2) It is not clear whether education actually gives people the ability to earn more, or if people with the ability to earn more are predisposed to spend more years in education. This dataset would meet the third criterion if an experiment had been published that randomly assigned some people to pursue higher education and others not to do so and then observed their income at age 30. For obvious reasons, nobody has actually conducted such an experiment. So this would be a situation where observational causal inference would be useful, but I can't use this data to validate my method due to lack of ground truth.
The best answers would list some publically available data that could be used to create a dataset with the above criteria or describe a set of measurements that could be easily carried out that would produce such a dataset.
",['data-request'],
Where to get realistic data for ABC-Costing in textile industry,"
First, let me explain what I am trying to do. For my graduation work with focus on automation I would like to show the impact of ""Sewbots"" (SoftWear Automation) on garment manufacturing.
My teacher suggested doing so by applying activity-based costing for a production line and then, by hypothesy, on a partly automated one. (I know one system of SewBots costs approx. 50.000 - 100.000, it can replace up to 17 workersand needs 1 supervisor for up to 5 production lines.)
I found some data on ABC in garment production but none of it seems complete (ex. http://journal-archieves30.webs.com/602-625.pdf).
Can someone suggest some sources where to get complete realistic data of activities, cost drivers, rates etc. in textile industry?
Every advice is appreciated. 
","['data-request', 'industry']",
Is cadastre data for Italy publicly available for download?,"
I am looking for a website where I may be able to enter the numbers of pieces of land and would be able to find some cadastre data, i.e. at least

size of the plot (square meters)
possibly shape and neighbouring plots
buildings

I would need this for certain places in Italy.
","['geospatial', 'italy', 'cadastral']",
Downloadable archives of illumination in Europe?,"
I'm trying to make a DLI (Daily Light Integral) map of Europe (what DLI has each country per month), but I can't find the data to do that. 
Is there any Open Source dataset that includes the DLI information, or some data usable to calculate the DLI? (Global Illumination, PAR (Photosynthetically Active Radiation), quantity of light, etc).
","['data-request', 'weather', 'europe']",
Looking for the itcvd vehicle detection dataset,"
In the article Vehicle Detection in Aerial Images the authors used a dataset of vehicles from aerial view called itcvd. I could not find any information on it online.
How can I obtain more information on it or download it?
","['data-request', 'aerial-photography']",
Mexican Sinkhole Locations,"
I'm looking for a dataset which catalogues the locations of all (or many) of the sinkholes in Mexico (specifically Yucatan), but I haven't had any luck.
I kind of hoped USGS would have some of the data.
Preferably, the data should be in CSV, XML or JSON format, but I can work with other formats.
","['data-request', 'geospatial', 'mexico']","I think you are speaking of cenotes. If so, a shapefile of the locations of cenotes is available from the Territorial Ecological Planning Program of the State of Yucatan."
Where can I find the open source data for the tick - Amblyomma americanum collection data of the USA?,"
Looking for the Amblyomma americanum tick data year wise in the USA  to analyze the risk of getting disease associated with the Amblyomma americanum
","['data-request', 'data.gov', 'disease']",
components of population change at block group level,"
I've been trying to find a good source that connects components of population change (births, deaths, migration) to the block level.
Whats the best source for this?
","['usa', 'census', 'population']",
Where can I find publicly available data on aggregate enrollment in health insurance *before* Medicare?,"
I'm looking for data on the number/share of people who had private health insurance by age and region (county, for example) before the introduction of Medicare in the United States? As in, before 1965?
","['medical', 'historical']",
CEO Pay Ratio Data,"
The recently released Rewarding or Hoarding report indicates...

According to the SEC, approximately 3,571 companies are required to file ratio disclosures

Then this report goes into details on...

the first 225 Fortune 500 companies to publicly disclose this information.


Where can I find the CEO to median worker pay ratio data from the current disclosures of these 3,571 companies? The analysis of 255 of the Fortune 500 disclosures is interesting; but seeing an analysis of the other companies would offer further insights.
If a compiled dataset doesn’t exist, then what is the best path to collect the data that has been released? Is there perhaps an SEC API to utilize?
I’m curious to see how many median pay jobs could potentially be formed if there were regulations restricting the pay ratio. If such an analysis has already been done with this data that would be even better.

For historical context, in 1965, the average CEO made 20 times the average worker.

","['data-request', 'usa']","The Ellison report says thatThese data were compiled by Bloomberg from the SEC’s EDGAR database.Unfortunately, it seems that SEC's EDGAR doesn't provide API.One can extract some information from the page on the Bloomberg site. The JS code is obfuscated, paste the following into browser console, emulating user actions:This is how output looks like (~760 records as of May 21, 2018):Data for the Technology sector companies:"
"Historic spatial extent of Beirut, Lebanon?","
I am looking for historic extent data for the city of Beirut, in Lebanon.
I would like to show the growth of the city over time, from 1950 to today. The data are to be used in a web visualisation to aid story-telling and therefore do not necessarily have to be from an authoritative source. Ideally I'd like to show the growth of the city one decade at a time, so 1950 - 1960 - 1970 - 1980 and so on.
I've looked at a number of data sources - including GADM and a number of 'GIS data aggregator' sites. Whilst finding contemporary boundaries isn't too difficult, finding historic data for comparison purposes is proving a challenge. Any spatial format is fine, even Excel with coordinates would be workable.
","['geospatial', 'government', 'historical', 'city']",
UK boundary data shapefiles where features have attributes pointing to their parent subdivision?,"
I know similar questions have been asked before but none have given me exactly what I need. I am trying to find boundary shapefile data for the UK which splits different subdivisons into different layers (the exact number of subdivisions doesn't matter), with each feature of a layer referencing it's parent in the above layer.
I would like the data to be 'clean' in that each layer only has appropriate regions, e.g. a county and city aren't on the same layer, so that all features of a layer are of a similar size and no features are surrounded entirely by another feature on the same layer (an enclave).
The closest I have got so far is at gadm.org, which provided shapefiles with perfect attributes, however Unitary Authorities were listed separately to their parent county on the same layer (e.g. Nottingham was an enclave within Nottinghamshire on the county layer, and thus in the next layer down Nottingham's parent layer was Nottingham, not Nottinghamshire). I could merge these and change the data for the parent, but this would have to be done manually which isn't preferable.
","['data-request', 'geospatial', 'uk']","The issue here might come from the official definitions of the hierarchy of local authorities in the UK being somewhat counterintuitive. As I understand it (correct me if I'm wrong) you want a spatial layer showing the outlines of all lower-tier local authorities (e.g. districts, boroughs etc.) and including a column showing which county each local authority is in. The problem comes about because unitary authorities are not formally 'in' counties for local government or statistical purposes. This means (to extend your example) the City of Nottingham unitary authority is not in the County of Nottinghamshire as far as the government is concerned: Nottinghamshire is a doughnut with Nottingham being the hole in the middle. This is particularly counterintuitive because Nottingham is served by Nottinghamshire Police, Nottinghamshire Fire and Rescue etc, but nevertheless Nottinghamshire County Council has nothing to do with services in the City of Nottingham.As you've noted, you can manually construct a layer using existing open data – either from GDAM or the UK Data Service boundary data site. Alternatively, you might want to look at the Ordnance Survey Boundary Line product, which is open data and includes layers for English ceremonial counties. This layer might give you the result you want (or allow you to create it using a spatial join) because, for example, Nottingham is in the ceremonial county of Nottinghamshire.One important thing to note, though, is that this will not help you for those parts of the country where the creation of unitary authorities means that there are no longer any lower-tier local authorities. For example, there are no longer any districts or boroughs inside the counties of Cornwall, County Durham, Northumberland, Shropshire or Wiltshire. "
Hand motion dataset,"
I am looking for a dataset of hand motions, e.g. take (with hand), throw (with hand), wave (with hand), etc. I imagine that a hand has a number of sensors attached, say, at an elbow, at a wrist, at the center of a palm, on each finger in four places.
A dataset would have the following format then:

motion tag, set of frames:

frame index, wall-clock time, 3-d coordinate of each sensor (either absolute or relative to the body);


All above is equivalent to the fact that dataset could be visualized using simple 3d application and motions are recognizable in the resulting video.
P.S. It would also be nice to know, if such a dataset could be easily collected.
",['data-request'],
Is there any public dataset on Bangla Language handwriting available?,"
I am willing to work on a natural language processing project that encompasses learning from Bangla handwritten texts. Hence, I am looking for publicly available Bangla handwritten texts' dataset.
",['nlp'],"The author (Ujjwal Bhattacharya) of this paper: An End-to-End System for Bangla Online Handwriting Recognitionhas an application for the dataset on their download page (direct PDF  link). You'll also find some sample datasets (for example).(Interestingly, also an Android App)"
"Database of common packaging icons (food, CPG, GM)","
Building a classifier that takes as input, a photo of a product and then identifies the common icons in that photo (e.g., recycle, non-GMO, kosher, fat free, gluten free, vegan, etc.). I am aware of the icons at thenounproject.com, but I am looking for more variants (pictures of the icons on actual products) so that the classifier generalizes well to real-world cases.
","['food', 'photographs']",
Open Standard for parking signage data (universal),"
keen to get feedback on a lightweight open JSON based standard for the depiction of parking sign/restriction data.  The focus would be to digitally represent any parking sign anywhere in the world.
https://github.com/whooshka/restrictiondataspec/
This has had initial feedback from some government councils in Melbourne, Australia.  At the moment, pretty much all parking restriction datasets are widely divergent.  This effort should help us to build tools to a common standard.  
Please do provide feedback and comments to the team so this standard can start to serve communities and useful tools can be built.
","['uses-of-open-data', 'parking']",
"Satellite, labeled image datasets for multi-temporal semantic segmentation?","
In this site there are labeled satellite image datasets for semantic segmentation but those images are not multi-temporal. In this question someone asks for satellite images but again, he doesn't ask for multi-temporal data. Where can I find labeled (as in, categorized, see here for an example), open datasets for multi-temporal remote sensing image analysis, more specifically semantic segmentation and deep learning?
Applications could be anything like land use, land cover segmentation; change detection, deforestation tracking or others. Multi-spectral or hyper-spectral images would be preferred. SAR, LiDAR or images from UAVs would also work.
","['data-request', 'geospatial', 'images']",
US State Boundary Shapefiles,"
Anybody know where I can download shapefiles of individual US state outlines? Something in the 1:100k range
I found this, but albert's is better (the census data requires processing)
https://www.census.gov/geo/maps-data/data/cbf/cbf_cousub.html
","['data-request', 'usa']","This dataset specifically has the state outlines broken out individually https://github.com/michalsen/states_geojson/, and here's another flavor with zip codes "
US Income datasets at the Census Tract / Block Level,"
I am currently using www2.census.gov to get demographics data from the census and was wondering if there was a similar source that could offer me blocks / census tract level data on income.
I would like to stay away from american fact finder, unless someone knows of a way to download entire datasets using python.
The www2.census.gov source is really handy so if the data is there and I'm just overlooking that would be optimal.
","['us-census', 'census', 'income']","Neither the Decennial Census or the American Community Survey report income information at the block level. They do report it at the block group and tract level.The data is accessible in many ways. I like using the Census API. Here's data on aggregate income by blockgroups in a census tract in Jefferson County, Alabamahttps://api.census.gov/data/2016/acs/acs5?get=NAME,B01001_001E,B19313_001E&for=block%20group:*&in=state:01%20county:073%20tract:000100"
Database resource: amount of different operating systems across the years,"
I would like to perform data analysis of the amount of machines using different operating systems (Windows, Mac,Linux Android, etc.) across the years. Any idea where I could get the data?
UPDATE
I am specifically interested in the absolute value of devices since e.q. 1980. The total number of devices will grow so it would be nice to also include that information. Also (if possible), devices should distinguish between laptops, smartphones, tablets, workstations etc. 
","['data-request', 'computing', 'technology']",
Suicide statistics,"
I am doing a project and I am having trouble finding statistics about suicide and links to depression, anxiety and alcohol abuse. I'm not sure if this is where to ask, but if you could help me, that would be appreciated.
",['medical'],"National Violent Death Reporting System (NVDRS) provides states and communities with a clearer understanding of violent deaths to guide local decisions about efforts to prevent violence and track progress over time. NVDRS is the only state-based surveillance (reporting) system that pools data on violent deaths from multiple sources into a usable, anonymous database. These sources include state and local medical examiner, coroner, law enforcement, toxicology, and vital statistics records.NVDRS covers all types of violent deaths—including homicides and suicides—in all settings and for all age groups. NVDRS may include data on mental health problems; recent problems with a job, finances, or relationships; physical health problems; and information about circumstances of death. Such data is far more comprehensive than what is available elsewhere.Data are available online to the general public through CDC’s WISQARS (Web-based Injury Statistics Query and Reporting System).For a more global view you may want to look at the World Health Organization suicide data.Also Our World in Data has a page on suicide."
Where can I find EEG database for autism-spectrum disorder patients?,"
I want to do some research about autism-spectrum disorder with electroencephalography (EEG). For that, I am badly in need of EEG data from autism patients.
Where can I find such data?
","['medical', 'research']",
API for searching Orphan Drug Designations and Approvals,"
I'm building a website using the openFDA APIs, which works perfectly.
I also notice that the FDA website provides a tool called ""Search Orphan Drug Designations and Approvals"" at https://www.accessdata.fda.gov/scripts/opdlisting/oopd/index.cfm
I wonder if there is any API for this search tool.
If not, is there any way I can incorporate this search tool into my website?
Thanks.
","['api', 'data.gov', 'openfda', 'healthcare-finder-api', 'drugs']",
Seeking data of geographical electricity consumption per area/district in any region of the world,"
I am trying to find if any electric utility (I don't mind which one) provides geographical information about elecricity consumption per area, discrict, etc.
For instance, the company which distributes electricity in a certain country publishes that the consumption in the district A is 500 MWh per year, in the district B is 640 MWh per year, etc. 
If it exists, I would be very grateful if you could provide the source (Internet address, person to contact, etc.). Thank you very much.
","['geospatial', 'energy']",
Where to find US Cadastral data?,"
Where to find US Cadastral data similar to Montana Cadastral Framework.
I would like to download taxable parcels and non-taxable parcels shape files.
http://geoinfo.msl.mt.gov/msdi/cadastral/
Service Description: The Montana Cadastral Framework provides a digital representation of the written legal description of taxable parcels and non-taxable parcels, or land ownership, as defined in the Montana Department of Revenue's (DOR) Computer Assisted Mass Appraisal database (CAMA) The non-taxable parcels may include public lands (federal, state, local governments, etc.), tribal lands in USA or tribal trust, and other exempt property such as church owned property. The boundaries of aliquot parcels are built on the Bureau of Land Management’s Geographic Coordinate Database (GCDB). The non-aliquot parcels (parcels based on bearings and distances) are/were created through the use of coordinate geometry (COGO) and/or original digitization of paper and Mylar maps or deeds and still primarily reside on a GIS base. 
",['usa'],
"Global biomes data set - eg. Rain Green Forest, Succulent Thorn Woods, Highland Scrub","
Data request
I'm looking for a global dataset of biomes but I need to cover quite specific categories that can be identified as termite habitats, as described in Sanderson (1996):

Rain Green Forest
Tropical Rain Forest
Tropical Montane Forest Complexes/Tropical Seasonal Forest
Temperate Forest
Savannah/Hot Grassland
Succulent/Thorn Woods
Cultivated Land: Farmland, Crops
Temperate Grassland/Shortgrass Prairie
Mediterranean Tree/Scrub/Highland Scrub
Desert/Semidesert
Eucalyptus/Acacia

Or any other land cover data that can be mapped to these biomes. Generally, any land cover data that is more detailed than the usual Forest-Crop-Grassland scheme will help.
Context
My aim is to calculate global methane emissions from termites based on the methodology by Sanderson (1996) but possibly with newer data. For this purpose I need to identify termite habitats around the world.
Format
Ideally a NetCDF file but I will do with pretty much anything (ideally in the resolution of 0.5 deg).
Non-answer
The mentioned paper cites the Olson database from the year 1989. If I step aside from the fact that I was not able to find the actual data (I did find some data but it contains different categories from those written in the paper), it's still a quite old data set, so anything more up to date would be appreciated.
","['data-request', 'global', 'land-cover']",
Population and GDP of the UK nations 1950-today,"
I'm looking for the population and GDP of the UK nations (England, Scotland, Wales and Northern Ireland) from the 1950s to today, ideally at the yearly level. Any tip?
","['uk', 'historical', 'population', 'gdp']","The Office for National Statistics website is going to be your friend here. The current Population Estimates Dataset includes (under 'Mid-2016 detailed time series') national and regional population estimates going back to 1838.For GDP there are several options, so it's probably best to look through the available data by searching the ONS website for 'region GDP' (note this link restricts the search to times series). One option is the Historical Regional GDP dataset, but that only goes back to 1968.If you can't find exactly the data you need, you can also ask ONS to release additional data."
High-Res or Vector 10m Topographic Line Map for Europe?,"
The USA puts out great free topographic line maps, but I can't find any free (topo line map) resources for the EU with enough detail to model the terrain. While I'd prefer 10m elevation between lines, I'd be happy with up to 100m. Do any such resources exist?
","['data-request', 'geospatial', 'europe']","So you are looking for a European wide contour dataset crossing all international borders at a resolution similar to the USA data produced by their mapping agencies? You are not asking for much then...Do you think the European countries would organise themselves to collaborate on such mapping task? I am happy to be proven wrong!Your only choices are to acquire each in country contour dataset and splice it into a single seamless data (no easy task but most likely to give you the resolution you are requiring), or use contours created from global datasets (so lower resolution) such as SRTM, a simple search on Google using the search term ""contour data europe"" threw up Contour lines vector tiles Europe."
Multi-spectral high resolution satellite images for flood events,"
I'm searching for multi-spectral high resolution satellite images for flood events.
I found a database of flood events at the Dartmouth (Colorado) Flood Observatory with dates and approximate locations (polygons) and I used the Sentinel API hub to download images. The problem is that images cover too large an area and I cannot find the interesting regions; neither can I get images of the exact same location for two different dates (to compare pre and post events).
Is there a way to get a free dataset of high resolution satellite images for flood events (pre and post disater)?
BTW, I want to apply machine learning algorithms on these images.
","['geospatial', 'images', 'aerial-photography', 'geohazard', 'download']",
"Age structure of German population; 1925 census, large cities","
Anybody knows where I can find data about German census at the city level for the period 1925-1935? 
In particular, I am interested in the age structure of the population of the largest cities, the so-called Großstädte (> 100 000 inhabitants). 
EDIT: I found out that in that period there have been two censuses in Germany, one in 1925 and one in 1933. I found data for year 1933 but I am still striving to find data about 1925 census. Any help in this direction?
","['data-request', 'population', 'germany']","You might check out the information provided by the German Federal Statistical Office https://histat.gesis.org/histat/de/index where one can find a large variety of time series data for social, economic and historical research. Both registration and download of the data are free. Another starting point for the search could be http://www.historische-statistik.de/datensaetze-karten-volkszaehlungsstatistiken/ which is a compendium of different historical data sets and data sources. The data is collected through different lectures at the University Bonn."
Product features / components / attributes data set,"
I am desperately looking for a way to either create or find an existing data set for products that lists the most common features / components or attributes of that product.
An example could be:
DSLR camera

Camera
Megapixels
Lens
Digital
Glass
Pro
Shutter
LCD
Optical
Zoom
Resolution
Megapixels
CCD
CMOS
Stabilisation
Macro
Telephoto
Wide angle
Filters
Batteries
Flash
Lighting
Memory card

As can be seen this example, I just listed as many attributes I could, related to a specific product. Such that you might do in a brainstorming session on a product.
I need a way in order to do this at scale. I am looking for all help possible on this, it would be greatly appreciated!
",['metadata'],
How do I download bicycle routes data from OpenCycleMap?,"
I am trying to get bicycle routes data (vector data/shapefile) of major cities of Europe.
Can someone tell me how to download the bicycle routes shown in the OpenCycleMap map?
",['openstreetmap'],"OpenCycleMap data are available as a layer on OpenStreetMap.
In fact,The OpenCycleMap global cycling map is based on data from the OpenStreetMap project.
  The map is updated every few days with the latest data from OpenStreetMap.Thus, see this similar question on help.openstreetmap.org.You can try Overpass API, if your area is small enough. Basically, the query should be like this:Link to the query, select Settings > Map > Don't display small features as POIs, if you want.You could also ask your question on gis.stackexchange.com."
"Greek wander paths, trails","
I need greek wander path, trail data preferred as shapefiles. I have found two sites containing such data but I don't know how to extract them. I would like to drop a rectangle on an area and extract the data if it is possible. Can someone help me?.
I have found these here: wander map and OSM wander map
","['geospatial', 'openstreetmap']",
How to get the best images from a Wikimedia Commons category?,"
Wikimedia Commons had tons of images of all qualities, sorted in categories.
The best images are sometimes awarded a ""featured"" badge, or a ""quality"" or ""valued"" badge.
The majority of images have no badge at all.
Question: How to get the best images from a given category, including its sub-categories?

Users will casually enter categories such as ""Butterflies"", which has hundreds of sub-categories containing tens of thousands of files. Despite this, the results must come within 10 seconds.
The API has to be available online (95% uptime or best)
Picture quality is readily available through the featured/quality/vales badges, but I am open to other objective and subjective quality measurements.
Ideally the API should return all images from in decreasing order of quality, with paging so that the data starts to come as fast as possible.

","['api', 'images', 'wikimedia-commons']",
Publicly available example ontologies for financial and political domain,"
I'm doing a research project and I have trouble finding suitable ontologies for financial and political domains. Political domain means any kind of political ontology regarding any country. Can anyone help?
","['data-request', 'ontology']",
what's the meaning of 'ordercategoryname' in mimiciii,"
I'm collecting informations of input data from mimiciii. I Find several strange data from the table.

In general, it is impossible to give patients 3000ml of liquid. I can also find similar records. One common character is that their ordercategoryname is '16-Pre Admission'. Should I exclude these data when I decide to calculate the daily input? what's the meaning of '16-Pre Admission'
",['mimic-iii'],
Is there any available dataset describing types of sensors (ideally using SSNO)?,"
I am developing an application that tries to predict what type of sensors would be needed in a working environment to achieve certain goals.
In order to function, this application needs to know (A) what type of sensors exist, and (B) what they measure.
For example, it would be useful for me to know which type of sensors are available to measure CO2 gas concentration, or temperatures, or vibrations.
I could, of course, search for available sensors myself on the web, and create a dataset with their main characteristics.
But I was wondering if such data already exists in some form.
I am particularly interested in datasets following the Semantic Sensor Network Ontology (SSNO). SSNO can be used to describe types of sensors, but so far I have not managed to find any dataset containing such descriptions (beyond a few toy examples). 
I know that I won't be able to find a comprehensive list of all the possible sensors, but I am interested in such datasets even if they are not very complete/accurate/updated...
","['data-request', 'standards', 'rdf', 'ontology']",
How can I query Wikidata for a label and optional image without further constraints?,"
I made a derivation of the cats with images example where I query for a specific cat, in particular its label and a possible image (in the web interface):
SELECT ?item ?itemLabel ?pic
WHERE {
    FILTER ( ?item = wd:Q17000472 ) .
    OPTIONAL { ?item wdt:P18 ?pic . }
    SERVICE wikibase:label { bd:serviceParam wikibase:language ""[AUTO_LANGUAGE],en"" }
}

I do not care whether it's a cat as I just want to query basic info of any entity. Including such constraint (?item wdt:P31 wd:Q146 .) would actually give a result, but again the entity could just be anything.
Am I deducing correctly that a WHERE statement in SPARQL expects at least one 'unoptional' triple? What would be a good pattern to query optional properties of a specific entity without any knowledge about it?
","['wikidata', 'sparql']","First, use VALUES instead of FILTER to provide inline data, even if query optimizer is as smart as in Wikidata's Blazegraph:Try it!Am I deducing correctly that a WHERE statement in SPARQL expects at least one 'unoptional' triple?Rather, you shouldn't start with OPTIONAL. Evaluation starts from the so-called universal mapping, if the OPTIONAL block is not able to retrieve any results this step simply retains the universal mapping.See also In SPARQL, Order Matters, example Q1b. DBpedia's Virtuoso also follows this convention.Fortunately, VALUES decide this problem, at least on Wikidata's Blazegraph. If you are still looking for properties that all Q-entities possess, then check wikibase:statements, wikibase:sitelinks, wikibase:identifiers, schema:version and schema:dateModified."
What is the best datasource for global administrative divisions?,"
We are setting up a new architecture of our system. One of the key components is the administrative division of each country around the globe. We are using Bing to map this structure. Sadly, Bing doesn't want to share their administrative division structure, although you would see them on the map if you search for a location. Google offers the same data.
To have an initial load in our systems I'm looking for a dataset that contains this structure. The only source I could find is Mapanet, but that's quite expensive and the reviews on data quality are also not very promising. Therefore, I'm looking for your expertise on this. Can someone help me with a good data source on this, both with a fair price and good data quality?
",['data-request'],
Where is the official source for UK population + age profiles data,"
I am looking for the latest UK population data at the lowest possible level (output area?) to include age profile breakdowns (eg 18-25, 25-30, 30+ etc).
Naturally I have googled the topic, and I'm totally baffled by the range of organisations who potentially provide this information:

ONS
NOMIS
Data.gov.uk
scotlandscensus.gov.uk
National Records of Scotland
Stats Wales
Data Cymru
Northern Ireland Statistics and Research Agency
ukdataservice.ac.uk
UN Stats
Ordnance Survey (for boundary data)

I've hunted around all their sites but wanted to post a question here to get a definitive answer on which is the most suitable source for UK population data, whether that means the last census counts (2011) or the latest estimates.
Ideally I'd like results at postcode level since these are so easy to map and process, but output area would also be suitable, and I'm aware it's quite easy to find output area boundaries and population weighted centroids.
","['uk', 'demographics', 'population']",
Real world objects and digital contents represented in RDF,"
Not sure if this is the appropriate forum for this question, especially after the Dataversity Q&A site shutdown, so please feel free to suggest better avenues. 
I am implementing an LDP server and setting some semantic guidelines around it. One convention I want to encourage is the use of Cool URIs to separate the concept of Real World Objects (RWO) and the RDF documents about them. 
So, if I request http://server.org/ldp/rwo01 I would get the following (pseudo-)RDF:
# Information about the document describing the RWO
</rwo01> a ldp:Resource ;
  dcterms:created ""2018-05-02""^^xsd:date .

# Information about the object itself
</rwo01#this> a myns:GreekAmphor ;
  dcterms:created ""500 BC""^^xsd:string .

This looks pretty straightforward with physical objects. What about digital documents, e.g. a digital image? Retrieving http://server.org/img01 (with content negotiation that yields the RDF documetn instead of the image contents) would give me:
# Information about the document describing the image
</img01> a ldp:Resource ;
  dcterms:created ""2018-05-02""^^xsd:date .

# Information about the digital image itself
</img01#this> a myns:StillImage ;
  premis:hasSize ""2469235""^^xsd:long ;
  dcterms:created ""2010-10-21""^^xsd:date .

This is also fine, however a bit awkward. In fact, the URI matching exactly my request is the subject of the metadata about the document, not of the document itself which is most likely the first thing that I would be looking for.
If I subverted the suggestions in the Cool URIs document I would end up with more intuitive semantics:
Retrieving http://server.org/img01:
# Information about the digital image itself
</img01> a myns:StillImage ;
  premis:hasSize ""2469235""^^xsd:long ;
  dcterms:created ""2010-10-21""^^xsd:date .

# Information about the document describing the image
</img01#metadata> a ldp:Resource ;
  dcterms:created ""2018-05-02""^^xsd:date .

And, to be consistent with this pattern, at this point I would have to turn the RWO representation upside down too:
Retrieving http://server.org/rwo01:
# Information about the object itself
</rwo01> a myns:GreekAmphor ;
  dcterms:created ""500 BC""^^xsd:string .

# Information about the document describing the RWO
</rwo01#metadata> a ldp:Resource ;
  dcterms:created ""2018-05-02""^^xsd:date .

Does that sound reasonable? Or am I reinventing the wheel? Or am I trying to invent a concave wheel?
","['linked-data', 'rdf']",
Why does Wikidata's query interface return no results for entities with an id of Q10000001 or higher?,"
I have this SPARQL query to return an item's label and the url of a Wikipedia article:
PREFIX schema: <http://schema.org/>
PREFIX wd: <http://www.wikidata.org/entity/>
SELECT ?article ?itemLabel WHERE
    { FILTER ( ?item = wd:Q10000000 )
      ?article  schema:about       ?item ;
                schema:inLanguage  ""en"" ;
                schema:isPartOf    <https://en.wikipedia.org/> .

      SERVICE wikibase:label { bd:serviceParam wikibase:language ""[AUTO_LANGUAGE],en"". }
    }

This works as expected, but as soon as I substitute the id with Q10000000 or any higher number included, it yields no result. Not only to the entities I checked exist, but also does the query editor display a label when hovering over the id in that expression.
What is causing this behaviour and how can I adjust the query to get results for entities with ids that have an id of Q10000001 and higher?
","['wikidata', 'sparql']",There isn't an article about Татьяна Колотильщикова in English Wikipedia.Just comment out the second and the third triple patterns in your query.Or try e. g. Q11000001 instead of Q10000001.
Does exist any free dataset (geocoded or by country) on UXO? [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 5 years ago.







                        Improve this question
                    



I am looking for a free of charge global or european dataset listing UXO presence or UXO incidents.
",['data-request'],
List of all county (and equivalent) seats for the USA,"
Does anyone know where I can find a list of all county seats for the USA? Specifically I'm looking for (if possible) the locality name, lat/long, county or equivalent name, and INCITS code.
","['usa', 'county']",
Sport's APIs For Headshots and Stats,"
I'm currently building an program that would benefit from higher quality images of University's Logos(NCAA, NAIA, etc.),head shots of athletes, and general statistical data(Games played, etc). The information needs to be quite accurate. I was looking into ESPN's API and it seems they no longer do public keys or are accepting new strategic partnerships. Is there anything else of that quality that is trustworthy? 
","['api', 'sports']",
How to find databases with firm’s contact details for a quantitative survey?,"
I am a PhD student from Australia in the discipline of international business. For my data collection, I intend to conduct an online survey among energy-related firms in six countries (Australia, USA, UK, India, China and Sri Lanka). For this, I need to contact managers in production, technology, R&D, and manufacturing divisions of the companies.
Based on my research model the minimum sample size is 356. Considering a low response rate (approximately 10%), I have to contact approximately three thousand firms. So far I am trying to collect this data by accessing specific firm’s websites. This is very time consuming, and in nearly 99% of cases, I could not find the specific email address I am looking for.
My question is with respect to the availability and ability to find these firms and specific contact persons contact details. Are there any websites or firms who could find the specific firms, contact persons (managers in production, etc.) and their specific email addresses?
",['research'],
"Can you look up the producer/manufacturer that owns a certain ""family"" of EAN barcode?","
I have a barcode, (9)8430709157279, that I have tried to find in several online resources that collects EAN codes but so far without luck (the product is at least 20 years old so it is no surprise). However, is it possible to find out which company or similar this code was assigned to in the beginning?
In other words, does a company get something like 84307091xxxxx and can use the ""wildcards"" however they like similar to IP-address ranges and MAC addresses ranges work? If so, can you lookup the prefix somewhere?
","['data-request', 'barcodes']",
Looking for year-by-year worldwide ethanol production data,"
What is the total worldwide ethanol production? I want any ethanol, for any purposes, including human consumption (drinking alcohol) and fuel and chemical industry.
I want to see how much total ethanol is produced, and compare how much is produced for fuel vs how much is produced for drinking. It should be interesting to see which is bigger. I also want year by year accounts to see any trends.
I have searched for this myself but the data is not trustworthy unless it explicitly explains ethanol for what purpose.
For example, This Site says US is biggest producer at 15B gallons in 2015, but it's in the context of ethanol fuel and doesn't say explicitly ""15B gallons of ethanol for all purposes"". In fact if you look down, it says ""The vast majority of U.S. ethanol is produced from corn..."" I am pretty sure if you throw drinking alcohol in the mix, the biggest source is gonna be grapes (for wine) and hops (for beer).
Other examples, Wikipedia: Beer in US says the US produced 23B liters (6.1B gallons) of beer in 2012. I guess I have to guess at the average ethanol content, which I'll guess at 20 proof, so 610M gallons of ethanol. This site says 196B liters (51.8B gallons) of beer was produced worldwide in 2015, but again, no mention of average ethanol content.
","['data-request', 'global', 'energy', 'industry']",
Do census tract geographic shapefile data update annually?,"
I am looking at census tract TIGER/Line shapefiles from data.gov (https://www.census.gov/cgi-bin/geo/shapefiles/index.php), and I see that they
provide options for census tracts for different years. 
I noticed that the file size between the census tracts for 2010, 2011, 2012,... 2017 all have different file sizes. I thought the census tract was supposed to only be updated per decade? I'm wondering why this is.
","['geospatial', 'usa', 'census']",
'Number of Faculty Members' not Available in the College Scorecard Dataset,"
The College Scorecard has data on the 'Average faculty salary' and 'Proportion of faculty that is full-time', but it does not report any data on total number of faculty. Does anyone have any suggestions where I can find these data (or something similar)?
I think this would be a really valuable variable to include in the College Scorecard, considering that the student to faculty ratio is a standard measure of college quality.
","['data-request', 'collegescorecard']",
List of us city mayors by year,"
A similar unanswered question, City mayor/council racial demographics, prompts this more generic question.
Where can I find open data source that lists all us mayors by year? 
","['usa', 'government']",
Ski trails/piste map data,"
Is it possible to download ski trail/piste data for major European and other resorts? I'm looking for polyline data showing the major runs in a resort - the kind of data you'd see on a piste map.
Openstreetmap seems to have quite extensive chairlift data, but not the actual runs down.
","['data-request', 'geospatial', 'sports', 'ski']",
Find a home for (old) video datasets,"
While looking for some older sets like PETS2006, which seems to be no longer available, i wondered if there might be already a place for them to be shared forever.
If there is none, i would encourage everyone to think about a good, free and open solution.
I know there are some sites out there which collect links - unfortunately a big part of the links is dead. 
","['data-request', 'download', 'video']",
Any open data sets for the (Football) World Cup in Russia 2018? Any open data for the World's Biggest (Sport) Event?,"
Are there any public data sets for the World Cup in Russia 2018?
Didn't find anything for download on the official FIFA site (besides a single-page PDF booklet for the match schedule).
Ideally the data set includes groups, teams, players, squads, matches, stadiums and so on and is in an open plain text format such as CSV (comma-separated values), JSON (javascript objects), SQL (structured query language), etc.
Any insight appreciated.
Disclosure: I'm the project lead of the football.db project collecting open public domain football data e.g.

openfootball/world-cup - World Cup Datasets (1930-2022)

so no need to highlight this little humble dataset about Russia 2018 ;-) (that incl. the teams, groups and match schedule) but is missing a lot (e.g. players, trainers, stadiums, etc. and once the events starts it's missing goal getters, goals, penalties, yellow cards, red cards, and on and on).
Again it's the world's biggest (sport) event - 1 000 000 000+ people watching live and there must be some more open data out there in this world. Help us find some datasets. Any insight appreciated. 
Kickoff! Matchday 7! Any updates? Any open datasets? 
","['data-request', 'sports', 'football', 'russia']",
World population density,"
I need a rough estimate of how many people live in each ""cell"" of the Earth.
For instance, how many people live in the cell between latitudes 70/80 and longitudes 210/220?

Exact number is not important. I would be satisfied with a 0/100/10k/100M estimate.
I wrote ""living"" but that could be ""working/etc"" or ""passing through"", these are acceptable too.
Any format is OK, even a raster image or a big CSV file.
The cells should be at most 10 degrees * 10 degrees, as seen in the map below. The more precise the better.


Context: I am writing software that needs to spend more time on areas where more people live.
","['data-request', 'geospatial', 'population']","Please see this one: http://ghslsys.jrc.ec.europa.eu/data.php The Global Human Settlement LayerLandsat data from 1975, 1990, 2000 and 2014 were processed and
  analysed in order to produce three different GHS products:one on population (GHS-POP),one on built-up areas (GHS-BUILT),  Data is open and free, with 250 metre resolution. What is inside:via Stats, Maps n Pix "
Texas Land System Grid data,"
I am working on R&D for Texas Grid data.Currently, I download https://tnris.org/data-catalog/entry/usgs-quad-grid/ data.But I don't know which is the actual Grid data for Texas.For example, Alberta provenance using DLS system Grid data.
So which is the Land system follow Texas and where I can get data?
Please, Any help to get a downloadable file or reference link to get Grid data for Texas Land system.
","['data-request', 'geospatial', 'government']",
What are methods to create open text data from copyrighted texts?,"
Language data are either texts or spoken utterances. By default, any text is copyrighted. We have Open Data for relatively recent time periods, where text were written intentionally with an open licence (like Wikipedia articles), or for relatively old time periods where the copyright has expired and the texts are public domain now. In between, there is a long period where no open texts are available.
My question is: What are generally accepted (or even better: legally proven) methods to create open data from copyrighted texts? The methods are probably in some way lossy and prevent the restauration of the original texts from the open data.
","['language', 'legal', 'corpora', 'text']",
Looking for 0.25x0.25 spatial resolution grid data for land surface temperature/precipitation,"
I used to work with UDEL grid estimate (look here) data where station values of monthly total raingage-measured precipitation (P) were interpolated to a 0.5 degree by 0.5 degree latitude/longitude grid, where the grid nodes are centered on the 0.25 degree.  However, after I tried to interpolate those data with Germany NUTS3 district only, and I got a poor match because I need to calculate population weighted yearly average for each Germany NUTS3 polygon but some polygon lost population data which affect my expected output. Now I realized that chosen grid estimate data is not precise enough which caused this problem. 
I used to work with UDEL grid estimated data with 0.5x0.5 degree resolution (http://climate.geog.udel.edu/~climate/), but it is not ideal for my research. I used also DWD station level data (DWD station level data link), but this dataset also won't fit my expectation.Now I am looking for a grid climate data (Temperature/precipitation data) with the better resolution. 
Now I am looking for the grid climate data with better resolution, where 0.25x0.25 degree grid data of global climate (land surface temperature/precipitation) are desired. Where can I find free open source grid climate data that meet my specification? Anyone know a possible source where I can download such data? Possible help would be appreciated.
","['data-request', 'geospatial', 'germany', 'climate']","Thanks to @Trevor-J-Smith (on GIS SE) I've found this publication in Nature's Scientific Data :Karger, Dirk Nikolaus, Olaf Conrad, Jürgen Böhner, Tobias Kawohl, Holger Kreft, Rodrigo Wilber Soria-Auza, Niklaus E. Zimmermann, H. Peter Linder, et Michael Kessler. 2017. « Climatologies at High Resolution for the Earth’s Land Surface Areas ». Scientific Data 4 (1): 170122. https://doi.org/10.1038/sdata.2017.122.http://www.nature.com/articles/sdata2017122The data are described and links to download are given at the ""Data Records"" chapter : https://www.nature.com/articles/sdata2017122#Sec18Following variables (among with other) are available as georeferenced TIF maps (raster data) at ~ 1km resolution :bioclim-variable:1=Annual Mean Temperature [°C*10]2=Mean Diurnal Range [°C]3=Isothermality4=Temperature Seasonality [standard deviation]5=Max Temperature of Warmest Month [°C*10]6=Min Temperature of Coldest Month [°C*10]7=Temperature Annual Range [°C*10]8=Mean Temperature of Wettest Quarter [°C*10]9=Mean Temperature of Driest Quarter [°C*10]10=Mean Temperature of Warmest Quarter [°C*10]11=Mean Temperature of Coldest Quarter [°C*10]12=Annual Precipitation [mm/year]13=Precipitation of Wettest Month [mm/month]14=Precipitation of Driest Month [mm/month]15=Precipitation Seasonality [coefficient of variation]16=Precipitation of Wettest Quarter [mm/quarter]17=Precipitation of Driest Quarter [mm/quarter]18=Precipitation of Warmest Quarter [mm/quarter]19=Precipitation of Coldest Quarter [mm/quarter]Here is an exemple of the stylised map of Annual Mean Temperature :You will find the code to style it this way here.If the CHELSA dataset dont suit your needs, then for the precipitations, there are these other data :Rustemeier Elke, Andreas Becker, Peter Finger, Udo Schneider, et Markus Ziese. 2020. « GPCC Precipitation Climatology Version 2020 at 0.25°: Monthly Land-Surface Precipitation Climatology for Every Month and the Total Year from Rain-Gauges built on GTS-based and Historic Data: Globally Gridded Monthly Totals ». Gzip compressed NetCDF. Global Precipitation Climatology Centre (GPCC). https://doi.org/10.5676/DWD_GPCC/CLIM_M_V2020_025Which you can access at the following link (scroll down : there are the gif and pdf versions of the files, you'll have to georeference them however) :https://opendata.dwd.de/climate_environment/GPCC/html/gpcc_normals_v2020_doi_download.html"
Relatively clean two-dimensional data for an example classification?,"
So, I've been searching around for a dataset to use in an example about Decision Trees. I was hoping for a two-feature, two-or-three classification problem so as to keep it as simple as possible to explain and to visualize. However, I'm not able to find even clean-ish datasets that separate well in only two features. Does anyone know of any such examples, even if they're somewhat unrealistic?
Few other restrictions:

No image classification - I'm focusing on a mathematical angle in the example and images would lean a bit too heavily on the computational aspect.
Simplistic or well-known - Niche datasets about a specific field don't really make sense, but if they fit the requirements well I'll be happy with them.
Region doesn't really matter to me, although if relevant I would tend towards datasets about European countries
Ideally looking for free datasets
Format doesn't matter

Thank you so much for your help!
","['data-request', 'machine-learning']","The Iris dataset is well-known, and I've experimented and found that using Petal length and petal width as features makes for a very good example."
What kind of sources can integrate CKAN?,"
I would like to use CKAN in my company but firts I have some questions to solve yet. For example:
What kind of sources can integrate CKAN? I explain myself firts.
If my company has its data distributed in the following sources:

Relational database (mysql, oracle)
Non relational database (solr, cassandra, mongodb)
Cloud (amazon s3, dropbox, google drive, google cloud storage)

Can CKAN access to this data sources for separate using a driver o some plugins and upload the data directly for example?
Can CKAN mix these data resources as a mashup tool?
",['ckan'],
Harvey Hurricane Disaster Area Data Sets,"
Looking for following Datasets for an ArcGIS Project

Damage Area affected by Hurricane Harvey
Recover centers per damaged areas for Harvey Hurricane
Population data before Harvey for affected areas
Population data after Harvey for effected area
Business Impacted in the disaster areas.

","['data-request', 'us-census', 'geohazard']",
Searching for dataset related to empowerment of women in agriculture as a result of participation in a development program,"
I am searching for a dataset concerning the empowerment of women in agriculture that contains a variable that is related to participation in a development aid program.
My research question is: Do development aid programs empower women?
I have found the Feed the Future Datasets (Baseline Survey) from USAID Data, but it does not contain any variables/observations related to if and how women were supported by the Feed the Future Initiative.
Is there any dataset with variables concerning empowerment and an aid program?
",['usaidopen'],
Open access electric vehicle trip dataset,"
Are there any open access electric vehicle trip dataset, that contains information about vehicle energy consumption, speed, acceleration, distance or GPS? Used electric vehicles should not be older than 5 years.
Most of the available data is already processed and contains annual statistics about electric vehicle trips.
The data would be used to develop energy consumption model of an electric vehicle.
","['data-request', 'machine-learning', 'transportation', 'energy']",
Julian and Gregorian dates from Wikidata,"
How can I get the Julian birth or death date for someone who was born or died under the Julian Calendar (Isaac Newton, for example) on Wikidata using a SPARQL query?
This simple query returns ""4 January 1643,"" which is Newton's Gregorian birth date:
SELECT ?birthdate
WHERE {
wd:Q935 wdt:P569 ?birthdate .
}
I've Googled (and DDGed) this up and have not come up with an answer.  Any help you could offer would be great.
","['wikidata', 'sparql', 'calendar']","As of April 2018, there is no way (in SPARQL).The RDF Dump format says: Note that the calendar model is the original values calendar model even if wikibase:timeValue was converted to Gregorian.Try this query: As you can see, there are two statements (one of them is not truthy), but the value is 4 January 1643 independently of the calendar model.By the way, Wikidata API returns two different dates:"
Where can I find historical presidential approval ratings,"
I'm looking for data on presidential approval polls going back as far as possible. Gallup has this data, but is not available to public. (http://news.gallup.com/interactives/185273/presidential-job-approval-center.aspx)
There is also data available from The American Presidency Project (http://www.presidency.ucsb.edu/data/popularity.php?pres=45&sort=time&direct=DESC&Submit=DISPLAY), but the site doesn't provide a link to the data.
","['data-request', 'polling']","You can tweak the url for The American Presidency Project to get the data on a specific president.  For example, here's the url for Obama:
http://www.presidency.ucsb.edu/data/popularity.php?pres=44&sort=time&direct=DESC&Submit=DISPLAYScraping the data from that site is pretty simple depending on your tools.  You could also easily copy & paste the table into a spreadsheet, if scraping isn't your thing."
Adword or web traffic dataset,"
looking for a website traffic analysis dataset for the project ASAP. can you direct me to any resources to download free datasets of such kind?
","['data-request', 'uses-of-open-data', 'releasing-data']",
Unemployment and minimum wage data by state (US)?,"
Where can I find yearly (historical) unemployment and minimum wage data (preferably inflation adjusted) by state?
I've checked BLS and DOL but they are not very user friendly for statistical analyses.
","['data-request', 'usa']",
Restrict returned claims in Wikidata entity,"
Is there a way to restrict the returned claims on wikidata's REST API?
For example I am using this query:
https://www.wikidata.org/w/api.php?action=wbgetentities&ids=Q17714&props=claims&format=json&languages=de|en

which returns all claims for the entity. But I am only interested in ""P31"", for example. It seems excessive to download the whole set. Any ideas?
","['api', 'wikidata']",
Planned grocery stores in the US,"
I am looking for any data/information regarding new and planned grocery stores in the US. Or specifically the Pacific Northwest. 
",['data-request'],
Stock Charts images dataset,"
I try to find a dataset with stock charts ... any timeframe and by sec, min, hr or day works for me as well. 
So I try to get them simple as possible with minimum indicators on it, candle style. 
P.S: did some manual pull of the charts but does include to much indicators and looks like the picture below:  and as can be seen the grid, all the numbers on corners, volumes etc I need to have it clear so can't find anything online ... any help on where to get or at least how to get them build manually thru an API will be helpful. 
","['data-request', 'api', 'stock']",
Is there a clinical dataset of BPM measured with smartwatch available?,"
I would like to use BPM measurements from smartwatch sensor (like apple watch) to conduct a study in my University.
Are there some public dataset to be used?
","['data-request', 'medical']",
Dataset of mathematical formulas,"
I'm looking for a collection of parsed mathematical formulas (expressions). I'm interested in studying the statistical properties of mathematical expressions written by humans. (Thus, formulas generated mechanically are not interesting.) For now, I'd prefer formulas restricted to the elementary functions.
I'm considering the following sources, all of which make available database dumps:

Wikipedia articles
StackExchange Q&As, particularly from MathOverflow, Math.SE, or Physics.SE
arXiv papers about math and physics

These sources contain plenty of LaTeX formulas but they'd have to be extracted, parsed, and validated, which is by no means trivial.
Are there any datasets of naturally occurring mathematical formulas that would be easier to work with? Or, failing that, what other sources ought I consider?
",['data-request'],
Radio base station location in Italy,"
Are there any datasets or websites that have the location data of cellular/radio base station in Milan, Italy?
","['data-request', 'geospatial', 'uses-of-open-data']","You may want to check out OpenCelliD, https://www.opencellid.org/. OpenCelliD aims to document all Cell Towers and WiFi APs around the world along with their locations."
How can I download AWS Public Datasets?,"
https://aws.amazon.com/datasets/ contain many datasets. How can I download an AWS public dataset?
",['download'],"I'll take the example of https://aws.amazon.com/datasets/enron-email-data/.Locate the AWS region in which the snapshot is located. To do, search for the snapshot ID in the list of existing snapshots, e.g. https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#Snapshots:visibility=public;search=snap-d203feb5;sort=snapshotId . If you don't find the snapshot, you have to change of AWS region:In the example of Enron-email-data, it is located in US East (N. Virginia) as well as in US Oregon. (In case you wondered: How can I know in which US region a snapshot ID is located? -> short answer: you have to try all regions yourselves by trying each region in the menu as shown in the screenshot above.)Create an EC2 instance in the same region as the snapshot, i.e. in our example Virginia a.k.a. US-East-1.  To do go to https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#Home and:Once the EC2 instance is launched and running, look at its availability zone on https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#Instances:sort=instanceId (change the AWS region to the region where you launched the EC2 instance), which in our case us-east-1c:Go back to https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#Snapshots:visibility=public;search=snap-d203feb5;sort=snapshotId and right click on the snapshot and create a volume:Make sure you select the same availability zone as the one where your EC2 instant is running, which in our case us-east-1c:In your volume list (e.g. https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#Volumes:sort=desc:createTime if you're in US East N. Virginia), right-click on the version you have created, and select ""Attach Volume"".It will ask you to which EC2 instance the volume should be attached. Select your EC2 instance.SSH into your EC2 instance, and mount the volume as follows:Done!Below are some tricks to transfer the corpus from the EC2 to your computer.To transfer the corpus from the EC2 to your computer, assuming that AWSvirginia.pem is the private key of the EC2 instance, and that the 184.72.123.192 is the public IP of the EC2 instance:After the transfer is completed, you can do additional checks as follows (even though rsync already checks for file corruption during the transfer):To get the shasum hash for each file in a directory and its subdirectories (and recursively):To check if the files match the shasum hashes:If there is any issues, it will display at the end of the checksum:To check every zip-file in every subfolder:Regarding the AWS costs, there 3 types of you should be aware of:"
Where can I find data on the following variables?,"
I'm looking for data (US) on the following variables for the years 2000-2014:

Does anybody know where I can find such a data set or custom data table? Preferably all in one table (or a table per variable, including all states and all years).
",['data-request'],
Open dictionary for English with International Phonetic Alphabet for every word,"
I'm seeking an openly-licensed dictionary that contains for every word the IPA transcription.
Is such a resource available for English?
","['data-request', 'language', 'english', 'pronunciation']","The CMU Dict is available online HERE. It doesn't use the IPA, but it uses Arpabet link to wikipedia here. You could easily convert it from arpabet to IPA. Also, since language is continuously changing it would be impossible to get 'every word'.Cheers"
Is there any free API to get historical forex exchange rates?,"
There are several free services for getting the live price or download historical data for 1M or 1D charts.
I wonder if there is a free API service to get the data (OHLC) for a specific date of 1D chart or DateTime of 1M chart?
","['api', 'finance']",
Just need a lo-res & 8-bit depth elevation map either real or fictional (BMP?),"
I am a software developer working on a strategy game in my spare time as a hobby. I still have very little knowledge of and experience with Geographic Information Systems and the different file formats, so please bear with me. 
I am interested in using real-world maps as the stage for my game and have been investigating several online map data services to see if I could download an elevation map and convert it to raw data for my game maps. For example it could be nice to have an elevation map of the southern part of Africa for instance (nice simple cone shape).   
For my purposes, the map data only needs to live up to the following: 

Depth of 8-bit, so between 0-255 values 
Elevation below sea level is not needed (sea level = 0) 
Low resolution, at best 1 kilometer, but 10 kilometer is fine too 

I am ready to investigate many of the file formats offered to be able to do so. However, since I am just at the experimental stage, I am wondering whether there aren't already some files like that available, e.g. in *.BMP format. 
P.S.: I am also open for fictional or procedurally generated maps to play around with. 
","['data-request', 'geospatial', 'games']",
Speech recognition english corpuses,"
Could someone provide a list (or link to) of english speech recognition corpuses with their availability and size (preferably in hours).
","['nlp', 'audio']",List: http://kaldi-asr.org/doc/examples.html (mirror)List: https://voice.mozilla.org/en/data:Corpus: https://voice.mozilla.org/en
Are there any datasets publicly available for interviews transcripts?,"
I am working on a project for behavioral analysis of interviewees using text data. Are there any available open datasets for interview transcripts, say telephonic interview transcripts or HR interview transcripts? The only available resource I found were video resumes on YouTube.
","['data-request', 'machine-learning', 'text']",
List of socks4/5 proxies in a plain text,"
I'm looking for list of public socks proxies in the plain text or another format which can be imported via curl.
I have tried extract it using script such as:
$ pup -f <(curl -sL https://www.socks-proxy.net/) '#proxylisttable tr td:nth-child(1),td:nth-child(2) text{}'

but it doesn't work as expected, so I'm looking for alternative open data which should be kept up-to-date in easy to read format.

Similar to how I could extract my IP address, like:
$ curl ifconfig.co
192.168.0.x

or:
$ curl ifconfig.co/json
{""ip"":""192.168.0.x"",""ip_decimal"":1406000000,""country"":""X"",""country_iso"":""GB"",""city"":""Y"",""hostname"":""example.com""}

The proxy list should be either in XML/HTML, CSV, JSON, YAML or in the plain text like:
x.x.x.x:xxxx
y.y.y.y:yyyy
z.z.z.z:zzzz

",['internet'],
Cell phone user and base station location dataset,"
Are there any datasets that contain cell phone users and their corresponding base stations location when phone calls were made? 
It does not have to be exact location, what I am interested in is to see a user is located under the coverage of which radio base stations. I would prefer a large dataset (more than 1,000 base stations).
I have been trying to find said datasets and the closest one is the Milan/Trentino dataset. However, there is no base station data so I would have to manually generate one (inc. finding base station location in these cities and manually calculating the coverage area of each base station), which is not ideal since I would prefer real-world data, it if ever exists at all.
","['data-request', 'geospatial']",
meds not appearing in FDA CDER or medical device DBs,"
The meds not appearing in either are as follows:

RabAvert
Donnatal
Androxy

The search engine I used for the FDA CDER DB is as follows:
https://www.accessdata.fda.gov/scripts/cder/daf/index.cfm
The one I used for the medical device DB is as follows:
https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfRL/rl.cfm
RabAvert is mentioned at https://www.fda.gov/BiologicsBloodVaccines/ucm133705.htm but a downloadable database would be nice. The FDA CDER and the medical device DB's have txt files you can download that correspond to different tables in a DB. Would there per chance be a similar txt file I could download for the biologics  blood / vaccines DB or do I have to do screen scrapping to get that stuff into a DB?
","['usa', 'openfda', 'drugs']","These are all special cases.RabAvert is a biologic, so it is be found in the CBER database, not the CDER database or the medical device database.Donnatal is an unapproved drug that was grandfathered in 1966 and is still on the market (why are unapproved drugs on the market, and what is the FDA doing to get them off? See our article ). You'll only find Donnatal in the National Drug Code directory: https://www.fda.gov/Drugs/InformationOnDrugs/ucm142438.htm . RabAvert and Androxy are there too, and you can also get the database file you're looking for :)"
Where can I get conversational/directed sentiment data?,"
I'm looking for datasets with text labeled according to how (un)happy or (dis)satisfied the speaker is with the person being addressed, e.g. ""You're a godsend!"" (10/10) or ""go kys, ******"" (0/10). Most sentiment datasets I've seen are in the form of customer reviews, which are often addressed to other customers rather than directly to the person, corporation, or product being evaluated. If there are no publicly available datasets like this, I'd love to hear suggestions on how to gather it myself. Thanks in advance!
~~~
EDIT: After reading How a good data-request question should look, I am adding some more specific information below.
Data: Pairs of the form (text, sentiment) in which the text is directed to the particular person or entity at which the sentiment is directed.  The text must be in English.
Context: I want to be able to automatically estimate how good of a job an agent is doing, from the perspective of the user, in real time as the conversation unfolds. If it's possible to also determine why the user is unhappy (e.g. misunderstanding, personal offense, poor outcome, etc.) this is even better, but it's not a must-have.
Region: USA, but other English-speaking countries are better than nothing.
Licenses: Free and open, if possible.
Format: I'm not picky about the format, so long as it's machine-readable.
Authority: No specific requirements here. I'm fine with crowd-sourced or screens-scraped data.
Requirements: See the first paragraph.
Non-answers: If it's just regular sentiment analysis data, it's not going to meet my needs. It absolutely has to be directed at the person the sentiment is aimed at. Also, it absolutely must be human-labeled already, or I can't use it.
","['data-request', 'sentiment-analysis', 'text']",
Where do I get data on how many people move from country to country globally in a year?,"
I'm calculating total addressable market for a business that has to do with immigration. I need to know how many people physically relocate to another country with intention to settle there permanently, or alternatively how many people acquire legal immigrant status in a foreign country in a year, something like that.
OECD's website calls this permanent immigrant inflows, for 34 OECD countries they estimate it at about 4M a year, but I need data like this for worldwide. Is there a way to find it?
","['data-request', 'economics', 'demographics', 'migration']",
"Road shapefiles of Thessaloniki, Greece for years 1991 and 2003?","
I want to download the road network for the city of Thessaloniki, Greece for years 1991 and 2003 in shapefile format.
Do you know where can I find data for those years?
","['data-request', 'geospatial', 'transportation', 'europe', 'download']",
What is the difference between metric and bucket aggregations in elastic Search?,"
I have started a new job where I would be using elastic search. I want to learn as much as about elasticSearch so I can hit the ground running when I start work.
",['data-request']," The aggregations framework helps provide aggregated data based on a search query. It is based on simple building blocks called aggregations, that can be composed in order to build complex summaries of the data.
Metric aggregations:
  metrics aggregations are a special type of metrics aggregation which output numeric values. For example: max, min, stats, avg etc. Bucket Aggregations:
Bucket aggregations don’t calculate metrics over fields like the metrics aggregations do, but instead, they create buckets of documents. Furthermore, you can also combine bucket and metric aggregations to retrieve a mathematical aggregation within a bucket.
 For example: Get me the average number of earthquakes occurred in North America. Where bucket is North America and the metric being used is avg."
Are there general terms of service or licenses for ESRI's ArcGIS FeatureServer?,"
Is it reasonable to assume publicly accessible data on ESRI ArcGIS FeatureServer is (or can be used as) open data?
For example, Boston has a number of FeatureServer instances such as this one, but on that page I do not see an explicit license or copyright notice. I'd like to use some data in a similar situation but I'm not sure if I have to contact the data owner to do so.
",['licensing'],
Data integration tool that supports Semantic Web,"
I've multiple data sources (files or API data). I want to integrate all these sources using one common ontology.
I've started using Karma Information Integration Tool; however, I'm facing some execution errors with its service. 
I'm looking for alternative solution. I wonder if OpenRefine still supporting RDF and ontologies ?
Edit
It's very important for us to have a defined mapping between ontology and data source (e.g., a web service). This allows us to apply automatically mapping every time we get new data from the source.
","['tool-request', 'rdf']",
Trying to find a shapefile on Hawaii volcano locations,"
I have downloaded a shapefile of volcanoes all over the world, but when zoomed in to Hawaii, not all of Hawaii's volcanoes are displayed. I have been searching but I can't seem to find a shapefile of all of the Hawaiian volcanoes or even the Hawaiian-Emperor chain.
","['data-request', 'geospatial', 'usa', 'land']",
Geographic Information Retrieval dataset,"
Where can I find some datasets for Geographical Information Retrieval? I tried to search for GeoCLEF, but the whole dataset is no more available. Moreover, some geo-tagget tweets do not usually contain geographical keywords, so we have geographic coordinates for test values with no textual content to be retrieved.
Moreover, I found the ""Mapping the lakes"" dataset, but even though it is organized as a gazzetter associating to each word its geographical coordinates, there are no full-text queries over which I can benchmark by retrieval system.
I've been searching for a long time for such dataset, but I was not able to find what I need.
Do you know where can I find some GIR dataset?
","['data-request', 'geospatial']",
"Western Canada ShapeFiles (Meridian, Township, Section and Quarter)?","
I want to create a TileGrid Map for Western Canada of the 36 ""Townships"" (where each ""Township"" has 16 sections). I want to create grid tiles from ShapeFiles/kml/kmz or any other format file.
I found the following link which points to a ShapeFile for the Alberta Altas Regions only.
https://gis.stackexchange.com/questions/143323/dls-grid-for-province-alberta-canada.
I would like to find more data of Western Canada's ""Townships"". Does anyone know of a reliable source for this vector data?
","['data-request', 'geospatial', 'city', 'canada']","One of the best sources for Canadian Geospatial data is the Canadian government's Open Data Portal and the Canadian Census Boundary files. After doing a quick search through the Census data, it appears that 'Townships' might only be an administrative unit at the provincial level. As such, another option is to download the specific townships directly from Open Data Canada (https://open.canada.ca/data/en/dataset?q=township+numbers&organization=nrcan-rncan&res_format=SHP&sort=). You may want to write a to download all the results or a script that targets only the names/codes of the townships that you want. Quickly looking over it, the data seems to be what you're looking for.EDIT: I may have found exactly what you are looking for. Here is a link to an NRCan FTP with the Dominion Land Survey (DLS) spatial/cadastral data for Canada. This includes all townships and is divided by province. https://www.nrcan.gc.ca/earth-sciences/geomatics/canada-lands-surveys/11092#CLdata"
Looking for a database of all NJ based companies,"
I was contemplating filing a FOIA request with a NJ state agency but do not know if they keep the state based companies in one searchable database? If they do not have this information what other sources can I use to obtain this data?
",['companies'],"OpenCorporates? https://opencorporates.com/companies/us_nj?q=&utf8=%E2%9C%93Perhaps not all, but a great amount."
How to extract DBpedia infomation,"
I wrote a python programme to extract the DBpedia links for a given document using DBpedia Spotlight. Now I am interested in getting the skos:broader property and dcterms:subject property for each DBpedia link. Is there any DBpedia API that I can use for this?
I am happy to provide any examples if needed.
","['uses-of-open-data', 'linked-data', 'rdf', 'ontology', 'dbpedia']","Here below I'm using examples from comments to your previous question.Linked Data FragmentsFor simple queries, you could use Linked Data Fragments:Query 1Query 2Add Accept: application/json header, if you need a JSON  response.SPARQLFor complex queries, you could use SPARQL.For example, you don't need to know preliminarily, whether a resource is a Wikipedia category or not:You can perform even more advanced queries with SPARQL 1.1 property paths.SPARQLWrapper is a Python library for working with SPARQL endpoints."
Looking for database of US companies,"
Crunchbase looks most promising but they seem to be payware. Are there any free datasets of companies (established business & startups) to do some data science analysis? Ideally, the data should be name, a description of what it does, location(s), products/services offered etc.   
I am looking for US businesses
","['usa', 'business', 'companies', 'database']",
Where can one track the number of FDA approved laboratory tests?,"
We are looking to find the number of tests that have been approved by the FDA over time. 
Mary Meekin's Internet report cited that there are over 60,000 CLIA waived laboratory tests (i.e. tests that consumers can use themselves without a doctor) and over 1,000 being added every year. But we are looking for tests that your doctor can order. How many are those and how many are being added per year?
",['medical'],
Patient Workflow Steps in MIMIC-III,"
I'm trying to build a workflow model for subjects in the MIMIC-III data set.  there's clearly no shortage of activities in here but if I were trying to track the major steps in the process (treatment protocol?) it might start with a patient (subject_id) admission (hadm_id), showing up at a site (admission_location), and subsequently leaving (discharge_location).  But given the number of items in Chartevents, Datetimeevents, Procedureevents and others, quite a bit takes place at the detail level and it's not clear if there's a summary level available or one that I can create.
So if I was trying to show the patient arriving, getting some treatment (perhaps a treatment in some major category e.g. the service description in Services or diagnosis), getting admitted, getting more treatment (same or new diagnosis), getting admitted to the ICU, getting more treatment (same or new diagnosis), getting better and getting discharged.
Is there a strategy that might be helpful to map out the basic flow from a higher level?
","['mimic-iii', 'best-practice']",
100 Audio files (.wav) with spoken numbers (containing zero) of 100 different speakers,"
I have been working on a machine learning project for speaker recognition.
I need more audio files from different speakers to improve the accuracy of my algorithm*.
I'm using the files to recognize who is speaking. It's not a speech to text algorithm.
I'm using just digits (initially only zero) to simplify my task, because it's still a proof of concept. 
*I tested my machine learning with just 10 speakers and it gave me 55% accuracy. I want to add more samples to get a higher percentage.
","['data-request', 'machine-learning', 'audio']",
Where can I download non-malicious .EXE files for my machine learning model,"
I have been working on a machine learning project which detects malware. I  have downloaded malicious files and tested my model and I was looking for a place which would contain about 50-60 non-malicious .EXE files. 
","['machine-learning', 'metadata']",
Where to find data regarding home types and addresses/zips in the US?,"
I am looking for the following, not everything is necessary, but I would like to somehow extract latitude and longitude for later mapping, and knowing where condos are located is a must:
Necessary:

Home Type (Condo, Town Home, Single Family, etc.)
Zip (or preferably lattitude and longitude)

Nice to Have

Home Estimate and/or last sale price and/or last tax assessment evaluation
Home Square footage
Last time the home sold
By-Law Type (loss assessment, liability only, etc. would only apply to condos)

MLS data only has current listings, and broken up by city, which is a pain to put together, and does not give me all the information I need anyway
","['usa', 'postal-code', 'real-estate']",
Infertility data: causes and solutions,"
I am looking for a list of all possible causes of infertility in males, females, and other sexes, (preferably with descriptions of these causes), or of inability to conceive due to problems during the conception or pre-conception phase, along with incidence percentage or percentage of these problems among the respective populations of unable to conceive or people who has to bear the very depressing misfortune of going through complications, in both males and females. 
It would be nice if for each such condition, there were also a table, listing preventive and non preventive solutions, including genetical solutions such as finding exact or close exact matching sperm and egg and using surrogates for child generation or production. This is, in fact, in my very opinion, the solution to many of these problems. It would also be nice if the given techniques used to achieve this were listed in each case. Alternatives welcome.
","['data-request', 'medical', 'research', 'biology']",
Looking for database with ethnic information in USA,"
I want to train a classifier with given names or surnames of different ethnic groups available in USA. I want to know if there are any open databases available or suggestions how we can create the database. 
","['data-request', 'usa', 'machine-learning', 'classification']","Voter rolls would be a fantastic place to look, the North Carolina State Board of Elections & Ethics Enforcement provides this data:The North Carolina database includes race, ethnicity, and gender. It would be a good place for your classifier to train."
Seeking the attendance data for English football teams for all four tiers,"
I am trying to analyse the attendance and position relationship of football clubs in the 4 tiers (Premier League, Championship, League 1 and League 2). Unfortunately, I am not able to get a legitimate source for the attendance data for each year since 2005/2006 season.
I already have reviewed the following question posted:
Any open public data sets for the English Premier League (EPL)?
Also went through the Kaggle database:
https://www.kaggle.com/hugomathien/soccer
All these sources focuse on the scores and wins, but no attendance records for any year for any tier.
Can anyone guide me to obtain this data set?
","['data-request', 'sports', 'football']",You can find attendance data since the season 1889 (and since 1922 for all top four tiers) from European Football Statistics
Data for Common Alternative Spellings for Names,"
I need a way to translate shortened/alternative spellings back to their original name.
Example: Tom -> Thomas, Ben -> Benjamin
Are there any datasets that you know of that could help with this?
","['data-request', 'names']","Using keywords hypocoristic and diminutive, one can find the following links:Finally, there is diminutives.db on GitHub:The databases of diminutives, male_diminutives.csv and female_diminutives.csv, are manually-edited versions of data that was automatically extracted from Wiktionary by the PHP script bin/generate_diminutives_csv.php."
List of languages with active or native speakers,"
I'm looking for a simple list that has a count of speakers per language. It can be either active speaker or native speakers, the exactness doesn't matter so much to me.
Any format, any license. It's not for research and just for fun - so the exactness is not so important.
Dream data:
Mandarin,9350000000
Spanish,390000000
English,365000000
Hindi,295000000
....
Chamicuro,20
Ongota,12
Njerep,6
Lemerig,2


There are many datasets, but I can only find ""top"" languages

https://en.wikipedia.org/wiki/List_of_languages_by_total_number_of_speakers#Ethnologue_(2017_20th_edition)
https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers#Top_languages_by_population

or ""least"" languages

https://en.wikipedia.org/wiki/List_of_last_known_speakers_of_languages

","['data-request', 'language', 'global']",
Childnessness and infertility by country and region,"
I would like to know, for each country, for each of the sexes male and female or other sex, what are the percentage of males and of females or other sex, the percentage of infertile males and infertile females or other sex, the percentage of children less fertile and childless infertile people and so on. I also would like to see a mean age till fertility and till infertility for each sex, possibly with distributions of these data.
","['data-request', 'research', 'biology']",
Audio data set of (telephone) conversations and their transcriptions,"
I need records of telephone conversations (or simple conversations between two persons) with their transcripts. I need English and French datasets.
","['machine-learning', 'language', 'corpora', 'audio']",
Non-aggregated age of endurance sport competitors,"
I'm looking for the actual age of competitors in endurance sports events (marathon, triathlon, ironman, etc). This can be any event, but it should be the age at competition time (36) and not the age bracket (34-39).
Any format, any license.

The aggregated data may look like this, but I look for non-aggregated, or at least a distribution per age:

(source) 
","['data-request', 'sports', 'demographics']","There is open data on with the ages of Boston marathon contenders, on Kaggle, in CSV format, and for years 2015-2017https://www.kaggle.com/rojour/boston-results/dataor this dataset from 2001-2014https://github.com/llimllib/bostonmarathonAlso, see this related question"
"How can I get data about Wikipedians (e.g. language proficiency), by username?","
Is there an open dataset containing information such as username, language proficiency levels (https://en.m.wikipedia.org/wiki/Wikipedia:Babel/Levels) and (possibly) academic degrees and nationality of Wikipedians? This info is (often) displayed in Users' pages https://en.m.wikipedia.org/wiki/User:usernamepages in the form of badges. I am not looking for aggregates, but for granular username-level data.
I couldn't find data of this kind at https://dumps.wikimedia.org/.
","['wikidata', 'wikipedia']","You can easily create your own, either by scraping the HTML or parsing down the full export/dump.First, get a list of listsThen, loop through each listAnd collect the usernames per degree.If you need more data, for example degree AND region, then it's easy enough to parse the HTML, and identify the relevant userbox, although be careful for users with multiple degrees/nationalities. You can make it even easier and just say that a userpage that, for example, links to /wiki/Doctor_of_Philosophy has a PhD.You'll also have to pick a language page (en for example), since userpages are also language specific."
Data about countries and how they are divided into regions/countries/states/etc?,"
Where can I find a list of all the countries and how they are divided into regions/counties/states/etc? For instance, in India it's states, in Russia it's krai/oblast', in Thailand it's provinces, in Mexico it's states, in Norway counties. In some countries there's no such a division at all.
I want ""country: [names of the divisions]"" data. Not merely the name of the division -- state, oblast', province, nothing.
","['data-request', 'geospatial', 'county']",
Data on Australian universities,"
In the United States there's a great deal of information made public on universities, to help potential students, student loan recipients, employers, and whomever else to make informed decisions. Most of this is through the government and is accessible through financial aid information websites and other portals. For profit higher education requires greater reporting to be able to receive Federal student financial aid.
Is there anything like this for Australia? 
I would like to know some of the test scores, GPA's, etc. associated with specific Australian universities.
","['data-request', 'education', 'australia']",
why doesn't FDA drug list include all meds?,"
The FDA has a drug list that I would have thought would have had all FDA approved drugs. The list can be downloaded here:
https://www.fda.gov/drugs/informationondrugs/ucm079750.htm
You can search it online here:
https://www.accessdata.fda.gov/scripts/cder/daf/index.cfm
The problem is...  not all drugs appear in it. A few examples:

Monovisc
Orthovisc

According to drugs.com these drugs are FDA approved so why aren't they in the FDA drug list? I note that the generic for each of these is the same...
","['usa', 'openfda', 'drugs']","The FDA CDER database, which you linked to, covers small molecule drugs. Monovisc is a medical device, so you'll need to search the medical device database: https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfRL/rl.cfm"
Neighborhood data for Canada,"
I am looking for Canada Locality/neighborhood data but did not get any useful links. Anybody know about a good Locality/neighborhood data for Canada??
",['canada'],
Vegetarian/Vegan dataset,"
Looking for a dataset involving the effect vegetarian/vegan diets have on the number of animals killed, the food industry, or health
","['data-request', 'food']",
Where can I find a data set on the federal student loan debt since at least 1965?,"
As the title says, I'm not sure where I can find the data set I'm looking for. I'm trying to explore the relationships between inflation rate, total student enrollment, and total amount of student debt since 1965. I've been able to find numbers for 2007 onward, but nothing going back any further than that. Any help would be appreciated. 
","['data-request', 'usa', 'government', 'economics', 'education']",
All US cities in GEOJSON,"
Is there a data set that contains all US cities in GEOJSON format? I saw something about Mapzen having it, but looks like they don't provide it anymore.
Did anyone download this or know where I can find something similar?
","['data-request', 'usa']",
Search in wikidata with specific Q code,"
I've this query but I can't understand why doesn't return any result. I try different versions (with link, with only code, with wd:code) but nothing seems to work. What I need is this query but searching by code (like the eg., Q6015113)
              SELECT ?item ?itemLabel WHERE {

 ?item wdt:P31 wd:Q5.
  FILTER (?item = ""http://www.wikidata.org/entity/Q6015113"")
 SERVICE wikibase:label { bd:serviceParam wikibase:language ""es,en,fr"" . }
} ORDER BY ASC(?num)

","['wikidata', 'wikipedia', 'sparql']","In short, URIs are ""things, not strings"". The filtering condition should be:There also exists the VALUES keyword for providing inline data."
GPS coordinates dataset of wandering people or tourists,"
I would like to use a dataset of GPS coordinates (with time if available) of people (preferable tourists) visiting places in a city.
I would like to use it to compute a map layer with the intensities or frequencies of visits.
I have been using an application to make journeys by my city to make some tests but I would need much more data to accomplish the project.
Where or how can I find it? 
City place or transportation used by people in that city is not a need 
(although is preferable walking people).
","['data-request', 'geospatial']","OSM has public GPS traces https://www.openstreetmap.org/tracesBut you'd have to screen either the GPX files based on GPS coordinates, or text label.You can use internet search to find keywords:And then each trace is individually downloadable, for example:https://www.openstreetmap.org/user/Matthew%20Sammon/traces/449560Apparently, public GPS traces are available in bulk in the Planet data - read more."
Does anyone know if/ where I can download shapefiles for bus routes in Cardiff?,"
Had a look on OSM and various sources on google, however, there does not appear to be any obvious websites. 
I specially want the number 52 bus route for this current task but if there is a general mechanism or website with other routes on this will be helpful in the future.
","['data-request', 'geospatial', 'uk', 'public-transport']",
Administrative divisions of Cambodia,"
Where can I find an official list with hierarchical relationship between various levels of the administrative division in Cambodia? 
","['asia', 'cambodia']",
How to build a concept hierarchy using LOD?,"
I am interested in building a concept hierarchy using the given Computer Science related concepts. For an example we can consider 'support vector machine', whether the parent category would be 'machine learning', the parent category of 'machine learning' could be 'artificial intelligence' etc.
Being a novice in this field, I am interested in getting some expert recommendations about the resources I can use for this in LOD? Can we only use DBpedia for this, Or are there any other resources that I can try out?
I am happy to provide more examples if needed :)
","['uses-of-open-data', 'research', 'linked-data', 'rdf', 'ontology']","Possible answers were listed in your previous questions.Perhaps some upper ontologies contain what you need.Another possible source is Wikidata. For example, this is SVM's page on Wikidata. As you can see, the wdt:P279 (""subclass of"") predicate currently corresponds to the parent-child relation you are talking about.The query below lists all parent-child relation between descendants of wd:Q11660 (""artificial intelligence"").Try it!You could also be interested in this simple tool."
YAGO entity details,"
I recently came across an article where they have mentioned that YAGO has more entities than DBpedia. It also mentions that ""Recently, a new version of YAGO has been released, which also accounts for temporal and spatial information associated with entities.""
Thus, I am interested in checking the entity details of 'support vector machine' in YAGO. Where can I find these entity details in YAGO knowledge-base? (E.g., Like in DBpedia: http://dbpedia.org/page/Support_vector_machine). 
Please let me know how to get these YAGO details of entity?
","['uses-of-open-data', 'linked-data', 'rdf', 'ontology', 'dbpedia']",YAGO Demo page lists two possible ways:Explore YAGO with our graph browser (YAGO3)Explore YAGO with our ontology browser (YAGO2)You can find what you need using query builder.  There also exists SPARQL endpoint.
France communes shapefiles,"
Where can I find a free dataset of all the shapefiles of boundaries of France ""communes"" administrative divisions?
","['data-request', 'geospatial', 'france']",This is the best source I could point you to - Découpage administratif communal français issu d'OpenStreetMap
Where can I download a raster with the elevation data of the whole US?,"
I know about USGS and USDA have DEM files but they are in small blocks, and I need the whole country. The closest that I've been with solving this is finding this website that contains all the files that I need but I can't download cause there is a limit of 15gb to download. Moreover, I would like to have the whole country in one file. 
Do you know where to find it? Preferably 30m resolution?
",['geospatial'],You could try the National Contours file. You could also try using an FTP program such as filezilla to retrieve these rasters.
Looking for Databases with gender of names and Ethnicity information,"
I want to build a classifier which can classify gender and ethnicity based on the names. 
I am looking for datasets to download where I take samples for supervised learning. 
If there are no open datasets available for download, what are the ways that I can create one?
","['data-request', 'nlp', 'python']",The wikidata query above (http://tinyurl.com/y9t44r59) yields 12841 results and may provide a helpful starting point.
Data on minimum wage by country?,"
Where can I get a dataset (yearly, if possible) containing minimum wage (US$ or other) by country?
",['data-request'],
Political candidate's stances on specific issues?,"
I believe that a large percentage of the US population are politically unaware and tend to vote on the candidate whom they 'like' the most. It would be great if public can have easy access to view each issue and each candidates stance on it.
","['government', 'politics']",Another way to gauge a politician’s stance is based on the sources of their donations.https://www.followthemoney.orghttps://classic.fec.gov/finance/disclosure/norindsea.shtml
Data on Lightning Times and Location,"
I am looking for data on lighting strikes, time and location between 2014 and 2015.
There is a similar request regarding lighting densities in colorado. I'd need worldwide (or at least Africa-wide) coverage of ideally at lasst 2014 and 2015. There are multiple potential data sets, (an overview is found here) such as the WLLN, however I was not able to find any openly accessible version of these data.
","['geospatial', 'weather']",
"Data set of particulate matter concentrations in Graz, Austria","
I am looking for a data set that which observations are half-hourly measurements of the concentration (measured in μgm −3 ) of particulate matter with an aerodynamic diameter of less than 10μm, abbreviated PM10, in ambient air taken in Graz, Austria from October 1, 2010 until March 31, 2011.
The Data set is used in 

Aue, A., Dubart Norinho, D., & Hörmann, S. (2012). On the prediction
of functional time series. Submitted for publication. 
Hörmann, S., Kidziński, Ł., & Hallin, M. (2015). Dynamic functional
principal components. Journal of the Royal Statistical Society:
Series B (Statistical Methodology), 77(2), 319-348.

There is a broken link in the second publication:
http://wileyonlinelibrary.com/journal/rss-datasets
I followed citations to 

Stadlober, E. Hörmann, S. and Pfeiler, (2008). Quality and
performance of a PM10 daily fore- casting model. Atmospheric
Environment 42, 1098–1109.

But can not find the data anywhere.
","['data-request', 'time-series', 'environment']","I suppose the link has become broken after the Wiley Online Library redesign and restructuring.Now this link should be the Please click here to access the full dataset archive link from this page. However, that new link is broken too.I don't think that this unavailability is intentional, a few months ago those datasets were available.I'd suggest you contact the Royal Statistical Society or the authors. The corresponding author of the second publication is Siegfried Hörmann.UpdateCheck this link."
Shapefiles for OECD United States Regions?,"
I'm looking for Shape files that match up with the OECD TL3 US regions. I've tried contacting the OECD but they have not replied.
so, i followed the links in the OECD document (below) where they are meant to explain reference shape files. However, they reported that they used the 'Census Bureau, 2015 Cartographic Boundary Shapefiles - Counties'. This is not right
It seems that the admin names used by the OECD are from different sources - i've combined all of the shape files from the cencus Bureau site (e.g. County District, Division, Statistical Area etc) and quered these against the OECD region names, but i only get 100 matches out of a possible 170 oecd region names.
Can anyone help?
http://www.oecd.org/cfe/regional-policy/territorial-grids-2017.pdf
","['geospatial', 'oecd']",
Where can I find area specific SST data,"
I am looking for sea surface temperature (SST) data for the Cayman Islands from 1972-2017. Can anyone point me toward a resource? I have checked out NOAA and NASA, but I cannot seem to access the data in a CSV or Excel format. 
EDIT:
I found this website, but it only has air temp, not SST. 
http://sdwebx.worldbank.org/climateportal/index.cfm?page=downscaled_data_download&menu=historical
","['data-request', 'climate', 'oceanographic']",
Data set request on domestic violence and the health and economic impacts it has,"
I am a student and have an assignment on the health and economic impacts of domestic violence. I need a ""data set"" on domestic violence to run a descriptive analysis for any correlation if any between these variables. Thank you.
","['data-request', 'data.gov', 'research', 'crime']",
Mapping between ImageNet and Wikidata entities,"
Wikidata and ImageNet both know oxcarts:

https://www.wikidata.org/wiki/Q1190777
http://imagenet.stanford.edu/synset?wnid=n03868242 (slow)

An AI library gives me the ImageNet ""synset"" about oxcarts.
From this ""synset"", how to get the equivalent Wikidata item?
","['data-request', 'wikidata', 'data-mapping', 'imagenet']","You may want to see ImageNet to Wikidata mapping (I am the co-author), which extends the work of Finn Arup Nielsen.We linked the ILSVRC 2012 dataset (often simply referred as ImageNet) labels to Wikidata entities. This enables using rich knowledge graph structure and contextual information for several computer vision tasks, traditionally benchmarked with ImageNet and its variations. We mapped all 1000 ImageNet labels - 461 were already directly linked with the exact match property (P2888), 467 have exact match candidates, and 72 cannot be matched directly. For these 72 labels, we proposed semantically close non-exact match candidates are presented as well.More details in the paper."
"City boundary for Fort Lauderdale, Florida","
Where can I find data for the boundary of Fort Lauderdale, Florida? I'd like to load the data into carto.com to create a map.
I looked on their gis website, but I couldn't find an outline of the city itself.
","['data-request', 'usa', 'geospatial', 'government', 'city']","You can get political boundaries from the Florida Geographic Data Library.Use the metadata tool: under content choose ""Admin & Political Bounds"", then scroll down to, for example, ""CITY LIMITS - DERIVED FROM FLORIDA PARCEL DATA - 2015""here's the metadata overview"
Is there a codebook for the 1990 Census API table names?,"
I'm trying to download Census data using R and the Census API. There's a list of variable names at https://api.census.gov/data/1990/sf3/variables.html
However, most of the variable descriptions aren't very informative. Is there a codebook somewhere that explains what each measure is actually measuring? Edit, for example the variable P1200008 is described as ""INC BELOW POV[14] Under 5 years"" - I assumed this meant ""number of people under 5 in households with incomes below the poverty line"" but that isn't returning expected values.
Here's the specific data I'm trying to get: I want to end up with county-level poverty rates. The total population numbers (the POP100 variable) seem right (they add up to 240 million or so) but the poverty rate ends up being around 2% when it should be 13%.
     get <- c(""POP100"", ""P0080001"", ""P1200008"", ""P1200009"", ""P1200010"", ""P1200011"", ""P1200012"", ""P1200013"", ""P1200014"",
                ""P1190036"", ""P1190037"", ""P1190038"", ""P1190039"", ""P1190040"", ""P1190041"", ""P1190042"")


        census <- getCensus(name = ""sf3"", vintage = ""1990"", key = key, vars = get, region = ""county:*"")
        colnames(census) <- get.labels

#poverty rate for county level rows
        census$poverty <- (sum of poverty variables) / census$POP100
#overall poverty rate, should be around 12%
rate <- (sum of poverty columns) / (sum of POP100 column)

Second edit: I was able to find the specific data I was after on an archived USDA page here: https://wayback.archive-it.org/5923/20110904012456/http://ers.usda.gov/Data/Povertyrates/1989_1999/PovListpct.asp?st=NY&view=Percent. Obviously that doesn't answer the general question, so if anyone can answer that (for myself and posterity) I'd be thankful!
","['api', 'census']","I think I found the culprit for your discrepant numbers. In addition, I have an alternative and a recommendation.The Culprit: I believe you are using Table P120 from Summary Tape File 3A.P120. POVERTY STATUS IN 1989(2) BY AGE(7) [14]Universe: Persons of Hispanic origin for whom poverty status is determinedI checked the documentation at this page, which led me to this series of supporting documentation.I found the contextualization for the table you are using in the TBL_MTX.TXT (aka TABLE MATRIX SECTION) file.Alternative Solution:I recommend using Table P117 instead.P117. POVERTY STATUS IN 1989(2) BY AGE(12) [24]Universe:  Persons for whom poverty status is determined Income in 1989 above poverty level:Recommendation: I recommend not using total population as your denominator for poverty. The Census Bureau recognizes difficulty in measuring poverty for certain populations (e.g. the institutionalized, active duty armed forces, foster children under age 16). These days, the Census Bureau would put the universe for the subject you would be measuring. Here, it seems they do not do that.To make your denominator, I would recommend summing all 24 items (P1170001 -- P1170024) in the table to calculate the ""population for who poverty status is determined""."
Is there any open data-set for products per brand (with description)?,"
I am looking for a dataset/API where I can query a product brand and it can give all the products of that brand along with their description. 
","['data-request', 'products']",
Geology/mineral dataset,"
I'm looking for a dataset that relates the location of minerals or other valuable resources like gold or oil to the geological conditions in which they occur. So for example for a certain location, it could have the surface pressure, temperature, soil info, etc. Where can I find something like this?
",['data-request'],
Agriculture shapefiles and additional GIS data for Australia,"
I am searching for agriculture shapefiles and additional GIS data for Australia to save them in a PostGIS database.
More specific I need these data for mountains and their paths, climatic zones etc. 
Can someone help me and give me some links where I am able to find these valid data?
","['geospatial', 'australia', 'agriculture']",Here are the links that might be what you are looking for but I'd google it if these were not what you are looking for:http://www.diva-gis.org/Datahttp://www.agriculture.gov.au/abares/data
How to use DBpedia to identify the topics,"
In the paper ""Discovering Relevant Topics using DBPedia providing non-obvious recommendations"" they have used skos:broader property and dcterms:subject property.
In my task given the word I want to identify the topic of it. For example, given the word; 'suport vector machine', I want to identify topics from it such as classification algorithm, machine learning etc.
However, I could not find the properties mentioned in the paper (skos:broader and dcterms:subject) in the relevant DBpedia pages: http://dbpedia.org/page/Support_vector_machine
Please let me know how I can achieve my task (retrieving topics from keywords) using DBpedia properties (or using any other knowledgebase)?
I am happy to provide more examples if needed.
","['nlp', 'wikidata', 'linked-data', 'ontology', 'dbpedia']",
"Google Finance Error: Sorry, you may be sending automated queries","
Using javascript, I tried pointing to a JSON from google at this URL:
www.google.com/finance/info?q=NSE:AAPL&callback=?
Then I got the error:

Sorry, your computer or network may be sending automated queries. To
  protect our users, we cannot process your request right now.

Question: Is that supposed to happen? I would like to circumvent this error. I'm thinking I may have misunderstood how ""open"" their api is. Do I still need an authentication key or something? Is that hard to do -- and more importantly is it still free?
","['data-request', 'api', 'finance']","I got the same error in the browser, so I guess your URL is old. Google Finance isn't an API (the API was shut down in 2012, so in effect you are just scraping)... Checkout Yahoo Finance or others for a more official unofficial API.In the browser:does work but without the &callback=?see this link for a workaroundhttps://stackoverflow.com/a/46073520/2327328"
Reputable source to get foot traffic in Australia based on different locations,"
I am interested in hourly foot traffic in Australia based on various locations. Let's say I choose a certain restaurant's location in Melbourne and set a 1km radius to measure the traffic hourly.
Is there a appropriate way where I could retrieve the historical hourly traffic? Or, if I need to pay for the historical data, do you have any recommendations on websites or analytics company I could reach out for?
","['data-request', 'traffic', 'extracting', 'australia']",
Where can I find HTML5 metadata?,"
I need the list of tagnames, interface names, attributes of each tagname (the name and the type) and the relations between them. 
The info at https://html.spec.whatwg.org/multipage/ is unformated and in an unprocessable format. 
The ""Index elements"" from HTML 5.1 2nd Edition at w3.org have better info but not in a structured format (json, csv, xml, etc). 
",['html'],"HTML is machine-readable/can be parsed, so not sure what you mean by ""unprocesable"". The document containing the information you desire may as well be valid markup, but more importantly proves its parseable.Alternatively, if you view source, there is a script html-dfn.js,
 and if you follow that you can see that it calls xrefs.json, which I'm assuming renders those pages.Alternatively, alternatively, WHATWG offers a very non-open data format flavor ala PDF which is visible form the main navigation."
UK monthly weather data,"
Is anyone aware of any monthly UK weather data based on grids, easting nothing, or even postcodes? Any pointers would be very much appreciated.
","['weather', 'uk']",
Surname - Cast/Ethnicity Mapping for Nepali Names,"
I'm trying to link family names to ethnicity / casts in the Nepali context. Is anyone aware of a publicly accessible data set that would allow or simplify such a mapping?
Example of what the outcome should be (based on manual coding):

Any micro-data that would allow to construct such a thing, or a ready-made (even partial) mapping would help.
","['census', 'names', 'asia']",
Polygons for Irish Counties,"
I wish to produce a set of 32 polygons for each county on the island of Ireland. I found shapefiles here of all 32 counties:
https://www.townlands.ie/page/download/
The problem is that there are no lakes and the Shannon Estuary is missing. 
I then found lake data here but the lake resolution is low and still no Shannon Estuary:
http://www.naturalearthdata.com/downloads/10m-physical-vectors/10m-lakes/

How might I acquire the required polygons?
Here what I have so far for the code below:

from shapely.geometry import Polygon, MultiPolygon, mapping, shape
import fiona
import matplotlib.pyplot as plt
from descartes.patch import PolygonPatch

ireland = Polygon([(-5.34,55.43), (-10.56,55.43), (-10.56,51.39), (-5.34,51.39)])

lakes = []
with fiona.open(""./ne_10m_lakes/ne_10m_lakes.shp"") as shapes: 
  for s in shapes: lakes.append(shape(s['geometry']))
with fiona.open(""./ne_10m_lakes_europe/ne_10m_lakes_europe.shp"") as shapes:
  for s in shapes: lakes.append(shape(s['geometry']))
lakes = MultiPolygon([s for s in lakes if s.intersects(ireland)])

counties = {}
with fiona.open(""./counties/counties.shp"") as shapes:
  for s in shapes:
    assert s['properties']['NAME_EN'][:7] == ""County ""
    counties[ s['properties']['NAME_EN'][7:] ] = shape(s['geometry'])

# 32 counties
counties = [c.difference(lakes) for c in counties.values()]

fig = plt.figure()
ax = fig.add_subplot(111)

for s in counties:
    p = PolygonPatch(s)
    ax.add_patch(p)

ax.set_xlim(-11,-5)
ax.set_ylim(50,57)
plt.show()

","['data-request', 'geospatial', 'openstreetmap', 'ireland']",
Weird results in search from wikidata,"
I ve this query, which i want to find every instance of human with name Jose (already a first name like John, very common) in wikidata spanish, and then I get only 10 results. I believe is the way of the subquery, like if I made the filter of my 50 previous results, but I can't move the conditions without breaking the query.
my query:
SELECT * WHERE {
  SERVICE wikibase:mwapi {
      bd:serviceParam wikibase:api ""EntitySearch"" .
      bd:serviceParam wikibase:endpoint ""www.wikidata.org"" .
      bd:serviceParam mwapi:search ""josé"" .
      bd:serviceParam mwapi:language ""es"" .
      ?item wikibase:apiOutputItem mwapi:item .
      ?num wikibase:apiOrdinal true .
  }

  ?item (wdt:P279|wdt:P31) ?type
   FILTER (?type = wd:Q5)
OPTIONAL { ?item wdt:P569 ?fecha_de_nacimiento. }
    FILTER(?fecha_de_nacimiento > ""1900-12-31T00:00:00Z""^^xsd:dateTime)
} ORDER BY ASC(?num)

and my edit, is similar in result:
SELECT * WHERE {
  SERVICE wikibase:mwapi {
      bd:serviceParam wikibase:api ""EntitySearch"" .
      bd:serviceParam wikibase:endpoint ""www.wikidata.org"" .
      bd:serviceParam mwapi:search ""josé"" .
      bd:serviceParam mwapi:language ""es"" .
      ?item wikibase:apiOutputItem mwapi:item .
      ?num wikibase:apiOrdinal true .
      ?item (wdt:P279|wdt:P31) ?type
   FILTER (?type = wd:Q5)
  }


OPTIONAL { ?item wdt:P569 ?fecha_de_nacimiento. }
    FILTER(?fecha_de_nacimiento > ""1900-12-31T00:00:00Z""^^xsd:dateTime)
} ORDER BY ASC(?num)

","['api', 'wikidata', 'sparql']","...like if I made the filter of my 50 previous results...Wikibase:mwapi supports the limit parameter of the Entity Search service:Try it!As you can see, results are still weird (but try e. g. ""José Mourinho"" instead of ""José"").Possibly you should add some filtering using CONTAINS. If you want to search people by their given names, probably you should use the wd:P735 property, however, there is no fast way to get most ""popular"" or ""relevant"" results."
Is there an API for getting app prices in the Google Play/App store?,"
I'm looking for an API that can get me prices for apps. I also want information on in-app purchases given the ID (package name in Android) of the app.
An example query would be:
Query:
ID: identifier of the application
COUNTRY: country to look for (some applications have price depending on country)

Response:
PRICE: price of the app in the country (0 if it's free)
IN_APP: true if the app has in-app purchases, false otherwise
PRODUCTS: dict object having name of the in-app product as key and the price as value

I did some research on the web. I found the 42matters API. However, it's only approximating the price of in-app products (I verified with one of my apps) giving a somehow large range, e.g.
[in_app_min:0.99, in_app_max:144.99]

","['data-request', 'api']",
Wikidata - Search of human instance that doesn't break,"
Is this possible, like the wikidata autocomplete combo works, in a speedy way, with a filter of ""itemlabel strings start with..."" ?
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

SELECT ?item ?itemLabel ?fecha_de_nacimiento  WHERE {

  ?item wdt:P31 wd:Q5.
  ?item schema:dateModified ?modified
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""es,en,it,fr,de,cs,[AUTO_LANGUAGE]"". }
  OPTIONAL { ?item wdt:P569 ?fecha_de_nacimiento. }

  FILTER(?fecha_de_nacimiento > ""1900-01-01T00:00:00Z""^^xsd:dateTime)

}
LIMIT 100

","['api', 'wikidata', 'wikipedia']","I suppose the problem is not that you're not familiar with STRSTARTS, but rather performance.This page contains some introductory remarks.Search in multiple languagesIf you really want to search in multiple languages, then, I'm afraid, the only option is to use wikidata.dbpedia.org as described in this answer on Stack Overflow.Search in single languageIf you want to search in a single language (according to your own question on Stack Overflow ), you can use Suggest API or call Mediawiki API from SPARQL.UpdateThe Wikibase Mediawiki API extension allows to use some special keywords on Wikidata, e. g. haswbstatement:P31=Q5."
Historic data on UK roads 1950-2010,"
I'm looking for data about roads in the UK. OS Open Roads is a great spatial dataset with detailed shapefiles, but it doesn't contain temporal information. I would like to find a dataset with roads from the 1950s onward. For each road, I would like to know when it was built (and closed, if it doesn't exist anymore). I'm particularly interested in the development of the motorway network in the UK. Does such dataset exist?
","['geospatial', 'uk']",
Seeking License Fees / Restrictions for MapQuest Light (OSM) Basemap,"
Can anyone direct me to a link that has the Usage Agreement / Licensing Fees / User Restrictions or metadata for a basemap called MapQuest Light (OSM)?
To View the Basemap, it can be found on this website:
https://mc.bbbike.org/mc/
Select the drop down and choose MapQuest Light (OSM).
Thanks all, I haven't been able to locate any metadata, a user license agreement, or any specifics on this basemap.
","['geospatial', 'licensing', 'openstreetmap']",
"Does anybody know how to retrieve historical forecasted weather data? I am looking for forecasted data, not actual data","
Most websites only provides historical actual weather data (e.g. the observed temperature on March 5 2015 was ...). I am specifically looking for forecasted weather data (e.g. the forecasted temperature on March 5 2015 for the next day was...).
Does anybody who came across such datasets? The geographical area I am looking for is The Netherlands.
","['data-request', 'machine-learning', 'weather']",
"mimic-iii missing ICUstay_IDs, Aren't all of these hospitalizations ICU admits?","
Of the 58,976 admissions (hadm_ID's) in the database, 1190 have no associated ICUstay_ID's. How is this possible? Are there hospitalizations in the database that didn't include any ICU admissions?
",['mimic-iii'],
CHARTEVENTS Carevue and Metavision,"
I want to find all patients that have measurements for some predefined variables. However items names for carevue and metavision db are different (e.g. Carevue - 'NBP [Systolic], metavision- ""Non Invasive Blood Pressure systolic""). Do you have some script to unify these two tables? What strategy should I follow?
",['mimic-iii'],
Historic roadworks,"
As part of a research effort, I am working on the recognition of roadworks from street-level imagery. On top of other sources, we have the plan to match historic street view snapshots with roadworks data in order to get a geographically diverse dataset. However, datasets seem to be sparse. We need three attributes: location (preferably XY), start date, and end date.
The only concrete dataset which suits my needs is the historic Vicroads snapshot.
After some digging, I can't seem to find other sources like it. OpenStreetMap has the construction tag but doesn't have a proper protocol for roadworks. Not to mention, searching the entire history of OSM snapshots requires a lot of set-ups.
Does anyone have any other suggestions on sources I could check out?
EDIT: For anyone stumbling in here in the future, I'll post any suitable working links I can find.
Leeds roadworks from the backup site
",['historical'],
Free Map matching benchmark data,"
I have my own map matching algorithm and I want to compare it's accuracy to some other algorithms. Is there a free trace dataset that has a confirmed match for each trace (ground truth), so I can perform the comparison?
",['geospatial'],"Your question is pretty old now, but I'm looking for the same stuff and found this article so far:
https://ieeexplore.ieee.org/document/7225829The corresponding dataset (described in this article) can be found here: https://zenodo.org/record/57731#.XDS-Plz0laQ Maybe this helps you. If you found something yourself in the meantime I would appreciate it if you could share/link it here. "
Shapefile or map of Mozambique localidades (localities) administrative boundaries,"
I am trying to find a shapefile for Mozambique's Level 4 administrative boundaries. These units are known as localidades, or localities, and there are over 1,000 of them. I've tried all the usual sources: GADM, etc. No source that I have found has anything below level 3 boundaries, which are districts.
Confusingly, some websites refer to level 3 districts as localities, but -- while this may have been correct years ago -- it is no longer right. There are ~450 districts and over 1000 localities in Mozambique.
At this point, I would be happy to find any map of localities, even piecemeal, that I could scan and assemble into a comprehensive shapefile. I am also open to alternative solutions, such as generating approximate polygons from a list of points known to reside within a given locality. But I have not found data that would allow me to do that yet.
","['geospatial', 'africa']",
List of French Hospitals and Health Clinics,"
List of French Hospitals and Health Clinics
There might not be a database covering all french hospital. 
So if we need more data that OpenStreetMap ha - Below is the data for France.
The French government has created a website showing the list of all 4307 hospitals and clinics in France:
http://www.ScopeSante.fr
Click on ""Voir la liste des établissements"" to get the full list.

You will need to scrape that. Each hospital name has a link to its detailed information page:

I have just sent them a message asking for a dump of the data. They replied to me saying that all of their data comes from the FINESS database, which is also maintained by the French government, and available online ""for private use"" and unfortunately does not have dump downloads, so that would mean scraping that:

what is aimed; i want to have a full list of the dataset.
See the https://ws.scopesante.fr/v4/carte-etablissements
The private API returns the full list of establishments along with their ""id"" numbers in JSON format.This is a great approach; This is the full list. We can use the ""id"" number of each organization to look up the ""details"" page for each organization. So, using the route to the ""details"" page: https://www.scopesante.fr#/etablissements/PUT_ID_NUMBER_HERE/fiche-detaillee/
We can get the details for a specific establishment directly by calling the API. See:
https://ws.scopesante.fr/v4/fiche-identite/010000024
This returns the details on the specific establishment.
We can replace the number on the end of the URL with the ""id"" number of the establishment you are looking up. Using an API is usually more efficient than scraping the pages directly.
We have for example the follwing ending of a URL
010000024
This number is also visible in the overview see the https://ws.scopesante.fr/v4/carte-etablissements
So I have to do some combination:
The question is - how to retrieve the full dataset of the approx 4000 records ?
I guess that the key is
a. retrival
b. processing of JSON-data and
c. creating a db that stores the whole dataset
Now I want to have a closer look at the decoding with json_decode() -  as with every JSON API.
Many thanks for your help here.
","['data-request', 'medical', 'france']",
"What limitations, if any, are there on what kind of concepts can be declared using RDF?","
I wanted to ask about limitations on the ""concepts"" that can be defined using RDF or OWL. Some concepts such as the economic term ""inflation"" or the concept ""overwork"" (as when someone works too much) come to mind as more abstract examples.
(This would be in the context of creating a triplestore of structured information for the purpose of training an AI.)
Are there known limitations on what kind of ""concepts"" can be defined using RDF?
","['rdf', 'ontology']",
"Looking for HDR raw data or high frame rate data, preferrably from satelites","
I'm working on an algorithm to enhance camera resolution.  Ideally the scene is static between the frames, and I need minimally the raw files that go into HDR images, or high frame rate data (the higher the better). 
",['geospatial'],
Tokyo Stock Exchange Historical Data,"
How can I fetch/retrieve or get Tokyo stock exchange data beginning the year 2001?
It does not have to thru code but can be a simple download or few lines of code in R or Python.
It has to be free and can be in any format. 
Please tell me the procedure or the website to get it. Thanks!
","['data-request', 'finance', 'japan']",
How can I find out how frequently certain words are used in Danish print and online news media?,"
Do you know of any sites that make this information available online?
","['data-request', 'media']",
Running speeds for young males & females at different ages,"
I'm looking for an open dataset that has aggregate running speeds over short distances, that divides the data into Male/Female and Age Groups. The data should be from regular human beings, like students or ameteur athletes, and not from Olympic level competition.
The exact raw data isn't so important, but my goal is to generate median max speed per age and gender. Any data that is related to soccer/football or other sports is also welcome.
The data can be any format or level of machine readability, and I'll use the data as a reference, so I don't have any strict license requirements.
Perfect dataset would look like this
M,13,median_top_speed,20
M,15,median_top_speed,22
M,17,median_top_speed,24
M,19,median_top_speed,26
M,21,median_top_speed,27
F,13,median_top_speed,19
F,15,median_top_speed,21
F,17,median_top_speed,23
F,19,median_top_speed,25
F,21,median_top_speed,26

","['data-request', 'sports']","I found this 2015 paper which has data for 11-18 year old Norwegian male and female running 60 meters:Performance Development in Adolescent Track and Field Athletes According to Age, Sex and Sport DisciplineThe link to download the data was dead (and I notified the author), but an archive is available on the wayback machine.https://web.archive.org/web/20150501075113/http://www.friidrett.no/stevner/statistikk1/alle%20tiders/Sider/Norgesbestegjennomalletider.aspx"
Where can I find data about Cameroons subdivisions and number of inhabitants?,"
I want to know where I can find detailed, current and authoritative (ie. government) data about all of Cameroons subdivisions and the number of inhabitants in each (ie. census data).
I know that Cameroon is divided into 10 regions, which are in turn divided into departments, which are in turn divided into communes, which in turn consist of villages, and even neighborhoods have their names. Often names exist in English as well as French. I want to know the official names of all of them and the number of people living in each.
I have come across a number of documents online (but am not allowed to post links to them):

United Councils and Cities of Cameroon (official but incomplete)
Village Dictionary of Donga-Mantung Division (official but neither current nor complete)
Joshua Project (inofficial and neither current nor complete)

Data for the Northwest Region and it's subdivisions is of particular interest to me.
",['census'],The Répertoire actualisé des villages du Cameroun provides data about the number of inhabitants for all subdivisions of Cameroon.
age persistence in information technology,"
My goal is to understand persistence of employment in the information technology sector over age groups. For example, for the person who enters IT at age 21, are they still employed in that sector at 31? 41? 51? 61? And, to put all this in context, how does the rate of career persistence compare to other U.S. sectors like finance, real estate, trades, health care, sales, education, etc?
Before I try to start from scratch, does this duplicate previous work?
",['usa'],
Seeking Underground Infrastructure Data for Brisbane (Australia),"
I am in Brisbane, Australia and am looking for GIS data relating to underground services (such as buried water mains, power lines, gas lines, etc).
Where might I find some of this information?
","['data-request', 'geospatial', 'government', 'australia']",
Seeking 2010 County Shapefile for China?,"
I have been researching frantically for the China 2010 dataset for county boundaries. I went through quite a few sources:
China Data Center - Can't afford it
GADM.org - Not verfiable for date
This is mostly 2000 Census: https://research.cip.cgiar.org/gis/modules.php?name=Downloads&d_op=viewdownload&cid=11&min=20&orderby=titleA&show=10
Can anybody help me get the 2010 county boundaries shapefile?
","['geospatial', 'county', 'china']",
Where can I get a vector file (or WMS) showing field boundries on the UK?,"
I am looking for vector data outlining the agricultural field boundaries in the UK (Specifically Scotland, England and Wales). I have tried all sources of open source data I can find and looked at Ordnance Survey Data.
Ordnance Survey have the data however they package it as part of the Vectormap Local data which costs in excess of £800k for the UK. The actual sub layer is called Rural Boundaries when the Shapefile is extracted. 
I need the vector file to allow me to trial an analysis of agricultrual fields. I would like to colourcode the fields dependant on intersecting designations such as flood risk or greenbelt. 
If anyone can help, I would be very grateful. 
","['data-request', 'geospatial', 'agriculture']","If you set the map scale to 1:10,000 or lower you can see field boundaries for England, Wales and Scotland.http://magic.defra.gov.uk/MagicMap.aspxThe usage is still protected under crown copyright.The other option is to extract from Environment Agency (Opendata) Lidar to get a field boundary dataset - this will be time consuming and require data clean up.https://environmentagency.blog.gov.uk/2017/12/30/uncovering-englands-landscape-by-2020/"
"Database of HFOV+focal length+crop factor, for most cameras and smartphones","
A photography app wants me to enter my camera's details:

I have no idea what these numbers means (I entered the numbers pretty randomly), but I know the brand/model of my camera.
Is there a database that gives these values for most popular cameras/smartphones?

Horizontal field of view
Focal length
Focal length multiplier

The Load lens data... button asks for a .ini file, so a database of such files would be great too.

Lensfun probably had that but it has not been updated since 2015.
PkmX/lensfun-profiles has only 5 lenses/cameras.

","['products', 'sensors', 'technology']",
Where can I find public financial data for private companies?,"
I'm looking for financial data sets of private companies that state their annual revenue, market value..etc. I'm doing so to be able to research their revenue vs their purchase history from us so I can build a predictive model.
","['data-request', 'finance']",
Dataset of unstructured road image,"
I search for the dataset of images of unstructured roads (images of snowy/dirt/rainy/broken roads).
Currently, I've collected ~130 images manually.
If someone can share or point out to the public dataset of images of unstructured roads, I'd really be thankful for that. :)






","['images', 'photographs']",
Business Location Test Data,"
I'm working through a book that deals with MEAN applications... and in the book it deals with geo-spatial data and creates a Review for Businesses (Think: Yelp. Look for businesses close to a location then select, see reviews and add your own!!! SO EXCITING!!!).
The problem I'm having is the book doesn't really provide a good data set... or actual data at all - just a couple very short examples and how to create more.
Given a location - say a state: Delaware, California, Australia... or a central point on map... or a ""BBOX""... what's the best place to get a set of data of:

Business Name
  Address
  Hours of Operation
  Long
  Lat  

I can absolutely fudge missing parts (Hours of operation and other things not listed here that the app displays about the ""Businesses"") and I can massage the data into an input stream for the database - so I'm more concerned about the raw data as opposed to the format/output: I'd love to have a realistic data-set even if it is outdated - and those are the ""core"" parts of whats needed for the examples in the book.
OpenStreetMaps might have what i want, but the options are daunting and I can't seem to weed through the noise. Is what I want there and I'm just not seeing it?
Or are there any other better data-sets - realistic if not ""real"" or ""current"".
(Note: I'm currently at work. I have a data-set at home that I can't seem to find here that has ""vacation"" type businesses - hotels, inns, etc that is ""close"" but not as expansive and inclusive as I'd like. I'll add a link to it if I can find it or when I get home)
PS: Link to book chapter, an example image of a ""Review Page"" I'm trying to finangle data for and a single data item:

location: {
  name: 'Starcups',
  address: '125 High Street, Reading, RG6 1PS',
  rating: 3,
  facilities: ['Hot drinks', 'Food', 'Premium wifi'],
  coords: {lat: 51.455041, lng: -0.9690884},
  openingTimes: [{
    days: 'Monday - Friday',
    opening: '7:00am',
    closing: '7:00pm',
    closed: false
  },{
    days: 'Saturday',
    opening: '8:00am',
    closing: '5:00pm',
    closed: false
  },{
    days: 'Sunday',
    closed: true
  }],
  reviews: [{
    author: 'Simon Holmes',
    rating: 5,
    timestamp: '16 July 2013',
    reviewText: 'What a great place. I can\'t say enough good things about it.'
  },{
    author: 'Charlie Chaplin',
    rating: 3,
    timestamp: '16 June 2013',
    reviewText: 'It was okay. Coffee wasn\'t great, but the wifi was fast.'
  }]
}

(First question here, so please re-tag, suggest edits and ask for clarifications)
","['data-request', 'geospatial']",
Which currencies are used in IMF's / Worldbank's PA.NUS.FCRF forex data?,"
I need annual, historic exchange rates of currencies worldwide. The PA.NUS.FCRF seems to be a great data set for that: it's open, spans almost all countries worldwide, and for many countries it dates back to 1960. But the data is not given in, for example, CHF to US Dollar, but in local currency unit (LCU) to US Dollar. My problem is I fail in finding out which currency the LCU corresponds to. 
I'd expect that information to exist in the metadata. Unfortunately it does not seem to be systematically. For some countries, some information is available in the Metadata Country table; for other countries (mostly European) some information can be found in the Country-Series table; for most countries though, there is no information available.
How do I know which currencies the LCUs in the PA.NUS.FCRF dataset correspond to?
","['finance', 'economics', 'metadata', 'worldbank']",
Seeking globally available road data for medium-scaled maps (1:200.000),"
I am seeking open data of roads for medium scaled maps (1:200.000, 1:500.000 up to 1:1.000.000). For the whole world, at least Indonesia and Africa. 
I know I could use OSM streets and somehow generalize them. But for my purposes this would be too time-consuming. 
","['data-request', 'geospatial', 'transportation', 'africa']",
Pharmaceutical Parallel Imports,"
I am looking for a dataset with parallel imports in pharmaceutical containing countries, countries in their basket, drugs, their prices, reference prices (not necessary). Even some of these fields would do. 
",['data-request'],
Global map of soil pore water salinity?,"
I am looking for spatially continuous data on soil salinity along coastlines. My guess is that this data does not exist, but figured I'd check here in case anyone seems to know of any. I need the data for input into a process-based model of wetland function (in which salinity may be a key component).
","['data-request', 'geospatial']",
"Overview on hospitals and medical services - in America, Asia, Africa and Europe","
I am looking for a overview on hospitals and medical services provided by the public (and also by the private) healthcare sector in Europe, Asia America and Australia.
public hospitals
private hospitals and medical clinics ...

I am looking for all the European Countries.
Requirements for each item:
name
address
postal code
town
street
website
(and email address)

Note: I know that I can approach with an OpenStreetMap attempt - but if there are some datasets & or sites that we can scrape & parse.
","['data-request', 'medical', 'openstreetmap']",
PETS 2006 Dataset,"
Does anybody have a copy of PETS 2006 Benchmark Data (or maybe you know, where can it be downloaded from)? Can you please share it? Their hosting seems to be down (both http and ftp. maybe, just this dataset not available anymore).
Dead links to the Dataset: http://www.cvg.reading.ac.uk/PETS2006/data.html ftp://ftp.cs.rdg.ac.uk/pub/PETS2006/
Update:
Shared the database, will keep it available as of now: https://drive.google.com/drive/folders/1F3xAgdcmCZNEWpJY_HQkWcQneWvMg7xo
","['machine-learning', 'database']","These sites are working for me:ftp://ftp.cs.rdg.ac.uk/pub/PETS2006/ftp://ftp.cs.rdg.ac.uk/pub/groups/cvg/PETS2006/Not working:http://ftp.cs.rdg.ac.uk/PETS2006/So you'd have to replace the links in the documentation page with one of the two working sites above, or just manually download the specific files.From the documentation page:The scenarios can also be downloaded from ftp://ftp.cs.rdg.ac.uk/pub/PETS2006/ (use anonymous login). Warning: ftp://ftp.pets.rdg.ac.uk is not listing files correctly on some ftp clients. If you experience problems you can connect to the http server at http://ftp.cs.rdg.ac.uk/PETS2006/."
API to use Klink-2 Computer Science Ontology (CSO),"
I came across this interesting paper that make use of the Klink-2 Computer Science Ontology (CSO):
Automatic Classification of Springer Nature Proceedings with Smart Topic Miner
Where can I find an API or something like that to access this ontology. In the paper they have mentioned that it uses the Klink data model available at:
http://technologies.kmi.open.ac.uk/rexplore/ontologies/BiboExtension.owl
But, that page does not provide any supporting details, as if how to use it.
Please help me to access this Klink-2 Computer Science Ontology (CSO).
","['data-request', 'api', 'linked-data', 'rdf', 'ontology']","It is unlikely that the entire Klink-2 Computer Science Ontology is openly available online.The authors decide to monetize their research creating Rexplore.
It seems that the generated CSO ontology is a very substantil part of the project.The demo of Rexplore is available here. Following instructions, one can generate topic trees for different series of Springer proceedings. However, the ""Download tree"" button is not working.However, a sample of the ontology is available.The paper you have linked to references to another paper, which contains this link.The content of the ZIP archive shows how OWL ontologies looks like.
However, those example ontologies (or rather taxonomies) covers Semantic Web topics only.As for API for ontologies.If an ontology is serialized into RDF, then you can make queries with SPARQL.
Languages for querying on more abstract level are DL Query and SQWRL.
There even exists the so-called OWL API.But first, just open an ontology in Protégé.Update 1The 2012 ACM Computing Classification System has been developed as a
poly-hierarchical ontology that can be utilized in semantic web
applications. It replaces the traditional 1998 version of the ACM
Computing Classification System (CCS), which has served as the de
facto standard classification system for the computing field.The full CCS classification tree is freely available for educational
and research purposes in these downloadable formats: SKOS (xml), Word,
and HTML.SourceUpdate 2The Knowledge Media Institute (KMi) of The Open University and Springer Nature are happy to announce the release of The Computer Science Ontology (CSO).CSO is a large-scale, automatically generated ontology of research areas in the field of Computer Science. The current version of CSO incorporates 14K topics and over 143K relationships extracted by applying the Klink-2 algorithm on a dataset of about 16M scientific articles.Source"
Open datasets on homeschool students vs traditional students,"
I'm doing a project for my stats class. I need to do 5 hypothesis tests with the same dataset: testing means, testing medians, testing standard deviations (or variances), testing proportions, testing for associations with categorical data, and linear regression.
If you have any other suggestions as to a different/easier dataset to use that'd be great too.
","['data-request', 'research']",
Cadastral data of Spain and Italy,"
I'm looking for cadastral geodata of Italy and Spain, especially for agricultural areas, countrywide. I found files for other European countries like the Czech Republic, Austria and France, but I can't find anything for Spain and Italy.
(For spain, I found a downloader for Qgis, but it contains every cadastral object, including buildings etc.). 
It does not matter if these files are WFS oder Esrishapes.
Note: I don't speak Spanish or Italian. 
",['geospatial'],
Using a publicly accessible research database for Development Data Library (DDL) submissions,"
I understand that in some cases if the dataset (that we're submitting to USAID) is maintained on a publicly accessible research database, then DDL submission is not required. Does this publically accessible database have to be approved first? Are there any other rules for doing it this way?
",['usaidopen'],
Polygonal Shapefiles for US Colleges/Universities,"
where can I find a shape file for college and universities that includes their POLYGONS rather than a POINT/lat long for the US? I'm currently using tl_2015_01_arealm however it only contains 2,972 universities. I noticed this post
Shape files for Colleges/Universities?
suggests 
https://hifld-dhs-gii.opendata.arcgis.com/datasets/4061dcd767c340d4a42fb7a0c6c5d5b4_0
and I've used 
https://www.sciencebase.gov/catalog/item/4f4e4acee4b07f02db67fb39
however both links above include the schools location/point rather than it's actual polygon. I'd greatly appreciate any help
","['data-request', 'usa', 'geospatial']",
Searching for a dataset about chess ELO rating distribution broken down by gender,"
A friend and I had a friendly argument recently about the origin of the apparent gender gap in chess ratings, wherein the grandmaster list is dominated by males, and the best male player today is far better than the best female player. My suspicion is that this is an issue of sample size rather than any real difference: since there are so many more male players to choose from, the pool of male players will sample the tail of the distribution more often and be more likely to contain someone with a very high rating. Or in stats term, the expectation value of the maximum value of N samples randomly drawn from a distribution will grow with N. 
Most of the articles I have read on the subject don't even consider this effect. They just say ""We looked at the top 50 men and top 50 women and found that the men were better"" or something along those lines, which would be exactly what you would expect to see if the distribution of chess ratings was gender-independent but the male pool had a larger sample size.
I've been poking around Kaggle trying to find a data set containing chess ratings and genders, but so far no luck. Does anyone have any idea where I could find a dataset with which to test my theory? I think it would be enough to have a list of chess players with a rating over some high value (2000, say?) broken down by gender. 
","['data-request', 'sports', 'demographics', 'games']","FIDE rating lists are available to download on this page.
The standard rating list contains both rating and sex information.Your hypothesis is interesting, but it seems not very easy to test it, because FIDE Elo rating distribution has many abnormalities.Here below are comparative density plots with and without filtering by K-factor:There are non-Elo rating systems and other Elo-based rating systems, e. g. USCF rating system.UpdateIt was noticed in comments that analyzing local communities makes more sense.P. S. Order of plots corresponds to this order. It seems that there is no great correlation between ""Average"" and ""Total titled""."
Yelp or similar dataset needed,"
I am writing a paper on aspect based sentiment analysis and I need appropriate datasets having only positive and negative classes to compare my result to other papers. Two of these papers that have used the yelp dataset:
Deep Convolutional Neural Network based Approach for Aspect-based Sentiment Analysis
Aspect Based Sentiment Analysis for Online Reviews
If possible I would like to have access to the datasets they have used, does anyone have them?
",['data-request'],
Unique identifiers of US companies as a means of tracking change,"
I'm a brand new business analyst for a company that currently maintains its second-hand customer list (given by medical distributors, consisting mostly of hospitals, doctor's offices and smaller distributors) in Excel, by hand, line-at-a-time, 70+ thousand entries. If this wasn't enough of a headache, they're basically using Google to catch changes in things like parent company/child company information, medical specialties, mergers & acquisitions, name changes, etc, etc. 
A large part of the problem is that these entities don't have a UID for easy tracking across changes. To that end, I've started trying to cobble together a webconnector to grab HIPAA NPI statistics, using the NPI as a UID and taking weekly updates from the HIPAA website for company updates. It's not perfect, but it's a start. I've spent a couple hours today looking at public API resources for company EINs via the SEC's EDGAR, but I don't seem to be getting very far. 
Does anyone else have any ideas on open resources to keep a customer list updated via automation so I can go back to, y'know, analyzing stuff? 
","['data-request', 'api', 'government', 'medical']",
WikiData - Specific country with flag and emojiflag by item ID,"
I need to query the WikiData to get for an specific country code (that I've, for the example is Q414 (ARG), the flag and the emoji flag respective. The emoji, by I know, is on zxx lang, but anyway any of my solutions worked. Any help will be preciated.
SELECT ?label ?nombre_corto ?imagen_de_la_bandera WHERE {
  wd:Q414 rdfs:label ?label.
  OPTIONAL { ?label wdt:P1813 ?nombre_corto. }
  FILTER(LANGMATCHES(LANG(?label), ""es""))
    FILTER(LANGMATCHES(LANG(?nombre_corto), ""zxx""))
  OPTIONAL { ?label wdt:P41 ?imagen_de_la_bandera. }
}
LIMIT 100

",['wikidata'],"Assuming that countries are entities with ISO 3166-1 alpha-3 codes, your query should be:Try it! (257 results)The main problem of the original query is probably a mistype: you use ?label instead of wd:Q414 in two places. By the way, values of ?label are literals, which cannot be subjects of RDF triples.The SPARQL 1.1 VALUES keyword allows to not repeat oneself and to avoid such mistypes.There are minor remaining problems, which manifest themselves as duplicated country codes.The first problem is that not only emojies can be used as short names with no linguistic content, consider wd:Q159 as an example.
In order to filter out that ""РОФ"", your query should address qualifiers on P1813-statements:Try it! (256 results)Other problems are related to Wikidata data quality.The second problem is exact duplicates, e. g. wd:Q9648 and wd:Q1249802.
The problem could be fixed in the same way as the next one.The third problem is that ISO codes are applied both to a part and to a whole: compare wd:Q35 and wd:Q756617; wd:Q55 and wd:Q29999.
One can get rid of such duplicates using GROUP and SAMPLE:Try it! (250 results)"
mimic iii: could a pretrained word2vec be made available?,"
Why reinvent the wheel? or would this be some sort of a breach since it would then be available to those who have not taken the ethics course?
","['mimic-iii', 'nlp', 'legal']",
Data set having menu items (food) and corresponding image?,"
I am working on identifying menu item names for food from their images. Is there any public/private (that I can buy) data set available for supervised learning?
I have this data set, but I'm looking for a larger one.
","['machine-learning', 'images', 'food']",
Soccer league and team hierarchical metadata,"
I'm looking for hierarchical metadata for soccer leagues and teams. I'm looking for any region or country (although Switzerland would be the first choice). There are many league or association website, but they don't have structured or machine readable data - and hence no real data model. So key is that the data is structured and machine readable (Wikidata like). No preference for API or database or files. 
The hierarchy would be something like this:
Country/Region > Gender/Age group > League > Team > Team Details

If no structured and machine readable data exists for soccer, I'll accept for other sports.
","['data-request', 'sports', 'ontology']","Schema.org has some decent categories, split between ""Sports Organization"" and ""Sports Team"". Also useful is ""Sports Vocabulary"" (PDF).Another Q/A here, as a reference: Schema.org - Correct way to set up a football (soccer) club with multiple teams"
Seeking shapefile of forest cover in Paraguay?,"
I am looking for a shapefile of the remaining forest cover in Paraguay. I am struggling to find an up to date file. Is there anywhere that has this information open access?
","['environment', 'geospatial', 'south-america']",
Enron data set: Get labels whether an email has been replied or forwarded,"
I am currently browsing through the Enron data set in order to come up with a way to extract labels (true/false) on whether an email has been forwarded or replied to. The task would be to predict whether an email is going to get replied or forwarded (per user).
It appears that this information is not available in the data set so what I want to do it try and post-label the respective emails. 
However, as I manually browse some of the folders I am not sure if this data set is actually suitable for what I am trying to do here. I do not know whether the data set actually contains conversation (or parts of conversations) which I can actually reconstruct in order to determine replied and/or forwarded messages.
Does anybody have some experience with this data set or is there another that somebody could recommend me for the task I described?
","['nlp', 'email']",
Mapping between UK SIC and US NAICS industry sector classification; other countries?,"
I am analyzing UK government company registry (CompaniesHouse) data. In UK you have SIC (Standard Industrial Classification) codes that help define what industry sector a company operates in. I am aware of North American Industry Classification System (NAICS) that seems to operate similarly. Is there any mapping between the two? What do other countries do? 
","['classification', 'industry']","Is there any mapping between the two?There exist miscellaneous services, e. g. this one.
However, I guess you are looking for a whole dataset, according to the scope of this site.On this page, I have found the following links:2002 NAICS to 1987 SIC1987 SIC to 2002 NAICSThe page also contains mappings between different versions of NAICS. Thus, one could construct mappings between SIC 1987 and recent versions of NAICS.See also:What do other countries do?"
Seeking Irish PostAim (151) AnPost boundaries?,"
I’m trying to source a shapefile or equivalent for the postal (sorting offices) in Ireland. The boundaries are used in the SortIt AnPost online tool to sort mail but I can’t seem to find them for download anywhere and AnPost are not replying to my emails. Can anyone help?
","['geospatial', 'ireland']",
Pairs of images before and after retouch/alteration,"
I'm looking for a corpus containing pairs of images before and after retouch/alteration.
Example of pair:
Before:

After:

I am aware of:

https://www.reddit.com/r/PhotoshopRequest/
http://zhopped.com/

","['data-request', 'images']",
Sudan Shapefiles (2008),"
Does anyone know if the shapefiles for Sudan, which correspond to the 2008 census enumeration areas are available for download?
","['census', 'geospatial']",
I am looking for an API that can provide all medicines that are sold in Pakistan. I have seen that chemists have a such kind of database?,"
I am looking for an API that can provide all the medicines that are sold in Pakistan. I have seen that chemists have a such kind of database. What are some pointers? 
","['api', 'sql']",
From when can I get a dataset of tagged images? [duplicate],"







This question already has answers here:
                                
                            




Alternatives to ImageNet

                                (2 answers)
                            

Closed 5 years ago.



I am looking for an open dataset of tagged images. The number of distinct tags must be in the range of around ~1000 with ~50 images per tag. An image can have multiple distinct tags.
",['data-request'],
Data for Moore's Law,"
What is a good source for data relevant to studying Moore's Law in computer hardware? I am interested in both the original formulation in terms of transistor count as well as some related metrics such as RAM or clock speed. The Wikipedia article on transistor count seems somewhat incomplete and the data that they discuss seems to be spread over multiple sources. 
",['data-request'],
Audio data for sentence type classification,"
I want to build a classifier, which would be able to tell statement sentences (.) form question sentences (?) from exclamatory sentences (!).
Thus, obviously I need a bunch of such audio samples with marked sentence types. Is there any open data set of this kind or related?
","['audio', 'sentiment-analysis']","There's a audio data corpus called TIMIT. Although it is not free (you should be a member of ldc or pay) https://catalog.ldc.upenn.edu/ldc93s1, you can find free version here https://github.com/philipperemy/timit. You can find diverse sentences with punctuations and .wav file for each of them."
DNS request sample traffic,"
I am trying to find a dataset about DNS request, which is created by any group of users during a period (a week or a month...). 
For example: employers in a selected company used the internet and made some DNS requests, then there is a collector which capturing all of them.
Because what I really care is the DNS requests and their created time. Therefore, if information like source IP address or requested domain name... is missing, it is still OK.
I wonder if there is any kind of dataset now. I have tried to find but still, there is no satisfied collection.
Thanks in advance :-)
","['data-request', 'internet']",
Job Title Classification Training Data,"
One of the tasks is to map Job Titles on LinkenIn and other data sources to more commonly known job titles so we can match better (e.g. Software Developer Engineer II --> Software Developer). I realize this is a very common problem and I have seen many papers on the different algorithms and prediction models to implement, but no link to training data where titles are mapped. So my question is, is there training data already publicly available out there or do I have to manually map ~20k job titles.
Thanks in advance
","['machine-learning', 'classification']",
Job Title Classification Training Data,"
One of the tasks is to map Job Titles on LinkenIn and other data sources to more commonly known job titles so we can match better (e.g. Software Developer Engineer II --> Software Developer). I realize this is a very common problem and I have seen many papers on the different algorithms and prediction models to implement, but no link to training data where titles are mapped. So my question is, is there training data already publicly available out there or do I have to manually map ~20k job titles. 
Thanks in advance
","['machine-learning', 'classification']",
"Books with multiple main characters, one per chapter","
I am looking for public domain, or creative commons fiction,
with:

multiple main characters,
written in 3rd person
Each chapter focuses on a particular character

Modern examples of such books include George R.R Martin's a ""Song of Ice and Fire"" series.
This is related to my request from a few years ago:
Novels with chapters annotated POV
However now I am not looking for annotated books, just so long as they have multiple characters.
So far I have found on Project Gutenberg:

Charles Dicken's ""A tale of two cities""
Jane Austen's ""Sense and Sensibility""

On Wiki Source:

Black Colossus by Robert Ervin Howard

I've yet to uncover a way to search project Gutenberg or Wiki-Source based on these requirements.
","['data-request', 'english', 'corpora', 'books']",
"Railways, trains and timetable data","
I have a school project in which I am supposed to analyse how much trains are late at different rail stations. I can create an artificial database for this purpose. However I would really like to use a real data for this project. Where can I find the data in which train courses, timetables, arrival and departure times (and anything else that is involved) is present. The country is unimportant.
EDIT: I am not interested in a website or a system to which I will have to do web scraping. My question is about a database which can be used directly.
","['data-request', 'transportation']","The Swiss Open Transport Data platform has ""Ist"" (actual) data as a big CSV file, split into individual days.https://opentransportdata.swiss/en/dataset/istdatenFor one particular dayhttps://opentransportdata.swiss/en/dataset/istdaten/resource/72d1b1cc-349f-420b-a692-f12c72841607each file is about 200 MB as uncompressed CSV.You will probably need to use the fieldsAN_PROGNOSE = to forecast (schedule)ANKUNFTSZEIT = arrival timeAB_PROGNOSE = from forecast (schedule)ABFAHRTZEIT = departure timeHere's a limited list of applications using the data, you might find some code on Github that saves you some time parsing the filehttps://opentransportdata.swiss/en/showcase-2/"
Where can I find Hebrew and Greek Bible texts interlined with Strong's numbers in plain text or JSON format?,"
Example in Hebrew:
Gen 1:1  בראשׁיתH7225 בראH1254 אלהיםH430 אתH853 השׁמיםH8064 ואתH853 הארץ׃H776 

Example in Greek:
Mat 1:1  βιβλοςG976 γενεσεωςG1078 ιησουG2424 χριστουG5547 υιουG5207 δαβιδG1138 υιουG5207 αβρααμG11

","['data-request', 'research', 'json', 'religion', 'txt']",
Hourly dataset of last 30 days of Bitcoin marketcaps [duplicate],"







This question already has answers here:
                                
                            




Total cryptocurrency market cap over time

                                (3 answers)
                            

Closed 5 years ago.



I have got the days wise data from the https://coinmarketcap.com/currencies/bitcoin/historical-data/?start=20171228&end=20180127 
But for my algorithm, I am in need of the hourly dataset of the coinmarketcaps like historic data. I mean, I need the dataset in the form of the following:  
Date    Open    High    Low Close   Volume  Market Cap

But the dataset should be hourly.  
Kindly, let me know where I can find such dataset.
",['data-request'],
Where can I find (free) historical tick-by-tick data for crypto currencies?,"
I have found out how to get historical price data from the cryptocompare API but the highest resolution is on a minute-base. Is there a (free) way to get historical tick-by-tick data (so on a second-resolution) for cryptocurrencies, ideally with a python API. I would like to train and backtest a model on that data. I can imagine that the high bandwith requirements of pulling so much data may be too much asked for a free API but maybe there is one...
Edit: I repeat, I am looking for free tick-by-tick (with a second-based timeframe) data. The question 
 Cryptocurrency historical prices is not explicitly asking for this kind of data, and the only answer for tick-by-tick data regards to a paid service.
","['data-request', 'api']",
Groundwater Levels for UK,"
I'm trying to find some open source data for groundwater levels measured from boreholes. The ideal geographic span would be the UK but if it was only England that wouldn't be such a big loss. 
I've found this government resource for England but the first link directs me to a paid datasource and the second link indicates it is no longer available.
Does anyone have a suggestion as to finding an alternative source of data?
The format of the data would ideally be .shp / WMS or something workable within GIS.
",['geospatial'],
Global country based raster,"
I am looking for a raster in WGS84 where all the countries in the world are available. 
This raster, in principle, should change the resolution of the pixel at the equator or the poles. The resolution should change as the earth is not planar. 
What I am trying to do is multiply a raster that I have with 1) all the protected areas in the world, 2) where other protected areas should be. By multiplying these rasters I intend to obtain the area per country.
","['geospatial', 'images', 'global']",
Where is DMOZ data available now?,"
I learned from wikipedia that DMOZ is no longer maintained. Where can I get the earlier DMOZ site directory data? or is there a similar data source?
Thank you so much.
Edit:
I found something here, seems like it's valid.
",['data-request'],
Alternative tool to view ImageNet images apart from the image-net.org website?,"
Are there any alternative tool/website to view ImageNet images apart from the image-net.org website? I experience a very slow response from the http://image-net.org website.
I would like to have a tool that quickly show example images, WordNet words, description and hierarchy from ImageNet wrt. to the identifier such as ""n03297495"".
(Incidentally, the WordNet server for WordNet URIs seems also to have issues at the moment. For instance, looking up http://wordnet-rdf.princeton.edu/wn30/03297495-n does not yield relevant information)
","['images', 'imagenet', 'wordnet']",
"There are a ""frictionless access"" recomendarion for Web page requests?","
Transparency is ""free access"", frictionless. Even publishing in the Web, with no password required, we can imagine a gradation of  frictionless. This access problem was posted at AskUbuntu: 

With usual .gov pages (URLs) with full-free access, we can do wget URL or curl -O URL  to download the page. Is a real ""access without barriers"".
With some other pages (eg. this one), with the same  ""free access needs"", the behaviour is different, and we can't download.

There are a RFC (or W3C recommendation, or similar) suggesting or classifying whats is ""HTTP frictionless access""?

PS: I need a standard that describes all the shades of gray between the ""100% free and frictionless""  and the ""non-free access""... or something defining a kind of ""best practices for frictionless HTTP request/response"".
",['classification'],
Payment terms data in international trade is needed,"
There are payment terms in international trade when an import or export is made. Advance Payment, Letter of Credit, Acceptance, Cash Against Documents etc are the types of the payments. 
I can't find a global data or data for some countries regarding payment terms statistics. 
",['trade'],
Worldwide sunrise and sunset time data,"
Looking for a database or free API with the expected sunrise and sunset times around the world (sunrise is more important). Ideally the data should be up-to-date, reflecting daily changes in weather in any given area. 
Good example would be http://www.weatherbase.com, but their API has to be licensed.
","['data-request', 'api', 'weather']",
A list of the organizations accredited to run projects under European Voluntary Service,"
I need a list of the organizations accredited to run projects under European Voluntary Service. 
See: http://europa.eu/youth/volunteering/evs-organisation_en
EVS accredited organisations search results: 6073
See also https://europa.eu/youth/volunteering_en
This lists the organisations accredited to run projects under European Voluntary Service - part of the European Union's Erasmus+ programme. We recommend that you first use the database of volunteering projects to find  projects that you might be interested in. 
How to get the list of the accredited EVS organisation, that run volunteering projects?
","['data-request', 'companies', 'database']",
"2017 Healthcare Data on Primary Care Service Areas, Availability of Primary Care Providers","
I will start by saying I am interested in answering a few specific questions namely:

Number of Primary Care Providers per 10,000 persons
Percentage of areas with Low Primary Care Physician Supply (Low being defined as <= 3,500 residents per doctor).
Number of Federally Qualified Health Center sites per 10,000 persons
Number of FQHC sites per square land mile

I found this interesting dataset which divides the United States into Primary Care Service areas (PCSA) which was designed to provide more accurate mapping procedures to illustrate how groups or populations of people made use of medical resources.
https://datawarehouse.hrsa.gov/data/datadownload/pcsa2010Download.aspx
The following download files contain the relevant information I need to answer my questions.

PCSA v3.1 Layer Attributes (File 1)
PCSA v3.1 Layer Attributes (File 2)
HRSA National Primary Care Physician Inventory Data

Unfortunately, this data is a bit old since as it's from 2010. I was curious if anyone knew of any updated datasets using this unique Primary Care Service Area designation.
Alternatively, does anyone know of a dataset which could answer my questions at some different geographic level? Ideally it would be at least the county level.
","['data-request', 'geospatial', 'medical']",
Seeking source of curated/cleansed data for 2016 Canadian Census?,"
I am working with open data sources and the 2016 Canadian Census is of great interest to me. The Canadian Statistics website provides boundary files, which work great, and some aggregated census data, which doesn't work so great.
The problem I'm having with the aggregated census data is that the data is too 'long' and 'narrow' e.g.

whereas my work requires the data to be 'shorter' and 'wider'
 e.g.

Does anyone know of a person or organisation that has solved this issue and made the data publicly available?
","['data-request', 'data-format', 'census', 'data-portal', 'canada']",
How to differentiate between city and non-city in city databases?,"
I am trying to find a population database of cities of whole world, no towns, no villages, only cities. I tried various data sources discussed here including following  Database of cities with coordinates and timezone 
List of every city and town in the world? 
Dataset of World Cities, Counties, Localities, Provinces, and States? But every city database has one issue. It does not differentiate between a city and a non-city (town, village). When i asked this question to support staff of these data sources, they mentioned that there is no way to distinguish between a city and a town. Is there really no way to differentiate between a city and town and a village and all are considered just populated places? 
","['geospatial', 'city']","Criteria of distinction between towns and cities are different from country to country and from time to time. In many places, there is no official distinction  between towns and cities. According to the common Open Street Map convention, city has population of 100 000 or more. There are many  local OSM norms, exceptions and holywars though…If you agree to rely on the OSM data, you could try to use Overpass API:The above query returns 8869 results. Please note that id is not persistent.Or you could try this query on Wikidata:The number of results is ~ 25 000."
Household data with earnings by each spouse and household spendings,"
I am looking for an open dataset on households where earnings by each spouse would be recorded (together with the gender variable) and that would also contain some variables on various household spendings.  
","['data-request', 'research']",
How to download Kiplingers best values in colleges,"
How can I download the data from https://www.kiplinger.com/tool/college/T014-S001-kiplinger-s-best-values-in-public-colleges/index.php ?
",['download'],
Multivariate numeric dataset for clustering,"
I am searching for a multivariate dataset consisting of vectors (no time series) for clustering experiments. It should have about 8-20 numeric features (non-numeric would have to be ignored by me) and about 100-500 instances. Having some labels additionally might be useful, but is not required.
","['data-request', 'machine-learning']",
Get list of all villages/towns in India,"
This might have been asked before but I couldn't get a similar question.
I am working on an application which will have addresses in India populated using dropdowns till 4 levels. 
State => District => Tahsil/Municpality(based on rural/urban) => Village/Ward(based on rural/urban).

Where can I get this data with full hierarchy? I checked few places but couldn't get all the data as a single file or in a few files. I got a list of villages from here but this will give out 35 files for 35 states and it doesn't have Urban wards. 
","['csv', 'census', 'address', 'india']",
Good sources for Data-sets for word problems of Calculus,"
I am currently working on a project involving solving word problems of Calculus through Natural Language Processing, AI algorithm. I tried to find a data-set for word problems of Calculus but could not find it. So can anyone please suggest some good sources for word problems of Calculus suited for NLP.
","['machine-learning', 'nlp']",
Chicago Electoral Precincts before 2011,"
Are there any sources for GIS data about Chicago electoral precincts before 2011. I have FOIAed the Chicago Board of Elections, and they say they don't have any shapefiles from before 2011.
",['data-request'],
Male/female recognition by voice,"
I'm going to train my neural network in recognizing if a person is male or female from audio speech samples.
  Unfortunately the only datasets I could find, were dedicated for natural language processing.  
Does anyone know where to find wav files labeled with this kind of information (male or female)? I'm interested in rather short samples of a person's voice (from 1s to 20s).
","['data-request', 'machine-learning', 'audio']","Mozilla just released the Common Voice datasethttps://voice.mozilla.org/en/datasetsEach entry in the dataset consists of a unique MP3 and corresponding text file. Many of the 1,368 recorded hours in the dataset also include demographic metadata like age, sex, and accent that can help train the accuracy of speech recognition engines.License is CC-0(HackerNews thread)"
"I'm trying to get a KML file for the Lorton CDP (Lorton, VA)","
I suspect that this information is available at the Census Bureau. It seems like something they ought to have. I spent some amount of time there, but can't locate exactly where they keep it.
I found this page: https://www.census.gov/geo/maps-data/data/kml/kml_tracts.html
But when I download the data for VA there's no mention of Lorton in it. Nor can I find any code associated with Lorton.
This is just one example. I want to know how to get KMLs in general for different areas. So a general solution would be preferable to a specific answer to this question.
","['us-census', 'kml']","Solution: I needed to look in the correct area of the census site. I went to the page:https://www.census.gov/geo/maps-data/data/kml/kml_place.htmland selected Virginia to download the place zip file for this state.I opened the zip file and brought the first kml (the largest one, titled ""cb_2016_51_place_500k.kml"") into a text editor. I then searched for ""Lorton"" and copied that entire <Placemark> ... </Placemark> section into a separate file I called ""lorton.kml""I then went to google ""my maps"" and created a test map and loaded the kml into a layer to confirm it works:https://drive.google.com/open?id=1wK6uhZJz1jKoaGqJ8lVd9Ph0GLFiq0R5&usp=sharingEdit: Two more solutions:
1) Open KML in Google Earth and search through each layer, unselected all that are not what you desire, and save.
2) Opening KML in QGIS does not give you write options, so I saved it as GeoJSON, the opened the GeoJSON file. From there, toggle edit options, then open up attributes table. Each CDP is a row, so I selected all but the desired row (Lorton) and deleted them. Then saved the file as KML."
How to import a SAS layout or Data Dictionary,"
Being totally new to SAS, I don't know how to import this layout/dictionary file into SAS® Studio:
       *********************************************
       *                                           *
       *           A T T E N T I O N               *
       *                                           *
       *   THESE POS RECORD SPECIFICATIONS WERE    *
       *   PRODUCED FROM OUR DICTIONARY AT THE     *
       *   SAME TIME AS THE POS DATA FILE THAT     *
       *   YOU REQUESTED. YOU MAY WISH TO CHECK    *
       *   THESE SPECIFICATIONS TO SEE IF ANY      *
       *   CHANGES HAVE OCCURED SINCE YOUR RECEIPT *
       *   OF ANY PRIOR DOCUMENTATION.             *
       *                                           *
       *   FILE CREATION DATE = 01/02/2018         *
       *                                           *
       *********************************************
 DATE: 01/02/2018              POS RECORD LAYOUT                      PAGE: 1
                 Hospital, CATEGORY = ""01"" (SEE POSITIONS 3-4)

   SHORT DESCRIPTION                                LEN  START END    TYPE

   Provider Category Subtype Code                    2    1     2    VARCHAR2
     Description: Identifies the subtype of the provider, within the
                  primary category.  Used in reporting to show the
                  breakdown of provider categories, mainly for hospitals
                  and SNFs.
     SAS Name:    PRVDR_CTGRY_SBTYP_CD
     COBOL Name:  PRVDR-CTGRY-SBTYP-CD
     VALUES:      01=Short Term
                  02=Long Term
                  ....

I got this file from cms.gov and I want to convert/export the data inside this text file into a MySQL database but first how can I import this into SAS Studio (ex. SAS University Edition)?
I was expecting that the provided data dictionary text file can be easily opened/imported into a SAS software but it seems not an easy task accoring to this reply from a communities.sas.com user.
I have no knowledge at all in SAS and I am not willing to learn it as this is just a one time import/conversion. All what I want to know (from SAS oriented users) is how they convert this kind of dictionary data into something that can be exported to work with in my PHP/MySQL world.
I tried to parse the txt file in PHP and extract the different columns for each table (18 tables) but still have some issue since the file format is not consistent.
The data I want to extract is explained in my stackoverflow.com question 

","['government', 'medical', 'conversion']",
Jobs opening for data scientist,"
Is there data regarding the number of job openings for data scientist/ data engineers and so on? 
","['data-request', 'time-series']",
Bahamas Digital Elevation Model,"
Does anyone know where I can find a digital elevation model for the Bahamas? North Bimini specifically? I'm looking to model the topography in ArcGIS.
",['geospatial'],
Is there a database for empirical/statistical probabilities?,"
I am trying to explain some estimates of mine to non-academics. So I have statements like ""The probability of event X happening is 75%"".
If they don't understand probabilities, then I would like to use examples/analogies to convey the meaning. For example, ""the probability of event X happening is 75%, which is as likely as the home football team winning the match"".
So is there a database where I can search for examples of events, where I enter a probability - say 80% - and it gives me events that occur with 80% probability? Or any website that does this?
I imagine insurance companies have something like this but hopefully you know of something freely available.. Thanks.
",['data-request'],
Russian text normalization dataset,"
I want to train a model for converting written expressions into spoken forms in Russian. I have come across the kaggle dataset
https://www.kaggle.com/c/text-normalization-challenge-russian-language,
but it has a lot of errors. (And they are not random noise; they are systematic errors, because the set was marked up by an algorithm, not by people.)
Are there any other datasets for Russian text normalization?
","['text', 'russia']",
Clinical dataset for machine learning,"
I want to experiment with Bayesian networks, as well as try other machine learning approaches for learning dependancies in the data.
Is there any clinical dataset (containing results of various medical tests like blood pressure, cholesterol, maybe some diagnoses of medical conditions) with around 500-1000 attributes, and at least 500 instances?
I checked the UCI machine learning repository and found nothing satisfactory.
Or maybe there's some other dataset which could be somewhat similiar to patients' data?
","['data-request', 'medical']",
Dataset about attainment of college degree based on parent's education level?,"
I am looking for a data about the attainment of college degree (response variable) based on the parent's education and other demographics.
This kind of data is e.g. referenced in Categorical Data Analysis for the Behavioral and Social Sciences, and I remember [vague] references to it when I was in school. But I can't find any dataset.
","['education', 'collegescorecard']",
Data on present and future electricity demand profiles in the UK,"
I am looking for typical electricity demand profiles with hourly granularity for domestic, commercial, and industrial sectors in the UK in the present and, if possible, in the future.
Could you point me to relevant sources?
","['data-request', 'energy']",
OIG Diversity Data,"
I am starting a research project on diversity in the Office's of Inspector General. Where can I find such data?
For example, gender data including the number of women and men that work in OIG's? Or the number of IG's and Deputy IG's gender?
","['data-request', 'usa']",
"Agricultural crops data on field level, Europe","
I am looking for data sets describing agricultural field crop data across Europe. I have already found:

The RPG data set (France) which describes majority crops for each field.
The CEH Land Cover plus data set (Britain) which describes annual crop type.

However I am struggling to find similar datasets for other European countries (I imagine because of the language barrier). What other field level crop data are available for Europe? What resources are there for finding similar data sets in the future? 
","['data-request', 'geospatial', 'agriculture']",
Licensing of machine learning tool trained on open data,"
The broad question is: how are the licensing terms for a classifier that is 
trained with open annotated (or manually annotated) data?

I am trying to train a dependency parser for German text with annotated data which is licensed under creative commons license (Attribution CC-BY). 
To train the classifier I want to a use machine learning tool that is licensed under the Apache license. Is it legally permissible to license the 
resulting classifier (my code and the model file) under a commercial license? 
Suppose I scrape a text from the web, or alternatively I download a corpus collection that is licensed under Attribution CC-BY, and I use an annotation tool that is open source under the Apache license, and I train a classifier with an Apache machine learning software, will it legally be  permissible to license the resulting classifier under commercial terms?

","['machine-learning', 'licensing', 'corpora', 'classification']",
Name and gender dataset,"
Looking for an name/gender dataset. From first name I need to infere whether it is a male or female. There are many online service, like this, or this. I need JSON or XML, to store it locally.
",['data-request'],"My answers (one & two) on given names and country of origin also has gender guesses.The file is a little cryptic, but it's the most complete dataset that's openly available.The best source of international human given (first) names comes from a German computer magazine. The text file has nearly 50k names that are classified by likely gender, and how popular in each country. It's carefully curated and has a friendly license (GNU Free Documentation License).The file can be downloaded here : ftp://ftp.heise.de/pub/ct/listings/0717-182.zip (name_dict.txt contains the data).Depending on which programming language you are using, there are libraries either built on this dataset or on others.See, for example, gender-guesser, a python library (github) based on the above file (formerly called ""sex machine"").You can also specify country:That codes doesn't give JSON/XML, but it parses the raw .txt file from above into a python object. Probably you can hack detector.py to give you all names as JSON.This is just one port of the raw data. I'm sure there are others."
Find geographic data on the languages spoken in Russia,"
Does anyone have any ideas for where I can get data on the number or percentage of speakers of a given language in the Russian Federation at some geographic level smaller than federal subject?
Preferably, the data should come from the 2010 census.
","['language', 'census', 'russia']",
Federal year 2017 USAID budget,"
I would like to know the 2017 budget for the US Economic Support and Development Fund, Global Health Programs, Transition Initiatives, International Disaster Assistance, and USAID operational accounts.
",['usaidopen'],
Breeding bird survey: meaning of RPID variable?,"
I am exploring the open data set on breeding birds, from the North American Breeding Bird Survey (BBS). The data is orgainzed in multiple files, including raw count data and information on survey protocols. The protocols say that each BBS route is run once each year, but the file RunProtocolID.txt includes ""run protocol ID"" (RPID) codes that seem to indicate that a given route can be censused multiple times (replicates) in a given year. For example, these lines from the file:
RPID RunProtocol_English                                RunProtocolDesc
101  Standard BBS                                       3-min, 1 observer, single run per year                                                                                                                                                                                                                    
102  Standard BBS Replicate 1                           3-min, 1 observer (same or different person), second run in year                                                                                                                                                                                          
103  Standard BBS Replicate 2                           3-min, 1 observer (same or different person), third run in year                                                                                                                                                                                           
104  Standard BBS Replicate 3                           3-min, 1 observer (same or different person), fourth run in year   

How am I to interpret the term ""Replicate""? Does it really mean that data for routes with RPID = 104 have been collected 4 times in a given year? How does this affect the species counts provided for that route in that year? Do they represent averages over all runs?
",['data.gov'],
Dataset labeled with IAB's content taxonomy categories,"
Is there any dataset labeled with IAB's content taxonomy categories?
I have some text data and I want to predict their categories based on IAB's content taxonomy.
","['machine-learning', 'classification']",
"What is ""gm / tkm"" in transportation dataset?","
I was trying to collect some data related to climate change and air quality. I came across a dataset of CO2 emissions in India. When I opened the dataset, it showed the units like gm/tkm.
Can someone shed some light on how to understand this measurement in transportation data?
",['data.gov'],
How do I find hard to find aerial photos that are not available online?,"
I am still on vacation and will not return to my work on 2nd January 2018, I do have a question about locating old Aerial Photos that I am seeking for my project. I am going to work on a lot of old not georeferenced aerial photos on my forest boundary. I have them that are on my external hard drive. If, for some reason, one or several aerial photo might be missing. I need to pull one or a few to be include my project. I am aware that USGS EarthExplorer and several other site that carry aerial photos that you can download from the internet.
My question to you is does the public or private library potential might have them on their online or in their storage ?
If the city or county offices has them, which department do they most likely have them ?
I prefer them to be free and download only. I am looking at the aerial photos that are done pre-50's.
","['photographs', 'download']",
Thailand administrative boundaries and population dataset,"
Does anyone know where I can get polygons for Thailand admin 3 level (tambon) with population data?
",['population'],
Is there a reliable source of weekly movie box office data?,"
I'm attempting to build some analyses and daatavisualisations about movie performance. How do movies compare, for example, on longevity at the box office? 
Some public sites such as BoxOfficeMojo (a part of Amazons IMDB network) have interactive pages with weekly data for many countries, but the data is inconsistent over time (in the UK some older pages only list the top 20 movies not all movies currently showing and there are occasional errors especially in the cumulative box office numbers). And, if you want weekly data you can only view it one week at a time.
Are there any sources where this type of data is available as a bulk download?
","['data-request', 'film']",
Is there a GIS layer file for the USGS Quad Boundaries in NAD27 coordinate system?,"
USGS topographic maps currently use the NAD83 coordinate system and all the layer files for the quad boundaries I can find do too. I'm wondering if there exists a nationwide GIS layer for the boundaries of the old NAD27 coordinate system that align with the neatlines for topographic maps pre-1983.
",['geospatial'],
ACS vs. CPS vs. PEP vs. Census,"
I am very new to census analysis/survey analysis so please forgive my ignorance.
I am interested in MOST data/information about the U.S.A. population. Demographic information like breakdown by age, race, sex as well as things like health-care coverage, income, poverty levels, unemployment rates, etc. I'm also interested in these things on a national, state, and substate level.
And then I'm also interested in these values on a year to year basis to see how the United States has changed.
For now I think I am mostly interested in the aggregated tables and summaries for these values not so much in the microdata. But I suppose this could change in the future especially as I grow more comfortable and learn more about how to properly analyze survey data.
To me it's very chaotic and hard to get a sense of the landscape for accessing this data as it is contained in a variety of different surveys behind a variety of different APIs and search tools.
In any case if anyone could provide any tools or suggestions for helping navigate the myriad amount of resources on the topic of the population of the United States, that'd be great. 
For now, my real question is... if I wanted to get a sense of how the U.S.A. population is changing year to year in regards to age, sex, and race, should I be using CPS (Current Population Survey) data, ACS (American Community Survey) data, Decennial census data, or PEP (Population Estimates Program) data? And then additionally, which should I be using for which geographic entities so to speak? I know this question is broad and probably will depend on the specifics, but any general guidance in this department would be helpful.
EDIT: I am interested in the totals for these populations not just the percentages if that makes sense.
","['data-request', 'api', 'us-census', 'demographics']","Geography is often a key factor in determining which dataset you'll use. Are you looking for national numbers? States? Counties? In general:If you want annual data, only need the basics (age, gender, race) then the Population Estimates Program data is the simplest to use. The data is published by state, county, and metropolitan areas, and also for large municipalities. Like all of the census datasets it's available via the American Factfinder and the census APIs, but since it's relatively small they also provide simple csv files you can download. Each sheet will provide numbers from 2010 to the latest year, and you can go back and get the previous decade in older sets of files. Right now data for all areas for 2016 is available. Data for 2017 has just been released for states but isn't available for other areas yet. The csvs are available directly from the program website:https://www.census.gov/programs-surveys/popest.htmlThe American Community Survey (ACS) is better if you need detailed socio-economic summary data beyond the basics of age, race, or gender, or if you need additional geographies - you can get states and counties but also smaller areas like census tracts and ZIP Codes. So if you need data on poverty, health insurance, unemployment, etc then this would be the source you need. For larger geographies that have more than 65k people you can get annual data, but for smaller areas the data are published as 5-year averages. Each estimate is published at a 90% confidence interval with a margin of error; in some cases you may need to use the 5-year averages even for larger areas if the margins of error for the estimates you're using are prohibitively large.It's challenging to gather and analyze ACS data on an annual basis, partly because the API and American Factfinder are designed to deliver data for one particular release at a time and not multiple years. For the 5-year averages it's only appropriate to compare sets of years that don't have overlap; 2012-2016 vs 2007-2011 would be appropriate. Some alternatives - the NHGIS https://www.nhgis.org/ provides some historical comparison tables, but is intended for doing longer-term research that covers many decades. The ACS came into existence in 2005; prior to that, detailed socio-economic data was collected in each ten-year census. The Missouri Census Data Center http://mcdc.missouri.edu/ has an ACS Trends application (in the toolbar on the right) that lets you pull together several years of ACS data. They also provide descriptive summaries of the different datasets which might be useful.We have a few tutorials that we wrote in our lab that cover the basics of navigating the American Factfinder. There's also some explanation of the different datasets and geographies. https://www.baruch.cuny.edu/confluence/display/geoportal/Census+TutorialsLastly - the CPS is typically used if you need national estimates on an annual or monthly basis, or if you need or want microdata. https://usa.ipums.org/usa/."
Sentiment classifcation - Publicly available datasets for market/trading/financial news sentiment,"
As the title suggest, I'm looking for publicly available datasets to train a classifier to distinguish bullish from non-bullish or bearish from non-bearish news.
","['classification', 'sentiment-analysis', 'finance']",
Bureau of Labor Statistics Query Geographic Profile Not Working,"
https://www.bls.gov/help/hlpforma.htm#GP
The above link is supposed to provide the formatting details for the series ID for ""geographic profiles"". The example series Id they provide is: ""GPU00200000R0328"".
However, upon trying to query for that particular series ID in the BLS data query tool:
https://beta.bls.gov/dataQuery/search
No results come up.
What gives? Is this feature to be released? Am I doing something wrong?
",['labor'],
Bureau of Labor Statistics Series ID Formats Question,"
https://www.bls.gov/help/hlpforma.htm
I know about the above site, and it's very helpful in terms of querying the BLS dataset. However, it does not seem to contain information about how to query for macro level employment characteristics like Civilian Labor Force, Unemployment Rate, etc.
For example, say I wanted the size of the unadjusted (seasonally) Civilian Labor Force for white men with less than a high school diploma (25 years & older). The series ID for this query would be: LNU01092181. But I'm not really sure how this series ID was structured and how to then intelligently query for other related fields (e.g. for women, different educational attainment, for different races, etc.)
Can someone help? Am I being dumb and missing something glaringly obvious in the Series ID format FAQ page?
",['labor'],"https://www.bls.gov/cps/#dataThis website had sort of what I was looking for.Under ""More Tools"" there is information concerning ""LN series id list"", ""LE series id list"", etc. While it doesn't break down the ""logic"" of how the series ids are created, at least it's a pretty comprehensive breakdown of all the series id and what they are."
Historical Forward Exchange rates for QAR (Saudi Riyal),"
I need data of 3-month Forward exchange rates between 5 pairs of currencies. Saudi Arabia Riyal (QAR or SAR) on one hand; and 5 currencies, USD, GBP, CHF, EUR, CNY on the other hand. I need quarterly data for period 2000-2015. I can find spot rates, but desperate to find forward rates. I can pay small amount of money, if anybody can help. Need urgently
",['data-request'],
MIMIC-III: many patients without prescription information?,"
Of the 46,520 patients listed in the PATIENTS database, 7,157 do not appear in the PRESCRIPTIONS database. About half of these are newborns (age < 1 year), but there remains about 3600 patients w/ mean age 73 (approx normally distributed) who have no medication info. 
Why is there no medication information on 8% of the patients in the database? Is this group random or are they special in some way?
",['mimic-iii'],
open access database with companies/large employers registered in a given city in US,"
Is anyone aware of an open access database with companies/large employers registered in a given city in US, specifying registration date (office opening).
","['data-request', 'usa', 'city']","The OpenCorporates data is the closest dataset that I know of. It includes the registration information for many U.S. states, but not all."
Obesity/Inactivity Data at a census tract level,"
Looking for obesity/inactivity data for adults at a census tract level for the state of California. Any good sources? Preferably in a format that can be uploaded to arcdesktop.  
","['medical', 'us-census', 'census', 'csv']",
Public International Database of Literature Works?,"
There's a question about books: (Public database of book titles?), but what I'm looking for is actually a DB of literature works, not books.
For example, ""Romeo and Juliet"" is a single literature work, but there are multiple books published with it.
So this is definitely different.
","['database', 'books', 'literature']",The best solution so far came from comments. Thanks to @StanislavKralin who suggested to use public Wikidata as a source. Here's the link to SPARQL query that can be tried: http://tinyurl.com/y6wpk5q5.
Historic Road Data,"
I would like to know if there is any data repository that can provide historic road data, starting from 1995 to 2017? The location of the data can be arbitrary, except United Kingdom. Also, I am looking for as much possible hierarchically available roads, with main focus on major road, secondary, connector etc. I have also looked on https://planet.openstreetmap.org/planet/full-history/, but the data that are provided do not fit on my requirements. 
I want to compare different street networks in different time intervals, thus the starting date must be between 1995-2000 in order to capture the slow rate of a road network's evolution. 
","['data-request', 'geospatial']",
what is the difference between drugs@fda and openfda?,"
What is the difference between (drugs@fda or drugs@fda data files) and openfda?  Is there a recommended resource to use for drug name lookup?
",['openfda'],"There are at least two key differences between drugs@FDA and openFDA. A key difference relates to how the data in each is designed to be accessed. With OpenFDA, the primary way to access the data is by using the provided APIs. Drugs@FDA, on the other hand, is an online application that one can use to search for information on FDA approved drugs. Both openFDA and drugs@FDA, however, also provide downloadable files that can be imported into one's one tool or database.Another key difference relates to the type of data each site provides. While there is considerable overlap (especially with respect to drug product labeling data), there are also major differences. openFDA currently has over 13 different datasets/APIs covering drugs, devices, and food. Drugs@FDA provides data on drugs. There is some information in drugs@FDA that is not in openFDA. For example, if you want to search for a generic drug product for an innovator drug product, then you would need to go to drugs@FDA. To get a more comprehensive sense of the differences, you may want to take a look at the human drug datasets currently provided via openFDA datasets (see https://open.fda.gov/drug/) and also take a look at the FAQS page for drugs@FDA (see https://www.fda.gov/Drugs/InformationOnDrugs/ucm075234.htm#purpose)."
"Open data about oil spills from pipelines, ideally by country","
In November 2017, the Keystone Pipeline spilled 5,000 of barrels of oil onto farmland in South Dakota. I suspect there is a correlation between the number of oil spills (say, per 1,000 kilometers of pipelines and per year) and the laxity of regulation regarding environmental pollution, so I am looking for relevant data.
Wikipedia has a list of oil spills, and that list also contains a list WorldSpills.com. However, WorldSpills.com appears to have a few issues in my browser (Google Chrome 63) and I can't find any information about where they get their data. 
Hence my question: are there any open data on oil spills from pipelines? Ideally, these data should be available for free or for a modest charge.
","['data-request', 'environment']",
Historical german rain radar data from opendata.dwd.de,"
Recently the German national weather service (DWD) published lots of data. I am especially interested in the 5 minutes radar data stored at: 
https://opendata.dwd.de/weather/radar/composit/wx/ or 
https://opendata.dwd.de/weather/radar/composit/pg/
However, this folder only contains the data for the last 2 days. Does anyone knows how to get older versions of that data? There is older data on the server but only with hourly data, but I need it in 5 (or 10) minutes resolution.
","['data-request', 'weather']",
Available open data on Portuguese Soccer League,"
Is anyone aware of open data involving the Portuguese soccer league (Primeira Liga)?
","['data-request', 'sports', 'football']",
Dataset where words are associated to colors,"
I am looking for a dataset mapping concrete words with common colors.
The only one i've found is this, but it has less than 100 entries.
EDIT: example:
red_words_list = [ ""apple"", ""blood"", ""rose"", ""strawberry"", ""cherry"" ]
green_words_list = [ ""grass"", ""tree"", ""forest"", ""clover"" ]
yellow_words_list = [ ""banana"", ""star"", ""sun"", ""desert"", ""lemon"", ""gold"" ]

It will be used to colorize lyrics using my audioleds.py script.
","['data-request', 'language']",
Looking for specific datasets with demographic data in column format,"
I'm looking for government datasets on a wide variety of topics concerning the population of the country. Things like the crime rate, unemployment rate, level of educational attainment by different segments of the population, median income, etc. I would also like this for a large range of years and also on a national, state, and county level.
I know, I know this is a crazy dataset which is very ideal, and I will probably have to cobble it together from multiple other datasets. I've already gone through the FBI API, BLS API, and Census API. They range in quality, but they are interesting and have lots of data relevant to the task at end. At some point I suspect I may also have to move on from the APIs on these sites and start doing some manually downloading of files or create some sort of scraper.
Really though, what I'd like, and what I have not encountered yet is a data format where the demographics are included in column format. What do I mean by this?
Well... when I query the BLS API, I provide a specific variable ID, say I'm looking for the unemployment rate for Male 16-19 year olds. I get my result. It will have one column for the date, one column for the variable id, and one column for the value. IDEALLY, it would be AMAZING, if it also had a ""sex"" column and an ""age"" column. It would be so amazing to have a dataset like this! Instead of having to know what the specific variable ID was, I could just filter on whatever demographics it was I wanted.
Currently, I am building this ""ideal"" dataset by hand so to speak. It's very slow going. So I'm curious if anyone here knew of datasets formatted like I am talking about. I hope this was clear.
","['data-request', 'api', 'data.gov', 'uses-of-open-data', 'data-format']",
Is there any open dataset for named entity linking?,"
Entity linking is the task of detecting mentions of entities from a knowledge base in a document.
Are there any openly available datasets to train and evaluate such systems? The datasets I came across are all closed (for instance, TAC-KBP is owned by the Linguistic Data Consortium, the YAGO-AIDA dataset requires access to the original CoNLL 2003 dataset, and so on).
The dataset should contain some text with reference annotations (for instance links to Wikipedia), and should be of reasonable size for machine learning purposes. For instance, Wikipedia dumps themselves provide this to some extent, but the wikilinks are generally not intended to be complete, so the annotations are very sparse.
","['data-request', 'nlp', 'wikidata', 'wikipedia']",
Is there a database of insect body sizes?,"
Suppose I have an insect species name (say Carabus nemoralis) would it be possible to obtain even an approximate body size for this animal? Traitbase / EOL seems to have some information, but not necessarily body size.
",['biology'],
"Yoga, Gym, Fitness API","
I have been searching for an API to get the Yoga, Gymnastic exercises details and curriculum with appropriate steps and measures. I am planning to use these details for my upcoming project.
As to my search, I have not found any links and references that fulfills my requirements.
Google and other companies are providing Fitness API, but they are confined to their application and usage. As for general purpose, they are not helping out to solve my current problem.
Also please provide links and references from where I can get complete details about Yoga and Gymnasium as well.
","['api', 'uses-of-open-data', 'medical']",
Is the CBCL FACE DATABASE available?,"
The CBCL FACE DATABASE includes 2,429 faces in the training set and is referenced on this page: http://cbcl.mit.edu/software-datasets/FaceData2.html
However, the download links for the faces.tar.gz - that I can find - yield ""not found"". For instance, http://cbcl.mit.edu/projects/cbcl/software-datasets/faces.tar.gz does not work. Neither does the link from http://www.ai.mit.edu/projects/cbcl.old/software-datasets/FaceData2.html
Is this data available for download somewhere?
",['faces'],I have found a copy of the dataset here: http://www.ai.mit.edu/courses/6.899/lectures/faces.tar.gz(27.5 MB zipped 110.3 MB unzipped)
Functional urban areas in the UK,"
I want to perform an analysis on urban areas in the UK. As, indeed, urban areas can be defined in multiple ways, I would like to rely on some well-accepted definitions and polygons.
I found this EU project that has nice data about functional urban areas in the Union, but the source data is rather old (2000). 
Then I found UK city regions, one of the many admin units in the UK, but I can't find shapefiles for them (and they look very large).
Moreover, I would like to find a point dataset with cities and towns (a gazetteer) in the UK, with population information in order to use them as labels dynamically (e.g., show cities > 1M, etc.). The OS Open Names product is way too detailed, and does not seem to contain a handy categorisation between small and large centres.
Any tips?
","['geospatial', 'uk', 'city']","For an existing area definition you might want to have a look at European statistic NUTS regions.There are different levels of granularity, as can be seen in this maps from eurostat:  Google also reveals a few random sources for the respective shapefiles (not reviewed in detail):"
Mass Distribution of common household objects around their volume,"
Where can I find a list of household objects, together with their typical shape, mass, and (if possible moment) of inertia about some axis - preferably in an SDF-like format?
Examples:

furniture: table, chair, sofa, bookshelf, bed-frame
appliances: microwave (standalone), fridge, fan, washing and drying machine
furnishings: mattress, curtain, blind

It may be possible to get info on these from separate manufacturers. I'm looking for a central source where someone has already collected this information. I'm also not particular about the exact type of objects (say queen bed, and not king bed). All that matters is correctness of the information. 
",['geospatial'],
Where can I find an academic paper that refers 50 species of trees?,"
I'm a student in a Translation Post-Graduation in Portugal.
Anyway for one of my classes we're analyzing vocabulary and I am supposed to build a database out of an academic paper, it must have from 30 to 50 terms.
For my theme I chose silviculture and for sub-theme species of trees. But I am having trouble finding a paper that refers from 30 to 50 species of trees. I must find a text from where I am supposed to build and translate the database.
Could you tell me where I can find such text? It must be a pdf. If someone has a big text for me work on I would be very happy.
Thank you so much!
Carlos Barros
",['research'],
Regression datasets for benchmarking,"
Is there a collection of regression datasets for the purpose of benchmarking? For classification I found this paper (https://arxiv.org/abs/1708.03731) which has a collection of classification datasets (some of the UCI ML Repository). Any suggestions would be helpful. 
The collection should include regression problems from different domains and should not be too easy or too hard (so that better models should get a relevant performance gain). 
",['machine-learning'],
Is it possible to get specific Asian population totals from the Census at the Block or Block Group level?,"
I know you can get it at the Tract level but I can't for the life of me find it at at a lower level. I can find totals for just ""Asian"" at these levels but I want it to be more specific than that (e.g. Chinese, Korean, Vietnamese, etc.) and specifically in California.
Is this type of information available at the block or block group level?
","['data-request', 'census']",
Are there any datasets regarding deaths due to lack of vaccination?,"
I am looking for datasets concerning the topic ""Vaccines"" so I would be interested in datasets regarding the number of deaths (for each country, and maybe region) caused by lack of vaccination and vaccination coverage.
In particular, I am interested in the European (and Italian) situation. I searched on the Eurostat website but I didn't find anything about it. Is there an updated and well done site with this information?
I hope it's the right place to ask, if not, I apologize.
","['data-request', 'medical']",
Data about writing as a hobby,"
I'm looking for information about what percentage of the population (in any Western country) write (literature) as a hobby. Either in the present day, or in historical development.
","['data-request', 'books', 'literature']",
Datasets for PDF information extraction,"
Are there any open datasets available for PDF information extraction. The documents can be insurance claims, invoice, legal contracts, rental agreements, financial reports etc.
","['data-request', 'pdf']","You can use the data.gov portal to search your target words, like ""contracts"" and then put a filter on PDF :: example queryAnother option would be to use FOIA'ed files, which may come as PDF, take a look at Muckrock.com."
Is there any international public transport data?,"
I want to create some proof of concept for an international public transport service. Is there any data or an API available that already normalizes this data across multiple countries, besides Google Maps?
","['data-request', 'transportation', 'public-transport']",TRAVIC has a list of public transport service APIs that conform to the GTFS standard: http://tracker.geops.ch/EDIT: I found a couple of more-direct links to GTFS feeds internationally:
Recent Demographic and Economic Data at CBSA-level,"
I would like to find a dataset of basic demographic and economic data at core-based statistical area level for the US. Ideally, it should include variables like population, median income, age distribution, unemployment rate from 2016 or up.
I have looked for this at Census, ACS, FRED, GitHub, various statistical packages that hit data APIs, and googled, but I have not found anything like this. I have found similar data for states in the past using some of the above.
Does this actually exist somewhere? If not, is the best way to build that by aggregating county or zip/zcta data with a cross-walk?   
","['data-request', 'usa', 'demographics', 'census']","I would like to see some ready-made sources for 2016 CBSA-level data. Until then, I suggest using county-level sources and aggregating them to CBSA-level. For this, you can combine cross-walks listed in your link or, possibly easier, use this cross-walk from Jean Roth provided at NBER. Given the excellent .csv and .dta files the aggregation should be straightforward.As for data: For the county-level, the American FactFinder provides a promising compilation. I found very detailed 2016 data on several of the topics you requested. Two examples:Comparative Economic Characteristics (Source ID CP03, ACS 1 year survey 2016) 

with, for example, the income distribution as well as mean and median income.Unemployment (Source ID S2301, ACS 1 year survey 2016)

with unemployment rates split by age group."
What is meant by aided students in College Scorecard?,"
For example: Aided students with family incomes between $48,001-$75,000 in nominal dollars  student share_middleincome.48001_75000  float   INC_PCT_M2
Is this

(a) receiving federal aid?
(b) receiving any federal or institutional aid?
(c) Pell grant recipients
(d)???

",['collegescorecard'],
Cryptocurrency historical prices,"
I'm looking for cryptocurrency historical data, including prices and market cap (either from exchanges or average price) of the main cryptocurrencies, namely: Bitcoin, Ripple, Litecoin, Ethereum, Dash.
So far I've only been able to find this source on Quandl and the historic daily price on blockchain.info 
Any additional additional sources for other cryptocurrencies and more detailed data (like hourly price or Open-High-Low-close) will be helpful.
Ideally the data should go back as far as possible but realistically data since 2012 would be enough. As for younger cryptocurrencies 1 or 2 years will suffice.
","['data-request', 'finance', 'historical']","As it turns out there are several resources one can use for all main cryptocurrencies so I will post here the most relevant and flexible I was able to gather.All CryptocurrenciesCoinmetricshttps://coinmetrics.io/data-downloads/This page has data for: Bitcoin, Litecoin, Ethereum, NEM, Decred, ZCash (transparent transactions only), Dash, Dogecoin, Ethereum Classic, PIVX, Monero.ETH -  BTCPoloniex As chartPoloniex As JSONOne needs to edit the timestamps in the API to get a different snapshot. And edit the period to adjust the details.BitcoinCoindesk Closing price and OHLCClosing price blockchain.infoBitcoin data on QuandlBitcoin data on Quandl IIEtherThanks to the answer to this question on Ethereum's stackexchangeEtherchain's APII will keep updating this answer with more links as I find them."
Pagination Type for Healthcare Finder API,"
Does anyone know the type of pagination that should be used when making a getCountiesForZip request from the HealthCare finder API?
I'm trying to use it with Qlik Sense which offers the following types found at http://help.qlik.com/en-US/connectors/Subsystems/REST_connector_help/Content/1.0/Create-REST-connection/Pagination-scenarios.htm:
Offset uses a starting value from which to read additional records. 
Next token uses a token that is passed to the URL call for the next set of records. 
Next URL uses a value that contains the URL for the next set of records. 
Custom is a special option that can be used when none of the other paging options are implemented.
",['healthcare-finder-api'],
"What are commonly used ontologies for spatial relations with terms like ""delimit""?","
Currently, on Wikidata there is an open proposal to have a projecty about delimit which is supposed to have the meaning of ""Walls of Jerusalem delimit Old City of Jerusalem"".
For good interoperability in Open Data it's very useful when different datasets use the same word to mean the same thing.
What other popular datasets have spatial relations relationships like ""delimit"" that contain prior art that might positively inform the creation of our Wikidata property?
","['geospatial', 'wikidata']","Linked Open Vocabularies at okfn is a common place for searching existing linked data terms.At 20 January 2018, the property has been created as has boundary (wd:P4777), inspiring by http://geovocab.org/geometry#boundary (see the property proposal)."
Dataset for TV commercials,"
I'm new to machine learning, and am trying to test machine learning on live TV video contents and detect the parts which are commercial ads. So I'm in need of some datasets for video contents and commercial ads for my trainingand classification purposes.
Where can I find such an ad dataset (real TV commercials)?
If you know any better ways to detect ads inside a given video, let me know. Or maybe you have a ready-to-use model, also would be great.

","['data-request', 'usa', 'machine-learning', 'media', 'classification']",
Country -> State -> County -> zipcode/city -> streets,"
Is there any database which holds data in the following fashion?
Country -> State -> County -> zipcode/city -> streets

I'm only looking for United States at the moment. 
","['data-request', 'usa', 'county']","I suspect you will need to use several data sources to get what you're after.I can suggest OpenAddresses as a good starting point. You can download address data for the US in four ZIP files, though each of these contains multiple files you will need to wrangle. That is, at the very least you'll need to remove duplicate streets and stitch together multiple files. A scripting language such as R or Python would serve you well.I should say that you might struggle to get County and/or Zip Code from these datasets as they appear patchy. Zip Code you might get from a separate source such as here. County I'm not so sure about; you could try here."
Panel Data for the membership of GATT/WTO,"
I need a panel data for the membership of GATT and WTO for all countries in the world. Do you know where to download such a file?
","['data-request', 'uses-of-open-data']",
Nesting zones in Canada,"
Looking for spatial data for bird nesting zones in Canada:

Taken from General nesting periods of migratory birds
","['geospatial', 'environment', 'biology', 'canada']",
Dataset for queries that are questions or others,"
I am looking for a dataset of queries that are posted in live chats or service providing chats. I want to test my API for tagging a query that is entered by the customer as a question or not a question. I am not able to find a suitable dataset that include some samples like:

where should I go to eat food.
Book a cab which serves food.

The first statement is a question where as second is not.These are the types of queries that a customer might use with out it being grammatically correct.
I need a dataset consisting of such data which are used in spoken English.
","['data-request', 'machine-learning', 'nlp']",
Multinational list of popular first names and surnames?,"
Is there a database containing the list of the most popular first names and surnames (with occurrence count, or at least sorted by popularity) for many nations/countries?
I need such data for the generating of sample customer database. Customers from given land should at best have the realistic names from that land.
","['data-request', 'names']",
"Missing College Scorecard data for Navy, Army, Air Force","
I'm using the College Scorecard api to pull data for various schools. It seems that data for Army, Navy, and the U.S Air Force is not available. I tried querying the API using REGIONS = 0 (U.S. Service Schools) and I also tried searching by school name, but the only data I could find was for the Marines. Will this data be available any time soon?
","['education', 'collegescorecard']","College Scorecard data are currently limited to institutions that participate in Title-IV federal financial aid programs.  As the U.S. service academies do not participate in Title-IV, the data needed for inclusion in Scorecard are unavailable."
Sources of funding to curate exisiting datasets?,"
At my institution (a large land-grant US University), there are some long term research programs that would be of great value to the scientific community if the data were curated and published in an online database or repository. 
The datasets (long term experimental studies of agricultural cropping systems) fit in the domains of agriculture, geophysics, ecology, biology.
These datasets are currently in a combination of spreadsheets and notebooks, with very heterogeneous formatting. I am thinking of a budget on the order of ~$150k per dataset, primarily to fund an 18mo postdoc.
Are there sources of funding available for such work, in which the primary output is a dataset?
Although such work could be 'built in' to hypothesis-driven grants, I am curious if there are sources of funding specifically for curation of existing data. The applications of such data could be described to justify the work (with many letters of support from end users).
","['releasing-data', 'historical']",
How/where to acquire public data on fears/phobias?,"
What's a good way to get data on what people are afraid of by geography? 
I looked into possible ways: 

Obtain search ranking of questions like 'afraid of spiders' on keywordtool 
https://keywordtool.io/search/google/14515792?keyword=afraid%20of&country=uk&language=en#suggestions
Get google trend ranking Arachnophobia

What would be the most sound method to get data on phobia?
",['data-request'],
How can i get database for all diseases and symptoms?,"
How can i get a database of all diseases, sicknesses ,ailments etc and all its associated symptoms?
","['data-request', 'medical']",
Public dataset of YouTube videos for analysis on views,"
I am planning on doing a data analysis on YouTuBe videos across multiple users. Specifically, I want to see what drives views and am looking for a public dataset or a way to collect data on YouTuBe videos. I want a dataset consists of views (video's views), video length, video age, ratings, comments, tags, categories and other factors that might affect views.
So far, I have found this data set http://netsg.cs.sfu.ca/youtubedata/ which is great for my analysis. However, the data only goes until 2008 and I would like to have a more recent set of data. Something similar would work well for my projects.
EDIT: I found this large dataset Trending YouTube Video Statistics and Comments in case anyone is interested.
",['social-media'],I found this large dataset Trending YouTube Video Statistics and Comments in case anyone is interested.
"correct way to add columns for all mlb player salaries, heights, weights since 2008 to merged MLBAM atbats_pitches table using MySQL","
I am desperately looking to add columns for salary, height, and weight to a merged MLBAM atbats and pitches table for all pitchers and batters using MySQL.
I did locate salary information from the Lahman database files and created a table from it.  But since its players comprise only a subset of those included in the merged MLBAM atbats and pitches table when I try to add a salary column (for either pitchers or batters) to the merged table from the salaries table using the following code, I'm left with a significant number of rows with NULL values for the salary column:
UPDATE `atbats_pitches_python_new` t1
INNER JOIN salaries t2 ON (t2.mlb_name = t1.mlb_name AND t2.year = t1.year AND t2.team_id = t1.team_id)
SET t1.salary=t2.salary

height and weight: I created a 'master' table from the Lahman files with height and weight columns; a table from Stattle with both height and weight columns; and the MLBAM atbats table with b_height that contain batter heights.  b_height column from the 'atbats' table does contain heights, and I am currently running the query to add that column to the merged atbats_pitches_python_new table, but after adding a weight column from both the 'master' table and then the 'players_Stattle' table to add players data unique to each of the two tables, I'm again left with many NULL values for weight.
Can someone please let me know what I should do differently with the files I have in order to include salary, height, and weight for all players in the merged atbats/pitches table and have no NULL or blank values for those three fields?  Is there another source for that information that I'm not using?  How are others handling this dilemma?
","['data-request', 'sports', 'sql']",
"Record of oil consumption, past hundred years, recent update?","
Can anyone point me toward a record of global oil consumption over the past 100 years, up to 2016 or 2017?
","['data-request', 'energy']","The U.S. Energy Information Administration has data on global oil consumption going back to 1980:https://www.eia.gov/beta/international/?src=-f4BP publishes an annual statistical review of energy that includes oil consumption. It provides a spreadsheet that goes back to 1965:https://www.bp.com/en/global/corporate/energy-economics/statistical-review-of-world-energy.htmlFor anything before that time, you'll probably have to search through old reports or books. For example, I scanned through the UN Statistical Yearbook and found production stats for oil, but not oil consumption (there was consumption data for total energy).https://unstats.un.org/unsd/publications/statistical-yearbook/past-issues/"
Tips for finding hard-to-locate data,"
Say Barry, could you use this site's ""answer your own question"" feature to give us some tips on how to find data that may not be readily available? 
","['data-request', 'metadata']",
Invasive Plant Species Data,"
Where can I find invasive plant species data? I'm looking for GIS point data with the locations of the invasive plant species specifically. Not limited to one particular area or invasive plant species, just looking for a hub or good website to search for invasive plant species data.
","['geospatial', 'environment']",
Social network dataset with features,"
For a university project, I need a social network dataset, preferably from Facebook. The problem is that there are many data sets on the Internet, but all I've found contain information only about which users are friends. What I need is relationships + basic info about the user (age, gender etc.). Is this kind of information available? If so, where I can find them?
","['data-request', 'social-media']",
Mid-19th Century to Early-20th Century Mumbai/Bombay Population Data(sets),"
I am an undergraduate student studying Geographic Information Systems. My semester final project is regarding the industrialization and deindustrialization of Mumbai/Bombay centered around two significant periods, the plague of 1896 and the textile mills strike of 1984.
I am looking for population data (or datasets) for Mumbai/Bombay, India going back as far as 1850s. So far, the earliest readily available population data I can find is 1991. I've datamined a bit and found population data within early 20th century publications, but all provide different numbers. I understand that population estimations for Mumbai/Bombay will vary greatly for this time period depending on the source; however, it would help tremendously if I could find a trusted source that stretches back to at least mid-19th century.
","['research', 'historical', 'demographics', 'india']",
Department of Labor Jobs API Descriptions Not Available,"
We are accessing the jobs available through the DoL for publication on our website. However, the Descriptions are not available. See  
https://api.usa.gov/jobs/search.json?KEY=XXX&PostingStartDate=11/21/2017&PostingEndDate=11/30/2017

How do we access the Descriptions? 
","['data-request', 'api', 'labor']",
Dataset for segmenting multivariate time series,"
I am doing a project on segmenting a multivariate time series into intervals with predominant trends. So I am looking for a multivariate time series dataset preferably biological data with high dimensionality (genes, proteins, metabolites monitored over time ) and one which can be broken down into atleast 4-5 different segments each representing some major event.  
","['data-request', 'biology']",
What is the actual record of the property's lot size in sqft?,"
I have a list of US Addresses. I am trying to find the 'lot size' of each address. is there any database I can go find this? or at least some data that gives me the average lot size by zip code?
","['data-request', 'postal-code']",
How to find information about buildings using specific addresses?,"
As indicated in the question, I am looking for all kind of information about buildings in Switzerland, preferably using an API. This could include information like whether a restaurant or a bank is located in this building or (if possible) information about when it was built.
Two possible sources I have in mind are using the Google Places API or the OSM API. However,concerning the Google API, I am a little bit concerned that the daily requests are limited. But since I don't have much experience in this area, I would very much appreciate to benefit from your experience.
","['data-request', 'geospatial', 'api', 'openfda']",
Deaths per year per Pakistan province? (2010-present),"
I've been trying to look for data on the number of community health worker deaths in Pakistan, ideally those who were working with polio vaccinations.
In particular, I'm trying to look for the number of deaths by year and by province in Pakistan, from around 2010 to right now. It's difficult to find data, but even if I can only find numbers on the number of deaths per year in the entire country, I'd be forever thankful!
","['data-request', 'medical', 'demographics', 'asia']",
Where Do I Get job listing from http://developer.dol.gov?,"
Can any one help me to integrate http://developer.dol.gov api for getting listing of jobs?
",['labor'],
MIMIC-III cancelreason meaning,"
In the MIMIC-III database, when describing the variable CANCELREASON in tables INPUTEVENTS_MV or INPUTEEVENTS_CV, the text says: 
""CANCELREASON""
                        ],
""If the order was canceled, this column provides some explanation.""
But I can not see any explanation, only a numerical coding 0, 1 or 2. 
Does anyone know the meaning of 0, 1 and 2?
",['mimic-iii'],
The list of restricted second-level domains such as .co.uk and .ac.jp,"
Some country-code top-level domains (ccTLD) contain general-purpose second-level domains, like .co and .ac, so the end user of the domain is identified with the third-level domain, such as oxford.ac.uk.
Where can I get the full list of such domains?
","['data-request', 'metadata', 'web-crawling']",
How to get account for IRI/LDEO Climate Data Library,"
I am trying to download precipitation data from the IRI/LDEO Climate Data Library maproom, but they ask for a log in password. 
Any idea how to register for this website?
",['geospatial'],
How do i import a 2gig csv file into R and be able to work with it on my PC?,"
Importing data into the R programming environment. I've tried imorting the data set with read.csv() but its telling me it cannot import vector of more than 500mb. 
",['machine-learning'],
Swedish Noun Gender List,"
I'm looking for a lexical resource on Swedish noun genders.
In my case which nouns that have gender neuter or not, that is if the indefinite article is en or ett.
","['data-request', 'language', 'corpora', 'dictionary']",
Data about bathymetry for Europe,"
I am looking for bathymetry data for European seas, and in particular for the Mediterranean see. Those datasets seem to exist (I could find some maps of bathymetry) but I would like to have the raw information (depth) and not the coloured maps. Raster or vector formats are OK, but I prefer raster. 
",['data-request'],"Raster or vector formats are OK, but I prefer raster.Are you looking for maps with isolines (""isobathes"")? Probably some formats available for download on the EMODnet Portal will be suitable for you (using appropriate software).I would like to have the raw information (depth)You could also download an XYZ file."
"When I click on Data Dictionary, it brings up a blank Excel spreadsheet","
When I click on Data Dictionary in the College Scorecard, it brings up a blank Excel spreadsheet. Where can I find the Data Dictionary information?  
","['metadata', 'collegescorecard']",
API/Dataset Containing Nutritional and Physical Activity data?,"
Im trying to find an API or dataset which contains both - the dietary information for example the number of calories aswell as a deeper breakdown into carbs, fats, proteins etc and also data on the persons physical activity/exercise so for example stuff like type of activity, calories burned, duration etc.
There seems to be datasets on just Nutrition or just Physical activity, but not both for some reason. I can work around 2 different data sets but ideally I would prefer if they were both in one, is anyone aware of any? 
",['data-request'],
Need data to access localized weather data,"
I am trying to build an application similar to zyGrib where in I want to add wind data onto an open layers map for a small local area. 
I am aware that there are public sources that I can access to get this data but I haven't been successful in finding one though. 
I want to preferably be able to access a very localized data set instead of downloading a huge global data set. 
","['api', 'uses-of-open-data', 'weather']",
data.dol.gov filters in R,"
I am making a data call against the data.dol.gov API using R and the following works:
apikey = ####
query = ""https://data.dol.gov/get/violation/limit/8/"" 
getdata <- GET(url=query,add_headers(""X-API-KEY""=apikey)) 
results <- fromJSON(content(getdata,type=""text""))

However, when I try to add filters, they don't appear to work.  I'm following what was provided in the developers
http://developer.dol.gov/accessing-the-apis-using-http-requests/
Using the following command:
query = ""https://data.dol.gov/get/violation/limit/8/issuance_date/start_date/2010-03-15/end_date/2015-04-15""

this does not work, even though I feel like i'm following what was provided in the developer's guide.  Any help would be most appreciated.
","['api', 'data.gov', 'labor']",
Wikidata differs from Wikipedia,"
I am trying to retrieve data for a company programmatically using the Wikidata API. However, the data retrieved from Wikidata is different from en.wikipedia.org. Is this expected? 
Example: Nissan Motors - WikiData and Wikipedia.
Revenue in wikidata: 94.62 billion USD (2007)
Revenue in wikipedia: 11.38 trillion JPY (2014)
Edit: This particular data discrepancy has been fixed. However, the general question still remains. Is it possible for wikidata and wikipedia data to differ? If yes, how frequently are sync'd? 
","['wikipedia', 'wikidata']","Wikipedia is an encyclopedic website that is written for humans.Wikidata is a database designed to be used by both humans and programs, in a multilingual way. The content of this database is transfered from a lot of different Wikipedia language versions, and because each one as independent content, Wikidata is a mix of different Wikipedias articles.So if a Wikipedia article is updated, wikidata will not be automatically edited. Perhaps a bot will do the job, but usually a contributor will have to update its data. It's why information may be different."
"Looking for GIS topographic data of Bogota, Colombia, with elevation contour lines","
I'm looking for the GIS data to create a topographic map of Bogota, Colombia; specifically, we want to get the elevation contour lines, and export that layer to CAD.
If anyone knows of any free places to find this data, we would love to hear it! I've been looking through some of the sources here http://freegisdata.rtwilson.com/ - but I'm not very familiar with that huge list. If anyone knows of a specific link in there that would be best to investigate, please let us know.
Thanks very much!
","['geospatial', 'south-america']",
Need small Higgs Twitter dataset,"
Can somebody tell me where I can find small Higgs twitter dataset.The Large one is present on the Stanford website but because of its large size, I am unable to create and display graph using matplotlib and NetworkX as it is taking very much time.
Basically, I need follower/followee dataset plus retweet dataset.The purpose is for modelling spread of the scientific rumour.Any type of help would be appreciated.
",['data-request'],"If you already downloaded the big dataset, I recommend you sample the data (reduce the dataset) yourself. There are different approaches that you can use:Hope this helps.  "
2000 Census Population by Block,"
I'm trying to get population data from the 2000 Census at the block level for the state of Colorado. This can either be as a shapefile or as a table along with a shapefile containing the 2000 block geographies. Essentially I'm looking to create a shape file which has the block geography along with the population count of each block. These are available for the 2010 census (https://www2.census.gov/geo/tiger/TIGER2010BLKPOPHU/) but I haven't been able to find them for the 2000 census. I've tried getting the information through some combination of American FactFinder and Tiger but I haven't had any luck.
","['us-census', 'geospatial']",
What do the alarm chartevents exactly mean?,"
An example:

row_id 24288398,24288390 and 24288389 in table chartevents are all
for the same patient. 
Itemid 224687 (row_id 24288398) shows the minute volume at charttime
2101-09-12 17:00:00
Itemid 220293 (row_id 24288390) shows the Minute Volume Alarm - High
at charttime 2101-09-12 17:00:00 (same charttime)
Itemid 220292 (row_id 24288389) shows the Minute Volume Alarm - Low
at charttime (2101-09-12 17:00:00) (same charttime).

I thought that the alarm events occur then the special item values (here minute volume) undergoes or overgoes some border but how could it be that all three events (minute volume, Minute volume alarm - high and minute volume alarm - low) could appear at the same time?
Maybe my understanding of how the alarm events work is just wrong. So what is the interpretation of the alarm events (here for example Minute volume alarm - high and minute volume alarm - low)?
",['mimic-iii'],"These are configurations for the alarm - not actual alarm events. So at that time you have the low alarm threshold = 2, the high alarm threshold = 18, and the actual value = 8.3.Side note: if using ROW_ID, it's helpful to reference the version of MIMIC-III (i.e. v1.4) as it changes version to version."
System configuration requirements for seting up MIMIC-III,"
I am trying to set up mimic-iii database and running into memory issues on local machine. Can anyone please share recommended hardware configurations to set mimic-iii database?
",['mimic-iii'],
Dynamic network data,"
I'm looking for a data set that is network data along with some kind of measure for each node at each time point, e.g. student performance data with data on who is working with whom in groups. 
","['data-request', 'network-structure']",
Data for teaching: Representative simple random sample in educational research,"
I´m searching for a gripping data set from educational research which is

a simple random sample (and therefore without weights)
representative 
and available as public-usefile 

to use for teaching. Any suggestions?
EDIT:
I`m teaching introductory statistics to undergrats, which are (student) teachers.
Representative means, that the demographic covariates of the sample are equally distributed to the population.
","['data-request', 'education']",
"Are there any anomaly dataset, which isn't imbalance?","
I am working an algorithm which I would like to test it on anomaly detection. But unfortunately, it is not yet proper for imbalance dataset, in which instances from one class is much less than the other one. 
So the question is 
Are there any anomaly dataset which is not imbalance? And how to download it? 
Note that, here by anomaly I mean some unwanted item:activity/object,etc, which is , not obvious by looking into a single item. For example, it may be many attacks into a network, but they may not be obvious by looking into any transaction of attacker to the network, but in the overall activity of the attacker. 
",['data-request'],"By definition an anomaly is not normal. This means your dataset needs to be somehow imbalanced, since normal defines itself in a bigger context as the regular. However, You can still take all sorts of anomaly datasets and use different techniques to rebalance them. Here is a post on some of these techniques:
https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html"
Sidewalk accessibility mapping in California,"
I'm looking for a data-driven way to virtually assess accessibility of sidewalks in California, particularly in the Bay Area. Basically, any tools that would help with estimating a 'walkscore' type of rating for sidewalks would be ideal.
FYI - There is a group of researchers at UMD doing something similar for sidewalks in Washington DC. Here's the link: http://sidewalk.umiacs.umd.edu
If you know any tools/ resources/ contacts who would be useful or can point me in the right direction, please let me know.
Thanks in advance!
","['data-request', 'geospatial']",
Any Available datasets for Hydroponic / Aquaponic /Aeroponic?,"
I'm working on a research project for developing predictive models for hydro-/aqua-/aeroponics. Where can I found related datasets for the nutrients and other sensitive parameters?
The specific idea of the project is not defined yet, I will set it according to the available datasets.
","['data-request', 'machine-learning', 'classification', 'agriculture', 'hydrology']",
Directory of museum collections online,"
What is the most comprehensive directory of museum online collections as of today? It seems there was an ICOM page for that but apparently it's no longer available.
",['database'],
Hierarchical semantic distances dataset,"
I need data (preferably human judgment) for the structural/hierarchical semantic distance between many couples (at least hundreds) of words.
For example, d(computer, television) < d(radio, television) < d(dish washer, television).
If we organize all words in a dendrogram or a tree, where each node is a category (""electric device"", ""with screen"", etc...), and words are in leaves, the number will represent several steps (nodes) we have to go from one word to another.
Does such a dataset exist? per couples ratings are enough, no need to have a full embeding/tree/specify the nodes (An example dataset will be:
Computer Television 1
Radio Television 2
DishWasher Television 3
I'm aware of the WordNet database but it has some very unintuitive definitions and the results achieved using it are not very correspond to human ratings. I would like to have a more human-rating alike data-set.
","['data-request', 'nlp', 'language', 'wordnet']",
Corpus of English text with tagged locations,"
I'm looking for corpora of English texts with locations tagged. 
I am aware of CONLL2002. This is the type of corpus I'm looking for, but want more.
","['data-request', 'nlp', 'text']","There are 1,108,558 English Wikipedia articles that have location information.  Location information is specified by Template:Coord in Wikipedia and can be easily extracted from the text. I guess this might be the largest free dataset that you can get with your requirements."
Database with multiple values for the same ID,"
I have a database where each entity has a unique ID, but recently all of the entity names were changed (not in the same way) to improve readability.  This has made a lot of the summary reports look like the following:
ID     Name            Total for the year     
3011   Joesmith          3000
3011   Joe Smith         1000
5024   DBS               400
5024   Deborah Smith     150

What's the best way of going about either correcting the old entries to match the new ones or simply displaying the new name for any matching ID?  At the end of the day we can get the summaries we're interested in by just using the ID's, but ultimately we want to interpret those by seeing our names.
We're looking at about 1000 or so IDs with different names and maybe 50,000 or so rows in total.
","['database', 'excel']",
Total cryptocurrency market cap over time,"
Does anyone know where to download historical data for the total market capitalization of the cryptocurrency ecosystem? For example, the data behind the ""Total Market Capitalization"" chart here: https://coinmarketcap.com/charts/.
Their API only allows access to the current market cap, not historical data. I've tried contacting them, but thought I would ask here as well. I would like to avoid calculating it myself if possible...
P.S. I've seen this question but no one suggested a source for the market cap data.
","['data-request', 'api', 'finance', 'historical']",As @philshem suggested I wrote some python to gather the dataThis gets the total market cap value from each snap shot which is taken each sunday.
Normal laboratory values for tests from the hospital/medical centers contributing to MIMIC database,"
Where can I get laboratory normal values and ranges for laboratory tests in the MIMIC database - tests like hematocrit, red blood cell count, bicarbonate, blood urea nitrogen, etc.?
Specifically from the hospitals associated with the database. I have data from Texas Tech University Health Sciences Center El Paso and there, like almost anywhere else where  normal values are published, there is the qualification

Note: The reference values provided in these tables should be used as guidelines only. Reference values vary based on several factors, including the demographics of the healthy population from which specimens were obtained and the specific methods and/or instruments used to assay these specimens.
Laboratories that are accredited by the College of American Pathologists (CAP) are required to establish and/or validate their own reference values at least annually. Thus, any given result should be interpreted based on the reference value of the laboratory in which the test was done; the laboratory typically provides these values with the test result.

I am noting discrepancies in normal ranges and mean ranges from the MIMIC database for some of the laboratory tests, in particular hematocrit, hemoglobin, red blood cell count and blood urea nitrogen (BUN), while the majority of the tests like sodium, potassium, etc fall within accepted normal ranges.
",['mimic-iii'],
Spatial data on cancer,"
I have to perform a autoregressive CAR bayesian model on some cancer spatial data.
I have no clue where to find open dataset with spatial information about cancer data.
","['data-request', 'medical']",
Any help on getting the city or zip codes that make up metropolitan statistical areas?,"
I have a list of addresses (city, state, zip) and I'd like to group them into regions throughout the united states.
It seems that metro/micropolitan statistical areas is a good way of doing that, but I'm having a hard time finding a list of all the zip codes and which area they fall into or city/state per statistical area.
Any leads? Thanks!
","['data-request', 'postal-code', 'usa']",
Are there data on physical album sales by city/state/region for 2000-2010?,"
I'm looking for data on physical sales of popular music albums in the United States by geographic region, e.g. city, state, or region? As fine-grained as possible? Ideally, I'm looking for data for the years 2000 to 2010, or even earlier.
","['data-request', 'music']",
Dataset to build customer service bot,"
I am building a customer service virtual assistant bot. It is on the tech support side of customer service.
Is there a way to get sample dataset that I can use to build it? 
",['data-request'],
High-quality voter (partisan) data for the United States,"
What is the best publicly-available data source for the geographic distribution of Republican and Democratic voters in the (individual) United States? I'm happy with either a presidential or congressional election focus, but I suppose the latter would be preferable as I'm looking into gerrymandering.
I understand that collecting, modelling, and generating such data is presumably a major statistical effort that many private organizations undertake, but perhaps there is some decent publicly-available dataset?
","['data-request', 'usa', 'elections']",
Historical Housing Data in Quandl,"
Quandl has housing data through their API including Price per square foot on the neighborhood level.  Is there a way to get the history for this data as well.  Say yearly back to 2009?
","['geospatial', 'api', 'real-estate']",
How to decode the company number in the field `header$companynumb`,"
Is there a lookup table where I can find the names of repackaging or drug manufacturing companies with companynumb reported in the field companynumb?
e.g. ""companynumb"": ""200501050""
","['api', 'openfda', 'uses-of-open-data']",
Property and sub-property pairs,"
Here are some example records:
https://www.wikidata.org/wiki/Q11361734
https://www.wikidata.org/wiki/Q74669
I have the following (updated) query:
# Script #2
SELECT
    (GROUP_CONCAT(       ?dateYear ; separator = "", "") AS        ?dateYears)
    (GROUP_CONCAT(       ?cooLabel ; separator = "", "") AS        ?cooLabels)
    (GROUP_CONCAT(DISTINCT ?gameENLabel ; separator = "", "") AS ?gameENLabels)       # English
    (GROUP_CONCAT(DISTINCT      ?dataLink ; separator = "", "") AS        ?dataLinks)
WHERE
{
    # types of item
          {?game wdt:P136  wd:Q744038}  # regular RPGs
    UNION {?game wdt:P136 wd:Q1529437}  # tactical RPGs
    UNION {?game wdt:P136 wd:Q1422746}  # action RPGs
    UNION {?game wdt:P136 wd:Q1143132}  # roguelikes
    #?game wdt:P136/wdt:P279* wd:Q744038.   # any class or subclass of role-playing video game, including MMORPGs
    ?game wdt:P31 wd:Q7889.      # instance of video game

    # English label
    ?game rdfs:label ?gameENLabel.
    FILTER(LANG(?gameENLabel) = ""en""). # we mainly want English labels

    # wikidata link
    BIND(CONCAT(""=hyperlink(\"""",replace(replace(STR(?game), ""entity"", ""wiki""), ""http"", ""https""),""\"")"") AS ?dataLink).       # changes the target of the URL and creates a MS Excel compatible hyperlink
    #BIND(STR(?game) AS ?dataLink).     # faster substitute

    # release date (simple)
    OPTIONAL
    {
        ?game wdt:P577 ?date BIND(YEAR(?date) AS ?dateYear)
        OPTIONAL
        {
            ?game p:P577 ?dateProp.
            ?dateProp pq:P291 ?region.
            ?region wdt:P297 ?cooLabel.
        }
    }
}
GROUP BY $game
ORDER BY asc (?dateYears) ASC (?gameENLabels)
#limit 100

However, there are some issues:

It is not rendering all ""publication dates"" when those dates do not also have a ""place of publication"" sub-property
If the ""place of publication"" is missing, I would like the missing property to be replaced with ""???"" (or something similar), so that every game has a date/region pair of some sort in the output

Can someone show me how to accomplish this? Thanks!
[edit]
Here is some example current output:
1983        Ultima III: Exodus  =hyperlink(""https://www.wikidata.org/wiki/Q2240236"")
1983        Ultima: Escape from Mt. Drash   =hyperlink(""https://www.wikidata.org/wiki/Q4003118"")
1983        Universe    =hyperlink(""https://www.wikidata.org/wiki/Q7894198"")
1983        Wizardry III: Legacy of Llylgamyn   =hyperlink(""https://www.wikidata.org/wiki/Q8028765"")
1983, 1982, 1978        Beneath Apple Manor =hyperlink(""https://www.wikidata.org/wiki/Q4887174"")
1984        50 Mission Crush    =hyperlink(""https://www.wikidata.org/wiki/Q635707"")
1984        Gemstone Warrior    =hyperlink(""https://www.wikidata.org/wiki/Q5530766"")
1984        Questron    =hyperlink(""https://www.wikidata.org/wiki/Q2687236"")
1985    JP  Cosmic Soldier  =hyperlink(""https://www.wikidata.org/wiki/Q869287"")
2016, 2016, 2016, 2016, 2015, 2015  JP, AU, JP, AU, JP, AU  Monster Hunter Generations  =hyperlink(""https://www.wikidata.org/wiki/Q20856979"")
2016, 2016, 2016, 2016, 2016, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2013, 2013, 2013, 2013, 2013, 2012, 2012, 2012, 2012, 2012    JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP, JP  Phantasy Star Online 2  =hyperlink(""https://www.wikidata.org/wiki/Q2709892"")

[edit]
Here is some example desired output:
2014, 2015, 2017    JP, ??, ??  Game Title =hyperlink(""https://www.wikidata.org/wiki/Q2709892"")

","['wikidata', 'sparql']",
Scorecard medians and information about methodology,"
I’m trying to compare my institution to the national averages as reported publicly. I can’t seem to replicate the National Median for average annual cost. When comparing institution type using the college score card tool, it looks as though two-year colleges and four year colleges have the same median. Does anyone have some insight on this?
",['collegescorecard'],
UK MoD Airfields and Firing Ranges,"
I'm trying to source shapefiles for UK Ministry of Defence airfields and firing ranges. Would anyone have an idea where to get them?
","['data-request', 'uk', 'geospatial', 'military']",
Are there any (openly) available data sets for medical coding examples?,"
Are there any data sets of medical coding examples available online?
Eg. Doctor's notes and resulting (correct/accepted) procedure and diagnosis codes for individual encounters or samples of incorrectly coded ICD10 and CPT code sequences/bunches and they are associated with corrected sequences/bunches (by saying, ing medical coders or reviewers).
Or something of the form, for example, of what a medical billing coder might see on a charge review screen. Something like says a dataset where each sample contains
[<patient demographics>, <Diagnoses>, <Charges (ie. ICD10 codes and the associated diagnoses)>, etc]

I'm aware of the MIMIC-III data set, but need ICD10 (the latest medical code standard, implemented on 2015-10-01) while the latest version of MIMIC uses ICD9. Also aware of this very similar question, but was hoping that users may have suggestions in this case since the data I need is slightly more specific. Would like to look at differences in what doctors record as diagnoses and procedure codes and what the actual correct/acceptable code combinations should be as edited by a medical coder before the charge was sent to an insurer.
","['data-request', 'mimic-iii', 'medical']",
Where can I find data to track migration out of Puerto Rico?,"
I am looking to track the migration of Puerto Rican nationals out of Puerto Rico post the devastating hurricanes. What datasets would be most effective for this? Travel data, flight data, etc.
","['data-request', 'migration', 'travel']",
Extracting data in tabular form from camelcamelcamel,"

Can anyone give me pointers on how I can extract price and sales rank data from camelcamelcamel.com? They display only a chart showing the evolution of prices/sales rank over time, but I'm trying to extract the underlying data that generates this chart. I tried looking at the HTML, but can't find the relevant call based on which the chart is computed. Any help will be much appreciated!
(Disclaimer: This is related to a research project that I'm doing, and I don't seek to clone the website or to scrape it en masse in any way - I just need price data for a small set of products (1000 at max)).
Edit: Here's a screenshot of the networks tab of a sample page - I tried to see if any of these files potentially have the data, but can't find it at first glance, if anyone has any pointers that would be much appreciated!
","['data-request', 'web-crawling', 'prices']",
Is interactive data in Google Maps accessible?,"
As we all know, Google aggregates lots of data that is later used in Google Maps.
One prominent example is traffic, another is customer frequency.
Is there a way (except using web crawlers) to access this kind of information, and if so, how detailed is it?
",['geospatial'],
Spanish POS (part of speech) tagged dataset,"
Where can I get a spanish POS tagged dataset with universal tags free to download?
","['machine-learning', 'nlp', 'corpora', 'dictionary']",
Where to find fracture xray imaging data?,"
Where can I retrieve X-ray image data of fractures?
Labeled data containing features like age, type of fracture would be best.
","['data-request', 'medical']",
Find all Wikidata items that use a particular P18 picture,"
I want to find all Wikidata items that have ""Gthumb.svg"" as a P18 property.
Leaving aside the fact that ""Gthumb.svg"" may not exist on Commons and that normal P18 values have a ""commons:"" prefix, it should return at least this item whose P18 is ""Gthumb.svg"": 
https://www.wikidata.org/wiki/Q11499608
So, I wrote this query:
SELECT ?item
WHERE 
{
  ?item wdt:P18 ""Gthumb.svg"".
}

Problem: It returns zero results. What am I doing wrong?
","['wikidata', 'sparql']",
Use Fuzzy Search with OpenFDA API,"
I want to ask how can I use fuzzy search in openfda api?
For example, I am using ""panadol"" to search something.
https://api.fda.gov/drug/label.json?search=brand_name:panadol
But sometime I miss some word in panadol, So I can search the same result like panadol?
For example, I am using ""anadol"" to search.
https://api.fda.gov/drug/label.json?search=brand_name:anadol
In this case, It will return no matches found. So can I use fuzzy search in openfda api?
Any comments will be much appreciated. 
","['api', 'openfda']","Sorry, openFDA doesn't currently support searches based on wildcard, fuzziness, regular expression or proximity. To get matching results, there are no reasonable alternatives except to search by the full accurate word"
Contact information (including email) for all US state legislators,"
Where can I find a single list containing the contact information (including email address) of state legislators for all 50 US states, ideally broken down by state and chamber (most states have a House and Senate, just like the federal government) and including US territories and possessions?
To clarify, I am referring to the group of people who meet in each state's capital city, not the people who meet in Washington DC to represent their state.
I've found several sites that have information for individual states. Some examples:

https://www.cga.ct.gov/asp/menu/hlist.asp (CT)
http://www.gencourt.state.nh.us/house/members/housemembersemail.aspx (NH)
MN is split by chamber:

http://www.house.leg.state.mn.us/members/hmem.asp
http://www.senate.mn/members/


In theory, I could try finding pages like this for all states, but I'm sure someone has already compiled such a list.
","['usa', 'legal', 'state']","Open States has all of this information. Here's contact information, including email for one of my senators.
You could scrape them or use their API."
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
,,,
Budget of religions,"
I want to see how religions receive and spend their money.
Example:
ReligionA:
  Income:
    50% donations
    30% rents
    10% subsidies
    10% graveyard fees
  Expenditure:
    40% humanitarian donations
    30% salaries
    20% buildings maintenance
    10% others
ReligionB:
  [...]


By ""religion"" I actually mean ""religious organization"", with local religious leaders at the bottom and a chain of responsibility leading to a central authority.
Religions without an organization are out of scope.
The income/spending patterns of a religious organization's Luxemburg branch and Ethiopia branch are probably different, these should be summed up to present a global view.
Due to complex structures this is probably very difficult to calculate, so estimation-based data is fine.
I am mostly interested in percentages, but actual amounts would be even better.

","['finance', 'religion']",
"What is the meaning of ""units in structure"" in Census/ACS data?","
The US census provides the number of housing units, which is supposed to represent individual dwelling units, not structures.  The American Community Survey provides the number of units by structure type.  My question is regarding the data for housing structures with more than one unit.  I am looking at b25024 data set:
B25024e1    UNITS IN STRUCTURE - Universe:  Housing units - Total: -- (Estimate)
B25024e2    UNITS IN STRUCTURE - Universe:  Housing units - Total:  1, detached -- (Estimate)
B25024e3    UNITS IN STRUCTURE - Universe:  Housing units - Total:  1, attached -- (Estimate)
B25024e4    UNITS IN STRUCTURE - Universe:  Housing units - Total:  2 -- (Estimate)
B25024e5    UNITS IN STRUCTURE - Universe:  Housing units - Total:  3 or 4 -- (Estimate)
B25024e6    UNITS IN STRUCTURE - Universe:  Housing units - Total:  5 to 9 -- (Estimate)
B25024e7    UNITS IN STRUCTURE - Universe:  Housing units - Total:  10 to 19 -- (Estimate)
B25024e8    UNITS IN STRUCTURE - Universe:  Housing units - Total:  20 to 49 -- (Estimate)
B25024e9    UNITS IN STRUCTURE - Universe:  Housing units - Total:  50 or more -- (Estimate)
Here is a description of that data:

2 or More Units--These are units in structures containing 2 or more housing units, further categorized as units in structures with 2, 3 or 4, 5 to 9, 10 to 19, 20 to 49, and 50 or more units.

When I look at the data, it doesn't make sense.  All the total units in B25024 add up to the total housing units reported by the census... great!  But if you look at one of these categories, such as B25024e8 (Total 20 to 49), there are some block groups with values like ""11"" or ""12"" or ""2"".  
How can you have a value in the 20-49 units category that is less than 20 units?  Is it possible that the original data was at the tract level and got split to block groups?
","['usa', 'census']",
Dataset from online forum,"
Recently I started to do some researchs on QA data aiming to rank quality answers from determined questions, for this I used the avaliables Yahoo! and StackExchange datasets.
Now, I would like to expand the research for identify potential answers to the thread starter along all posts on that thread. For this, I searched for some online forum dataset, possibly annotated (like the Ancestry.com, unavailable now), because on online forum a reply on a thread not always means that is a direct answer to the thread starter. But I couldn't find any dataset like this.
Do you guys know about some avaliable dataset that could help me? Thanks.
","['data-request', 'nlp', 'research']",
Annual reports from UK public companies,"
How can I get the 'annual report and accounts' from the top 500 listed (public) companies in the UK? (They are valuable data, despite them being PDFs.)
We looked at scraping annualreports.com but it didn't seem to have the latest year's report for many of the companies. In addition some companies' reports are locked until someone pays them.
We're resorting to automated Google searches, but surely there's a better way?
","['finance', 'uk']",
Dataset that has commercial property rent data for the United States,"
I was looking for a dataset that contains the rent data for commercial properties in the US.
Any help would be appreciated 
",['data-request'],
"Moon phase data for Queensland, Australia","
I am looking for a moon phase calendar for Queensland, Australia. Something which might have dates and moon phase on a particular date. Any ideas where can I find such a complete calendar for say last 25 years?
","['data-request', 'data.gov', 'uses-of-open-data']","Moon phase data is usually computed, not observed. Additionally, moon phase data is not location dependent. The full moon occurs at the same time for all locations: http://www.lunarabundance.com/full-moon-same-time-around-the-world/http://astronomy.stackexchange.com/questions/13488/where-can-i-find-visualize-planets-stars-moons-etc-positions may be helpful in finding moon phases, though google should also be helpful.If you believe the computed moon phase data may be inaccurate and want to compare it to observed moon phases, you might poke around on astrophotography sites."
In need of dataset for fraudulent insurance claims,"
I tried looking at all major sources but in vain. Is there any dataset of insurance claims with honest and false insurance claims? This is to be used to train and test a classification algorithm.
","['data-request', 'machine-learning', 'classification']",
Database of bicycle sharing systems,"
I am looking for a database of bicycle sharing systems. It does not need to be real-time (even though that would be wonderful).
Each entry should ideally have the following:

Name of the system (ex: Vélib')
Official URL (ex: http://velib.paris.fr)
Wikidata page if available (ex: https://www.wikidata.org/wiki/Q1120762)
Number of bicycles (ex: 18200 bicycles)
Whether it is OK to leave bicycles anywhere or not (ex: false)
Number of stations, if applicable (ex: 1230 stations)
Name of the city (or area) of coverage, if possible as a Wikidata identifier (ex: https://www.wikidata.org/wiki/Q90)
Price per use/day/month/year if applicable (ex: 0EUR/1.70EUR/NA/29EUR)

Optional but would be great:

Area covered (geographical shape or list of stations coordinates)
Average daily ridership (ex: 108090 rides)
URL of the mobile apps for Android and iOS (ex: https://play.google.com/store/apps/details?id=com.paris.velib)
Stars given to the mobile apps (ex: 2.9/5)
URL to a picture of a bicycle on Commons (ex: https://commons.wikimedia.org/wiki/File:Service_bicyclette_hangzhou_zhongguo.jpg)
URL to a logo of the system (ex: https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/V%C3%A9lib%E2%80%99_logo.svg/1280px-V%C3%A9lib%E2%80%99_logo.svg.png)

","['data-request', 'transportation', 'city', 'public-transport']",
Where can I find dump from network traffic capture while DNS attack?,"
I'm searching for dump from network traffic capture like tcpdump while DNS attack. With direct classification which record is related to the attack and vice versa.
",['security'],
Map coverage for CenturyLink High Speed Internet?,"
Does anyone know where to find a map coverage that CenturyLink has for their high-speed internet? I am asking specifically in Colorado.
","['data-request', 'geospatial']","There is an interactive map from CenturyLink (from any other source it'll be be hard to find official data)https://www.highspeedinternet.com/coTo get the underlying data, you may have to deconstruct javascript (I pulled this from the HTML source)https://d1sfco99flnudn.cloudfront.net/www.highspeedinternet.com/js/2023195885.site.jsIt references the Mapbox API (and Markers)"
Mixture data for pair-copula model,"
I am a PhD student and would like to get a mixture real data that may exhibit upper and lower tails dependencies along with other dependencies structure. I am working on a pair-copula models.
These models mean that, if we have a multivariate data, then we can build an acyclic tree where only two variables are modelled at a time. These models help to model non-normal dependence structures.
I would like to have a multivariate data that exhibit mixture dependencies between each variables and hope these dependencies including tail dependencies. Most of this data can be financial.
","['data-request', 'finance']",
Historic (start of 2017 season) Formula 1 betting odds,"
I'm looking for historic (i.e. from the start of 2017 season onwards) betting odds for Formula 1 races. Specifically, I'm looking for data such as winning odds for each driver (and/or team) for each race, podium odds and generally as more data as possible.
I've built a machine-learning F1 race prediction engine and I want to check if my predictions could somehow guide any betting endeavours.
","['data-request', 'machine-learning', 'historical', 'sports']",
Aircraft parts database,"
Is there an open dataset of aircraft parts?
Each part has a unique number. Several services provide search across resellers. These searches return little details on the part itself, only reseller contacts.
FAA maintains several datasets, one of which is aircraft vehicle registrations:

http://registry.faa.gov/aircraftinquiry/

No parts data. Though someone must certify all parts and assign numbers.
Who maintains this data or is supposed to have it?
","['data-request', 'transportation', 'products']","FAA actually publishes parts approvals, but Google doesn't show it in top results:This database contains the FAA Parts Manufacturer Approvals and may be viewed by make, PMA Holder, and part number.A commercial database that groups standard parts together:It helps in matching similar parts with different approval numbers."
Public companies' employee count and properties from SEC/Edgar 10-K,"
I've browsed through several 10-K documents and found that companies provide their employee headcount (under Item 1. Business) and properties they own or lease (Item 2. Properties). (Yahoo example.)
I saw this question for employee numbers, but the answer does not provide a timeseries or property info.
Has anybody extracted these data elements from the 10-K text (per year) and made them openly available? Thanks!
","['data-request', 'companies', 'real-estate']",
News to Category/Section mapping DataSet,"
Is there a public dataset which has news articles to various sections/categories mapping? 
For example:
Article 1 (title, text, etc, CATEGORY)
Article 2 (title, text, etc, CATEGORY)
Article 3 (title, text, etc, CATEGORY)
and so on.
Categories/sections should refer to commonly used names in news media such as sports, entertainment, science, tech, lifestyle, news, politics etc. 
I did some search but couldn't find anything except 20newsgroup which is a very small dataset. 
","['data-request', 'machine-learning', 'nlp', 'news']",
Open information on UK properties,"
I'm looking to find any open data on UK properties.
I have already looked at all the VOA datasets. And I am aware that the commercial side of the land registry will be becoming free to access towards next year.
I'm more looking for commercial property information, or an easy way to determine commercial properties from residential (other than using VOA business rates, as this is flawed in multiple aspects).
","['data-request', 'data.gov', 'uses-of-open-data', 'uk', 'land']",
SIC code for company name,"
Can any one please suggestion me where can I get SIC (Standard Industry Classification) code for US based companies. Have list of US - based companies name and web site info, addition to it - in want of SIC code. It would be great if i get free data set. You suggestion and info would help me a lot...
","['data-request', 'usa', 'companies']",
Internet Peering Locations,"
Is there any dataset about worldwide Internet Interconnection locations?
Some information about the average or maximum switching capacity would be nice.
I found a map (and raw data) about seacables (http://www.cablemap.info/), but nothing about connections on land.
","['global', 'internet']","I'm not aware of any open solution but here's some real quick data I found after a brief search:  PCH (Packet Clearing House) Internet Exchange Directory exposes their data in JSON/TopoJSON here:
Countries TopoJSON
Directory Data JSON
and Data Center Map's Internet Exchange Points (IXPs) map exposes their data in one of their JS files.  I've put them all into this gist for the moment. Will probably port to GitHub/Datahub.io/data.world at some point..."
american hospital directory - a list of all US-hospitals,"
Where can one find a list of all US hospitals with the number of licensed beds? I believe that CMS provides this data somewhere, but I cannot find it!
btw: there is a american hospital directory: Here's a list of beds per hospital 'non-federal, short-term, acute care hospitals', 
ordered by state, so in 50 clicks you'll have the data: https://www.ahd.com/state_statistics.html
I strongly suspect that this list is incomplete, and some hospitals have reported 0 beds, which seems unlikely.
Is there a dataset in a spreadsheet available somewhere? 
","['data-request', 'usa', 'medical']",
Datasets in for taxi/uber in Pakistan with spatio-temporal components,"
Where can I find datasets for Careem or Uber taxi trips in Pakistan, like e.g. the Taxi & Limousine Commission Trip Record Data in New York, for spatio temporal analysis?
","['data-request', 'geospatial', 'traffic', 'asia']",
Data for a truly randomised treatment?,"
My research is on estimating average treatment effects using different machine learning models. However, I need a big data set with a truly randomised experiment in order to estimate the ""true"" average treatment effect. Does anybody have knowledge of such a data set that is publicly available? It does not matter what it is about, just that the treatment assignment is truly random.
",['data-request'],"I don't know what you mean exactly, and I assume you don't mean ""double-blind"" studies.However, if you already had your own dataset: You can randomize that data yourself, and take averages of permuted values of interesting columns as a baseline.Just augment + shuffle/permute the data table correctly, and  you'll get a  randomized dataset just as you need.This code is from the Datacamp.com class ""Foundations of inference"" where this technique is demonstrated at length:Dataset (2 columns, 40 rows): R Code:Result:This shows that 5 randomized datasets derived from the original show max +-12.5 % difference in people promoted, regardless of gender, whereas the original data show a mean difference of 29% difference (when grouped by gender)."
Looking for open dataset mapping informal company names to ticker,"
We've looked for trained data for named entity recognition (in particular for company names). The end goal is to feed in a list of entity names (with potential misspellings, acronyms, punctuation etc) and map these to official company names and hence a ticker e.g. BBG ticker. 
Searches here found questions asked like Dataset for Named Entity Recognition on Informal Text though this does the tagging of the words, not a mapping to a clean entity name so it isn't what we're looking for.
If this is not readily available, should we be approaching this by scrapping a list of entities from an informal source and feeding that through some of the available APIs e.g. Google Cloud to 'create' a trained dataset?
","['data-request', 'language', 'opencorporates']",
MODIS flood map,"
Searching for flood maps I found NASA NRT Global Flood Mapping. 
Are there other sites from where I can get flood maps?
","['data-request', 'geospatial']",
"Australian Vehicle or Car Brands, Models, Styles, and Specs API","
I need to show Car Models and Specs on my Website. Similar to carsales.com.au search form. Does any one know an API to get these data? There's a lot of US APIs but no Australian APIs at all. There is one RedBook API. But is there any other cheaper options?
I checked Following but no luck
https://vpic.nhtsa.dot.gov/api/
http://edmunds.mashery.com/
","['data-request', 'api', 'cars', 'australia']",
Fluid Input Categories Changed from MIMICII to MIMICIII?,"
I would like to get some external verification to see if I am correct. 
I originally used the MIMIC II (2v26) database and I looked for fluids based on category in the d_ioitems table. For example: 
MIMIC2=# select * from mimic2v26.d_ioitems where lower(category) like 'colloid%';
 itemid |         label         | category
--------+-----------------------+----------
   2036 | Sterile Water 150.0ml | Colloids
   1894 | Dextran 70            | Colloids
   1438 | Hespan 1000.0ml       | Colloids
   2688 | Albumin 25% 50.0ml    | Colloids
(4 rows)

But it seems that categories such as 'Colloids', 'Fluid Bolus', 'IV Infusions','IV Drips' are no longer present in MIMICIII (v1.4):
MariaDB [mimiciii]> select distinct category from mimiciii.D_ITEMS where 
category in ('IV Infusions','IV Drips','Colloids','Free Form Intake','Fluid Bolus');
+------------------+
| category         |
+------------------+
| Free Form Intake |
+------------------+
1 row in set (0.00 sec)

And that 'Free Form Intake' is what replaces the categories that I'm looking for. 
Is there something I am missing? I haven't been able to find any documentation on this change. 
If these category names no longer exist, then I will likely need to filter for specific 'label' names that are indicative of the categories I'm looking for. 
",['mimic-iii'],"At least for colloids, the category became null when going from MIMICII to MIMICIII. In addition to some colloids increasing in their itemid (for example Hespan, itemid 6313 to 46313), there was also merging of itemids. Using hespan as an example, MIMICII had multiple labels (itemids) for hespan in different categories: But upon further investigation with specific patients, itemids 246, 623, 662, 1438 were all combined into 6313, and in MIMICIII, all became 30012, with 6313 becoming 46313 as expected:"
Real-estate property data for USA,"
Any location or database that has real-estate property information for the USA?
Data items could include:

Monthly rental rate
Purchase price
Financing options
Purchaser income

","['data-request', 'data.gov', 'real-estate']",
"Car breakdown database and diagnostic trouble codes, that caused a breakdown","
I didn't found source of the data in which there could be information about car breakdowns, the causes of failure and, possible, diagnostic trouble codes(DTC). Can your help me with this problem?
","['data-request', 'transportation', 'cars']",
Best method for crop mapping [closed],"







Closed. This question needs to be more focused. It is not currently accepting answers.
                                
                            











Want to improve this question? Update the question so it focuses on one problem only by editing this post.


Closed 5 years ago.







                        Improve this question
                    



What is the best method/algorithm to perform crop classification?
",['classification'],
Looking for Soviet Union or Russia transportation GIS dataset,"
I am looking for a dataset that can I obtain about Russia's transportation.
I am working on a PDF of the former Soviet Union's St. Petersburg map that I have here and need to georeference it. Is there a way that can I go to a website where there is an English version? The map I have is written in Russian.
","['data-request', 'geospatial', 'transportation', 'historical', 'russia']",Possibly this: Russian gis on SE's gis site 
Determining if drug is generic or brand using NDC,"
Is there a way to determine if a drug is generic or brand by passing in an NDC (National Drug Code) to the drug label endpoint (https://api.fda.gov/drug/label)?
",['openfda'],
Satellite image of agriculture land cover for North Korea,"
I am looking for free satellite images of agriculture land cover for North Korea. 
Is it available on Earth Explorer, which image should I download?
I'm looking for imagery with which I can do an analysis (in ArcGIS) of how much vegetation is healthy on the agriculture land and how much is lost due to drought. 
","['geospatial', 'agriculture', 'korea']",
Available datasets for HTTP headers,"
I would like to know if there are any publicly available datasets with HTTP header data, such as URI, user-agent, referer, content-length, etc--
I've tried searching with the usual keywords to no avail. All network flow data I have chanced upon are flow-based, or are incomplete- one only provides the host + URI, whilst the other hashes the URI used due to privacy issues.
",['internet'],
Datesets - users accessing database tables,"
I'm trying to model user behavior on database tables. Do you know any public date sets of the form: User U accesses table T.
I.e. I need a data set of the sort [user u,table t,timestamp], that states that table t appeared in a query executed by by user u.
Also, a data set of the form user accesses/uses/... Object would suffice. 
",['data-request'],
Open FDA - Medical device search -> summary pdf,"
I want to know how to search the PDF files with a search term.
Most 510K records have the value ""Summary"" stored in the Summary field.
How can one search the PDF files attached to the summary and run query on that pdf file?
This search does NOT work -> https://api.fda.gov/device/510k.json?search=limit=1&statement_or_summary:%22cardiac%22
But this document DOES contain the work cardiac in it
https://www.accessdata.fda.gov/cdrh_docs/pdf14/K140916.pdf
Please help.
",['openfda'],
Air quality in all cities in the USA,"
Where can I find information about pollution or air quality by city in U.S.? I would like to the data to be from an official source.
","['usa', 'city', 'environment']","The Environmental Protection Agency monitors this in many places and have much of this data available for free, as well as extensive documentation: https://www.epa.gov/outdoor-air-quality-data"
Vehicle crash Data for all states in USA,"
Looking to pull as much crash data as available and use it in analytics. Is there any API to pull data directly instead of manually downloading PDF files?
","['data.gov', 'api', 'transportation']",
City car parking dataset in EU (and US),"
I want to do a research project about the prediction of car parking occupancy rates and compare different cities in the EU/US. 
Are there public datasets that you can recommend?
I found a couple of RSS-feeds which provide real time information via XML, however, I am especially interested in regularly updated historical data for my project.
","['data-request', 'uses-of-open-data', 'city', 'europe', 'parking']",
Where can I find a KML file for Scottish Datazones 2011?,"
I'm working on mapping my data in Google Fusion and would like to have a KML file for Scottish Datazones 2011 so I can do some work on deprivation.  I can't find one and I don't have the skills to work out how to make one.
",['kml'],
Where can I find a list of cities within each county?,"
I found some lists for some states, e.g. https://georgia.gov/municipality-list, but not for all counties in the US...
","['usa', 'data.gov', 'us-census', 'census']",
Cost living or CPI (consumer price index) by city in de US,"
I'm looking for data on cost of living per city from official U.S. sources.
So far I've only been able to find this data for states or counties like the following to examples:  

Living Wage Calculation for Alabama (MIT)
Census.gov 'Housing' publications (Cost of Living Indicators — Housing, Public University, Hospital Stays, Energy Expenditures, and Utilities Excel sheet)

","['data-request', 'data.gov', 'us-census', 'cpi']",
"Hi, does anyone know if the FDA has released ANDA submission dates?","
I know the ANDA sometimes will comment on changes in ANDA review time, however the Orange book only provides the approval date and not the submission date.
Does anyone know either where the submission data has been released in the past, or if there's a specific office that we should be in contact with for this data? 
","['data-request', 'releasing-data']",
Data tables from Sorokin's Social and Cultural Dynamics,"
The title says it all, does there exist in digital form, like csv-files or spreadsheets, the (very many) data tables from Pitirim A Sorokin's Social and Cultural Dynamics, all four volumes:
I   Fluctuations of Forms of Art
II  Fluctuations of Systems of Truth, Ethics, and Law
III Fluctuations of Social Relationships, War, and Revolution
IV  Basic Problems, Principles, and Methods

","['data-request', 'historical', 'books', 'social-process']",
A database with PAO (period after opening) by beauty product,"
I'm working on an app and I'm looking for a open database with PAO (period after opening) by cosmetic product of worldwide beauty brands.
",['data-request'],
Yearly population projections for the fifty American states till 2050,"
I'm looking for population projections for the fifty American states (yearly up till 2050). Are these available online, or in any academic papers? Thanks. 
I've found the following two sources; the first only gives values for 2010/2020/2030/2040; the second source gives projections which are slightly outdated (from 2004), and these go up till 2030. 
National Population Projections - Cooper Center
Population Projections - CDC WONDER
","['us-census', 'population', 'north-america']",
Where can I find public access data on mortgage delinquencies and foreclosures?,"
Where can I find public access data on mortgage delinquencies and foreclosures? I would like data at the monthly (I'll settle for quarterly) level for each county or zip code (I'll settle for state) in the US. I am just interested in the total numbers, but as a percent of all mortgages is fine too.  
","['data-request', 'usa', 'real-estate']",
LIDAR data for Israel,"
Are there any public sources for LIDAR data for the country of Israel? Searching online has not lead me to find any sources out there.
","['data-request', 'geospatial', 'images', 'oceanographic']",
Hydrology for Tonle Sap lake in Cambodia,"
I am looking for Basins (or Catchments Watersheds) with basic hydraulic parameters such as the upstream downstream relation for the Tonle Sap lake region in Cambodia. I typically use WWF's HydroBasin level 6 but since the flow in the Tonle Sap river system changes direction during certain times of the year, I might need a more detailed dataset. 
","['cambodia', 'hydrology']",
Are the API keys on data.gov considered sensitive?,"
To access the US data.gov public datasets, you need a CKAN API key.
Should I consider this sensitive information, e.g. can anyone having my API key 'misuse' it so that it causes me harm, directly or indirectly?
","['api', 'data.gov', 'ckan']","There are some API limits tied to a specific API key. If a third-party used your key, their calls would effect how many calls you can make. "
State and Average Local Sales Tax Rates 2000-2010,"
I am looking for historic data on State and Local Sales Tax Rates (not tax revenues, but actual rates) for 2000 to 2010. I thought such data could be easily available, however I only managed to find the following information for 2017: 
 https://taxfoundation.org/state-and-local-sales-tax-rates-midyear-2017/. 
I need similar data for 2000-2010. Surprisingly, neither IRS nor Census Bureau seem to provide historic sales tax rates. 
","['usa', 'state', 'taxes']",
UK demographic data at full or outer postcode level,"
Is anyone aware of any open UK demographic data (England would be sufficient) at full or out postcode level?
","['data-request', 'uk', 'demographics', 'postal-code']",
Offset not working for VETS4212 data API,"
Both the following URL API calls return the same record despite using the Offset filter:
https://data.dol.gov/get/vets4212dataset/format/json/limit/1/date_column/EndingPeriod/start_date/2015-07-01/end_date/2015-07-01/orderby/asc
https://data.dol.gov/get/vets4212dataset/format/json/limit/1/date_column/EndingPeriod/start_date/2015-07-01/end_date/2015-07-01/orderby/asc/Offset/2
Am I querying correctly?
",['labor'],
Quantitative data on number of insects per area over time?,"
In my surroundings a couple of people / friends have the feeling that the number of insects has declined over a number of years. 
Do you know of any sources of data which give quantitative numbers on insects per area over time for any country in Western Europe, Americas, Australia, where insect can be:

fly
wasps
bees (wild type)
mosquito 
or any similar indicator species?

A time range over more than 20 year would be appreciated. If the data set also included confounding factors, this would be a plus.
It seems that biodiversity measures a slightly different number, and for example I wasn't able to find interesting data sets on the European Environmental Agency's website for biodiversity (besides decline in common birds in Europe).
Any hints or tips where to look or what to search for?
","['data-request', 'historical', 'population', 'environment', 'biology']",
Looking for TRMM data of 4km resolution or more of july 2014,"
I have been looking for this data without much luck. I want TRMM/PR/GPM daily or hourly precipitation data (mm/hr) with a spatial resolution of 4km or more. 
",['data-request'],
Hate speech text data,"
Where can I find a collection of hate speech articles and texts? I have tried using hate speech and offensive language from github but I am looking for long pieces of text (>~160 characters).
","['data-request', 'corpora', 'classification']",
News Article Data,"
I'm looking to find historical news articles (Politics/ Economics especially, eg. CNN, Bloomberg) from the past several years. The articles would need to have time stamps and be downloadable as an archive so that they can be used in a machine learning algorithm. Any ideas where to find such data?
","['data-request', 'economics', 'politics', 'news']","The wayback machine archive.org has coverage for news sites, e.g. CNN. It can be bulk downloaded, see e.g. here, which discusses using wget."
Is there a source for a dataset or WFS of nationwide TIGER Data at the county-level (All Roads)?,"
If you go to the Census Bureau's website there is a web interface to download Primary, Secondary, and All Roads (FTP link doesn't appear to be working at the moment). The All Roads option is only available per county. Does a 2016 dataset or web service already exist, free or not, where all these county datasets have already been compiled together?
",['geospatial'],"You can ""extrapolate"" the download links from the source codeSee javascript function goDownload()and similar functions goDownloadNational(), goDownloadState(), goDownloadCounty().You can see also in the source code where these functions are called (about line 4130 in my version)So you take these two variables, directory and filename, and generate a complete URL with the values from the dropdownbecomes thenwhich works (26 MB).You have to then write a small script that loops over all states and countries and then make a URL based on the formula in each function, and then make the queries 1 by 1 (maybe with a short pause, to not get your IP address blocked)"
Data source for pharmacy directory,"
Where can I find a reliable US national pharmacy database? I need basic info like name, address, if they are mail order, etc.
Does not have to be free.
","['data-request', 'usa', 'medical']",
Search population by city from the US census API,"
I'm interested in know the population by city, but I'm not finding that option on the API. 
Then, what I'm considering is to use the zipcodes to do make the mapping, that information seems to be available from the API:
https://api.census.gov/data/2015/acs5?get=NAME,B01001_001E&for=zip+code+tabulation+area:*
This is a sample of the table:  
+-------+-------+-------+
| 00601 | 17982 | 00601 |
+-------+-------+-------+
| 00602 | 40260 | 00602 |
+-------+-------+-------+
| 00603 | 52408 | 00603 |
+-------+-------+-------+
| 00606 | 6331  | 00606 |
+-------+-------+-------+
| 00610 | 28328 | 00610 |
+-------+-------+-------+
| 00612 | 64816 | 00612 |
+-------+-------+-------+      
As I understand: 
First column is the zip code.
Second column is population.
Third column is zip code tabulation area (ZCTA).
Now, this data is suppoused to not be available on the by zip code, but only by ZCTA, is indicated here.
This is because ZCTA represents actual areas where the population can be calculated while regular zip codes represent a collection of mailing addresses that not necessarily form a polygon. 
My question then is, is it reliable to use the above table t estimate the population by city summing up the values for all the zip codes in the same city?
","['api', 'us-census', 'population']","You could try to accept my comment as an answer (I don't think that's how it's done). But I would think some useful documentation would serve you more than a quick link edit.Here is a link to their API guide. Also, a list of their available survey/data sources and how to build the API links for them. I haven't gone through them extensively, but it looks like a lot of it is there."
How to download SRTM 30m at once for a country?,"
How to download SRTM 30m at once for a country? Is there a path/row file like SRTM 90m?
",['geospatial'],
Inflexible search params with open.fda.gov,"
I'm having the following issues with the Search result limitations with open.fda.gov:

Up to 100 results for single request; and up to 5100 results for single search criteria
No flexible search (e.g. no params to search from ""starts with"", ""ends with"")

Is there any way around these limitations?
",['openfda'],
Is there a historic drug shortage database?,"
I was wondering if there was a historic database of drug shortage data?
The current database (link below) appears to only reflect any shortages that have been resolved in 2017 but does not include shortages resolved in past years.
https://www.accessdata.fda.gov/scripts/drugshortages/default.cfm
","['data-request', 'releasing-data', 'historical', 'drugs']",
Bioacoustic Data,"
I'm looking for bat bioacoustic data. Preferably the data would cover a large geographic scope (i.e., not constrained to a single country/continent). Species data would be very useful, but most important are call counts. 
","['data-request', 'biology']",
"Most efficient way to get the Wikidata entity for a city, given as a string","
The goal is to get from the string ""Lugano"", the entity Q7024, knowing that I am searching for Swiss locations, by name in German.
So far this is how I do it but it doesn't look very efficient.
1) Get entities that match ""Lugano"" in German language
https://www.wikidata.org/w/api.php?action=wbsearchentities&search=Lugano&language=de&format=json
Parsing the result, I get the following entities:
Q7024, Q660612, Q298642, Q34937366, Q661389, Q440182, Q686002
(in reality, I would actually need to continue the search because not all matches are returned in the same response, but for this example it suffices to get the values in the first page of results)
2) Run a query to filter for Swiss settlements among the collected entities in step 1
SELECT ?location ?locationLabel WHERE {
  ?location wdt:P17 wd:Q39.
  ?location wdt:P31 ?settlement .
  ?settlement wdt:P279 wd:Q486972
  FILTER (?location IN (wd:Q7024, wd:Q660612, wd:Q298642, wd:Q34937366, wd:Q661389, wd:Q440182, wd:Q686002))
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". }
  }

That returns the desired entity, Q7024.
Is there a better way to achieve that result, possibly in a single query?
","['geospatial', 'wikidata', 'sparql']","Try it!In some cases, you might be interested in the REGEX SPARQL function. As for efficiency, see  e. g. this question on Stack Overflow."
"Sort results by proximity with the ""around"" service in Wikidata","
With this query, I can get a list of German cities around Berlin, within a radius of 50 km. 
SELECT ?place ?placeLabel ?location WHERE
{
  wd:Q64 wdt:P625 ?arcLoc . 
  ?place wdt:P31 wd:Q515 .
  ?place wdt:P17 wd:Q183 .
  SERVICE wikibase:around { 
      ?place wdt:P625 ?location . 
      bd:serviceParam wikibase:center ?arcLoc . 
      bd:serviceParam wikibase:radius ""50"" . 
  } 
  SERVICE wikibase:label {
    bd:serviceParam wikibase:language ""en"" . 
  }
}

How can I sort the result by proximity in Km, like it is done in this page?
","['geospatial', 'wikidata', 'sparql']",Try it!P.S. geof: is for <http://www.opengis.net/def/geosparql/function/>.
Google Map based on emergency location information,"
I would like to build a google map where I can see the locations of currently happening emergencies like earthquake, storms, wildfire, etc.
Does anybody know sources from where I can get data like that? Especially for Europe. 
Similar services from google itself are available. But not really for Europe.
https://www.google.org/publicalerts
https://www.google.org/crisismap/weather_and_events
","['data-request', 'geospatial', 'europe', 'real-time', 'geohazard']","Regarding the request from philshem in the comments to the question, I will post my comment details as an answer.Disclosure: I am the author of the mentioned website.As a suggestion, as I feel it fits the question and this was migrated from softwarerecs: Currently, I am getting emergency location data up and running and have recently added wildfires and earthquakes as WMS. The services are not free though (services need to be maintained) but the respective data is open data. If you'd like to put it into a cool map app, I'm open to discussing usage options like free use for non-commercial applications. You also might be able to find more data here: www.geodata.one.The data contents include e.g. major volcanic eruptions, major tsunami locations (World); current river water levels, wind speed/ direction, rainfall amount, temperature, severe weather warnings, current radiation values (Germany). Some of the data services are external, some still need to be set up or updated. If there is more relevant data out there, I will definitely add them (suggestions welcome)."
Wikidata - How to get a table with all US cities with associated counties?,"
I did not find existing data of good quality that I can use directly.
I thought that Wikidata was the best source to use and that it would be an opportunity to learn how to extract from this data source.
Seems not so obvious to extract what I want and to deal with the links between all elements, and the different data types.
How to use query.wikidata.org or the REST API to get or construct the table with all cities in the United States with associated counties?
Example of what I want to get (for all the US cities) :
NY; ROCHESTER; MONROE
NH; MANCHESTER; HILLSBOROUGH

If more than one county, I want to list them all (with another separator or multiple lines)
","['usa', 'wikidata', 'county', 'sparql', 'rest']","I do not think that Wikidata is a reliable source in this case.A basic query is here below. 
The first revision of this answer contains more advanced attempt.Try it!In order to show Wikidata's unreliability in this particular case, one should compare this list of counties with more official lists, but please do it yourself."
Registered voters by county,"
i am looking information about presidential election 2016 by county. There is information how many people voted for Clinton and Trump ( https://data.world/aaronhoffman/us-general-election-2016 ) However I cannot find data how many people are registered for vote by county. Do you know where i can find such data?
","['usa', 'elections']","One of our data scientists pointed out that, while not a Census thing, you should check out: https://data.world/data4democracy/election-transparency/ Or specifically: https://data.world/data4democracy/election-transparency/workspace/file?filename=PartyRegistration.csvThis might be helpful if you prefer to stay on data.world."
Availability of data from 3 specific FDA web pages,"
I'm looking at the API references for drugs and for devices, but haven't found answers. I'm wondering if it is possible to return the information that is listed on 3 web pages at FDA:

Hematology/Oncology (Cancer) Approvals & Safety Notifications (https://www.fda.gov/Drugs/InformationOnDrugs/ApprovedDrugs/ucm279174.htm), specifically the approval status, indication, drug name
List of Cleared or Approved Companion Diagnostic Devices (https://www.fda.gov/MedicalDevices/ProductsandMedicalProcedures/InVitroDiagnostics/ucm301431.htm) specifically the drug name, device trade name, manufacturer, intended use/indications
Also from Medical Devices (ucm330711): Nucleic Acid Based Tests - specifically disease name, trade name, test manufacturer

I don't want to screen scrape; openFDA JSON file returns are perfect. 
If these can be pulled from openFDA data, could you point me to the reference information that will enable me to accomplish these data requests?
","['api', 'openfda']",
"UK Postcode Data by City, Town, Villiage","
I have been searching for the last few days and have found a number of datasets but nothing that meets my needs.
Effectively I need a table to postcodes that contain a flag on if it exists within a City (actually quite easy to do manually), Town or Village.
I think this might be a tall order as I don't even think any of the paid sources has the flags that I need, so this is a last resort really.
A flat file would be ideal but an API will also be fine.
","['uk', 'postal-code']",
US agencies forms data set,"
Is there an API or a dataset of all US administrative forms?
I tried many searches without great success
","['government', 'uses-of-open-data']",
A database about transactions?,"
I wish to have a database about some products that their transactions are recorded. So, ideally it has at least the following columns: 

Transaction ID
Customer ID
Date
Product

Any guidance about how I can find this database would be really appreciated. 
",['data-request'],
Worldwide database of locations (cities)?,"
It's the first time I post in this community, I hope my question belongs here.
I'm currently developing an app where a user can add a location to his post, just like Instagram does (or Facebook). To do so, the user could either manually search for a location, or agrees to share his location so the app finds out where he is (geo-loc).
In the backend, for each post, I'll store the location name, location coordinates and a location ID.
I obviously thought about Google Maps in the first place, I then discover that Facebook has a Places API too. They both provide the data I need.
1.I was wondering if there's another API somewhere that could fit my requirements and that would be a bit more open and less intrusive regarding user privacy. I don't need a big precision, I believe only cities would be fine. I would also like to not put any money into that for now, as the app is a side project and might never generate any revenue.
2.Related question but maybe not for this stack exchange community: would it make sense to host a database of all cities myself (if that ever exists), or use an external service ?
Thanks
","['data-request', 'api', 'city', 'geocoding', 'database']","I suggest to try Geonames, which is a well-recognized open database of geolocalized places worldwide. Geonames links the name of places (from hotel to cities) to coordinates (longitude & latitude, in WGS84) as well as other information when available (population, zip code, ...). You can have a look of webservices based on geonames here. Among the webservices, the FindNearby might suit your need:Example here : http://api.geonames.org/findNearbyJSON?lat=49.6842&lng=5.8143&radius=10&username=demoHowever, I don't know how to filter to output only ""big cities"" (and not the smallest populated place). An option is to make a query using a certain radius and then filter by population > your_threshold. As stated here, do not use username=demo in production but create an account. For your second, related question, have a look at the terms of use of Geonames or contact them to check if you can use their services directly or if you have to implement them on a dedicated server. "
"How can I get the PI Label ""Highlights"" (or page 1) of the drug's label","
Are the ""highlight of the prescribing label"" available through openFDA?
","['api', 'openfda']",
Twitter handles for artists/bands/movie stars etc,"
I need to find a dataset of the twitter handles for as many artists, bands and movie stars as I can find. These twitter accounts do not have to be super famous. The most important thing is just that I can obtain the handles. Associated with the handles should be the name of the artist/band. For instance, it could be 'Justin Bieber = @justinbieber'. Does anyone know of a dataset like this?
","['data-request', 'social-media']","Wikidata contains about 90 000 entries with Twitter username.
Also, Wikidata contains about 130 000 entries with MusicBrainz artist ID.
Intersecting these sets, one could retrieve about 17 000 twitter accounts of artists, bands etc.Try it!Related queries"
How to open GRIB data in GIS software?,"
I have downloaded soil moisture files but they are in GRIB format and I don't know how to read them or display them in GIS software like QGIS or Saga GIS.
How can I do that?
",['geospatial'],
Which region has the most granular census data?,"
Which region (ideally, at least city sized) has census data with the finest geographical resolution? 
In addition, which region has the most detailed census data (i.e, most dimensions / categories in data)?
Looking for places outside and inside the USA. 
Census-like (crowdsourced?) data is OK too!
","['data-request', 'geospatial', 'census']",
religious tax exempt addresses in detroit/Michigan,"
I am looking to obtain a full list of all religious institutions that are deemed tax exempt for Detroit Michigan. I have visited there website http://www.detroitmi.gov/ and could not find such a list. Before I file a FOIA request I was wondering if there some sort of database that compiles this information, form a state, county or municipal/city level
","['geospatial', 'taxes']",
Survival rate vs fall height,"
I am looking for the chance to survive a long fall vs the fall height.  If the data takes into account surface, age, gender, it would be even better.
","['data-request', 'medical']",
Data sets for small human written programs,"
Where can I find a data set with large set of relatively small (<500 LOC) computer programs. Programs should be consistent in language used. can be written in any one language (Javascript preferable). 
I do not want large project code bases. Aim is to find small independent programs.
","['data-request', 'software']",Have you tried Github.com? There are millions of lines of code from different programs of varying lengths. Github also has an API. 
Data about worldwide import tax rates,"
Is there a dataset available that contains data about import tax around the world?

Problem with most of such ""data"" is that they come in form of thick booklets full of regulations and nothing to parse
I'm looking for a parseable dataset to get the general idea about import tax rates, single number per country would probably be enough
I'm not interested in the regulatory specifics 

","['finance', 'global', 'taxes', 'trade']",
Business Name to NAICS Code Mapping,"
I am looking for a way to map business name + address to NAICS code. Found few government sites like follows:

http://www.thinkkentucky.com/kyedc/kpdf/All_Facilities_Alpha.pdf
http://www.rcgov.us/Portals/0/Departments/BSC/Documents/2016_BL_Alpha%202016-12-14.pdf
http://www.muncie.com/Site-Selection-Data/Industrial-Directory.aspx

Can someone recommend a more centralized place where similar lists could be found across US?
","['government', 'uses-of-open-data', 'business', 'geocoding']",
Where can I find repeated measures data arising from longitudinal studies involving psychometric tests?,"
Where can I find repeated measures data arising from longitudinal studies involving psychometric tests?
I'm mostly interested in mental health data but I am open to other suggestions.
","['data-request', 'longitudinal']",
Cant find code tables in DOL OSHA enforcement dataset,"
I am trying to find ""code tables"" in OSHA enforcement dataset of the DOL.
Code tables have been mentioned in the inspection table of DOL OSHA enforcement data set:
Column Name       Data Type    Column Description
const_end_use     varchar(1)   Construction - end-use **(code table ENDU)** 
project_cost      varchar(1)   Construction - project cost range **(code table COST)** 
project_type      varchar(1)   Construction - project type (code table PTYP) 

But I have no idea how to get these codes or let alone where are they located...
",['labor'],
NASA live Europe imagery,"
I saw here https://api.nasa.gov the NASA provides tons of public endpoints for browsing data/images. I'm just searching for a webservice that exposes live satellite (hourly updated) images on the Europe. I'm not clear if it's there is something like that or not.
Maybe you know some other webservices?
",['astronomy'],
A free API for rock climbing locations?,"
Is there a free API for rock climbing locations in the UK? What I'm thinking of is an API which gets information along the lines of ukclimbing.com, e.g. https://www.ukclimbing.com/logbook/crag.php?id=457.
Failing that, is it possible to scrape the ukclimbing website?
","['data-request', 'api', 'uk', 'sports']","Kaggle hosts the 8a.nu dataset, which is scraped from the 8a.nu global climbing logbook.This is all of the publicly available information from http://www.8a.nu, the world's largest rock climbing logbook, as of 9/13/2017. Check out https://github.com/dcohen21/8a.nu-Scraper for more information about this project.** Github repo down due to DMCA noticeIn the table ""ascent"", you have 4.11 million records. Each has a field ""country"" where you can filter on UK (ISO 3-letter code is GBR)Registration required to download the data, which is in sqlite format. You can use a library like datasette to build and API from a sqlite file."
"Train/subway accelerometer data, with line/stations metadata (train rider's smartphone OK)","
I need accelerometer history taken by people riding urban trains or subway.
Ideally more than 10 minutes of riding, and more than 20 samples for each train line.
The name of the train line, and the time at which each station is reached, should be available for each file.
Some noise will probably result from people handling their phones or moving a bit in the subway, that is not a problem.
","['transportation', 'public-transport', 'accelerometer']",
Looking for historical weather forecasts,"
I am looking to write a report about the accuracy of weather forecasts. I have already found several source that provides data for actual weather in different locations, but I am having difficulty finding data about weather forecasts in the past. I would like to find a site that has this data available.
","['data-request', 'weather', 'historical', 'internet']",
Google Trends data at county level,"
Does anyone know how Washington Post has managed to source Google Trends data at county level for this map?

Here's a state-level query for Kansas. The geographical response is by metro.

In the (unofficial) API response this data is labeled interest_by_dma (designated market area), which is more granular than state level, but less than county as per Washpost's map.
I've heard that Google does not sell Trends data. Assuming this is right and Washpost does not have some private arrangement, does anyone know how they might have sourced this data?
","['usa', 'county', 'search-engine', 'trends']","While I don't work for The Post or Google, and thus cannot speak authoritatively, I was at a Google event for top news organizations last year in NYC, and can attest to the fact that -- depending on the publication -- Google often provides custom Trends data as an enterprise service to publishers. That would be my guess here."
"Looking for precipitation scans (radar) for Germany, 5 min intervals, >= 1 a","
Maps like this ...

... are based on radar precipitation scans. Germany recently changed its law governing the German national weather service (DWD) and made it publish a lot of its data on a new open data server. Precipitation scan data is for instance offered from 17 sites in 5 minutes intervals in down to a 250 meters raster for the last 48 hours for free here. 
I'd be interested in having this kind of data for longer periods of time, one entire year at least, if possible, for non-profit experiments & research. 
Are there any known services which offer the described data for download in some form? Quite a few private weather sites possess archives of this kind, however all of them explicitly exclude bots and (naturally) prohibit crawling this data off their websites.
I'd love to have the full 5 minute interval data instead of down-sampled or averaged data (e.g. per day), being aware that for Germany and one year the size of the overall raw data set would land anywhere between 50 and 100 GByte (based on what I can extrapolate from what I see on DWD's open data server).
","['data-request', 'weather', 'meteorology']",
Do post-2010 American Community Survey data rely on the 2010 PUMA boundaries?,"
From the census page on gazetteer files, only 2010 contains data for public use microdata areas. 2012 and onwards have other files but nothing on PUMAs. Are PUMA boundaries redrawn once a decade?
",['census'],"The US Census Bureau's statistical areas are only redrawn once each decade, including the PUMAs. Even through the census tracts and ZIP Code Tabulation Areas appear in each year of the gazetteer files, in reality they are only redrawn once every ten years (although it's possible they may update them to fix errors and make small adjustments). The boundaries that can change each year are legal ones (like counties and places) or ones defined by other agencies (like metro areas, designated by the OMB).The PUMAs are a bit out of synch with the other statistical areas; most statistical geographies are redrawn and published with each decennial census, but new PUMA boundaries are usually released a couple years later (since summary decennial census data is not tabulated at the PUMA level; PUMAs are used for the American Community Survey summary data and for microdata from both series).I checked those gazetteer files and the PUMAs listed under 2010 are the current boundaries; it's easy to tell because they have ID numbers and names. In contrast the 2000 PUMAs only had id numbers.Here are a couple of good resources that describe the 2010 PUMA geographies:https://www.census.gov/geo/reference/puma.htmlhttp://mcdc.missouri.edu/geography/pumas2010.shtml"
"Spatially Orienting 1,4 Dioxane Data From the EPA UCMR-3 Data Set","
I am attempting to draw conclusions about the source of 1,4 Dioxane, an emerging contaminant. In the last few years, the EPA released the UCMR-3 (Unregulated Contaminant Monitoring Rule) which had every large or medium sized public water supply test for the contaminant I'm interested in, 1,4 Dioxane. So I have a tremendous amount of data but there is no spatial references, no addresses to place it onto a map. I tried looking up each one individually through the EPA SDWIS or safe drinking water information system, [https://iaspub.epa.gov/enviro/sdw_form_v3.create_page?state_abbr=NJ] and got some addresses but that would take forever since there 1400+ columns (representing samples) for New Jersey alone. 
The question I am asking most simply is how can I get this EPA data with no addresses onto a map? I figure I have to find a list of addresses for public water supplies related to this UCMR data, if any exist? Need help.
","['data-request', 'geospatial', 'data.gov', 'uses-of-open-data', 'metadata']",
"Data for ""Proximity to Green Space"" in United States","
Is anybody aware of a dataset or API that will return 'proximity to green space' if given a zip code or lat/long?
I'm not sure how proximity would be measured, but there exists something similar for 'walkability'. In short, a walkability score will grade a location on a 0 - 100 scale where 100 means there are many shopping, grocery, park, transportation, work, etc. options within walking distance. An NYC neighbourhood would be very walkable while a rural farm might have a very low score.
https://www.walkscore.com
I'm looking for the green space equivalent of the walk score if it exists. In other words, I'd like a metric to score how close a location is to parks, forests, green traffic medians, arboretums, etc. Alternatively, I can come up with my own metric if there was a raw dataset available.
","['data-request', 'usa', 'api']",
Crime statistics by city in Ukraine,"
I'm searching for a crime statistics by city in Ukraine, especially murder rate. The other crime statistics are also good, though.
I couldn't find it in English, so it would be welcomed if it is in Ukrainian or Russian languages.
Does anyone know if/where I can get it?
","['data-request', 'crime', 'ukraine']",
Is it possible that there is only one patient < 16 y/o in entire MIMIC 3 database whose data was recorded by metavision data recorder?,"
Try this code:
SELECT ie.subject_id, ie.hadm_id, ie.icustay_id,
    ie.intime, ie.outtime,
    ROUND((cast(ie.intime as date) - cast(pat.dob as date))/365.242, 2) AS age
FROM mimiciii.icustays ie
INNER JOIN mimiciii.patients pat
ON ie.subject_id = pat.subject_id
WHERE
ie.DBSOURCE = 'metavision'

all adults... why  ?
did I do mistake ?
",['mimic-iii'],
Are there any automated techniques one can use to gather data online for a dataset?,"
I am a developer myself and would like to use latest technologies to build some open data datasets.
I would like to know if you are aware of any techniques or algorithm one can use to automate gather data on the internet instead of manually doing something following,

Google search and then trying to gather data
Put in Excel
Clean data using whatever language you require

I am fairly new to this so I might be thinking it completely wrong.
",['web-crawling'],
OTC Pink Sheet Merger Acquistions,"
I was wondering if you may know of :

Databases that can be used to research up and coming future merger deals for companies that are listed in the OTC Market Pink sheets?
I am having a hard time finding something simple  with this type of information to study.
It would be very much appreciated for any information regarding Shell companies acquired, in order to follow in real time the effect it has on their market prices.
How to go about effectively measuring the good deals from the bad ones?In other words, what to look for to determine ahead of time if it most likely will be successful or not. To weigh against the ultimate conclusive result.

",['data-request'],
Data on user-user trust ratings and user-item ratings,"
I am doing a research project on Recommender System, where I need data of user-item ratings and user-user trust ratings. Publicly available similar datasets are

Film trust dataset
Epinion dataset 

Both have user-item ratings but don't have user-user trust ratings; instead they have user-user trust statement. Also they only contain positive trust statement and don't have negative trust statement.   
The difference between statement and ratings is, statement can only have value of 1(trusted) or -1(not trusted), but rating will have values in range 0-5 or 0-1. 
So is there any prior work on this type dataset and where can I find these type dataset?
","['data-request', 'machine-learning', 'research', 'trust']",
Where can I find data on GDP of US counties?,"
I am looking for data on the total GDP of most or all United States counties. (GDP per capita is fine too, I can multiply it by population). I am not sure if this data exists, but I know there are definitely sub-national statistics on GDP, for example, there is data on GDP of each individual state and for most Metro Areas in the country. 
Also, income and GDP are different. This wikipedia article is the closest thing I've been able to find, but it lists counties by their income per capita, not GDP per capita. You can tell, because they have it listed per state as well, and if you multiply the income per capita by population, it doesn't come anywhere close to the state GDP for most states. 
","['data-request', 'usa', 'county', 'gdp']",The Bureau of Economic Analysis released the first official GDP estimates for the county level in December 2019:¹
How to link a new dataset to an existing dataset?,"
I have to construct a dataset of hospitals.
For each hospital, I will indicate the the town/region in which it is located.
I already have dataset of towns/regions of the concerned geographic area.
In order to not repeat informations about towns/region in my new hospital dataset, I wonder if is it possible to be linked to my existing towns/regions dataset.
Many Thanks.
","['geospatial', 'government', 'releasing-data', 'linked-data']",
How to find out sub soil moisture from Satellite Images?,"
Want to find out sub soil moisture from Sentinel or any other satellite images. But don't know the process exactly. 
",['geospatial'],
Torrent for the fastText pre-trained models?,"
I would like to download the pre-trained models for ~100 languages, which are ~3GB each.
(See https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md)
Is there a utility or .torrent somewhere for this?
","['nlp', 'language']","A torrent would be more robust, but here is a workaround download.sh for now:For example ./download.sh bg el ka hy ru fa es fr de it pt ar tr pl koIf stopped it will not re-start automatically, but if re-started it will continue from where it stopped."
Iraq IDP/Refugee Camps,"
Where can I find an updated data set on refugee and internally displaced camps in Iraq? UN OCHA has one from 2014, but it's too old. REACH has one but it holds no geographic information. 
I'm working on a triangulation project, so coordinates -- or enough present info to scrap coordinates from the web -- are important. Any ideas?
","['data-request', 'geospatial', 'releasing-data', 'global']",
Download OpenOffice/Hunspell dictionaries (.oxt / .dic+.aff) for many languages at once?,"
I would like dictionaries for the top ~100 languages or so.  Manually searching and evaluating the results at https://extensions.openoffice.org is quite cumbersome at that scale.
Is there a command line utility, .torrent or some other way to get dictionaries for all the major languages or for languages specified programmatically by locale?
","['nlp', 'language', 'global', 'corpora', 'dictionary']",
API/machine access for Gapminder data?,"
I'd like to be able to access the Gapminder files programmatically (e.g. via R or Python), but I can't find a way so far.

Gapminder's downloads page offers a variety of tools and charts, but nothing for programmatic access (that I can tell)
their data page is clicky.
there's some discussion of the possibility of an API on their community support page, but nothing concrete
someone wrote a Python app, but I have to admit that I don't really understand how to use it (I have installed it, and can run python3 app.py after that, but that's as far as I get ..)
this web page has a promising name, but it's a description of an R package that contains a little bit of downloaded Gapminder data

There's a nice R package for accessing World Bank data that overlaps with the data I want, but Gapminder seems to have stuff that isn't included in the WB database (e.g. GDP per capita 1950-1960).
... thoughts ... ?
","['api', 'demographics', 'global']","I downloaded http://www.gapminder.org/data/ after choosing ""ALL"" and noticing the spreadsheet links end in ""output=xlsx"". I changed the xlsx to csv to see what would happen, and did, indeed, get CSV files as expected. More specifically, I ran:perl -nle 'while (s/href=""(.*?)""//) {$x=$1; $x=~s/\&amp\;/&/g; print ""curl -LO \47$x\47""}' gapminder.html | fgrep xlsx | sed 's/xlsx/csv/' | shzipped the results, and uploaded them to https://www.dropbox.com/s/r77tfdjt1lzkn56/gapminder.zip?dl=0The only problem is that 519 files I thus obtained have weird names, so you may need to figure out which file is which."
"What are some presentations that delve into the changes in academic publishing toward open access, pre-print archives, etc?","
I am looking for slide desks, infographics, conference presentations, or blog posts that tease apart the shifting landscape of academic publishing and the ongoing battle between the ""old guard"" traditional publisher, and the range of new models that are being advanced, usually under the banner of ""open access"". 
My objective here is to provide a balanced primer to my colleagues at an academic institution. I'm looking for sources that give a fair hearing to different view points, and that have nice figures I can reuse.
","['publishing', 'open-access']","The community that certainly has specifically what you seek is SPARC. In particular their open access section and its Open Access Impact Stories. It may be fruitful to ask this question in their google groups forums: SPARC OA Forum and SPARC Libraries & OER Forum.  Here's a non definitive list of open access resources that you can use too:
Open Data Access Policies and Strategies in the European Research Area and Beyond
Ope Access, Open Education Resources and Open Data in Uganda
Open Access and Open Data: Similarities and Differences
Open Access and Open Data: What Do I Need to Know (and Do)?
After Bill Gates Backs Open Access, Steve Ballmer Discovers the Joys of Open Data
Open Access, Open Data, Open Research? The challenges and opportunities of enabling public access to publicly funded research
Open Data and Reproducible Research - Open Access at Nature Research
Open Access and Open Data - Stanley Wood, Bill and Melinda Gates Foundation
Open Methods, Open Data, Open Access
UMass Medical School Open Access Guide
Open Access, Open Data, Open Science...What Does ""Openness"" Mean in the First Place? "
What are open source projects for setting up an academic pre-print archive?,"
The only one I know of so far is OSF pre-prints: 
https://github.com/CenterForOpenScience/ember-preprints
","['publishing', 'academia', 'open-access']",
Need some domain knowledge,"
I am looking for some BD (Business Development) help. 
I am building a product that does sentiment analysis. 
I want to know which domains in the internet space (for which there are online/offline ""reviews"" from users available) I can cater my product to for their review analysis needs. 
",['sentiment-analysis'],
Aspect Based Sentiment Classification,"
Are there any services which provide aspect-sentiment of the sentence? 
If the sentence/review is talking about multiple aspects, all the aspects with their sentiments (Positive, Negative, Neutral should be the classes) are expected in the output. 
I'm looking for something which is more cognitive than just a key word based engine for aspect (umm, may be using word vectors?) and more than just fixed lists for sentiment classification (like using robust ML and NLP techniques here). 
Please let me know of all the products that do the job (I can provide the data). 
","['machine-learning', 'nlp', 'sentiment-analysis', 'classification']",Have a look at this http://xpresso.abzooba.com/XpressoOnWeb/ for aspect based sentimental analysis.
Corpus of words divided by language,"
I am looking for a word dataset composed by lists of words of multiple languages (possibly all the major languages), non topic specific, divided by language.
I don't really care for translations, meanings, alternative forms, pronunciation or anything else. However, I would need an offline dataset.
Do you know if any such dataset exist?
ps: I have seen the Multilingual Wordnet site at http://compling.hss.ntu.edu.sg/omw/ however it is missing some important languages like German, Russian and Korean.
","['data-request', 'language', 'global', 'corpora', 'dictionary']","If you are just interested in words (and not translations) you can check out Wortschatz at Universität Leipzig.An alternative (with very different coverage across languages, but actually providing translations) is the Wiktionary."
Is there a metals corrosion open dataset?,"
I am looking for a dataset to contain environment-metal details such as: humidity, temperature, chemistry, stress, erosion.
Is there a metals corrosion open dataset, or one from which you could get such data?
","['climate', 'technology']",
Is there a crosswalk between U.S. Census 1990 SF3 and 2000 SF3?,"
Is there a source that compares the tables from the U.S. Census 1990 SF3 and 2000? Something like the data provided in this Census 2000 to ACS5 comparison tool.
Some information is provided by Columbia University Library. The Longitudinal Tract Database also provides limited table level crosswalks in their codebook.
","['usa', 'us-census']",
Need Tagged Data sets for training ML algorithms to classify sentences/reviews into single/multi classes,"

Need tagged text data of any domain. Preferably generalized and ubiquitous domains such as ""Food & Hospitality"" (Reviews about the quality of the food, comments about the ambience and service etc. This can be found in reviews for restaurant websites or food delivery and review sites like Zomato). 
More Details :
Each review might be classified into various classes*. This makes it a multi-class classification problem. 
Classes* - Important ""aspects"" that the review is talking about. 

For example 

Here I also mentioned the Sentiment Column (Which is 3 class, Positive, Negative and Neutral). Typically every domain, a broad class of aspects would be decided and tagged. 
Can anyone link me to good data sets that meet the requirement? I will be needing hundreds of thousands data. The more, the better. 
Or suggest me an alternative way ? 
","['data-request', 'machine-learning', 'nlp', 'classification']",
Database of user agents,"
I'm looking for list of web browser user agents for testing purposes. Ideally in some common text format. Especially for the desktop and mobile devices.
",['software'],"The User Agent Project is a research project consisting of a comprehensive list of unique user agent strings compiled since 2006. The UA Project is accessible as a specialized search engine.  Browscap's repository includes a User Agent Database Resource, althouth the wiki hasn't been updated since 2015. Browscap has had updates as recently as 2017-06, but that includes the entire repository, not just the ua db.  Udger UA List Database ""includes detailed information about ever(y) single user agent and operating system"".  User Agent String.Com has a large list of user agent strings by ua type, and offers an API User-Agents.org has a List of User-Agents (Spiders, Robots, Crawlers, Browser) in XML format, as well as a search database and some other offerings.  "
Does anyone know where to get the disaggregated data from the 2013 Consumer Expenditure Survey by the Bureau of Labor Statistics?,"
I am doing research in econometrics and am in need of the disaggregated data from the 2013 Consumer Expenditure Survey. I would like to analyze it using R.
When looking for the data on the Bureau of Labor Statistics website I was unable to find it. I contacted them and got a response that essentially amounted to ""it's on there"" yet I still can't find it. Does anyone know if there is another source of this data?
","['data-request', 'spending']",
Looking for lots of real texts written by humans with user-metadata,"
I am an NLP researcher and for the purpose of my ongoing work I need lots of textual data produced by real human beings. It's probably not so hard to obtain, but it's important that it's also contains user meta-information like gender, age, country, education, native language and so on. Topic preference is common talk.
I would be grateful for a link to such datasets or any ideas of how to harvest such a data.
","['nlp', 'social-media', 'text']",
Where can I find USA ocean port FIPS code?,"
I am interested in all of the FIPS codes for USA ocean ports. For example, ""PORT_New Orleans, PORT_Houston"".
What I have for now: I have all the lat & lon for the port. I know I can reverse geocoding from lat & lon to FIPS, but I am still interested in other methods.
","['usa', 'geocoding']",
Where can I find a database that contains all the airline companies with their alliances and if they are low cost or not,"
I am looking for a database that contains all the airline companies alongside the alliances that they belong to, and if they are low-cost or not.
So far I found this Airport, airline and route data but it doesn't seem to give the information on whether the compagnies are low cost and to which alliance they belong to.
","['data-request', 'geospatial', 'transportation']","Try this query on Wikidata:The values in the affiliateLabel column are coalesced from the values of these  properties:Try this query, if you want to get the values of these properties separated.As to low-coster status, the data is obviously incomplete. For instanse, wd:Q18398469 is definitely a low-coster."
Open news dataset regarding downsizing and employee layoff,"
I am looking for open news dataset related to downsizing and employee layoff.
I have looked up Reuters and BBC News datasets but their categories are quite broad. Can anyone please suggest any resources for the same. I am trying to scrape various news sites but this will take a lot of time to get a good amount of data. 
","['data-request', 'companies', 'news']","I have scrapped few sites likes Techcrunch, Reuters , Bloomberg and few others and collected the articles related to Employee Layoff. The dataset is not that big but have around 320+ articles. Anyone is welcome for the contribution. The link for same is:
https://github.com/prayalankar2/Employee_Layoff_News_Dataset"
Alternatives to ImageNet,"
I'm interested in freely available crowdsourced images with semantic tagging similar to what ImageNet provides. Are there any alternatives to ImageNet here?
Update: I just found NEIL http://www.neil-kb.com/ but it doesn't seem that open. There's only one training set from 2013 available. Anybody knows if its trained models are available for download?
","['data-request', 'imagenet']",
Next College scorecard update release date?,"
Will the next college scorecard update be released before the 15th September? I need to know for a project I am working on. 
",['collegescorecard'],
Seeking current global cloud cover data?,"
I'm working on a project to check variation of UV index with cloud cover. I'm trying to get the cloud cover data which I'll be using to plot the graph. I've historical data which I got from MODIS (MOD06_L2). But it doesn't has the current(today's) data. The closest date for which they have the data is 4 days back. Does anyone knows of any reliable source where I can get this data  ? It will be better if the source has hourly data for cloud cover.
","['data-request', 'weather', 'noaa']",
Limit the array of drugs in openFDA,"
Hello I am messing around with openFDA and was wondering if its possible to search for a medicinal product and only return objects with one drug in the array.
For example when you search for a drug, some patients have multiple drugs in the array. Some have up to 30!

Is it possible to search for patients who only have 1 object in the drug array?
This is what I am using to search for the medicinal product
search=patient.drug.medicinalproduct
Anyone know if this is possible?
Thanks!
",['openfda'],
"Trying to get college SAT scores from http://api.data.gov/ed/collegescorecard/, unable to form query?","
I need to get SAT related data for colleges but using the SAT related parameters I am not getting the data back. It is giving me an error i.e. invalid field, is this data not exposed under Schools endpoint?
Here is my query.
",['data.gov'],
Get historical data of the S&P500?,"
I'm looking for data of the S&P 500; The data should have the following properties:

It should contain all daily returns of the past 6 or 8 years for all stocks included in the S&P500 - so not just the daily returns of the S&P500 itself;
It should have a format I can process in Matlab (my favourite) or R

Any idea where to get it for free? 
",['data-request'],
Grocery products per year,"
I'm looking for historical open data on food products you can find in supermarkets (like the data available on openfoodfacts.org).The idea would be to know which products have been commercialized in 1990, 2000, 2010... to study the evolution of palm oil in food composition. 
","['data-request', 'historical', 'food', 'global', 'products']",
Seeking shapefile of unincorporated areas (US)?,"
I've been working with TIGER/Line shapefiles of CDPs/towns/cities, and want to fill in the empty areas between these places with shapes of those unincorporated areas well. So far, I've been unable to find shapefiles of the unincorporated areas at a national scale. Are these available to download in one dataset?
","['usa', 'geospatial', 'census']",
Using Wikidata to practically leverage semantic linked data for content annotations,"
I swimming the huge sea of semantic Web and Linked Open Data (LOD) to use these knowledge bases for annotating semantically biological experiment of my organisation. 
My idea consists of:

RDF-izing my local biological experiment data in my triple store
linking them to references which point to LOD
If some concepts are not available as LOD, completing my virtual KB locally, by creating other types and properties in my triple store linked to the LOD cloud.
Analyzing data through federated SPARQL queries, to leverage my virtual KB (= local data of points 1,2 plus external LOD of point 3)

In principle, that's is exactly one of the use cases LOD were created for but, practically speaking, there are some issues to tackle.
Issue 1: are federated queries scalable for the real world problems? 
Issue 2: There are many linked data vocabularies out there in the LOD Cloud. In this day and age, it is very huge and covers many fields of Life Sciences, but some of such datasets are out-of-date or do not have a SPARQL endpoint to perform federated queries. They seem not very stable.
One alternative, is using semantic stable hub like Wikidata as the principal external KB. Wikidata is a general purpose KB but it seems very active. 
Could be a valid opportunity or are there other design patterns for LOD usage?
","['uses-of-open-data', 'research', 'linked-data']",
Annual average humidity by country,"
Is there any source that aggregates average humidity around the world by country? Ideally I'd want annual or five-year averages. NOAA seems like it might have something buried in its labyrinthine website, but I'd rather not deal with their 'check out' data request system when I want data for 100+ countries.
","['weather', 'climate', 'meteorology']",
Micro-finance data set,"
I am looking for the data sets on micro-finance institutions per country. I have tried to find it in the World Banks data base but I couldn't find anything. 
","['finance', 'economics']",
Various Country Statistics,"
In Wikipedia articles of countries a lot of statistics are given about the country at hand. For example in the Venezuela article, demographics are described in terms of ethnic groups (e.g. 51.6% are Mestizo), religion (71% catholic), and total population size and population density. There is GDP statistics, Gini-index, Human Development Index, and more.
Is there any openly available dataset with this type of data for many/all countries?
I'm of course aware that there is going to be some missing data within such a dataset.
","['data-request', 'global', 'wikipedia']","World Statistics provides the following links:Software/servicesOther sourcesThe World Factbook.The World Factbook is in the public domain and may be used freely by
  anyone at anytime without seeking permission. However, US Code
  (Section 403m) prohibits use of the CIA seal in a manner which implies
  that the CIA approved, endorsed, or authorized such use. National MasterYou may not use any robot, spider or any automated or manual device to
  monitor or copy any aspect of this site (including content) without
  the NationMaster prior permission, unless your purpose is to index the
  content for a traditional search engine (eg. Google, Bink, etc). You
  may not replicate, modify, reproduce, publish, distribute, display or
  transmit any portion of this web site, except as permitted in this
  document."
English / Swedish translation data?,"
I'm looking for a dataset similar to the ""parallel data"" (i.e. one file is English and one file is Swedish) found in the WMT translation task. Their datasets include news commentary, European parliament proceedings, and more. Is there a similar open dataset that has parallel translation data for English and Swedish?
","['data-request', 'language', 'translation']","Check out OPUS, an open parallel corpus.OPUS is a growing collection of translated texts from the web. In the OPUS project we try to convert and align free online data, to add linguistic annotation, and to provide the community with a publicly available parallel corpus. OPUS is based on open source products and the corpus is also delivered as an open content package. We used several tools to compile the current collection. All pre-processing is done automatically. No manual corrections have been carried out.Example - http://opus.lingfil.uu.se/bin/opuscqp.pl?corpus=EMEA;lang=sv"
Human name country wise corpus,"
Where I can get the human name corpus country-wise, so that I can use it for training my neural network for detecting the human names out of the string.
Does anyone have idea of this?
","['uses-of-open-data', 'corpora', 'names']",
"LCD/OLED Historical Resolution, Size and Prices","
We are looking for historical data on the resolution, size and prices of LCD and OLED displays (consumer or business). 
We are able to find current prices and also historical prices. Ideally, we would like to see the price per centimeter at a given resolution going back to the birth of each technology.
","['historical', 'prices', 'technology']",
Free real-time source for satellite image,"
I am interested to apply image processing for analyzing image map. However, I require a real-time source to follow any change during a given time period. Can anyone introduce any online and free real-time source to work with?
I need these image to detect the source of the dust.
","['uses-of-open-data', 'geospatial', 'environment', 'real-time']",
Accessible source of social network chat data,"
Are there any accessible source(s) of actual chatting text between users of any social network? There exist other conversational corpora (for instance, the Berkeley Restaurant Project corpus is one). But what I am looking for is the access to a data source from a normal social networking site/app (similar to Facebook, Skype, etc.) that includes the conversation history of its users (with unique ids for users to differentiate them). Essentially, it will be the text that the users (within that particular social network) themselves write in their chat boxes.
","['data-request', 'nlp']","I've found the below link to some conversational data sources, may not be facebook, whatsapp etc but should do. http://freeconnection.blogspot.co.uk/2016/04/conversational-datasets-for-train.html"
Dataset of bodybuilding exercises,"
I am looking for a dataset of bodybuilding exercises that list which muscles are activated for each exercise in a machine readable way.
","['data-request', 'sports']",
Cannot access to the OSM Boundaries website,"
I was using the OSM Boundaries website to download shpfiles of boundaries and using them in QGIS:

Today, when I was attempted to access this website I get this message and I get the same result from the Wiki link.
 
I did not get this message from other OSM website, like this one that have shpfile of big cites around the world. 
Can anyone help?
Thanks 
","['metadata', 'openstreetmap', 'reliability']",
Child facial image dataset,"
I am looking for a face-image dataset of children. I have found one for facial expression: CAFE - The Child Affective Face Set. Another possibility is to use an AGE based dataset, such as Large Age-Gap, and keep only the child images. However, I would like to know if there is any other complete and better dataset.
A possible use of this database is to develop child identity recognition, such as this one.
",['faces'],
Where can I find historical county level daily NDVI data?,"
I'm looking for historical normalized difference vegetation index (NDVI) by county for the past 20 years. Preferably in csv or other simple format, but I can build a scraper as well. 
","['data-request', 'agriculture']",
Finding Spatial Data for US Metropolitan Statistical Areas,"
I am looking to map (US) Metropolitan Statistical Areas, but do not have a source for the Spatial Data needed to do this.   Can somebody point me to a public data source? 
",['usa'],
Sharing Genomic data/docker files via P2P network,"
Genomic data size has reached volumes to the point, some NCBI has stopped taking certain types of data from Investigators. Other openData projects are also running into barriers..
I know there are tonnes of open source Bittorrent projects: https://github.com/search?o=desc&q=topic%3Abittorrent&s=stars&type=Repositories
What I am wondering is if there is any upperlimit on the file storage that bittorent can handle efficiently?
I know that there are issues regarding seeding, i.e. a lot of users will leech files and stop seeding. Which is probably a major roadblock to adoption of this technology. Has this issue been solved? Is there a way to enforce a certain ratio of upload to download?
Are there any other technologies other than bittorrent that I should look into?
","['uses-of-open-data', 'bittorrent', 'genome']",
OS VectorMap Local Layer Definition Files,"
Would anybody be kind enough to share their QIGS Layer Definition Files for the following OS VectorMap Local layers. SLD file formats would work as well. Alternativly, where do you buy your OS VML data from? The site I got mine don't have the files I need yet.
Boundary_Line
Building_Area
Building_Line
Building_Text
Countour_Line
Height_Point
Height_Text
Landform_Area
Landform_Line
Misc_Text
Point_Misc
Road_Line
Road_Text
RoadCLine
Settlement_Area
Settlement_Line
Vegetation_Area
Water_Area
Water_Line
Water_Point
Water_Text
Woodland_Area
","['geospatial', 'data-format']",Here is a link to the official Ordnance Survey Stylesheets hosted on Github. They also do ones for VectorMap District which is the open data versionhttps://github.com/OrdnanceSurvey/OS-VectorMap-Local-stylesheets 
Seeking habitat data for UK,"
I am currently looking to analyse the effects of habitat on animal movement and was wondering whether there is any freely downloadable high resolution (preferably <10m) habitat raster data (e.g. woodland, wetland, grassland etc) for the UK, specifically Devon?
If not, would anybody be able to direct me to a tutorial to create my own raster map of these features?
","['data-request', 'geospatial', 'images', 'uk', 'biology']",
Public datasets for Text summarization,"
I'm looking for raw text datasets in HealthCare domain (scientific journals, articles, etc..) for Text summarization.
Where can I get such data (publicly distributed)?
","['data-request', 'machine-learning', 'medical', 'research', 'text']",
Looking for datasets of complaints/requests filed at municipalities or cities,"
I'm looking to do some text analysis on complaints or requests filed at cities or municipalities.
The data must have:

type of complaint (e.g. ""Noise complaint"")
complaint text (e.g.: ""The people in the building across from me are having a party"")

It would also be nice if there's more meta-data, such as:

time of complaint
location
responsible department (e.g. ""Police"" or ""Fire dept."")
response (e.g. ""warning issued"")
time of resolution

So far I've found various 311 datasets (such as the New York one), but none of them contain the actual complaint text.
Preferably the data would be in English, Dutch or German, but I'll take what I can get.
","['data-request', 'city', 'legal', 'text']","US City Open Data Census results for Service Requests should have what you need. And there's always Open 311, though I'm pretty sure its implementers will overlap with the census results.  There is also Open Referrals, an initiative developing common standards and open platforms for the sharing of community resource directory data — i.e., information about the health, human and social services that are available to people in need. More background information:
 Introducing Open Referral: Open211+Open311 protocols for health/human/social services and Open Referral Initiative: A Standard for the Safety Net."
Extracting Residential Building (UK Datasets),"
I am working with building polygon data of a city in England. The data are from EDINA Digimap's Topography Mastermap. I extracted the 'Building' attribute from 'DescriptiveGroup' fields to get buildings polygon. However, I need to filter the residential building only.
Doses anyone know any resource to get the residential filter for UK datasets?
",['uk'],"Before I start THIS IS NOT OPEN DATA. You will need access to Ordnance Survey products, either through your employer or academic institution. However all the techniques have wider applications which apply to open datasets.Using the correct techniques you can extract a lot of information from Ordnance Survey Mastemap Topo when it is combined with other data.E.g. Show me all residential buildings over 18m tall (draw your own conclusions)This method uses a database but it could be done with shape files and text files but a database have other advantages for further analysis.To answer your question you will need the following:Method:At this point you have a number of options. You could then perform a select query on class to find residential properties or one of the many address classifications included in Addressbase. You can also symbolise on code which may be much more useful as if you colour each class differently or use the field calculator to aggregate the classification into much broader classes (I usually do this at the load stage using Pentaho)If you also download the building height data and join it using Toid you can then identify all the high-rise buildings in your area. Combined with Addressbase this lets you produce an address list of all these properties.A minor caveat of this is that the height data was published in December 2014 and hasn’t been updated.If you need more detailed classifications can I sugest taking a look at ukmap from Verisk http://www.geoinformationgroup.co.uk/ukmap which has much more detailed classifications than provided by Ordnance Survey, although for a much more limited coverage"
Scanned architectural building plans,"
I am trying to collect architectural buildings plans for some computer vision project. Many cities publish scanned house plans as a service to the public, but it is not standard and not trivial to collect.
Is there a large dataset of scanned plans? It does not have to be of houses for sales or from a specific place. Alternatively, are there open data services of house plans that would be easy to sample from?
","['data-request', 'images', 'city']",
User-Movie Ratings,"
Is it possible to get ratings per user, per movie, for Hollywood movies?
For example, OMDb API and themoviedb let users rate each movie. Can I get per-user, per movie ratings for a DB like this?
","['data-request', 'film']",
"Last.fm's track.getTopTags method, and what it retrieves","
I'm interested in using MSD's Last.fm database, but I'm unsure what, exactly, is represented by the tag counts associated with each track.
I know that each track-tag pair corresponds to a number between 1 and 100, but how is this number derived? I need to know if it would be redundant to calculate a measure of association for the tracks and tags.
EDIT: 
Link to the Last.fm Dataset.
Link to the track.getTopTags method in Last.fm's API.
",['music'],
Where can I download a dataset including longitude and latitude coordinates at a city level,"
I am looking to download a dataset with longitude and latitude coordinates for each city in the world. The systems data I am working with has geo_country (3 three-letter country codes), geo_regions adn geo_city and I wondered if ISO or equiv publish a table which has all combinations of these 3 columns, including the longitude and latitude coordinates of each city? 
","['geospatial', 'city']",
Are there military conflict open databases?,"
I want to make worldwide annual summary on military conflicts intensity.
",['military'],
Where can I find county-level land area?,"
I'm looking for U.S. county-level land area (sq. miles) per 1990's. The U.S. Census provides gazetteer files for 1990, 2000, and 2010. I need data from 1950-1980. Where can I find this data?
This is what the gaetteer files look like:
    fips land_sqmi
   <chr>     <dbl>
 1 01001   594.436
 2 01003  1589.784
 3 01005   884.876
 4 01007   622.582
 5 01009   644.776
 6 01011   622.805
 7 01013   776.829
 8 01015   605.868
 9 01017   596.531
10 01019   553.700

","['usa', 'us-census']",
Coordinates of Icelandic warm/hot springs,"
Is there a list of warm and hot springs in Iceland, with latitude, longitude, and perhaps temperature (range)?
Íslenskar orkurannsóknir (Icelandig Geosurvey) publishes a geologic map (Jarðfræðikort / Berggrunnskort) including warm springs (laug; 25–50°C), hot springs (50–75°C), hot to boiling springs (laug eða hver; 75–98°C), and boiling springs (Suðuhver; 98–100°C).  The paper map is published at 1:600,000, which is not really accurate enough to locate a spring in the wild.  The springs are also shown in their online map, but that map allows coordinates to be retrieved only down to two decimal degree places, which translates to a 1.1 km × 0.5 km area.  For a spring that may be less than 10 metre in diameter in a possibly rugged wilderness area, that is rather large.  Google Search yields mainly tourist websites that all list the same ""secret"" hot springs, which just happen to be colocated with outfitters and other commercial exploitation.  Openstreetmap does not have the remote springs, nor does this old topographic map series.
I am particularly interested in the ones near Hofsjökull.  From the linked geologic map, I succeeded to derive the list: 18.74°W, 64.97°N; 64.98°N; 18.34°W, 65.03°N; 18.28°W, 64.92°N; 18.78°W, 64.65°N; 18.85°W, 64.66°N; 18.81°W, 64.62°N; 19.31°W, 64.68°N; but as stated, this is not precise enough.
Is there a list of all warm and hot springs in Iceland, such as collected by the Icelandic Geosurvey or otherwise, including the position to within at least 100 metre (preferably 10 metre), and possibly (as a bonus) the temperature (range) of the specific spring?
","['data-request', 'geospatial']",
How reliable are 250 m soil map data from soilgrids.org?,"
I have 250 m soil map from SoilGrids. I need to extract the soil type for some districts to perform land suitability analysis. But not sure how reliable are they?. Any suggestions?
",['geospatial'],
Where to find ICD-9 category codes?,"
Where does one find downloadable category data for ICD-9 codes in CSV/XML/JSON or other structured format? 
(We are looking for structured data rather than web scraping or writing parsers for semi-structured text.)
CMS offers downloads of subcategories but the category headings for each subcategory are missing. 
The CDC offers ICD-9 downloads as well but the updates only go to 2011 and the file is in RTF format as opposed to CSV/XML etc.
A closed question on StackOverflow is filled with efforts that parsed those RTF files - but there appear to be no structured sources that include the latest CMS updates from 2014.
As some background...
ICD-9-CM codes are three-to-five digit numeric and, in certain cases, alphanumeric codes. The first three digits in a code are called the “category.” The category describes the general illness, injury, or condition of the patient such as: 123.0 – {Disease} in Chest. The zero after the decimal point is the subcategory.
123 – {Disease} (The first three digits make up the category)

123.0 – {Disease} in Chest (The zero after the decimal point is the subcategory.)
123.00 - … uncomplicated
123.01 – … with complications in cardiac system
123.02 – … with complications in digestive system (the last digit is the subclassification. This gives even further information about the designation outlined in the subcategory. If we were to select 123.02 as our code, we’d read the full code as “{Disease} in chest, with complications in the digestive system.”

",['medical'],Here are a couple I found on a quick Google search:
Medication administration in MIMIC-III,"
Does MIMIC-III provide any medication administration data for oral or IV push medications?  I'm aware that the PRESCRIPTIONS table contains all medications, but this table only reflects ordered medications (not the MAR).
For example, if I want to identify patients who received IV push enalaprilat, I can see 788 entries of 'enalaprilat' in the PRESCRIPTIONS table:
select count(*) from prescriptions where drug ilike 'enalaprilat'
-- Returns 788 entries

But because I cannot identify a D_ITEM corresponding to enalaprilat, there will not be any entries in the INPUTEVENTS tables:
select * from d_items where label ilike 'enalaprilat'
-- This query does not return any rows

I assume that IV push and oral medications are not considered as ""input"" because they are small or negligible volumes.  Is there any MAR equivalent in MIMIC to verify that a prescription/order was actually given to a patient?
",['mimic-iii'],"An electronic MAR is is fairly new and thus is not available in the data set:https://github.com/MIT-LCP/mimic-code/issues/292The electronic medication administration record (eMAR) went online
  only a few years ago and so is not in MIMIC-III v1.4. We plan to add
  on something similar for a subset of patients in a future update. Stay
  tuned! :)"
Database/-set containing information about rice yield and growth duration,"
I am looking for a database or -set that contains information about rice seed varieties in Asia. Ideally such a dataset would contain the following keys:

growth duration
mean yield
rice variety
location the data was obtained (e.g. country)

I know there scientific publications regarding the relationship between growth duration and yield (e.g. Vergara et al. (1966), Hussain et al. (2014)), however most of them are either outdated, incomplete or only relating to a small, specific area.
I am trying to correlate the information on growth duration and mean yield to another dataset containing information about growing season lengths and thus estimate the rice production volume.
Any accessible database, API or file format is fine. Regarding the license the dataset would need to be accessible for non-commercial, scientific use with the option to publish derived results.
Do you know any database or -set that contains this information and can be considered relatively ""complete"", i.e. current and large in size representing the most common rice varieties?
","['data-request', 'research', 'agriculture', 'asia']",
Looking for holiday data of Saudi Arabia and Bangladesh/Pakistan from 1950s until now,"
It is okay if the data is not downloadable but viewable. But I need to compare dates of a particular holiday being celebrated in these two/three countries and plot a graph. 
I looked into timeanddate they do not have data for Bangladesh/Pakistan from early times.
","['data-request', 'uses-of-open-data']",
Open database of historical currency holidays for major currency pairs,"
Is there a database containing all historical currency holidays for the major currency pairs ?
It would be in the spirit of the following data (https://www.interactivebrokers.com/en/index.php?f=709), but historical (since 1995 at least).
",['data-request'],"I found a free reuters link, but this is only for few currencies and only since 2013. You can try this - https://dxtra.markets.reuters.com/Dx/DxnOutbound/400201801100745208295001.htm"
Public School Teacher Dataset,"
I'm looking for a dataset with information about public (and private, if possible) school teachers in the United States, including names, schools, and possibly any other identifying information such as department, school location, etc. 
I assume that this information is freely available. I have tried the methods explained in this post: 
Is there an open database of elementary, middle, and high schools in the United States?
but the farthest I was able to get was a dataset including every public school in the United States. If anyone has any information on such a dataset, or possibly a direct link to one, I would be grateful.
Thanks
","['data-request', 'usa', 'government', 'education']",
Pain levels using GSR and heart rate measurements,"
I am looking for dataset(s) that classifies the GSR (skin conductivity) / heart rate readings to emotions and pain levels for machine learning purposes.
","['machine-learning', 'csv']",
Database of labeled hyperspectral imagery,"
(Cross-post from GIS StackExchange.)
Are there any datasets of hyperspectral imagery that can be used for AI training and classification, comparable to ImageNet? The Universitat de Valencia has one listed on their site, HyperLabelMe, but it seems to have been taken down.
","['geospatial', 'images']","University of Alaska has some test datasets
USGS Spectroscopy Lab FTP
Spec Lab has tutorials with small datasets"
where can I find city contracts?,"
Where can I find full copies of city government contracts? I prefer file types that allow for searching. The city of Chicago provided access at one point but I can no longer find the actual files. 
","['data-request', 'government']",
Ontological Database of Objects,"
I am searching for a Database containing a hierarchical Ontology of most objects.
For example, an Apple is a special type of an edible Fruit, which is a special type of Fruit. A Fruit is a physical Object and therefore has a volume, weight, smell etc.
I have found some openly available Ontological Databases, like dbpedia, but extracting the hierarchical Information is non-trivial.
Has anyone worked with similar Databases and is able to recommend something similar?
","['data-request', 'database', 'ontology']","...but extracting the hierarchical information is non-trivial.I am searching for a database containing a hierarchical ontology of
  most objects.Many of the so-called upper ontologies are in fact very comprehensive or have many domain-specific extensions: There are also the so-called commonsense knowledge bases:Many of these ontologies and commonsense knowledge bases are interlinked."
Open Data for the monthly or quarterly GDP of the Eurozone (or Europe 19),"
Trying to find a source that provides monthly or at worst quarterly data of the GDP in the Eurozone area. During my research, I found this link click but it is annual and it does not allow you to change to quarter.
Apart from that I would like it to be reliable and free of charge.
Any thoughts?
Edit:
So I have also found this 1 which is quarterly data published by ECB. However there seems to be a large deviation on the values reported by these two links. Their difference is not that obvious to me.
Any insights on their differences? 
","['data-request', 'europe']",GDP isn't calculated monthly.You can use the ECB numbers and cite to the ECB. The metadata page is useful.ECB data is seasonally adjusted. The Eurostat data doesn't say seasonally adjusted that I could find.
Can I use Mapbox as an open source maps provider in Qgis?,"
I am working in Qgis and using their satellite map.
In the Mapbox website  the said that they are an ""open source"".
Just for being sure: can I use their maps like OSM maps? 
Give them credit and use them in Fiverr?
Tanks!
",['uses-of-open-data'],"The source code is open source, but if you want to use their service, that comes with constraints. The easiest summary is the Pricing page.Note that the underlying data is still OSM. There are lots of ways to consume that data, including a range of rendering and data query options."
Countryside Stewardship Water Quality Priority Areas (England),"
I'm trying to acquire the 'Countryside Stewardship Water Quality Priority Areas (England)' which can be viewed here under Countryside Stewardship Targeting & Scoring Layers> Water (also shown below) in GIS format. I've tried calling the environment agency who Magic directs me to but the EA have no clue what this layer is.  I'm assuming there's no sneaky way to go into the development tools inside chrome and extract the layer out from the code.

","['data-request', 'releasing-data', 'uk']",
I am looking for statistics on the percentage of children's books versus other genres in self-publishing,"
I have tried doing searches for this and can't seem to track down the exact numbers. The sources will list the top selling genres but that doesn't include children's books. I am giving a presentation in October 2017 and need this information.
","['data-request', 'publishing']",
Seeking all Roads in Ohio?,"
I'm looking for a layer with every road in the state of Ohio in order to create drive-time polygons. I'm not familiar with Ohio data sources. Could anyone point me in the direction of a shapefile with all roads in Ohio, or even all roads in the Cleveland area?
",['usa'],
Database of customer service accounts on social media sites,"
I am looking for a database of companies' customer service accounts on social media sites. Any suggestions where I can get this data or any ideas how to create such a dataset?
","['data-request', 'social-media']",
Morocco Post Code Shapefiles,"
I'm searching for the post codes shapefiles of Morocco, anyone have an ideas where I can find those.. ?? I searched on google but I didn't find what I was looking for.. 
Can be open source. 
","['data-request', 'geocoding', 'postal-code', 'geospatial']",
Seeking shapefile of Indian electricity transmission network?,"
I need the data for the research I am carrying out for a masters thesis. There are a few maps out there (e.g. http://powermin.nic.in/sites/default/files/uploads/powergrid_map.pdf), but they seem more like schemas and would be difficult and very time-consuming to turn into a shapefile.
","['geospatial', 'india']",
Camera calibration and distortion parameters data archive (for OpenCV)?,"
I wonder if there is a library of Camera calibration and distortion parameters (as presented in OpenCV camera model or convertable to it) that would cover main cell phone models (iOS\Android) and popular web cameras?
It shall include main distortion parameters such as k1, k2, p1, p2, k3 or a formula on how to convert into them.
As For now I found this and this:
ipad2-front    3.3398628913791757e-02 3.6208493485118960e-02
    -1.3077939973028386e-03 -2.0534401775609144e-03
    -7.7594364452126163e-01


ipad3-rear 2.3628479801842187e-01 -1.4838185680077374e+00
    6.1164837177226554e-03 -1.3917464527942961e-02
    2.3228740041746385e+00

ipad3-front 2.8173092926263271e-02 -7.7958809141800769e-02
    -3.8787165863786166e-03 2.2533495554116770e-02
    8.5297577164938476e-01

macbook-pro-2009   -1.0939089498246352e-01 5.1756087136315387e-01
    1.8180735389345232e-03 -3.3265554687567211e-03
    -7.2079094436631030e-01

",['images'],
Accessing Rental History,"
I'm able to access my county's Public Record system to look a historical information (owner's names, taxes, etc) for a given property. Is there a similar means to access the same history, but with renting tenants?
Example:
https://www.skagitcounty.net/Search/Property/?id=P107482
Similar to this question, but I'm looking for a link between name and address.
","['usa', 'real-estate']","tl;dr - noA landowner had both legal rights and responsibilities (such as paying taxes) so ownership needs to be tracked by the state and is a pubic record.  A tenant; however, has no public responsibility.  His responsibility is to the owner. This certainly can vary by state; but, I have never heard of any responsibility to register a property's tenant - only its owner.  Someone might be able to infer tenancy from a person's current address; but, registering your address does not necessarily mean you pay the rent.  ""Everything is on the internet""; so, I wouldn't be surprised if someone figured out a way to determine it (like from instance from utility bills); but, I doubt you'll find it on a state registry.I skimmed the Washington Rental Laws and I didn't see anything."
Seeking Saudi Arabia County borders as KML?,"
Anyone knows where I can find Saudi Arabia County border as KML file?
I searched the net with no success
","['geospatial', 'kml']",
How can I flter data from a stream of very large text files?,"
I have a stream of data being delivered to my Amazon S3 bucket in the form of tab-delimited text. I would like to scan as it comes in to keep a very small subset of the rows from that match certain criteria. Given the following constraints: 

Each file is 5-50GB in size.
I'm receiving just over 1 billion rows of data per day. 
I am to use Amazon AWS services.
I need to do it as cheaply as possible.

All of the data only needs to be read once then can be deleted. How do I most efficiently perform both a range filter on one field, and a keyword filter on another, keeping the entire row that matches a given query for ingest into another system?
I can think of a number of solutions and none of them are cheap. Originally I was thinking of loading into a Redshift cluster but this seems like it may be overkill on the basis of both complexity. Lambda seems like an obvious choice except for the fact that it doesn't support loading that much data into memory. I suppose I could see how well an auto-scaling group of workers performs, but that doesn't seem like the most efficient way. Ideally I'd like to perform spatial queries on locations represented as x,y coordinates but I can simplify that to a series of bounding box queries if necessary. All suggestions appreciated. 
","['csv', 'big-data']",
90ies Windows .exe database on CD: Extract underlying data,"
I would like to extract data from a register stored on a CD from the 90ies. The Windows executable on the CD allows one to browse the database with keywords and by specific variables. However, there is no manual option of exporting this data in a structured way. I guess that the .exe program accesses the information stored in the folder ""DATABASE"". 
 
Opening the largest file with 21.7MBs in Xcode, this is what the first lines looks like: 

=iulm?=ide?=uhumd?Ghsldo!eds!odtdo!Ctoedrm'""339:oeds=.uhumd?=.ide?=cnex?=i2?@cmrrds!Gs'""343:biuding!FlcI=.i2?=cs?Mdhrohfds!Bitrrdd!2-!15678!@cm'""332:=cs?=c?Ctoedrmoe;!=.c?Rbirdo=cs?=c?U;!=.c?)125273(!2!19!27!=c?Gy;!=.c?2!19!27=cs?=c?Csobido,Os;!=.c?=!isdg<#10020#?10020=.?=cs?=c?Ioedmrsdfhruds;!=.c?@lurfdshbiu!Mdhq{hf!ISC!2470=cs?=c?Coj)do(;!=.c?Shggdhrdocj!Fshll=cs?=c?Fs'""343:oetof;!=.c?0881!)33/!Ed{dlcds(=cs?=c?Fdrbi'""339:gurg'""343:isds;!=.c?Fsudoct,Hof/!Cdsoe!Mdiloo-!Limhr=cs?=c?Fdrdmmrbiguds;!=.c?Ncrumoe!E'""343:ssvdhu{rbido!@F!,!011!$=cs?=c?Fdrbi'""339:guru'""339:uhfjdhu;!=.c?Ds{dtftof!wno!Ncru!kdfmhbids!@su=cs?=c?Rull,Jqhum;!=.c?EL!1-14!Lhn=cs?=c?Cdrbi'""339:guhfud!0887;!=.c?6=cs?=c?Tlru{!0884;!=.c?EL!1-4!Lhn:!0885;!EL!0-0!Lhn=cs?=rlmm?Inqqdorudeu,Ghsldootllds;!209!672!703.86.O=.rl`mm?=.cnex?=.iulm?

How can I convert this and make sense of it?
","['data-format', 'companies', 'database', 'extracting', 'conversion']",I received some help on it. Something along these lines with xor in Python did the job:
Where can I find a list of investigational drugs?,"
I am looking for a primary source (read: preferably not from a reseller) of all drugs currently in development. The FDA says they don't disclose the information, and it seems that clinicaltrials.gov has the information, but there's no easy way to pull out the names of all the drugs in ct.gov. 
Are there any other authoritative sources for investigational drugs?
","['data-request', 'drugs', 'medical']",drugbank.ca -which has listed over 11000 drugs- offers the possibility to filter for investigational drugs. see https://www.drugbank.ca/categories?utf8=%E2%9C%93&investigational=1&us=0&canada=0&eu=0&commit=Apply+Filter
What are known open data sets for the Smart City domain?,"
For example, air pollution data, traffic jams data, .. Probably also with spatial and temporal dimensions.
",['city'],
Where I can get the datasets containing article with its summarization?,"
I am trying to create a summarizer as my project and using ANN and AI for trying to get a dataset for the training purpose.  
Kindly, suggest me where I can get a large dataset for training such a model? I am looking for unpaid datasets, ready to donate.   
Kindly, help me.
","['data-request', 'machine-learning', 'nlp', 'news']",
How can I access FDA drug recall or warning letter data?,"
How can I access FDA drug recall, or warning letter data?
So that I can use that information to predict the Drug Shortage 
using machine learning algorithms 
","['usa', 'openfda']",
Open Data platform from scratch [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 6 years ago.







                        Improve this question
                    



I am doing research on how to build an open data platform with a web portal and a REST interface without relying on a turnkey solution. 
I found different solutions: CKAN, Socrata, OpenDataSoft and Junar.
But they all lack documentation regarding the different technologies they use in order to have such system working, and why they used them. Also, Twitter documentation is very detailed, but obviously I can't find anything about their Rest API architecture. 
Only CKAN has good documentation, but their architecture description doesn't go much into details of the different software stacks it uses, because I guess I need more than a front end, a load balancer, a backend and a database to make it work.
","['api', 'uses-of-open-data', 'ckan', 'data-portal', 'rest']",
Schools in Canada,"
Is there a database of schools in Canada? Can you drop a link that would direct me to that database?
If this does not exist, would you by chance know if the provinces have such data for the schools under them?
I have searched and seen only BC and ON.
","['data-request', 'education', 'canada']",
ISO Country Code for lon/lat 0.5degx0.5deg cells,"
I have a dataset of Koppen climate classifications for the global land mass on a 0.5degx0.5deg lon/lat grid (simple table giving lon, lat and Koppen class for each of approx 85,000 cells as it has changed in decadal steps since 1900 provided by http://hanschen.org/koppen). I want to be able to map this across countries and need a similar dataset that identifies the ISO country code for each grid cell (but current state is sufficient, don't need history).
",['geospatial'],
Retrieve Import Alerts published by FDA,"
The FDA publishes lists of Import Alerts in HTML format, such as, for example, on this page. This is in FDA site under Industry > Import > Program Actions & Enforcement > Import Alerts.
This data is not structured to be processed by software.
I am looking for a way (API, web service...) to retrieve these lists in a format that can be processed (JSON, XML, whatever). I found the OpenFDA (https://open.fda.gov/) site, but it looks like the Import Alerts are not published here.
Does anyone know of an alternative source of info for FDA publications or something specific for Import Alerts?
","['api', 'openfda']",
How to download College Scorecard raw data,"
How can I download the raw data for the College Scorecard application? Specifically I am interested in cost of attendance information. When I visited the link to download a zip file from this page, I received a 404 error. I reported the error on Data.gov, but I am hoping others know of a way to get that information. 
I work for a scholarship/college access organization and college cost of attendance is necessary in determining how much to award a student. It would be impracticable and a waste of resource to manually gather this information for every single college when it appears to be open source and available through College Scorecard.
Thank you for your help!
","['data-request', 'data.gov', 'collegescorecard']",
Crunchbase-Like Database(s) for Countries,"
Where can I possibly look for IT companies, key people, investors, etc for a particular country to create my own dataset? Like crunchbase, but not global.
","['data-request', 'companies']",
Mapping between JSTOR stable ids and DOIs for Publications of the Royal Society of London,"
Is there a mapping between the DOIs used by the Royal Society of London and the  Stable URLs provided by JSTOR? I am looking specially for the publications of the Royal Society of London (Philosophical Transactions, Abstracts, Proceedings) before 1923.
EDIT: Some sample jstor_id's: 102661, 106670, 109020, 111263, 110829, 112791 
","['data-request', 'doi', 'data-mapping']",
USA States Schools data base,"
Seeking an open database of schools across the states in the USA. Ideally, this database includes the schools name, address, email address and telephone number.  
Seeking this dataset because we are a SaaS ""Software as a Service"" based company located in South Africa and want to market an app we developed to the the US States' education systems.  
","['data-request', 'education']",
Nigeria Wards Shapefile,"
Where can I find GIS Wards data for all of Nigeria?
I tried searching everywhere to no avail. 
Diva GIS only has the LGA layer, and I am looking for the level below that.
","['data-request', 'geospatial']",
Drivers and Vehicles information Datasets,"
Where can I find datasets which contain basic info about drivers and their cars? In details, I'm interested in

Driver's sex
Driver's experience (years)
Driver's profession
Car's basic info (company/model)
Car's type (sport/passenger/truck etc.)
Car's cost
Car's age
Type of ownership

","['data-request', 'cars', 'privacy']",
Free database of vehicle data and VIN,"
I've been looking for a free database of vehicle manufacturer's specifications, data, and VIN for a long time with no luck, does anyone have any ideas?
Please identify any database of free or non-free, you know. Free database are more important.
Information required from the following manufacturers:

Acura
Alfa Romeo
Audi
Baic
Bentley
Benz
Besturn
BMW
Brilliance
BYD
Chervrolet
Chery
Citroen
Daewoo
Daf
Dodge
Ferrari
Fiat
Ford
Geely
GMC
Great Wall
Haima
Honda
Hummer
Hyundai
Infiniti
Jaguar
Jepp
Kia
Lada
Landrover
Lexus
Lifan
Lotus
Maserati
Mazda
MG
Mini
Mitsubishi
Nissan
Opel
Peugeot
Porsche
Renault
Rover
Smart
Ssang Young
Subaru
Suzuki
Tesla
Toyota
Volkswagen
Volvo

","['data-request', 'transportation']","this information tending to differ by region/continent. Maybe you should check which could fitting best to you and/or merge them.* As of Feb 2018, they have closed their openAPI program"
Save Scraped Data to an Open Database,"
I want to scrape data periodically from a website and save it to a database that's should be readable by everybody. I thought about using a Google Docs Spreadsheet but the overall API management (especially the authorization) seems to be not suited to my needs. Do you know of any alternatives?
","['data-portal', 'database', 'publishing']","A quick an easy way to provide open access to your scraped data would be pushing it to GitHub or another easily accessible online repo in a text format (CSV/TSV or JSON if it's less structured -- this would also allow you to add timestamps for when data was scraped) and update it automatically. Without an explicit license to publish the data it may not be open, legally-speaking, so I would advise including any license information published on the source site as well as asking for the data and/or permission from the publishing organization. Even if they say no or ignore you, you've done your homework and may learn something important (and they can't say ""yes"" if you don't ask)."
Looking for labeled audio data for sentiment,"
I'm looking for labelled audio data. Like a cat meowing, or a spoon falling on the ground, a car driving past, etc... i.e. sound clips of events. Does anyone know of where to find this? Would be very grateful for any help here. 
","['data-request', 'audio', 'sentiment-analysis']",
Free ocean currents polyline/shapefile download?,"
Does anyone know where I can find a map of polylines/polygons indicating the rough location of major (and minor if possible) oceanic currents? Velocity is always welcome, but directionality would be ideal. 
It would be similar to this map which I believe is only available to ArcGIS users.
This will mainly be used for comparing to other data layers, rather than integrating into the model.
I am using QGIS, and any resolution is okay, but really the finer the better (as always).
","['geospatial', 'oceanographic']","Here's that dataset (Major_Ocean_Currents_arrowPolys_30m) in GeoJSON Pyesridump is a very powerful tool you can use to liberate data from ESRI's silos.
This literally took me less than a minute to strip it out, load into geojson.io, and then save it as a gist."
Sample Employee organization data?,"
I am looking for a sample dataset for employee organization hierarchy like who reports to who? Can anyone point me to a relevant open downloadable dataset for this?
",['data-request'],
Collection of datasets for sentence relatedness or stance classification,"
I have been developing a classifier with machine learning to know if two texts are related or not. By that means, if they are talking about the same topic or not. I have tried to gather data but, so far, I have only come up with the FNC dataset (http://www.fakenewschallenge.org/) which is more a problem o stance classification but I can modify it slightly to only classify texts as relevant/irrelevant between themselves.
Where can I get datasets for sentence relatedness or stance classification? Thanks in advance.
","['machine-learning', 'nlp', 'classification']",
Elevation data API for Spain,"
I would like to obtain the accumulated elevation from a request with lat and long.
I need an open data API without limit like OpenStreetMap but with elevation.
",['api'],
Seeking free traffic Data of the world [duplicate],"







This question already has answers here:
                                
                            




Data of vehicle traffic

                                (3 answers)
                            

Closed 2 years ago.



I am working on a project that needs road network traffic data.
I saw the Open traffic collection on Github but the data is not what I need:
It is not detailed, there is no traffic data by road segment in France or GB for example, and it is annual. I need at least daily traffic data, like this one of Paris 
Is there any source from which I can get traffic data of main countries' roads ?
",['traffic'],
centroids or boundaries of unincorporated communities,"
I have the Tiger places (dark green), which I believe contains census designated places. I also have the Census Bureau's Cartographic Boundary Shapefiles - Places (Incorporated Places and Census Designated Places) (light green). Those two basically overlap just perfectly as shown here:

When I look at the same area on Google Maps, the unincorporated community of Aberdeen, California shows up (as well as Blackrock and some others):

Are there any sources out there for unincorporated communities? When I check the USPS zipcode lookup I get a zipcode for Aberdeen, and I imagine I can use something like the Census Bureau's ZIP code spatial data to get an idea of what communities are in what zipcodes, but that really doesn't give me the actual centroid or boundary of Aberdeen.
","['usa', 'census', 'population']","Using Wikidata SPARQL Endpoint:Place this pseudo-comment — #defaultView:Map —  anywhere in the query above, if you want to display results on the map.Not all unincorporated communities has coordinates in Wikidata. If you do not want to exclude these unincorporated communities from results, use OPTIONAL:These unincorporated communities has no coordinates in Wikidata:You can add missing coordinates yourself (e.g. for Carolan, Arcansas).Using DBPedia SPARQL endpoint:The number of unincorporated communities in DBPedia is less than in Wikidata. You can add missing communities creating their pages in Wikipedia. "
Digital terrain models for Scotland at 1m resolution or less,"
The following link allows you to download a composite 2m DSM/DTM:
2m LIDAR Composite DSM & DTM for Scotland 
Are there any freely available datasets containing DTMs which are in <= 1m resolution, perhaps a similar link in the data.gov.uk site or indeed any other site?
","['data-request', 'uk']","The text on that very page reads:Data is available at 2m, 1m, 50cm, and 25cm resolution.and I found 50cm LIDAR Composite DSM & DTM for Scotland just searching for LIDAR Composite Scotland on data.gov.ukI didn't see the 25cm, but you can do more searching yourself, or contact the responsible agencies directly with a request for the data."
Historical electricity prices for countries,"
Is there a source for national electricity prices for current and preceding years/ months for individual or grouped countries? I would like them in a standardized measure but national currencies is good enough and just adds an additional conversion step. 
","['data-request', 'global', 'prices', 'energy']","The European Energy Exchange (EEX) is a marketplace for European energy (electricity), both futures and spot prices (although most trading is done either with brokers or as OTC). From your question it sounds like you are looking for spot auction prices, which are traded the day before delivery and have hourly resolution. That means each hour of the day has one settled price and volume. Multiple markets/countries have individual prices. The markets trading on EPEX Germany/Austria, Switzerland, France, UK, Netherlands, Belgium. EPEX prices are available from the parent company, EEX. Unfortunately, only individual days are available, so you can either copy/paste one by one, or scrape the HTML (hint: there is a json file somewhere in the source code)A portion of this data is available on Quandl (energy data documentation). Here's an example of average daily prices in Germany/Austria from 2014."
UK Income and population by POSTCODES,"
I searching the data of the population + the income of the person in the post codes area for any digit layer in UK.
","['uk', 'income']",
OBD ii Dataset for collision dectection,"
We are a tech team of an insurance company. My team working on a project to find out faking collision for insurance claims. So we are currently testing 100 of our insurance clients with OBD ii. we just start collecting data. But to progress in our research, we are looking for a tested OBD ii dataset with many parameters. especially with an accelerometer, gyroscope, and collision occurrence information.
any suggestions would be appreciated
","['data-request', 'machine-learning', 'cars', 'accelerometer']",
Sudoku puzzles of different sizes,"
Does anyone know where I can download already generated Sudoku puzzles of different sizes, even greater than 16x16? 
The format where they are saved it's not important provided I can parse them relatively easily. The size of the dataset should at least be of 100.
Note: I've looked at the software qqwing, but it seems to generate only 9x9 grids. Furthermore, it would be nice to have them already generated and, maybe, stored in a file format like .csv, so that I don't have to change the code of other people to obtain what I want. Moreover, I'm actually more interested in grids greater than 9x9. Finally, I'm not necessarily looking for the solutions.
","['data-request', 'games']",
wikidata extract,"
I have a list of wikidata entity IDs (i.e. Tour Eiffel Q243, Big Ben Q41225...), and a list of properties (i.e. coordinates P625, country P18 ...).
Is there any way to gather and extract in Excel (or csv) a table with the information?
What I look for is something like:
[
","['wikidata', 'excel']",
Shapefile for Petrol Fueling stations across USA,"
I am trying to find a shapefile or csv/kml/kmz file with all of USA's vehicular fueling stations. All I have found thus far is E85 (alternative fuel stations) from energy.gov (https://energy.gov/maps/alternative-fueling-station-locator). 
Does anybody know where I can find other fuel types (such as E87, 89, 95 etc), i.e. just regular gas stations?
","['data-request', 'usa', 'geocoding']",
USCIS Processing Times,"
Can I get the USCIS Processing Times by Service Center via the API? For example, the I-140 processing times for the Nebraska Service Center. https://egov.uscis.gov/cris/processingTimesDisplay.do
","['usa', 'api', 'labor', 'migration']",
"Global map of rough peak wind spead, wind risk assessment, or design loads","
I'm developing a web application which provides cost and sizing estimates for the construction of a facade. The user can input several variables including geographic location. One of the primary variables that our engineers need is design wind loads (Stronger possible peak winds = larger necessary structure.) On any real projects that come in we'll do further site specific analysis with licensed engineers, so the web application just needs to give a ballpark estimate. We're planning to design around three tiers of wind speeds, so the spatial resolution needs to be as high as possible, but the wind speed or risk level resolution can be very low.
I'm trying to find a map, or data which I can process into a map, which encodes wind loads, wind risk assessment, or peak wind gust speeds so that I can then sample the map with the user's selected location. Things I've tried:

There are a handful of posts on Open Data looking for global average wind speeds, which I've browsed already. The data is good for what it is, but I'm looking for peak speeds (from thunderstorms, cyclones, hurricanes, etc.), and the events that drive those speeds are short enough in duration that they don't affect the averages enough.
The best example of what I'm looking for is the ASCE Wind map, which gives wind design loads for USA only. Something like this at a global scale would be ideal, but I haven't found anything.
The closest I've come on a global scale is in looking for maps of level of threat of tropical cyclones (e.g. Global Risk Data Platform - click ""Preview the data"", top right.), but comparing this with ASCE suggests there's something more to this than tropical cyclones. Alaska, for example, has no risk of cyclones but is equivalent to Southern Florida on ASCE's map.

Of course it would be great if there's a free resource out there, but we'd definitely consider paid alternatives.
Moving this from gis.stackexchange in hopes of more luck...
","['geospatial', 'climate']",
How avoid duplication in a data lifecycle?,"
I will put an example.
I have a 1 TB CSV file, I need to conserve the raw file and sanitize then.
After the sanitization near 10% of entries has changed.
Both files need to be stored for years.
So, what's the best way to handle the two files?
I need to avoid duplicate the files to save 0.9 TB of disk usage, so the best way I find it's to store only the 10% of sanitized data when somebody wants to read an entry that not exists in the sanitized file the software layer try to find it in the raw file.
So, i can save 0.9 TB of disk space but I need a software layer to handle the requests for the entries.
The problem is, I don't have found a software that does it for me, so I need to write them.
However, Linux BtrFS filesystem has a deduplication resource, I can have the raw file and the sanitized file and allow the filesystem to handle the deduplication. But in a test, an estimate can save only 0.5 TB because need space for metadata.
I'm a little lost here:
How can I apply my requirement to save disk space without writing the software?
Or perhaps, the question should be: What methodology I need to apply to save disk space in file duplication and operation?
If someone likes to recommend a book, I'm open to reading it.
",['best-practice'],
Dairy Farms in Wisconsin and Minnesota,"
I'm looking to get a directory of Dairy Farms in Wisconsin and Minnesota and the approx. size of each farm in heads terms?
Any idea where can I get this info?
","['data-request', 'usa', 'research', 'analysis']","The Census of Agriculture, National Agricultural Statistics Service (NASS), and the ERS (Economic Research Service) branches of the USDA have most of the data you are looking for. However, I'm not sure if you can get down to the farm/number of heads level, although you should be able to get pretty close.  You can get a good feel for this here:
Ag Census Web Maps lets you mash them all up and get a better view (in my opinion). Here's a screenshot of Average Number of Cattle and Calves per 100 Acres of All Land in Farms: 2012Lastly, try states agricultural services website; Wisconsin's has a directory "
Australian post code/area shapefiles,"
I'm looking for the Shapefile of the Australian Postcodes/area 4-digits. I would prefer an open source if possible.
","['data-request', 'geocoding', 'postal-code', 'australia', 'geospatial']",
"Jeypore Reserve Forest in Assam, India Shapefile","
Does anybody have the shapefile for Jeypore reserve forest which is adjacent to Dehing patkai wildlife sanctuary, Assam, India? 
","['data-request', 'india', 'geospatial']",
"Are ""protocols"" to usgov open data also available?","
The U.S. gov creates and makes available a lot of open data on various topics, but the one that I am interested in is new legislation.
Let's say that there is an open data source for new laws (which I believe to be the case). I'm interested in creating a database for ""scholarly"" (legal journal) articles on these new laws. The government would (presumably) have apis, or other protocols for gathering, indexing, collating, etc. on these new laws. Would it be possible to license, or otherwise obtain, these protocols from the government to create a ""parallel"" private sector data set that would articulate or interface with the government data set instead of ""recreating the wheel?""
Put another way, how would the government create these open data sets, and are the creation tools available by license or other otherwise from the government? I am interested in ""back end,"" data collection procedures. I think I know people that can handle the front-end, presentation issues.
","['api', 'releasing-data']","It depends It depends on which particular agency/department. It depends on which dataset(s). It depends on how they go about collecting/curating/presenting/utilizing said datasets (FOSS vs. proprietary), etc. It depends on how many corporate entities are already at play in that particular space; how much of the space have they already captured, how does the space feel about said capture, etc.The federal government has not mandated FOSS, nor has it defined FOSS and its relationship to open data, so there is no clear path* for government worker bees to follow. Last year the Obama administration laid out a path for Open Source to start being created by government, but that is about as mandated as it gets. Note the clear absence of a path to start adopting open source. You can see this in the following examples:  HUD offers many of their datasets in SAS and another proprietary format that I can't recall off the top of my head. They give you two options, but you can't do anything with either, if you don't have a license for the software they are distributing it with.  It seems like almost every single federal GIS portal has gone the way of ESRI/ArcGIS, and while most offer downloads of open source data formats, some rely entirely on ESRI. You either have to use ESRI's tools, or find a way around them (like pyesridump). A lot of the older satellite imagery data NASA, NOAA, USDA, and USGS have are JPG2000/MrSID; the options for getting them converted into an open format are extremely limited, especially if your on one of the operating systems that they do not support (mostly OS X).  Speaking of operating systems, some data may also come with open source software, but that software sometimes is only built for one OS. USGS and NASA have done a fairly good job creating FOSS tools, but most are not cross-platform, so they still lock some potential users out.Many corporate entities offer free-ish (freeware, basic account, etc.) software/technology that looks great to those not familiar. Here the lack of a clear definition hurts/holds us back; those not in the know, hear ""free"" and think they are taking the right path only to find out (typically) to late into the process that free != the entire product/service, etc. **Socrata entices groups because their data platform is free to adopt by government institutions. But the free runs out once you hit a certain number of datasets. It's the same with Google Maps: free to use until you hit a certain usage rate. Combine Google Maps with Google Fusion Tables and see how confusing that is for governments publishing on said platforms. They are both free-ish, but you can't just download data from Fusion Tables, and you can't use Maps free all the time.
I am going to keep picking on Google: Google Earth was made free relatively recently, so it seems ideal to publish GIS data in KML format if you were not in the know. Said ideal decision became less than ideal when Google Earth announced their latest version, which only works in Google Chrome. Google Chrome is a proprietary browser that you may not be allowed to install or simply may not want to install. Lastly, the below quote from Google Earth's Wikipedia entry sums up just how FOSS Google Earth really is (it is not):  ""Every image created from Google Earth using satellite data provided by Google Earth is a copyrighted map. Any derivative from Google Earth is made from copyrighted data which, under United States Copyright Law, may not be used except under the licenses Google provides. Google allows non-commercial personal use of the images (e.g. on a personal website or blog) as long as copyrights and attributions are preserved. By contrast, images created with NASA's globe software World Wind use The Blue Marble, Landsat or USGS layer, each of which is a terrain layer in the public domain. Works created by an agency of the United States government are public domain at the moment of creation. This means that those images can be freely modified, redistributed and used for commercial purposes.""Even the most widely used/consumed processes, technology, and formats in U.S. federal gov (state and local too) that have longevity are not clear, nor precise when wading through this arena. (Almost) Every single document of (almost) every single gov site has some disclaimer at the bottom of it explaining you need software to open up PDFs, and points to Adobe's Reader site. What is wrong with this picture?
a) PDF is not an open format, even though Adobe claims and markets it as one. There are certain aspects of it Adobe specifically omitted from the open license to continue their mastery in this space. One particularly horrible aspect: you can't get accessible PDF software without paying for it. That's right, its an ""open"" format, but functionality required for some people to even be able to use it at all, costs money.
b) the corporate links these government sites point to almost all fall under the free-ish examples I've already touched on. Sure, you can open and view a PDF in Adobe's free reader, but you can't do anything else without a license. Microsoft's free products follow the same theme as well. They let you taste it, but if you want to eat, you're going to have to pay up.
c) Why do all of the links point to Adobe? or for office documents, why do they all point to Microsoft? There are open source/free software options that could be linked to, as well as open source/free software formats they could adopt, yet the only spaces I've seen this in are on extremely niche USGS/NASA sites, where the entire team has adopted FOSS/OS. The lack of options even being presented to users is mind-boggling to me. It is a mix of confusion, denial, ignorance, atrophy, and going-with-flow/don't-rock-the-boat that serves no one save the government employees and Adobe/MS/Corporate entity.  Lastly, and this muddies the waters even more, some departments/agencies/personnel have their own definitions of FOSS/open data. USDA APHIS runs a database to which they don't provide table headers for. I requested the definitions because it is impossible to understand the table/underlying data without them. USDA APHIS response to me was that they are proprietary. And that about sums about the wild west show that is U.S. federal government open data/FOSS.  The FCC had done a great job initially adopting and promoting open source, however the only link in the content of this page 404s. Following it up in the wayback machine, there are two entries a year and a half apart 2015-03 and 2016-08 that redirect to a dfferent URL.
None of this means that the FCC doesn't support FOSS, or that they've stopped, but its extremely hard/confusing to follow along. I'm assuming its the same for the premise for asking this question in the first place.
While FCC does go above and beyond in adopting/supporting/promoting open source here in federal us dotgov terms, did they really? I don't think so, these MS-Office tools for tracking tie you to software, and possibly an OS (at least at one time they did): Microsoft Access-based Tracking Tool (.exe), Microsoft Excel-based Tracking Tool (.exe).NOAA's ESI (Environmental Sensitivity Index) maps and tools mostly all fall into this categorization too: you can view the data in ESRI ArcGIS maps online, but you can't do anything with the tools built for them without accessing ESRI's ArcGIS ecosystem, which is not open source.I can provide a plethora of other resources for state/local that are doing the same things with different software/data.  And all of this doesn't even touch on what/how the rest of the facets of openness (Open Access, Open Science, Open Education, OER, etc.) are playing out currently in this arena.  If you have a particular dataset/department/agency in mind, it never hurts to engage them and feel them out. In many cases it feels like they want to hear from you/will work with you. Many simply are not aware of the entire ecosystem and/or have yet to see anyone they know on the federal level implementing something like it or similar.  In summation, there is no clear answer and every single question on this topic in this space has a unique answer.*18f and USDS have blazed paths to open source; NASA, USGS, and NOAA have done a lot as well, just not as a whole agency. To be fair, the latter three have substantially bigger variants to deal with: number of employees, existing infrastructure/architecture not built as FOSS, niche/specific details unique to particular datasets, data collections, etc.•• Aside from Google and all of its products, I'm not singling out any characters or actors on purpose. These are just the default examples I go to when discussing this. There is a place for corporate/for-profit/enterprise in government. That said, everyone has to be a good faith actor in this field, or it all falls apart.
Google (Alphabet) has become entirely too dominant, across too many (crucial) spheres of the web, while simultaneously ditching it's famous motto ""Don't be Evil"". Not all Google/Googlers are bad, and they are still doing a lot of great work on the web, but their actions have clearly shifted from their roots. An open web needs healthy, competitive, decentralized ecosystems. Google has done extremely little recently in regards to that, and in some instances, worked against it."
Opengeocode.org account has been suspended?,"
Does anyone know what has happened to 
opengeocode.org
The well used website is showing that the account has been suspended

","['internet', 'geocoding']",
French word list?,"
I would like to make an auto-completion tool for people who are don't type very well, like what exists on phones. 
So I do not need just a dictionary but a list of all words, like all conjugations of verbs and all word variants (plural, gender). 
I can use use the wiktionary's word frequency list, but it is not as complete as I would like. Yet, the frequency sorting property is interesting for me. 
So should I look for something else or should I start with what I have?   
","['data-request', 'language', 'dictionary', 'french']","I have found the perfect dataset for me: http://www.lexique.org/Word are extracted from books and movies subtitles. It contains about 140,000 words."
"Washington, D.C. Shapefile","
I am looking for a shapefile of the Capital city of the United States.
I have looked in Natural Earth and GeoTECHO, but I have only found a list of cites that covers the entire world.
Can anyone help me with this?
","['data-request', 'geocoding']","There is an abundance of open GIS data on Washington, D.C., however they all have distinct characteristics. Your going to have to pick through and select which one(s) fit what you need.  Search Code for DC's Open Data Portal for Files of Type ""SHP""
Note: There are exponentially many more datasets here in .geojson format; converting to .shp can be easily done in a number of ways, I prefer using Q-GIS for small/one-off/testing conversions.  Search DC.gov's Open Data Portal for ""shapefile"".
DC.gov typically releases datasets in a number of GIS formats, including shapefile; searching for what you want in the portal will most likely be more fruitful.  None of these are pointing to a particular dataset, because the request is vague; there are a plethora of DC shapefiles in both portals, each having distinct characteristics from others. Census Tracts, Wards, Boundaries, City Line, Districts, Voting Districts, Neighborhoods, are just a few of the many options there are to choose from. "
Places to get large (volume wise) datasets reasonably well formatted and free to share?,"
I've been struggling with this problem for almost 2 hours now :(
I need some datasets that are somewhere around 50 - 5000 GB large when uncompressed to showcase and test various data storage and query systems.
Nothing fancy, but I'd prefer to use real datasets rather than randomly generated numbers and strings, or repeat insertions of very small datasets.
Kaggle has a few large datasets (e.g. https://www.kaggle.com/c/malware-classification/data) but they don't allow free sharing of the data (which is what I need, since I wish to be able to publish re-creatable benchmarks).
The only real requirement I have besides size is reasonable dimensionallity (e.g. at least 4-5+ columns), be formated in a non proprietary plain text format (e.g. CSV, JSON, TSV, XML... even most SQL formats will work, though I'd prefer to avoid them if possible) and the ability to download the compressed version for free, from anywhere, using a static url.
If anyone knows of a website or other ressource that provides datasets for free which might have this I'd beg you to tell me... I did not think this kind of thing would be this hard to find :/
","['data-request', 'web-crawling']",
Criteria of Countries selection in Natural Earth Data 1:110m?,"
I'm trying to figure out how Natural Earth Data has selected the countries listed in its 1:110m Admin-0 Countries dataset. Indeed there is only 177 countries in this dataset.
Is it Population size ? Territory size ? Something else ?
",['geospatial'],
Aliexpress price history dataset,"
I want to find any dataset on Aliexpress products' price history? I found only one good quality website - https://www.pricearchive.org/ but according to their faq - they ""do not provide special access (including via API) to any data shown on the pages of our website."" Aliexpress own API doesn't seem to give access to the price history.
","['data-request', 'api', 'uses-of-open-data', 'historical', 'prices']",
GIS Landcover/Precipitation/Geologic Faults Data for Nepal,"
I am doing some analysis for a project regarding disaster recovery in Nepal and I am trying to get my hands on data that is required to do the complex statistical analysis like regression. I am looking for landcover raster or vector, rainfall tables, as well as any type of raster or shapefile related to geologic faults in the region. Much of my analysis is dealing with landslides. Please be detailed in your response.
","['data-request', 'geospatial']",
Is there any registry of active 24/7 animal video feeds (from public IP-like cameras)?,"
I am developing a IP-ish surveillance-like animals behaviour analyzing solution. I have some private video streams, but to check method robustness I need to be able to check on other animal types\locations\light conditions. So I wonder if there is some ""registry"" or list of publicly available 24\7 animal video stream links (say of some zoos)?
","['data-request', 'real-time', 'animals', 'video']","No registry that I am aware of, but some government sites do post all of the webcams within their agency/department/etc., like NPS Air Quality Web Cameras.
I keep a lists of some webcams, here are the ones that have animals.  EarthCam Live Webcam Network  has over 500 Search Results for ""Animals and Zoos"" as well as an Animal Cams section.
Eagle Cam @ Berry College, GA
FWS Eagle Cam
DC Eagle Cam
Animal Planet Live
San Diego Zoo
Kelp Forest Cam - Channel Island National Park
Under Water Scuba Cam - Channel Island National Park
Bear Cam - Brooks Falls
Puffin Burrow Cam
Farallon Islands Live Webcam
Farm Sanctuary - Pig Pasture
Shark Lagoon Cam
Live Penguins Cam
Penguin Cam
Phillipine Coral Reef Cam
Wolf Cams
International Wolf Center Exhibit Pack Live Stream
Panda Cam - San Diego
Panda Cam - Atlanta
Panda Cam - National Zoo
Live Safari Cams
Video Streams Broadcasing Live from the National Aquarium
Elephant Cam - National Zoo
Lion Cam - National Zoo Note: Explore.org has a lot of webcams of animal life, but make sure you are watching the live feed vs. the highlights reel from the previous season that they run during hibernation season.  "
Database of manufacturers of medical devices outside US,"
I'm doing some geospatial analysis of medical device manufacturers. In the US, the FDA requires manufacturers of medical devices to register their devices and the location of design and manufacturing.  This information is publicly posted in the “Establishment Registration & Device Listing” database, located at this address:
https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfRL/rl.cfm
This provides details such as the address of the location where a devices is manufactured. Are there comparable publicly available registration databases in the European Union or China?  Are there other (non-public) sources of this information?
","['data-request', 'medical', 'europe', 'china']",
"Is any Dataset for chitchat regional languages in english in watsapp, facebook messenger etc available in tensorflow","
I started a project in chatbots for the normal regional languages chatting in english like below , I need a dataset to train my model in tensorflow ,Is any dataset default present in tensorflow or any framework available to do this . if so how to use it . I checked the awesome public data sets list, But i could not able to find it and also i verified in tensorflow sonnet related frameworks ,no chance , Please help with the solution ,I almost created the android app but very poor performance with the dataset available in hand
Tamil language written via english
""Neenga Epdi Irukenga?"" ==> ""How are you ?""
More Info
Keyboard Support is very limited for most of the regional languages ,To make the conversation in regional language ,people are typing regional langauges in english the way as like pronounce
Additional Info
Similar to transliteration but transliteration is for unique word ,the dataset needed for meaningful sentence
","['data-request', 'machine-learning', 'nlp']",
How can I reliably host and share large data sets?,"
Relevant to this answer, I discovered that datahub.io has a 100MB limit on file uploads. I was disappointed to learn this, and it tooks many server errors to realize I should read the FAQ, where I learned there is a limit.

The file upload size limit for datahub.io is set to 100MB. If your files are bigger than that you can host them on a separate storage provider like Dropbox or Amazon S3 and link to them from your datahub.io dataset.

Github has a similar 100MB filesize limit.
I'm not opposed to paying to host large files, 

but how can I share big datasets that are not personally connected to me, like Dropbox? (S3 isn't really an option to host 1 file)
and that offer a one-time fee to host the file ""forever"".

In this particular case, the zipped CSV is 440MB, so not TB or even GBs of data.

Related, but without the focus on large files:
How do I share Open Data with others on this SE site?
Note: torrent could work, but requires a file that doesn't change and also requires decent interest from the community. For this question I'd like to focus on http/ftp hosts.
","['releasing-data', 'big-data']","If you want quick, dirty, and free, you can always host downloadable datasets at the Internet Archive (archive.org).  No pretty interface, but as much storage as you could ever want."
NEISS injury dataset - machine readable and decoded,"
The National Electronic Injury Surveillance System (NEISS) database offers both a query tool and bulk CSV downloads at maximum one calendar year. The available data dates back to 1991.

Patient information is collected from each NEISS hospital for every emergency visit involving an injury associated with consumer products. From this sample, the total number of product-related injuries treated in hospital emergency rooms nationwide can be estimated.
Records are weighted to estimate the total population.

Here's a fun twitter-bot using this data:



There are two issues: (1) files are individually downloaded by year, and (2) CSV files contain encoding, for which the metadata is in PDF files and websites (see my other question related to this)
My question: Where can I find multi-year datasets that are decoded? (contain actualy injury and cause, and not just an ID number)
","['data-request', 'releasing-data', 'medical']","I have manually downloaded the individual files and combined them into several file formats. Combined files, total rows = 8,852,972data.world repository CSV sampleFull export - zip:CSV (440 MB compressed, 3.2 GB unpacked)Full export zip:sqlite3 (717 MB compressed, 4.0 GB unpacked)RelatedData visualization with 2015 dataR Package ""Neiss"" from Hadley WickhamPython consolidation project"
Unsolved murder rates by country/state/municipality,"
I have read on Hacker News today that

The overall solution rate for murder in the US is about 65%. In big cities with dubious police leadership, the solution rate for murder can be under 50%.

(Chicago, Baltimore, St.Lou etc..., right?)
Where can one get the dataset for the States, and for other countries of the world, at any level of aggregation?
Yes, I do know about police misreporting, and forced confessions. Having both corrected and raw rates would be great.
The narrowest definition is finding the victim's body. Rate of unsolved disappearance cases would be a welcome, but not essential variable.
Similar questions here:

Where can I find adult abduction victim statistics for the United States? (a somewhat different crime, unanswered)
Obtaining data sets for solved murder (the question asks for a micro dataset, is unanswered, and I want a geographically aggregated one)

P.S. Use case - should be an excellent indicator of rule of law/lawlessness in an area.
","['data-request', 'crime']",
Dataset with Addresses and Building/Structure Type in the US,"
I'm looking for a dataset where I can find out an address' building/structure type. I know that the Google Places API will return types but I am looking for a different source which might be more accurate. I've explored contacting city and county assessors and found some datasets with building types but not all cities and counties make the data accessible or free. I'm also hoping there is something more monolithic than contacting each city. 
I'm looking for recommendations or for someone to point me in the right direction. Thanks so much in advance!
","['data-request', 'usa', 'real-estate']",
Accessing raw OpenFDA data for visualizations,"
Is there a way to connect a Tableau Web Data Connector to the data on the OpenFDA API?
",['openfda'],
How to find DEM data with attribute table for Brighton UK,"
Where can I find accurate DEM data of Brighton UK (with an attribute table) to be used in ARC GIS, being used for a university GIS project and have struggled to find this data. 
","['data-request', 'uk']",
Geocoding of Chicago crime data,"
The City of Chicago publishes some rich crime data, available e.g. here:
https://catalog.data.gov/dataset/crimes-2001-to-present-398a4
The address of event crime is partly obscured, so as to read for example ""010XX N CENTRAL PARK AVE"".  The data also provides coordinates and longitude / latitude data.  These agree if you use the correct projection (in feet).  I would have expected each coordinate to, for example, correspond to the middle of the block, but this is not so.
Screen shot from QGIS with OpenLayers as the basemap:

So what we see is clusters of events, corresponding to the correct block.  What I find puzzling is that the mid-point of these clusters does not appear to be the mid-point the block.  The pattern is repeated, seemingly, across the whole dataset (so in other parts of the city, with residential buildings on the avenues, you get north/south clusters, again, not centred).  Could the centre of each cluster perhaps correspond to the centroid (projected onto the middle of the road) of all the buildings in the block?
From some messing about in Python, and simulation, the clusters look like they are normally distributed (not uniformly distributed).
Interestingly, I've now looked at the complete data set, from 2001 onwards, and the crimes reported in 2001 (only) seem to show a rather different pattern:

Frankly, this looks pretty realistic to me!  Is it possible they only started obscuring the real coordinates after 2001?

Does anyone know the exact way the location coordinates are actually generated?

","['usa', 'city', 'geocoding', 'crime', 'chicago']",
Can I get access to Davis Bacon Wage Determinations via this API?,"
Can I get access to Davis Bacon Wage Determinations via the APIs at this site 'http://developer.dol.gov/wage-and-hour-division/wage-and-hour-publications-system'?  I am looking for recent and historical Davis Bacon wage determinations for select counties and trades.
",['labor'],
Neighborhood by Zip Codes for New York and Los Angeles,"
I haven't been able to find an online open source of US neighborhoods with their corresponding zip codes. I am particularly looking for New York and Los Angeles. 
","['data-request', 'usa']",
Is there any API to get list of ingredient that contains added alcohol,"
Is there any API to get list of ingredient that contains added Intoxicants/alcohol not the natural that just exists ?
Above would do the job for me for now, but if you are curious to know why I am asking this then some background...
I would like to develop an open source web app which will figure out if certain food products are halal or haram based on product's ingredients initially.
I already found a product ingredients database here - https://world.openfoodfacts.org/
But I am struggling to find a database for Haram ingredients or products.
[Haram food][2] is a big topic to cover but initially developing a simple engine would be a good start.
","['api', 'food']",
Where to find healthcare practice and hospital names?,"
I can get all physician data in the US from the NPI registry. But it doesn't contain the practice names (or the hospital names). Is there a place I can get these?
","['data-request', 'usa', 'medical']",
Archive of TV schedules,"
I am looking for a TV Schedules dataset with at least following fields:
TV Network, TV Channel, DateTime, TV Program, (TV Episode etc)

","['data-request', 'media', 'telecom']",
Free publicly available 3D faces morphable models,"
I've found two excellent models. The first one is linear face model of Basel university called Basel Face Model, which includes different face shapes. Another one is bilinear model FaceWarehouse, which includes not only different shapes, but expressions as well. The problem is: I don't know whether it's available for ordinary students; also seems like it doesn't contain textures.
The aim of my Master's thesis is to implement a better algorithm for 3D facial surface inverse rendering than existent ones. I've understood that I'll not achieve good results without different facial expressions, so I need a good dataset for further work.
Do you know free publicly available morphable 3D face models?
I need it to contain models with full correspondence of vertices in order to have linear space of faces with different expressions. Would be nice to get textured high-resolution model (tens of thousands vertices).
Though, what another names of such models do you know except ""liniar model"", ""bilinear model"", ""morphable model"" and ""generative model"" (you may provide your variants in comments)?
","['data-request', 'machine-learning', 'faces']",
What tool can I use to manage a researcher network bibliography?,"
I am making a website for a researcher network using Jekyll and hosting it on github pages.
Each researcher (250+ people) should have his own document with an up to date bibliography.
I could request from them the bibliography in a BibTeX format and include it using Jekyll-Scholar plugin. However, it would require them to update it each time they publish a new paper.
So I looked into ResearchGate, hoping to find an API (they landed 35 Millions to make one 2 years ago). No luck, they only have a plugin system far from fulfilling my requirements.
So I wondered if there is any reliable endpoint to fetch an individual researcher bibliography, assuming she or he would agree and keep it up to date. 
","['api', 'web-crawling', 'rdf']","ORCID provides a persistent digital identifier that distinguishes you from every other researcher and, through integration in key research workflows such as manuscript and grant submission, supports automated linkages between you and your professional activities ensuring that your work is recognized.  ORCID also has ResearcherID integration.  ORCID.js is a JavaScript library for doing exactly what I think you are seeking.  In the GitHub repository example, it passes an ORCID profile ID and spits out a list of the corresponding researcher's work."
"Vector layer of the Jerusalem city line (""הקו העירוני"")","
I would like to guide a tour in Jerusalem sometime next week. For the historical and political perspective, I would be happy to show the City Line on a modern Google Map during the tour. I can either use a existing vector data or georeference a high-quality raster city map.
I searched online, and only found rough sketches like the one below, taken from Wikipedia.
Any idea where I can find an accurate map of the Jerusalem pre-1967 border?

",['geospatial'],
Derived variable origin,"
I was wondering how the variable SCH_DEG from College Scorecard was derived. What does it mean to be the degree prominently awarded in terms of the actual #'s? Is it > 50% or more than that?
","['education', 'collegescorecard']",
Census data aggregated at MGRS level,"
I would like to be able to have a file with U.S. Census data pre-aggregated at some level of the Military Grid Reference System (MGRS). Ideally at thier 10km precision level, but I'd take whatever I could get.
","['demographics', 'census']","Unfortunately, I don't think this exists as a pre-aggregated data file. However you could use a tool like census_area to get a close approximation. With this tool, you could download block or block group level data and aggregate them your desired geographies.(I'm one of the authors of this library)"
Electoral district boundaries (international),"
I'm looking for a resource with shapefiles for various current and historical electoral boundaries for legislative districts in various countries, for example in North Africa (Algeria, Morocco, Tunisia, and Libya).
","['data-request', 'elections', 'geospatial']",
Where I can get the dump of WHOIS Database?,"
I am trying to create a neural network based identification network for various websites and with their owners.
I tried to search for database, but could not find any. Kindly, let me know where I can get the complete database dump of whois for websites, so that I can feed that data to my network and process it.
","['data-request', 'machine-learning', 'network-structure']",
How the numbers of Nazi deportees from France varied over time,"
I'd like to know how the rate of deportations of Jews from Nazi-occupied France varied over the course of the occupation.  Was it a steady flow?  Were there any clear trends?
","['data-request', 'france']",
Human Movement Data,"
I'm interested in studying human movement (any type of transportation except aerial), specifically related to health. 
I would assume most of this data is owned by one possible creators/collectors of it, such as telecom companies (which record their cellphone client's position on the cell ""handover"" procedure). 
I've searched around the web and have not found data sources yet.
Do any other open data sources, in which I could obtain at the very least trends of human movement, exist? For now I'm not interested in international migration. Any country is OK. 
What I'm interested in is the ""movement"" people usually do, their commutes, and their most usual movements. I'd use this data to research it jointly with case data (of multiple different diseases) and see if there's a correlation.
","['data-request', 'travel']",
Dataset for road accidents or traffic,"
I am looking for datasets that lists the location of accidents or traffic (latitude and longitude) with date and time in many countries.
I found datasets for USA and UK, now looking for datasets for other countries. 
Any type of road accident would be great.
","['data-request', 'transportation']",
A health related and text based dataset,"
I am looking for a labeled text based dataset which is health related for a machine learning project.
I found some interesting papers like ""Evaluation of Facebook and Twitter Monitoring to Detect Safety Signals for Medical Products: An Analysis of Recent FDA Safety Alerts."", ""Evaluation of the Feasibility of Screening Patients for Early Signs of Lung Carcinoma in Web Search Logs."" and other similar publications but neither of them had a public dataset.
Where can I find such a dataset?
Edit: My topic of interest is extracting medical data from social media, like the paper I have mentioned. But I'd appreciate other suggestions.
","['data-request', 'medical', 'social-media']",
Data set for action recognition in trains,"
I am working on a project for visual recognition of actions of people inside trains and metro stations. My aim is to detect abnormal behaviour.
I am looking for data from any kind of sensors that could be installed in trains, such as wide angle cameras, microphones and 3d sensors. 
Does anyone know any relevant online data source?
","['data-request', 'machine-learning', 'public-transport']",
Data set for original exchange a security traded on,"
I'm looking to find a data set containing a security ticker, company name and the original exchange it was listed on (NYSE, NASDAQ, OTC, etc.). Any suggestions would be appreciated.
","['data-request', 'finance', 'historical']",
"Looking for clustering dataset/usecase with large (10^5+) number of points, medium (256-2048) dimension, small k (10-max 100)","
I would like to test on real numerical data a clustering algorithm which works well in the following setting:

large number of points (let's say at least 10^5, but can be way more);
medium dimension, at least a few hundreds, up to a few thousands;
a number of clusters k not too large (ideally ~10-20, maybe up to 100 but no more)

Does anyone know a dataset, or a use-case for which this could be interesting?
For now I tried to use 10 classes with 40000 pictures each from the Places2 dataset, and extracted a VLAD descriptor for each image (dimension 8192, further reduced to 1024 by PCA), but I don't really get well-separated clusters (adujsted rand index between the result of a standard kmeans and ground truth = 0.12). I guess I can have a better separation of the clusters using for instance spectral clustering, but this would reduce the dimension of the features to d=k as well, and then it would not be really interesting anymore.
","['data-request', 'machine-learning']",
Seeking census religious data by block group in New Jersey?,"
Where can I find religious census block group data for New Jersey (NJ)? 
I am fairly certain this data is on american factfinder but I am unable to find it. 
My plan is to join to a NJ block group shapefile and display is on a map. 
","['data-request', 'geospatial', 'us-census', 'religion']",
Global/European soil properties database,"
I'm looking for global or European scale database / maps of soil properties. Resolution does not really matter even though the higher is the better. By soil properties, I mean:

soil textural classes : % of sand, silt, clay
soil hydraulic properties: soil hydraulic conductivity, water content at saturation, field capacity and wilting point. 
soil pH
soil organic carbon content
soil depth
soil color/albedo

I'm interested in any data sources that adress at least one of these properties. 
J.
","['data-request', 'europe', 'global', 'environment', 'soils']","Since the moment I've post my question, I did some research and found some databases that nearly fulfill my needs. 1) European Soil Database (Europe-28 + Turkey + neighborhood countries)The webpages of the European Soil Data Centre have indeed interesting database, such as the European Soil Database, available here. Understanding the database takes some times: here are my notes for anyone interested for using the database:2) FAO Digital Soil World Map (Global)A zip file was downloaded (from here: http://www.fao.org/geonetwork/srv/en/main.home?uuid=446ed430-8383-11db-b9b2-000d939bc5d8) with a shp of the digital soil map of the world. But the resolution of this vector data is bad, with very smooth polygons. The EU soil map has much more classes and a finer resolution. 3) Harmonized World Soil Database (Global)4) Lastly, there is this excellent page of David Rossiter that references dozens of soil database across the world: http://www.css.cornell.edu/faculty/dgr2/research/sgdb/sgdb.html + this page that references some other resources:
http://www.dataset.mapping-sense.com/tagged/Geology%20&%20SoilsJ. "
Aerial photos of different tide heights,"
I'm looking for aerial photos taken at different tide heights of Holy Island, Northumberland, UK. Are these available anywhere?
","['uk', 'aerial-photography']",
Can an image licensed under CC BY-NC-ND be used in free application,"
I've found an application which shares art for free. Recently I was served with an image which seems to licensed under CC BY-NC-ND.
Is this legal? I mean is a free application always considered NonCommercial in terms of CC BY-NC-ND?
","['licensing', 'creative-commons']","Without pretending to legal expertise which I do not possess, the best answer I can give is maybe. Note that the definition of NonCommercial is defined as follows:NonCommercial means not primarily intended for or directed towards commercial advantage or monetary compensation.(https://wiki.creativecommons.org/wiki/NonCommercial_interpretation)From that, I would interpret that if the primary purpose of the app is to make money for (or otherwise gain some commercial advantage for) the creator e.g. through serving ads or through the use of in-app purchases, this wouldn't be compliant with the NonCommercial clause.Potentially - again, I stress I am not a lawyer - it sounds like if the app has some commercial element (e.g. a donate button) but the primary purpose is not to make money, this may well be a legitimate use of an NC-licensed image.As to the second point - is a free app always considered NC? - the answer there appears to be that this wouldn't always be the case. At least in principle, I can conceive of a free app which nonetheless primarily serves a commercial purpose e.g. although the app itself is free, it exists primarily to promote a paid service provided by a particular company. This would seem to meet the definition of ""commercial advantage"".I would note that Creative Commons themselves are fairly vague on the exact definitions of commercial vs. non-commercial use. From the Executive Summary to Defining “Noncommercial”: A Study of How the Online Population Understands “Noncommercial Use”:Perceptions of the many use cases studied suggest that with the exception of uses that earn users money or involve advertising – at least until specific case scenarios are presented that disrupt those generalized views of commerciality – there is more uncertainty than clarity around whether specific uses of online content are commercial or noncommercial.(https://wiki.creativecommons.org/wiki/Defining_Noncommercial)At the end of the day, I suspect these definitions are vague enough that it would have to come down to legal proceedings between the creator of the image and the app developer before a definitive answer could be found as to whether this specific case is legal or not.TL;DR - It might be legal, but it probably depends on the specifics of the case. Ask a professional IP lawyer."
Wordnet for other languages,"
I'm looking for downloadable wordnet for other languages. Preferably connected to the Princeton WordNet. Is there any?
","['data-request', 'dictionary', 'wordnet']",
Seeking US public school serving area boundaries,"
I am trying to get the serving area for public schools in US. I can get a lot of KML from the census website at https://www.census.gov/geo/maps-data/data/tiger-kml.html 
However, it only has school district kml boundaries, but not each individual school. 
Is there any way that I can get the boundaries for each US public school?
","['usa', 'geospatial', 'us-census', 'education', 'kml']",
Trying to match convenience store names / gas station names to their corporate parent,"
looking to map (for example) all the various Kroger brand store names to ""Kroger"", will appreciate any pointers to datasets and/or data scrubbing logic.
","['data-request', 'business']",
How to openFDA Query data from 2014 to present?,"
I was looking through the openFDA API and have been trying to find a good way to get data from the start of 2014 to now. Unfortunately it appears the downloads only go to 01-25-16. I also ran a query on the live database giving a very wide date range and got some strange results which do not appear to match up with that of the downloaded JSON file. 
The download JSON file can be found here: ""http://download.open.fda.gov/2016-01-25/food/enforcement/food-enforcement-0001-of-0001.json.zip"" and my query run can be found here https://api.fda.gov/food/enforcement.json?search=report_date:[20140101%20TO%2020170429]&limit=100 . The problem I am finding is that the query seems to return far less results then I am expecting if it stores the same contents as the downloadable JSON. 
What I mean by that is that the first entry for the query is with a report date of ""20160316"" and the last entry having a report date of ""20140903"". Where as the download has well over a 100 entries for any given year within its bounds. Is this an issue with my query, the database, a bug or something else entirely? Any help would be much appreciated.
",['openfda'],
public list of world banks,"
I don't need branch offices and full addresses.
I think of data ... XML, CSV ... with these fields :

bank code, as used in SWIFT BIC
bank name 
country name or country code (ISO two letters)
optional : city of bank headquarters

For each bank, one record per country of presence.
If there are other bank codes, of widespread usage, it is good.
","['data-request', 'bank']",
UK Cities and Towns,"
I've scoured the internet (including stack exchange) and trialled a few datasets but none have suited my needs. I'm after UK town and city names with long/lat positions and populations (so I can style which towns to label by rules).
I'm aware of the OS Names product but that doesn't have populations and there are hundreds of spreadsheets to amalgamate into a single usable .csv file.
I found this (global dataset): https://www.maxmind.com/en/free-world-cities-database which is ideal. However the file is too big to clip and QGIS's clipping window closes as soon as I run it.
","['data-request', 'uk', 'city', 'population']",
PDB protein data as a network (graph theory graph),"
I try to find dataset where PDB protein with Atoms and coordinates is constructed as a network (will work adjacency matrix or contact map).
Managed to convert the file manually in a distance matrix but want to know if is already datasets what I can use for research. 
location for the PDB bank protein: 
http://www.rcsb.org/pdb/home/home.do#Category-download
",['network-structure'],
CKAN - Find and add tags to multiple datasets can this be done?,"
I want to add a tag ""Water"" to any dataset that includes data ""agua""
Can I use the API to search, find and update all datasets that contain the search string ""agua"" to add a tag ""Water""
","['api', 'ckan']",
EU workforce per commune,"
For a project I need geodata of communes with residential population and workforce (optimally also full-time equivalents, FTE) for at least FR, DE, IT, and AU. 
On Eurostat and EU Data Portal websites I managed to find geodata for census regions (2011) and communes (similar, but not identical) as well as the Census Hub, where at least in theory it seems I can obtain residential population per commune. (I filed a data request with the interface for the data for FR, DE, IT, and AU, but the job hasn't completed after several hours; I suspect there's an error.)
However, I couldn't find data on workforce (and/or FTE) per commune anywhere. In Census Hub it seems to me the data may be available for NUTS3 regions but not at a finer scale. Does anybody know where such data may be available, at EU level or per country?
","['data-request', 'europe', 'census', 'population']",
List of all UK political party/politician facebook pages,"
I'm working on a Chrome extension to analyse Facebook advert targetting by political parties, in the run-up to the 2017 UK general election. (https://whotargets.me)
In order to conduct our analysis, we need to match adverts to political parties.
Do you know any lists of UK political party / politician facebook pages? Ideally we need:

page ID
vanity URL string
page name
party affiliation

We're really eager to find regional/local/branch party and politician pages.
","['data-request', 'uk', 'social-media', 'elections', 'politics']",
Types of license for OpenData,"
In order to release the data as open it should come with a license. In the open world, there are differente licenses for different purposes (GPL, MIT, BSD licenses for Software - OpenSource; Creative Commons for artwork - sogns, text, images, videos; even GFDL can be used for documentation) but it is not always clear which are the possible license to release correctly data as open.
OpenStreetMap had this issue with its huge database, and changed the license from CC to ODbL. However, if I want to release a dataset, for example a CSV with some information, it is not a database.
Which license can I use?
","['releasing-data', 'licensing', 'legal']",
Download clean coordinates from Wikipedia Map Module: … detailed map,"
I would like to know if there is a way to either download/scrape a clean CSV with coordinates and controlling group from Wikipedia conflict maps, or how to generate an ESRI shapefile from the Lua script. I have no experience using Lua.
Wikipedia has several maps for civil conflicts, which all seem to share the same structure and naming, e.g. Module:Sinai insurgency detailed map, which I've chosen due to its simplicity.
# R script for scraping text
# library
library(rvest)

#SINAI
url <- ""https://en.wikipedia.org/wiki/Template:Sinai_insurgency_detailed_map""
coords <- url %>%
    read_html() %>%
    html_nodes(xpath='//*[@id=""mw-content-text""]/div[2]') %>%
    html_text()

I am currently using the above script to write a raw .txt file. I then clean it with OpenRefine to create a usable CSV in QGIS. I realize this is not the most efficient workflow.
","['geospatial', 'programming', 'wikipedia']",
"Seeking Meteorological stations data for Europe, especially Denmark?","
Where can I find a geospatial data set of meteorological stations of Europe, preferably in point geometry for Denmark?
","['data-request', 'geospatial', 'meteorology']",
Is there any public database for financial transactions,"
I want to use the R language to do data mining for anti-money laundering. But do do this I first need a dataset of transactions.
Is such a set available?
","['data-request', 'finance']",
2000 census data by block group,"
I need Population & Housing Unit Counts for Blocks (all the states) from 1990, 2000, and 2010 Census. I downloaded 2010 and 1990 from the following links, but can not find the corresponding data for 2000 census. 
Does anybody know how to get such a data for Blocks for each state from 2000 census? 
American FactFinder does not have the information for housing units for blocks and even for the population, it should be downloaded for each county separately (time-consuming for the whole US).
2010:
https://www.census.gov/geo/maps-data/data/tiger-data.html
1990:
https://www2.cdc.gov/nceh/lead/census90/house11/download.htm
","['data-request', 'usa', 'census']",
Do US banks have reporting requirements for public money they hold?,"
Do US banks or depository institutions have reporting requirements on public money they hold? If so, how could I find which banks hold the money for a particular local government?
","['data-request', 'government', 'finance']",
Receipt images database,"
I am looking for a database of receipt images (like of receipts you get from the supermarket). I didn't found any open database, do any of you know something useful?
I would need a few thousand images at best, but less is still good.
","['data-request', 'images']",
How is a Crunchbase organisation's address flagged as headquarters?,"
A Crunchbase registered user can add addresses to an existing organisation. These addresses can be named freely (e.g. ""HQ"", ""Headquarters"", ""xyz"", etc.) via a free-form field, but the address creation form does not include a headquarter flag.
However, at the other end of Crunchbase, the API gives access to a one-to-one relationship between organizations and headquarter addresses (alongside a one-to-many relationship between organizations and all their addresses), according to this page.
As a user of the API, I have personally been able to verify that the organization HQ file is a subset of the organization address file and that there is no more than one HQ per organization.
So, somewhere between the user interface and the API, addresses are flagged as HQs. How are organization addresses flagged as HQ and by whom? Have I missed something in the Crunchbase user interface?
","['companies', 'address']","Good question. The first address added to a company in Crunchbase is assigned the headquarter relationship. If a new HQ is subsequently added, it can be selected and reset on crunchbase.com on the top card. "
UK flight paths,"
There seems to be some data for the US, but is there any vector data for UK flight paths? 
The best case scenario is to obtain separate lines/polygons for different altitudes (I only need 0-1000m). 1 years worth of records should do the trick.
---- Update ----
I found this (still not optimal data): http://openflights.org/data.html
If you scroll down you can download global flight paths in the following format:
Airline 2-letter (IATA) or 3-letter (ICAO) code of the airline.
Airline ID  Unique OpenFlights identifier for airline (see Airline).
Source airport  3-letter (IATA) or 4-letter (ICAO) code of the source airport.
Source airport ID   Unique OpenFlights identifier for source airport
Destination airport 3-letter (IATA) or 4-letter (ICAO) code of the destination airport.
Destination airport ID  Unique OpenFlights identifier for destination airport
Codeshare   ""Y"" if this flight is a codeshare (that is, not operated by Airline, but another carrier), empty otherwise.
Stops   Number of stops on this flight (""0"" for direct)
Equipment   3-letter codes for plane type(s) generally used on this flight, separated by spaces

Sample data:
BA,1355,SIN,3316,LHR,507,,0,744 777
BA,1355,SIN,3316,MEL,3339,Y,0,744
TOM,5013,ACE,1055,BFS,465,,0,320

So how do I get that data format into QGIS without coordinate data?
","['data-request', 'geospatial', 'uk']",
Seeking school quality data?,"
I need to create a map that shows school quality in Atlanta. I'm having a really hard time finding either test score data or school proficiency data. 
Where or how can I search for this?
",['usa'],
Drug patent to National Drug Code (NDC) mappings?,"
From the FDA's Orange Book site, I have lots of information about drug patents. I want to be able to link up drug patents with NDCs. Does anyone know of a mapping table that bridges the gap between Orange Book fields like Patent Number and Product Number and NDC?
","['medical', 'drugs']",
Crimes by Block Group for state of Michigan,"
Is there any crime rate information by Census block group available for Michigan state? Possibly in the for of crime count/amount per block group? 
","['data-request', 'geospatial', 'crime']",
Word list with learning age,"
I'm looking for word databases, mainly in English and Swedish, which contain lists of words associated with the ages where they are typically learned.
WordNet linkage is a big bonus.
","['data-request', 'english']",
Resume Dataset Request [duplicate],"







This question already has answers here:
                                
                            




A dataset of resumes

                                (3 answers)
                            

Closed 4 years ago.



Where can I find a dataset of resumes around 1000-2000 for machine learning project. Preferably good resumes of software engineers. I know this question has been asked before, but I believe there should be some dataset online hiding. 
P.S. Any chance of using a Python crawler to download resumes from indeed?
Thank you,
","['data-request', 'machine-learning', 'research']",
Photos of tree leaves,"
I need to train a neural network to recognize photos of leaves.
I have only laboratory photos with a white background, but I need leaf photos from nature.
Do you know where I can get this type of photos?
I need > 100 photos of each leaf (tree species).
","['data-request', 'images', 'photographs']",
Data set of French Communes,"
I'm looking for a data set with the names and INSEE (ID code) for all the French communes.
I am hoping to find a data set for the entire country.  So far I have found that Wikipedia has it on the department level.
","['data-request', 'france']",I think this might be what you are looking for (at insee.fr):Liste des communes existantes au 1er janvier 2016 
API for FCC electronic equipments radio emissions,"
The (USA) Federal Communications Commission maintains a database of all the equipment they test, located here.  
I am looking for an API ( REST, SOAP, etc...) to query and fetch the data.
My queries are low volume; I don't want to scrape the data from HTML.
","['data-request', 'telecom']","FCC's OET Laboratory API has a getFCCIDList method call, all though I'm not sure how helpful that will be without a list of IDs. Seems like a bunch of busy work, exactly what you are trying to avoid by not scraping it.
OET Laboratory Services API Documentation (PDF)
getFCCIDList API Call Example for ID 'OPS' FCCID.io - Searchable FCC ID Database has a lot of exposed IDs, and I would start there if I were trying to amass a complete list. It may also be worthwhile to contact them and inquire about accessing the master list/database.  "
Looking to add layers of Massachusetts State Senator and State Representatives to map?,"
Where can I find files of Massachusetts State Senator and State Representatives to add these layers to a map?
","['data-request', 'usa', 'geospatial']",
UK cities longitude and latitude details,"
I require a list of data on UK cities giving longitude and latitude details. Preferably in CSV or Excel format.
","['data-request', 'geospatial', 'uk']",
UK Wind Speed for QGIS,"
I've looked at related questions but none seem to provide what I'm after.
I would like to hear if anyone knows open source data of annual wind speed (not direction) for the UK. The data can be downloaded by post code or areas of 1km2 to show mean wind speed across the nation. Just a simple figure (e.g 10mph) per grid square would be ideal so I can associate a colour for every grid to generate a 'heat map' for wind speed.
I've looked into:
https://maps.darksky.net/
Although I don't think that's what I'm after.
This is more what I'm after...http://www.renew-reuse-recycle.com/noabl.pl?go=Go&postcode=NE66+1TL&osx=&osy=&country=gb
","['data-request', 'geospatial', 'weather', 'uses-of-open-data']","Courtesy of Daniel Neumann (See comments)Soon, there will be (ECMWF ERA5)[climate.copernicus.eu/climate-reanalysis] data be available. It will be published within the (EU Copernicus Programme)[copernicus.eu/]. All Copernicus data (Satellite, Model, In-Situ Measurements) are for free (at least for European citizens). The data will be published within the (Copernicus Climate Service)[climate.copernicus.eu/climate-reanalysis]. – daniel.neumann "
List of all products and their ingredients,"
I need list of all products with following attributes,

Ingredients 
Country or origin
Manufacturer

Now the tricky part is that, I don't want it for JUST a specific country, I want it around the globe and I don't mind automating this task too as I am a software developer.
However I don't want to reinvent the wheel which is why asking here is my first approach. I don't mind and I think the only choice would be to gather data from supermarkets somehow ?
","['data-request', 'food']","Open food facts is a ""food products database made by everyone, for everyone"". And ""it is open data, anyone can re-use it for any purpose"".It has calories, ingredients, photos. It's crowdsourced : you can use it and contribute to it as well (and let your user contribute) according to the OdBL licence."
Update on severity scores regarding code from MIMIC repository?,"
What is the status of the following scores and appropriate code as of April 2017? (taken from https://github.com/MIT-LCP/mimic-code/tree/master/concepts/severityscores)
Beta? Production? Good to use?
I would like to use code for SOFA/SAPS/OASIS but I have no idea how trustworthy these codes are.

OASIS
The Oxford Acute Severity of Illness Score (OASIS) is a parsimonious severity score developed using a hybrid genetic algorithm and particle swarm optimization approach which allowed direct optimization of a severity score in a clinically relevant form with simultaneous multivariate feature selection (Johnson, 2013). The new score discriminated better than the Acute Physiology Score III (APS III) when evaluated in a univariate fashion and equivalently when evaluated as a covariate in a larger risk adjustment model similar to APACHE IV. OASIS was designed to have an extremely low burden for data collection and quality control, requiring only 10 features, and not requiring laboratory measurements, diagnosis or comorbidity information.
SAPS
The Simplified Acute Physiology Score (SAPS) was intended as a simplification of the Acute Physiology Score (APS), reducing the number of physiological parameters required from the original 34 to 13 plus age (LeGall, 1984). The variables chosen were present for 90% of patients in the initial survey used to develop the APS (Knaus, 1981). Though the original publication only provided ROC curves and not the AUROC, trapezoidal integration showed that SAPS had an AUROC of 0.7697 and APS had an AUROC of 0.7661.
SOFA
The Sepsis-related Organ Failure Assessment score was first developed by a consensus meeting of the ESICM in October 1994, though it eventually became known as the Sequential Organ Failure Assessment (SOFA) score as it was applied outside of septic populations (Vincent, 1996). The purpose of the score was to provide the clinical community with an objective measure of the severity of organ dysfunction in a patient. It is stressed that the score is not meant as a direct predictor of mortality but rather a measure of morbidity, or the level of the diseased state, in a patient. The score is evaluated for 6 organ systems: pulmonary, renal, hepatic, cardiovascular, haematologic and neurologic. Note that the organ-specific morbidity scores are highlighted as a useful compliment to the overall score.
Future work
  The following severity scores have yet to be implemented, but are desirable, and contributions are welcome.
SAPS II
The Simplified Acute Physiology Score II (SAPS II) published in 1993 (Le Gall, 1993), aimed to rectify two issues with SAPS. First, the variable selection process in SAPS was done by clinical judgement, whereas SAPS II utilised univariate feature selection to filter out features uncorrelated with hospital mortality. Second, there was no model for calculating a probability of mortality from SAPS. SAPS II was published with calibration coefficients which allowed conversion of the integer score into a risk of mortality which ranged between zero and one.
SAPS III
The Simplified Acute Physiology Score III (SAPS III) is the latest model published and attempts to account for poor calibration of SAPS II found in later studies (Metnitz, 2005). While SAPS II was developed on ICUs in western Europe, SAPS III included ICUs worldwide. The parameters of the model were identified using a stepwise logistic regression, followed by statistical hypothesis testing to ensure the parameters were significantly related to patient hospital mortality (Moreno, 2005). The final prediction used 61 binary indicator features which dichotomised various ranges of 20 distinct variables (e.g. the highest heart rate variable was split into three binary features, one for heart rates $= 160). A hierarchical model was used, specifying patient characteristics as fixed effects and different ICUs as a random effect. A logistic regression equation was then used to calculate the probability of mortality.
APACHE IV
APACHE IV is the most recent iteration in the Acute Physiology, Age, and Chronic Health Evaluation system. The model was published in 2006 and coefficients are freely available online. Overall, APACHE IV tends to have the best discriminative performance among the most recent generation of general purpose severity of illness models.
  APACHE IV's components include: the Acute Physiology Score (APS) III, comorbidities, diagnosis, admission source, surgical status, mechanical ventilation flags and existence of thrombolytic therapy. Unfortunately, the diagnostic component of APACHE IV is very difficult to code.

",['mimic-iii'],
Dataset of retail (chain) store locations by store number,"
I'm looking for a dataset which translates US store name and numbers to (geo) locations or street addresses. 
For example:
Chick-Fil-A #2193 is located at 1845 Main St, Chester, MD 21619.
Panda Express #2529 is located at 4506 N Main St, Roswell, NM 88201.
Wendy's #5218 is located at 13430 W Maple Rd, Omaha, NE 68164.
Chipotle #1720 is located at 865 Market Street, Space C10, San Francisco, CA 94103.
J. Crew #508 is located at 3222 M St NW, Washington DC, 20007.
Nordstrom #736 is located at 9607 Research Boulevard, Austin, TX 78759.

It looks like there are a couple of (spammy) websites which try to do something similar, e.g. storelocations411.com and chargeprotect.com (not hyperlinked to avoid more link spam).
I'm surprised that there's nothing obvious out there, so I'm hoping I missed something - any help would be great!
","['data-request', 'geospatial', 'business', 'companies']",
Cryptocurrency historical prices,"
I'm looking for cryptocurrency historical data, including prices and market cap (either from exchanges or average price) of the main cryptocurrencies, namely: Bitcoin, Ripple, Litecoin, Ethereum, Dash.
So far I've only been able to find this source on Quandl and the historic daily price on blockchain.info 
Any additional additional sources for other cryptocurrencies and more detailed data (like hourly price or Open-High-Low-close) will be helpful.
Ideally the data should go back as far as possible but realistically data since 2012 would be enough. As for younger cryptocurrencies 1 or 2 years will suffice.
","['data-request', 'finance', 'historical']","As it turns out there are several resources one can use for all main cryptocurrencies so I will post here the most relevant and flexible I was able to gather.All CryptocurrenciesCoinmetricshttps://coinmetrics.io/data-downloads/This page has data for: Bitcoin, Litecoin, Ethereum, NEM, Decred, ZCash (transparent transactions only), Dash, Dogecoin, Ethereum Classic, PIVX, Monero.ETH -  BTCPoloniex As chartPoloniex As JSONOne needs to edit the timestamps in the API to get a different snapshot. And edit the period to adjust the details.BitcoinCoindesk Closing price and OHLCClosing price blockchain.infoBitcoin data on QuandlBitcoin data on Quandl IIEtherThanks to the answer to this question on Ethereum's stackexchangeEtherchain's APII will keep updating this answer with more links as I find them."
How do football APIs get their data?,"
I am wondering how sport APIs get their data.
Do they use web scraping or web crawling?
If they do: is it legal to create my web scraper to gather data?
I checked various sites and they all lead to different API/Feed, but how do these feeds get their data?
And how do they update it so fast (live scores)?
","['data-request', 'web-crawling']","I think they get it from the contribution of the community.
More Info: https://www.jokecamp.com/blog/guide-to-football-and-soccer-data-and-apis"
Shapefile or GeoJSON of all Caribbean Islands,"
I'm looking for a large-scale geospatial data set (or several components that could be merged) that includes all the islands of the Caribbean region. The trick is that as many of the physical individual islands as possible need to be listed individual features in the data table. In other words, I want the data set up so that it is easy to select particular islands (not countries) and style them individually.
I've tried Open Street Map -- specifically Quick OSM and the Overpass API, using the place:island tag. That works pretty well, but there are a not-insignificant number of islands missing (e.g. most of the bigger Florida Keys, the main island of Cuba (though the smaller islands of Cuba are included), some of the main islands of the Bahamas, and others). 
Natural Earth has two problems -- the scale is not small enough, and the each table row represents a country (group of islands, or mainland and islands together), rather than an individual island. 
Any suggestions much appreciated.  
","['data-request', 'geospatial', 'openstreetmap', 'north-america', 'south-america']","The OSMData Land Polygons include all land areas in the world, which should mean it includes the data you are looking for. It's derived from natural:coastline rather than place:island, so it shouldn't have the same gaps for larger islands but may be excessively large and unwieldy. You may be able to pare it down or recreate it on a regional basis based on the description provided on the same page."
List of coodinate systems with attributes,"
I am looking for a website which lists all common coordinate systems with their attributes (angle true, area true). I aware of spatialreference.org but this do not give me the desired information(or I am too blind to find them).
A plus would be a searchable system with EPSG codes. Double plus would be a side in German (because  I am lazy) 
","['data-request', 'geospatial']",
Where can I get shapefiles for changing German territory during the Second World War?,"
I am looking to get ArcGIS shapefiles for changes in the territory of Germany throughout World War Two.
","['data-request', 'historical', 'europe', 'geospatial']","I found the spatial history project, which give month to month changes of the front lines. The article covers all interesting information and you can download the dataset (after the first figure) - viz., EuropeanBorders_WWII.zip (~260 MB)."
List of symbols with corresponding names,"
I am searching for wording for symbols icons and what they are. For example, if you have a symbol such as flag, or types of cars. I want to look it up online and search for the name of that symbol.  I know that there are tons of them online but what I would like to have a general thousands of symbols or icons and if you don't know what they are you can pull it up and look for it.
I know it is hard for me to describe. I am a GIS Specialist and sometimes I get a hardcopy maps and I have some odd symbols and I couldn't find it on my software to match it. So, when I google and I couldn't find it either...
","['data-request', 'internet']",
US freight commodity flows by county or BEA,"
I am looking for data on freight commodity flows in US by county or BEA area for a two digit STCC code. The information that I need is how many tons or loads of freight of a given commodity was transported between a given origin-destination pair.
The best I could find so far was Commodity Flow Survey, but they only have data for around 80 metropolitan areas and everything else is aggregated to ""rest of the state"".
","['data-request', 'transportation']",
C2C commerce data set,"
I'm working on a research about recommender systems and I'm looking for a C2C e-commerce data set, the data set should contain transaction data with the buyer id, seller id, item id and some item attributes. it will be better if it contains some attributes about the seller and the buyer that influences the trust between them.
","['data-request', 'research', 'shopping']",
Train Stations Open Source Point Data,"
I am searching for proper open source train station data.
I need only the central stations per country (best would be worldwide). I know the OSM source stations for each country but as far as I know you can't differentiate between the station type.
The values I'm looking for are name, country, longitude and latitude.
Is there any reliable source?
","['data-request', 'geospatial', 'openstreetmap']",
Is there any dataset of Indian Traffics Signs?,"
I wanted data set of Indian Traffic Sign for classification purpose.
","['data-request', 'traffic', 'india', 'classification']",
Where can I download North America Tropical Cyclones dataset?,"
Is there any government website from where I can download North America Tropical Cyclones dataset in CSV or array format?
","['data-request', 'weather']",The International Best Track Archive for Climate Stewardship provides all tracks in CSV format at IBTrACS-All data in the following formats:
Undergrad-Total Institutional Aid Received by school,"
Is there a data set out there that has OPEID with types and total aid received, specifically, Total Institutional Aid (if there others or all included, that's definitely ok)?
I've tried following the steps outlined on page three of this document: https://nces.ed.gov/pubs2015/2015604.pdf but I can't seem to get dollar totals. 
","['data-request', 'education', 'aid']",
time series for US weather [duplicate],"







This question already has answers here:
                                
                            




Sources of weather data

                                (6 answers)
                            

Closed 5 years ago.



is there a public resource for  weather time series (temperatures). my phone collects temperature by the hour but I wonder if weather stations store this information somewhere.
Data collection has improved so it I am only looking for recent years (and avoid too much work normalizing).

","['data-request', 'weather']",
Looking for dataset on teachers' unions membership by school district,"
Specifically, I'm looking for data on the number of teachers belonging to a union for each county in Florida. 
","['data-request', 'usa', 'education']",
How to find address from the Census Blocks Code?,"
I have Census Blocks Code data (15 digits code) and need to get corresponding street names and addresses in NYC. What is the best source of such information?
","['usa', 'geospatial', 'us-census', 'geocoding', 'address']",
Newspaper ownership data,"
Is there a dataset of the ownership of newspapers in America? For example, it is common knowledge that Jeff Bezos owns the Washington Post, and that News Corp has bought the Wall Street Journal. I would like to extend that to look at local newspapers around the countries (such as all those listed here.
","['data-request', 'companies', 'media', 'publishing']",
City mayor/council racial demographics,"
I can't seem to find any data regarding racial demographics at the US place (city) level for mayors and council members per year.
Is there any resources available with such information?
I would like to know and access them.
","['data-request', 'usa', 'demographics', 'politics']",
Looking for ASL letter and gesture resources (images/datasets),"
I'm planning on working on a project at an upcoming event. I want to translate sign language (ASL) on the fly/teach a computer to translate ASL. I have a cousin who has taken a few ASL classes so I'll have him help verify, but are there any resources for images/gifs/videos of letters and common gestures?
I would be attaching a camera to record the user signing and then translate it.
","['usa', 'images']",
How to get all U.S. census blocks within a state,"
Is there an easy way to download the set of census blocks (12-digit FIPS codes) for a given state?  I've tried using R packages tigris and acs to no avail.  (Well, tigris works but it gives me the shape data for block which is major overkill since I only want to know what blocks are defined for each state.)
","['programming', 'census']",
Why do some patients have no clinical notes in the first 48 hours in the MIMIC-III database?,"
Using MIMIC-III (v1.4), it seems that some patients do not have any clinical (i.e. physician, nursing, respiratory, nutrition) text notes during the first 48 hours of their admission. The number ranges from 5-6 thousand depending on whether you use the CHARTTIME or CHARTDATE against the ADMITTIME. There are, however, radiology notes during this period. Additionally, there are about 15k unique HADM_IDs for which there are no such clinical notes at all.
Do these missing notes reflect missing data? An error in the date/time? Or were the patients in the ER, OR, or somewhere else where perhaps the clinical notes weren't captured?
",['mimic-iii'],"While this may not be the definitive answer (disclosure: I am not the author of this dataset), further digging revealed that almost half of the missing notes were associated with admission source Clinic referral/Premature, while only 2-3% of this type are found in notes that do have clinical text notes present. I would hypothesize that the missing notes are due to some combination of 1) the admission dates of urgent clinic admits may falsely appear earlier than the ""actual admission,"" thus the first 48h are actually in the outpatient setting 2) patients may end up boarding in some kind of obs or pre-admit area, where notes are not complete or perhaps not captured. However, this still wouldn't explain the other half of the missing notes without the Clinic referral/Premature designation. "
Sensor data trains dataset,"
For an experiment I'm looking for a particular type of data set, been looking for quite a while but couldn't find any data sets which even remotely match this description. Are there any good datasets on the internet with these characteristics:

time series
sensor data (temperature, humidity, velocity, frequency, ...)
collected on trains (or comparable vehicle)
available in tabular format, like CSV, XSLX, ...
(or as long as I can convert it to a tabular form and use it locally it should be okay.)

The purpose of this is to emulate a bunch of sensors with real world values. Based on the data, I could let a 'sensor' output a value at a particular rate, for example 20 Hz. This data preferably comes from trains because I need to emulate train sensors, and I don't have access to a real train.
","['data-request', 'transportation', 'time-series', 'csv', 'sensors']","Not sure if this dataset matches your requirements completely. At least it reads as a dataset from a German logistics company having sensors mounted on shipping containers. The description is in German but the field names of the dataset are mainly in English.It contains lat/ lon coordinates, motion, humidity and temperature values. And it comes in csv format already."
Unemployment Data,"
Where can I find data about unemployment data (any country) as well as other economic data, e.g. Gross domestic product, Living wage and etc. 
In Russia I find only 15 rows of data. I cant build a model based on this data to complete my goal of developing a model for forecasting unemployment.
","['data-request', 'demographics']",
ArXiv data download per category,"
I want to download all articles related to a set/category, say cs.AI. I came across bulk S3 access, but that contains all the articles and is about 725GB of today (02-April-2017).
References:
https://arxiv.org/help/bulk_data_s3
",['data-request'],
Database of French companies,"
Where can I download a database of all French businesses?
It must be free, and contain as much details as possible about each company.
","['data-request', 'business', 'france']",
Low resultion bathymetric and elevation data (eg ~ 20' by 20`),"
I am looking for a low resulution data set (grid) of the world that contains the elevation above or depth below sea level, respectively. For my purposes, it's enough if I can display the entire data set on a laptop screen. For example, with a 20 by 20 minute grid, that would be 1080x270 pixels. It could by slightly larger, though.
","['data-request', 'geospatial']","You can use the ETOPO dataset by NOAA NCEI.  It has a 1' resolution, which you can of course downsample according to your needs.Several derived data sets are available as well."
Dataset of Home Appliance Usage,"
I'm interested in obtaining a dataset that includes the electricity usage of individual home appliances measured at hourly intervals. An example of such a dataset is the IRISE Project from REMODECE. Unfortunately the data provided on their website contains daily averages and I need the data for each day. Does anyone have any idea of datasets that contain this information, or how to obtain the full IRISE dataset?
","['data-request', 'energy']","The Almanac of Minutely Power dataset Version 2 captures three major types of energy consumption, namely electricity, water, and gas. It includes data from many individual home appliances such as clothes dryer, clothes washer, dishwasher, heat pump, fridge, TV, wall oven, etc.
The data were captured in a Canadian residential house over a 2-year period (1 minute intervals). Also, it has been beautifully cleaned and ready to be analyzed.DRED (Dutch Residential Energy Dataset) contains energy consumption data of a residential house in the Netherlands over 6 months (1 minute intervals). It also has data of individual appliance."
"Are there any US Census columns that can give me information about rents with respect to the size of housing units? (bedroom, sf, etc)","
The US Census department provides a fair amount of data on rents within areas. Median Gross Rent, Average Gross Rent, you've got the normally bands of rents ($800-$999, $1000-$1249, etc). But these rent numbers could be for 1BR apartments or massive homes. Are there any columns that could shed some light on rents with respect to the size of housing units? I don't think the census department collects square footage of homes, but maybe bedrooms?
","['us-census', 'real-estate']",
Is there an American Community Survey dataset that provides individual-level data at the census tract level?,"
I am hoping to estimate the number of five year-olds below various poverty thresholds by census tract. The ACS definitely asks these questions individually, but no data source I've found can provide this exact statistic. What I've tried:

American Fact Finder: Can produce summary tables of either estimated number of five year-olds by census tract or estimated number of individuals below poverty thresholds by census tract, but not a combination of the two. This goes for their online interface, their summary file, and FTP as far as I can tell.
IPUMS: Provides individual-level data that allows for such a combination of variables, but does not provide it at lower than the PUMA geographic level.

Does anyone know of a source that could provide me with such data? If it matters, I'm looking at 2015 5-year estimates.
","['data-request', 'us-census']","To answer your first question: No, there is no open data version of the American Community Survey with PII (Personally Identifiable Information).As for your original query, Table B17001, does provide the age breakdown between those below the statistical poverty threshold and those at or above the statistical poverty threshold.The AFF link I provided is a modifiable link through something the Census Bureau calls deep linking. My suggestion is to figure out which state's Census Tracts you'll want, figure out the FIPS code for that/those state(s), and modify the link. You'll need to create at least two since the Census Bureau provides a limit on geographies per request if you're doing a nationwide download (last I checked the limit was 50,000 and there are ~74,000 Census Tracts)."
NSF Abstracts Dataset Update,"
We're looking to analyze data from the last five years similar to the NSF Research Abstracts
Is there an updated dataset that covers a time after 2003? Are there other text datasets relevant to NSF grants, or research funded by the NSF?
data.gov has some data, but it doesn't seem like they have any text data describing proposals/grants from this period. Even a link to a website that we can scrape would be helpful.
","['data-request', 'data.gov']","The NSF puts all their grant data on the web, and for a given year you can download the zipped file at the following URL:https://www.nsf.gov/awardsearch/download?DownloadFileName=YOURYEAR&All=true"
Dataset Wanted: Classification,"
I'm currently working on a paper that I want to evaluate on a publically available dataset. The following requirements apply:

Classification (target variable is boolean or a factor)
n observations of m objects
1:m of the objects are observed multiple times (the more, the better)
there exist objects m that are always classified as 0 and objects that are observed at different states (0/1)
every object m has a unique id (statements like ""object a had class 0 at observation n_1 and class 1 at observation n_2"" are possible)

E.g.
+------+----------+----------+----+
|class | feature1 | feature2 | id |
+------+----------+----------+----+
|    1 |      1.1 |      0.3 |  a |
|    0 |      0.8 |      0.4 |  a |
|    0 |      0.9 |      0.3 |  b |
|    1 |      1.0 |      0.3 |  c |
+------+----------+----------+----+

Does anybody know a dataset that matches the criteria and is able to share a (link to a) .CSV? E.g. to the UCI repository.
An example is the forrest fire data set. This dataset holds several ""forrests"" (m, identified by coordinates) and the target is to predict if there was a fire or not. Almost Every forrest m is observed more than once - which is perfect.
","['data-request', 'classification']",
Categorized Data for Deep Learning,"
I want to create deep learning neural network to recognize opinion in text. Is there any database where I can find categorized text sets so I could use it to feed my neural network? Can you provide me some examples?
","['data-request', 'machine-learning']",
Using NOAA api to get historical hourly temperature data,"
I've been attempting to use the NOAA api to get hourly temperature data for a specific location when given lat/lon coordinates. I can find the nearest weather station within an area of lat/lon coordinates using the station section of their api, but I need information from the ISD (Integrated Surface Database) and have absolutely no idea how to see which station actually has access to this database, or if I'm even doing this the right way at all.
I'm so lost! This is what I basically need to do:

receive input of latitude/longitude
find nearest station/location that the ISD has historical hourly temperature information about (last ~5 years or so)

and I really have no idea how to go about this using the NOAA api, or if I even need to use the NOAA api. Do I need to just download this information offline and then access it from a CSV or something similar? Any help or documentation you could provide would be very much appreciated. I've found very little documentation during this whole process and it's making it very frustrating.
Thanks so much!
edit: just wanted to note that I am not accessing the hourly data for any sort of profit, it's for an internal program that we're using to run simulations on our solar thermal panels
","['api', 'noaa']",
A free tool to find grants from IRS 990s?,"
At the beginning of 2016 the IRS finally opened up their electronically filed 990 forms from nonprofits (see article from the Sunlight Foundation). All of the 990 data is now machine-readable and uploaded by the IRS to Amazon Web Services.
Amazon provides instructions on how to interact and procedurally use this data trove, however I can't seem to find any free website that has actually done this.
Right now the only way I know of how to find who a Private Foundation has given money to is:

Tediously read through each Foundation's actual IRS 990-PF form and
look at each grant recipient.
Pay for a subscription (starting at
$200/mo?) from FoundationCenter.org to use their database.

Does anyone else know of any other ways or a free database that's already been created from all of the data that the IRS placed on AWS?
","['uses-of-open-data', 'irs']",
Mimic III: clinical note match with icd9 code,"
With noteevents how can we match the icd9 code for a given clinical note from the diagnosis table. It seems that the subject_id, HADM_id are not unique. 
",['mimic-iii'],
New delimited shapefile for Delhi,"
I was looking for a shapefile of Delhi (ward-wise) updated after the delimitation of its 272 wards this year.
I got the old shape file based on delimitation in 2007 here.
I have individual images of all the new wards here (last 3 items in the list on left), but I need a complete updated ward-wise map of Delhi.
","['data-request', 'geospatial']",
Where can I find DR Congo's electricity transport network geographic data?,"
I've been told that the geographic data for DR Congo's electricity transport network is available on google earth.
I can't find it though. Is there a special place to find this data?
","['data-request', 'geospatial']",
Billiards or Snooker Data,"
I am interested in developing an index for rating for player ability in billiards or snooker. To do so I was hoping to get a dataset consisting of attempted shots and their success with other factors (distance from object ball, angle of cut, distance from pocket) etc. 
Is there any dataset that exists like this?
","['data-request', 'sports']","My favourite source for all-things-snooker is CueTracker.It features high-completeness at all times and a plethora of statistics covering all manner of things (from both professional and amateur tours), all put together and maintained by an amateur snooker player and enthusiast."
"Sub-licensing an ""Open Data Commons Attribution License (ODC-By) v1.0"" Database","
I have my own database that I would like to combine with another database for redundancy. The other database is released under the ""Open Data Commons Attribution License (ODC-By) v1.0""
Can I license my combined database under this same license?
","['api', 'uses-of-open-data']",
Sydney bus routes kml or csv or GIS datasets,"
I am trying to import Sydney bus routes into a google map. Are there kml, csv or GIS datasets publicly available? 
I couldn't find anything on data.nsw.gov.au or data.gov.au.
","['geospatial', 'public-transport', 'kml']",You can look into the Sydney GTFS-Files: https://transitfeeds.com/p/transport-for-nsw/237The stops.txt contains the coordinates of the stops and the shapes.txt should contain the shapes of the lines.You can use gtfs2geojson to convert the GTFS-Shapes to GeoJSON
List of houses parcel number US,"
Some government sites or real estate sites like zillow, provide a parcel number for houses which seems to be a unique identifier for that house; is there a site where I can find a list of all parcel numbers in US?
","['data-request', 'real-estate']",
Websites reliability database,"
It is a bit subjective, but we can all agree that guardian.com is more reliable than clickhole.com
Here I define ""reliability"" as the tendency to publish information that are considered true by the majority of academics in the relevant field, and the tendency to not publish information that is later found to be erroneous.
Is there a database giving websites a reliability score?
The score could be decided by experts or rated by users or somehow generated (for instance by seeing how often the website is used in Wikipedia citations).
Sometimes very different publications are hosted under the same domain name, so it might make sense to have a finer granularity (by URL?) if needed.
The database should cover at least websites than market themselves as news websites or reference websites.
Such a database already exists here but it is not open data, and it is only available as a web interface or browser extensions, not available as a full download: http://www.lemonde.fr/verification/
","['data-request', 'reliability', 'news']",
Is labevents table having lab values for tests before and after ICU admission?,"
I am noticing, that labevents table has labs values, from before and after critical care units admissions - icu stays, correct me please if I am wrong ?
So lets say there is patient X coming into ICU for 4 days, then staying in the wards (usual floor, not ICU) within the hospital and obtains more bloodwork, i understand, there is a high change of these results of bloodwork, also goes into labevents table ?
Always sometimes ?
",['mimic-iii'],
Hydroponic/Vertical farm system historical sensor data,"
I'm working on Machine Learning project to improve/automate hydroponics farming systems. Is there any datasets covering crop yields in vertical/hydroponic farming setups ? Any hints or tips on how find such data will be highly appreciated.
","['data-request', 'machine-learning', 'agriculture']",Plant OS a research group in Malaysia involved in Open Agriculture Initiative works published their first datasets on Github: https://github.com/plantOS/plant-os/tree/master/datasets
Where does all recipe get their on sale data? [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 6 years ago.







                        Improve this question
                    



I had gone to Safeway on Monday to pick up some items, that you posted that were on sale. But they had no idea or how they got posted. Can you please explain so I don't waste my time or has chasing these deals, while trying to make your recipes.
",['data-request'],
"Icons set to represent Wikidata classes (hospital, park, waterfall, prison, school, etc)","
I am looking for icons that can illustrate Wikidata classes such as:

Q16917   hospital
Q22698   park
Q34038   waterfall
Q40357   prison
Q3914 school
etc

I could use each class' image property, but the image is usually a very detailed picture so using it as an icon would be a bad idea, it would be unrecognizable.

The icons should be recognizable even at small scale, for instance when used as pins on a map.
The icons should all be in the same style.
It would be wonderful if each icon's filename could include the Wikidata QID or at least the class name, for instance icon-Q16917-hospital.svg. If not included, I will write the mapping myself and make the resulting set available to all.
Open license, free to redistribute and modify, if possible no attribution required.
Ideally the icon set would be produced by a community whose explicit goal is to cover as many Wikidata classes as possible.

Context: My app shows a map of nearby Wikidata items.
","['data-request', 'images', 'wikidata']",
"What is the value of standardized metadata (e.g. OAI-PMH, LOM, Dublin Core) in the days of search engines?","
What is the value of standardized metadata (e.g. OAI-PMH, IEEE-LOM, Dublin Core) in the days of search engines? Sites that offer open data (e.g. Open Educational Resources), want their content to be found and used. Often emphasis is put on including correct standardized metadata to this aim. These enable repository harvesting services, such as Jisc's store, Europeana, etc. to find the data.
But I never see one of my students lookup something at such a service, neither do I do myself. Everyone looks up with a search engine, such as Google. Google (or another search-engine) is the default start of a web-look-up. Specific look-up services are only used for specific subjects (e.g. finding flights, hotels, public transport travel information, second hand goods, scientifical publications, etc.), for all the rest generic search engines are used. 
Metadata then might help retrieving if the search engines would use them. I cannot find much about that. I only found that Google does not use the 'keywords'  tag and stopped using OAI-PMH. 
That leaves me with the question 'how important are standardized metadata nowadays'? Isn't search engine optimization with good descriptions and titles, meaningful URLs etc. more important nowadays?
","['metadata', 'search-engine']",
public source of streaming IP addresses,"
I'd like to build a data pipeline, for demonstration purposes, that enriches a stream of data containing IP addresses with location, ISP, organization, etc... using MaxMind's GeoIP2 Downloadable Databases.
Does anyone know of a public source of streaming data that contains IP addresses? Perhaps something in the cybersecurity space (since this domain often deals with IP addresses)?
","['data-request', 'api', 'real-time']","You could use torrents to collect the IP addresses of peers, although the coding is a bit tricky because of the protocol. I was looking into it as a hobby project, to use Python libraries. See here for more details.For fun, Netflix Uses Pirate Sites to Determine What Shows to Buy"
Contents of sheet music songbooks,"
I want to use a software (excel?) to get my sheet music organized.
But typing in all songs of all books by hand is annoying and error prone.
I am interested in all kind of data about the songbook and the pieces, e.g.

song title
composer
publisher
date published
page number
isbn number of songbook

Unfortunately the information shown on amazon.com or on the
publisher's websites are not enough (e.g. page number 
is missing most of the times).
How can I get this kind of information?
Does anybody have such lists in structured form?
","['data-request', 'music']",
Accessing historical data from the U.S. Census of Manufacturers,"
I am looking for historical data from the U.S. Census of Manufacturers for the period from 1945 to today, and ideally even for the period before 1945. On this website, I found out that such data does exist - at least from 1947 onwards. However, because the original reports were published as books (see this one, for example) I am not sure whether the historical data was digitized at some point and if it is available.
Can I download the data somewhere? (If so, where?) Or will I need to go to a library and digitize everything myself?
","['data-request', 'usa', 'economics', 'historical']",
Are there any datasets for electric vehicle range estimation?,"
Are there any datasets out there which provide details about an electric vehicle, the trips it took and change in remaining range? Or something similar which can be used to test on machine learning algorithms.
Edit:
I found the the chargecar dataset here after looking through some papers on range estimation. Anything similar but larger and with more recent cars would be ideal.
","['data-request', 'machine-learning', 'transportation']",
Long haul flight density at Dulles International Airport,"
I have an emergency department admission data-set for deep vein thrombosis. Long haul travel is a risk factor for DVT. I would like data on long haul travel to see if there is any correlation with DVT. Therefore I would like information on the number of long haul flights at Dulles International Airport over the course of the year. For example are there peak months? 
","['data-request', 'medical', 'global', 'travel']",
"Oral contraceptive sales in the USA, especially Washington DC and Maryland","
I have an emergency department hospital admission data-set for deep vein thrombosis (DVT). Oral contraceptive use is a risk factor for DVT. I would like to correlate oral contraceptive sales with hospital admissions for DVT.
Therefore I am looking for data on contraceptive (particularly oral) sales in the USA. If specific data on sales in Washington DC and Maryland is available this would be ideal. 
","['data-request', 'usa', 'economics', 'medical']",
Any AVL raw and open data?,"
Does anybody know any Automatic Vehicle Location (GPS) raw data source for transportation analysis? (Except SFMTA) 
","['data-request', 'public-transport', 'traffic']",
Does this violate copyright of music/lyrics/sound?,"
So, we are beginning to create a Karaoke app. And we have few queries in the copyrights aspect. We would like to have these cleared before we get any further with our app's development.
The decided functionality of the app is, user shall upload a song track from their iPhone and upload it in our app. Our app sends that to our backend which process the song track and return its karaoke version with suppressed vocals. 
The doubt here is, will Apple reject this? Since we will never be sure whether the user uploaded a song for which he has a legal copyright.

Is it ok to let users upload the songs irrelevant of copyright? (Consider Dubsmash app, I believe not all the users are uploading copyright protected audio clips)
Say, we would like to include few songs in our app by default (like in Smule app). Do we need to buy copyright/licenses for those songs and then upload or is there a work around?
And what if the app is targeting a specific country alone (India)? Does it still need to satisfy U.S copyright law?

Any help is much appreciated. And I am not sure whether this is the right place to ask this question, if not it will be great if could point me a place to ask these questions.
Thank you!
","['api', 'licensing', 'programming', 'legal', 'music']","As long as you don't keep the song anywhere on your servers, and have clear warnings ""Do not transform songs that you are not allowed to transform"", I believe you don't risk that much. You are just an audio conversion online tool, and your app is just a music player.Yes, you will need to buy the songs you want to include. Contact a music company and see what they offer for what price. You can also choose songs that are free to embed in your app, check for instance https://www.jamendo.com and check the license of the songs.India and the U.S. have copyright agreements, you can not ignore copyright of a song just because its copyright is owned by a U.S.-based company.Will Apple reject it? Nobody knows, Apple takes arbitrary and sometimes incomprehensible decisions."
Global Ground Slope Data,"
Does any open global georeferenced dataset on ground slope exist?
Precision of 0.5x0.05 degrees longitude-latitude would suffice.
","['data-request', 'geospatial']","With-out a clear definition of ground slope (no Wikipedia definition), I am assuming it basically is proportional to the gradient of a topography data set. These are available at a resolution of 0.002 deg.Ignoring earth curvature at that resolution, a simple two dimensional numerical differentiation should suffice.  Please correct me, if I am wrong."
OpenFDA Bad Zip File?,"
I have been working to build a download and unzipping ""pipeline"" going (as a noob) with OpenFDA data, and I saw with interest @h.das' closed post about zips - ""Python crashing when trying to read zipped json files"", but this issue to me seems more like an issue with the source file than my noob status (tho of course I'm out a limb there) or the lack of RAM (I threw a TON of RAM at this, btw).
Programmatically with python 2.7's zipfile library and on the plain ol' bash cli on a ubuntu machine as well as through chrome on a win10 laptop I get (just now 2017-03-17 9am ish) a failed file error of one kind or another with the following URL:
https://download.open.fda.gov/drug/event/2011q4/drug-event-0006-of-0007.json.zip
It's easy enough to pass over with exception handling but I don't want to miss some 300+MB of data in the middle of what seems like exactly what I want to look at.
",['openfda'],
Download list of the name of every airport in Western languages,"
I am looking for a list of all airports in all countries in all Western languages. At least, in all EU languages in a CSV or tab-separated download.
Would appreciate any pointers
","['data-request', 'geospatial', 'travel']",
Human body measurements dataset,"
I'm doing research on good ways to take measurements in order to make a match between someone's morphology and a garment.
As I don't have the resources do tests in the field, I'd like to use a dataset of containing basic human body measurements (height, weight, chest, waist) for a diversified population.
Do you know about any good resources I could use to do such a work?
EDIT: I noticed how my question lacked of precision. So ideally the dataset would contain as basic information: 

Height 
Weight 
Neck size
Chest size
Waist size

for adult men and women.
",['data-request'],
Issues harvesting metadata from Data.gov,"
I'm trying to harvest data from the CKAN API of Data.gov, using Python code. Doing this however, I ran into problems. I use the following URL:

http://catalog.data.gov/api/3/action/package_search?rows=1000&start=0

And increment the 'start' parameter after every request. I have run into two difficulties:

It seems like I get throttled: Sometimes after a few pages or even at the first page, and other times only after 120 pages (1000 results each) I experience request timeouts, and progress becomes extremely slow (e.g. 100 kb/s). I do have an apiKey for api.data.gov (Is this actually valid for the CKAN API?), but if I include this as 'Authorization' in the http header, still timeouts occur. 
Using an offset of 42000, often only 998 packages are returned, although it is still far from the end of the list (192.633). This occurs by doing the following request: http://catalog.data.gov/api/3/action/package_search?rows=1000&start=42000. Other times it actually does return 1000 results here, but returns 998 results on a later page...

Can I do anything on my end to prevent the throttling from occuring, or is something else wrong?
","['api', 'data.gov']",
When do Census Tracts get their boundaries adjusted?,"
I'm curious as to when the 2020 US Census Census Tract geometries actually get adjusted to account for any changes. I know they're semi-permanent, but that can indeed change from year to year.
We have some boundaries that are defined by grouped Census Tracts, and wondering what the earliest year is I might possibly be able to reconfirm/adjust our boundaries.
","['us-census', 'census']",
Where can I get wind data for southern China for arcgis analysis? (Specifically Hong Kong),"
I'm doing a GIS school project where I have to use the GIS software to locate and assess a suitable area for an offshore windfarm. As I live in Hong Kong city (Southern China), I'm going to base my project around the coastal area of the city. But I'm having a really hard time finding data that will allow me to map out wind speed and/or wind density so that I can produce contour maps like the one below. Help is much appreciated. Thanks!

","['data-request', 'geospatial']",
U.S. Census CBP Employment by year at aggregate U.S. level,"
I'm analysing employment by U.S. CBSA in the period 2001-2014, based on U.S. Census CBP data. I'd like to obtain aggregate employment in the U.S. (50 states+DC) based on CBPs. Since CBSA data is partial, I can't get country-level aggregates by just summing CBSA data. (I could get it by aggregating county-level data but that's a lot of work.) Is there a source for U.S.-level CBP-based employment year by year? (It may be somewhere on the U.S. Census website, but I can't find it.)
EDIT 1: Based on this answer, I found this U.S. Census website page, where the link ""Economy-Wide Key Statistics (Number of Establishments, Annual Payroll, Number of Employees, ...)"" leads to an empty American Fact Finder table.
EDIT 2: Another link ""County Business Patterns (Number of Establishments, Annual Payroll, Number of Employees, ...)"" on the same page leads to an American Fact Finder table with total employment for a single year at a time from 2005 to 2014. So you need to manually click and copy-paste 15 times. But I'm still missing the same for years 2001-2004.
",['us-census'],"U.S. total CBP-based employment is available from https://www.census.gov/programs-surveys/cbp/data/datasets.html. Click through each year (since 1986) and you will find a ""Complete U.S. File"" link to a simple text file. It contains total US employment for that year in the ""EMP"" column, 2nd row."
I am looking for Product (computer systems specifically) datasets,"
I am working on an expert system project and I am looking for sample data-sets for computer system products (laptops, desktops, tablets, etc.). This data should include at least price and specifications.
Do you know where I can find data which has this information? 
","['data-request', 'products', 'computing']","As you haven's specified a timeframe of the data you are looking for, you can try the amazon crawl: http://jmcauley.ucsd.edu/data/amazon/Particularly:
metadata (3.1gb) - metadata for 9.4 million productsWhere:I suppose you can filter by category to get only laptops,desktops, tablets,etc..Mind that the data is oldish: May 1996 - July 2014."
Vector data for Volcanic Ash Advisory Centre (VAAC) regions?,"
I would like to use the boundaries of the VAAC regions, as a layer in a GIS I am building.  I can find images of various (1) quality/extents, but no vector data. 
For example, Wikipedia provides the following map (image details), though it is out of date because there are no longer any parts of the globe not covered by a VAAC (see link to Wellington map below).
Does anyone know if such an open vector dataset exists?
Obviously some of the boundaries are defined by latitudes and longitudes, but the squiggly bits are defined by Flight Information Regions (FIRs); so if there are any open vector datasets that exist for FIRs, that would be useful too.

1 Maps of VAACs provided by the VAACs are: 
London, Toulouse, Anchorage, Washington DC, Tokyo, Buenos Aires, Wellington, Darwin, Montreal ~ no map found
","['data-request', 'global', 'public-transport', 'geohazard']",
Shape dataset for classification,"
For a project, I need a shape (circle, square,triangle, cylinder, rectangle) dataset and I want to use this dataset for image classification.
The images can have width and height in the range 256.
",['data-request'],
College scorecard only has 40 states?,"
So I just downloaded the college scorecard datasets and import into R, I used a unique() function on ""STABBR"" and it only returned 40 unique values for states, what happened here?
","['collegescorecard', 'programming']",
Religious Institution Survey Information,"
I am after some data to assist in analysing religious bodies to detailed things like: -

the frequency of attendance
Giving/tithe
demographic breakdown
location data of the particular church/mosque/temple/etc.
size of the members and adherents
etc ... 

But these data I am interested in finding out not on a national level, but on an individual church/mosque/temple basis. Some trending data would be great too.
I can find some data around these for USA institutions, but for the UK/Australia/Canada/NZL and other countries would be great too!
","['data-request', 'geospatial', 'religion']",
"Database or feed of software vulnerabilities, aggregated and with correlations","
Is there a comprehensive free and open source database of aggregated and correlated software vulnerabilities available anywhere?
",['security'],
Datasets like MNIST for image classification,"
For my thesis, I developed some tensor-based algorithms for image classification. I have been using the MNIST dataset as benchmark for quite some time now but I want to test my algorithms on other datasets. Because I need images that are already preprocessed (centered, rotated, ...) there aren't much datasets I can use. For example, the COIL datasets contains images of objects that are rotated which isn't good. I have found one other dataset with faces that I can use but are there any other already preprocessed dataset I can use?
","['data-request', 'machine-learning']",
Interaction based recommendation system dataset,"
Is there a recommendation system dataset where the data is not in term of ratings, but number of times a user has interacted with the item? I know last.fm has a set, but it is rather small and I have not found other published results on it. Hopefully the set also has existing benchmarks.
","['data-request', 'machine-learning']",
How to download in excel/csv all the FDA drug enforcements available?,"
The openFDA drug enforcement reports API download returns results in one large JSON file.
Unfortunately I have no experience in parsing/programming JSON and I need the drug enforcements data in Excel/CSV format (2004-present as far as I know).
Can anyone help please?
","['data-request', 'drugs']",Download the JSON file and open it with a Json to CSV converter like http://www.convertcsv.com/json-to-csv.htmYou will get this file.
Data on Surname Origins and the United States,"
I'm doing some fun analyses in my free time at home.  Has anyone seen a dataset that lists out surnames/family names and their place of origin?  I haven't even found one that gets to a country-level for origins yet but I'd like to get as sub-regional as possible.  I'd prefer a list that hits surnames commonly found in the United States but I'm open to anything - like I said, this is kinda for practice and fun.
Have a good day,
-Nate       
P.S. I've seen a couple of questions on here and other forums that ask about names but not necessarily the combination of surnames and their origin.  If you've seen an answer elsewhere, I would love for this question to have already been asked and answered. 
","['data-request', 'usa', 'names']",
European or Danish data set that specifies roof types,"
I am looking for a data set that specifies the roof types (flat/hip/gable) of buildings in Denmark.
A second best result would be the same data for another Northern European country.
I have looked into the cadastral data of Denmark but could not identify datasets that would contain the roof type (they do have a Minecraft dataset though).
Would anyone know of such a dataset for Denmark or any other Northern European country?
","['data-request', 'geospatial']",
A data set for click through rate,"
I'm particularly looking for the dataset in the article
Predicting Clicks:
Estimating the Click-Through Rate for New Ads
Does anyone know if this data set is available? 
(Note: I checked all the references and didn't find the data source. I contacted the authors and am waiting for their reply).
",['data-request'],
Is there a set of data points available to draw an outline of the coast of the British Isles?,"
I would like to plot a map of the coastline of the British Isles using gnuplot, for which I need a data set of points along the coast. Is this available in csv form, please, or help to convert it to this format? A low resolution outline is all I need.
","['data-request', 'geospatial', 'uk', 'csv']",
Where can I find GIS sub-division boundary data of Saudi Arabia and Turkmenistan?,"
Where is it possible to find GIS shapefile data of the second-level admin boundaries of particularly Saudi Arabia and Turkmenistan, as well as a number of other countries/territories?
Neither of the GADM and DIVA-GIS websites include these, and in the case of Saudi Arabia, the first level areas (regions) are actually out of date (compared to Saudi's statistical website - Population and Housing Atlas) . 
Saudi Arabia - Regions and Governates (General Authority of Statistics KSA)

Turkmenistan - Regions and Districts (Wikipedia)

For some reason, these boundaries barely exist as shapefiles amongst the free administrative datasets available, including their respective government websites. The only organisations that I have found which do provide this data, are GFK Geomarketing and Allmapdata (Mapmechanics), however these are sold as large data packages that include other datasets, such as postcodes and topography which are highly expensive. 
I am also looking for similar administrative data for smaller countries, that is not available on GADM or other likewise sites including:
Cyprus, Malta, Aruba, Anguilla, Belize, Lesotho, Western Sahara.
","['data-request', 'geospatial', 'asia']",
Does openMRS have open data?,"
Does the Open Medical Records System expose patients medical records for public data mining or research? 
",['medical'],"While I cannot at present find a citation to support this assertion (I'm on mobile and their site isn't mobile-friendly), I am almost positive from having worked with Open MRS once that OpenMRS does not provide any open data from the organizations running their open-source health record system.For one, this would be a violation of the open-source ToS, which explicitly state that Open MRS does not record any of the confidential patient data itself. Second, just to clarify, the 'Open' part of their namesake refers more to the fact that the software itself is open for use as a platform. Not to open as in open data."
Dataset of planets and moons in the solar system,"
Where can I find such dataset.
For each object, I would want name, size, distance from sun (if applicable), mass. Can be separate dataset for all moons and for all planets. (and maybe asteroids).
","['data-request', 'astronomy']","Devstronomy project provides the datasets for planets (plus Pluto) and their satellites(moons) in accessible formats (CSV, JSON, SQL), available for download. The datasets originate from  NASA Jet Propulsion Laboratory. Check the site for details.Edit: please note that I'm the author of Devstonomy project. I had a similar issue and did not find a solution. So I've provided the datasets on the Devstronomy site."
Where Can I Find Library Utilization Data?,"
I am interested in data on the utilization of US libraries. Ideally I would like listings of libraries with locations, a complete listing of their available catalog of books, and a history of which books were checked out when. It's fine if the check out history is de-identified.
Is there a centralized place where this data is available rather than querying individual library systems which are usually organized at the county or city level?
","['data-request', 'usa', 'government']",
Looking for shapefiles of map of assembly constituencies of India?,"
I used shapefile from the link: https://github.com/datameet/maps/tree/master/assembly-constituencies
to create district and assembly constituency level maps of India. While the district maps look fine. The assembly constituency level map has a huge chunk of Uttar Pradesh missing.

","['india', 'geospatial']",
Ozone in Fruit and Vegetable Cleaning and Storage [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 6 years ago.







                        Improve this question
                    



During post harvest storage, surface infections on produce can spread and cause significant losses of the crop. The use of ozonated water for washing and disinfecting can reduce these losses and maximize returns. Ozonated water is a convenient way to wash fruit and vegetables and offers the following advantages over traditional chlorine based sanitizers.
The level of dissolved ozone in the water can be accurately and simply controlled using ORP (Oxidation Reduction Potential) measurement.
The disinfectant effect of ozone is not dependent on the pH level of the water.
Ozone will leave no residue on the produce that may affect taste or reduce shelf life.
Ozone is generated as required and therefore needs no special storage.
Ozone has no ongoing chemical purchase or disposal costs.
Ozone leaves no residue in the water and therefore makes reuse simply a matter of filtration.
Are these claims correct or not?
",['research'],
Getting ImageNet 21k dataset,"
I want to train a model for a wide variety of classes. So, I would like to get an ImageNet 21k. Where is it possible to get it (besides the official website as they are not very responsive)?
","['data-request', 'machine-learning', 'imagenet']",
Determining a drug's approval status from ClinicalTrials.Gov/chEMBL,"
I am trying to query these databases and identify trials that passed, and those that didn't. I have gone through and parsed all of ClinicalTrials.gov and matched it to records from chEMBL to build a database. 
The fields I have available to be for each drug are:
+ is_fda_regulated_drug: which is null in 99% of cases
+ overall_status: Terminated, Completed, Recruiting, etc. 
+ phase: ""Phase 1"", ""Phase 2"", ...
+ primary_completion_date: Date as a string or null
+ primary_outcome: Date as a string or null
+ primary_outcome: mess of text that is too inconsistent to parse
+ start_date: either date as a string or na
+ time_frame: mess of text and often not a timeframe at all
+ CHEMBL_ID: as string
+ FIRST_APPROVAL: a year, but this is first approval for any application, not the study in question
+ MAX_PHASE_FOR_IND: 1,2,3,4

So far the only definitive logic I've been able to define is:
if overall_status = terminated and phase != 4 then the trial failed

Suggestions?
","['api', 'openfda']","Drug approval is called ""marketing authorization"" and is not directly related to clinical trials. A program of clinical trials will usually lead to a marketing authorization in one or more countries. You probably have to look somewhere else on FDAs website. Try Drugs@FDA or have a look at WhoDD to get from drug substance to marketed drug (and approval, maybe)."
Open API for E numbers information,"
Is there any API or open database for E-numbers data that includes information about e-number status (dangerous  / not recommended / valid)?
I've found only this database: https://webgate.ec.europa.eu/foods_system/main/?event=substances.search&substances.pagination=1
But it doesn't include the status info.
",['food'],
Global tide data - is it out there?,"
I'm looking for a tidal range GIS layer. Anything global that shows either mean tidal range, maximum tidal range, or maximum tidal height. I have been trawling the web for tide related GIS layers and they don't seem to be available. If any one knows of a source, please let me know!
","['data-request', 'geospatial', 'global', 'oceanographic']",https://www.arcgis.com/home/item.html?id=3d626ffd8ca1483ca37d32fd430b277dThis data is available as of 2020 and I think is what people are looking for! It was computed using the FES2014 model data obtained from AVISO. It is possible you need an ERSI account to access it.
Are there IMDb datasets with IMDb ID numbers and actor birthdates?,"

I want datasets that have the name of the movie and its link on the site or the tt-number.
E.g. for Jurassic Park (1993) it would be in the format:


> NAME                     ID           LINK
> Jurassic Park (1993)     0107290      http://www.imdb.com/title/tt0107290/



The datasets of actors contain no birthdates, at least not in the ones I can find on ftp://ftp.fu-berlin.de/pub/misc/movies/database/.

Does anyone know how to get those?
Please note: I do NOT want those general imdb datasets!But instead I want ones that have the above mentioned characteristics. 
","['data-request', 'data-format', 'film']",
Places to find credit risk data-sets,"
I am looking for places to get datasets regarding credit risk and risk analytics in financials services.
I have tried many places but was unable find what I am looking for. Can I get any pointer or link to find these?
","['data-request', 'finance']",
Raw data for Central Limit Theorem,"
I want to show my students how Central Limit Theorem works in the real word examples.
More precisely, I want them to plot histograms and make Kolmogorov–Smirnov using SPSS.
I have already prepared artificial data using VBA. However, I would also like to do test on real data.
The data I wish to posses are:

IQ scores
noise in signal

I spend good amount of time browsing Google and open data sites, but I didn't found nothing useful.

Request: Can you help me with finding such data?
Side question: Do you have some tips for how should I browse for such data?

",['data-request'],
Where to find river flow time series for rivers in Europe?,"
I am looking for river flow gauged data for rivers in Europe, i.e. time series.
Data can be peak flow or daily flow (m3/s) but it has to cover all  of Europe's river basins.
","['data-request', 'europe', 'time-series']",I found this website and it is the best solution so far:http://www.bafg.de/GRDC/EN/02_srvcs/21_tmsrs/riverdischarge_node.html 
How can I get salary data on the gamer population in the US and/or Europe?,"
I am trying to conduct a study on the gaming population in the world for market research purposes.  I want to know what the average % of income is spent on gaming (hard/soft ware).  
Are there any open source data where I can extract salary mean/sd statistics from a sample population of gamers?
","['data-request', 'uses-of-open-data', 'europe', 'population', 'games']",
Colorado Ski Areas GIS dataset,"
I am looking for Colorado ski areas in GIS dataset out there that can I download or request them from an individual that worked on them.
","['data-request', 'usa', 'geospatial', 'ski']",
Searching by disease through openFDA API,"
I'm trying to query for all drugs related to a certain disease group (say, for example testicular cancer). How would I structure that query? is this possible?
","['openfda', 'json']","I'm Jack Finch with the openFDA team. Looking at what you're trying to do, I'll suggest a couple queries that should satisfy your needs and link you to the appropriate sections of documentation which explains how it works.If you just want a list of drugs which are related to a specific disease (or any other text string, for that matter), you can search for that string and get the count of substance_name.For example: https://api.fda.gov/drug/label.json?search=""testicular cancer""&count=substance_nameIf you'd prefer to have all of the details for the drugs, you can use the limit field to specify how many results you want maximum (the default is 1). If you search just for testicular cancer (https://api.fda.gov/drug/label.json?search=""testicular cancer""), the meta field will include a total field, indicating how many records were found by your search (40 in this case). You can then set the limit to an appropriate amount. Note that while displaying 40 records in the browser is feasible, any more than 100 may result in a delayed response or even a crashed browser - there are limits to the amount of data that we can easily display over the web.The search with the limit qualifier set looks like this:https://api.fda.gov/drug/label.json?search=""testicular cancer""&limit=40The basics on searching can be found here. Information about drug label specific fields can be found here. Let me know if that addresses your question adequately."
Dataset of Sentences Classified by Type?,"
Where can I find a labeled dataset of sentences classified by type (interrogative and declarative)? I'm particularly lookings for Russian sentences, but other open and labeled datasets of other languages will be helpful.
Basically, I need a dataset of sentences, which not consist only of question words, and sometimes don't have a question mark. It will be good, if dataset will have some declarative sentences with question mark (e.g. 'The bus has already left?')
","['data-request', 'nlp', 'language', 'russia']","Mark Weisser's SPAADIA corpora consist of 35 transactional dialogues annotated at the sentence-level with function/mood (declarative, interrogative, imperative, etc)He's also got a nice annotation guideline for expanding on this schema.
martinweisser.org/index.html#spaadia_v02"
Library of human faces with tags for displayed emotions,"
Is there an open dataset with images of human faces that's labeled with the emotion that the face displays?
","['data-request', 'images', 'faces']",
Data with Revision/Version (Versioning) History?,"
I'm looking for data set with entry values being corrected, and those corrections are documented with previously incorrect values available as well. This can be in the form of errata, diff files, or old and new versions of the same data set. Ideally, I would prefer data set consisting of numerical/ categorical values that can be used by simple machine learning algorithms like logistic regression. The more the better.
","['data.gov', 'weather', 'finance', 'uses-of-open-data', 'us-census']",
"Dataset of World Cities, Counties, Localities, Provinces, and States? [duplicate]","







This question already has answers here:
                                
                            




Batch conversions of lat, lon to US census tract?

                                (2 answers)
                            

Closed 6 years ago.



I have a JSON list of international cities with country, latitude, longtitude, but not the corresponding state or province associated with them.
Is there a free database of cities that include what I have plus states and provinces.
If not is there a web service where I can run all my latitudes and longitudes to get the state or province for the city?
Please note this is definitely not a duplicate question the suggested answers are for USA only, I'm asking for all any location in the world. 
","['city', 'json', 'global']",
What are some time-series datasets for clustering (and classification)?,"
I'm searching for my thesis about the time-series (non-video) datasets for the purpose of clustering (and classification). By non-video I mean the dataset should not be video data. Any idea of the dataset or where I can get such data? Any suggestions are welcome.
","['data-request', 'machine-learning', 'time-series', 'classification']",
Where Can I find Data on African Startups?,"
AngelList data is very outdated. I want to create a CrunchBase-like  database of African Startups.
Things like this would help:
 - Size
 - Location (City, Country)
 - Website
 - Funding
 - Social Media
etc  
","['data-request', 'africa']",
Smart Grid Smart City -- Customer trial data,"
I am looking for the Smart Grid Smart City (SGSC) customer trial data set. The data set was mentioned, and linked to, in this answer to this question.
I have made an account at the following site in an attempt to access the data, but I get a message that I am

Unauthorised to read package smart-grid-smart-city-customer-trial-data 

For completeness, I was able to access other data sets at the http://data.gov.au/dataset/ website, just not the SGSC data that I am seeking to access.
For those interested, more information on the data set can be found here.
","['data-request', 'energy']",
Where can I download cities' polygons in Wales and England,"
Is there a website to download the polygon that illustrates all the cities in Wales, especially Swansea City?
","['openstreetmap', 'kml', 'geospatial']",
Chronological Series of PCI,"
I need a chronological series of PCI, to compare different maintenance costs (from different maintenance policies).
The file can be in any format but not limited to: txt/tsv, csv, ods, xls/xlsx, and pdf.
","['data-request', 'data.gov']",
need a client request dataset,"
I'm looking for a dataset for client requests (requests posted in forums) for buying device requests (like ""I Want a good budget phone with 2GB ram And Snapdragon Processer."").
","['data-request', 'database']",
API for localized nutrition and food data,"
For a current project I am looking for an API (or 'offline' CSV like format) which contains names and nutrition (kilokalories, protein, vitamins, etc.) of food and ingredients.
What I found so far:

the food API of the USDA: https://ndb.nal.usda.gov/ndb/doc/
the CSV export of the Federal Agency of Switzerland for food: naehrwertdaten.ch (sorry - I don't have enough reputation to post more links)
resolve EAN 13 code to products: http://www.product-open-data.com/
a very similar discussion: Open API for nutritional information and/or food barcodes?

Also there are some commercial APIs for resolving products to nutritions.
But what they are all lacking is multi-language support.
My Use Case are e.g.

User searches for ""basmati rice"" -> gets a response which list all the nutritions of basmati rice. 
User searches for ""Erdbeeren"" (German for strawberries) -> gets a response which listing nutritions for strawberries. 
User searches for ""farine complète"" (French for wholemeal flour) -> gets a response listing nutritions for wholemeal flour.

Just as a example. It is of course okay to first see a list of results and choose between e.g. different brands or variants.
","['data-request', 'api', 'food', 'translation']",
US state-level: Mean and median per capita income for 1950 to today,"
I am looking for mean and median per capita income data for each US-American state and for each decadal year from 1950 to 2010. Ideally, I would like to see the data combined in one data set (in total or per year).
I have found quite a few data sets already but most them date only back to the 1970ies or 80ies. Also, I found this series of data sets where the income data is listed separately for each state but (for now) I would like to save me the trouble of downloading and merging all of these individually. I assume, there must exist some complete data sets on this topic.
","['data-request', 'usa', 'economics', 'income']",
Get metadata from all datasets on Socrata,"
Socrata.org gives a possibility to browse all datasets that are published by their customers with their API via Open Data Network.
I'd like to collect metadata such as:

Dataset size
Number of rows
Number of columns
Number of tables (if applicable)

for as many datasets as possible (possibly all of them).
I see two possible approaches here:

Download whole dataset and calculate metadata myself.
How to automate download of all available datasets?
Download only metadata that has already been calculated by Socrata and is published in dataset description.
What is the API that I should use? Is it possible at all?

","['metadata', 'socrata']","Approach #1 is doable, but not necessary. We'll go with approach #2 here: Download metadata provided by Socrata.The Open Data Network has an official API that you can use to query the various entities and datasets. You should be able to use that to find all datasets in the network (it looks like that might be doable through a single query, without having to script your way past pagination). Be mindful of usage thresholds so you don't get throttled, and be sure to create an API key, rather than abuse the one from the demo page. Each entry has a few fields that will be useful for fetching metadata and other related tasks: The metadata itself is available in a few places. If you just want the row count, one of the easiest ways to get it is via a request to <domain_url>/api/id/<id_no>.json?$select=count(*)+AS+count. This uses Socrata's query language to query the dataset directly. This is also what the dev_docs_url page uses under the hood to display that info.For more extensive metadata, which includes field information, null count by column, update frequency and times, etc., you can query <domain_url>/api/views/<id_no>.json. I don't think number of columns is explicitly included but the columns array's length should give you that value."
Images with symmetry parameters,"
I wrote a program that searches for aesthetic pictures.
One of my parameters is how much a picture is symmetrical.

This picture is taken from 33Pol (from Iran-Isfahan). As can be seen, the water reflection causes a certain symmetry.   
Is there any free or public database containing images + rates for aesthetics + symmetry parameters for this purpose?
For example in this page you can see votes but there are no parameters for symmetrical properties.
","['images', 'programming']",
Is there hyperspectral drone imagery available for free for research,"
We are just looking at testing some processes before purchasing a hyperspectral drone sensor and was wondering if anyone knows any sites where we can download a few sq km of data for testing. It can be anywhere in the world and ideally at a river mouth with sedimentation.
I have checked some of the camera suppliers websites but can't find any sample data. They should all supply some on their websites for people to check what can be expected before purchasing. The white paper specs are just not enough sometimes.
Something similar to https://www.tomstechtime.com/downloads/ would be ideal
",['images'],"Here’s a few example I found.NASA supplies some free AVIRIS hyperspectral data.
https://aviris.jpl.nasa.gov/data/free_data.htmlHere’s an example of using the AVIRIS data. 
http://www.microimages.com/downloads/hyperspectral.htmResonon supplies some sample data with a free version of their hyperspectral analysis tool.
https://www.resonon.com/Products/spectronon.htmlProfessor D. H. Foster has posted various hyperspectral images to his webpage.
http://personalpages.manchester.ac.uk/staff/d.h.foster/default.html"
Versions of CKAN datasets and its resources,"
I am working on an analysis based on open data from a CKAN data store. For this analysis to be reproducible it obviously needs the exact same input dataset. I would hence like to make sure that a resource that is downloaded in a future execution of my analysis is the exact same resource of any current execution. For that CKAN would need to support revisions of resources, but I couldn't find such a mechanism. How does versioning of datasets and its resources work in CKAN and how do I know which part of the data and metadata will never change, and which part could change in the future?
",['ckan'],
Looking for historical data on NBA player-specific salaries and other contract information,"
I would like to find data that describe every player contract in the NBA, as far back into the past as possible. Optimally, this would include salary, term of contract, player agency, etc. 
I search extensively and could not find. It seems that USATODAY had a similar database, but now they only have it for MLB, as in this link. 
Can someone propose a source where I can find these data for an NBA, as detailed as possible and ranging over as many years as possible? Thank you kindly.
","['data-request', 'releasing-data', 'sports', 'historical']",
Municipality 2017 shapefile Europe,"
Where can i find the  municipality 2017 shapefile of Luxembourg or does someone know a site where I can download shapefiles of updated municipalities in Europe? 
","['data-request', 'europe', 'geospatial']",
API or datasets for websites demographics (age & gender distributions),"
Data request
Data: I am looking for an API or dataset where I can find age distribution (age groups: percentage of an age group according to the population) and gender distributions for the biggest websites of each country like: Facebook (USA, Germany, France aso), Twitter (USA, Germany, France aso), Spiegel Online, Instagram aso. Something like Alexa Top 500 sites but with statistics about their audience.
Context: I am working on my Master's Thesis and would like to compare my scientific samples to the population.
Region: I need Data from the whole world.
License: Unfortunately I am a Student and can't spend more that 50 Euro on this data.
Format: A JSON API would be perfect. XML, CSV, XLSX or any other common data type is ok too.
Authority: I need the data to be reliable. That means, the sources of the data have to be visible and official.
","['data-request', 'api', 'demographics', 'global']",
Where can I find data on MARTA?,"
Atlanta, GA has a Metro Area Rapid Transit Authority (MARTA) which has information on trains, passengers, etc. Where can I find this data?
","['data-request', 'usa', 'transportation', 'public-transport']",https://github.com/loren138/martaHackResources
Is there any data on actual average USPS delivery times,"
I'm looking for data on the average delivery times between points for the US Postal Service.  I've found maps on their site with scheduled delivery times but I'm wondering if anyone has data on actual deliveries?
","['usa', 'government', 'transportation']",
Dataset for teaching trustworthy vs. untrustworthy news sources,"
Teaching students to distinguish between trustworthy and untrustworthy sources of news has taken on an increased urgency, and the Chronicle of Higher Education recently described this as a higher education trend for 2017. Are there any freely available datasets on this issue that are amenable to the pedagogy of statistics?  
In particular, I am looking for any dataset on trustworthy versus untrustworthy news sources, or on related issues, such as how the use of different media sources is associated with how well informed a person is.  My goal is to integrate one or more datasets into undergraduate statistics courses in psychology, one course for 2nd year students and the other for 4th year.  I'm certainly willing to simplify the data for teaching purposes if necessary.
","['data-request', 'media']",
US county-to-county and/or state-to-state migration flows - historic data for the 20th century,"
I am looking for US county-to-county migration out flow data. That is, for every county in the United States (say, 1001 Autanga), the data would contain the absolute or relative number of people who migrated to other counties (say, 1002, 1003, ...) in that period.
I was able to find such data for the period from 1995 to 2000 (see here) as well as for the periods between 2000 and 2014 (see here) through the U.S. Census Bureau. Now I am looking for similar data for earlier periods throughout the 20th century. Say, for example for the periods 1920-25, 1950-55, 1970-75.
Any suggestions are much appreciated.
In absence of county data, I would also appreciate state-to-state migration for the same period.
","['data-request', 'usa', 'population', 'county', 'migration']",
SPARQL federation and attribution licenses?,"
Many public datasets are published under licenses that require attribution, such as CC-BY. If I have a public SPARQL endpoint, and allow federated queries to access data from such endpoint, that means that a query result can contain data that is under CC-BY. However, as far as I understand, there's no standard way to incorporate attribution into SPARQL results, even not counting the hassle of actually figuring out the fact that federated query is being used and what kind of attribution each of federated endpoints require. 
So, the question is - what is the best practice for complying with attribution license in such scenario? As the endpoint is public, the combined data can be reused anywhere (so it can plausibly be considered redistributing?) but I see no way to ensure CC-BY compliance (unless I misunderstand its requirements). Does it mean that attribution-licensed data can not be feasibly used in data federation scenarios? Or does it mean attribution requirement does not apply to such scenario, or should be satisfied by the end user of the data (such as publishing the results of a federated query in a paper) and not by intermediary tools processing the data?
","['uses-of-open-data', 'licensing', 'sparql', 'creative-commons']",
Meaning of specific Code status/DNR levels,"
I'm trying to understand the clinical meaning of two of the potential code status levels in the MIMIC3 data.
The six levels are:

Comfort Measures
CPR Not Indicated 
Do Not Intubate 
Do Not Resuscitate
Full Code 
Other/Remarks

In particular, I'd like to know what CPR Not Indicated means and what Other/Remarks means.
CPR Not Indicated could mean: 

""The patient chose to not have the caregivers use CPR, but intubation is ok.""
""The patient chose to not have caregivers use CPR or intubation"" and is functionally no different than DNR
""The caregiver has decided that this patient is not suitable candidate for CPR"" (ie - a futility case)

Other/Remarks could mean:

""The patient has a complex case that cannot be coded. More info in the notes""
""We don't know the patient's code status.""
Something else?

Does anyone know the correct interpretation of these code statuses?
",['mimic-iii'],
Wikipedia Article Category,"
The wikipedia Page View API provides information about the number of page views for a given article, including an option to view top-N articles in a given day or month:
https://wikimedia.org/api/rest_v1/metrics/pageviews/top/en.wikipedia/all-access/2017/01/all-days
I would like to filter these top-N rankings by removing articles about people such as celebrities, politicians etc.
Is there a way to obtain metadata information about an article that would contain such classifications?
","['data-request', 'wikipedia']","I don't think it's possible to filter articles by topic with a single query in the API. However, you can use Wikidata to detect and filter politics, celebrities and so. You'll need to follow several steps:There are different tools for each step, but the most critical one is step 4. You'll lucky if most politicians have occupation:politician but there will likely be several occupation tags for celebrities.Using categories from Wikipedia is another option but I won't advise to take it due to the structure of categories - a category of actors can have subcategories with actors along with subcategories with films, for example."
Did terabytes of data get removed from open.whitehouse.gov in January or February 2017?,"
I received an email on 2017-02-27 promoting the March For Science.
One of the arguments was as follows:

It appears that the Trump administration has removed terabytes of data from open.whitehouse.gov http://open.whitehouse.gov/ replacing it with Trump administration news and press releases. While it says “Check back soon for new data” the removal of this data would be significant set back in science and computing. This situation is well worth monitoring.

Did terabytes of data get removed from open.whitehouse.gov in January or February 2017? If so, why, and is there any mirror/backup of it somewhere else?
","['usa', 'politics']","I'm not sure about ""terabytes"" but yes, the new administration has edited the whitehouse.gov domain, including the open subdomain.  Why?
New administrations across all levels of (U.S.) government, particularly around elected officials, wipe domains and start a new.
While there are many things going on currently with the Trump administration that are bad for open data/open gov, this is nothing new, nor inherently alarming.  Are there backups?
Yes, the Obama administrations entire whitehouse.gov presence is currently hosted at obamawhitehouse.archives.gov/ including the open subdomain.
Furthermore, Max Ogden tweeted out that he had archived the entire subdomain, though I'm not aware of where/if it is online yet.  You can also look/view/track on the Wayback Machine; I recommend doing this for some clarity around how often this occurs. I'm most familiar with virginia.gov which gets wiped with every new administration; its a great example because Virginia doesn't allow for back-to-back governors, so every four years we have a new site.  Max Ogden's tweet:Executive Office of the President Open Data Archive Backup"
API or datasets for age & gender distributions of the world,"
Data request
Data: I am looking for an API oder dataset where I can find age distribution (age groups: percentage of an age group according to the population) and gender distributions for each country of the world. Something like this:
Zensus Germany 
Context: I am working on my Master's Thesis and would like to compare my scientific samples to the population.
Region: I need Data from the whole world.
License: Unfortunately I am a Student and can't spend more that 50 Euro on this data.
Format: A JSON API would be perfect. XML, CSV, XLSX or any other common data type is ok too.
Authority: I need the data to be reliable. That means, the sources of the data have to be visible and official.
Non-answers: I have tried:

Open Data Network
World Bank
U.S. Census Bureau

","['data-request', 'api', 'demographics']","I think geoba.se might interest you, although I'm not sure how reliable their sources are.Unfortunately, geoba.se doesn't have an API, but you could try to scrape the data yourself using code like the one found on this answer.When I have more time, I'll update this answer with a bit of code."
Is it possible to perform an efast 5500 filing search?,"
Do any of the APIs allow us to do a search of the 5500 efast  filings, similar to the public web form which the DOL already provides?
",['labor'],
Data about past floods (in the UK),"
I'm looking for data about past floods in the UK. I know that the Environment Agency provides historic water level readings and also does predictions about possible floods at http://environment.data.gov.uk/flood-monitoring/archive, but is there any place where I can get access to actual occurrences of a flood?
","['data-request', 'geohazard']",
Average height of Shetland Island residents,"
I am looking for the average height of Shetland Island residents by gender.
I am sure it must be out there but for all the data sets with height by location, I have not found the Shetland Islands broken out separately. Weight would be a bonus.
It seems that the average size of almost all animals in the Shetlands are small. Not just the famous Shetland Sheepdogs and Shetland Ponies, but even sheep, pigs, ducks, etc. I am curious if it is completely uncorrelated with the size of humans in that location.
","['data-request', 'medical', 'europe', 'demographics']",
Infectious disease outbreakes in Russia by region,"
Are there sources where I can find information about infectious disease (say, plague, hepatitis, polio) outbreakes in modern Russia? Typically, a disease outbreak is followed by a warning issued by public health regulators: are those kind of data archived and tallied? I'd prefer to have the data grouped by regions. A go-to resource at FSSS lists surprizingly little about public health.
","['data-request', 'medical', 'russia']","There are many global infectious decease outbreaks databases.
For example, Gideon (15-day free trial) provides data of this kind:There are also many sources of statistical information from Russian federal authorities (or their territorial bodies):Rosstat statistics (see my comment above);Minzdrav annual reports (an example);Rospotrebnadzor annual reports (an example).Unfortunately, all these sources are rather unsuitable for your needs."
Open Land Cover Data for Australia,"
I'm interested in both low (rough) and high (fine) resolution, open (free) and classified land cover raster data for Australia. 
Ideally geodata sources; the less thematic classification is better; forest entity is the most important for my research.
","['geospatial', 'australia', 'land-cover']",The WRF Preprocessing System (WPS) has open land data and a documentation. You could also try the NCAR data. There is land cover included but the webpage is unclear about the data access. A data set only covering the years between 2001 and 2012 is the MODIS Land Cover. It is available as GeoTiff.
Acquiring Global Data on Rainfall?,"
Does there exist a global dataset on rainfall (at least 0.5x0.5 degrees grid) already in .csv or similar format? 
EDIT:
I have found this:
https://precip.gsfc.nasa.gov/
the precision is 1x1 log-lat grid. I check if it is enough for my case.
EDIT:
I see that asking about rainfall data is quite common. As soon as I write the code to properly open the binary files in the link above I will share it in order that order researcher will be able to easily use these data for whatever purpose they will to. The code will be R based.
",['data-request'],
CollegeScoreCard - Earnings from 2012 for 2014 query,"
Why is the earnings data taken from 2012 whereas other fields are all from 2014? 
https://github.com/RTICWDT/college-scorecard/blob/dev/js/src/picc.js#L492

MEDIAN_EARNINGS:      '2012.earnings.10_yrs_after_entry.median',

Also the data for 2013 and 2014 are null for all records (I verified many schools).
",['collegescorecard'],
ED Vitals and CHARTEVENTS prior to ICU admission,"
Are emergency department vital signs available in MIMIC III's CHARTEVENTS table?
I understand that medications and laboratory data is available throughout the entire hospital stay (not just in the ICU).  In testing a few patients, I can see some vital signs are available for some patients prior to ICU admission in CHARTEVENTS, but I'm not sure how reliably this is reported.  
Some patients appear to have no CHARTEVENTS listed prior to 'intime' in the ICUSTAY table even though they are listed as being admitted through the emergency department, whereas other patients do have items within CHARTEVENTS.
Example with vital signs:

select label, value
  FROM chartevents CE
  LEFT JOIN icustays ICU on ICU.icustay_id = CE.icustay_id
  LEFT join admissions A on A.hadm_id = ICU.hadm_id
  LEFT JOIN d_items ON d_items.itemid = CE.itemid
  where A.hadm_id=157346 AND CE.charttime < ICU.intime

Example with no vital signs:

select label, value
  FROM chartevents CE
  LEFT JOIN icustays ICU on ICU.icustay_id = CE.icustay_id
  LEFT join admissions A on A.hadm_id = ICU.hadm_id
  LEFT JOIN d_items ON d_items.itemid = CE.itemid
  where A.hadm_id=176032 AND CE.charttime < ICU.intime

I understand that there may be some minor variability (+/- a few hours) with ICU admission times, but if a patient stays in the ED for an extended period of time prior to being admitted to the ICU, will the patient have metrics, such as blood pressure, recorded into CHARTEVENTS?
",['mimic-iii'],"Vital signs in MIMIC-III are captured from the CareVue/MetaVision intensive care systems, so this data is not available during the period of emergency care. Emergency care data is currently being integrated into MIMIC and we hope to make it available to researchers in the future."
Where can I find highest resolution soil data from public domain in India?,"
Are there any soil data sources for the modeling of flood hazard or flood inundation for India?
","['data-request', 'india', 'soils']",
Transportation statistics for Grand Central Terminal,"
Grand Central Terminal reports serving 750K people daily. 
Is there an MTA dataset for that, or at least a way to approximate that with hourly granularity?
","['data-request', 'transportation']",
Mobile games demographic data,"
I'm looking for demographic data for mobile games.
I've looked at App Annie, SensorTower, and Apptrace. These three sources give estimates on the app store ratings, number of downloads, and rankings in each country -- but their free versions provide no information as to WHO is using these apps/games. I want to get a better idea of WHO the users are.
Data - I'm looking for information regarding players' age, sex, ethnicity, income, race, and basically anything that could assist in targeting mobile users in a more precise manner. Monetization is key. My clients, of course, are interested in targeting users who are spending money. 
Region - English speaking markets (primarily North America and Western Europe)
Any format or source is acceptable. I'm looking for any kind of data regarding mobile gaming in English markets -- and I will, of course, try to assess the credibility on my own. Essentially, I'm looking for free and open estimates/analytics -- as signing up for a subscription based service is pricy for a small business. 
","['data-request', 'usa', 'demographics', 'games']",
Data missing from CollegeScorecard but in Delta Cost Project database,"
I noticed that the data from the National Center for Education Statistics (NCES) contains important information that the CollegeScorecard dataset does not. I noticed this because I was looking at the average faculty salary in the data dictionary which states,

Average faculty salary: Average faculty salary per month, calculated from the IPEDS Human Resources component. This metric is calculated as the total salary outlays divided by the number of months worked for all full-time nonmedical instructional staff. Prior to the 2011-12 academic year, when months worked were reported in groups, the value for 9-10 months is estimated as 9.5 months and the value for 11-12 months is estimated as 11.5 months. Values prior to the 2003-04 academic year are limited to degree-granting institutions for consistency with values in subsequent academic years.

Since that description is a bit confusing, I wanted to calculate ""the total salary outlays divided by the number of months worked for all full-time nonmedical instructional staff"" myself to double check the numbers, but there is no column in the CollegeScorecard for ""the total salary outlays."" However, in the Delta Cost Project dataset there IS a column ""salarytotal"" which is described as ""Total salary outlays of full-time instructional faculty"". 
I also noticed other columns which are in the Delta Cost Project database but are missing from the CollegeScorecard, for example the total assets. They are both public datasets provided by NCES, so I'm a little confused why some data has been added and other data removed. Furthermore, the Delta Cost Project goes back to 1987, whereas the CollegeScorecard data only goes back to 1996.
Can someone help explain (a) how to properly backwards calculate yearly faculty salary (I'm assuming I just multiply by 9.5? Then what about the 11.5 months part?) (b) Who should I contact about getting this data into the CollegeScorecard dataset since I believe there is important data missing (that they already have)?
",['collegescorecard'],
Humidity data in the US,"
Does anyone know where we can find daily/monthly humidity data at zipcode/county/state level?
","['data-request', 'usa', 'geospatial', 'weather']",
Higher Education Graduations by U.S. County,"
The U.S. Census provides educational attainment statistics at county-level. This is a break-down of local population by level of educational attainment (high school, bachelor, etc.).
I am looking for historical (since 2000) annual county-level (or Metropolitan Statistical Area-level) enrollment/graduations from higher education institutions.
","['usa', 'education']",
Device events has duplicating patient records,"
It seems that in the https://open.fda.gov/device/event/ the patients have duplicated records.
  ""patient"": [
    {
      ""sequence_number_treatment"": [
        """"
      ],
      ""patient_sequence_number"": ""1"",
      ""date_received"": ""19920310"",
      ""sequence_number_outcome"": [
        ""1. R""
      ]
    },
    {
      ""sequence_number_treatment"": [
        """"
      ],
      ""patient_sequence_number"": ""1"",
      ""date_received"": ""19920310"",
      ""sequence_number_outcome"": [
        ""1. R""
      ]
    }
  ],

",['openfda'],
Classification system for healthcare facilities based on most common procedures,"
I work for a Health Insurer and need to map facilities (in this case they would be Ambulatory Surgical Centers) to a handful of yet to be defined categories (e.g. Ear Nose & Throat, Gastroenterology, etc.) based on the types of procedures most commonly done at the facility (this would be identified in their claims data).
At this point the best grouping I have is the Clinical Classification Software (CCS) grouping, but that has about 250 categories and I need a system that gives me closer to 5-10 categories.
Has anyone done or seen anything similar?
","['data-request', 'medical', 'classification']",
Is there an emotion speech detection - accurate classifier or large dataBase available publicly?,"
I am practicing machine learning and would like to explore more precise functionality with emotion recognition in speech. 
I am looking for a ranked datatset or a trained model. Current libraries are narrow, something over 250 segments with emotion scaled in separate data file from soundbytes should be a good start. 
","['data-request', 'machine-learning', 'audio']",
Level of education required for employment over time,"
I want to get a data set that can be used to look at a year and the levels of education required for employment. 
My thoughts are that although we have many more opportunities in the modern world the level of education required to access these opportunities is increasing. I would like a dataset that helps answer that question
Note I suspect the change in education required would have started to occur around the late 70s so a data set at least from 1930 would be useful
","['education', 'demographics']",
Historical Black Sea oceanographic data,"
I'm looking for a data set of historical oceanographic data for the Black Sea, specifically wave heights and sea surface temperature.  NOAA keeps a history archive at ftp://polar.ncep.noaa.gov/pub/history/waves/ and the README ftp://polar.ncep.noaa.gov/pub/history/waves/README claims that the files where GRIDID =  glo_30m - The 30 arc-minute global grid is global is global data.  However it's not truly global; it's for oceans, and it does not contain the Black Sea.
Is there a resource for historical oceanographic data for the Black Sea?
This is a screen shot of what the `glo_30m' actually covers

","['data-request', 'noaa', 'climate', 'oceanographic', 'meteorology']",European data can be obtained from ECMWF at http://apps.ecmwf.int/datasets/data/interim-full-daily/levtype=sfc/ and they have an API https://software.ecmwf.int/wiki/display/WEBAPI/Python+ERA-interim+examples
Data about default rates of H1B visa holders on their past student loans?,"
For international students in the US, I would like to know if there are any specific default statistics about international students. I’m mostly interested in looking at defaults that occur when the borrower is no longer a student and is employed (on a H1B visa for example).
","['data-request', 'usa', 'data.gov', 'finance']",
clinical report dataset,"
I am doing a research on detecting negation cases on medical reports (NLP medical). 
I need clinical report that contains sentences, patient conditions, patient history, clinical terms, etc
Is anyone can help to find?
","['data-request', 'medical', 'nlp', 'text']",
Cancer images dataset,"
Are there any datasets out there consisting of images of samples of cancerous/noncancerous tissue and their labels as such? 
","['data-request', 'medical', 'images']",
US Radiation measurements,"
Is there a service that provides gamma energy data from RadNet in machine readable format such as JSON or CSV?
The current RadNet UI is restricted to html and charts. Excel report itself is limited to 400 samples.
Likewise, EPA sources on data.gov contain no time-series data.
","['data-request', 'usa', 'data.gov', 'government', 'environment']","Since January 18, 2018, near-real-time data are available for download on this page in CSV format.I suppose this FAQ answer is applicable to CSV files too:RadNet near-real-time air data are refreshed hourly during business
  hours, Monday through Friday. This hourly refresh ensures that the
  most up-to-date data are available for the last 24 hours."
computer data set of Mozart piano sonatas,"
I think after 200 years the scores to the Mozart piano Sonatas are in the public domain.  I can look at the scores and download them from IMSLP

However, these are not suitable for consumption by a computer. I don't even know what the standard format is.  Could it be MIDI? I am concerned that Midi will miss things like slurs, dynamics and other articulations (which are often put at very precise places).  Nonetheless I found Mozart, Wolfgang Amadeus [bap. Mozart, Joannes Chrysost[omus] Wolfgangus Theophilus] on kunstderfuge.com.
It could be quite an effort (and also error-prone) to compile these myself.  MIDI files also cannot capture the timbre of the musical instrument or a musicians artistic judgement.
Yet, are there any efforts to computerize classical music in a standard way?
",['music'],
"Data License Model for ""Use, don't share""?","
Is there a data license model which allows private usage but not sharing/publishing results or further sharing of the data?
The reason:
I am an open source software developer and in case of user bug reports which are data specific, e.g. non reproducible by my own data, I need access to this data. Further I know that I have users which like for example seeing their data in a video tutorial with a clear link to the data owner, but others do not. 
To avoid potential conflicts I would like to try out that I can accept only licensed data. For the first group of users something like:
Creative Commons Non Commercial Share Alike 4.0
would be appropriate imo. Now is there a license which a user could put which allows me to fix the issue in my code, but does not allow me to ""promote"" the new capabilities of my software? A single user license, like existing in software code? Maybe a third one not allowing the freedom of doing anything but allowing educational purpose in form of a 5 min video?
I give such support outside of project time. I do not want to worry about what I am allowed to do and what not in my free time. If I only clearly accepted licensed data and offered two or three models which satisfy the needs and desires of the majority of my users, maybe my life gets easier. 
",['licensing'],
Bacterial infectious diseases dataset,"
Does anyone know of a dataset relating:

bacteria (not viruses or fungi)
infectiousness
symptoms 

...or something of the sort?
I'm looking to classify infectiousness (ie. infectious/not infectious) via bacterial genomic sequencing/metadata. I have the capability to match names to genome fragments from other sets. 
","['data-request', 'medical', 'releasing-data', 'metadata']",
Where are some examples of interesting analyses of the College Scorecard data?,"
I've been searching online for plots and analyses of the College Scorecard data, because I'm interested in analyzing the data myself. I don't want to reproduce what others have already done. 
I've played around with the tools that the College Scorecard site provides, but they aren't exactly what I'm interested in... what I'm most interested in is producing a plot that clearly illustrates which colleges are most likely ""scams"" based on the data. 
Can someone please point me to some interesting examples of some  analyses/plots of the College Scorecard data? Thanks!
","['uses-of-open-data', 'collegescorecard']",
Bacterial infectious diseases dataset,"
Does anyone know of a dataset relating:

bacteria (not viruses or fungi)
infectiousness
symptoms 

...or something of the sort?
I'm looking to classify infectiousness (ie. infectious/not infectious) via bacterial genomic sequencing/metadata. I have the capability to match names to genome fragments from other sets. 
","['data-request', 'medical', 'releasing-data', 'metadata']",
Data on US-production in each industry as defined per NAICS,"
I am looking for data on economic production (as in GDP) split by industries.
So, for example, how much value did the car-manufacturing industry produce in 2016?
And this for all industries.
Ideally, industry categories should be as detailed as 6-digit NAICS codes, but 3-digit NAICS code would also be okay as long as I can get data for all industries.
Ideally, I am looking for 2016 data set, but can do with the 2015's in the absence of that.
","['data-request', 'usa', 'economics', 'industry']",
Getting cold calls data set,"
I am looking for cold calls data set for my research.
the data should be an audio file of recorded calls. ( sales calls ..)
Any idea where can I get such data?
","['data-request', 'nlp', 'uses-of-open-data']",
Request for seismic data annotated with Earthquake/NoEarthquake labels,"
I tried searching (and failed to find) annotated times series of seismic data. More specifically, I'm interested in seismic data time series that would have labels like ""earthquake"", ""no earthquake"", etc.
",['data-request'],
"Dataset with personal information (eg. gender, age) and movie preferences","
Does anyone know of a data set that contains anonymous but personal information about people connected to their movie preferences or alternatively some other preferences (i.e. favorite music, etc)?
","['data-request', 'music', 'film']",
Average Monthly temperatures for cities around the world,"
I am looking to find the average historical temperature in april (not the average temperature in april of 1988, for example) in different cities (about 400 cities across the world) and store that data in a format that is manageable in python. I've found the data in weatherbase.com but I haven't found a way to collect the data automatically (I've found one api for weatherbase written in python but it doesn't have much documentation) Does someone know a not-that-complicated way to collect the data from  weatherbase or other website?  
","['api', 'weather', 'python']","If there is no well documented API for weatherbase.com, it might be interesting to scrape the information. Here is the list of cities the site contains with their URL. You can select some cities and paste their rows into a csv file. This Python 2 script will read the .csv and extract the average temperature in February for each city. The code is probably very poorly written, but it is functional. Feel free to improve it.EDIT : Python 3 version with better results in csv"
How to access USAID funded project data,"
If I know about a specific USAID funded project underway:
How do I get access to the data produced from the project?
Also, how can I tell if data about the said project be subjected to the open sharing policy?
","['data-request', 'usaidopen']",
Wikidata get property of property,"
This question is related to this.
We have the following query:
SELECT DISTINCT ?item ?itemLabel ?AuthorLabel ?year WHERE {  
  ?item wdt:P166 wd:Q255032.
  ?item wdt:P50 ?Author .  
  ?item wdt:P577 ?year .
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"" }    
} 

We get items and these properties, for example Author, date of publication.
But we need to get not direct property, for example date of Award.
Item has award received property and this property has point in time property.
How can we get its value?
","['wikidata', 'sparql', 'ontology']","The point in time property of the award received is what Wikidata calls a qualifier:Along with sources and ranks, qualifiers allow statements to be expanded on, annotated, or contextualized beyond what can be expressed in just a simple property-value pair.Here is the modified query to access the point in time of the award received: Wikidata also has a short description and some examples about how to work with qualifiers."
List of U.S. trucking companies with additional info,"
I'm looking for data set of trucking companies in de U.S. Specifically:

Name
Phone number
DOT#
MC#
etc...

","['usa', 'data.gov', 'transportation', 'companies']",
How much did MIMIC have to pay hospitals to get access to their data?,"
In the United States, many hospitals as well as health insurance companies charge universities to access patient data.
How much did MIMIC have to pay hospitals to get access to ""their"" data? 
",['mimic-iii'],"While hospitals charging for data access is a disappointing trend, I don't think MIMIC paid for access in the sense implied by the question. The research and development of MIMIC is the product of collaboration among MIT, Philips Healthcare, and Beth Israel Deaconess Medical Center sponsored by National Institutes of Health grants: NIH-R01-EB017205, NIH-R01-EB001659, and NIH-R01-GM104987.See: MIMIC-III, a freely accessible critical care database "
geonames.org data dump seems incomplete compared to its API?,"
Because of geonames.org's API limit, I tried to download its data dump to match with my record.
However, it seems like the allCountries.txt data dump seems incomplete with only ~ 7 million records. Indeed, Geonames.org claims to have over 11 million records.
For example, Guatemala City -- ID 0003598132 is available on the API, but not in the allCountries.txt.
Am I using the correct data dump? Or is there a more complete dump?
","['api', 'geocoding']",Are you sure that Guatemala City ID3598132 is not in your file ? I used the version of allCountries.txt found here.
Free world flags 4:3 dimensions,"
Similar to this request, I need some flag images (not icons) with uniform dimensions (preferably 4:3). All the flag libraries I've found all have non-uniform dimensions. Does anyone know of a free resource that caters for my need?
","['data-request', 'images']",I found a suitable library. Flags in both 4:3 and 1:1. I hope this helps others. https://github.com/lipis/flag-icon-css 
How to register in each state (U.S.),"
I'm looking for a place that systematically keeps track of the ways voters in each state can register, such as whether they can register online or by mail, links, voter qualifications, etc. 
","['government', 'elections']",
Is there a dataset for OCR of handwritten texts available?,"
I would like to evaluate an idea for OCR of handwritten texts (especially with mathematical contents).
Is there a dataset for OCR of handwritten texts available? It should contain images of documents, e.g. something like

It would be good (but not necessary) if the dataset contained information about the language(s) of the document and probably also the topic.
Side questions
I'm not sure how OCR algorithms are evaluated, as OCR contains multiple problems:

Segmentation: Find single entities in the source image
Classification: Classify the segmented images
Placement: Find the relationship between two classified symbols (is one to the right of the other or rather the the right-top? Hence: Is it ax or a^x?

I'm also not sure how such a dataset should be labeled. But for this question, I would also accept datasets which do not contain labels.
","['data-request', 'unstructured-data']",
Largest U.S. cities per state in 1950,"
I am looking for a data set that contains the largest city for every US American state in 1950. The data should contain the city name, the state name, the population and, if possible, longitude and latitude coordinates for each city.
The data might look similar to this list but would need to include the largest city in every state.
Alternatively, a data set with the 1000 largest cities in the US as of 1950 would probably be sufficient, too, as it might allow me to reconstruct the largest city in each state manually.
","['data-request', 'usa', 'city', 'historical', 'population']",The data you want are in these files.The primary source for this data was a US Census Bureau dataset of ~7500 incorporated cities whose populations surpassed 2500 people at some point in their existence. Additional cities were added from a variety of sources (...)
US Hospitals by Number of Beds,"
Where can one find a list of all US hospitals with the number of licensed beds?  I believe that CMS provides this data somewhere, but I cannot find it!
",['medical'],i think you are looking for the medicare cost reportshttps://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/Cost-Reports/Hospital-2010-form.html
Free radar (SAR) satellite data and Optical satellite Imagery of same scene,"
I'm looking for free sources of radar (SAR)and optical satellite imagery of same scene captured at same duration of time (week /days/ month) but of same location.
Does anyone know of sources?
","['data-request', 'images']",
Dataset for IAB taxonomy text classification?,"
I'd like to train a system that takes text and predicts IAB classes.
Are there any public datasets available for this?   
",['classification'],I think this is what you are looking forhttps://www.kaggle.com/datasets/bpmtips/websiteiabcategorizationif you want to validate your model you can use this free api to validate results of your modelhttps://front-page.com/domain.php?domain=google.comyou just need to provide attribution to https://front-page.com
Mapped culverts information,"
I was wondering where I can find maps of culverts that runs under interstates? 
I'm in Indiana. I wrote an email to INDOT (Indiana Department of Transportation) and they said they don't have such information. 
I searched Indiana Map Atlas and somehow wasn't sure if culverts were related to hydrology maps? 
Like, canal, ditches, connectors, drainage? 
They don't have a map specifically associated with ""culverts"". 
Does anyone have an idea about it?
",['usa'],
Blockgroup-level data on industries and occupations in California,"
The American Community Survey (ACS) provides some information on people's work places on the block-group level, that is spatial data a bit more detailed than at zip-code level.
Do you know any other sources for data at the block-group level or similar detailed spatial data that gives away information on the industries and occupations people work in?
","['usa', 'geospatial', 'industry']",
IPEDS variable for automatic admissions,"
Some colleges and universities offer automatic admission to students who meet minimum criterion. For example, University of Texas offers automatic admissions to Texas students that are in some top percentile of their high school classes.
Is their an IPEDS field that indicates this type of assured admission?
","['collegescorecard', 'education']",
Measures of racism in US,"
I'm doing a research project that tries to provide insight into the underlying causes behind racism. More specifically, the project examines out-group bias based on race or ethnicity in US.
I'd be interested in knowing what data there might exist that could hint at either the development of racism over time or across different parts of the county. Does anyone know of relevant datasets?
","['data-request', 'usa']",
Units of measurement conversion database,"
Tools to convert units of measurement and conversion data is abundant, but what databases/datasets exist which aim to consolidate unit conversion data?
For example:

1 pound equals 0.45359237 kilogram per ""Refinement Of Values For The Yard And The Pound"", US Nat Bureau of Standards, 1959

Ideally it should:

indicate which coefficients are prescribed by standards (rather than derived from the application of multiple other coefficients)
cite the standard for each conversion coefficient
carefully indicated precision of conversion coefficients
contain standard unit abbreviations/symbology
document units clearly to avoid confusion (ex: aliases and formal names)
be expressed/published in a portable machine-readable format (i.e. JSON)

Fantastically it would:

also contain outdated standard historical values
contain symbology for hybrid units
describe context in which particular units are used (professions, regions of the world, etc.)
cite standards for the unit symbology (ex: ""lb"")

This would make implementing a unit conversion library much easier since the step of aggregating conversion coefficients would be unnecessary.
",['data-request'],
US county-level temporal economic data,"
For a research project I'm very interested in economic data such as unemployment rate on a monthly basis for individual counties in the US. Is this available somewhere?
I know that the information I'm requesting is quite detailed. Perhaps someone has made a model that makes reliable predictions on a monthly basis? I'd be very interested in that as well!
","['data-request', 'usa', 'economics']","The U.S. Bureau of Labor Statistics publishes Local Area Unemployment Statistics (LAUS). These provide unemployment rates at various geographic levels: in states, metropolitean areas but also in counties. The summary can be found here. You might have to apply for the data, though."
"Dataset for human body temperature, heart rate and illness","
For testing my healthcare project I'm looking for a data set in which the following attributes are present:
gender temperature heart-rate   illness
  1        100         70       high temperature (fever)
  2        101         94       high temperature with high rate

","['data-request', 'medical']",
historical data for bus arrival time at bus stop,"
I'm working on a project of predicting the bus arrival time for each stops based on the historical data. I checked the database for Boston and New York, but the result is not very perfect.
For Boston, I only found the GTFS schedule data and the real-time data API.
For New York, I did find the historical database. But the trip id in the corresponding data is not in the same format to the trip id from the GTFS schedule data of New York, which makes it hard to connect the historical data to the scheduled data.
Can someone provide some suggestions or some other database which I could use?
-----update
What I plan to use are two types of data: GTFS data and historical data.
The GTFS data is downloaded from here: http://web.mta.info/developers/developer-data-terms.html#data
The historical data is downloaded from here:
http://data.mytransit.nyc/bus_time/
The first one is used to represent the scheduled arrival time of buses at different stops and the second one is the record of the location of each bus at different time points at a specific day. 
The connection between these two types of data is the trip_id, which represent a specific trip for a bus. Theoretically, they should have the same trip_id, but they don't. In other words, there are many trips in the historical data with the trip_id which I cannot find from the GTFS scheduled data. As a result, I cannot confirm the specific route and the stop list for these trips.
Thus, I wondered whether you could provide some suggestions.
","['data-request', 'usa', 'transportation', 'public-transport']","I have fully figure out what happened to my problems. 
For the GTFS data of New York, it can be found here: http://transitfeeds.com/p/mta
These data has been divided into several different parts, thus we need to download all of them.
For the historical data of New York, it can be found here:
http://data.mytransit.nyc/bus_time/When I compared the full data of the GTFS schedule data and the historical data, every trip_id can be found in both of them. Thus, I think these two parts together should represent the complete data for bus system for data analysis. "
Can anyone use this Journalism tool on UK Public Bodies?,"
Are you looking for information on public bodies: especially links to their website and FOI request on ""what do they know""?
","['releasing-data', 'uk', 'journalism']",
wikipedia user data for a recommendation engine,"
So I pulled the Wikipedia Page Traffic Statistics into an AWS instance and then downloaded a file which represents one hour from several months of usage data to look at locally, but it didn't really have what I was hoping for. 
From the notes:
Each line has 4 fields: projectcode, pagename, pageviews, bytes

Here is an example of a quick search within the one hour of data:
$ grep versailles pagecounts-20110331-230000 

commons.m Image:Chateau-de-versailles-Rotonde.jpg 1 6695
en File%3ABallet_versailles.jpg 1 34511
en File:Ballet_versailles.jpg 2 69056
en File:Bosquet_des_bains_d_appolon_du_chateau_de_versailles.jpg 1 9010
en File:Chateau-de-versailles-cour.jpg 5 85244
en File:Theatre-versailles.jpg 2 15030
en Galerie_versailles 1 20375
en Palace_of_versailles 1 56442
en Treaty_of_versailles 6 300984
en galerie_versailles 1 542
en versailles_bakery 1 546
en versailles_cafe 1 544
en versailles_country_kitchen 1 555
en versailles_cuban_restaurant 1 556
en versailles_distinctive_elegance 1 560
en versailles_drive_in_the 1 552
en versailles_fine_dining 1 551
en versailles_restaurant_diner 1 556
en versailles_sub_%26_bagels_shop 1 559
es Archivo:Salle_jeu_de_paume_versailles_int%C3%A9rieur_2.jpg 2 17772
fr Fichier:Ballet_versailles.jpg 1 10039
fr Fichier:Logo_chateau_versailles.jpg 1 8911
fr Fichier:Palace_of_versailles,_part.JPG 2 20161
it File:Prefecture_yvelines_versailles.jpg 1 9932
ru %D0%A4%D0%B0%D0%B9%D0%BB:Eglise_notre_dame_versailles_fa%C3%A7ade.jpg 1 12709

Can see that Treaty of Versailles was winning that hour but Versailles Cuban Restaurant also got some attention.
This is unfortunately only one half of what is needed for a recommendation engine - the traffic of 'products' viewed, but the dataset does not provide the other half, namely a set of 'users' and what they viewed/bought.
I have never heard of logging into wikipedia but can see it is possible. Could be logged in or cookie based data available somewhere. Does anyone know if such data is available?
","['machine-learning', 'wikipedia']",
Is there a large and varied syslog corpus available for download,"
I'm looking for large amounts of varied syslog data for testing a log analysis tool.
Wishlist:

Logs from different Unices and Linux distributions
Logs from routers, switches, storage arrays, firewalls, IDS and appliances
Logs from different countries and industries
Logs spanning several years

Google searching has only given me small sets of fairly repetitive logs.
",['data-request'],"""Loghub maintains a collection of system logs, which are freely accessible for research purposes. Some of the logs are production data released from previous studies, some others are collected from real systems in our lab environment. Wherever possible, the logs are NOT sanitized, anonymized or modified in any way.""https://github.com/logpai/loghub"
Is there any text data set with both paragraph and document-level labels available?,"
I am looking for a text data-set. I need this data-set for a set of experiments which compares effectiveness of a set of algorithms working in paragraph-level with the same algorithms working in document-level. For this reason, I want a data-set which has both paragraph-level and document-level labels. It's ok if only a subset of items in each level has labels. I found a lot of paper, which worked on a text processing on both paragraph-level and document-level data-sets but none of their data-sets is publicly available.
Edit: I want to do a set of experiments at the paragraph-level and see if the result is better than learning the same concept at the document-level. As long as labels are binary, it's not important what is labels.
Thank you very much.
","['data-request', 'text']",
What are the available datasets for fake news detection,"
I want to know about recently available datasets for fake news analysis
",['data-request'],
UK region wise families with young children,"
Where can I find the data about the number of families in the UK with young children of age between 1 and 14? I could not find it anywhere in the official www.ons.gov.uk.
","['data-request', 'uk']",
Real data for Markov Chains,"
I'm looking for real data for the application of some algorithms that involve applications of Markov chains and Power methods. What I need is a huge transition Matrix for some experimentation and testing, but I can't find this kind of matrix. Can someone help me, please?
","['data-request', 'machine-learning']",
MIMIC III medications,"
The prescriptions table, only has information, about the dose, medication name and days between which (i assume inclusive) the medication was ordered (not even sure if this corresponds to actual administration)... this is too crude for meaningful research analysis received medications dosing.
Is there any other way, that this information could be saved ?
For example doses of IV gtts. are generally retrievable from the 
inputevents_cv  and inputevents_mv.
But how about lets say prednisone doses patient received ? 
Any one figured that out ?
How to calculate sum of the dose of prednisone given orally during patients ICU stay ?
",['mimic-iii'],
What percent of U.S. companies outsource their accounting function?,"
What percent of U.S. companies outsource their accounting function?  What is the size of the outsourced bookkeeping industry?
",['data.gov'],
Company descriptions API?,"
Is there any API or Dataset that gives access to companies and their descriptions?
Like an ""about me"" of a company.
I have used FullContact but I'm looking for something that can do this without web URLs possibly.
","['data-request', 'companies']",
"The ""right to mine"" and scraping the web in EU","
Sorry for the somewhat general question, to which the answers necessary depend on the country of operation and necessarily are also subject to become obsolete at some point. But I think it to be quite relevant to the open data initiative, and perhaps on this forum there are people who are informed of this. 
Legislation in EU has aimed to form an exemption for mining the data for research purposes. As far as I understand, UK has introduced a rule like this last year. However I am not sure how and where to find up-to-date information on this.
I understand that ""the right to read = the right to mine"" states that anything that can be seen/read/heard by a human can also be analysed for research purposes. This seems to make sense in a way, as in principle you could physically read all those webpages make notes, collate, and the finish your study. On the other hand doing things automatically can allow things otherwise very difficult or impossible to be manageable, so in this sense the difference can be measured in something else than human time.
Maybe someone here has a good overview of the field now. What are the current state in the EU for research purposed web-crawling with no aimed commercial application? Is the UK law like this in operation?
If the licensing stated on a web-page contradicts this rule, what happens then? The link on UK above seems to imply that the law overrides the web-page licensing (similar to cases of Fair Use in the US I think), and this seems to be exactly the point of the initiative. 
Thanks for your help, if you are able to bring some clarity to the issue, or help me phrase the question in a way that can be well answered. Perhaps there are good up-to-date online materials that I should read.
","['licensing', 'europe', 'legal', 'web-crawling']",
Over-the-counter prices of pharmaceutical drugs in the United States,"
I'm looking for a data set containing the over-the-counter prices of pharmaceutical drugs by pharmacy in the United States.
","['data-request', 'usa', 'medical', 'finance']",
Dataset of automobile factories,"
Where can I find a list of automobile factories in the world with GPS? The more additional attributes like production size, number of employees, etc is included the better. Wikipedia contains some lists of a few vendors but information included is very poor and unstructured
","['data-request', 'industry', 'cars']",
Does a tagged data set of online news articles and associated comments exist?,"
First of all I would like to apologise for the length of this question and also for my explanation as it might not use the ideal terms.
I am looking for a possible data set that has articles from online sources or otherwise and user comments posted in reply to those articles, similar to a Disqus setup. I would then use this data set to verify that a system I am building is actually identifying the correct areas between two different sets of words. So far I have tried the simple and crude cosine similarity between a comment and a part of the text and the results are not really encouraging as people would use different words to refer to the same object: car-vehicle-automobile etc. (synonyms)
What I am really after is a similarity tagging between a comment and the article or parts of it. For example, if we take this website and all Stack Exchange sites, a user posts a question and other users reply with answers or comments etc. What I would like to have in the data set is a tagging where a particular comment/reply is ""linked"" to a particular part of the original question. The linking can be numerical etc. It would be similar to what certain API's such as Alchemy output with relevance between a word and the text being processed.
Obviously, the text can be from any source as what is really needed is the ""link"" between the main text and a short comment. I thought of manual tagging but this takes way too much time. Another option was to ask others to do it (like Mechanical Turk) but then I would not know how accurate that can be and since I would be using this set as my gold standard, I would need to know that it is relatively accurate.
I have been searching high and dry but have not seen anything close to what I would need. 
Any help or link to a possible collection would be much appreciated. Thank you. 
","['data-request', 'nlp', 'ai']",
"Data Sets of SCOPUS, Web Of Science and/or Google Scholar","
I need to access the data from both SCOPUS, Web Of Science and/or Google Scholar. The data is needed in the following form:
paper1 paper2 date1
paper3 paper4 date2
paper10 paper3 date3
.
.

where, paperA paperB date means: paperA cites paperB on 'date'.
I tried using this API to access citation data from scopus without any success. And I have no clue of getting this kind of data from Google Scholar or Web of science either. But I have seen a few papers making use of data from these portals. Can anybody help me?
",['analysis'],
"How to get ""historical"" shapefile (road, waterways, railways, etc.) of India?","
I am interested in looking at future trends in linear developmental activities in India and how they may impact the integrity of wildlife corridors. Basically, I need to do trend analysis over the past 20 years (from 1995) and predict the kind of changes that might come in the next 5 years. For this, one of the requirements is getting historical data of roads, railways, waterways etc. and see how they've changed over the years. I already have the latest shapefile of these from OpenStreetMap (OSM). Is there any opensource from where I can get this information?
","['data-request', 'india', 'openstreetmap', 'geospatial']",
Largest employers in each US Congressional district,"
I would like to find a data set showing the largest employers, by number of employees, in each US Congressional district.  Something like the top five or ten in each district would be ideal.
","['data-request', 'usa', 'business', 'politics']",
"US freight railroad networks, stations, yards and junctions","
I am looking for a dataset containing US freight railroad networks, stations,  yards and junctions for class I railroads for all US states. 
Any help is appreciated!
","['data-request', 'transportation', 'network-structure']",
looking for all massachusetts childcares dataset,"
Looking for massachusetts childcares. data format can be in any spatial format(shapefile,kml,geojson) or a csv/xlsx etc... as long as it has addresses or coordinates 
",['geospatial'],
Are there any public agencies which are currently streaming real-time video data?,"
I'm engaged in a discussion with the network security department at a public agency with the goal of making their live video data publicly available on the Internet; currently the data never leaves their private network. Most if not all of the cameras support RTSP (Real Time Streaming Protocol).
Security is obviously a paramount concern and beyond that it would be ideal to find a solution which allows for fine-grained access management and integration with common directory services (e.g. LDAP and Active Directory) for authentication and authorization.
I have some basic understanding of what goes into architecting a solution to this kind of problem, but not enough to make specific recommendations with a high degree of confidence. I was hoping to find some examples of other public agencies which have successfully carried out this sort of project so that we might be able to model our solution on something that's already been shown to work.
One particular software package that jumped out at me was DataTurbine. Are there other, similar tools out there? Are there any cities or other public agencies which are using them to stream live video data over the internet?
","['releasing-data', 'internet', 'computing', 'security', 'video']","Yes, there are (U.S.) public agencies that are currently (2017-03-07) streaming real-time video data. I'm not aware of a list of them (would LOVE it, if one such exists), but here's one:  Live Video Stream - NOAA Ship Okeanos Explorer I'm not familiar with DataTurbine, nor aware of similar tools, but that's not to say they don't exist.
Seattle has been quite proactive regarding publishing their Police Department's body cameras data; while not streaming/real-time, they have been blazing the trail for other agencies/departments in this arena. Particularly around data storage, as well as privacy issues. One (amazing) citizen that was actively submitting FOIA requests for their data was actually hired by them to set up/run this project. Contacting the City of Seattle and/or Seattle Police Department is definitely worth your time here."
Relationship Diagram software,"
I have some datasets that I would like to present in graphic form, as relationship diagram (see picture)

Do you know a software that can convert excel data in a such type of graph?
",['network-structure'],
Data on trade - annual imports and exports country to country,"
I'm looking for a dataset of import and export trade (goods and services) between all combination of nations globally, by year, i.e.:
2015
Afghanistan > Albania (import $XXX, export $YYY)
Afghanistan > Algeria (import $XXX, export $YYY)
...
Zambia > Zimbabwe (import $XXX, $YYY)
2014
...

MIT's OEC (http://atlas.media.mit.edu/en/resources/about/) has a vast dataset, but at a product level, which I'm worried might not aggregate correctly to sources that are more authoritative (and seems an unfair use of their API as I'd need to get all their data). I've had a look through OECD and World Bank but haven't managed to identify in more granularity than 'Country > World (import $XXX, export $YYY)'.
","['trade', 'worldbank', 'oecd']",
Epinions extended dataset search,"
I am looking for the extended version Epinions dataset. The Librec Project, extended opinions dataset is no available on this site (link is dead).
Do you know the current link for this repository? Or the other source of the Epinions data in the extended version?
Checked repositories
I know these repos, however they don't have the Epinions extended: 

Project RED (liris.cnrs.fr/red/)
Snap: Epinions dataset (snap.stanford.edu/data/soc-Epinions1.html)

Edit:
Doesn't work means: ""The www.trustlet.org page isn’t working""
","['data-request', 'social-media']","Dr. Jiliang Tang provides a raw data download of a scrape of the Epinions site. I am unfamiliar with the fields you are looking for, but this data link provides 283 MB of data."
IMDB dataset on Kaggle and copyright explanation,"
I was surfing on kaggle and I found this dataset
https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset
it contains data from 5000 IMDB movies. I was surprised since i thought that this would be copyright infringement, could someone explain me or give me some references about scraping/copying data from other sites and making them publicly available like this?
",['uses-of-open-data'],"It is absolutely a violation of their conditions of use, unless this person got prior permission from IMDB: http://www.imdb.com/conditions
""Robots and Screen Scraping: You may not use data mining, robots, screen scraping, or similar data gathering and extraction tools on this site, except with our express written consent as noted below.""If you'd like to use their data, they do have an ftp interface:
http://www.imdb.com/interfacesThere's also the OMBb API, https://www.omdbapi.com/, the TMDb API, https://www.themoviedb.org/documentation/api, the MovieLens dataset, https://grouplens.org/datasets/movielens/, and a few others. So if you're looking to use the data yourself, I would suggest you try those sources rather than a resource that might have legal issues."
reference to share on best practices [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 6 years ago.







                        Improve this question
                    



I'd like to find a best practices document to share with the developer of a internal DB interface.  Specifically I'd like to show that the approach that has been used for 15+ years results in output files that require a lot of editing to easily read into R, python, gis.

Thanks!
","['best-practice', 'unstructured-data']",
Open data with AB test results,"
I'm teaching an online course on A/B testing, and I'd like some real world data to use in my course.  However, I've had a really hard time finding good examples of A/B testing datasets, as it seems companies like to keep this information private.  Does anyone know of any good resources for this problem?
",['data-request'],
"Diesel exhaust data, road vs. test lab","
Is there open data on Diesel exhaust
(NOx or soot), comparing a number of the same cars

on the road
in the test lab ?

What I want to do is plot the correlation: if road NOx is around say 2 times test lab,
legislators could use test lab data and scale limits by this ratio, here 2.
(Or is this common practice and I just don't know it ?)
","['environment', 'cars']",
Retail analytics dataset for use in a paid course,"
I'm designing an online, paid course in retail analytics, and I'm looking for a dataset that I can use for that course.  If I find datasets that are 'open data' then am I allowed to use those datasets within a paid course?  Are there any good sites for finding such datasets with retail or marketing data?
",['uses-of-open-data'],
"Contents of Song Books, Real Books, Sheet Music Collections","
There are lots of sheet music in my cabinet. When looking for a certain score I'm always lost.
I want to build a list of all my sheet music in order to quickly search through this list. This list should contain searchable data including:

song title
author / composer
page number
date
rights holder
includes songtext, chords, ...
musical style (as jazz, blues, classical)
...

and of course data about the songbook as

title
instruments
...

So I'm looking for any kind of structured data from song books, real books (jazz), collections, etc. My favority music is popular music from 1920 (starting with ragtine, blues) up to now. Main instruments are piano, trumpet, trombone.
Please note: I don't need the paper sheets since I already got them in printed form.
",['music'],
US-County level - median income 1930 to 1990,"
I am looking for median income statistics per county for the time period from 1930 to 1990. I have found these median income statistics from 1960 to 1990 at the US census bureau. However, I seem to be unable to find any earlier calculations at the county level. Do they exist? If so, where?
","['usa', 'historical', 'income', 'county']",
Corpus for intention mining,"
I need a corpus with intention words, but I was not able to get one yet. please, somebody, help me.
Note: I'm new to intention mining if you know some useful corpus or links on intention mining please let me know those as well.
","['machine-learning', 'nlp']",
"There are some ""Right of Knowledge Acquisition"" in the Right to education?","
Educational rights and the Freedom of information (FOI) are in the ""Fundamental Rights"", and are adopted as law in many countries.
The FOI establish a kind of ""right-to-know"" in the governance sphere, and the Educational rights complement it in other spheres: there are a more specific ""Right of Knowledge Acquisition""? 

PS: ""knowledge acquisition"" is a jargon of artificial intelligence technology (an intelligent agent is the subject of this acquisition), and also a method of learning in the Aristotelian tradition... We can use here as ""knowledge acquisition for person"", an intersection of  both.
",['open-definition'],
Where can I download IGARSS 2012 data fusion contest data?,"
I khow that IGARSS 2012 data fusion contest contained worldview/quickbird images of San Francisco. Does anyone know if that data is available for free and where can I download it?
","['data-request', 'usa', 'geospatial']",
Drug coverage by health insurance,"
I'm looking for a data set containing the copayment of all drugs for the various health insurance operators in the United States.
","['data-request', 'usa', 'medical', 'finance']",
Easily browsable atlas of current climate normals for Europe,"
I'm looking for an end-user friendly atlas of climate normals for Europe.
CM-SAF have a climate atlas but this is for particular months.  KNMI have a climate explorer but it is specifically about climate change.  What I'm looking for is like what UK Met Office have for the UK, or what exists in the Dutch school atlas Bosatlas.  Of course, this can be constructed relatively easily from publicly available reanalysis data, but does any online interface exist that is relatively easy to use for end users?
",['climate'],
Is there a standardized mapping from Olson timezones to 3-letter codes?,"
Can time zone codes like ""EST"" be mapped cleanly to Olson time zones like ""America/New_York""? If so, is that data openly available anywhere?
",['geospatial'],
Swiss Canton Level Data Request on unemployment and social spending,"
I am interested in finding Swiss canton-level data on unemployment and public spending. Where could I find this? 
","['data-request', 'geospatial']","I do not have a reference on public spending,  but the unemployment data is available from the Swiss Federation.   You will need to speak one of French, German or Italian. Use the pull down menu to select a year and monthly data is available. Use the long version (on the left)."
Temporal Network data and Animal hierarchy time stamped network data set,"

Is there any data set which is labelled list of animal interaction where their position in the herd is known for network analysis?
What are the most popular time stamped network data sets?

","['data-request', 'network-structure']",
Is public information obtained through FOIA an example of Open Data?,"
I have collected information about a public school district in the U.S.  I have obtained some of it through FOIA.  Some of it was obtained from the district's website previously, although it is no longer available there.
I want to ask a question about where would be a good place to publish it online, and have been trying to figure out which StackExchange site would be appropriate.  I think maybe here would be good, but I'm not sure, because I'm not sure if the information I have collected is an example of Open Data.
Examples of the information I have collected:

The district's Technology Plan, submitted to and approved by the state.
The district's biannual special education report, submitted to and approved by the state.

One would have thought the district would have published these things on its website, but it hasn't.
","['education', 'open-definition', 'publishing']","Data obtained through FOIA is open data. Before it was attained, I would argue that it is not, as it was not being released.  Data previously published on a government website was and still is in the public domain and open data. There maybe tiny exceptions here regarding privacy issues, etc., so think through what you are going to republish, but again, it is almost always open data and is ok to republish.  The Wayback Machine and archive.is (and other archives) are a virtual treasure trove of this kind of data. Particularly around websites that publish data in HTML, but also very useful for finding old documents and in some great cases, entire databases, etc.  How would you publish this data on a stack exchange site? I'm confused by that part.
You can publish that data any which way you see fit; here are some options for you:  Publish it on the Open Data Stack Exchange datahub.io portal.
Publish it on data.world.  (You can bring up your thoughts about how to organize the various reports with data.world, they're very interested in what users want/need, etc.)
Publish it on Google Drive (make sure you click share with all).
Publish it GitHub."
How to work around or resolve a Census.gov IP-Blacklist?,"
I've recently been IP blacklisted from Census.gov. To dispel any possible doubt, I'm a developer using PostGIS. And a contributor to the project. When I try to access Census.gov, I'm getting
Access Denied

You don't have permission to access ""http://www2.census.gov/geo/tiger/TIGER2016/ROADS/tl_2016_72069_roads.zip"" on this server.
Reference #18.23a40517.1485370813.e70dcbc

www2.census.gov resolves to deploy.static.akamaitechnologies.com which is currently hosted at 23.195.82.227. I am also getting error when I try to reach the contact us page which is even more comical, http://www.census.gov/about/contact-us.html
Is there any method to get Census.gov to remove the IP ban? Thus far, I've tried posting a question to

The Twitter account of @usdatagov, @uscensusbureau
The email address at geo.geography@census.gov
The phone number 301-763-9099

That raises a few questions

Has anyone ever got un-blacklisted?
What is the criteria to get blacklisted?
Is there a private vendor of the census data that I can pay to get access to?

Other PostGIS developers are also reporting this problem.
",['us-census'],
Info based on page title?,"
I'm looking for a way to get info from wikipedia based on the page title.
example: If i have a page called ""Britney Spears"" i want to be able to get a simple bio extracted from wikipedia onto the page. ""age"" ""height"" that sort of stuff. 
","['wikidata', 'wikipedia']",
Where can I find dataset for University acceptance rate for college athletes?,"
I'm looking for some data sets so that I can import them into my database and do some data analytics with that data. The main dataset I'm looking for is the University acceptance rate, the GPA of the accepted student, and whether or not that student is accepted for an athletic sport.
I'd like to do some analytics to see whether or not having an athletic ability gives you an upper hand when getting into some big-name schools even though the GPA and acceptance requirements are much lower than of the accepted students who won't be playing in an athletic sport.
I have looked around and have found very little information. Most of the datasets show the total averages for some universities. I'd like to get a list of reported GPAs for each university and whether or not they will be playing a sport.
If the data set provides more information, that's even better! Any links I can take a look at will also be helpful.
","['data-request', 'education']","Possible options:
Student-Athlete Experiences Data Archive
Stanford University Common Data Sets (CDS) This article has data for PAC-10:
Comparing the Acceptance Rates of Athletes to the General Public U.S. DOE's EADA (Equity in Athletics Data Analysis) looks promising, but after a quick look, it actually has very little useful information in my opinion."
Internal company data: policy and documentation,"
Does anyone know of any examples of companies that have published their internal documentation and policies, or a handbook. Things such as:

Workflow
Communication guidelines
Corporate identity guidelines
Tools

","['business', 'companies', 'industry']",Here are some more interesting ones:The Ropes at Disney (1943)Interestingly constructed with a rope going throughout the document; women at the time had 10 sick days and men only 5.Steam (2012)A fun read on the flat organization front and approach to employee development.The Motley FoolWebsite designed for easy policy information dispersal.Big Spaceship A company with a portion dedicated into the handbook justifying having dogs in the office.
Textual and corresponding image datasets,"
For a small project for multi-modal semantics, I am looking for a dataset which contains textual and visual information about different objects i.e. cars, flowers etc. 
Requirements 
Categories - More than 20 objects
Type - jpg, png
",['data-request'],"Based on the requirements, following datasets can be use.Pinterest Multimodal Dataset ToolBox Text and Vision (TVGraz) Dataset "
Creating NER Tagging Benchmark Corpus,"
I am trying to test one name entity tagger. 
I am using NLTK's nltk.HiddenMarkovModelTagger.train(trains)
which requires data in Brown corpus's tagged_sents() format. 
I was looking for a free benchmark entity tagged corpus in the said
format of Brown corpus.
I could not find anyone. 
I found conll2000 in NLTK itself from which I am trying to extract data 
as (w,c) format as in http://pastebin.com/AttNEbSe and test. 
I am thinking of an alternative. 
I found two online NERs, like 
Stanford Online NER
Cognitive Computing Group NER 
If I paste data generate NER like http://pastebin.com/x1bVW6u7
and create data in said format, may I use either of them as benchmark data? 
Please suggest
","['machine-learning', 'nlp']",
GIS data for Keystone XL Pipeline?,"
Does anyone know a source for the GIS / spatial dataset of the proposed Keystone XL Pipeline Route?
","['geospatial', 'energy']",http://keystone.steamingmules.com/maps/keystone-xl-google-earth-downloads/https://gis.stackexchange.com/questions/31261/finding-shapefiles-of-pipeline-dataThere is a long list that you can get from google search : https://www.google.com/#q=keystone+pipelines+gis+data+download
Is there any open data-set for sentence segmentation?,"
I am working on textual analysis of reports in English language. The documents are official records. I requires the sentence level segmentation of text. One way is through regular expression. Other way is through classifier trained on tagged data-set and then predict whether a period is sentence boundary or not? But for that i will require tagged data-set. Is there any sentence boundary tagged data-set freely available?
","['nlp', 'text']",
Data on shop/restaurant discounts (preferably UK),"
Apps like Groupon, VoucherCodes show shop and restaurant offers/discounts near you. 
Are there any open data sets containing discount information over a large period of time? I am looking preferably in the UK. 
","['data-request', 'uk', 'shopping', 'restaurant']",
UK postcode sector coordinates,"
My research involves calculating the distances between centroids
of postcode sectors. In order to do this, I need to convert postcodes
into latitude/longitude coordinates in large batches. It is important that I am able to obtain centroids of postcode sectors, and not of the full postcodes.
Is it possible to obtain that information anywhere? The only data I
could find was on full postcodes.
",['postal-code'],
Meme Caption Database,"
I am trying to create an application that uses some machine learning in relation to meme captions and was looking for a database. Is there any database or API of meme captions? If not, is there any way I could create one?
","['images', 'database']",
"Company bankruptcy filings: updated daily, optionally historical","
I'm looking for data on bankruptcy filings. Not the total number, but specific companies and when they filed for bankruptcy. Historical data would be nice, but I'm most interested in up-to-date info. I know of PACER, but that's difficult to use with scrapers or Google's ImportHTML function.
",['finance'],
Looking for geographic information on Veterans with PTSD,"
Where can I find statistics on veterans with Posttraumatic stress disorder (PTSD).  Along with geographic location and nationality?
","['data.gov', 'medical']",
Is there any api that can be used to find a company's NACE code (industry code)?,"
I have ca. 30k European company names mainly from Germany, Iberia, France, Benelux and Austria  (SMEs*) and their addresses.  In 2/3 of cases I also have a national ID (SIREN for French companies, CIF for Spanish companies...)Is there a way to get the respective NACE (2008 version) codes of those companies? There are commercial outlets who do this for around 30 cents a pop but something cheaper would be appreciated.
* Small and medium sized enterprises
","['data-request', 'api', 'companies']",
Sci-Hub Download Requests Data,"
I was wondering if SCI-HUB has an open repository for the download request information. 
I found nothing on their Web Page nor searching online (I might have missed something on google)
There is a public dataset (http://datadryad.org/resource/doi:10.5061/dryad.q447c/1) from sep2015 till feb2016 but I need more data and more recent data.
",['data-request'],
I am looking for a list of the biggest european hospitals in Europe by number of beds,"
I am looking for the 10 biggest European hospitals by number of bed. I can't find this data anywhere. 
","['medical', 'europe']",
Is there any api that can be used to classify/find a company's industry?,"
I am working on a project that needs to classify a company's industry.
Is there any api/any programmatic way in any language that can be used to classify the industry a company belongs to? The companies are mainly in North America but world wide company's data would be great.
","['api', 'classification']",
Stream/River depth GIS shapefile for contiguous United State,"
I am looking for a shapefile of stream/river depth for the contiguous United States for my GIS project. NHD does not provide depth information. Could you please recommend me any suggestions?
","['data-request', 'usa', 'geospatial']",
Datasets with confidence ratings and ground truths,"
Here's an example of the sort of thing I'm looking for
Is obnubilate a word? YES/NO
How confident are you in your answer on a scale of 1 to 5?
Or alternatively:
Rate your confidence that obnubilate is a word from 1 to 10, where 0 means ""very confident it is not a word"" and 10 means ""very confident it is a word"".
The datasets don't need to relate to word/nonword studies, and could be any kind of scenario where there is a ground truth.
It would be best if there were at least 100 participants giving at least 100 responses, but this is not strictly necessary.
It would also be best if each participant was responding to the same question set in the same order.
",['data-request'],
Selecting subjects with specific waveform types,"
I would like to run a query that selects all subjects containing specific waveform types such as II.
A few months ago I run a script on the WAVEFORM_SEG_SIG table, but the table no longer exists. Is there a way that I can get such information?
",['mimic-iii'],
Rental / Loan Agreement Document Database,"
I'm looking for a rental and/or loan (monetary) agreement databases. 
",['database'],
Ski resort snow conditions / forecast API,"
I'm looking for an API for retrieving ski resort snow conditions and (hopefully) also condition forecasts.  At least for ski areas in North America, but global would be good too!
Specific data:

Base Depth
Season Total
New snow


overnight
last 24 hours
week/other?

Qualitative descriptor (ex: ""packed powder"")
Acres/runs/lifts open
Grooming report

A couple I've found:

OpenSnow API indicates ""New OpenSnow API keys are no longer available, sorry of the inconvenience.""
Weather2 Ski Resort Snow Report and Weather Forecast API

Related question: Open database for ski resorts/stations
",['api'],
Looking for a Canadian vegetation layer?,"
I'm using Landfire cover type for my work in the U.S, but I'm looking for data for all of Canada that will show aspen extent. I've looked at the USGS site using Little (1971) but that is way too general. Preferably something derived from satellite imagery like GAP or Landfire, but I'll take what I can get at this point
",['data-request'],
Where can I get updated list of mcc and mnc (official) of whole world?,"
Is there any website that provides updated list of all MCC (Mobile Country Code) and MNC(Mobile Network Code). Which department is reponsible for allocating these codes ? Is it ITU ? I searched their database but couldn't find the updated list. There are few unofficial websites that provide this data but I need the official ones if possible. Can anyone guide me ?
",['telecom'],
Remotely sensed estimate of mangrove area for all of the Galapagos Islands,"
I am looking for a remotely sensed estimate of mangrove area (derived from an RS image) for all of the Galapagos Islands.
Not:
Hamilton SE, Casey D (2016) Creation of a high spatio-temporal resolution global database of continuous mangrove forest cover for the 21st century (CGMFC-21). Global Ecology and Biogeography 25 (6):729-738. doi:10.1111/geb.12449
nor
Giri C, Ochieng E, Tieszen LL, Zhu Z, Singh A, Loveland T, Masek J, Duke N (2011) Status and Distribution of Mangrove Forests of the World Using Earth Observation Satellite Data. Global Ecology and Biogeography 20 (1):154-159. doi:10.1111/j.1466-8238.2010.00584.x
These two are global estimates that contain the Galapagos Islands. I am looking for an analysis particularly designed for the Galapagos.
","['data-request', 'geospatial']",
Future updates to college scorecard?,"
Does anyone have any concrete knowledge of whether or not there are plans to continue to update the Scorecard each year? Specifically updates that include data for additonal years, not really the updates that fix coding errors.
My guess is that the answer to this depends heavily on our new Secretary of Education and funding levels, but if someone knows more about this I would appreciate your input.
","['usa', 'collegescorecard']","You are correct that the future of the Scorecard is subject to changes initiated by the incoming administration.  However, the Department's current plans are to provide a major update (e.g. additional data) to the Scorecard annually.  Minor updates are anticipated to occur quarterly."
Bathymetric data of European lakes,"
I'm looking for open bathymetric raster data of various European lakes. While it is relatively easy to find the high-quality bathymetric sea and ocean data (7.5 arcsec data, for those interested), I have a lot of trouble finding this data for lakes (preferably 7.5 arcsec or more detailed).
In specific, I'm looking for data of these lakes:

Lac Leman (CH/FR)
Lac d'Annecy (FR)
Lac du Bourget (FR)
Lago Maggiore (IT)
Lago d'Orta (IT)
Lago Trasimeno (IT): I found contour data for this lake
Lago di Bolsena (IT)

","['geospatial', 'europe']",
Boundary coordinates of the states/cities/provinces of germany,"
I am trying to create a leaflet application. I want state shapes of Germany for a use case of the application. Is there a source where I can get all the boundary coordinates for the states. If not, is there a way to achieve the result without the coordinates.
Sample state coordinate for a the US state of Alabama looks like this.
var statesData = {
    ""type"": ""FeatureCollection"",
    ""features"": [{
        ""type"": ""Feature"",
        ""id"": ""01"",
        ""properties"": {
            ""name"": ""munich"",
            ""density"": 0
        },
        ""geometry"": {
            ""type"": ""Polygon"",
            ""coordinates"":  [
                [
                    [-87.359296, 35.00118],
                    [-85.606675, 34.984749],
                    [-85.431413, 34.124869],
                    [-85.184951, 32.859696],
                    [-85.069935, 32.580372],
                    [-84.960397, 32.421541],
                    [-85.004212, 32.322956],
                    [-84.889196, 32.262709],
                    [-85.058981, 32.13674],
                    [-85.053504, 32.01077],
                    [-85.141136, 31.840985],
                    [-85.042551, 31.539753],
                    [-85.113751, 31.27686],
                    [-85.004212, 31.003013],
                    [-85.497137, 30.997536],
                    [-87.600282, 30.997536],
                    [-87.633143, 30.86609],
                    [-87.408589, 30.674397],
                    [-87.446927, 30.510088],
                    [-87.37025, 30.427934],
                    [-87.518128, 30.280057],
                    [-87.655051, 30.247195],
                    [-87.90699, 30.411504],
                    [-87.934375, 30.657966],
                    [-88.011052, 30.685351],
                    [-88.10416, 30.499135],
                    [-88.137022, 30.318396],
                    [-88.394438, 30.367688],
                    [-88.471115, 31.895754],
                    [-88.241084, 33.796253],
                    [-88.098683, 34.891641],
                    [-88.202745, 34.995703],
                    [-87.359296, 35.00118]
                ]
            ]
        }
    }]
};

","['data-request', 'geospatial', 'germany']","The website http://www.openstreetmaps.org contains all of this information, though you might have to figure out what boundaries you want exactly (some documentation here: http://wiki.openstreetmap.org/wiki/Key:border_type)Two examples of borders:"
MIMIC-II query builder unavailable for running query on waveform table,"
I am trying to run a query on MIMIC-II database but it currently has an invalid certificate (SSL_ERROR_BAD_CERT_DOMAIN) and browsers refuse to go there:
https://mimic2app.csail.mit.edu/querybuilder/
Is there any alternative way to access it?
Specifically I am interested to run a query that selects all users containing specific waveform types such as II. 
Is there a way to do it on MIMIC-III if the MIMIC-II database is no longer supported?
",['mimic-iii'],
How can I register a new API key for api.data.gov programatically?,"
UPDATE: The government generously increased the API request limit to 1,000 per IP per hour. This question is now obsolete.

api.data.gov allows for up to 1,000 API requests per user per hour, which is plenty.  However, each user requires their own API Key.  How can I request a key for them without asking a user to register with api.data.gov?
The API I am using says:

""If you engineer your app to request a key for each user during your
  registration process – all they need is the users’ email, the app then
  acquires a key and stores it for use by the app. This then gives each
  instance of the app a rate limit of 1000/hr.""

But they do not say how to create a key for those users.
The underlying technology is API Umbrella, but their documentation is not clear to me in programatically generating a key for users either.
How can I create a new key for each of my users, which could number in the thousands?
","['data-request', 'data.gov', 'api']",We have set a rate limit of 1000 requests/hr per IP rather than key.  Our documentation now reflects this change.
Reference year for College Scorecard loan repayment rate,"
What is the year or cohort to which the loan repayment rates refer on the College Scorecard as shown today? My institution shows a repayment rate of 68% but there is no year of reference.
","['usa', 'collegescorecard']",
Angeles National Forest Trail data,"
I'm looking for data, in any geospatial format, of hiking trails in the Angeles National Forest. The Forest Service's geospatial webpage seems to be broken.
",['geospatial'],
Clark County Nevada Parcel GIS data,"
I am looking for Clark County Nevada Parcel GIS data. The data format can be in any type of geospatial format. shapefile,kml,geojson, etc...
Their county gis department has a ton of data http://www.clarkcountynv.gov/gis/services/Pages/FreeGISData.aspx
but they do not seem to have parcel data for download. I have also OSM data for the entire state of nevada, which has a ton of data including building outlines, but I cannot find parcels.
I am getting the feel that I will have to pay for this data but I do not want to do this. If anybody knows of any resources how to obtain this data that would extremely helpful.
I know Python and can somewhat tinker with javascript so if there is a way to pull the data off the web I may be able to do that. 
",['geospatial'],
Trying to link ZIP code to core-based statistical area,"
I have a dataset downloaded from the IRS reporting AGI by ZIP code (link: irs.gov). However, I'm interested in tying each ZIP code to statistical areas (whether it's [a] primary statistical area, [b] combined statistical area, [c] core-based statistical area, [d] metropolitan statistical area, or [e] micropolitan statistical area). Having all of them in one dataset would be ideal, but I'd settle for just CBSA.
I found a great ""crosswalk"" dataset on the HUDUser website (link: huduser.gov) that does exactly this--connects ZIP code to CBSA. I merged the two files in SAS on ZIP code and voila, most of my problems were solved. But I realized that there were some blaring issues with the merged dataset; for instance, Los Angeles was characterized by different CBSA codes in each file, amongst other errors. I went back to the download sites (both the AGI by ZIP code dataset from the IRS as well as the HUDUser ZIP code to CBSA dataset) and noticed that they were different dates--2014 and 2016Q3 (HUDUser datasets are updated quarterly), respectively. Of course, this could have been the issue, so I tried a date that was closer to 2014 (2013Q4, which was updated 2013-12-22). Fewer errors this time, but still many errors.
Can anyone weigh in on this? How can I ensure that there is no mis-match between CBSA coding on my IRS dataset and my HUDUser dataset? Or, is there another ""long"" dataset that contains all statistical areas by ZIP code, where each valid ZIP code is a row in the dataset?
","['data-request', 'usa', 'us-census', 'postal-code', 'csv']",
Cross-cutting U.S. Government data retention policies and rules?,"
I'm interested in learning more about USG data retention. I realize this is a complex question. I think it would be too lengthy and complex to examine this for each agency, but I would like to get a top-level (federal) overview of the rules and conventions.
As I understand it, the most applicable overarching law is the Federal Records Act. More information can be found on the Record Management FAQ. Additionally, I've found the NARA Management Guide.
I haven't gone through these yet in detail. Here are some things I'm looking to clear up:

The definition of ""keeping"" and ""preserving"" a record seems particularly important. Practically, storing a record somewhere is very different from making it discoverable and available via the internet.
Longer term, old data formats tend to rust and degrade (in the sense that they become harder to access and interpret).
Legally-speaking, can a new administration (in one way or another) defund record-keeping? Can they take information offline that was once online?

Full-disclosure: for data in the public interest, I tend to advocate for open data. I am not trying to lay out my reasoning or convince anyone of that in this particular question. For the purposes of this post, I'm most interested in the facts of the laws and regulations. Distinguishing between rule of law, guidance, and administration preference is also useful.
Related resources:

The Sunlight Foundation's Open Data FAQ

",['legal'],
Merging Pitchf/x tables Correctly,"
I need all the pitches and who threw them. I have downloaded the data into a sqlite db using the PitchRx library in R. All the pitch data is stored in a table called ""pitch"" and the pitcher name and ID number is stored in ""atbat"". The way I saw this done on this site uses the SQL code:
 SELECT * FROM atbat INNER JOIN pitch ON
    (atbat.num = pitch.num AND atbat.url = pitch.url)
    WHERE atbat.pitcher_name = 'Mariano Rivera'

But there are duplicates of pairs in the ""pitch"" table with ""num"" and ""url"", so you could be merging Mariano Rivera's name with a pitch from a different pitcher who threw the same day. I don't believe this joining the tables correctly. What is the correct way to join this data?
Note: I am using the SQL code in the sqlite3 library in python so there may be issues with the SQL code.
","['sports', 'sql']",The following SQL statement works fine to merge the tables. 
Data set of Air waybills,"
I am looking for a few hundred completed Air waybills like this one. There probably isn't a complete data set for this but does anyone know how I can find a large amount of these?
",['data-request'],
Is there a dataset of temperatures in India before 1947?,"
I am trying to get a dataset of temperatures in India before 1947 - say 100 odd years (before partition). Is there a web-site or some place where I could visualize such data or even have graphs of temperature of that period ? 
It would be preferable if such information is either in .csv or .json format (both are foss formats) making it easier to manipulate and get some patterns out of it. 
","['data-request', 'weather', 'geospatial', 'india']","It is difficult to obtain such old datasets. Depending what you are trying to do you could use the 20th century reanlysis made by NOAA-CIRES. The description of the dataset:It is a modeled dataset and you can extract several variables as surface temperature on a latitude, longitude position.Other option is the post-processed dataset released by the CRU: Read the ReadMe:Other modelled dataset is the 20th century reanalysis by the ECMWF:"
Geodata of Great Wall of China,"
Where can I get a freely usable geo dataset of the Great Wall of China? I would prefer a (Multi-)LineString, not something with an area but any format is ok. Vector data in any format, as long as I can somehow get it into GDAL/OGR or similar free software tools.
The only datasets I found are not publicly available and under very restrictive licenses.
OpenStreetMap has a relation (https://www.openstreetmap.org/relation/318110 (warning, huge)) but it is disconnected and incomplete.
","['geospatial', 'china']","Here's a website which links to a project related to the Wall and a few resources in kmz format.
I haven't had a look at the actual data though.There should also be a dataset here, according to ResearchGate."
Corpus of utterances and transcribed words for testing speech recognition algorithms,"
I am looking for a free English data set to use for testing different ASR API's. 
","['data-request', 'english']",
"Cancer imaging, clinical and genomic data request","
Are there other database regarding cancer imaging, clinical and genomic data except the cancer imaging archive and the GDC data portal?
","['data-request', 'medical']",
What is the percentage of internet users in the USA? Discrepancy between Google result and World bank data,"
The Google default results for ""internet user United States"" is 84 % of the population.

The source is the World Bank, but when I go to the World Bank website, it shows only 74% internet users in the United States in 2015.
I noticed this because I'm using a model in which I only take into account countries which have more than 80% of internet users.
","['usa', 'internet', 'worldbank']","This does not resolve the conflict, but traces its origin. One of the first links that appears from your Google query is for
Internet Live Stats that also presents the 84.2% number and what seems to be a justification by giving the total population and the number of internet users. That source cites ""Elaboration of data by International Telecommunication Union (ITU), World Bank, and United Nations Population Division."" (bolding mine) So it is odd that it disagrees with the World Bank number.There is something suspicious about the Internet Live Stats data. Using the 2013 data to match the Google chart, they give the basis for their percentage:  the number of internet users  (267,028,444) and the number of people in the US (317,135,919). First of all, Note that these figure are reported with 9-digit accuracy. This figure could only have been accurate for a single day in 2013. Acording to the 
US Census Bureau US population was:Similarly, the number of internet users changes rapidly, so 9-digit reporting is odd. 
However, note that 
267028444 / 317135919   = 0.84200000063695091.    It seems a bit unlikely that it works out so that the ratio is a one-decimal place percentage to 9 digit accuracy. The reported percentage was surely not calculated from these numbers. Rather, at least one of the numbers was calculated from the percentage.  I see that the World Bank cites ""International Telecommunication Union, World Telecommunication/ICT Development Report and database, and World Bank estimates""
so both of them are using ITU data. Curiouser and curiouser. So there is nothing left to do but look at the ITU. I could only find the proportion data at the ITU (not the population numbers used to calculate the percentage), but this page at the 
ITU offers a couple of useful spreadsheets. There is a link for a spreadsheet call
Percentage of Individuals using the Internet
It says that the US percentage of individual users of the internet was 74.45 in 2015 (71.40% in 2013). The same page also offers 
Core indicators on access to and use of ICT by households and individuals
This second spreadsheet says that the percentage was 74.6% in 2015. Those two seem to point to the lower figure. BUT there are some links at the lower right hand side of the page,  one of which is for the 
Google Data Explorer
which offers ""Explore and visualize key ICT indicators with Google Public Data Explorer.""  Presumably, this is Google analytic tools applied to ITU data. Using that tool,  you can select ""Percentage of Individuals using the Internet"" and ""United States"". The resulting chart says that the percentage was 84.2% in 2013 (the latest date on the chart). So the inconsistency seems to originate from within the ITU. Disclaimer: This is what was available on the mentioned sites on 15 Jan 2017."
I need to motorway map of the UK as data in CSV format,"
I need the motorway map of the United Kingdom as data in CSV file format.
","['data-request', 'geospatial', 'uk']",
Looking for ways to estimate average household sizes based on their incomes (US census data),"
The US census provides the population of households within a given area (say, census tract) making a certain amount of money per year (ACS T056). So if I were to be tasked to determine the population for a given census tract living inside households making between $35,000 and $40,000 a year, the best way I currently know how to estimate that would be to multiply the average household size (ACS T021) for that area by the respective number of households making $35,000 to $39,999 (T056_008).
The problem with this is that average household size probably varies with respect to that house's income. For my native state of South Carolina, in 2015 the Average Household Size value for census block groups varies between 1.2 people per household and 5 people per household with an average of 2.66. Has anyone determined a better way than just using the average household size to refine their population estimates that are based on total household numbers?
Some ideas:

maybe I should just plug a constant estimated household size like 2.58 that represents the entire United States
maybe I could find determine on some macro level the impact that income has on household sizes and apply multipliers to respective income segments (very apprehensive of this -- could backfire terribly)
maybe there are some overlooked ACS columns that could help me better estimate household sizes based on income segments (my hope)
maybe household size does not correlate with income at all, in which case I would be better off using my original method of using the local average household size column (T021) or my 2.58 people/household number.

","['us-census', 'census', 'income', 'population']",
Open Satellite Map Tiles for offline use,"
I'm building an offline gis app and need satellite tiles. Download and use of most tile providers like google are against their terms of condition. Is there any open/free source for such data?
I can use NASA Blue Marble NG and generate tiles from their images, but the scale is 500 meters and is too coarse grained for my usage.
",['geospatial'],
Non-Paid Opportunities to Teach Coding to Children? [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 6 years ago.







                        Improve this question
                    



A friend of mine is interested in non-paid opportunities to teach coding to children within an hour's drive of Baltimore. He was a professional game developer/ senior software engineer in Silicon Valley for six years and taught at both the undergraduate college and high school levels for many years.  He's currently enjoying teaching CoderDojo. 
Does anyone know of opportunities in the DC-Baltimore area? Thanks so much for any advice and contacts! 
Best,
Rebecca 
",['data.gov'],
Corpus of Iranian surnames,"
I'm looking for a dataset of names and surnames. Preferably I would like to have Persian (Iranian) names, either in Latin script or Farsi. 
It doesn't matter if it is a dataset or a web site/web page etc.
","['data-request', 'names']",
Shapefile for traditional culture areas of the Americas,"
I am searching for a shapefile showing the traditional indigenous culture areas of the Americas. 
Here's an example of pretty much exactly what I want (without the plotted tribal names)
http://kids.britannica.com/comptons/art-153006 
Does anyone have any suggestions?
","['geospatial', 'north-america', 'south-america']","This isn't really an answer, but too long for a comment. Thoughts:You could use the map itself (pixel-by-pixel analysis) to generate a shapefile.Googling several tribe names in quotes (eg, https://www.google.com/search?q=%22mojave%22+%22kaska%22+%22huastec%22+%22blackfeet%22+%22yurok%22+%22chickasaw%22&ie=utf-8&oe=utf-8) yields several interesting results, including 2 books and the wikipedia page https://en.wikipedia.org/wiki/Classification_of_indigenous_peoples_of_the_Americas which has a higher resolution map, but covers a smaller region and does not necessarily agree with your map.Doing the above as an image search may also yield potential resources.https://www.census.gov/population/www/cen2010/cph-t/t-6tables/TABLE%20%2863%29.csv is probably unhelpful, but poking around on the census.gov site might be useful.For a less automated approach, you may want to contact http://www.nmai.si.edu/ -- they have similar maps published online (eg, http://www.nmai.si.edu/education/codetalkers/html/chapter2.html), but I couldn't find any that exactly matched what you wanted (google search: https://www.google.com/search?newwindow=1&biw=992&bih=495&tbm=isch&sa=1&btnG=Search&q=site%3Awww.nmai.si.edu+map)A reverse tineye.com search of your image doesn't yield much, but might still be helpful: https://www.tineye.com/search/89cf2f0dca0781afe0dcee5c91e3368a15bf098d/ (alamy.com in particular appears as though they MAY have a vector map of what you need)."
Where can I find historical business address data for specific types of businesses?,"
I am interested in compiling a database with the address of every operating racetrack casino establishment in the USA, for each year from 1998 to present.
This might sound like a difficult task. However, there are only 49 racetrack casinos in America at present, and they only operate in 14 states. Moreover, the industry lobby produce a report which states the number of racetrack casinos in each state for each year. 
For example, from the current report, as of May 2016 the following racetrack casinos were open:
Delaware      3
Florida       8
Indiana       2
Iowa          2
Louisiana     4
Maine         1
Maryland      1
Massachusetts 1
New Mexico    5
New York      9
Ohio          7
Oklahoma      2
Pennsylvania  6
West Virginia 4

From quickly searching yellowpages.com it is pretty easy to find current racetrack casinos. For example, the four in West Virginia are:

Wheeling Island Hotel-Casino-Racetrack.
1 S Stone St, Wheeling, WV 26003.
(877) 946-4373
Mountaineer Casino, Racetrack & Resort.
1420 Mountaineer CirNew Cumberland, WV 26047.
(304) 387-8000
Mountaineer Casino Racetrack & Resort.
RR 2 Chester, WV 26034.
(800) 804-0468
Mountaineer Casino Racetrack.
1000 Washington St, Newell, WV 26050.
(304) 387-8000

I could replicate this process for the 14 states to find all 49 racetrack casinos. 
My question is:
How could I repeat this process historically? I want to do this, going back in time, for each year from 1998 to present.
","['geospatial', 'business', 'historical', 'address']",
How to find the amount of Mylan revenue generated for doxycycline hyclate drug,"
I'm writing an article on the antitrust investigation into Mylan and other companies. I need to obtain the amount of annual revenue that Mylan generated from sales of the drug doxycycline hyclate 150mg for 2013 - 2016. Tried looking on the internet, but can't seem to find anything.
I might be able to estimate it by multiplying the number of prescriptions times the unit cost times the average number of pills per prescription sold for those years, but can't seem to find the number of prescriptions sold either.
Anyone have any ideas?
","['finance', 'drugs']",
School Closing Due to Snow or Bad Weather [duplicate],"







This question already exists:
                                
                            




Snow days per county per monthly in US specifically in Colorado?

Closed 3 years ago.



I am looking for a dataset that contains the amount of snow that will cause a school to close in the US either by school district, zip code, county or any subdivision smaller than state. I am familiar with this map. However, there is no methodology provided besides a short description.
","['usa', 'weather', 'education']",
Sub-city-level data on criminal behavior – without relying on crime reports?,"
I am attempting to measure what proportion of crimes committed lead to arrests in Chicago, and whether that rate varies in different parts of the city. 
I'd like to do this with without relying on crime report data because the definition of ""criminal"" behavior varies, as does the likelihood of residents to report it.
The types of ""criminal"" behaviors I am interested in are: drug use/sales; theft, burglary and/or robbery; battery/assault; vandalism; and (illegal) firearm possession/use.
Any ideas for datasets that could provide a fuller picture than crime reports of the frequency of these behaviors on a sub-city level, or maybe on a demographic level?
","['usa', 'crime', 'chicago']",
Match Excel Spread Sheet of Addresses to State Legislator,"
I work at a non-profit called the Georgia Justice Project.
In February, we are hosting an event called Justice Day where people from across the state will gather at the capitol to lobby with their legislators.
It is very important that each attendee knows the names of their legislators.
Is there an easy way to take a spreadsheet of addresses and match them to state legislators?
Matching by five digit zip code is not accurate as districts overlap within zip codes.
","['government', 'address', 'nonprofit', 'district', 'politics']",
Rural road/field dataset,"
Is there any open dataset, containing images or stereo-pairs of images of rural landscapes/roads/fields? Examples are attached. Any help appreciated.
Any location/time of day are suitable.

","['data-request', 'images']","Finally, I found something. But still if you find anything better, it would be great if you post it here.http://www.nrec.ri.cmu.edu/projects/usdapersondetection/dataset/The NREC Person Detection Dataset is a collection of off-road videos taken in an apple orchard and orange grove. The videos are collected with a set of visible people in a variety of outfits, locations, and times. We encourage you to train a detector on our dataset and submit your curves for display on this webpage.Labels are provided in Pascal VOC format and images are provided as rectified pngs. A training set has been partitioned for algorithm training. A full validation set has been partitioned for algorithm tuning and development results. Finally, a test set is provided for final evaluation and publication. We ask that the test set be used only after completion of development, in order to preserve the integrity of the dataset.Scripts for working with the dataset can be found at: https://github.com/zpezz/nrecAgPersonEvalThe benchmark only requires the apples left labeled and oranges left labeled. The right images are provided for stereo. Additional left and right images, including 7 frames (1 second) before the labeled data begins are available in the unlabeled files. These can be used to compute motion features for detection or for visual odometry and new view synthesis benchmarking. Finally, the unassigned.zip file includes additional labeled data not included in the dataset, for instance, videos taken at night."
Source of coordinated for very small world globe,"
I need to make some small world globes on balls, 55 mm in diameter, to illustrate and give away at a talk on map making. I have written a computer program that draws the gores to fit the ball (any size ball), but I need a source of suitable coordinate data to draw coastal outlines on it. All the data sets I have so far found have far too many points, much too detailed, very nice for larger scale regional maps but not suitable for my purpose. Please is there a source of data that I can use? I expect to need somewhere between a hundred and a thousand points to plot.
A way of reducing one of the large data sets to a more acceptable scale might be possible but looks to be a very difficult operation to do effectively.
","['data-request', 'geospatial']",In the link below you can download shorelines and other information in several formats and resolutions:https://www.soest.hawaii.edu/pwessel/gshhg/The crude resolution is quite low resolution and maybe fits your needs.
Mapping PUMA Codes to TIGER/line shapefiles,"
I downloaded PUMA mapping shapefiles for California from TIGER/line and am able to use R packages maptools, mapproj, and ggplot2 to plot maps of California with each PUMA outline as a border. My goal is to match the PUMA mapping files to ACS data I have for CA to create heat maps, (such as average income per PUMA). 
However, the shapefiles have id numbers which are number 0-264 identifying each PUMA like so:
pumas.points
        long      lat order  hole piece  id group
1: -122.6464 38.59859     1 FALSE     1   0   0.1
2: -122.6447 38.60216     2 FALSE     1   0   0.1
3: -122.6447 38.60322     3 FALSE     1   0   0.1
4: -122.6418 38.60548     4 FALSE     1   0   0.1
5: -122.6391 38.60927     5 FALSE     1   0   0.1

range(as.numeric(pumas.points$id))
[1]   0 264
length(unique(pumas.points$id))
[1] 265
This data I am able to map with ggplot2. For my ACS data, instead of id numbers 0-264 I have each 5 digit PUMA code, like so.
test
 PUMA10   percent

1:  08513 0.3647587
2:  07301 0.7857143
3:  01903 0.5035714
4:  06509 0.5312500
5:  06506 0.7687927 
Each PUMA10 code corresponds to one of the PUMAs in the points file created from the .shp file. 
length(unique(test$PUMA10))  

[1] 265
However, I have so far been unable to find a file mapping the 1-3 digit id values assigned in the shapefiles with the 5-digit PUMA10 codes assigned in the ACS data download. My goal is to be able to create maps similar to proximity one. If anyone knows if such a file exists it would be most appreciated.
Thank you
","['data-request', 'data.gov', 'us-census', 'programming']",There are 4 variables you are leaving out of the shapefile that was imported to R.
Where can I get consistent global map data for topology and environmental properties?,"
I'm a developer trying to procedurally generate a Minecraft map based on the real Earth. I've recently spent a few days looking for Earth data for my generator to use, but I've found very few good results.
Here's a list of data sets I could use for generating such a map:

Elevation
Bathymetric (undersea depth)
Vegetation(coverage percentage, type of vegetation, etc.)
Soil type
Crust composition data
Water salinity

I'm extremely new to global data collection, so there's probably a host of other properties which could improve the map. However, I've not been able to find a consistent source for getting such data. I've found a few sources, but each of them has problems.
For example, this land-cover dataset has decent vegetation and soil maps, but their resolution is 1 degree² per pixel and there are a large amount of holes. Ideally, I'm looking for something at least with a resolution of 0.01² degrees (36 arcseconds). For this project, I'm looking for maps in/convertible to the Miller or equirectangular projection.
If there are absolutely no other options, I can just use a vector tracing algorithm to roughly upscale the vegetation maps and then fill in the holes, but that should be a last resort.
","['data-request', 'geospatial', 'global']",
Dead Sea historical measurements 1930s to 1970s,"
I'm looking for historical Dead Sea water levels data. There's a good sequence from 1976 until today on a monthly basis, but there are some graphs that show measurement data from the 1930s.
I'm looking for that data in spreadsheet/table form.

","['data-request', 'historical']",
Download an ancient Digital Elevation Model (DEM),"
I need an ancient DEM. My research is focus on Spain and the most important characteristic of the DEM is the year. The resolution is not such important as the year. Do you know where I can download it on free?
",['data-request'],
Data for the number of departing tourists in each country?,"
I'm looking for the number of tourists in each country that go to another country, not the number of arriving tourists, which is readily available. Preferably by year.
For example, here is a ranking of the number of arriving tourists by country:
Ranking Country Region          Number of arriving tourists
1       France  Europe          84.5 million
2       US      North America   77.5 million    
3       Spain   Europe          68.2 million
4       China   Asia            56.9 million    
5       Italy   Europe          50.7 million

But if it is the number of departing tourists, the ranking should be something like this:

China
US
Germany
UK
France

, with Japan and Russia in a relatively higher rank.
Is there any such data available? (And if at all possible, the data would be better if it is split by region, since the most departing tourists from European countries only travel for another country in Europe).
Any data format (CSV, TSV, XML, JSON, etc...) will do.
","['data-request', 'travel']",
Data Set request: Blood donation data,"
Does anyone know where I can find a dataset on blood donations in a given country or area with demographic information like household income ect.?
(Edited to be in line with the sites policy on data requests.)
Context: I'm doing research on whether paying donors for their blood donations or giving them a tax receipt is an incentive to donate more blood. I'm also trying to Identify if there is a reservation wage for blood donation
Region: Preferably either American or Canadian data but I will take anything that meets the other requirements.
License: Open available data or some other data set
Format: Whatever I can read into R. I usually use CSV file formats.
Authority: Im not picky, but please note the origin of the data 
Non-answers: https://archive.ics.uci.edu/ml/datasets/Blood+Transfusion+Service+Center (does not have info about income or consumption any goods and services)
","['data-request', 'medical']",There are data on blood donors confined to specific regions and times. You could use these data to link with additional demographic information from other sources to indirectly infer the answer to your research goal.A few examples:You could browse through Google Datasets search results for the query blood donors (or so) to potentially find some more relevant data.
Travel Trip Diaries,"
I am building an agent based traffic micro simulation and am looking for travel trip diaries of an individuals trips on a specific day. Usually, the trip will be done by origin, destination, mode of transport, and unique person. 
The ones I am finding online are missing the micro level details of the origin and destination.
","['data-request', 'transportation', 'travel']",
How to download all the ophthalmic devices data from device classification end point in openFDA,"
The API call 
https://api.fda.gov/device/classification.json?search=medical_specialty_description=%22ophthalmic%22
is returning (limiting) the number of records to 1 for ophthalmic devices data. I am trying to download all the records for ophthalmic data. I would appreciate if anyone could help me with the api call that can download all the records of ophthalmic data from device_classification end point.  
","['data.gov', 'openfda', 'api', 'medical']",
Open sourced LiDAR dataset?,"
I mean laser ranging data from a ground based, moving vehicle. As it's the data the self-driving algorithms chew on, I'd assume there must be some interest.
","['data-request', 'images']","Have you tried University of Michigan?  They have some large datasets available for download from their test runs around campus: We provide a dataset collected by an autonomous ground vehicle
  testbed, based upon a modified Ford F-250 pickup truck. The vehicle is
  outfitted with a professional (Applanix POS LV) and consumer (Xsens
  MTI-G) Inertial Measuring Unit (IMU), a Velodyne 3D-lidar scanner, two
  push-broom forward looking Riegl lidars, and a Point Grey Ladybug3
  omnidirectional camera system. Here we present the time-registered
  data from these sensors mounted on the vehicle, collected while
  driving the vehicle around the Ford Research campus and downtown
  Dearborn, Michigan during November-December 2009. The vehicle path
  trajectory in these datasets contain several large and small-scale
  loop closures, which should be useful for testing various state of the
  art computer vision and SLAM (Simultaneous Localization and Mapping)
  algorithms."
"Census India, population by religion - village (ward) level","
What I am looking for is the religious composition on a village/ward level from the census.
The official census doesn't seem to report it, but since it is available for towns and the census abstract (including literacy rates etc.) is available on a village level I still hope that it might be available somewhere.
I actually don't care from which census, even pretty old ones would be OK (even off-census estimates). The only thing on religion I could find from the 2001 census was aggregates per state.
","['census', 'india', 'religion']",
Large time-series data for learning,"
I am looking for large time-series data for learning forecasting methods. Data should preferably be at hourly or minute level. 
Domain doesn't matter much but multiple types of data (financial, IOT, economic etc.) would be helpful. 

A few previous posts have given relevant information.

See This post pointing to a resource at the UCI Data repository. 
Another post is not asking for time series, but the first answer points to a resource with many time series. 
You can get lots of weather data at ECMWF

","['data-request', 'time-series']","Consider electricity consumption data, which is an interesting for forecasting due to having various types of seasonality (day of week, month, season), temperature, weather and daylight effects, holidays, etc.Swissgrid, the Swiss Transmisssion System Operator (TSO), publishes a quarter-hourly timeseries for indidvidual regions as well as the entire country. The files are machine readable (Excel) and are divided into years, going back to 2011. The data is updated at the end of the month, for the previous month.https://www.swissgrid.ch/swissgrid/en/home/experts/topics/energy_data_ch.htmlSee column B of the sheet named ""Zeitreihen0h15""Total energy consumed by end users in the Swiss controlblock""* Timestamp** Kilowatt-hourThere are many other columns for regional and national consumption and production, as well as import/export, etc. Production is a little harder to forecast because it depends on market prices in Switzerland and neighboring countries (for example, if there is lots of solar and wind power in Germany, the hourly price can go quite low, even negative, and this would likely mean you'd see Switzerland importing from Germany and very little Swiss production.)p.s. I used similar data from ENTSO-E, which is monthly-aggregated and for all countries in the EU market (including Switzerland).my tweetFor yearly aggregated data for Switzerland, going back to 1910, check out worldenergy.chmy tweet"
Get Historic Temperature Data by GPS and Timestamp Using R,"
I have a dataset:  
ID       Time                Lat        Long   
a    2016-06-01 10:35:26    41.79925   -71.33052  
a    2016-06-01 10:35:57    41.80174   -71.33307
a    2016-06-01 10:37:30    41.79259   -71.31087 
a    2016-06-01 19:21:34    41.65239   -70.95343  
a    2016-06-01 19:22:36    41.65485   -70.97474  
a    2016-06-01 19:23:07    41.65504   -70.98545  

I want to get hourly temperature data(assume temperature remain the same during hour) for each point based on GPS and timestamp, since the data are consecutive vehicle trajectory data. The expected outcome would be:    
ID       Time                Lat        Long       TempHourly
a    2016-06-01 10:35:26    41.79925   -71.33052     70
a    2016-06-01 10:35:57    41.80174   -71.33307     70
a    2016-06-01 10:37:30    41.79259   -71.31087     70 
a    2016-06-01 19:21:34    41.65239   -70.95343     65
a    2016-06-01 19:22:36    41.65485   -70.97474     65
a    2016-06-01 19:23:07    41.65504   -70.98545     65   

Is there any free APIs that I can get accessed to fetch the temperature data?
","['api', 'weather', 'historical', 'programming', 'xml']","I recommend trying rnoaa https://cran.rstudio.com/web/packages/rnoaa/ - It's an interface to many different data sources from NOAA. Using rnoaa you can access data from Integrated Surface Data (ISD) which has hourly data, but not sub-hourlyFor each point you can do something like:ISD data is not cleaned up so e.g., temperature has to be divided by 10, so 197/10 = 19.7"
What specifications are out there for the precision required to store money?,"
SQL uses a notation of NUMERIC(precision, scale)
I've been googling on what precision and scale is required to store money and I see numerous people referencing things like the European Union (EU), and GAAP standardizing on numeric(x,6) or numeric(x,3) or something like that. I'm just wondering where this is specified. Can anyone quote the spec, provide a link, and date that this was issued?
",['standards'],"FASAB as a slighltly murky relationship with GAAP, but it's ""the body that establishes GAAP for federal reporting entities."" I believe it publishes what is referred to as GAAP in the document, ""Statement of Federal Financial Accounting Standards (SFFAS) 34, The Hierarchy of Generally Accepted Accounting Principles for Federal Entities, Including the Application of Standards Issued by the Financial Accounting Standards Board.""Their FASAB Handbook mentions rounding to three decimal places when required.The agency should determine whether the proper dollar scale (e.g., whole dollars, hundreds, thousands, etc.) for the cash flow spreadsheets was used. Some program subsidy rates, particularly those for programs disbursing over several years, may be influenced slightly with the scale of the program. Therefore, management should determine whether rounding to three decimal places has no significant effect on the cash flow spreadsheet values and the subsidy rate.The only document that I've found that cites an EU standard is this document entitled Converting to the euro. It says,National law can bring more detail to rules on rounding as long as this leads to a higher degree of accuracy. For example, some groups of services that are sold in units, such as the telephone, electricity or fuel, may require greater precision. In this case, their unit price could be expressed in three or four decimal places and rounding to the nearest cent may only take place on the total amount.So I would guess that in the case of utilities to be safe in the EU, pricing to a scale of four decimal places is appropriate and you can only be sure if you round at the end of the transaction.Use what works for your use case. There is no general rule here. Both are fine:"
Looking for an api to search for songs and artist? [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 6 years ago.







                        Improve this question
                    



I want an api that I can make an autofill feature with. So it would for the search 'b' return the most popular artists/songs starting with b and so on. I am looking to make an ios app with this.
","['api', 'music']",
looking for a joke/humorous/cartoon data set,"
For a reasearch i'm doing I need a data set as sepcified in the head line. I'm already familliar with JESTER, and I wonder if there are any other available sets of this sort, , since i dind't find any.
I would like to have more data about the user (JESTER has only a user i.d. and jokes ratings): gender, age, location, education, etc. Also, jokes that are short and has some formula behind it, for example ""you have two cows..."" and unlike JESTER's jokes that are long and varied, are prefered
",['data-request'],
Collecting data on private rooftop characteristics?,"
Is it legal to save data about private rooftop terraces in a Open Data set? I mean: location, characteristics, etc.
","['legal', 'real-estate', 'privacy']",
Can LCAs Be Populated/Submitted Through A Third Party Application?,"
I have a question regarding the Labor Condition Application process that I would really appreciate some insight into.
Specifically, I have been trying to determine whether it is possible to fill out/populate a new ETA Form 9035 outside the iCert web environment, i.e. through a third party web application. On top of that, is it possible to submit a filled out form outside the iCert web environment/through said third party application?
In short, I am looking into the more recent update of 20 CFR 655.734, and am trying to understand what the DOL's limitations are in terms of allowing third party apps to interact with the iCert portal's back end. For example - can an LCA be filled out via a third party interface but still be generated and submitted through iCert (my understanding is that some products provide this already)? Can it go farther?
Thank you!
","['api', 'labor']",
Using cURL with data.dol.gov,"
Is cURL required for downloading data using data.dol.gov? Will the data.dol.gov API allow the API key to be embedded in the URL without using cURL?
",['labor'],
Dataset on bilateral trade in services between India and other nations,"
I am looking for a dataset on bilateral trade in services between India's top 10 trading parterns and India for the past 10 years. I have looked at the OECD STAN database, but that seems to only have manufacturing data. I tried to use the UN Comtrade database, but the generated results kept telling me that either there was no data, or that the query was too complex. The WTO database does not provide data on bilateral flows, so that does not suit my purposes. 
Does anyone know where I can find year by year data on bilateral trade-in-services flows between nations.
","['data-request', 'india', 'trade']",
Looking for a data-set of server performance data,"
I am looking for a data-set of server performance stats collected from one of more servers. Does anyone know where I could find or if someone can provide a data set - the project is to test some interesting visualisations and some predictive functions.
So far I have looked on 

AWS Public data sets
Numerous GitHub posts which have URLs for Data-sets
Kaggle
UCI
Stanford Data-set collections page
R-Dir
Reddit
Crawdad

None of them have any data-sets which have anything close, so if anyone can donate a data-set or point me to a resource I have missed I would really appreciate it.
","['machine-learning', 'visualization']",
get item's properties know QID,"
Know QID I can get items's label:
SELECT DISTINCT * WHERE {
  wd:Q302 rdfs:label ?label . 
  FILTER (langMatches( lang(?label), ""EN"" ) )
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". }    
}
LIMIT 1

see this query on Wikidata Query Service.
But how can I get other properties, for example description?
I tried the following:
SELECT DISTINCT * WHERE {
  wd:Q302 rdfs:description ?description . 
  FILTER (langMatches( lang(?label), ""EN"" ) )
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". }    
}
LIMIT 1

or this:
SELECT DISTINCT * WHERE {
  wd:Q302 rdfs:label ?label . 
  wd:Q302 rdfs:description ?description .
  FILTER (langMatches( lang(?label), ""EN"" ) )
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". }    
}
LIMIT 1

or
SELECT DISTINCT ?label ?description WHERE {
  wd:Q302 rdfs:label ?label .   
  FILTER (langMatches( lang(?label), ""EN"" ) )
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". }    
}
LIMIT 1

but got nothing.
Description is only for sample, I need other properties too.
UPDATE: Probably SPARQL isn't best way to do this, I open to other ways.
UPDATE2: What exactly I need: I have Query, where I get info about item searching by it's label:
SELECT distinct ?item ?itemLabel ?itemDescription
(SAMPLE(?DR) as ?DR) (SAMPLE(?article)as ?article)
WHERE {?item wdt:P31 wd:Q5. 
?item ?label ""Einstein""@en 
OPTIONAL{?item wdt:P569 ?DR .}
?article schema:about ?item .
?article schema:inLanguage ""en"" .
?article schema:isPartOf <https://en.wikipedia.org/>.
OPTIONAL{?item wdt:P570 ?RIP .}
OPTIONAL{?item wdt:P18 ?image .}
SERVICE wikibase:label
{ bd:serviceParam wikibase:language ""en"". }}
GROUP BY ?item ?itemLabel ?itemDescription

I need to get the same info using it's QID, in this case Q937.
","['wikidata', 'sparql']","I asked similar question on SO  and got 2 answers.first answer:Using the URI instead of the variable ?item will get the information
  based on the entity Albert Einstein:second answer:If you already have the QID of the entity you are looking for and
  simply look for its properties and labels, you're better off using the
  Wikidata API wbgetentities
  moduleIn A. Einstein (Q937) case, that
  would give the following API call: 
  https://www.wikidata.org/w/api.php?action=wbgetentities&ids=Q937&format=jsonI think both answers are valuable to be presented here."
Video dataset for abnormal event detection in bank ATM?,"
I am doing a project in abnormal event detection in ATM counters. I googled but couldn't find any video dataset for ATM counters. For training purposes, I need videos from people behaving 'normally' in ATM counters and from people showing abnormal behavior.
With ATM counter I mean a (small) room with one or more ATM machines built in a wall.
Normal event: A person walks into the room, puts his card into the ATM, enters pincode, retrieves his card, take his money, maybe a receipt, then leaves.
Abnormal events: Someone hitting the ATM, attacking and robbing a customer at an ATM, fiddling with the machine in unexpected ways, taking photographs inside, etc.
",['data-request'],
Experimental data,"
I would be interested in some experimental data to play around with causality concepts. Ideally, this would be data where an accompanying paper is available as well. The data set could be relatively small, and should ideally come from a randomized experiment. It would be cool if there were some covariates. It would also be ideal if the experiment the dataset is based on would be fairly intuitive to understand for a layman in this area.
Can you think of a dataset, or sources for these types of datasets,  that at least satisfy some of these criteria?
Many thanks
",['data-request'],
Data of GDP values of cities in the world,"
I am looking for a data which lists GDP (gross domestic product) values of all the cities in the world. I already looked at the Wikipedia page List of cities by GDP but the list is too limited for me. Specifically, I would like to have the data for each city which has airport in it.
Does anybody know of such an exhaustive list of cities for GDP?
","['data-request', 'city', 'gdp']",
Is there any place that hosts open flight status information with an API?,"
I am looking to create a flight status app, however I don't know where to start sourcing my data from. Is there any simple open API I can use to get flight status for a flight given a date and flight number?
",['transportation'],
Data on the number of cats and dogs kept as pets in Asia and Africa,"
I am looking for data regarding dogs and cats kept as pets in Africa and Asia.
","['data-request', 'demographics', 'africa', 'asia']",
Where can I find earthquake resistant school design?,"
I am looking for earthquake resistant designs for school construction in Africa. Ideally, including blueprints.
","['africa', 'usaidopen']",
Is there any source available to read more about O-clustering ? (Orthogonal Partitioning Clustering) [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 6 years ago.







                        Improve this question
                    



I am interested in reading more about O-Cluster and unfortunately all the links I found only contain very small description of the algorithm and do not give details about how to implement it.
The most detailed link I found is this https://docs.oracle.com/cd/B28359_01/datamine.111/b28129/algo_oc.htm#DMCON059
I need to write a detailed description of the algorithm until tomorrow and I am really stuck
","['api', 'classification']",
2016 Fort McMurray Wildfire Aerial Street Level Images with Exif GIS,"
In 2016 there was wildfire in Alberta, Canada that damaged property in Fort McMurray.  There are many images of damage to neighbourhoods on the internet like the one below. However, I have not been successful in finding images with Exif GIS metadata. 
I am looking for as many of the fields as possible as I want to as accurately as possible overlay lat/longs on the image for further processing. These depend on the camera's position, altitude, zoom, angle and other parameters. 
I have a strong preference for a free resource as this is a hobbyist project at the moment.

","['geospatial', 'images', 'fire']",
Database of arpabets sounds,"
I am currently working on speech synthesis with Labview as my platform.
I need a database of mp3 files or waveforms corresponding to arpabets in English along with stress.
Where can I get and download such files?
I have seen many phoneme charts with their pronunciation and arpabet to phoneme chart; I can map arpabet to their pronunciation from this but it's quite a cumbersome task.
Any other alternative will be helpful.
",['data-request'],
Graph representation of NUTS-3 regions to determine adjacency,"
I need a graph representation of NUTS-3 regions in the European Union, which can answer the question whether a certain region is neighbor of another region. 
Dataset available?
I have looked at the data available from geovocab and from EuroGeographics but I cannot find discrete adjacency information there. Is there a dataset or available transformation routine out there with this information?
Proposal for an algorithm
Otherwise I would apply the following algorithm to get this graph:

Get NUTS-3 data with named city
Find lat/lon of city and create the nodes of the graph
Determine pairwise distances between all nodes
Determine pairwise angle between all nodes
Given the polar coordinates from step 3/4, find the nearest neighbors in every direction
Create edges between these nodes

Do you have comments or improvements on this algorithm?
","['data-request', 'geospatial', 'metadata', 'europe', 'network-structure']","Based on the NUTS-3 Boundaries in Eurostat and some GeoTools code I generated this list for you. Where the first column is the NUTS_ID of the zone and the list in [] is the list of neighbours, which may be empty. "
MIMIC III - C-Reactive protein,"
I'm trying to find CRP values in the MIMIC-III database.
I've tried different search strategies but I've only found two items (227444, 220612) in the d_items table, which are both empty variables.
Are there any CRP data available in the database? If yes, what am I doing wrong?
",['mimic-iii'],"Lab results are shared between the tables labevents and chartevents: see here.The itemids found in the table d_items refer mainly to the table chartevents. I have found 743 results in chartevents using the itemid 227444. 220612 does not seem to be used anywhere.In the table d_labitems you will find that the itemid 50889 also corresponds to CRP, but is connected to the table labevents. There are 6604 records of CRP in labevents using this itemid.Hope this helps."
Publicly available transaction data,"
I need publicly available transaction data to use for my statistical analysis project.
Preferably, it should relate to either:

Flight data (arrival, departure, number of seats, locations, etc.)
Sales data
Medical data

","['data-request', 'data.gov', 'big-data']",
Seasonal Sales Data for time Series Analysis,"
I am looking for a typical sales data set, which I can use for a time series prediction. I especially want to show how to decompose the seasonal component.
A good example would be a fictional company, or a restaurant that sells much higher volumes in the summer/ or winter.
","['data-request', 'programming', 'time-series', 'seasonality']",
GRE results by graduating institution,"
To be clear, what I have in mind is the average GRE scores of students who have graduated from, or are attending a college and have taken the GRE (for whatever reason); data like:

U.C. Berkeley  700 
MIT          691

I contacted the GRE about a year ago and they do not seem to have this data (at least, not for public consumption)
Asking here based on the slim chance that this is available through some other source.
",['education'],
Database of English words difficulty,"
Data request
I am looking for a database that describes the ""difficulty"" of each English word.
Difficulty of a word is not easy to define, but it is probably a mix of:

Level of study needed to understand the signified meaning
Time it takes for a certain person to read the word
Probability that a certain person will fail to understand, or misunderstand the word
Rarity of the signifier in literature
Length of the signifier
Rare characters in the signifier
Rare combinations of characters in the signifier

Context
I have a huge database of English words (sample) and want to split them into flashcard decks of different difficulty levels. (actually for a GSoC project)
That's why I need to know the ""difficulty"" of each English word.
Note: There are some algorithms to calculate complexity (Flesch Kincaid Reading Ease, Flesch Kincaid Grade Level, Gunning Fog Score, Coleman Liau Index, SMOG Index, Automated Reability Index, Dale-Chall Readability Score, Spache Readability Score, etc) but they are very primitive, and while they can be useful to evaluate the complexity of a whole book, they are totally ineffective for a single word.
Region
Any variant of English, or any combination, is OK
License
Must be reusable and embeddable into my server-side non-redistributed software.
Format
Any format is fine. The most obvious would be a CSV with an integer (or decimal) for each word, like this:
WORD; DIFFICULTY
rhinoceros; 3
cees; 11
leptophyllarum; 14

In any case, I would prefer to avoid web-scraping.
Authority
Preferably data from an academic body, but crowdsourced data is acceptable too.
Requirements

Must contain at least the 3000 most-used words of the English language
The complexity scale must have at least 3 different levels, for instance Easy, Medium, Difficult. The more levels the better.

Non-answer
The database at http://elexicon.wustl.edu would be a great answer if it were open data. This project measures how long it takes for a human to do a ""lexical decision"" for a particular word.
So far they have measured 1,123,350 reaction times, by 443 humans, with 40,481 words and 40,481 nonwords.
It is not yet clear to me what ""lexical decision"" actually is, but I am pretty sure it correlates or at least is an important factor in complexity.
Unfortunately not open:

Unauthorized Use Strictly Prohibited: Word lists generated from this website are available for non-commercial research purposes only and may not be used in the development of speech technology.

","['data-request', 'language', 'english', 'metadata']","The New General Service List (updated just a few weeks ago) is a list of ""the most important words for second language learners of English"".It ranks the top three thousand headwords (plus more words within each headword, such as plurals and tenses).  So it won't cover all the words in your list, and it's really indicating ""usefullness"" rather than difficulty.  But I think useful words are more likely to be used, so more familiar, so ""easier"".  It's certainly something you could use as a major factor, along with other factors, to determine difficulty.The data is in a spreadsheet, and the license is CC-BY. For (more difficult) words beyond that list, you could use word frequency as a major component of a difficulty rank.  One source is subtitles word frequency lists (CC-BY).  That lists a few hundred thousand words by how often they appear in English-language TV and film subtitles.  Again not the same as difficulty (and it's spoken English, rather than written), but it's an indication of how likely it is that somebody has heard the word before."
New Jersey Dairies,"
Looking for a shapefile/FileGDB (any type of spatial data) of all the New Jersey dairies. I have found a Washington state layer here http://geography.wa.gov/data-products-services/data/data-catalog but I cannot find the same or similar layer type for NJ
","['geospatial', 'agriculture']",
Are there anonymized medical records publicly available for research?,"
I realize this is kind of a long shot, but I figured I would ask - I'm try to do large scale analysis of medical data for research purposes, but it's exceedingly difficult to get access to medical records in any large quantity.  Is there data available for something like this?
I'm trying to get as complete a set of electronic medical records as possible.  Specifically, I'm looking for information on diagnoses for a variety of conditions.
Data format or source doesn't really matter to me.
",['medical'],
Where can I find a list of latin words?,"
I'm currently searching for a big list of machine readable latin words. I need it in a (.txt) file and preferably no definitions with the words, and each word be on a different line. For example:
studiose
studium
stultus
suadeo
suasoria
...and so on...

Does anyone know where I could find something like this or does someone have it? If you know of one with definitions, the would have to be commonly separated like with a colon:
latin_word:definition

","['data-request', 'language', 'dictionary']",
Dbscan time duration gauge,"
I'm running a Dbscan. On a matrix that's 10333 by 10333, using an epsilon value of 50. Is there any way to gauge how long this will take? It's been running for the past 8 hours now. Also does it depend on the magnitude of the elements value? 
",['programming'],
marines with breast cancer stationed at camp lejeune from 1952-1987,"
I am a marine that was stationed at camp lejeune from 1986-1988. I recently was diagnosed with breast cancer. I just want to know the total is now for marines that were there doing the contamination that has breast cancer.
",['data.gov'],
Fleet (Transportration) Dataset,"
Is anyone aware of any dataset that is about fleet and fleet management? I mean data about a set of vehicles that transport goods or perform some tasks among different centers within a central management.
I am open to different varieties such as Walmart sending goods to its branches, a postal company, some car manufacturer remotely controlling the cars or even transportation of livestock.
We plan to investigate how technology can improve such businesses from both technological as well as business point of view.
","['data-request', 'geospatial', 'transportation', 'traffic', 'real-time']",The exact data you are looking for is kept private as it is a competitive advantage. You have two options on getting the resolution of data you would like:Open Data Sources:Proprietary Sources:
US county-to-county and/or state-to-state migration flows - historic data for the 20th century,"
I am looking for US county-to-county migration out flow data. That is, for every county in the United States (say, 1001 Autanga), the data would contain the absolute or relative number of people who migrated to other counties (say, 1002, 1003, ...) in that period.
I was able to find such data for the period from 1995 to 2000 (see here) as well as for the periods between 2000 and 2014 (see here) through the U.S. Census Bureau. Now I am looking for similar data for earlier periods throughout the 20th century. Say, for example for the periods 1920-25, 1950-55, 1970-75.
Any suggestions are much appreciated.
In absence of county data, I would also appreciate state-to-state migration for the same period.
","['data-request', 'usa', 'population', 'county', 'migration']",
US county-level data on population and urbanization rates 1950-2010,"
I am looking for county-level data from the U.S. containing the counties' name and FIPS code (or any other identifier) as well as information total population and urban population rates. How urban population rates are calculated, i.e. what is classified as urban and non-urban is not extremely important. More, important is that definitions are consistent.
I am looking for data for the years 1950, 1960, 1970, 1980, 1990, 2000 and 2010.
(This looks like a trivial question, and probably it is. However, I was not able to find any appropriate data when I was searching NHGIS, ICPSR etc. Maybe I overlooked something?)
Any suggestions?
","['usa', 'us-census', 'county', 'population']","(After a while I have found some useful sources. I will answer my own question, so that future visitors to this site with the same question, have a starting point.)Data 1940-1990 (from ICPSR):Urbanization rate data for the earlier period can be obtained from the ICPSR 02896 data (see here). In particular, the datasets DS70 throughout DS78 and, in addition, DS83 cover the time frame above. Note that data (in most instances) either contains information on total population and total urban population, or on total population and urbanization rates, so that you are able to construct the third (and missing) variable yourself.Data 1970-2010 (from NHGIS):Urbanization rate data for the latter period can be obtained as time series data from the NHGIS (see here). To find the data go to select data, choose the years 1970 to 2010 and the topic ""Urban, Rural, Farm status"". Under the header Time Series Tables, you can then select the data set ""Persons by Urban/Rural Status"" which contains information on the absolute number of people living in urban and in rural areas for all US counties. Note, however, that the data seems to contain some errors (especially missing values coded as 0)."
Shapefile of Malaysia Postal codes?,"
I am currently doing a project regarding a Choropleth map and I need data sets containing postal codes of Malaysia in a shapefile for map making purposes.
I have already gone through these sources without success:

http://www.geopostcodes.com/Malaysia (Spatial Points Data frame, not Polygons)
http://www.mapcruzin.com/free-malaysia-country-city-place-gis-shapefiles.htm (does not have shp files that contain postal codes)
http://www.zipboundary.com/international.html
http://gadm.org/country (Good resources but still do not have shp files that contain postal codes)

Does anyone know of a data repository that might have a shapefile of Malaysia's postal codes?
","['data-request', 'geospatial', 'postal-code']",
How do US agencies connect their APIs to Data.gov's registration system?,"
Data.gov contains over 190,000 data sets, but only a select few are integrated into Data.gov's API key registration system. What is the process to integrate an existing API with data.gov as an API gateway and what are the benefits?
","['usa', 'data.gov', 'api']",
get label (Name) instead QID field,"
Using the following query:
SELECT ?item ?itemLabel ?itemDescription ?director WHERE {
  ?item wdt:P31 wd:Q11424 .
  ?item wdt:P161 wd:Q2263 .
  OPTIONAL{?item wdt:P57 ?director .} 
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". }
}

I can get movies with Tom Hanks and QID of director.
But how can I get director's name (label of this QID) in this table.
Query can be seen on Wikidata Query Service page.
","['wikidata', 'sparql']",Just add ?directorLabel to the select. The label service seems to work on any declared variable if you suffix it with 'Label'
Data source for names demography analysis?,"
I'm looking for datasets allowing one to map names (given names, family names) to geographical locations. So far, the best source I've found is Wiki/DBpedia with ~ 1 million records, and Web Of Science Author names and geolocation of their affiliation.
Is there any other source I could use or someone can think of?
","['data-request', 'demographics', 'names']",
Shapefile of European Union regions and districts,"
I'm looking for a shapefile containing all EU countries / regions / districts / city boundaries.
","['data-request', 'geospatial', 'europe']",
Database of Press Releases,"
Is there a corpus of business/corporate press releases? I'm looking for a collection of releases like these, but from any corporation whatsoever: http://www.businesswire.com/news/home/20161209005816/en/IMPORTANT-INVESTOR-ALERT-Goldberg-Law-PC-Announces.
Specifically, I only care about English texts.
","['business', 'corpora', 'journalism', 'news']",
London bus stops registry,"
I'm trying to find public dataset where it's possible to find NaPTAN code from bus stop number displayed on the plate on each stop. 
For example for ""CROFTON PARK STATION"" number on plate is 58556 and maching NaPTAN code is 490018484N  (source: https://tfl.gov.uk/bus/stop/490018484N/crofton-park-station)
From public enquiry I found out that NaPTAN codes relate to BODS codes. Unfortunately, I was only able to find an outdated lookup spreadsheet that doesn't have the newer NaPTAN codes. data.gov.uk's NaPTAN database covers public transportation but lacks local bus stop numbers.
Is there way to translate BODS code to NaPTAN or might be someone knows where it's possible to download that database?
","['data-request', 'transportation', 'uk', 'public-transport']","I finally found it at http://naptan.app.dft.gov.uk/datarequest/help under GTFS section, direct link: http://naptan.app.dft.gov.uk/datarequest/GTFS.ashx "
Retrieve periodic table information from wikidata,"
I'm trying to retrieve some basic informations from chemical elements stored in wikidata to create an interactive periodic table.
It's my first attempt to use wikidata, so I've understood how to get properties stored directly inside a chemical element(here is the hydrogen wikidata page) like atomic number or symbol, here's the code modified from the example:

Chemical elements and their isotopes by number of neutrons (min/max)

SELECT ?element (SAMPLE(?symbol) AS ?symbol) (SAMPLE(?protons) AS ?protons) (SAMPLE(?mass) AS ?mass) (SAMPLE(?group) AS ?group) (SAMPLE(?period) AS ?period)
WHERE
{
  ?element wdt:P31 wd:Q11344;
           wdt:P1086 ?protons;
           wdt:P246 ?symbol.
}
GROUP BY ?element
ORDER BY ?protons

But I also need to get the position inside the periodic table know as group and period.
The chemical element page states that for example the hydrogen element is an instance of group 1 element (Q19557), and period 1 element (Q191936) but I can't figure out how to get these numbers, directly in the json response.
Edit 1
I tried to add a series ordinal property to groups in order to retrieve these numbers. For example see Group 15. However, I can't figure out how to get these numbers. Sorry for my ignorance!
","['wikidata', 'sparql']","Using the series ordinal added to the chemical groups, I can extract the group and period numbers with this query.However the chemical data in wikidata seems still messy and need to be better organized."
"Can I use SpotifyCharts for getting music album, artists and song names for US using Spotify API for commercial use?","
I want to create a music application for which I need to support user searching for top music albums, artists or songs in USA using voice. In order to create language model I need to cache these charts entries...not actually the song content.
I am building it for a client so it's a commercial application. Can I get those charts using spotify API for free? They seem to allow you to download them for free here 
https://spotifycharts.com/regional/us/weekly/latest
So I wonder may be it's also allowed to scrape it or get the charts using API.
",['music'],
Setting up an offline Tile Server for Terrain Data,"
I'm setting up an offline OpenStreetMap Server and need to provide terrain data as well. What exists to do this?
","['geospatial', 'openstreetmap']",
Highlight regions of the US map [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 6 years ago.







                        Improve this question
                    



I'm looking for a tool to Highlight regions of the US map.
Cities, states or metropolitan areas. If it is an online tool much better.
Edit:
Found it:
https://drive.google.com/templates?type=drawings&sort=user&view=public&ddrp=1#
",['geospatial'],
Permits of US metropolitan areas,"
I'm looking for permits of US metropolitan areas, like Chicago, so far I found this one:
Permits issued by the Department of Buildings in the City of Chicago from 2006 to the present
But this one only includes construction permits, I'm also looking for other types of permits like electrical and plumbing 
","['data-request', 'usa']",
Forest inventory and lidar,"
I am looking for a dataset combining both lidar point cloud and individual tree inventory (positions, crown diameter,...) on a forested area.
",['data-request'],
Open data on cyber bullying?,"
Do you have any sources of open data on cyber bullying?
Are there any U.S. government (federal, state or local) departments that provide this data?
",['data-request'],
Can anyone else unzip the DBLP data?,"
I believe this is the official source for DBLP (dblp computer science bibliography of the University of Trier, Germany).
I am having trouble unzipping the latest xml dump (2016-12-07).
Since this file changes, here is a static file that I'm having trouble with as well: 2016-12-01 release.
In fact, the md5 doesn't even match up.
The md5sum specified in dblp-2016-12-01.xml.gz.md5 is 57e3406f01fa64a260affaef129d4afd
On my mac, when I type ""md5 dblp-2016-12-01.xml.gz"" I get a md5sum of 56903ba02acfcf46d0469565f14629b5
When I try to unzip it, I get an error
$ unzip dblp-2016-12-01.xml.gz
Archive:  dblp-2016-12-01.xml.gz
  End-of-central-directory signature not found.  Either this file is not
  a zipfile, or it constitutes one disk of a multi-part archive.  In the
  latter case the central directory and zipfile comment will be found on
  the last disk(s) of this archive.
unzip:  cannot find zipfile directory in one of dblp-2016-12-01.xml.gz or
        dblp-2016-12-01.xml.gz.zip, and cannot find dblp-2016-12-01.xml.gz.ZIP, period.

or gunzip it
$ gunzip dblp-2016-12-01.xml.gz 
gunzip: dblp-2016-12-01.xml.gz: unexpected end of file
gunzip: dblp-2016-12-01.xml.gz: uncompress failed

Problem Solved
The issue seems to be my download mechanism.
I had my coworker download and unzip the file and it worked on his machine. So I had him send me his zip file and I was able to unzip it. The md5sum also checks out on his download of the zip file.
So it turns out it has something to do with the way I'm downloading it.
I downloaded using Chrome 54.0.2840.98 (64-bit) I also tried downloading using curl 7.49.1
But methods resulted in a file that I could not unzip.
Anyways, problem solved for now. I'll just have my coworker download all my files from now on ;)
",['data-request'],
English queries to GIS systems,"
I'm building a system that tries to answer geospatial English questions such as ""Where is the closest restaurant"" or ""How many historic sites are in the east of Nantes?"". Underlying database is OSM. To improve my system I need more English questions. Does anyone know of any place/logs etc. where I might find such a collection of questions?
","['data-request', 'geospatial', 'nlp', 'english']",
Documentation for spatial USAID DDL data,"
I am engaged in a project, Climate Resilient Ecosystem and Livelihood, where we generated and/or compiled various spatial data (satellite images, ArcGIS featureclasses, spreadhseets, static maps, etc.) related to protected areas of Bangladesh. As a USAID requirement, we need to submit these data to a DDL system.
I have submitted this form and created an account with USAID. I see the DDL space allows users to upload files. I've been looking for guidance on spatial data standards and found out that they must be in a non-proprietary format. I've also been able to find some data that are public; this data contains CSVs and accompanying PDFs as documentation. 
I would like to know specific guidance for spatial data and metadata standards for USAID. An example folder would be helpful, like those found alongside the CSV data in the Sample DDL folder.
I am stumbling on where from to start. I found another DDL folder that I think is spatial data related work where from I might get the direction but it is restricted see here.
Has anyone worked with the USAID DDL system for spatial data before?
","['geospatial', 'usaidopen', 'documentation']",
GML with geographic information,"
I'm creating a 2D realistic RTS (Real time strategy game) and I wanted to be able to use real locations as the scenarios for the games.
The game will be developed via unreal engine which uses c++. The idea is for the engine to read an file and convert into a grid where each square has type of terrain associated, like in this image of a scenario editor.  

It would be preferable if the information was free.
The problem I'm facing is obtaining the information about the different features that influence units or line-of-sight. More specifically I would like to know the information about bodies of water present, roads, elevation (for this i'm thinking of using the google API), forests, etc in a map
I'm just asking for a pointer to an information source. Where can I download or obtain a GML or similar with this geographic information?
","['data-request', 'geospatial']","Open Street Map: https://www.openstreetmap.org should have everything you need, it's pretty much an open source version of google maps. It allows you to easily export any part of the world map to an .osm xml file.For converting from their OSM files to GML, have a look at this wiki page: https://wiki.openstreetmap.org/wiki/GML"
Classifiable data where the features change over time,"
I am looking for large datasets to investigate classification on time-dependent data where the data's features change over time.
An example of this might be a large spam dataset that covers a clear change in trends over time of constructing spam that can by-pass spam classifiers.
In other words are their any publicly available datasets available where it is clear that a classifier might have to be re-trained after a period of time to cope with feature changes?
","['data-request', 'classification']",
Hong Kong geocoding data,"
I would like to obtain Hong Kong data for geocoding, where can I get it in addition to OSM and Geonames?
I use postgresql and postgis as my database, and the TIGER dataset in postgis, which is a product of the US Census Bureau. This was created to support the US Constitution's requirement for a decennial census to support redistricting in the US House of Representatives. Their mandate only covers US states, commonwealths, territories, and possessions. And Hong Kong is not one of these.
I have downloaded Geonames data from http://download.geonames.org/export/dump/, but these data are very incomplete.
Then I downloaded OSM data from http://download.geofabrik.de/asia.html. But its SHP file looks like it has no information about coordinates and zip code, and I don't know how to open or process the other two format files. 
","['data-request', 'geocoding']","I have been using Mapzen to download Hong Kong map data. The source is from OSM but it includes some name tags. Hope they are helpful. Not exactly what you are looking for, but I have toyed the data here.  "
Any sources for UV light exposure on land for various geographies?,"
We are looking for daily amounts of UV light falling onto the earth. We have been able to find weather reports through Google BigQuery from the U.S. NOAA's NCDC but they don't appear to track sunshine hours.
Does anyone know of a source for solar environmental data?
","['data-request', 'geospatial', 'weather', 'climate']","Running list of UV/UVI/Air Quality/AQI data sources:
Ultraviolet Index issued by NWS
World Ozone and Ultraviolet Radiation Data Centre (WOUDC)
Solar Ultraviolet Spectral Irradiance
Solar Data Services
Solar UV Index
Stratosphere: UV Index
Global Fields of UV Index Forecasts
NECP FTP
USDA/Colorado State Univ UV-B Monitoring and Research Program
NOAA SURFRAD - SURFRAD (Surface Radiation) Network
SURFRAD FTP
NOAA FTP Radiation Directory
World Ozone and Ultraviolet Radiation Data Centre (WOUDC)
UV Alert Forecast Map
Ultraviolet Index Information - NWS
Daily UV Forecast - Map of Danger Areas
Daily UV Forecast - Text List of UV Levels by City
Daily UV Forecast - Monthly Means and Maximums
Daily UV Forecast - Annual Time Series of UV Index Forecasts
Daily UV Forecast - Past UV Bulletins
Daily UV Forecast - NWS Local Forecasts
Current UV Index Forecast
Archive of UV Index Bulletins
Monthly Means and Maximums
Annual Time Series of UV Index Forecasts
UV Radiation and UV Index Information
Sun Safety
SunWise at NEEF
SunWise History at EPA
UV Index Scale - EPA
Ultraviolet Radiation and the INTERSUN Programme
UV Index Reporting Sites
Global Solar UV Index
Typical Values for UV Irradiation - SoDa
Search Results for ""UV Index"" - NASA Earthdaa Search
UV Index Forecast and Archives
World: UVAwareness.com, Ireland
Europe: Integration and exploitation of networked Solar radiation Databases for environment monitoring
Europe: The Met Office (UK)
Mediterranean Basin: Environmental Forecast and Information Service (French/English/Spanish/Italian)
Australia: Bureau of Meteorology
Argentina: Servicio Meteorologic Nacional (Spanish)
Canada: Meteorological Service of Canada (English/French)
Finnish national public information service (in Finnish language)
Finnish national public information (in Swedish) service
France: Securité Solaire (French)
Germany: Bundesamt für Strahlenschutz (German)
Germany:  Deutscher Wetterdienst (German)
Greece: Laboratory of Atmospheric Physics (Greek)
Hong Kong: Hong Kong Observatory
Italy: Stazione Metereologica del La.M.M.A. (Italian/English)
Luxembourg: Meteorological Station of the Lycée Classique de Diekirch (English)
Netherlands: Royal Netherlands Meteorological Institute (UV Index)
New Zealand: Lauder National Institute of Water and Atmospheric Research (NIWA)
Poland: Instytut Meteorologii i Gospodarki Wodnej (Polish/English)
Spain: National Meteorological Institute (Spanish)
Switzerland: Bundesamt für Gesundheit (German/French)
United States: The Weather Channel
United States: NOAA/ EPA Ultraviolet Index
Sun Safety - Cancer Control PLANET
Erythemal Exposure (Erythemal UV Exposure, Erythemal UV Daily Dose,  UV Daily Dose)
Ozone Data Centers
World Ozone and Ultraviolet Radiation Data Centre
UV Related Links - NOAA
OAA Antarctic UV Monitoring Network
UV Index: Annual Time Series
UV Index EPA Envirofacts API
UV Net Data Archive
UV Index - UV-B Monitoring and Research Program
UV Index - UV-B Monitoring and Research Program
Air Quality Index KML
County Level UV Exposure Data for the Continental United States "
Retrieving Amazon product reviews?,"
I am currently working on a customer feedback project for brand products. I've used social media sources like Twitter and Facebook to get brand mentions, but I need customer feedback for particular products.
I've tried Octoparse to get Amazon product details but it doesn't seem to be able to collect customer feedback. Does anyone know of a method for scraping/collecting product reviews?
","['data-request', 'api', 'social-media', 'products', 'companies']",
How to read Data.gov Data Update Frequency code,"
How to read data update frequency code. For example for Consumer Complaint Database the code in the Dates section is :
Data Update Frequency:  R/P1D
How to read R/P1D. I guess it is a daily update but I am not sure. Where can I find the codification rule?
",['data.gov'],
OPenFDA API - querying on dosage_and_administration_table _exists_ not working,"
I was planning to get the results where brand name is aspirin and whose drug result has property dosage_and_administration_table. 
So I did this
https://api.fda.gov/drug/label.json?search=brand_name:aspirin+AND+_exists_:dosage_and_administration_table&limit=100

It returns no results (no matches found). But there are results where dosage_and_administration_table exists. And one more interesting thing is _exists_ works with every other parameter like active_ingredient, dosage_and_administration etc., but not with dosage_and_administration_table. 
What's wrong with the query?
","['data.gov', 'api', 'openfda', 'json']","I have looked at the openFDA code: it appears dosage_and_administration_table element is explicitly excluded from indexing in Elasticsearch along with a bunch of other table elements, which is why you can't query on it, but still are able to see it in some search results.I'll need to go back to the team to understand why dosage_and_administration_table is being excluded from indexing; most likely because it contains HTML markup and is redundant to the dosage_and_administration element. In the meantime, I'd recommend that you use dosage_and_administration in your _exists_ clause."
USPS drop box locations in NYC?,"
I posted this in GIS but was referred here. I'm hoping someone could point me in the right direction...
I'm doing some analysis on the impacts of neighborhood characteristics on physical activity. One of the covariates is distance from geocoded home addresses to points of interest, which include USPS office and drop box locations.
Does anyone know if a dataset/shapefile exists containing USPS drop box locations? I was able to find USPS locations from NYC Open Data, but can't seem to find one with the list of drop box locations.
","['data-request', 'usa', 'geospatial', 'city']",
"Health Care industry data for Hospitals/Urgent Cares, etc","
Is there a database available (free or not) that contains health care industry data for hospitals, urgent care, clinics, their location, ownership information (parent/child relationship), and other information for the USA?  CMS tracks doctors and ""some"" hospitals however the industry uses ambiguous terms for what is a hospital vs medical center or primary care center vs urgent care.
Does anyone know of a source for statistics in the US Health Care industry? 
","['data-request', 'usa', 'medical', 'analysis']",
Books by category published annually in Ireland,"
UNESCO monitors both the number and type of books published per country per year.
It's very intriguing for me to notice that Ireland is missing from this list.
I was wondering how can I get such figures, at least a rough estimate, for any year for Ireland. Does anyone know a source for the numbers and categories of books published in Ireland?
","['data-request', 'books', 'ireland']",
US Election Twitter Data,"
Is there a way that I can get US election-related tweets from October 15 to Nov 15 from various countries.
Can anyone tell how to use the Twitter API to get data older than a month? Alternatively, does any one know of sources where I can get this data which includes tweet content, location, date, time etc.? Any sort of help much appreciated.
","['usa', 'api', 'elections']",
DBPedia missing important smartphones,"
I could see DBPedia is missing very important mobile phone list. They exist in Wikipedia but not in DBPedia, e.g. OnePlus series, Micromax Yureka , Moto g4
I'm refering this link: http://live.dbpedia.org/page/Smartphone
Does it mean that it is not yet ready to be used for critical usage - say a customer related project?
",['dbpedia'],
Database of lots in Tokyo,"
I am looking for a dataset of all lots/addresses in the Tokyo Metropolis, or a dataset containing this information that I can process.
Japan has an open data portal, but most datasets are (logically) in Japanese, and none of the English-named ones appear to contain the relevant data:
http://www.data.go.jp/data/en/dataset
The 'Japan City Open Data Census' has 'no data' as to whether Tokyo provides this information:
http://jp-city.census.okfn.org/place/tokyo
Thanks for any help finding such a dataset, or even Japanese terms or resources to use to search for it. 
","['data-request', 'geospatial', 'address', 'japan']",
Aerial or high quality satellite images from one area at different times in a day?,"
I'd like to analyze some changes in time. Is there a way to get free aerial or high quality satellite images from one place in different times of the day - for example one for each hour?
I'm not interested in any specific area, instead I want many high quality (high resolution) timestamped images from one arbitrary inhabited area.
","['data-request', 'geospatial', 'images', 'analysis', 'aerial-photography']",
Indian Religions/Castes List?,"
I am developing a matrimony web application, for this a list of Indian religions and their belonging castes is required.
Does anyone know of a data set containing the Indian castes and/or religions organized by geographic region?
","['data-request', 'demographics', 'india', 'religion']",
Evaluations of programs that aim to reduce gender-based violence?,"
I'm looking for evaluations of programs that aim to reduce gender-based violence (GBV), specifically within countries.
So far, I failed searching for them (how would I search for them)?
",['usaidopen'],
Real-time data APIs,"
I've recently started building a home project in Java for which I need lots of data (around 100 events per second). The problem, of course, is that I can't seem to find any publicly available APIs I could use. 
The only source I found is meetup.com's RSVP that can deliver around 150 events per minute.
Does anyone know of open API services that deliver 100 events per second?
","['api', 'big-data']",
US Population/Housing Data?,"
I'm looking for population and housing data for the USA at the city-wide level. The 2010 Census page has this information available: 
http://www.census.gov/2010census/popmap/ipmtext.php?fl=06:0667000#
But it's only for that year and it has a rather complicate format for automate the task. For the case of population density information is available in CSV format (http://www.census.gov/2010census/data/) but only at a state wise level.
Does anyone know of another source for higher resolutions of this data? 
","['data-request', 'us-census', 'demographics', 'population', 'real-estate']","The Census API is pretty good and should have what you're looking for. If you want only recent data, you can use the ACS to get 2014 data. If you want more historical data, the 1990, 2000, and 2010 are all exposed via the API."
Wharton Research Data Service - Need to query/download comScore dataset,"
I'm currently doing a project in university which involves analysing passenger behaviour in the airline industry. 
I am seeking clickstream data for airlines, who I have contacted but to no avail. 
I have identified the comScore dataset on wharton as being suitable for the study and alas I have no access.
If any kind soul could help me out with this it would be greatly appreciated. Or if anybody know of any airline clickstream datasets, please let me know. 
Thanks In Advance, 
David 
",['data-request'],
US phone area code city/state database?,"
Is there a database that matches each US phone area code to the major city and state that it belongs to?
","['data-request', 'usa']",
"Olympic speed skating data, beyond final standings","
I'm looking for Olympic speed skating data, I have found many data sources providing the final standings (e.g. the official website: https://www.olympic.org/olympic-results).
However, I'm also interested in the order in which the athletes started, who they were paired with, what lane they started in (inner or outer), false starts and disqualifications. Does anyone know where I can find these data?
My interest isn't limited to the Olympic games only, data from other speed skating competitions would also be great.
","['data-request', 'sports']",
Services used to collect training data for Machine Learning,"
What services do ML/AI researchers use to get training data? (Amazon's Mechanical Turk, CrowdFlower)
What kinds of tasks do researchers post to those services? Are tasks usually a variant of classification tasks*?
I am trying to collect some data from ML researchers, practitioners or hobbyists. 
* User can select one of the classes (options) provided as solution to the task. E.g. Is this product a [1] Electronics Product [2] Beauty Product [3] Health Product?
","['data-request', 'machine-learning', 'classification']",
Database of injuries of inmates while awaiting trial in jail,"
I am looking for a dataset listing injuries of inmates who were awaiting their trial in a jail. Injuries could be caused by anything, e.g. other inmates or neglects.
Here are some fields I would be interested to have:

date/time
jail location
inmate demographics
type of charges against the inmate
type of injuries
length of the state in the jail
outcome of the trial

I am mostly interested in jails in the United States.
","['data-request', 'legal']",
How to Geocode coordinates?,"
I need a way to obtain the coordinates for all of one type of store/restaurant in a country. For example, all the McDonald's in South Africa. 
I'd like to use R or any tool that is more appropriate. I've looked into using Google's Geocoding API but I'm not sure if it integrates well with R. My experience with using APIs is limited.
","['api', 'programming', 'geocoding']",
Running Data / Race Data,"
I'm interested in measuring my performance (as a runner) against a large pool of statistics to grade myself overtime and understand how I am improving. 
I'm familiar with the WMA tables and how to calculate an age graded score, but I'd like to use more granular datasets (with actual finish times, ages, genders, different distances...etc) in order to visualize how I compare and what my next goal should be. 
Does this kind of dataset exist? If so, where can I find it?
","['data-request', 'sports']","I am not aware that such a dataset exist.
But almost every race organiser (including the ones at amateur levels) put the results (often organised by age, gender, ...) online, publicly accessible.
Unfortunately they are usually not directly downloadable which means you have to scrap them from the web site or parse a PDF document.
An example is the Boston marathon data from 2001 to 2014 which have been collected in a GitHub repository as CSV files by Bill Mill."
National Spanish soccer lotteries - La Quiniela and El Quinigol datasets,"
Looking for any of those National Spanish soccer lotteries in format similar to :
week, game 1, game 2 .... Chances: Home (game 1), Draw (game 1), Away (game 1)    ...

1       X       2                     20%             35%            45%
2       1       X                     60%             20%            20% 

PS. Info about lotteries here - https://www.quinielista.es/index.asp?fuseaction=home
","['data-request', 'sports', 'data-format', 'europe']",
Clinical dataset,"
Does anyone have any idea where I can get free clinical data (it does not matter what it is) for a data mining project I have? I need to use the data to predict something like mortality or hospitalization or... to do classification basically. 
An example might be: I have data on cancer patients containing conditions (stroke, chf, etc.) and demographics. Using these features (some or all) I can predict one year mortality. There are no specific criteria. I just need a relatively big and slightly complex (health-related) data.
I need to do some preprocessing first (so it should not be clean data) and use something like Weka to do the prediction. 
The data can be in the following formats csv, tsv, xls
","['data-request', 'medical', 'machine-learning']",
Emmy Award winners,"
I'm looking for nominees and winners of the Emmys, but haven't found anything more structured than a Wikipedia article:

https://en.wikipedia.org/wiki/List_of_Primetime_Emmy_Award_winners

And a scraping-friendly list on the Emmys' website:

http://www.emmys.com/awards/nominations/award-search

I've checked the IMDb FTP dump but didn't found any award data. I tried Wolfram Alpha (as described here); it shows only the Oscars.
Is there a machine-readable list of Emmys or only scraping can help?
","['data-request', 'film', 'media']","The dataset is not available, it could be useful in several projects and this Sunday evening was boring: three good reasons to scrape this site. Here is the file. It contains the nominees and the winners from 1970* to 2016 (two sheets). Before merging both, I would prefer that someone take a look at it to check the data quality. * I wonder why the scraper stopped in 1970, since the site contains information until 1949"
Running openFDA api locally,"
I am trying to do some classification and clustering on the openFDA dataset. I started by downloading a year's worth of data and realized I run into system limits and would need to solve for that.
Then I decided to query for just one drug indication, the subset I am looking at has about 422k records. But I realized that I hit the skip limit and cannot get the data through the API. 
I then decided to run the api locally so as to push through the limits, but I am unable to find clear instructions on how to do it. I have installed node, elasticsearch, and run bootstrap and npm install? I believe I need to run the pipeline, do I just run all-pipelines.sh?
","['openfda', 'uses-of-open-data']",
Cyber Monday Traffic Data,"
Are there any sites/tools that provide data on how much traffic a site is currently encountering?
I'm particularly curious to see how much traffic increases on sites like Amazon.com with regard to ""Cyber Monday"". So, more appropriately, does Amazon provide any live streams or web services for such data?
","['data-request', 'extracting', 'polling']",
Sources of weather data,"
Barry, could you abuse this site's ""answer your own question"" feature to create a community wiki answer for sources of weather data (both current and historical), since it gets asked so often?
","['data-request', 'weather', 'climate']","This list is (and may always be) incomplete. Please add to it when you can.Per minute data: ftp://ftp.ncei.noaa.gov/pub/data/asos-oneminNOAA's ISD data (goes back to ~1900 in some cases):https://www.ncdc.noaa.gov/isd (home page)ftp://ftp.ncdc.noaa.gov/pub/data/noaa/ (direct link to data, some stations include multiple report per hour in some cases)https://www1.ncdc.noaa.gov/pub/data/noaa/isd-lite/ (direct link to ""lighter"" version of data-- hourly observations only)Global Historical Climatology Network (GHCN) observations, some dating back to the mid 1700s:https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-ghcn (home page)ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/ (direct link to data)http://mesowest.utah.edu/ includes solar radiation and snowfall accumulation, which some other sites don't. Sample:The ""raw"" data as it comes into NOAA from airports, surface weather stations, boats, and buoys:You can read more about these ""cycle"" files at: http://www.nws.noaa.gov/tg/datahelp.php Note these files are updated every few minutes and have not been curated, so data can be inaccurate. Reports in these cycle files are sometimes updated (and thus invalidated) in later cycle files.To translate station codes to physical locations:Well known sites:"
ChartEvents Column ValueEOM,"
I would Like to know Following information About Chart Events table:
1)full form of the ValueEOM column.
2) what they are used for .
3) Abnormal Values range 
For Example:
bpm : Beats per minute 
used for : heart rate
Normal Value Range : 60 to 100 
There are 100 unique values of the column. It would Be great if some one would help me find these value details. Also if there is any info useful regarding these informtion in MIMIC-iii will also be of great help.
Thanks In Advance.
",['mimic-iii'],
free astronomical datasource with the oldest historical data,"
I want to know the position of some well-known astronomical objects as deep in the past as possible.
Which is the open database of astronomical objects with the oldest historical records?
","['data-request', 'astronomy']","Historical records have been superseded observations of modern scientific satellites (especially with respect to positioning data). Older catalogs dating back to the late 1800s were useful for identifying the stars themselves. Many of these identifiers have been carried over into the 21st century.I compiled a list of these well known catalogs here:https://numeracy.co/artnez/star-catalog/The ""Catalogs"" folder contains normalized versions of existing catalogs. The oldest catalog listed there is NGC2000.0 which is a revised version of the New General Catalog (published 1888)."
Worldclim and Interpolation [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 6 years ago.







                        Improve this question
                    



I am interested in work with climate data since 2012, I found it in http://www.worldclim.org/version1, but there is something draws my attention:
There it says: ""Current conditions (interpolations of observed data, representative of 1960-1990)""
Does it mean the current data is something like a ""temporal projection"" based in data of 1960-1990?
or
Should I understand it like an interpolation of weather stations existing since 1960 with not including stations existing since 1990?
",['climate'],
Making sense of US census summary tape files?,"
I'm trying to get 1990 decennial US census data into a choropleth map, but having difficulty making sense of the data format and documentation. I've gathered that the block level data belongs in summary tape file 1b
http://www2.census.gov/census_1990/STF1B_ASCII/
These are organized in .zips by state, but without headers. There is documentation 
http://www2.census.gov/census_1990/STF1B_ASCII/TechDoc/D1-D90-S100-14-TECH.pdf
but it runs 200pp, and after a few hours I've only gathered what I've written above. I have no idea how the data dictionary manifests itself in these text files, or what the rows/columns correspond to. A simple example of, e.g., how to extract age summaries for census blocks X would go a long way.
","['usa', 'census']","After googling around and playing w/ the files, here's what I found:There are 4809 characters per row, and 2 rows make up a record for
a total of ~9618 characters (columns) total.http://www2.census.gov/census_1990/STF1B_ASCII/TechDoc/STF1CRDD.ASC
is the file you need.In this file, the rows starting with ""G1"", ""T1"", ""F1"" start a new
field. All rows until the next ""G1"", ""T1"", or ""F1"" are about the
given field.An ""F1"" row just indicates a filler of blank spaces. These only
occur at the end of each line (2 lines = 1 record) to keep the row
lengths even.An example of set of ""G"" rows in STF1CRDD.ASC and what they mean:The ""G1"" is just an indicator that this is a G1 rowThe ""AREAWAT"" is an abbreviation of what information is provided
in this field (in the actual data file, eg STF1BxAK.F01); if you
want the full description, look for the ""G2"" row immediately
following the ""G1"" row:G2 182 Area (water)The ""10"" is the column length of the field.The ""A/N"" probably represents whether the field value is a
number, a string, or something else, but I'm not entirely sure.Both ""182""s represent the starting column for the data. For the
""G"" fields, these numbers are identical. Similar numbers will
differ for the ""T"" fields, described below.Thus, the water area for the geographical area in a given record
is given in columns 182-191 (the 10 columns starting at column 182).Note that the next field G1 ANPSADPI 66 A/N 192 192 0 begins
at column 192, as we would expect.For some ""G"" fields, like ""AREAWAT"", the following columns
simply provide a number. In others, however, the value of the
field is provided in a lookup table. Example:If the value of the field in column 289 (namely ""PSADC"" or
""Political/Statistical Area Description Code"", which extends to column
290 since it's a two-column field) is ""05"", it means:Census area - county equivalent in Alaska; ""Census Area"" is appended
  to the name of the entity in census publications and related data
  products.Note that the description is broken across 3 rows, since G3 rows are
at most 81 characters in length.T1 P22 5646 841 9 0 37 1The ""T1"" simply indicates this is a ""T"" record.The ""P22"" indicates what information this field gives. This
information is described in text in the ""T2"" field immediately
following:T2 P22 RELATIONSHIP AND AGEand also starting on page 37-47 of the PDF file you provided.The 5646 indicates this field starts at column 5646 if you
consider the two lines that constitute a record as a single
line. If you consider the second line just by itself, this field
starts at column 841.The 9 indicates that each value in this field is 9 characters
long (but see next point).The 37 indicates there are 37 values packed into this field.I don't know what the ""0"" and ""1"" mean.Note that 37 values at 9 characters each is 333 characters
total, so we would expect the next ""T"" field to start at 5646+333
= 5979, which it does:T1 P23 5979 1174 9 0 12 1T4 P22 RELATIONSHIP AND AGE 37means the first of the 37 values gives (namely, the values from column
5979-5987, since each value has 9 characters) is the number of
households reporting another householder or spouse living with the
person who filled out the Census questionnaire. Note that we ignore
the ""In households:"" row, since it ends in a colon.The next 9 columns indicate the number of households with a child
under 3 years old where the child is related to the person filling out
the Census (thus, ""related child:"") and, in fact, the direct
descendant of the person filling out the Census (""Own child:"").Again, the ""Related child:"" and ""Own child:"" do not take up any
columns in the data file. If you count the number of non-colon lines
with ""T4 P22"" (and exclude the first line which indicates the number
of values), you'll see that it's exactly 37.Note: I've taken minor liberties with formatting, such as reducing
multiple spaces to a single space.DISCLAIMER: The above may not be 100% accurate.Other possibly helpful links I ran across (some of these have subsets of the above data in different formats):"
Where to find Geology data for Europe - GIS,"
I'm looking for Geological/Lithological data for Europe in any scale (obviously more detail = better). Is there something similar to Corine Land Cover, but for geology?
CLC is great, because it standardize data for whole Europe, so there is one legend for whole Europe and we can compare different parts of Europe.
Data which I'd like to find could be either free or paid, but it should be vector data in GIS format (shapefile).
","['data-request', 'geospatial', 'europe', 'database']","Whilst onegeology.org is great, and certainly there are a lot of European Geology WMS and some WFS services available.  In this situation I think that currently (a) you might be better off going to the EGDI portal.  European Geological Data Infrastructure (EGDI) is a collective project of the European Geological Surveys, and EGDI is intended to showcase all geological data sets available as OGC services that have been created by these survey organizations, which includes services that they have made available on OneGeologyAs part of the creation of the EGDI portal the survey organizations revisited their harmonized geology services (some of the old services are available on the the soon to be retired OneGeology-Europe portal), updating the attribution to use the latest INSPIRE vocabularies, and are working to create both GeoSciML WFS and GeoSciML-Lite (portrayal) WMS, the latter of which will offer default styles based on the colours recommended by the INSPIRE geology data specificationFor EGDI the geological survey organizations have also created a collective harmonized geology simple feature WFS of some of the attribution from their fuller (complex feature) WFS.The service endpoint for simple feature WFS is:So the WFS GetCapabilities is:You get both age and lithology data sets for surface geology at a variety of scales.  As it's a WFS you get the data to download as GML (shapefile is not available in this service), but you can use GIS software such as QGIS to convert the GML to a shapefile.  As it's a WFS you don't get any styling.  If you want to see styling for this data you can use the corresponding WMS, or if using QGIS you can apply the appropriate SLD as below:(a): Eventually I expect that all harmonized geology services (WMS and WFS) will be available through the OneGeology Portal.DISCLAIMER.
I work for a European geological survey organization, and have been involved in OneGeology, OneGeology-Europe, and the EGDI projects."
Python crashing when trying to read zipped json files [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 6 years ago.







                        Improve this question
                    



I downloaded the 2015 adverse drug events data from openfda and I want to run some analysis with python. I am a python newbie, but have become comfortable with the scikit-learn libraries, but I cannot seem to get the json decoding to work to even get started.
This is my basic script:
import json  
import zipfile  

d = None  
data = None  
with zipfile.ZipFile(""./data/drug-event-Q4-0001-of-0013.json.zip"", ""r"") as z:
   for filename in z.namelist():  
      print(filename)  
      with z.open(filename) as f:  
         data = f.read()  
         d = json.loads(data)  

I know this is a pretty basic question, but I have been searching and though I am able to find code snippets for gzip, I cannot find any for plain zip files.
","['openfda', 'uses-of-open-data', 'python']",
Music database like IMDb,"
Looking for a public music DB Api, where a music title / author of music are submitted and it returns cover photo and sample of the song can be downloaded for listening. Something like IMDb for movies. Does anything exists?
Found this list here.
","['api', 'music']",
Accessing NREL data for specific wind turbines?,"
I am looking for a specific data set from NREL (US National Renewable Energy Laboratory) western wind resources dataset, but I am not sure how to navigate the site to access and download the file.
The data I am looking for is the 10-minute data for years 01/2004 to 06/2005 for machine learning training data, and the 10-minute data for years 7/2005 to 12/2006 as test data.
The turbines I would like to obtain this data from are Casper (ID = 23167), Hesperia (ID = 2028), Las Vegas (ID = 6272), Reno (ID = 11637), and Vantage (ID = 28981).
These are all values given in a paper on machine learning, and I would like to use the same data these researchers used but conduct different experiments on them with different algorithms.
Do you know how to access this data on the NREL site so I can download it as a file? If possible, please post either the instructions or the link to the source.
","['data-request', 'usa', 'machine-learning', 'weather', 'energy']",
Animal size database query,"
I am looking for different database that would present length, height, weight etc.... Of an animal (any). I am looking for a table of at least 300 - 500 animals of one type in a table. Preferably mammals, but birds are good as well. 
","['data-request', 'database', 'animals']",
"Movie review blog posts with view count, likes etc","
I started doing a research project for my final year and I need to analyze blog posts and extract common patterns from them.
For that I need blog post data where I can get the content with number of views, likes, comments, social media shares and etc.
I am mainly focusing movie and product reviews. 
Are there any public datasets available for my requirements?
",['sentiment-analysis'],
Free CDN (content delivery network) serving US Census shapefiles?,"
Is there a free CDN (content delivery network) serving US Census shapefiles?  Specifically, I need state legislative district boundaries.
Of course, I've googled around, and didn't see anything. Sometimes it's just a matter of knowing the right terms to search for though. I'm using them in a JavaScript-powered mapping application (Leaflet).
I must emphasize here that I don't want to link directly to the Census Bureau because AFAIK it's not an intended mode of use; they may change URLs, and probably are not set up to support heavy load. (I don't expect huge use, but you never know.)
","['geospatial', 'api', 'us-census', 'census']",
Personal information dataset,"
I am looking for a dummy dataset of personal data with these fields:
Name
Gender
Location
Age

Does anyone know where I could find something like this?
","['data-request', 'geospatial']","I've used an online tool for this task. With this you can make dummy CSV, Excel, JSON and other files. You can choose the field names and types, and set limits and functions. 1000 rows are exportable per CSV. Here's a simple example - there are other websites that will do the same (e.g. Mockaroo)"
traffic statistics by roads or parts of any German city,"
I'm looking for any traffic statistics by roads or parts of any German cities. I would like to use it for a QGIS-Workshop with students of Infrastructure-Science.
Add: I found something at DeStatis: https://www.destatis.de/DE/Publikationen/Thematisch/TransportVerkehr/ThemaVerkehr.html but unfortunately without spatial reference.
","['germany', 'traffic']","The GeoPortal Deutschland has a list of sources from which to pull GIS data. A first stop might be Open DataBerlin's FIS-Broker provides a pretty nice dataset. If you are not German speaking the word you are looking for: Straßenverkehrszählung or Verkehrsmengen.
"
Seeking shapefile of Cumbria (county) outline?,"
Looking for a shapefile of the entire county of Cumbria (UK) to use in ArcMap.
Any ideas on where I can find one? 
",['uk'],
North American housing and real-estate appraisal data,"
I am trying to perform spatial analysis regarding affordable housing across North American cities. 
Does anyone know of a source (city, commercial, or other website) which offers real estate or housing appraisal data?
","['data-request', 'geospatial', 'real-estate', 'north-america']","Affordable housing is difficult to track as there are intricacies to the process: Is it Housing Choice Voucher Program (Previously Section 8), is it a an established property that specifically handles affordable housing (which the government pays a private enterprise to operate), or is it public housing. You should look at property appraiser data for each county to figure out what basic values are available, then identify where the affordable housing locations are.Statewide Parcel Data in Shapefile Formats with Property Appraiser Data:Use Trevor's answer for non-commercial purposes only, Scrapy, is your scraping buddy.If you adhere to the guidelines, you can access MLS data through the Zillow API.Finally, you are going to need to go the HUD website to identify affordable housing locations. "
Accessibility categories for social media data,"
What is the best way to generically categorise data in social media back-end databases within a context of level of openness?
Both academic sources and own thoughts and ideas are appreciated as I have struggled to find any categorisation of the sort.
I didn't come far and my definitions are not crystal clear but here is what I thought:

Open data - information that is open to anyone who requests it. For instance the data that you can access when visiting an url to a Facebook profile without being logged in.
Open data with general limitations - information that is open to a user only if the user meets certain general requirements. For instance the data that you can access when visiting an url to a Facebook profile while being logged in. Also data in open Facebook groups.
Open data with qualified limitations - information that is open to a user only if the user meets specific requirements. For instance the data you can access if you are logged into your Facebook account and the Facebook profile you are visiting is a Facebook friend. Also data in Facebook groups that can be joined after being approved.
Locked data - information that is open only while being logged in as a specific user. For instance that user's chatlogs, data hidden from everyone through privacy settings. Also data in secret Facebook groups.
Internal data - information available only to the provider of the service. For instance every chatlog of every user.

I realise different social media use different standards. I hope this can be a categorisation in general terms.
","['metadata', 'social-media', 'open-definition', 'categories']",
Scraping product image from eCommerce websites [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 6 years ago.







                        Improve this question
                    



What are the legal clauses associated with scraping images of products displayed on eCommerce websites (such as Home Depot, Walmart, Amazon, eBay etc)? The intention is to obtain meta-data from the images, and not to reproduce or store them. 
","['legal', 'web-crawling']",
Sources of weather data,"
Barry, could you abuse this site's ""answer your own question"" feature to create a community wiki answer for sources of weather data (both current and historical), since it gets asked so often?
","['data-request', 'weather', 'climate']","This list is (and may always be) incomplete. Please add to it when you can.Per minute data: ftp://ftp.ncei.noaa.gov/pub/data/asos-oneminNOAA's ISD data (goes back to ~1900 in some cases):https://www.ncdc.noaa.gov/isd (home page)ftp://ftp.ncdc.noaa.gov/pub/data/noaa/ (direct link to data, some stations include multiple report per hour in some cases)https://www1.ncdc.noaa.gov/pub/data/noaa/isd-lite/ (direct link to ""lighter"" version of data-- hourly observations only)Global Historical Climatology Network (GHCN) observations, some dating back to the mid 1700s:https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets/global-historical-climatology-network-ghcn (home page)ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/ (direct link to data)http://mesowest.utah.edu/ includes solar radiation and snowfall accumulation, which some other sites don't. Sample:The ""raw"" data as it comes into NOAA from airports, surface weather stations, boats, and buoys:You can read more about these ""cycle"" files at: http://www.nws.noaa.gov/tg/datahelp.php Note these files are updated every few minutes and have not been curated, so data can be inaccurate. Reports in these cycle files are sometimes updated (and thus invalidated) in later cycle files.To translate station codes to physical locations:Well known sites:"
What are some good databases of wind speed and direction to use as training data for machine learning? [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 6 years ago.







                        Improve this question
                    



I am fairly new to machine learning, but what I am trying to do is predict energy output of a wind turbine based on a data set of wind speed and direction, and ideally turbulence and shear.
Do you know what type of data I need? I know I need a database of wind speed, direction, and possibly turbulence and shear. My questions are as follows:

Do you know of a specific database I can use with wind data and files I can download for my algorithm? So far I have these two sites:       

50-meter wind from National Renewable Energy Laboratory 
NOAA Federal Climate Complex Integrated Surface Data Inventory

Are these good options? Can I download one of these files to use in MATLAB?
Do I also need data of past energy outputs of the wind turbines I am focusing on (for comparison of my prediction with the actual data)?
Might neural networks and SVM algorithms suit the purpose of predicting wind energy output?

Thank you!!
","['data.gov', 'machine-learning', 'weather', 'energy']",
List of every city and town in the world?,"
I was wondering if anyone knows of a downloadable list of all cities and towns in the world. 
Can someone suggest a resource that has a comprehensive list city and town names?
","['data-request', 'city']",
"Dataset of US local, state, federal contact phone numbers?","
I'm looking to create an app that facilitates U.S. Americans to contact local, state, or federal representative based on home address. I can use the already public shape-files to figure out the relevant municipalities but I can't find a centralized list of contact numbers.
Does anyone know of a comprehensive list of contact information for multiple levels of US government representatives?
","['data-request', 'usa', 'data.gov', 'government']",
Toy problem for RNNs in computer vision,"
I am writing some neural network training code that I will later use to solve a specific problem. First, though, I want to validate that the code is working and is able to train an RNN (recurrent neural network) as expected.
I'm looking for a simple problem and dataset that I know a simple network can do very well on. Here are some guidelines/criteria:

The problem should not be too difficult. I want to be able to train networks quickly so that I can fix bugs in the code quickly, without waiting several says for the training to complete. Thus, small networks should be able to solve the problem well.
Ideally, reasonably small networks would be able to achieve near-perfect accuracy. This gives me a metric I know I should be able to aim for.
The problem should not be trivial. Several resources online suggest generating simple number sequences, but I worry that my training code might break down when I switch to my real dataset.
A computer vision based task would be preferable, since my real problem is one of action recognition. I hesitate to use datasets as complex as Sports1M and friends, though, since work on datasets like these is still the cutting edge--hardly a toy problem.

If I were implementing pure CNNs, I would simply use MNIST or CIFAR, but I'm unsure what the analog is for convolutional RNNs. What are some datasets that I might use?
","['data-request', 'machine-learning', 'images']",
Water Quality/Infectious Disease Data,"
I am trying to find data on how water quality (such as the presence of nitrates and phosphorus) correlates to infectious disease.
I have found many papers that discuss the approach and results, but have not been able to find any downloadable data that I can use to train a neural network, which will predict outcomes based on a given set of water quality data.
","['data-request', 'disease']","I work at Quandl and we have some databases that cover water quality and infectious diseases. Within each database, you can search for ""water"" or ""infectious disease"" to narrow the datasets presented to you. Here are some databases showing datasets for ""infectious disease"": Organisation for Economic Co-Operation and Development https://www.quandl.com/data/OECD-Organisation-for-Economic-Co-operation-and-Development?keyword=infectious%20diseaseNational Bureau of Statistics of China
https://www.quandl.com/data/NBSC-National-Bureau-of-Statistics-of-China?keyword=infectious%20diseaseNational Institute of Statistics and Economic Studies (France)
https://www.quandl.com/data/INSEE-National-Institute-of-Statistics-and-Economic-Studies-France?keyword=infectious%20diseaseHere are some databases showing datasets for ""water quality"" - you may also want to try searching just ""water"" or ""water sanitization"": WHO UNICEF
https://www.quandl.com/data/WHO_UNICEF-Who-Unicef-Joint-Monitoring-Program?keyword=water%20qualityWorld Bank Africa Development Indicators
https://www.quandl.com/data/WADI-World-Bank-Africa-Development-Indicators?keyword=waterUN Environment Statistics
https://www.quandl.com/data/UENV-United-Nations-Environment-Statistics?keyword=waterUN Global Indicators
https://www.quandl.com/data/UGID-United-Nations-Global-Indicators?keyword=water%20Hope this helps somehow..."
Email data set with plain text emails for spam classification,"
I am searching for a data set, which contains plain text emails, in order to do a classification of spam or not spam emails.
I this data set but it does not contain the text of the emails. I also found the enron email data set, but I found very weird formatting in the emails, which probably no one would enter manually when writing a mail. Not only html tags. HTML tags would be fine I guess, I could probably simply remove them with a regex and then have cleaner data.
Which email data set has plain text without artificially added weird formatting and is recommendable for learning spam classification?
","['data-request', 'machine-learning', 'email', 'classification']",
Availability of descriptive ship metadata,"
I'm creating my own ship position map by AIS (Automatic Identification System) messages from the base transceiver station (BTS).
Can I find a free database of static information about the ships by MMSI (Maritime Mobility Service Identity) number ?
I need only ship name, type and dimensions.
","['data-request', 'transportation', 'metadata', 'database', 'ais']",
Sources for federal funding of local governments,"
Are there sources that would let me find out how much money my local government receives from the federal government, ideally by federal program. My local government's budget documents lump federal, state, and local grants together.
","['data-request', 'usa', 'federal']",
Postal code boundaries for India?,"
I'm trying to find out where to download Postal Code boundaries (e.g. Shapefiles, GML, KML) for India. This data needs to be compatible with a typical GIS software (e.g. ArcGIS, QGIS).
Can someone point me to a data source for this?
","['data-request', 'geospatial', 'postal-code', 'india', 'kml']",
Elevation data by latitude and longitude for the Grand Canyon,"
I am looking for elevation data organized by latitude and longitude for the Grand Canyon.
I have found USGS elevation data (http://nationalmap.gov/elevation.html), which is in the form of an ESRI Grid, which I don't know how to read. I was looking for a more straightforward data set of Longitude, Latitude, and Elevation. 
Alternatively, if someone  could describe how to read data from a .dbf file into matlab that would be great. I have tried to download Mapping Toolbox add on for matlab in order to use arcgridread command, but it isn't included in my matlab licence.
","['data-request', 'geospatial', 'data-format', 'environment']",
Tweets organized by regional location and period of time?,"
Where can I find large data-sets of tweets from people in a certain region (say an entire state or city in the US), during a certain period (say last 6 months, or from June 1st 2015 to June 1st 2016)?
So, for example, a large data-set of tweets from people in Illinois in the last 6 months? Is this possible? Is location something Twitter makes public? Or am I looking at geolocated tweets only?
","['data-request', 'geospatial', 'social-media']",
Introduction to Statistical Thought - med.1000 dataset,"
Does anyone know where the med.1000 dataset used in the Introduction to Statistical Thought book (by Lavine, PDF) comes from?
I just can't seem to find it with Google!
It contains measurements of ocean temperature at a depth of 1000 meters in the North Atlantic near 45 degrees North latitude and 20 degrees West longitude.
","['data-request', 'programming']","Following @philshem's advice I emailed the author who kindly sent me a csv called oceantemps.csv. I get identical looking plots to those in the book using the code from the book with a only minor edits - med.1000 to whatever you import the csv as, and long, lat and temp are written in full as the column headings.After receiving the csv file I also found the website with the datasets for the book that had somehow eluded me: http://people.math.umass.edu/~lavine/Book/data"
is there a dataset of financial blogs?,"
I am looking for a database that contains the name of all the financial blogs out there. 
Ideally each blog should be linked to the website it refers to (say, I need to be able to know that blog X is a blog from the financial Times).
","['data-request', 'metadata', 'social-media', 'media']","Answers to this question are easily found with a search engine. For example, A list of 789 financial blogs:Top Personal Finance BlogsThere is no export, but the 7 pages of HTML-tables are pretty readableAnd the corresponding view in the browserHere's an online tool to convert HTML tables to CSV. There will be many others, although doing it yourself programmatically is probably the best bet."
Seeking spatialized Employment Information for England?,"
I was looking for a shapefile with employment opportunities (jobs) for England or London – at the LSOA or output level. Im not sure is this is what they call Workplace population. 
Is this it? 
Do you know how to get the data?
","['data-request', 'releasing-data', 'uk', 'europe']",
Does data change between versions of mimic III database?,"
I am on version 1.4 and the query below which is suppose to count number of in-hospital mortalities has a count of 5854. However, I'm reading a paper that is written on version 1.3 of mimic III and claims that there are 5813 in-hospital mortality events. 
SELECT count(*) FROM ADMISSIONS 
WHERE DEATHTIME IS NOT NULL ORDER BY DEATHTIME;

Either my query is wrong or does the data change between v 1.3 and v 1.4 of mimic iii?
",['mimic-iii'],"Several changes are made between versions, some of which may affect the result to queries such as the one in your question.  A summary of the changes is listed on the MIMIC website: http://mimic.physionet.org/about/releasenotes/In this particular case however it looks like the difference is a result of your query double counting 41 subject_ids. Adding the DISTINCT keyword to your query returns 5813 uniquesubject_id in MIMIC-III v1.4.I believe the duplicates relate to the way organ donor accounts are recorded in the system (see the diagnosis column of the admissions table)."
"List of all world cities with populations over 100,000","
I'm making use of the UN demographic yearbook which has a table listing most of the world's cities with populations over 100,000 (along with their populations). However, some major places are missing, such as China and both Congos. An answer to a similar question here provides a tsv file but GeoNames' population data is not too accurate (lots of outdated data and the specific sources used for each country are unknown).
Does anyone know of a list that does indeed have all of the world's cities with populations over 100,000 that also lists their population? Preferably as accurate as possible, i.e. using national census data, and relying on estimates only when necessary (and stating their source for each data point). 
","['data-request', 'government', 'population']",
How to classify EEG and ECG signals,"
I'm a student and a beginner on Physionet. What is the best method to classify EEG and ECG signals: KNN or SVM? And how can I do it with matlab? Should I convert the .dat files to .mat or just extract features to build my matrix for training and for testing? I don't know how to begin to develop my classifier?
","['machine-learning', 'research', 'data-format']",
Running statistics from real users,"
There are plenty of mobile applications where you save the running route you took with some stats like speed, distance, duration etc.
Here is an example from one of those apps:

So, I tried to google for any open dataset (global or country specific) with the coordinates and the stats from those routes. Of course without personal details.
Are you aware of any dataset like this one?
Edit: I am interested on walking/running routes and not driving routes. So, the suggested link in the comments is not related with my question. Although, it could be used as an alternative in case nothing else is available.
","['data-request', 'geospatial']",Open Street Map users can upload their GPS traces to the website and label them.There are about 4000 traces with the 'Running' label. You can find the individual traces here: https://www.openstreetmap.org/traces/tag/RunningThere's a similar number of traces with the 'Walking' label: https://www.openstreetmap.org/traces/tag/Walking
Free Cadastral Map,"
I'm writing a theoretical paper on landscape planning. I need a cadastral map to illustrate some things. It could be a map of a real city (doesn't matter in which country or state) or a fictional one (doesn't matter as long as the map is precise and if possible covers a whole city).
The filetype of the map doesn't matter (dwg,shp,svg,tif etc.).
","['geospatial', 'city']","From Wikipedia: A Cadastre is normally a parcel based, and up-to-date land information
  system containing a record of interests in land (e.g. rights,
  restrictions and responsibilities). It usually includes a geometric
  description of land parcels linked to other records describing the
  nature of the interests, the ownership or control of those interests,
  and often the value of the parcel and its improvements.Cadastral maps or parcel data can be found across the United States. Any county property appraiser will be able to provide you with this data and can be combined to form a basic city or metropolitan area.Statewide Data in Shapefile Formats"
Making changes to data already posted,"
We have posted data for a survey for Feed the Future and want to know how to make changes to what has already been posted to DDL?
",['usaidopen'],
2016 US national election exit poll data,"
I'm looking for 2016 US national election exit poll data. Is there an open source version of these data?
Essentially, I'd like access to the NYTimes data shown here:
http://www.nytimes.com/interactive/2016/11/08/us/politics/election-exit-polls.html
NYTimes characterizes their data:

The voter survey is based on questionnaires completed by 24,537 voters leaving 350 voting places throughout the United States on Election Day including 4,398 telephone interviews with early and absentee voters.

The source is cited as:

Edison Research for the National Election Pool, a consortium of ABC News, The Associated Press, CBSNews, CNN, Fox News and NBC News.

Is there an open version of these (or similar) 2016 exit poll data?
Note: there is an ongoing study that computes ""exit poll"" style results using ecological influence (Flaxman et al., 2016), but I'm seeking actual exit polls.
","['data-request', 'usa', 'elections']",
how to search archive.org for PDF files on a captured website between some date range,"
I am trying to search health insurance companies' website content on
http://archive.org/ during the period of 2005-2008 for legal documents related to pre-existing medical conditions.
most of these websites contain forms that users could have filled out for a cost estimate or rate quote, but http:// form submissions rarely work on archive.org historic pages, so my search dead-ends there.
I suspect that most of the actual text content I am looking for is hosted in legal agreements in PDF files, so the optimal search would simply be to grab all captured files ending with .pdf but I am unclear how to do that for a specific website for a specific date range?  example websites would be https://www.anthem.com/ or http://www.kaiserpermanente.org/
","['web-crawling', 'html', 'archive.org']",here's how i automated the process within R
Realtime Nationwide (or as many states possible) Auto Crash/Incident data,"
I'm looking to create a database that will pull Realtime Nationwide (or as many states possible) Auto Crash/Incident information with the inclusion of the people that were involved in the incident(s) first, last name, age and the incident type [auto_accident_personal_injury]. 
An example that has some of the information I need is here https://data.vbgov.com/Public-Safety/Police-Incident-Reports/iqkq-gr5p/data- but it does not include the first, last name, age which is public information. Wondering if there is a way to also grab this in Open Data Network?
I've looked for weeks now and cannot figure this out. Any help would be awesome! I'm willing to hire someone to help me.
","['data-request', 'cars', 'police']",
Survey Creation in Microsoft Access [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 6 years ago.







                        Improve this question
                    



I am trying to make a survey within a database system. My goal is to make an input where an individual selects their age and the program allows them to continue, similar to the Kunden Example. 
Can anyone help me in this issue?
Thanks alot
",['database'],
Labeled dataset for sentiment analysis in Mandarin,"
I am doing my research on sentiment analysis for Standard Mandarin. I don't have any benchmark dataset. I need usable labeled dataset for my research.
","['data-request', 'nlp', 'language', 'sentiment-analysis']",
Hate crime dataset in the United States,"
I'm looking for a dataset listing hate incidents in the United States with as many following fields as possible:

time and date 
location
demographics on attacker(s)
demographics on victim(s), or attacked community
type of hate incidents
legal outcome
victim injuries


Hate incidents can be based on the following:

disability
race
religion
transgender identity
sexual orientation.

","['data-request', 'usa']",
Reddit comments labeled data-set for sentiment analysis?,"
I was searching for a Reddit comments data-set which is labeled into three classes: positive, negative and neutral to train a ML model. I can get labeled data for tweets, movie reviews but what about Reddit. Is there any credible source for it?
PS: I don't want to annotate the data myself.
","['data-request', 'machine-learning', 'nlp', 'sentiment-analysis']",Reddit Comment Dataset Including Sentiment Data
Is there a dataset for the Federal congressional voting record?,"
The data.gov initiative has a large variety of digital data sources for every agency of the government, but Congress has ZERO data sources for their own voting records.
If someone can find it please let me know.
",['data.gov'],
OSHA Occupational Chemical Database,"
I need to access the OSHA Occupational Chemical Database using the API. Is that service available? I would like to download it to a local database and then translate it to other languages.
","['data-request', 'api', 'labor']",
List of New Jersey businesses sorted by zip code and SIC code,"
I'm looking for a list of New Jersey businesses sorted by zip code and SIC code.
","['data-request', 'business']",
OpenStreetMap: Finding shape dimensions from a query,"
I often propose OSM as a resource on this site, but actually I don't know how to use it very well. (I'll post this first to OpenData but maybe it's more appropriate for GIS.)

If I have a single latitude and longitude point, how can I find the dimensions or geo-coordinates of the object?
Here's an example:

latitude/longitude = (47.382844, 8.503754) - Satellite Image



On OSM, it looks like this (link):



And I'm looking for the coordinates of this rectangle:



According to the color legend, it's either ""Sports centre"" or ""Sports pitch"" (probably the former).



On the Overpass Turbo (OSM API) I can find the object - 168927595



And the Nodes underneath are actually the corners.



BUT how can I do this all programatically, via a URL, webservice or API?
I have to do only a handful of queries spread over months, so I can use a public resource with limited quotas. My geography is only in Switzerland for the moment.

I've tried the Nominatim API 
http://nominatim.openstreetmap.org/reverse?format=xml&lat=47.382844&lon=8.503754&zoom=18&addressdetails=0&polygon_geojson=1

results:
<result place_id=""71071014"" osm_type=""way"" osm_id=""28733849"" ref=""Stadion Letzigrund"" lat=""47.38282055"" lon=""8.50373866657526"" boundingbox=""47.3817046,47.3838748,8.502166,8.5051997"" geojson=""{""type"":""Polygon"",""coordinates"":[[[8.502166,47.3824916],[8.5021808,47.3826066],[8.5022493,47.3827219],[8.5023643,47.382886],[8.5027706,47.3832445],[8.5031899,47.3835916],[8.5033192,47.3836894],[8.5034696,47.3837748],[8.5036004,47.383825],[8.5037349,47.3838587],[8.5038731,47.3838743],[8.5040127,47.3838748],[8.5041689,47.3838591],[8.5043265,47.3838209],[8.5045304,47.3837468],[8.504745,47.3836457],[8.5049314,47.3835164],[8.5050552,47.3833863],[8.505141,47.383244],[8.5051831,47.3831285],[8.5051997,47.3830107],[8.5051826,47.3828853],[8.5051352,47.3827558],[8.5050291,47.3826127],[8.5049168,47.3824909],[8.5042159,47.3819128],[8.5041256,47.381865],[8.5040485,47.3818273],[8.5039701,47.3817961],[8.5038053,47.3817439],[8.5035874,47.381712],[8.5033799,47.3817046],[8.5032385,47.3817138],[8.5030521,47.3817444],[8.5028884,47.3817959],[8.5027417,47.3818565],[8.5026008,47.3819327],[8.5024694,47.3820137],[8.5023528,47.3821055],[8.5022551,47.3822116],[8.5022036,47.3822879],[8.5021698,47.3823797],[8.502166,47.3824916]]]}"">
Stadion Letzigrund, Herdernstrasse, Erismannhof, Hard, Aussersihl, Zurich, Bezirk Zürich, Zurich, 8004, Switzerland
</result>

But the GeoJSON results don't give the corner points of the rectanlge (viewer)

","['api', 'geospatial', 'geocoding', 'openstreetmap']","The problem is that OSM has many nodes and ways on the map, and many of them overlap. I don't know if there is any way to filter data with Nominativ, but you can filter data with Overpass.First step is to determine what data you want. In example above it seems that you want soccer field. OSM doesn't have any metadata standard, so it depends of every contributor what metadata is written to each feature. You can see the most common tags that are used on taginfo website.Second step is to write an Overpass query with bounding box location and key-value pairs of tags for data you wish to query, for example:You can write these kind of queries and test them at Overpass query form.
When you're satisfied with result, you can convert it to to compact Overpass QL at the same website. You'll get something like:URL link for that query would be:Third step is to save ID of feature (or features) in variable, and then you can use gimmeOSM (github.com/ustroetz/gimmeOSM) to get that feature as GeoJSON file, e.g.:"
"XLS or CSV Historic EDGAR CIK list, for a specific state?","
I'm searching for historic business physical addressees for California, I've found that the CIK header for EDGAR states the company name and address. 
Is there a method to download a file with all the CIK for a given year?
CIK is a Central Index Key with the SEC's (Securities and Exchange Commission) EDGAR system (Electronic Data Gathering, Analysis and Retrieval) 
","['data-request', 'usa', 'business']",
Canadian and USA Administrative Boundary Data Service,"
I have a list of place names (300+), which are mostly cites and states/provinces in United States and Canada. I would like to get the administrative boundary for them. I know the raw boundary data is downloadable from the government website but I wonder if there is any convenient service to search and download using API or a UI.
","['data-request', 'usa', 'geospatial', 'canada']","Your best bet for up-to-date boundary files at the provincial/state and municipal/county level for the world is the Global Administrative Boundaries Project. Unless you're looking for a specific Canadian/American boundary type (Economic Regions, Special Counties?) this data set should be fine. All data can be downloaded directly through their website.Alternatively, if you're working in R, the 'sp' package fully integrates the GADM data, offering an API-like method for downloading and presenting the data. More info on how to do that can be found in the GIS SE (e.g. https://stackoverflow.com/a/30024321)"
Individual precinct voting data for Pennsylvania,"
I'm currently trying to find voting results by precinct for for Pennsylvania. I know several states such as South Carolina have published voting data from the 2016 General Election. This data can be accessed here. Does Pennsylvania, or any other state for that matter, have anything like this?
","['usa', 'government', 'elections']","You can find County-level voting data on the election site of Townhall.A kind person has done a scrape of the website and made the data available on Github as a CSV and Ipython notebook.2016 County Election ResultsScraping townhall.com for county-level election results from the 2016 presidential general election with Python(my source)The above data source gives a FIPS code for each county. It's sometimes four digit, because the leading 0 is removed when it was converted to an integer, but I think you can map it to the 5 digit codes available from census.govHere's one 1988 mapping from the CDC between Zip+4 codes and FIPS county codes.The County Cross Reference File is a product which provides a
   relationship between ZIP+4 codes and Federal Information
   Processing Standard (FIPS) county codes.  The file allows users
   who have assigned ZIP+4 codes to their address files to obtain
   county data at the ZIP+4 level.(the first 5 digits are the zip code, 00602 is in puerto rico for this example)"
Where is voter data from the recent General Election?,"
I'm looking for the rawest form of voter data available from the U.S. Nov 8, 2016 general election.
The source would both let me explore demographic data around voters based on region, correlate that to other items voted on per-ballot, and explain how Google,etc was able to maintain their live analytics of the election during Election Night.
I found a few other questions that referenced formats elections results could be in, but the actual vote data is still evading me.  I expect different states to behave differently / have different interfaces.  And Open Elections looks like the best historical record I can find, but where are they pulling their data from?
The related question asking specifically for demographic data has some sources, but are far too aggregated and historic for my question.
","['data-request', 'usa', 'demographics']","Many states have posted the data on their election commission websites. The format varies from state to state. To answer your question about Open Elections, they pull their information directly from the state election commission."
USA 2016 election demographic data,"
I am looking for demographic data (age, income, race, location) for individuals who voted in the 2016 US presidential election. The resolution that I am looking for can be at the state, county, or census block level. The data format is not important.
","['data-request', 'usa', 'demographics', 'elections']",
Data on building locations and characteristic in France,"
I am looking for data on French buildings on an address level, e.g. elevation, height, number of floors, square meters, type of building etc.
","['data-request', 'geospatial', 'france']",
Where can I find data that shows USAID development assistance in the Congo?,"
Please show me where the data information is on the website.  
",['usaidopen'],
Is there a data set for all vehicle accidents in USA?,"
Looking for raw data of road traffic accidents, with impact location, make, model, model year, airbag deployment (Y/N)
","['data-request', 'usa', 'government']",
Mimic iii - Are the months of the year accurate to the actual months?,"
According to the Mimic III documentation:

All dates in the database have been shifted to protect patient
  confidentiality. Dates will be internally consistent for the same
  patient, but randomly distributed in the future. Dates of birth which
  occur in the present time are not true dates of birth. Furthermore,
  dates of birth which occur before the year 1900 occur if the patient
  is older than 89. In these cases, the patient’s age at their first
  admission has been fixed to 300.

My question is whether the month/day/time information has been obfuscated as well... ie if the subject's ADMITTIME is stored as 4/11/2172 19:40 - can I reliably say that the actual patient was admitted on April 11th in ""some year"" or has all of that information been shifted as well?
",['mimic-iii'],"The answer is No - you can't extract accurate month, day or year data from MIMIC.De-identification diagram:
The de-identification example actually shows that the month, day and year are all shifted.As @Gary Weissman pointed out in the question comments, the days of the week and ""approximate"" seasonality are preserved in MIMIC II, and MIMIC III follows the same de-identification process.1.4.4 De-identification of patients’ data [...] • The day of the week and season of the year were preserved.The complete information can be found here"
Indian health related data sets from research point of view,"
i want to carry out some analytics in health care field but i am unable to get Indian data set.Does anyone know from where to get the same dataset ?can anyone please help?
",['medical'],
Any open dataset for football stadium coordinates,"
I'm looking for the stadium coordinates of the teams (at least) that have played the Champions Leage. 
I found this one that contains teams from Spain, Germany, England, Scotland and France. I'm looking for the rest of the teams in Europe and Russia. Best case scenario would be from teams all over the world.
","['geospatial', 'football']","Here's a Wikidata query that retrieves the coordinates for a ton of football teams (4866 results at time of writing): https://query.wikidata.org/#SELECT%20%3Fclub%20%3FclubLabel%20%3Fvenue%20%3FvenueLabel%20%3Fcoordinates%0AWHERE%0A%7B%0A%09%3Fclub%20wdt%3AP31%20wd%3AQ476028%20.%0A%09%3Fclub%20wdt%3AP115%20%3Fvenue%20.%0A%09%3Fvenue%20wdt%3AP625%20%3Fcoordinates%20.%0A%09SERVICE%20wikibase%3Alabel%20%7B%20bd%3AserviceParam%20wikibase%3Alanguage%20%22en%22%20%7D%0A%7DThat website includes links to download the query results in just about any format you might want, or you can also access it via an API (which is ideal for keeping this data up to date long term); more info here.For sake of avoiding dead links, here is the SPARQL query:That query searches for all entities that have the ""instance of"" property (P31) set to ""association football club"" (Q476028). It then looks for those clubs to have a ""home venue"" (P115) property, and then looks for that home venue entity to have a ""coordinate location"" (P625) property.You might notice that the current query retrieves every club, even ones in tiny leagues. Most football clubs in major leagues have a ""league"" property (P118), so you could tweak the query to filter to certain leagues if you want."
Open data quality frameworks,"
I'm looking for some kind of lightweight framework for assessing the quality of datasets, as a publisher. The most widely known one is Tim Berners-Lee's ""5 star open data"", but it's actually not very helpful. Virtually all of our datasets would get exactly 3 stars, as linked data is not a priority for us.
What else is there?
","['releasing-data', 'data-format', 'standards', '5-star-scheme']",
How do I recover CIPCODE string values when data was exported to .csv as numbers?,"
I'm trying to download the CIPCODES from file c2015_a.csv, but the csv file shows them as a number rather than a string.  That means the ##.#### formatting is already gone before I can do anything with it.  This results in some majors such as ""16.03"" (East Asian Languages, Literatures, and Linguistics) viewed as the same thing as ""16.0300"" (East Asian Languages, Literatures, and Linguistics, General.).  There are a number of instances where this happens.
It seems to me that there is no way to recover the data I'm looking for and that CIPCODES would need to be exported from the source as a string.  Is this right?
Info I'm looking for came from download for: Awards/degrees conferred by program (6-digit CIP code), award level, race/ethnicity, and gender: July 1, 2014 to June 30, 2015
",['collegescorecard'],
Sexuality and first kissing and kissing questionnaire [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 6 years ago.







                        Improve this question
                    



I would like to know whether there is any honest histogram data on kissing and first experiences. The first question asks for one's perceived physical sexuality, and a separate histogram is generated for each case, so that, say, if someone checks Male, the total of all male-checked questionairres adds to100%. For example:
1)
I am / define myself as, physically

[X] Male
[ ] Female
[X] Both

2)
On my first kiss,

[X] She forced me into a kiss.
[ ] I forced her into a kiss.

3)
In my opinion, the experience was

[X] disgusting
[ ] pleasant

4)
Because

[X] It made me think of my mother kissing my father.
[ ] It made me think of my father kissing my mother.

5)

[X] I thought I was my father in it.
[ ] I thought I was my mother in it.

6)
Nowadays, when I start kissing someone, I would rather think I am

[ ] Male
[X] Female

7)
Nowadays, when I kiss someone, my partner knows my answer to (6.)

[X] Knows it.
[ ] Doesn't know it.
[X] Doesn't care.

8) On my first kiss, the thought of kissing

[X] Scared the shit out of me.
[ ] Was looking forward to it.

9) If I could plan my first kiss ahead, I would rather:

[X] Impersonate the parent I liked the least (prior to separation if applicable).
[ ] Impersonate the parent I like the most (duh).

10) When I kiss, the image of my mate, 

[X] quickly disassociates into that of another (perhaps separate) person
[ ] It takes a while.

11) If my parents saw me do that, (if you don't invite the answer, check the ones you think what the answer could be):
My mother would feel uncomfortable.

[X] Yes
[ ] No
[X] Maybe

My father would feel uncomfortable.

[X] Yes
[ ] No
[X] Maybe

My mother would feel embarassed by the situation..

[X] Yes
[ ] No
[X] Maybe

My father would feel embarrassed by the situation.

[X] Yes
[ ] No
[X] Maybe

My mother would feel gealous of someone taking me away from them.

[X] Yes
[ ] No
[X] Maybe

My father would feel gealous of someone taking me away from them.

[X] Yes
[ ] No
[X] Maybe

My mother would feel envious of what she imagined her part in it.

[X] Yes
[ ] No
[X] Maybe

My father would feel envious of what he imagined his part in it.

[X] Yes
[ ] No
[X] Maybe

My mother would feel like cheating on my father, by copying.

[X] Yes
[ ] No
[X] Maybe

My father would feel like cheating on my mother, by copying.

[X] Yes
[ ] No
[X] Maybe

Thank you for letting me know where I can find a questionnaire of this sort.
",['data-request'],
Extracting P&ID Reference and the drawing number from a PDF Isometric drawing into excel,"
There are more than 8,000 PDF files containing PIPING ISOMETRIC drawings of a process plant. These isometric drawings contain Process and Instrumentation Diagram reference (P&ID). Each file has a unique drawing number. I want to extract this drawing number as as well as the P&ID drawing numbers in an excel file. There is no provision here to attach a sample file but it looks something like this.
P&ID: MD-513-1A00-EG-PR-PID-2035       ;        DWG: MD-513-1A00-ISO-CWR-AA22-0401-23
Can anyone please help. It would save me a lot of time. Thanks in advance
",['pdf'],
How to download GNU makefile for windows to work with MIMIC III [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 6 years ago.







                        Improve this question
                    



How can I download GNU makefile for windows to donwload and intall MIMIC III V1.4 friendly?
",['mimic-iii'],
Database of consumer (food) product ownership,"
I'd like to find a source of corporate ownership information for consumer products, in particular foods. For example products that have labels/brands which are owned by GlaxoSmithKleine, Monsanto, etc.
Does anyone know of something like this?
Edit:

I'd just like the companies that produce brands. For example Dasani is produced by Coke, Pringles are owned by P&G. .
As for the format of the data, anything that I can write a script to read is fine. CSV, XML, JSON, SQL, whatever.

","['data-request', 'food', 'products', 'companies']",
Where can I find dataset for product characteristics and its possible values?,"
The thing is, i need a set of predifined values and characteristics for products, if there will be a category if possible. So I need to have a list of predefined values for my application.
When user will create or edit product, he/she should choose characteristics from ready list of possible characteristics/values/categories. And system will store id's of those characteristics for each product.
Something like:
Characteristic:Color, Value:Red;
Characteristic:Color, Value:Black;
Characteristic:Color, Value:Green;
Characteristic:Material, Value:Metal;
Characteristic:RAM, Value:2GB;
Characteristic:RAM, Value:4GB;
",['data-request'],
Searching for a survey data to perform data analyses,"
I have tried searching on the internet for some survey data (R datasets, datacentral etc) but only came across data set which had only a few observations or had only a few attributes.
I am looking to find a data set which would have a few rating questions and maybe a few open text questions such 'What's going well' and 'What needs improvement'.
Can anyone suggest or share any link where I can find that? I require such a data set only for visualization purposes
",['survey'],
Where can I find historical data for Italian weather (especially for hail storm)?,"
I need historical hailstorm data for Italian cities, day by day since 2014.
I don't mind what format the data is in (csv, xml, etc...). Having a Web API would be great as well.
","['weather', 'historical']",
Geospatial Canadian Socioeconomic Data,"
I've been working with Canadian statistics data and performing geovisualizations of this data joined to census boundary shapefiles.
Most of the data I've been able to join has been at the level of:

Provinces/territories
Health Regions
Census Division (for a not-so-reliable set of Household-level variables; For those familiar with the 2011 National Household Survey, the limitations are jarring)

I'm curious if there are any socioeconomic data tables available through CANISM or other Canadian statistical agencies for variables such as:

Self-reported Quality of Health 
Average Income per capita/household
Educational Attainment
Cost of Living Indicators
etc.

that can be geospatially organized (ie: GIS-formattable) at a very fine resolution (e.g. Census Dissemination Areas/Blocks, Postal Codes, Industry Canada Service Areas)
Update:
I've been able to find the CHASS database (http://dc.chass.utoronto.ca/index.html) which is an intermediary data product compiled from statistical data for all census across geographic regions. This data is only open to researchers at specific Canadian universities.
Does anyone know of a similar project, but openly available to unassociated researchers?
","['data-request', 'geospatial', 'census', 'canada', 'economy']",
mimic-iii question about ICD9,"
I have access to mimic database now, and for my research I need every patient's symptoms like fever, bleeding , .... I would like to know if this information is provided in the database and which table has this information?
In addition, I want to get query from the database to find all the disease that every patient has, So can you please help me if there is any code that I can use?
Also, in ""PATIENTS.csv"" file, I can see a column with DOB name and I supposed that it has the date of birth of every patient, but my problem is that those are like for future for example one of them is 3/13/2075 ! so could you please also help me to find patient's date of birth?
",['mimic-iii'],
Top Active Pharmaceutical Ingredient Sales in US During 2016 (Current Year) Dataset(s)?,"
Seeking open dataset of Top active pharmaceutical ingredient sales/molecules sales data in US during current year.
","['data-request', 'drugs']",
Large datasets with user-reported birthdates (preferably older records),"
I'm looking for some substantial (say >10k entries) datasets which contain birthdates which will have been user-reported, not recorded from or checked against official records.
Ideally, these would be showing data recorded before ~1950, but more recent is also interesting. Other information isn't important (though it would be helpful to know general demographic information about the sample, like ""American women"") and completely anonymised other than birthdate is fine, assuming there's some way to avoid duplication of entries.
For context, I'm looking at mis-reporting/mis-recall of birthdays - hence why self-reporting is important - and so far have worked with British and Canadian WWI service records. We have a fairly good idea of how this data was gathered and can be confident that the majority came through asking the person, and not by looking at ID (which few if any people carried around in this period, anyway).
At a guess, the majority of data from before the mid-20th century would be user-reported (the obvious exceptions are things like birth registrations) but I'm finding it challenging to find large, easily accessible, datasets covering this period.
","['data-request', 'historical', 'demographics']",
San Francisco Housing Data,"
I am a student with the Singapore Management University's postgraduate School of Economics. I am writing to seek your assistance in obtaining certain data on San Francisco’s housing market.
For our Econometrics project - we are looking into running a regression model to predict the housing prices in San Francisco. To do so, we would require datasets of houses in San Francisco city.
I am wondering if it is possible for you to share with us the raw data collected to arrive at these reports. Or others, to point us towards the person and organize we would be able to obtain it from.
We would require 10 years worth of monthly data:

Housing purchase prices in San Francisco
Per sq ft area of houses
Types of houses (house, apartment)
Number of bedrooms
Extra amenities (pool, tennis court)
Quality of neighborhood
Age of house
Size of yard
Location (from city center)

(For example, in Singapore's case, data can be found at data.gov.sg.)
","['data-request', 'prices', 'real-estate']",
Where can I find the number of banks by country?,"
Seeking an open dataset listing the number of banking institutions that exist, and the country/countries they exist in?
","['data-request', 'global', 'bank']",
Popularity of programming libraries,"
There are so many libraries, for instance for C# networking or Java encryption.
I am looking for data about the ""popularity"" of published libraries.
Any measure of ""popularity"" is fine, for instance it could be defined as:

the number of downloads of that library
the number of open source projects using that library
the number of people talking about it
etc

Bonus if the data is easily searchable using a web browser.
","['data-request', 'programming', 'software']",
Drill Core Stratigraphic Data,"
I am a student looking for data for a GIS project to use in modeling subsurface lithology in ArcScene.
Does anyone have any suggestions regarding where I can find spatially-organized stratigraphic data including lithology for bore-holes?
It does not matter what country. As long as I have quality data, I am happy to work with it no matter the source.
","['data-request', 'geospatial', 'environment']",
City boundaries for Europe,"
Is there public data of city boundaries for countries in Europe?
I tried using ArcGIS Online search function but could not find anything.
","['city', 'europe']",
Good web-service based API for getting the latest CME Globex future data,"
We are looking for a good url/json/python based API for getting the latest CME Globex future quotes. We want to run it on command line based Linux server, any suggestions?
","['data-request', 'api']",
Looking for specific Sales Dataset,"
I am relatively new to programming and therefore don't really know where to find specified datasets. What I am basically looking for is Sales Data from any Company (can be made up).
The data needs have coverage of the number of clients, the amount of money they paid and the date for each transaction. I want to predict the worth of each customer with this information, using the RFM-method on R.
","['data-request', 'programming', 'companies', 'analysis']",You can find an example with full R code here: RFM Customer Analysis with R LanguageYou can find the accompanying dataset here: http://brucehardie.com/datasets/
Can I share informations from USA company register?,"
I want to start my own directory website. Can I use informations from SEC.gov | Company Search Page and add to my website? Is it legal?
","['uses-of-open-data', 'business', 'companies']","It most certainly is legal, although I don't see anything directly on the site regarding the specific search data. Most federal data (content for that matter) are automatically open when published by law. SEC's Open Gov Commitment (which actually seems like they stopped trying mid Obama's first term) doesn't name that dataset specifically, but would be safe to assume if the SEC is publishing it, it is fair game."
Seeking free GIS data for USA equivalent to Swedish General Map?,"
In Sweden we have ""Lantmäteriet"" wich is same as ""USGS"".
""Lantmäteriet"" have several datasets like ""Road-map"",""General-map"", etc. These data-sets contains boundaries, roads, landcover, contour-lines, lakes,etc. Se the link and the image on that link, thats how the map looks like when I open it in ArcMap. Its only 1 zip file you download, and that file contains all the layers, polylines, polygons, points.
Link to English information PDF about Swedish ""General-Map"".
https://www.lantmateriet.se/globalassets/kartor-och-geografisk-information/kartor/produktbeskrivningar/eng/e_overshmi.pdf
Does USA have free data-sets that contains the same or similar amount of data as the Swedish General-map and where can I download that data from?
","['data-request', 'usa', 'geospatial']","There are many resources that provide general map resources for the United States.The Census Bureau provides a repository for demographic data and administrative GIS data. In particular, the U.S. Census Bureau releases a series of shapefile data under the TIGER project through their main website and through an FTP directory. TIGER includes administrative boundaries (e.g. states, counties, cities), cartographic boundaries such as shorelines, hydrography within a moderate resolution, roads/highways, and address ranges. This pdf is a good example of how it structures each type of information.The USGS has hydrography, land cover classification, digital elevation models (DEM), and land/water boundaries but at a better resolution. They also contain orthographic satellite imagery on their FTP site. You can find more information here. It may or may not also have LIDAR data.Lastly, the Bureau of Transportation Statistics includes another avenue for transportation networks through the National Transportation Atlas Database.I hope this information was helpful."
Getting 403 Error While Accessing FPPlanQuotes API,"
I'm getting following error while using fpplan quotes api.

RuntimeError: Error requesting quotes from HHS: 403   
  Access Denied  Access Denied
  You don't have permission to access
  ""http://api.finder.healthcare.gov/v3.0/getIFPPlanQuotes""
  on this server.
  Reference #18.3c367c68.1478156165.473be90 
  

I'm accessing this from out of USA., any input will be appreciated.  
EDIT:
getiFPPLanQuotes Healthcare.gov Finder API XML Error - Request is not valid for the schema Screen shot.
This error is being seen from within the USA.

",['healthcare-finder-api'],
"Open/Public Data Sources For Land-Cover/Vegetation Data In The Provinces of British Columbia and Alberta, Canada?","
The title is quite clear: seeking land-cover/vegetation open/public data sources for the Canadian Provinces of British Columbia, and Alberta.
Note:
This question was originally posted in the The Spatial Community - GIS Devs Slack Channel 
","['geospatial', 'canada', 'land']",
Zimbabwe Satelitte Imagery,"
I need a high resolution map of an area in Zimbabwe; Google maps just isn't doing it good enough for me. 
Specifically, I'm seeking 5 areas all within 1 farm. The coordinates are
-17.607872, 30.478440
-17.599700, 30.487746
-17.597962, 30.483809
-17.610236, 30.486348
-17.606459, 30.483873  
","['geospatial', 'africa']",
Minimum wage data via DoL API,"
I am trying to access the following type of info: https://www.dol.gov/whd/minwage/america.htm#Consolidated
through the Dept of Labors API.
Using the method outlined here: Beginners Guide Method
I am able to access all other available datasets aside from the one that sounds like it might have this data: Wage dataset
For instance, when using my generated API Key, this works fine: Working Query
but all of the following fail with a 404:
http://api.dol.gov/V1/WHPS/PublicationsView/?KEY=xxxx
http://api.dol.gov/V1/WHPS/Publications/?KEY=xxxx
http://api.dol.gov/V1/WHPS/DocumentsView/?KEY=xxxx
http://api.dol.gov/V1/WHPS/Documents/?KEY=xxxx 
According to the Wage and Hour Publications System (WHPS) it should work, however the WHPS API URL throws a 404.
",['labor'],
Query OpenFDA by UPC,"
I am trying to query OpenFDA by UPC but the API keeps returning ""No Matched Found"". I assume this works in the same way as product NDC, which is returning as expected when I try something like this:
https://api.fda.gov/drug/label.json?search=product_ndc:%2259779-612%22
When I switch ""product_ndc"" with ""upc"" I get no matching results:
https://api.fda.gov/drug/label.json?search=upc:%22300450449092%22
Am I missing something in the query? Or can the API only handle a subset of UPCs? Thanks in advance for the help!
",['openfda'],
Collecting Real Estate Data in the US,"
I have seem some related questions but none of them seem to have the answer I am looking for. I want to be able to find a website (say like the Multiple Listing Service listings) that would allow me to scrape data from their site about property sales records. In particular, for a given zip code I would like to be able to aggregate purchase histories such as number of houses sold in a particular month and year, and prices (during that month and year) in which the houses sold.  Does a website with this type of data to be collected exist?
","['usa', 'real-estate']",
Parcel map and/or snow load KMZ?,"
I'm looking for two KMZ files that I can import into Google Earth:

which will show me the parcel outlines
will give me local snow load information

I need this information for a few counties in Northern California only.
Does anyone have a suggestion?
","['usa', 'geospatial', 'kml']",
Merging social care expenditure data to NHS trust data,"
I have downloaded social care expenditure from the following website http://content.digital.nhs.uk/article/1165/Search-catalogue?topics=1/Social%20care/Social%20care%20expenditure&sort=Date&size=10&page=1#top
The social care expenditure data are given by councils. I however want to merge this data to NHS Trusts data so that I can determine the level of expenditure on each council or councils in which the NHS trust operates or is located on.
I have tried numerous ways but to no avail. 
Can you please have or have some suggestions on how to perform the merge.  
",['data-format'],
Data on road traffic in Germany [duplicate],"







This question already has answers here:
                                
                            




Data of vehicle traffic

                                (3 answers)
                            

Closed 2 years ago.



I'm looking for road traffic data (e.g. average road traffic by day) or congestion data for German cities or other spatial units (e.g. a certain road or highway).  What would be important to me is, that there is some differentiation by time and spatial units (e.g. by day, week, month in city x or at road y). I'm not interested in highly aggregated figures such as annual averages. Ideally, I would look for (more or less live) data from traffic counts at some fixed points over time.
I know that there are automated counting stations operated by BASt, but I can only find data up to 2018 (and in not very useful format). There is also hourly information by road, but again only until 2018 as of today.
There also is an old question in the forum (from 2016) with a similar topic, but the answer is outdated.
Can anyone point me to some resources?
","['germany', 'traffic']",
Looking for complete sensor datasets from a production process,"
I am working on simulation sensor data for an industrial machine I can choose. For that I am looking for multiple data points from a single process, for example, multiple pressure and temperature curves to use as sort of blueprint. 
My simulation does not focus on accurate simulation but instead on believable sensor data output.
","['data-request', 'machine-learning', 'sensors']","The UCI Machine Learning Repository has a quite large sensor datasetGas sensor array under flow modulationThe data set contains 58 time series acquired from 16 chemical sensors under gas flow modulation conditions. The sensors were exposed to different gaseous binary mixtures of acetone and ethanol.The data set is organized in two 'csv' files, 'rawdata.csv.gz' (4.5 MB) and 'features.csv' (200 kB). The raw data are stored in the first file 'rawdata.csv.gz', where each line represents a single measurement per sensor. Consequently, one needs to read specific 16 consecutive lines to get a single measurement from 16 sensors. The features extracted in (Ziyatdinov et al., 2014) are provided in the second file 'features.csv', where each line represents features extracted from all 16 time-series of the sensors (a single measurement).Additionally, blog post ""Great IoT, Sensor and other Data Sets Repositories"" has 10+ sensor data sets.Many of these modern, sensor-based data sets collected via Internet protocols and various apps and devices, are related to energy, urban planning, healthcare, engineering, weather, and transportation sectors."
Where can I get information on US congress and government?,"
I want to make a website that displays information about the United States Congress and make it easy to understand. As far as I know the US congress has everything recorded and under the public domain including votes, etc. Is there some way to access that automatically without making FOIA requests? I basically am imagining a system where you have a UI of the full seats of congress and you can hover/highlight on live streams of representatives, save information you are interested in, query information, etc. I just am not sure where to get the data at.
",['visualization'],Go through these resources maybe you'll get the data of your interest at any of these--Hope it helps. But in case you need more data and info update me on that. I'll try my best to bring you more data. Cheers! UpdateAPI for Campaign Contributions- Open API
How to publish annual datasets?,"
I work in the open data team for a large city. We have a number of datasets that are produced annually, such as budgets. I'm trying to choose between different options for publishing this data:
Single, expanding dataset
A single dataset called ""budget"" with a year column. I fear that this increases the effort for the consumer, who probably has to filter to get the year they're interested in. Also, sometimes it makes the dataset more complex, as the 2015 budget contains 2014 actual spending, 2015 budgeted spending, 2016 projected spending etc.
One dataset per year
Alternative, we could have ""Budget 2015"", ""Budget 2016"" etc. This creates some logistical challenges, such as the difficulty of automatically creating (as opposed to updating) datasets. Also, it's not clear how you would answer a question like ""Is this dataset updated regularly?""
Both?
Perhaps the right option is a single expanding dataset, with filtered views on it?
Is there any guidance here? Best practice? The platform we're using is Socrata but I'd prefer platform-agnostic advice.
","['time-series', 'publishing']",
Actual text and corrected text? Or autocorrect data?,"
I seek essentially a parallel corpora, which has the dirty original user-generated input on the one side, and a cleaned up version on the other side - with corrected spelling, casing, punctuation and formatting.
So the dirty side should have been composed by human users, and the clean side should have been redacted by human linguists:

'how are you', 'How are you?'
  'is their bad waether?', 'Is there bad
  weather?'
  'As of 2011, it was live.', 'As of 2011, it was live.'

Autocorrect data would also be useful.  It would need totals or proportional statistics which imply the relative probabilities:

'how', 'How', 0.5
  'waether', 'weather', 0.7
  'waether', 'whether, 0.1

(This will then be used to train machines to generate more of the dirty content, given cleanish content, thereby augmenting a text data set.)
","['nlp', 'corpora', 'text']",
Dataset of Japanese company industries and HQ locations?,"
Does there exist a dataset containing information (historical or current) on the following characteristics of Japanese companies?

Industries (e.g. ""electronics"").
Headquarter addresses (e.g. ""3-23-14 Higashi-Ikebukuro, Toshima-Ku, Tokyo, 170-0013""). Latitudes/longitudes would be even better.


The dataset maintained by Aswath Damadaran at Stern seems extensive, but it only includes per-company industries, not HQ addresses.
The Tokyo Stock Exchange listed company search seemed promising, but as far as I can tell, although they provide per-company industries, their provided HQ addresses only specify the city, not the full address.
","['data-request', 'geospatial', 'companies', 'japan']","You can look into opencorporates. They provide a nice api to download data.
Recently they have added database of 4.4 million japan companies.Search for SoftBank  gives"
Satellite imagery dataset containing labels like building footprints or soil type,"
I'm working on a computer vision project involving satellite/aerial imagery, and I'm having trouble finding the kind of labelled data I need. So far, I've come across datasets like:

https://archive.ics.uci.edu/ml/datasets/Statlog+(Landsat+Satellite)
https://aws.amazon.com/public-data-sets/spacenet/
... (can't post more links)

which contain labels like building footprints or soil type. I'm looking for data that's annotated with features like rivers, forests, deserts, lakes, stuff like that. I'm not sure this is out there, but thought I would ask. Thanks!
","['data-request', 'machine-learning', 'aerial-photography']",
Open datasets like the GigaWord for text summarization?,"
The English GigaWord dataset by the Linguistics Dataset Consortium contains some 10 million articles alongside an equally large vocabulary set. It's a lot of organised data. If I had to say it less formally, I'd call it every data scientist's wet dream.
However, it costs a non-member $3000 to obtain. 
You heard me. Three grands.
The CNN and DailyMail data that DeepMind uses here sizes up to some 300,000 articles which is a mere 30% which would reflect by a similar proportion in terms of learning.
Might be a long-shot but are there any large open datasets which could be used for the purpose of text summarization?
","['data-request', 'machine-learning']",
Access to 5m Terrain data for flood modelling,"
I am doing flood modelling for my Parish in Shropshire on a voluntary basis and need high-res elevation data. Terrain 5 from OS would be ideal. Unfortunately I can't get it under the PSMA with OS.
Does anyone know a source of free 5m elevation data. I have tried the Environment Agency Lidar but it's quite noisy and gappy.
Ideas please?
","['data-request', 'geospatial', 'uk']",
Are there any free real estate properties database out there?,"
I'm looking for a nationwide records on properties that have been sold from 2003 to present. Trulia does not have an API anymore and Zillow's is very limited. 
","['api', 'real-estate', 'database']",
HealthCare Finder API Version 2 and 3 Functionality Differences [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 5 years ago.







                        Improve this question
                    



Our application currently point to http://api.finder.healthcare.gov/v2.0/. This website no longer working. Looks like there is a new URL available https://finder.healthcare.gov/#services/version_3_0. 
Where can we find the functionality changes between the 2 versions? Is there any documentation that can help us to quickly do the analysis? 
","['api', 'healthcare-finder-api']",
Labeled data: two concentric circles i.e. a cluster encircled by different clusters,"
For my theoretical work, I have generated synthetic data where a single cluster is completely encircled by other clusters, in 2D the data set has the form (roughly) as in the picture below:

I am looking for some real data that have a similar characteristic, dimensionality is not of importance (for visualization I can use PCA and project to 3D).
I have looked through most of the data sets in UCI and randomly searched on the internet but could not find what I am looking for...
Intuitively I would expect that many rich data sets should have this layout, that is one cluster of similar objects and all the rest of the data which is a noise in which the cluster is immersed.
I would appreciate it if someone could point me out which data usually has this layout (medical data, econometrics, imaging, geospatial data) any other suggestions would be very appreciated!
","['data-request', 'geospatial', 'medical', 'machine-learning', 'finance']",
Where to get archive tweets? [duplicate],"







This question already has an answer here:
                                
                            




Where can I find data set of tweets of users? [duplicate]

                                (1 answer)
                            

Closed 6 years ago.



I want some old tweets on mobile device to proceed in my research. Tweets should contain any mobile device name or handle. Where can I get old tweets?
","['data-request', 'api', 'social-media']",
How can I obtain public transport data for Hong Kong / Shenzhen?,"
I am going to develop an offline transport mobile app around my region (Hong Kong / Shenzhen) but I cannot find any GTFS (General Transit Feed Specification) data available on the web. How can I obtain a set, or generate one myself by using other open data?
","['data-request', 'transportation']",
To fetch bigger dataset from twitter,"
I need twitter data for my project, but with streaming api I am able to get only 15 min window frame.Hence a very smaller sample space.
I have a written code in python as follows  
import tweep
from tweepy import OAuthHandler
from tweepy import Stream
from tweepy.streaming import StreamListener

consumer_key = ""T---------------------------------------f""
consumer_secret = ""N-------------------------------------------d""
access_key = ""3-------------------------------------------------------u""
access_secret = ""M-----------------------------------------X""

# authorize
auth = OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_key, access_secret)
api = tweepy.API(auth)

# get streaming tweets by hashtag
hashtag = '#madebygoogle'
class MyListener(StreamListener):
     def on_data(self, data):
        try:
            print data
            return True
        except BaseException as e:
            print('Error on_data: %s' % str(e))
        return True
    def on_error(self, status):
        print(status)
        return True

twitter_stream = Stream(auth, MyListener())
twitter_stream.filter(track=[hashtag])  

How can I increase the rate of tweets??
","['uses-of-open-data', 'social-media', 'python']",
What encoding does the Census use in TIGER data?,"
What encoding does the Census distribute TIGER data in? The example on page 88 of PostGIS in Action, Second Edition seems to indicate latin1.
shp2pgsql -s 4269 -g geom_4269 -I -W ""latin1""
➥ ""tl_2012_states"" staging.tl_2012_states |
➥ psql -h localhost -p 5432 -d postgis_in_action -U postgres

",['census'],"According to this FAQ entry,Were all delivered in ISO-8859-1 (latin1), andWhile 2015 and later is UTF-8.  Note:
*: This data and all future dates"
API for 1990 Census geographies,"
TIGERweb provides an API for the 2000, 2010, 2013, 2014, and 2015 US Census geographies. Does the Census (or someone else) provide an equivalent API for the 1990 geographies anywhere?
","['api', 'us-census']",
Open Data for software options,"
I need a dataset of the following:

user's software options for a particular software (e.g., whether to start the software with system) with 
user's information (like user's system information, demographics). 

The purpose is given a new user, based on the user's information, I can recommend them appropriate software options.
Is there any of such dataset?
","['data-request', 'uses-of-open-data']",
What format is NASAs JPL Data Dictionary written in?,"
The Jet Propulsion Lab Data Dictionary which describes planetary data is written in some obsure format, and I'd like to know if there is an easy way to parse it.
https://pds.jpl.nasa.gov/tools/dictionary.shtml
Below is an example of the output:
OBJECT = GENERIC_OBJECT_DEFINITION
  NAME = BAND_BIN
  STATUS_TYPE = APPROVED
  DESCRIPTION = ""
     The BAND_BIN group provides a mechanism for grouping keywords that
     describe the properties of each 'bin' along a spectral axis.  It is
     primarily designed for use within the SPECTRAL_QUBE object.""
  REQUIRED_ELEMENT_SET = {
     BAND_BIN_CENTER,
     BAND_BIN_UNIT,
     BAND_BIN_WIDTH,
     BANDS}
  OPTIONAL_ELEMENT_SET = {
     BAND_BIN_BAND_NUMBER,
     BAND_BIN_BASE,
     BAND_BIN_DETECTOR,
     BAND_BIN_FILTER_NUMBER,
     BAND_BIN_GRATING_POSITION,
     BAND_BIN_MULTIPLIER,
     BAND_BIN_ORIGINAL_BAND,
     BAND_BIN_STANDARD_DEVIATION}
OBJECT_TYPE = GENERIC_GROUP
END_OBJECT = GENERIC_OBJECT_DEFINITION
END 

As you can see it is certainly not JSON, XML, HTML, Markup/Markdown, etc... which rules out most plaintext data formats. Any tips would be helpful.
","['government', 'space']",
Endpoint not returning expected data based on NDC package code,"
I recently stumbled upon openFDA and it seems to be the perfect answer for relaying drug brand name information to our users based on a provided NDC code.  The issue I am running into however is that majority of the searches I am doing keep turning up with ""No matches found!"".  For instance when using NDC 10135-150-01 (ASPIRIN 325MG TAB) in my query it comes up with nothing.  Here is my query (going off of the example demo on the openFDA site):
https://api.fda.gov/drug/label.json?search=package_ndc:""10135-150-01""&limit=1

I believe the above query is correct because I have gotten it to work with other NDC package codes, and I believe the codes are true codes because they come up when googled, so this leads me to believe that either the package_ndc codes stored don't include every package code, or there is possibly only base codes of some sort stored?  I'm obviously not an expert in the coding system, so if anyone can point out anything obvious it would be much appreciated!
",['openfda'],"openFDA has only the NDC codes that are in the National Drug Code Directory. This particular one -- ""10135-150-01"" -- isn't there, which is why you are getting no results back."
"Publishing (structured?) data about products: information about products, barcodes, photos (incl. packaging)","
Is it legal to publish photos of products and their packaging?
Can such be done anonymously on some open license? (which would be the best for such data to be open for public use, as products are generally available to see in shops for everyone?)
Where and how to publish?
Is Wikidata+Wikimedia right place?
I am thinking on (structured) data, that includes:

packaging photo
product photo
derived information


barcode(s) (EAN)
ingredients
weight, nutrition, etc.


What information requires publishers to be careful regarding sharing (e.g. prices in given shops)?
Update:
Thanks to insight from one of the answers the topic of ""copyrighted materials"" or ""trademarks"" on packages was pointed out. Fair concern.
Therefore, let me frame question in direction of purpose, so additional questions, requirements:

what additional steps would make such collection feasible? (something that scales and is feasible for crowdsource preferably, e.g. ""blurring out""/""black out"" parts of images with products logos ? Converting to ""black&white""? (unless product owner comes and gives permission by him/her self)?)
goal is to collect most ""data"" about product: barcode, ingredients, dietary information, amount of contents (ml,pieces,grams), plus eventually approvals from organizations.


imagine use case: you want to find set of products that compose into desired meal, but need to take care of allergies, diabetics and other constraints. Such db when cross across shops in (or webshop delivering to) your area, could provide valuable suggestions!


","['releasing-data', 'wikidata', 'wikimedia-commons']",
Dataset for reapeated measures,"
I need data sets to apply a study based on repeated measures. I need of hints to find open data of nature that be possible to publish in scientific journals.
","['data-request', 'data.gov']",
How can I leverage machine learning in my Business Intelligence/Data warehouse? Request [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 6 years ago.







                        Improve this question
                    



I work in a Datawarehousing environment where we host a rich collections of data from different systems and have probably the most holistic view of the dataset across our organization. Some of them are our Marketing, Revenue, sales, opportunity, Employee, traffic etc. We are basically an internet company providing state-of-the-art technology to the industry. I am more interested in my contribution to the company by leveraging my knowledge and access to the data
","['machine-learning', 'ai']",
Monthly/Daily UK Rainfall Data,"
Do you know where I could find UK monthly rainfall data for as many gauges as possible? I am interested in the rainfall daily sum, within one month.
I found this: 
https://data.gov.uk/dataset/historic-monthly-meteorological-station-data
but there are only 37 gauges. Do people know of any resource for the same data but for more gauges?
","['data-request', 'uk', 'climate']",
On Exchange plans mixed in with Off Exchange plans,"
I ran individual quote from finder.healthcare.gov (zip: 23513, dob: 02/03/1982, Male, No-Tobacco) and the results are showing On Exchange plans mixed in with Off exchange plans (E.g. Anthem HealthKeepers Bronze X 4900 for HSA - is On Market plan, and Anthem HealthKeepers Bronze 4900 for HSA - is Off Market plan). How do I tell which plan is On Exchange, which plan is Off Exchange? I thought finder.healthcare.gov is supposed to show only Off Exchange plans. 
",['data-request'],
A dataset with ~10 million rows,"
I am looking for a dataset with 10 millions of rows to analyze it. Actually to rework it into more usable format and come up with some interesting metrics for it. So there are two requirements:
1) ~10 million rows
2) ""Interesting"" data to build some metrics on it (like users per country, average temperature in month, average check and so on).
So the question is: where can I find such dataset? I found awesome-public-datasets repo on Github but looks like there is no any classification by data size/format there. If you have any ideas about relevant datasets and where I can find it it would be great.
","['data-request', 'data-format']","City bike shares will have about that number of records, and because there will be some geospatial data (latitude/longitude) along with timestamps, it's usually a fun topic to exploreGitHub list of city bike share dataWashington DC (Capital Bikeshare) has quite a large bike share systemCapital Bikeshare CSV Column DescriptionsRaw data for Capital Bikeshare (by my estimate, 1 MB zipped is about 100k rows of CSV)Duration - Duration of tripStart date – Includes start date and timeEnd date – Includes end date and timeStart station – Includes starting station name and numberEnd station – Includes ending station name and numberBike # - Includes ID number of bike used for the tripMember Type – Lists whether user was a Registered (annual or monthly) or
Casual (1 to 5 day) member.(photo source Wikipedia)"
Where can I get maven central updates?,"
Is there a service/feed I can subscribe to that produces new maven central groupId's, artifact's, and versions?
I don't want to scrape maven central periodically. It's too big. I just want to know what was updated when it's updated.
",['data-request'],
How might I go about linking databases of business records to ratings data (such as yelp or google places)?,"
Given a large database of business names and addresses, how might I go about pulling ratings for those entities from other accessible online data sources OR from the BBB, Yelp, or Google Places?
","['data-request', 'api', 'uses-of-open-data']",
How do I read these IRS SOI Tables for Individual Income?,"
Has anyone worked with the IRS SOI Tables for Individuals?
I am doing research on income distribution, and while these resources in particular the series: All Returns:  Sources of Income, Adjustments Deductions and Exemptions, and Tax Items looks good, I can't find much support explaining the breakdown for the items.
My particular interest is in Table 1.4 the 2012 table for Sources of Income. Inside is a breakdown of income ranges, individual types of income, types of deductions, and net gains/losses. I am interested in knowing the breakdown for Adjusted gross income less deficit (Item 2, Column C) and the breakdown for Total income (Item 4, Column E).
If I am reading this document correctly, some combination of Columns F through EG by addition/subtraction should equal the Total Income and Adjusted Gross Income for each row (within a margin of rounding error). Does anyone know which items I should be using?
Sidenote: The reason I am choosing the year 2012 is because it coincides with the observed year for the 2013 Survey of Consumer Finances. I want to compare the source of income by income level between surveys such as the SCF, CPS ASEC, ACS, and others with administrative data such as these IRS SOI tables.
","['usa', 'income', 'irs']",
Czech republic population income dataset [closed],"







Closed. This question needs to be more focused. It is not currently accepting answers.
                                
                            











Want to improve this question? Update the question so it focuses on one problem only by editing this post.


Closed 6 years ago.







                        Improve this question
                    



I have to collect stastics on:

Population income by region of Czech Republic 
Crime data 
Real estate prices

I tried opendata.cz but they don't provide these data.
Perhaps there is an EU data portal where this kind of data might reside.
","['europe', 'income']",
Looking for data on Eastern European scientists working in Western Europe,"
I would like to have statistics on Eastern European scientists working in Western Europe. 
I have found some related papers like Brain Drain in the European Union: Facts & Figures or Emigration from Eastern Europe with a Focus on Brain Drain but these do not contain data material for knowing how many scientists move from Eastern Europe to Western Europe.
Could you help me finding a reliable data source on this?
","['data-request', 'migration']","The German Federal Statistics Office was so kind to provide me data on the issue in Germany:https://www.destatis.de/DE/Publikationen/Thematisch/BildungForschungKultur/Hochschulen/PersonalHochschulen.htmlOn page 190, you will find the table13 Wissenschaftliches und künstlerisches Personal nach Herkunftsländern und Fächergruppen der fachlichen Zugehörigkeit that is, scientific and art personnel according to their original country and per job area."
River rapids list and coordinates,"
Are there any sources of spatial information about river rapids worldwide (with difficulty category)?
","['data-request', 'geospatial', 'global']",
Dataset/database for the evolution of world's political entities (countries) along the years?,"
What would be the most accurate or complete source of data about the boundaries of states or other political entities, at different times in human history ?
(In order to represent how the boundaries evolved along those years.)
",['geospatial'],
Where can I find machine readable transcribed text of the 2016 Presidential speeches and debates?,"
I'm looking for a machine-readable repository of transcribed Presidential debates and speeches from the 2016 general election. Structured data with a common format is desirable, as well as updates for the remaining speeches before the election.
","['data-request', 'usa', 'government', 'nlp', 'politics']",Text from the speeches are available at the UCSB Presidency websiteText from the debates available as well.
"How strictly are ""universal design"" standards enforced in open data?","
""Universal design""is a U.S. government standard that forces items, in this case metadata, to be accessible to people with disabilities.
Apparently universal design standards were promulgated some years ago (2011?), but aren't in yet in followed everywhere, even today.
Why is that? How strictly are universal design standards enforced in and outside of open data? Could it be the case that they are, in fact, enforced across open data, and the issue exists only outside the open data system?
","['usa', 'best-practice']",u.s. government doesn't even enforce section 508. universal design is just another idea to them. i have yet to see anyone doing it or enforcing it. 
UK Weather Data Service,"
I'm looking for an online data set which can provide present UK-wide average temperatures, rain likelihoods, humidity levels and other meteorological data.
Is anyone aware of an API/flat table data source that can provide this information?
","['api', 'weather', 'uk']","A major resource for grabbing live weather data is through the OpenWeatherMap API. The free plan offers up to 60 calls per second and access to present and 5-day forecast for individual locations, as well as weather map layers (temperature, precipitation, etc.) that can be integrated with Leaflet, OpenLayers and other WMS systems for regional representations. For personal use, the free plan should be sufficient for your needs."
"What does a ""null"" result mean in the Census ACS API?","
There are ACS 5 variables that are available at the tract level, but return null at the block group level. For example, median monthly housing costs:
http://api.census.gov/data/2014/acs5/?get=B25105_001E&for=tract:*&in=state:17%20county:001
http://api.census.gov/data/2014/acs5/?get=B25105_001E&for=block%20group:*&in=state:17%20county:001%20tract:00100
What does a null value signify? Is it that the variable is never available at the block group level, or just for some/most of the block groups?
","['api', 'us-census']","A null result means that the variable has been suppressed for that geography. Some variables are always suppressed for a certain level of geometry, but even if a variable is usually available for a level of geometry, it may still be suppressed for a particular geometry because of:"
Wikidata: QueryTimeoutException: Query deadline is expired,"
I used to execute successfully the following query:
SELECT (COUNT(?r) AS ?count) WHERE { [] <http://www.wikidata.org/prop/direct/P31> ?r }

on http://wdqs-beta.wmflabs.org/bigdata/namespace/wdq/sparql
However, now this endpoint has been stopped, and when I execute the same query on official wikidata endpoint service: https://query.wikidata.org I get the following error:

java.util.concurrent.ExecutionException: java.util.concurrent.ExecutionException: org.openrdf.query.QueryInterruptedException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.bigdata.bop.engine.QueryTimeoutException: Query deadline is expired.

This means that the query has exceeded the limit time.
Is there a way to expand executing time, or is there another SPARQL endpoint that allows me to execute the query?
","['wikidata', 'sparql']","The following query is almost instant (try it):In general, one have to download a dump and use it for such queries.Another option is to use special reports (you should be especially interested in this one):Additionally, property usage statistics is available on the Property discussion page.UpdateHackish way: https://query.wikidata.org/sparql?ESTCARD&p=<http://www.wikidata.org/prop/direct/P31>"
multivariate competing risks failure-time data set,"
I'm looking for a failure-time (survival analysis) data set 
which is
- Multivariate or clustered 
(Multiple individuals are observed in one sampling unit. For example, family members in a family)
- Competing risks
(There are multiple failure causes, for example, death from breast cancer and breast from lung cancer)
Is there such a data set?
",['uses-of-open-data'],
Geometries for census tracts in 2012 and 2013 ACS 5 Releases,"
The Census API provides ACS 5 data for 2011 and 2012 (along with more recent years).
The Census's TIGERweb services provides census tract geometries for the 2013 ACS release and the 2010 Decennial Census. 
Are the census tracts used in the 2011 ACS and 2012 ACS the same as either the 2010 or 2013 geometries? If not, is there a web service that provides the 2011 and 2012 geometries?
","['api', 'us-census']","According to the Census website, for both the 2012 and 2011 Estimate Year, Census Tract uses the 2010 Census (https://www.census.gov/programs-surveys/acs/geography-acs/geography-boundaries-by-year.2012.html and https://www.census.gov/programs-surveys/acs/geography-acs/geography-boundaries-by-year.2011.html)"
Where can I find subtitled recordings of university courses?,"
I'm doing a research on the language used by university professors and I'm looking for closed captioned videos from real university classes.
","['data-request', 'language', 'education']","Any video on YouTube that has captions can be used, although you'll (probably) have to find a way to avoid auto-generated captions.For example, from MIT (with friendly CC license). You can use open source tool GoogleSRT or similar to download captions from YouTube.See here for more details."
What standards are available for classifying Organizations and Businesses?,"
I'm looking to create directory and I would like to know what standards are available for classifying businesses, professions, and organizations?
","['standards', 'classification']",
"What open access journals are there in the fields of psychology, neuroscience, behaviour, etc.?","
What open access journals are there in the fields of psychology, neuroscience, and behaviour?
",['publications'],"Here's a list of Open Access (OA) directories, journals, and repositories you can scour through.   Note: Be selective in your choices, as OA is ripe with Open Washing; Virginia Tech has a good break down in the differences between real OA Journals vs. Open Washing OA Journals.   87k+ Results for 'Psychology' - DOAJ
Medicine & Health Sciences Open Access Journals - Open Science Online
Results Under 'Neurophysiology and neuropsychology' - Open Science Directory
Results Under 'Psychology' - Open Science DirectoryDOAJ (Directory of Open Access Journals)
List of Open Access Journals - Wikipedia
SPARC (the Scholarly Publishing and Academic Resources Coalition) is a global coalition committed to making Open the default for research and education.
You should certainly join and ask the SPARC OA Forum
OKF Open Science Working Group
OKF Open Access Working Group
PLOS (Public Library of Science) publishes many publications, including a suite of Open Access journals - PLOS Journals
OAD (Open Access Directory) is a compendium of simple factual lists about open access (OA) to science and scholarship, maintained by the OA community at larg
Search OAD Categories, and/or Search OAD Articles.
OpenDOAR - The Directory of Open Access Repositories is an authoritative directory of open access repositories, each visited by project staff to check/verify information that is recorded there. OpenDOAR's in-depth approach does not rely on automated analysis and gives a quality-controlled list of repositories.
ROAR - Registry of Open Access Repositories
Open Access Journals - International Association for Media and Communication Research
OAJSE - Open Access Journals Search Engine (Excluding India) "
Wikipedia: How to activate email notification from watchlist?,"
I may have a blackout on this, so please help.
I have a wikipedia account with a confirmed email. I have checked the box ""Email me when a page or file on my watchlist is changed"".
I have two pages on my watchlist:
1. a page I edited
2. my sandbox page
I have visited my sandbox page several times and edited it. But I have not received any notification emails.
What did I do wrong?
This is one instruction that I believe I have followed:

*If your Preferences has ""Email me when a page or file on my watchlist is changed"" set, then only by visiting a page will you actually set
  its email notification flag.
Once you miss the email for a particular page change or don't visit
  the page (or ignore the email), you will not receive any more emails
  for that page. You can still dutifully monitor that page by its
  watchlist edit-summaries, but its particular email notification flag
  will remain unset until you visit it. This facilitates monitoring a
  large watchlist while preventing potentially useless emails to you.*

","['wikipedia', 'email']","I haven't tried the mail feature, but I think MediaWiki notifies you when somebody else edits the page. There is no reason to send you a mail when you edit the page yourself - you should already know that you have edited it.If you want to make sure that it works, you can try adding an often edited page and check if you are getting mail daily - for example, articles on the present and previous presidents of the United States could make a good benchmarks these days, because they are getting a lot of editions a day."
Processing Times [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 6 years ago.







                        Improve this question
                    



Are Processing Times accessible via your API?
https://icert.doleta.gov/#fragment-2
",['labor'],
Up-to-date Global Lake Information and Data,"
Are there any sources of up to date information about world lakes? 
I'm interested in both spatial (not necessarily in great detail) and basic non-spatial (such as lake area, volume and maximum depth) information.
The key point is last update time. I've already considered Natural Earth Data and Global Lakes and Wetlands Database. HydroLAKES dataset is next in line (when it will be released). And I've noticed that, for example, the information about the Aral sea is quite old and different from source to source (both about its contour and area value).
Which of these sources (or maybe some alternative) provides the most reliable data and information at the global level?
","['data-request', 'geospatial', 'global', 'environment']","I did a little searching around and came across another dataset that's relatively new (2014) and might be forthcoming soon:GLOWABO - Global Water Bodies databaseThe study used remote sensing and water body extraction techniques [GWEM] to count and categorize the world's lakes, circa 2000. Some new agencies that reported on it mentioned that the data would be released openly. It might be worthwhile to contact the lead researcher, Dr. Charles Verpoorter, to see if they've started hosting the data.Beyond that, I would suggest that the HydroLAKES project might be the most likely candidate for performing analyses on water bodies at the global level. The major value from a continuous data set is that at the very least you can expect a degree of consistency between areas/regions/continents.Data collection for more recent estimates of water body numbers and extents is difficult to perform at the global level, but if you're looking for specific lakes, you could always perform pansharpening and comparative analyses on remotely sensed LandSat 7/8 Data yourself. Hope this helps."
UK Open Retail Locations Data [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 6 years ago.







                        Improve this question
                    



We just released an open dataset for UK retail locations. We are working on getting this into Open Street Map in the future but for now we will release GIS files and tables. There is some more information on our blog. Feel free to use and share the data.
http://blog.geolytix.net/2016/10/19/retail-points-update/
",['geospatial'],
Is Wikidata up to date with Wikipedia?,"
I think that DBpedia links to Wikipedia by Wikipedia database dump, making it not up to date with on-line Wikipedia contents.
I was wondering if Wikidata uses on-line Wikipedia content or if it also works on Wikipedia dump?
","['wikidata', 'wikipedia']","The dependency is supposed to be the opposite, i.e. that Wikipedia should rely on data in Wikidata. This is however not fully implemented yet. If you look at the infobox on this cheese in French, all data comes from Wikidata, but not in English (yet). We are far from full implementation, so expect to see any combination of people pulling data from Wikipedia to Wikidata or the opposite in any article."
Data set of automobile performance,"
Is there an open data set of car performance? By year, manufacturer and model? I'm looking for all kinds of measurements such as 0-60 time, engine displacement, mpg, 1/4 mile time, 60-0, etc.
In the absence of an open set, I may contact publications like Motor Trend or Road & Track to see if they have a table they can share.
",['cars'],
Cars Registered in London and Paris Last Century (1900-1940),"
I need a few statistics for a school project, about the number of cars registered in Paris and London during 1900-1940. Any year between 1910, 1920, and 1930 would be extremely helpful.
",['transportation'],
Official Help and Support on customising CKAN,"
Please, anyone knows how or where can I get quick support for issues I'm having with CKAN? I work for Argentinian Government and I'm in charge of launching a Open Data Portal for all the country Justice system. I have CKAN running and mostly all information uploaded but for some Datasets and Resources I'm having weird and strange issues that I couldn't track on any site after extensive google searches. Any information of where I can have fast answers and support I will be very grateful. Thanks all.
",['ckan'],
European roads toll cost,"
I'm looking for a dataset or an API that provides information about toll costs of european roads.
Something similar to ViaMichelin, that is what we are using now, but preferably free of charge.
Does somebody know some free dataset with this information?
I was thinking in OSM, but I do not know if offers this information.
Thanks
","['geospatial', 'cost']",
Open dataset containing distance between states in the USA,"
We use the GeoDist database from CEPII for distances between countries around the world.
However, doing proper GeoIP load balancing between states in USA, there's a lot of sites offering this functionality, but it does not seem to be an actual database with that information.
Is there an open dataset that contain information like distance between states? If not, is there a good reason that one needs to API one of these sites that have the data?
","['data-request', 'usa', 'geospatial', 'api']","Often it doesn't make sense to store (database) and share (API) data that can be easily reproduced, especially when everyone has slightly different requirements. In your case, to calculate the distance between the US capital cities, you can calculate it with a small piece of code, by reading in an array of capital cities latitude and longitude, and then calculating the distance. Here's an example using Python's geopy library (calculating distance between to points on a sphere is not trivial, details).Returns: 4525.33307066 (kilometers)Since there are only 50, you can either manually create a list of US capital city geo-coordinates, or find something prepared online.US 1000 largest cities (JSON)GIS discussion on the topicSome random website (hint, see HTML source, which is easily parsed)"
Is there a way to access Microsoft Academic data set listed on Microsoft DataMarket?,"
The data set is listed here: https://datamarket.azure.com/dataset/mrc/microsoftacademic
It supports the Open Data Protocol. However, when I access it on Chrome, e.g., with https://api.datamarket.azure.com/Data.ashx/MRC/MicrosoftAcademic/v2/Domain?$top=2, the result is: 
<m:error xmlns:m=""http://schemas.microsoft.com/ado/2007/08/dataservices/metadata"">
<m:code/>
<m:message xml:lang=""en-US"">
We are currently experiencing problems with the backend database. If you continue to receive this error, please contact us (https://datamarket.azure.com/support).
 We appreciate your patience and will continue to improve the product based on your feedback. -- Reference #: 36dd1702-5a3e-483f-a3a6-35347222af36
</m:message>
</m:error>

Here is the returned result on IE 8:
  <?xml version=""1.0"" encoding=""utf-8"" ?> 
- <m:error xmlns:m=""http://schemas.microsoft.com/ado/2007/08/dataservices/metadata"">
  <m:code /> 
  <m:message xml:lang=""en-US"">We are currently experiencing problems with the backend database. If you continue to receive this error, please contact us (https://datamarket.azure.com/support). We appreciate your patience and will continue to improve the product based on your feedback. -- Reference #: 356e0d00-ef73-4c9e-9e01-3e6854a5fe2f</m:message> 
  </m:error> 

Did I do something wrong? Or the data set is just faulty?
","['data-request', 'api', 'odata']",
Matching 1980s address data to 1990 census geoid10?,"
I am hoping to match a list a addresses gathered in the mid 1980s with block group codes from the 1990 census. The geocoder on the census website processes this for 2010 block group designations only. Are there any other utilities or programs that can do this? I plan to do most the data processing in R if there are perhaps any packages that can help with this.
","['us-census', 'census', 'programming']",
Speed Limit Data For ArcGIS: Metro Atlanta Region,"
Working on a project to determine the speed limits of every road network within Metro Atlanta's boundary. I have GDOT RC data, Navteq/HERE data, ABM data made in-house, and Open Street Maps. These all differ a bit. Where can I find, or pull, the data to get closer to the completion of my project?
","['geospatial', 'transportation']","You need to define a hierarchy of speed limits. The NavTeq/Here data will include all roadway databases; starting with this, then you can spatially join the data to the base network you create.The key will be determining which database you ""trust"" more. "
Climate change projections for Europe/Germany,"
I am searching for climate projection data with the following criteria:

covering Western/Central Europe (especially Germany), gridded data would be ideal
monthly or at least seasonal (3-months) resolution
temperature and precipitation
covering the next 30-50 years
from a reputable source (and OK to use for academic/scientific purpose)

Can you recommend a datasets that meets these criteria?
","['geospatial', 'europe', 'germany', 'environment', 'climate']","If you're looking specifically for a small region in the European interior, you're going to need model simulations at the regional scale. For that I'd suggest checking out the CCAFS Downscaled Climate Change data portal: http://www.ccafs-climate.org/data/The data offered there are 30-year monthly normalizations of most every AR4 and AR5 climate models and scenarios (SRESs and RCPs) for the 2030's, 2050's and 2070's. They also have the historical period data available at the same scales so you can perform present-day comparisons with future periods to identify climate anomalies and areas where changes may be more drastic. The license agreement allows academic/non-commercial use as well.You can download realizations by tile but be warned that the data storage needed is considerable, especially if you want to calculate model ensemble averages. If you're going that route, you might want to consider only using the models with the highest validation statistics representing each cluster. For more info: http://onlinelibrary.wiley.com/doi/10.1002/grl.50256/abstract"
Spatial Data for Srilanka & Bangladesh,"
I am working on a mapping project and would like to map Srilanka and Bangladesh. I downloaded data from OpenStreetMap but the level of detail, particularly for POIs, leaves a lot to be desired (There are only around 18k POIs for Srilanka and 12k POIs for Bangladesh).
So I am looking for alternate sources of spatial data (POIs in particular) for Srilanka and Bangladesh. 
I don't mind paying for the datasets as long as they are comprehensive and of good quality
Google has a lot more POIs than osm,
Google Maps:

OSM:

","['data-request', 'geospatial']",
Traffic camera datasets,"
I'm searching dataset with photos of front cars, like speed camera photos.
Standford dataset is interesting, but too good quality, not from traffic cameras.
Who knows where to find such?
","['transportation', 'images']","Open Data Ottawa's data portal has this data:
Traffic Web Cam Images Dataset
""Provides images for the City of Ottawa's traffic web cams. These images are available at sixty second intervals. To access the images users will be required to have an access key.""  Application form for access keys
Caltech Has Two Car Datasets and One Motorcycles Dataset
MIT CBCL Card Database #1
UIUC Image Database for Car Detection Computer Vision Datasets
CVonline: Image Databases "
satellite imagery data for crop identification,"
I'm working on a project to identify crop and do yield analysis using satellite imagery. can someone please guide me, where can i get this dataset?
","['data-request', 'geospatial', 'images', 'agriculture']","USDA has a vast ecosystem that can be tapped into for this kind of imagery.  CropScape hosts a geospatial data product called the Cropland Data Layer (CDL). The CDL is a raster, geo-referenced, crop-specific land cover data layer created annually for the continental United States using moderate resolution satellite imagery and extensive agricultural ground truth. All historical CDL products are available for use and free for download through CropScape.
USDA FSA Satellite Imagery Resources (PDF)  VegScape delivers interactive vegetation indices so that web users can explore, visualize, query, and disseminate current vegetative cover maps and data without the need for specialized expertise, software, or high end computers. New satellite-based data are loaded on a weekly basis during the growing season. One can compare year-to-year change since the year 2000, compare conditions at a given times to mean, median and ratio vegetative cover, and can overlay a crop mask to help identify crop land versus non-crop land, among many functions. Vegetation indices, such as the NDVI (Normalized Difference Vegetation Index), and mean, median, and ratio comparisons to prior years have proven useful for assessing crop condition and identifying the land area impacted by floods, drought, major weather anomalies, and vulnerabilities of early/late season crops. The National Aeronautics Space Administration's MODIS satellite is used for this project and provides imaging at 250 meter (15 acres) per pixel resolution. Additionally, the data can be directly exported to Google Earth for mashups or delivered to other applications via web services.  NAIP acquires aerial imagery during the agricultural growing seasons in the continental U.S. A primary goal of the NAIP program is to make digital ortho photography available to governmental agencies and the public within a year of acquisition.   USDA Census of Agriculture
NASS - National Agricultural Statistics Service
Aerial Photography - USDA Farm Service Agency USDA FSA says ""access is for subscribers only""; not sure if that requires payment (meaning its not open data) or not.
Global Crop Production Analysis - USDA FAS Satellite Imagery Archive Ag Census Web Maps
Details Regarding How the Ag Atlas, part of the Ag Census, Creates its Maps
NASS Data Visualization"
Sports Clubs & Facilities,"
I want to create a website with which people can easily find sports clubs or facilities in their area.
I basically need a list/database of all sports clubs and facilities in the world. If there is only data available from certain regions/cities, these would be useful as well.
Data should preferably include:

Address or Latitude + Longitude
Sport (e.g. Tennis)
Name of club / facility

(additional data such as email,website,phone etc. would be welcomed)
Thank you for your help.
PS: If anybody is interested in helping actively please contact me
","['data-request', 'uses-of-open-data', 'sports', 'geocoding']",
Percentage of radio stations that are terrestrial stations versus Internet stations,"
What are the percentages of radio stations which provide:

terrestrial radio station only
Internet radio station
both

I am looking into this data by year and world country. Thank you for your pointers.
","['data-request', 'wikidata']",
What is the difference between Census TIGER and Gazetteer data?,"
The US Census currently distributes two zips for ZIP Code Tabulation Areas (ZCTA) data with 33,114 features,

Gazetteer ZCTA (59M)
http://www2.census.gov/geo/tiger/GENZ2016/shp/cb_2015_us_zcta510_500k.zip

TIGER ZCTA (502M)
http://www2.census.gov/geo/tiger/TIGER2015/ZCTA5/tl_2015_us_zcta510.zip


What's the difference between the Gazetteer and TIGER data? Why such a large file size difference? Which one should I use? They both have 33,144 features.
Likewise, we see that with the state dataset, Combined Statistical Areas csa, and Core Based Statisical Areas cbsa

Gazetteer State (4.6M)
http://www2.census.gov/geo/tiger/GENZ2015/shp/cb_2015_us_state_500k.zip

TIGER State (15M)
http://www2.census.gov/geo/tiger/TIGER2016/STATE/tl_2016_us_state.zip

Gazetteer CSA (2.5M)
http://www2.census.gov/geo/tiger/GENZ2015/shp/cb_2015_us_cbsa_500k.zip

TIGER CSA (18M)
http://www2.census.gov/geo/tiger/TIGER2016/CSA/tl_2016_us_csa.zip

Gazetteer CBSA (6.4M)
http://www2.census.gov/geo/tiger/GENZ2015/shp/cb_2015_us_cbsa_500k.zip

TIGER CBSA (50M)
http://www2.census.gov/geo/tiger/TIGER2016/CBSA/tl_2016_us_cbsa.zip


","['geospatial', 'us-census', 'postal-code']","I wrote to the Census and they wrote back,The Gazetteer file you are looking at is a Cartographic Boundary Shapefile which is for small scale (limited detail) mapping projects clipped to shorelines. Designed for thematic mapping using GIS. The TIGER/Line shapefile is the most comprehensive dataset hence the difference in file size. So depending on what level of detail you need will depend on which file you use. Here is the TIGER Products link: http://www.census.gov/geo/maps-data/data/tiger.html see the graph at the bottom if you want to compare the product types.Please let me know if I can be of further assistance.I'm not exactly sure why anyone wouldn't just always use the TIGER database. But, for whatever reason there are two. For comparison here is a map with CBSA and CSA layered over each other. The green is CBSA, and the red-dash is CSA. The first frame, the one with more green, is the TIGER set. Note, I generated with the 2016 TIGER set and the 2015 Gazetteer set.I'm not sure of the context of thematic, but clearly the Gazeteer CBSA zones excludes more water and the CBSA zones in TIGER include it. Also, thanks to the email and the name we can see that the Gazetteer files are also called Cartographic Boundary Shapefile. In the link provided,Tiger Line Shapefiles are defined as,Full detail (not generalized) ; Shapefiles (.shp) and database files (.dbf); Most mapping projects--this is our most comprehensive dataset. Designed for use with GIS (geographic information systems).And Cartographic Boundary Shapefiles (aka Gazetteer files) are defined as,Less detail (generalized); Shapefiles (.shp); Small scale (limited detail) mapping projects clipped to shoreline. Designed for thematic mapping using GIS.However, looking into it further the Cartographic Boundary Shapefiles also have .dbf files."
Open sports data,"
Today you can find all sorts of data in an open format. Most financial data, polling and government databases, just about every baseball play ever played. 
However this open data paradigm hasn't reached across the rest of the sporting world. Getting NFL, NBA, NHL and NCAA data remains quite difficult and legally confusing. This is making it difficult to create an open data science interest in professional sports data.
Does anyone know about any projects that are working on making this kind of data easily accessible via API or other database forma?
","['uses-of-open-data', 'sports']","Open Sports Data has been around for awhile, as sports have some extremely involved fans.Here is some data, references, and resources:Sports Data Query Language (SDQL)
SportsDataBase (SDQL) Google Group
Sports Data Visualization using the Sports Data Query Language
Download KillerSports.com's Data
API
More Databases Lahman Database (.csv/.sql/.mdb)
Retrosheet – Play-By-Play Files, Game Logs, Schedules
Japanese Baseball Data
Baseball Tools - Tools for Working with Baseball Data
Baseball Databank
Baseball Reference .com Data The Football Project – Play-By-Play Data
Advanced Football Analytics
more football
SportsDatabase.com makes box score data researchable
Advanced Football Analytics' Play-By-Play Data Archive
Play-By-Play Repository of Older NFL Data via 10flow
10flow allows you to roll your own NFL Play-By-Play Datasets College Football Data Warehouse
Disclaimer: the next two repositories are mine:
College football datasets from cbstats.com
NCAA Football Profits DatabaseBasketball Stats Database Download Hockey Databank – Yahoo Group "
Cellular data subscription costs,"
The US Census July 2013 Computer and Internet Use Supplement surveys US households and asks ""How much does your Internet service provider charge you per month?"" From this, I can get an empirical distribution of US households' monthly Internet service costs.
This data is mainly about fixed broadband (i.e. home Internet access), however. I am looking for a data set that will allow me to compute this same distribution for cellular data plans.
There are various reports that compile the cost of selected mobile broadband plans (e.g. the FCC International Broadband Data Report appendix), but not the number of subscribers for each plan. So these don't really help me.
Is there a data set that allows me to compute the distribution of monthly cost of cellular data subscription in a population? I prefer US, but would also be happy with data for another population.
","['data-request', 'internet', 'telecom']",
Daily Reimbursement Rate for ROWPU,"
How can I find the reimbursement cost of a ROWPU? Reverse Osmosis Water Purification Unit. 
",['data.gov'],
Data Set of all registered Defined-Benefit Pension schemes in the UK,"
Just a data set I'm trying to find. 
Ideally with Company & Pension Assets data as well. 
Help and ideas much appreciated.

The data exists (privately) in at least one place: The Pensions Regulator, as ""The Official Register of Pension Schemes"". 
Extensive search suggests that it doesn't exist anywhere else, but I thought I'd ask the community anyway.
",['data-request'],
Open large datasets on human body temperature?,"
Does anyone know of any large population-based dataset that recorded human body temperature? 
","['data-request', 'medical', 'population']",
MIMIC-III Inputevents_mv 'Rewritten' value,"
Can anyone clarify how the 'Rewritten' value in the statusdescription column impacts the data? It appears impossible to ascertain the final ""approved"" sequence of events in a particular fluid delivery.  The time sequence of multiple rewritten columns from a particular linkorderid seem to have overlapping time segments with no way to determine which ones are the accurate (Read final set accepted by the clinicians) time / rate / amount. 
",['mimic-iii'],"For what it's worth for anyone else who stumbles upon this question and want an answer, see https://github.com/MIT-LCP/mimic-code/issues/47#issuecomment-282734892As far as we know, all rewritten rows should only be used for audit
  purposes, i.e. these rows correspond to drug doses never being given
  to patients. We are considering removing this audit trail in the
  future as its use in research seems limited and it only acts to create
  a confusing table.So in my own analysis, since I care about what the patient received, I exclude those that have Rewritten in the column statusdescription. However, I also only include cancelreason = 0. The corresponding code for cancelreason is unclear, but if there's any reason for cancelling it then in my analysis I do not include it. "
What public datasets of radiology reports exist?,"
I know about MIMIC database, which includes ""imaging reports"".
Here you can also find data that includes radiology reports.
I am yet to explore any of these datasets. But from what I understand they are not focused on radiology reports. Are there any others datasets of this type?
",['data-request'],
International Education Spending,"
I am interested in looking at the relationship between money spent on education (by country) versus educational ranking (by country). I am looking for a database that shows something like amount of money that is spent on students in different countries as well as the education ranking of those countries.  The data can come from more than one source (say one for money spent and one for education ranking) as I can merge them myself once I have the data sources. 
","['education', 'global']",
Acquiring Used Car Sales Prices,"
I'm looking for used car prices for luxury cars (i.e., Ferrari, Porsche). Essentially I'd like (for any given Ferrari/Porsche car) the price it sold for, the miles it already came with at the time of its sale, and the year it was manufactured.
It seems simple enough to search for, but after scouring the internet, I couldn't find a straightforward solution to my inquiry. Is there a government agency that could perhaps supply this data?
","['data-request', 'prices', 'cars']",
Criminal news stories,"
Any open data sources containing collections of criminal news stories across a wide variety of newspapers?
I know there are a lot of newspaper archives but I can't seem to find any that allow you to sort by 'crime' articles. (I'm interested in contemporary stories, last 10-20 years, but more recent the better. ) 
","['data-request', 'media']",
Satellite Images on OPeNDAP,"
I am looking for global satellite images(as recent as possible - say three hours ago) of meteorological data that can be accessed through OPeNDAP protocol i.e. subsetting via latitude, longitude and time. Meteosat does have them but only upto 2015 - Meteosat OPeNDAP
I am looking for current global satellite images that can be accessed via OPeNDAP. 
For continental USA this site does provide the images - CONUS
","['data-request', 'geospatial']",
Where can I find a nationwide breakdown - by race - of police detentions that did not result in an arrest or citation?,"
UCR statistics tell me how many people, in the year 2013, were arrested. It breaks down the data based on race and crime.
What I'm looking for is more along the lines of how many people were detained but not arrested or issued a citation. I thought there was data somewhere on the FBI Website, but I could not find it.
",['data-request'],
Tracts in a Place from Census API,"
Using the US Census Decennial Census API, is it possible to get a list of all the Census tracts that are part of a Census place.
",['us-census'],"It is not possible with just the Decennial Census API, but a solution can be constructed with the Census's TIGERweb services. In sketch, use TIGERweb REST service to get the geometry of a place, and then use that geometry with another TIGERweb REST service to get a list of tracts that intersect with a place, and then use the Decennial Census API to look up information about those tracts.This is the road I took in this python library that allows queries of tracts, blockgroups, and blocks by place (or other arbitrary geometries). "
Is there a database of actions commonly associated with specific nouns?,"
Is there a publicly available dataset of particular nouns with the verbs that are often associated with them? For example: {""apple"": [""eating"", ""peeling"", ""cutting""]} or something.
",['data-request'],
"Why are the values of some variables different in the current version (updated on Sept 13, 2016)?","
I do not understand why the values of certain variables changed from the previous version to the current version. For example, grad_debt_mdn for the first observation (unitid=100654) is 25106 in MERGED_2010-11 datafile in the current version (updated on Sept 13, 2016). However, grad_debt_mdn for the first observation (unitidi=100654) is 27070.5 in merged_2010_PP in the previous version (updated on March 2, 2016). Given that the variable grad_debt_mdn from Merged_2010-11 measures NSLDS AY2009-10, AY2010-11 pooled cohorts, why should the value for grad_debt_mdn change when the data was updated? I did the checking and it was not caused by the inflation adjustment. I noticed this change also happened to a lot of other variables such as FIRSTGEN_YR6_N.
I thought the only update was adding the most recent data file ""MERGED_2014-15 datafile"", but apparently it is not the case. So how was the data updated? Is there a document that can show me the things you did to update the data?
","['data-request', 'collegescorecard']",
Is there a way to query openFDA for drug pair interaction?,"
openFDA is awesome particularly the drug/event database. But I can't find a way to query whether a particular drug (e.g. xanax) has any drug interaction warning, precaution, or contraindication. Essentially, I want to know whether by specifying two drug names, openFDA tells me whether the interaction is unsafe. Something like what webMD drug interaction checker does. Your assistance is greatly appreciated.  
","['openfda', 'json', 'drugs']",
Searching for database for Colorado soils that goes back to 1990's,"
Are there any database for the soils database out there beside NRCS ? I am fully aware that NRCS has their database on their website but I was wondering if there is one that can't i find them ? I am looking more specific for Colorado. They can be either database or geospatial but I prefer them to be the database that goes back to 1990's They need to have mapunit, map name, and their survey areas ?
","['database', 'soils']",
Constructing a WordNet-like tree from the Wikidata dataset?,"
Is there an approach to constructing a semantic tree somewhat like WordNet, but using the vastly more structured and useful Wikidata data instead? How could this work? Could we place similar entities together, and dissimilar ones farther away? Does this need to be supervised in any way by a human, or is there an approach to similarity using only the properties that Wikidata provides?
","['data-request', 'wikidata']","I would say that the P279-property (subclass of) will span a semantic ""tree"" (it is not necessarily a tree but a directed graph). You might be able to build semantic trees from other Wikidata information too.The P279 graph can, for instance, be obtained from the Wikidata Query Service (WDQS). The below tree is based on a query around 'novel' (Q8261). The graph can be rendered with the following SPARQL query on WDQS:Link to Wikidata Query service for P279 graph on 'novel'Similarity information is not readily available with Wikidata and WDQS. 
I have been experimenting with Wikidata and graph embedding to make this possible. A work in progress prototype called ""Wembedder"" is available at https://tools.wmflabs.org/wembedder/. For instance, a query on 'short story' is available here: https://tools.wmflabs.org/wembedder/most-similar/Q49084#language=en The current Wembedder returns ""essay"" and ""narrative poetry"" as the most similar other items. 
The web service is described further in Wembedder: Wikidata entity embedding web service."
Seeking land parcel data having cost of land for each land parcel for states of Gujarat and Maharashtra in India?,"
I need to find land parcel data for the states of Gujarat and Maharashtra in India having cost of land associated with each land parcel.
",['india'],
why the total number of datasets sometimes smaller but sometimes bigger than before?,"
Over time, I've found that the total number of datasets on data.gov is not gradually getting bigger but sometimes smaller than before. e.g. the number is 190000+ in 2016-04 but now (2016-10) it's only 180000+. Why do the number of datasets seem to be shrinking?
",['data.gov'],
Remix Music Audios,"
I am searching for a dataset/ways to collect audio of remix musics, with names of their original pieces.
Any suggestions and pointers are much appreciated!
","['data-request', 'music', 'audio']",
Looking for specifically distributed dataset for classification task,"
I'm working on a specific classifier which can classify the below toy data, which is a 2-class problem but the classes are distributed among each others. So it is not possible to solve it by typical SVM or Knn or prototype based classifiers. 

But in order to show the practical use of my method, i need some real dataset generally similar to the above condition. It can be n-class problem, where the class data are coordinated among each others, but locally separable, and shouldn't be possible to achieve high performance using Knn or SVM classifiers. 
I was wondering if such dataset is available anywhere?
",['data-request'],
GPS or Printable map? [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 6 years ago.







                        Improve this question
                    



Question for you guys, especially travelers like me do you prefer GPS or printable maps? I don't know but from my latest trip, GPS wasn't much of help. I had to resort to pdf maps from this site http://vectormap.info/ which have been very useful.
","['geospatial', 'city', 'global', 'travel']",
Nicknames database,"
I'm interested in being able to identify a name like ""Nick"" as a short form of a name like ""Nicholas"" in a data set.
Is there any kind of open or somewhat standardized mapping of names and nicknames available? I am fine if it's limited to Western or American English names, but international data is even better.
","['data-request', 'names']","Nicknames and Diminutive Names Lookup (CSV)
CSV, Database of Common Nicknames and its GitHub Repository: Common Nickname CSV (Database)
Name to Nickname CSV and Nickname to Name CSV"
Violent/Non-Violent News Headlines from the Past,"
Looking for data on news headline grouped by crime type: violent vs nonviolent; for 1993 and 2013 or 2014. 
","['data-request', 'crime']",
Hadoop open source design and implementation,"
I have a big project to analyse the client’s history, records in order to predict and manage the resources more efficiently. This has to deal with millions of data sets flew from various resources. My question here, what is the best tool / predictive technique allow me to achieve this?
Any help would be appreciated!
","['sentiment-analysis', 'big-data']",
How to get the property name for a specific ID?,"
Wikidata entities have claims, inside which are property IDs with their snaks. But how do I get the name for a particular property ID?
","['api', 'wikidata']","Ok, I admit it might have been a little bit obvious, maybe. You just use I know, the action is wbgetentities, but it does work! You get a JSON response like this:This works because, oddly enough, properties themselves are entities in Wikidata."
Diabetic vs non-diabetic dataset,"
I'm looking for information for a research. I need some data on a group of diabetic people and a group of non-diabetic people.
This is some of the information I need:

Age
Body mass index
Fasting blood sugar

Any ideas where I can find these data?
I prefer data from Brazil, but if you have this data from other countries I'll gladly accept it.
","['data-request', 'medical']",
Cost of retirement housing in the regionally in the UK,"
I was wondering if anyone knew of a data source that had the cost of retirement housing in the UK split by region or postcode?
",['medical'],
How to search multiple tags in a Socrata site?,"
You can find all datasets in a socrata site like this:
/data/?tags=parking

How can you find datasets that match one of several tags (OR)? This doesn't work:
/data/?tags=parking&tags=footpaths

",['socrata'],
Dataset for consumer digital media,"
I'm looking for a dataset that will help me determine a correlation between college major and media preferences i.e. genre.
","['demographics', 'media']",
What are the sites to download kidney function datasets?,"
In desperate need for a site that provides medical datasets around kidney function tests (Kidney failure tests) and kidney failure CT scans (datasets) for my graduation project.
",['medical'],
Where can I find the graduate school college scorecard data,"
I want to know the data and information about graduate schools. Where can I find it?
",['collegescorecard'],
Audio Conversational Dataset?,"
I'm trying to get some test data for a conversation dataset for free. I have referred to: Speech audio files dataset with language labels, but unfortunately it does not meet my requirements. 
I am specifically looking for a natural conversation dataset (Dialog Corpus?)  such as a phone conversations, talk shows, and meetings. I've considered two approaches:

1) Find a suitable dataset 
2) Scrape talk radio podcasts for audio
  content.

These files need to be stored as a .wav format. 
Any suggestions and help would be appreciated. 
","['data-request', 'audio']",
Where can I get a data set of medical information of healthy people?,"
I'm developing a data mining application for healthcare sector. I need a data set that would give information on age, blood pressure, specific gravity(of blood and plasma), sugar, amount of red blood cells, sodium level and some attributes like that sort of healthy people.
","['data-request', 'medical', 'machine-learning']",
Data set for Social Commerce,"
I am looking for a reviews/rating dataset for my social commerce application (for building up the recommendation engine). In this dataset, along with product info and reviews/ratings by users, I also require user demographics information like age, gender, occupation. 
I have looked through Amazon datasets, unfortunately, they don't have the user info. 
I have also looked through UCI repository, but couldn't find anything relevant.
I came upon this paper, and found the dataset description exactly the way I wanted, but unfortunately, this  dataset is not open.
","['data-request', 'machine-learning', 'social-media']",
Stock market historical data,"
I was surprised not to find a similar question here. But what are the best sources of stock market daily (weekly, monthly) prices for all listed companies in a given market?
Google Finance, Yahoo Finance grant limited access via API. But since the question concerns historical prices, perhaps, are there more friendly ways to get it?
","['data-request', 'finance', 'historical']",
Are there IDs that can be used to access entries on Bloomberg's Private Company Search?,"
Bloomberg's Private Company Search provides access to a lot of companies. I'm currently not sure whether there's a way to access the results of this list with FIGI numbers. If so, are their special FIGI numbers that are about the company directly and not about it's shares?
Otherwise is there some other ID for companies?
",['finance'],
Finding ward level administrative boundary data for india?,"
In the census 2011 data there is data at ward level.
Is it possible to get shapefiles at that level? (paid/free)
Please don't refer me to GADM , which is at taluk level.
I want at least 2011.
How good is google geocoding api with respect to this?
Are there any other alternatives?
","['data-request', 'geospatial', 'census', 'india']",
Access ECMWF Data via python script,"
I want to access ECMWF data via a python script. I am not sure how to do that. 
I followed the instruction given on the website: 
Accessing ECMWF data server in batch
Unfortunately it says: ""This method is only supported to UNIX platforms with Python.""
I am on a Windows platform. Does that mean I can't access the data from ECMWF? If this method is only for UNIX-Users only, is there an alternative for Windows-User?
So far I did the following: 
created textfile in my homedirectory with content:  C:\User\Name\ .ecmwfapirc.txt
{
  ""url""   : ""https://api.ecmwf.int/v1"",
  ""key""   : ""my-API-code"",
  ""email"" : ""my.email@example.com""
}

Next I installed python library: ecmwfapi 
python -m pip install https://software.ecmwf.int/wiki/download/attachments/56664858/ecmwf-api-client-python.tgz

Last but not least I created the python script which looks like: 
 #!/usr/bin/env python
 from ecmwfapi import ECMWFDataServer
 server = ECMWFDataServer()
 server.retrieve({
     ""class"": ""e2"",
     ""dataset"": ""era20c"",
     ""date"": ""2010-01-01/to/2010-12-31"",
     ""expver"": ""1"",
     ""levtype"": ""sfc"",
     ""param"": ""167.128"",
     ""stream"": ""oper"",
     ""time"": ""12:00:00"",
     ""type"": ""an"",
     ""target"": ""CHANGEME"",
 })

I am not sure if the python script is correct either. Also I don't know whether the location of the python script is important when executed. 
","['api', 'weather', 'python']","I know this topic is six months old, but for reference: 
the ECMWF API is now supported on Windows. Please see here for details The OP created a file '.ecmwfapirc.txt'. This is wrong, it has to be named '.ecmwfapirc' (without extension).From what I can see your retrieval script is correct.
There is a web interface to help you create your retrieval script: http://apps.ecmwf.int/datasets/ At the end click 'View MARS request'The location of the retrieval script script does not matter; only if you save the output to the same location, the location has to be writeable."
Locus of Control Test Results,"
I am looking for at least 1000 observations of locus of control tests like this one or this one. I need what each person answered for each question and ideally their demographics. This is highly unlikely but also metadata on them as they filled out the test would be amazing, for example how long it took to answer each question and other data points. Where can I find this data?
I would like it to be this data set but another large data set of personality test results would also be helpful.
",['data-request'],
Bittorrent usage for distributing open science-data?,"
Writing a grant proposal. - I am looking for information about the usage of the bittorrent protocol for open science data. Does anyone know of a recent paper, blog post or study?
Specifically I am interested in the usage of science data from the natural sciences, specifically Earth Sciences, e.g. geophysics datasets. But I am not looking to download data, I am more interested in usage patterns and popularity measurements. 
What is this data offered via bittorrent like? Is it legacy data from old projects (that someone wrapped up and put in a container), or reference datasets that everyone uses, or newer datasets that are just too big to be hosted on a single computer?
(However the question asked here is a marginal aspect of the proposal.)
Update:  here is one general article: Langille & Eisen, 2010: 
""BioTorrents: A File Sharing Service for Scientific Data""
Update 2: Similar Question from 2014, asked here, with very comprehensive answers (community wiki): What are some OpenData torrents to seed?
","['uses-of-open-data', 'bittorrent']","Did you try searching Google for open science bittorrent usage filetype:pdf
There's a lot of results there to go through, but here are a few:
Enabling Distributed Scientific Computing on the Campus
not 100% bittorrent, but applicable in my professional opinion:
Are P2P Data-Dissemination Techniques Viable in Today's Data-Intensive Scientific Collaborations? "
NDC 11 digit CMS/HIPAA to NDC dash-format code,"
I'm looking for  a way to convert 30K NDC codes in normalized CMS/HIPAA format to dash format codes or otherwise identify them. 
Examples
'00002144509' -> 0002-1445-09
'00023917715' -> 0023-9177-15
'12634053995' -> 12634-539-95
I don't think it's possible to algorithmically convert normalized codes to dash codes is it?
Many of these codes go back years and may no longer be current. They don't show up in the current NDC or RXNORM data. Manufacturers are allowed to change product codes after 5 years so attaching a date to code is a big benefit.
If I can get the old codes I can convert to the 11 digit format and create a lookup table.
I'm looking at DailyMed SPL data, which does go back to the mid-2000s and includes a date (effectiveTime), but the XML seems very poorly structured and difficult to parse. I'm using Python & lxml.
NDC data archives go back a ways but only have the trade name and no dates. I wonder if collecting old versions of RXNORM might be the easiest, taking data from the NDC archive and then looking up the generic names in RXNORM.
Any suggestions?
","['medical', 'drugs']",
Where can I get OCD Division of a state's district_court based on an address?,"
I am unable to find an API that will return the district_court OCD division for an address. I have tried the Google Civic Info API (specifically https://developers.google.com/apis-explorer/#p/civicinfo/v2/civicinfo.representatives.representativeInfoByAddress) and look through the Open States API.
I'm trying to do this for North Carolina addresses. Here is the map of current districts: http://www.nccourts.org/Courts/Trial/District/Documents/DistrictCourtmap15.pdf
","['usa', 'api', 'geocoding', 'district']",
How can I convert xy line-plots to textual data values?,"
I want to reverse engineer a simple XY-line graph to scalar data values.
An example of such a plot is linked below, 
 water temperature as a function of datetime.  As far as I know, the raw data (sensor readings) and the processed numeric temperature values of this  are not openly available on the internet, not in text format.
http://www.met.fu-berlin.de/de/daten/mevis-grafiken/TegelerSee/TEGSEE_Jahr_TT-WT.jpg
I think such tools are available as desktop applications (e.g. Neuralog) but those I know are nonfree, expensive, and require too much manual interaction.
What I want to do is process the same plot (linked above) again and again, say every two weeks. Automating the data cleanup (remove outliers, merge timeseries) seems doable to me.
(Maybe this been asked before by someone else on one of the other sites (software-recs, SO)...)
","['data-format', 'software']","Here is a blog post that compares 16 graph digitizing tools, some free, some not. The suggestion is to use WebPlotDigitizer. The blog doesn't mention if any of the tools can be used to automate the process.To read an image file and process the data, then you probably want to use a programming language. Python or R-digitize are good places to start."
Historical land cover (land use) in Central Asia,"
I would be curious to know if there is GIS data of the historical land cover (land use) in Central Asia? It has to be finer grained than half a (spatial) degree like the DAAC dataset to be useful for my (socio-economic) analysis. 
I suppose that newer datasets like FAO's GLCN maps are based on satellite pictures. Hence, I have no idea if it would be realistic to expect good resolution land cover data earlier than the 1990s, as orbital objects were still carrying dogs instead of GPS technology back then. I would be particularly interested in agriculture and grassland coverage in the *stan countries. :-P 
","['geospatial', 'asia', 'land', 'agriculture']",
Has CKAN been used as a data portal for any Open Science initiatives by an academic institution?,"
CKAN is the leading data portal solution, and is typically used by governments and their agencies. I am wondering if this software has been used by scientific institutions and universities for Open Science projects. Links to example sites and/or relevant publications would be helpful.
",['data-portal'],
Can anyone HELP provide codes to import 'CHARTEVENTS' and 'NOTEEVENTS' in sas or R?,"
I tried R and SAS to import these two datasets, but the programming runs forever. I could not open in excel either. Can anyone provide codes to import these two table: 'CHARTEVENTS' and 'NOTEEVENTS' ?
","['mimic-iii', 'programming']",
US Census Block Internal Points,"
I am trying to get a list of all ~11 million 2010 census blocks' internal points (latitudes and longitudes assigned by the census to be used as approximate locations for each block). I can't for the life of me find these anywhere without downloading the entire polygon geodatabase! I finally broke down and downloaded that, but at ~6 petabytes, I don't have the storage to unzip and work with the file. Does anyone know of a source for internal points ONLY before I whip something up to download and process each geodatabase by state or county? 
","['geospatial', 'us-census']",the intptlon and intptlat fields of the census bureau's summary files contain the center of every census block nationwide.  there's some pretty straightforward R code to download and import these files here:https://github.com/davidbrae/swmap/blob/master/how%20to%20map%20the%20consumer%20expenditure%20survey.R
Where can I find historical College Scorecard Data,"
In September 2016 there was an update to the Scorecard Data. See here: 
https://collegescorecard.ed.gov/data/changelog/
Is it possible to access data before the update? Or the original data when the Scorecard went live?
","['data-request', 'collegescorecard']","the Wayback Machine is your friend.
data on 2015-09-15 - Original Data
data on 2016-06-17 - Updated Data "
Examples and experiences of text and datamining use of open data?,"
I am currently working on a research project that looks at the barriers and best practices when it comes to text and datamining. 
www.FutureTDM.eu
Do you have any experience with this in relation to open data ? Do you have any insights you wish to share and contribute to the recommendations we are developing for the European Commission please contact me ! Looking forward to hearing from you
","['api', 'uses-of-open-data', 'licensing', 'best-practice']",
MIMIC III: timestamps are shifted by several years... is that normal?,"
Background: downloaded the MIMIC III data sets from PhysioNet in csv form. Opened ADMISSIONS data table in MS Excel, only to find that the time stamps have been shifted by many years.
e.g., ADMITTIME
""2191-02-25 20:30:00""
""2111-08-29 03:03:00""
Does any one have an idea as to how this may have happened?
",['mimic-iii'],"The following paper provides important background information on the MIMIC-III dataset: http://www.nature.com/articles/sdata201635. The point below addresses your question:""dates were shifted into the future by a random offset for each individual patient ... resulting in stays which occur sometime between the years 2100 and 2200.""Please also refer to the section on ""Times"" in the MIMIC-III documentation:
http://mimic.physionet.org/mimicdata/time/"
Where can I find a dataset containing legal documents?,"
I have a machine learning task I wish to pursue. For the task I will need several hundred sample legal documents of the following types: Employment contract, service contract, sale contract, rental contract/lease, loan contract, confidentiality contract, company formation agreements. I don't expect anyone will have an answer which will help me find all of these contracts but if anyone has any kind of lead as to where I can find a mass amount of one of these contracts it would be much appreciated. 
Thanks.
","['machine-learning', 'nlp', 'legal']",CFPB Credit Card Agreements DB I think that is a service contract.docracy - open source legal contracts Requires sign up
Telemetrics datasets for vehicles,"
I need telemetrics dataset for vehicles, to categorize riskiness of drivers based on their driving behaviour. I have already looked into kaggle's AXA Telemtrics challenge, unfortunately kaggle has removed the data.
Does anyone has the link to AXA data or any other vehicle telemetrics data?
",['data-request'],
User complaint/review description for running nlp-ner on telecom(preferably) data,"
I am looking for Consumer complaint/review description data which is not generated from automatic logs but manually entered by the end-user/customer-support.
The objective is to run the Stanford NLP-NER tool on the user description for determining the Location, Organization, Faulty Device, etc related to the complaint.
I have been struggling for 2-3 days to explore and have found some Telco data, but all of the Data is STRUCTURED. See my answer on this question.
The key elements of the data I need are -


UNSTRUCTURED description by the end-user or by customer-support.
Data can be in the form of either of 'complete sentences' or phrases(say comma separated/semi-colon separated data).
  A hypothetical example (just for the sake of clarity and not restricted to the following format) of tow of the concerned columns among the rest of the user/caller info -

Fault Description - ""I am calling from New York; staying at Hotel Marriot Marquis; Please help asap - my phone not working.""
Fault Resolution - ""System connection established in New York; Hotel Marriot Marquis; Issue resolved by on-site visit - problem in region multiplexer..bla bla.""

I believe this problem would make for an interesting application in the Telecom domain.
","['data-request', 'nlp', 'telecom', 'unstructured-data']",
Best way to get Open Data Community to Engage (Attend/Volunteer) at The White House Open Data Summit?,"
Wondering what are the best methods/approaches to informing the Open Data Community of the upcoming Open Data Innovation Summit at the White House.
Attendees and volunteers are needed, and anyone with interest in Open Data that will be in the DC metro area is invited.  
More Information About the Event:
The White House Open Data Innovation Summit with Solutions Showcase is taking place onSeptember 28, 2016 at the Walter E. Washington Convention Center in DC, and we need your help to make this an even better event! We plan on selling out in the next few days, so now's your last chance to register
The Summit will highlight the Obama Administration’s work in opening U.S. government data and to discuss the path forward to continue this progress. This event will feature cutting-edge uses of government open data to promote government efficiency and effectiveness, drive innovation, economic opportunity, and improve the health and welfare of the American public. During this free and open Summit we will hear from people on the front lines who are championing data-driven innovations. 
To attend as a general or half-day attendee, register at this link.
Questions? More information on the Summit can be found here or contact WHOpenData@gsa.gov.
",['uses-of-open-data'],
Public domain data for sample/training purposes,"
I'm looking for some real-world data for use in creating database/educational training materials. 
The sample should have a good Entity-Relationship diagram/data model, multiple tables, and ideally SQL scripts with create tables/insert statements to run on my database (SQL Server ideally, but I'm flexible on that).
","['data-request', 'data.gov']",
Can I get dataset of google queries asked by people in a particular time period?,"
I am doing a research on how queries have evolved over time(focusing on google mainly). I want to compare what queries people searched on google last year and compare it to what they are searching right now.( I want raw query and not abstracted data on topics most searched like google trends) I went through all the option mentioned in this answer on quora including google's bigquery dataset but couldn't find appropriate dataset. Can anyone guide me in this regard?
","['data-request', 'internet']",
Country City Population database,"
I'm trying to do some research for some people in the SEO and data marketing industry.
I'm flat broke so I don't have money to spend but I would love to find a database that's free that just has the Country and all its cities or at least major cities and their recent population.
","['geospatial', 'city', 'database']",
Raw data on sexual behavior,"
I am a college students doing a small research project on sexual behavior and was wondering if there was any raw data on sexual behavior that I would be able to access. It would really help me out. Any help is appreciated! 
","['data-request', 'medical', 'lgbt']",
How are national average calculated in consumer website?,"
How does the Scorecard compute national averages on the consumer website?  Example: the Scorecard reports national average ""salary after attending"" as $33,410, but when computed using the data download, I get $32,850. Is the difference due to suppression in the download data or something else?
",['collegescorecard'],
Looking for panel dataset,"
Hi I am looking for panel data set for my academic project. It should not be too small . Any links to panel data sets with good business value will be helpful.
",['data-request'],
Data for vehicle speed and altitude at Nürburgring,"
Are there any sources of data for driving at Nürburgring. I would like to get location data (like GPS data) including altitude and vehicle speed during a high speed lap.
","['data-request', 'geospatial']","Open Street Maps has a community portal to upload GPS ""traces"". These are then publicly accessible.There isn't a ton of tracks available, but you can try to find other tracks in the region that aren't tagged 'Nürburgring'."
Compare geographical data on accomodation with external factors,"
I collected 200′000 data records from a major accommodation website in the United States and will compare this data with external factors like crime data, population, economy growth, tourism popularity and so on. 
The rental data include, among other things, the price and the coordinates. The next step will be to analyze these coordinates. Does somebody know an interesting website, where I can have access to external factors with coordinates.
Thank you for your help
","['usa', 'uses-of-open-data', 'analysis']","If you found non-aggregate data based on latitude/longitude, then you'd still need some algorithm to map your point to the nearest measurement coordinates - which is not trivial. It's unlikely to find US-wide ""incident-level"" data, whereas most data will be aggregated to some geographical region and time frame.For that reason, I think most demographic, economic, environmental and crime data will be only mappable from aggregates like zip code, city or municipality, voting district, county and state. You can create a simple mapping table between all your latitude/longitude combinations and then which zip code, municipality, etc they belong to. For 200k records, you probably can't use Google Maps Reverse Geocoding (also due to license):But OpenStreetMap provides reverse geocoding as well:Geonames is another resource for reverse geocoding.Whatever API service you use, make sure you understanding the quotas, and that you also have a good strategy for importing all the data to a local database (or file archive). This way you can do the reverse geocoding once for all your records, over a period of days or weeks, and then not need any more queries.Once you have your latitude/longitude mapped to geographical regions, there are tons of resources at data.gov to start to join to your original dataset. (Don't forget about season differences!)Sidenote - for those using zip codes - check out this research that shows how zip codes masked the contaminated water crisis in Flint, Michigan.Their ZIP code data included people who appeared to live in Flint and receive Flint water but actually didn't, making the data much less accurate than it appeared."
Open data in US which can provide with live traffic?,"
Is there any open source dataset I can use for my project about live traffic data?
So that I can visualize something like shown in this visual-link

I found the data in the same domain at this data-link
I guess this uses Waze Jam Data, If not I couldn't download the data from data-link.

Is There any alternative dataset I can use? preferably live traffic data.

In these datasets I found there is the UUID encoded location. How can I decode or how can I use in my application?
Say I'm using Tableau for this.
","['data-request', 'geospatial', 'traffic', 'real-time']",
Government survey that includes detailed job titles,"
I'm looking for a U.S. government data source that provides detailed or ""raw"" job titles alongside the usual standardized occupations (e.g. Census, SOC, or O*NET occupation codes). Here's the catch: There must be some indication of how many people are in each job-title/code pair.
I'm aware of various match files and indexes that pair standardized codes with more detailed job titles, but none of them give a hint about the relative frequency of each title within each code (respondent count, or individual weighted records), which is really what I'm after.
The reason I ask for a government source is that I want the results to be as close to an unbiased random sample as possible.
","['data-request', 'usa', 'survey', 'economy']",
Historical NCAA football poll rankings by week?,"
Is there a source for historical weekly poll rankings for NCAA football? Ideally something like the AP poll, but any of them would do, I would just like to look at yearly rankings in the beginning of seasons matched against final season performance.
","['data-request', 'sports', 'historical']",
Bikesharing datasets,"
Im trying to obtain historical datasets of public transports like train, bus and also bikesharing provider. While api.citybik.es provides almost all APIs of these providers, i struggle to actually find a database with compiled data throughout a year.
My big goal is to compare the capacity usage of two or more of these public transports in one city(preferably Germany).
","['data-request', 'api', 'public-transport', 'bikesharing']","motivateco, the firm charged with operating the city's now-public Bike Share program, have a list of XML and JSON feed for each city they operate in. 
They also release the General Bikeshare Feed Specification (GBFS) which they are trying to push as a standard for bike sharing data publication.If you are looking for time series data check out: "
NJ Highway accident hot spots,"
I am conducting a hazardous vulnerability assessment of truck spills on main highways in NJ. I am looking for any type of data (GIS, spreadsheets, statistical analysis) of hotspot locations of where truck accidents are most likely to occur on a highway 
","['geospatial', 'research', 'traffic']",
Existence of a diseases/symptoms database,"
For a personal project, I am looking for a database containing (possibly) every disease with its associated possible symptoms. Do you know if such a database is available somewhere?
","['medical', 'database']",
US Presidential Election by County,"
I'm trying to find election data from 1789 to last general election, down to county level. I was lucky to get for only 2002 on this page Center for Congressional and Presidential Studies. I was wondering if anyone has a credible web link to resources that can provide me with these sets of data.
","['data-request', 'usa', 'elections']",
Obtaining data sets for solved murder,"
Ii'd like to do a research project & developing an application which requires a data set of solved murders. Ideally containing: Something unique to the case, like an ID. Solved / unsolved and a description.
Does anyone know if anything like this exists for the UK / USA.
I've tried some Googling and couldn't really find much which really suits the requirement. 
","['data-request', 'usa', 'uk', 'crime']",
Simple elevation data for Europe,"
I have a specific need, which is to do as little coding as possible to transform the dataset that you recommend to a format that our software can use.
We want to divide Europe (possibly, later, the world, but let's stick with Europe for now) into 30 arc-second cells, with 100x100 cells for one degree.
For each of these cells, we need the highest elevation above sea level for anything at all in that cell, to a one metre resolution.
I would imagine that I will find datasets with far too much data, and would like to make it is simple as possible to reduce that to what we want. I will code a Python script to do that.
I would guess that it would be simplest for me to parse a dataset with fewer data items – I do not need to know that names of towns, or where rivers or airports are, just the height of each point  in the dataset.
A bonus would be  if there exists a Python module to parse the data format of the dataset, but I can code it myself if not. Otherwise, simpler formats, like CSV or XML are preferred over more complex formats.
Any dataset MUST be freely available of commercial use and must NOT require us to publish our source code.

[Update] I can find a few datasets, and also the Google elevation API (https://developers.google.com/maps/documentation/elevation/start), but I can't find a dataset which gives me the highest point in each 30 arc-second cell :-(
","['data-request', 'geospatial', 'europe']","I think you may find European DEM data useful. It can be retrieved with this link : http://www.eea.europa.eu/data-and-maps/data/eu-demThis not really Open Data, rather free data that needs you to mention you used it, but I'm unsure I understood exactly what you need, because you mix the need for data and the need for extracted info from your data.To find the highest point, you will need to generate a grid vector layer, then perform some zonal statistics, but this is more of gisstackexchange area if i'm correct.To read and process the data, you can use QGIS Open source software.The EU-DEM is a 3D raster dataset with elevations captured at 1 arc
  second postings (2.78E-4 degrees) or about every 30 metre. All three datasets are made available as tiles (5x5° or 1000x1000km)
  and as single files:
  -    EU-DEM in ETRS89 geographic (EPSG code 4258)
  -    EU-DEM in ETRS89-LAEA (EPSG code 3035)
  -    Colour shaded relief image over Europe in ETRS89-LAEA (EPSG code 3035)The datasets are encoded as GeoTIFF with LZW compression (tiles) or
  DEFLATE compression (European mosaics as single files)."
"In the World bank database, why is there no GDP data for switzerland between 1970 and 1979?","
The World bank database has a gap for Switzerland between 1970 and 1979: 
Worldbank GDP data for Switzerland.
Do you know why is there this gap and what is the best source to fill it?
","['worldbank', 'gdp']",
"Get QID from Wikidata label name, via SPARQL","
I use api.php to get the QID of something using its English label.
Example: Mozambique → Q1029
$ wget --quiet -O - ""http://www.wikidata.org/w/api.php?action=wbgetentities \
  &sites=enwiki&titles=Mozambique&format=xml&props=""

<?xml version=""1.0""?><api success=""1""><entities><entity id=""Q1029"" type=""item"" /></entities></api>

QUESTION: How to do the same with a single small SPARQL request?
","['wikidata', 'sparql']","Yes, you can, but it isn't short:You can see it here."
UK Life Expectancy (Either HLE or LE) by small area,"
I have managed to track down the UK Life Expectancy statistics for multiple different criteria, but not by local area. 
Ideally this would be by either Lower Super Output Area (LSOA) or by 2015 election ward. 
The idea would to then be able to compare life expectancy across a city or county.
I have tried data.gov.uk and neighbourhood.statistics.gov.uk as well as a few other sources (such as DataHub.io), but cannot find anything that provides this type of data in a usable format.
Any help would be greatly appreciated.
","['data-request', 'uk']",
People from the Nordics Living Abroad,"
I am looking for data regarding Nordics (Denmark, Norway, Sweden, Finland) living abroad. I was wondering whether there were any up-to-date resources for the stocks of people from the Nordics already located in foreign nations. I have found the OECD and UN databases, but they are either not up to date or are lacking in data for certain countries (in particular Singapore seems to guard its demographics data very fiercely).
I would also be interested in whether there were already some analyses regarding the financial backgrounds of emigrants from the Nordics - i.e. profession, or income prior to migration - to see the economic make-up of Nordic emigrants. I have been through the official statistics bureaus for the Nordic nations already so I would be looking for independent research available online.
","['data-request', 'migration']",
What API can I use to retrieve HealthCare Data?,"
I am looking for an API which provides the healthcare data of a patient.
What I am trying to do is:

User logs in to our website.
Then the user want to get the CDA data from his/her healthcare provider.
Selects the healthcare provider.
Provides the userid and password for that provider.
Our website makes a call to the API with all this information.
The API returns the CCDA data for that particular patient.

I have tried MedFusion and HumanAPI both of which are quite expensive. Can anyone suggest me something cheaper?
I don't want to go the web scraper way, as it can be cumbersome and buggy.
","['medical', 'web-crawling', 'healthcare-finder-api']",
Free Vehicle Database including ground clearance data,"
I'm searching for a freely available database of vehicles sold during the last 10 years (or more) which stores technical specifications including the ground clearance. The only database I was able to find was the Canadian Vehicle Specifications (CVS) but this lacks information about the ground clearance.
Is there a free database available which also includes information about the ground clearance?
","['data-request', 'transportation', 'cars']",
Google Trends weekly data,"
I have an issue regarding google trends: I have noticed that recently something has changed.
I used to be able to get all my weekly-based data, no matter the time period I was interested in. A couple of days ago I have realized that this is no longer possible: google trends lets me see and download the weekly-based data only if I'm analyzing a time period of maximum 5 years.
If I'm dealing with a 6 years period, for example, I can still download my data, but it is only monthy-based.
Do you know if there s any solution to this?
","['data-request', 'extracting', 'trends']",
Immunological Genome dataset,"
I'm looking for immunology gene dataset, basically try to see if I can find any data what will include all auto immune disorders (at the gene level). 
looking online found that only research labs will provide and basically need to be in enrolled in research in immunology to can have access ...
I just try to explore/research the gene sequence, no looking to read articles about disorders meaning of disorders. 
thank you. 
","['data-request', 'genome']",
Suggest Scientific papers collection with precision and recall for pre-judge query dataset,"
I'm working on a project for indexing scientific papers and I will need a free collection of papers with a pre-formed set of queries and his precision/recall values. 
Anyone can tell me some suggestions?
",['data-request'],
Where can I get a shapefile for English Local Education Authorities,"
I am looking to map some data to local education authorities in england. I've found map examples here: http://schoolswebdirectory.co.uk/maps.php?region=all and https://www.haven.com/download/uk-summer-holiday-map-2014.pdf
Description is here: https://data.gov.uk/dataset/local-education-authorities-ew-apr-2009-names-and-codes
But I can't seem to find a shapefile to use. Any ideas?
","['geospatial', 'uk']",http://geoportal.statistics.gov.uk/datasets/c4a62d87de9f4b6087cf5f1515d5a0c1_0?geometry=-8.141%2C54.005%2C4.933%2C55.897&uiTab=table&orderByFields=ctyua14nm+ASC_ from the ONS Open Geography Portal appears to be along the right lines.
Mental health diagnosis datasets?,"
What I am looking for is a dataset that has a number of independent variables, such as age, sex, smoker/non-smoker etc. for which I intend to carry out supervised learning for the dependent variable which would be a mental health diagnosis such as major depression, schizophrenia or a personality disorder.
I am aware of the SAMHDA data on drug abuse but that is not quite what I am looking for.
(I do not have institutional access to any such thing.)
",['machine-learning'],
Canada storm reports,"
I am looking for an equivalent of the SPC storm reports database they have in the US, but for Canada. 
Is there a similar repository that would consist of observed severe weather (wind, hail, heavy rain, etc)? Weather stations just don't cut it, they are too sparse and don't record short-term severe weather very well. 
",['weather'],
Where is ZCTA/CBSA relationship file for 2016?,"
I am looking for the updated ZCTA to CBSA Relationship files. I can only find one for 2010, but there is a Tiger2016 ZCTA...where is the updated relationship file? Or is there another way to find this data?
http://www2.census.gov/geo/docs/maps-data/data/rel/zcta_cbsa_rel_10.txt
I am mapping the ZCTAs within a list of CBSAs and I have gaps caused by missing ZCTAs. 
What am I missing here? 
","['geospatial', 'us-census']","The Census Bureau does not update crosswalk files beyond the decennial remapping. Anthony Damico's suggestion of using HUD's crosswalk files, which are updated quarterly, is the best answer. (Marking this as a community-wiki answer since I don't intend to take credit, just want there to be an ""answer"" to this question.)"
Seeking high resolution transportation map of North Carolina?,"
I am trying to find a transportation map of North Carolina with geolocation to overlay into my project. 
I have gone in circles on the USGS sites and other sources. 
Can anyone point me in the right direction?
","['usa', 'geospatial', 'transportation']",
I am looking for good german <-> czech dictionary in text format(or something else),"
I am looking for good german <-> czech dictionary in text format (or something I can easy read).
The Idea behind is I would like to program a program for myself for learning czech, but the sources I found online are not good.
Any ideas?
","['data-request', 'language', 'dictionary']",
Number of people over age 65 in each ZCTA for each year since 2005,"
Population and age data for zip codes are easy to find for 2010 and later. Where can I find zip code level population and age data from 2005 to 2010? Specifically, I need the number of individuals over age 65 in each zip code for each year since 2005. 
","['data-request', 'us-census', 'population']",
Text Fields Extraction Tools Recommendation,"
The Problem: I have emails coming through and I want to parse few fields from this emails to save it as structured data , can use regex if I just have one or two structures but I have a lot of them so I am looking for library then accepts text input + rules like then will look for each rule and try to extract the required field based on the defined steps Example:
Text Input:
Lorem ipsum dolor sit amet, consectetur Name : John Doe adipiscing elit. Mauris at ipsum quis quam iaculis luctus. Nam vitae accumsan dolor, at maximus risus. Aliquam interdum finibus erat at tincidunt. Age : 25 In ullamcorper sapien sit amet molestie faucibus. Pellentesque leo massa, egestas eu ullamcorper id, sollicitudin at justo. Etiam sit amet ornare ante, vitae facilisis lacus. Etiam a orci vel mauris elementum sollicitudin.
Rules (JSON Or XML):
Remove Empty Lines
Field Name : Name
Something like that a good example is mailparser.io , you set your parsing rules and then the platform extract the data based on your rules
",['data-format'],
Questions and answers from answers.semanticweb.com,"
answers.semanticweb.com was a QA website a bit similar to here.
There were a lot of great questions and answers about SPARQL and related technologies.
The website got sold two times, and since a few weeks, it has been down.
QUESTION: Is there a place where I can download a dump of the questions and answers?
The content had been made CC-BY-SA 3.0:

https://web.archive.org/web/20151031172423/http://answers.semanticweb.com/questions/366/who-owns-the-content-on-this-site
https://web.archive.org/web/20160306114803/http://answers.semanticweb.com/questions/21999/creative-commons-by-sa-for-questions-and-answers

",['data-request'],
workday population data for germany,"
I'm currently looking for workday population data in shp or any other gis file formats. I have found many of population data all over the world but couldn't find the ones that have daytime population.
It does not have to be free so does anyone know where I can get these data?
","['geospatial', 'census', 'germany', 'population']",
List of things users might be interested in,"
For a small project I'd love to have a list of tags which I can suggest my users for them to enter into their profile. Examples would be ""food, photography, japan, typography, art, ..."". Ideally those tags would also be hierarchical: food -> italian -> pizza
I somehow expect that such a list of tags exists, because it's not a very uncommon use case for users to be able to assign tags - but I can't find a comprehensive list anywhere which is publicly available.
Any hints where I might find one?
",['data-request'],
Collegescorecard - individual-level anonymized data,"
Where does the individual-level anonymized data for the collegescorecard live? For obvious reasons, this would be more valuable to researchers than the summary data.
I don't see any access to it from the documentation
","['data-request', 'releasing-data', 'collegescorecard']",
Carto Help in minimizing geographic dataset,"
I have a file that contains location points all over the world, using lat long coordinates. I am trying to trim it down to only new York and Newark new jersey. I have a shape file that is the boundaries of new York and includes new jersey but is in shape area and shape length. I am trying to extract the data points that fall in those boundaries but I am stuck. Does anyone know how to do this in carto or any other program?
","['data-request', 'geospatial', 'tool-request', 'geocoding']",
Is there a way to ask a CKAN repository only for changed datasets after a certain time?,"
I am trying to harvest several CKAN repositories for their metadata, using CKAN REST API.
I wanted to only update the changed datasets (metadata only) in my repository, but I do not see a way to specify that I only want changes since my last update, as recently_changed_packages_activity_list does not have a timestamp as input.
Is this to be done with the offset parameter, and therefore assume that the order of the changed datasets is constant and the list gets appended to?
","['metadata', 'ckan', 'rest']","Do not use the REST API, it's old and deprecated. Use the Action API.You can get the results you need using the package_search action, eg for datasets modified since 1st August 2026:http://demo.ckan.org/api/action/package_search?fq=metadata_modified:[2016-08-01T00:00:00.000Z TO NOW]For datasets created since then:http://demo.ckan.org/api/action/package_search?fq=metadata_created:[2016-08-01T00:00:00.000Z TO NOW]You can of course combine these with any other filters, pagination, sorting, etc. Check the docs to find more."
Looking for service to get movie posters? Need authorized use of the content,"
I need to show movie posters in my Mobil app, so need a official source from where I can download it. I could pay for it to have get permission of the copyright content. Do you know any?
",['film'],
Is it correct to use a full URI as a parameter to another operation?,"
Is it correct to use a full URI as a parameter to another operation?
I think this is best described by example:
Consumer calls: http://my-rest.my-org.com/api/films
And receives a film

Name: Reservoir Dogs  
DirectorName: Quentin Tarantino 
DirectorId: 1237 
Director: http://my-rest.my-org.com/api/directors/Quentin%20Tarantino

It makes sense to give out the URI for the director so that the consumer can go and fetch that data
Here's the part that doesn't seem right to me...
There is some other operation, a search, for example, that does not return a single type of resource and needs a few parameters to function; therefor it has no fixed set of URI's (perhaps the data behind it very dynamic)
For example a search function constrained by director: GET/ search-by-director?director={0}&keyword={1}&foo={2}&bar={3}
Now the question, is it okay? Is it sane? to have an operation that takes the full URI as one of the operation's parameters? Resulting in:
http://my-rest.my-org.com/api/search-by-director?director=http%3A%2F%2Fmy-rest.my-org.com%2Fapi%2Fdirectors%2FQuentin%2520Tarantino&Term=Mr%Pink
My natural inclination is that the Search, constrained by director operation, should use the DirectorId (Or better, a director Alias that is a human readable, unique representation of the director name).
http://my-rest.my-org.com/api/search-by-director?director=1237&Term=Mr%Pink
There are obviously ways to refactor this to get the parameters as ""slash"" URI segments which would make it look nicer (although even more horrific with the encoded URI for the director slapped in the middle), but this is a trivial example for illustration.
",['rest'],
Dataset of Home Appliance Usage,"
I'm interested in obtaining a dataset that includes the electricity usage of individual home appliances measured at hourly intervals. An example of such a dataset is the IRISE Project from REMODECE. Unfortunately the data provided on their website contains daily averages and I need the data for each day. Does anyone have any idea of datasets that contain this information, or how to obtain the full IRISE dataset?
","['data-request', 'energy']","The Almanac of Minutely Power dataset Version 2 captures three major types of energy consumption, namely electricity, water, and gas. It includes data from many individual home appliances such as clothes dryer, clothes washer, dishwasher, heat pump, fridge, TV, wall oven, etc.
The data were captured in a Canadian residential house over a 2-year period (1 minute intervals). Also, it has been beautifully cleaned and ready to be analyzed.DRED (Dutch Residential Energy Dataset) contains energy consumption data of a residential house in the Netherlands over 6 months (1 minute intervals). It also has data of individual appliance."
Median and Mean Household Income at the County Level back to 1990,"
Interested in measuring the spread between the median and mean household income in New York County (aka Manhattan) going back to 1990. Where can I get median and mean household income at the county level going back 20 years?
Sources I've found: 
Here is median income for NY State for that time period:
http://www.statista.com/statistics/205974/median-household-income-in-new-york/
ACS has this info, but only back to ~2009:
https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_14_5YR_S1901&prodType=table
",['income'],"1990 Census of Population: Social and Economic Characteristics (page 410)
http://www2.census.gov/library/publications/decennial/1990/cp-2/cp-2-34-1.pdfTable QT-P32 Income Distribution in 1999 of Households and Families: 2000, Census 2000 Summary File 3 (SF 3) - Sample Data
http://factfinder.census.gov/bkmk/table/1.0/en/DEC/00_SF3/QTP32/0400000US36.050002009-2014 earnings in last 12 months:
http://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_14_5YR_S1901&prodType=table"
"Where can I find average GPA data by graduate year and college, and ideally by major too?","
I'm looking for a data source of average GPA results from each college in the US by graduate year. In an ideal world, an additional level of granularity would by by graduate major for a given college?
I'm thinking this is basically impossible to find, particularly for private schools, but any input would be appreciated.
I've found basically every other data point possible via the excellent collegescorecard.ed.gov
","['data-request', 'releasing-data', 'collegescorecard']",
Historical weather forecast compared to actual weather?,"
I am searching for a resource showing historical weather forecasts compared to actual weather data. 
I'm mainly interested in seeing how accurate various forecast services have been in the past, when you compare their predictions to actual weather records.
I'll be interested in anything of the sort, however, some things that would be nice are:

Accuracy percentage for a certain forecast service 
Accuracy percentage for a given time period
Accuracy percentage for a given geographical location
A combination of the three previous points
Detailed per-day comparisons

I realize these are quite demanding criteria, and it might not exist. However, I'm interested in anything that even remotely fits. 
","['data-request', 'weather', 'historical']",
Finding LiDAR data for London Borough of Camden?,"
I'm working on creating heights of polygons above terrain level, as in this blog post, but my area of interest is London Borough of Camden.

Camden is the green shaded polygon on the map below, generated using the Environment Agency's 1M resolution DTM and DSM LiDAR composites. As can be seen, coverage for Camden and neighbouring Islington is almost completely lacking.
Are there any other data sources that might be available to fill in the gaps?
",['uk'],"LIDAR data of Camden is available as a dated survey. You need to go to http://environment.data.gov.uk/ds/survey/#/survey?grid=TQ28 and scroll down to the LIDAR Tiles 1m 2015. The survey was flown in February 2015 and has not yet been added to the composite data. The new updated composite, with the 2015 data included should be available in the next few weeks."
Bargaining Data,"
I'm interested in finding a dataset that includes bargaining offers (both rejected and accepted offers). Does anyone have any idea of datasets or industries that collect this information?
",['data-request'],
Find UK daily flow discharge data with gaps in the time series,"
I am looking for 2 UK hydrological gauges (one main river and one stream) which must have daily flow discharge data with gaps in the time series and the data in the two time series must overlap.
For example:
Gauge 1 gap: from 2-09-1980 to 7-10-1980
Gauge 2 gap: from 15-08-1980 to 2-09-1980
I am trying to find my answer manually on the NRFA website http://nrfa.ceh.ac.uk/data/search but it is not easy as the completeness of the time series is really good.
Any suggestion?
","['data-request', 'time-series']","I found what I was looking for just by checking manually the gauges on the NRFA website http://nrfa.ceh.ac.uk/data/search .In the map, if you click on the gauges you can go to the relative info page where you can see the completeness of the time series.Really nice."
Where can I find a data set with 1000 records of kidney patients?,"
I need a data set that can be used to predict kidney disease risk. I searched UCI repository but it contains only 400 records. Please help me.
",['data-request'],
"On average, in the United States, when the youngest child of a husband and wife turns 18 years of age, what are the ages of the parents?","
What I really want to know is, at the point in each child's life when they are gaining full independence from their parents, on average:
1) What is the father's age?
2) What is the mother's age?
Recognizing the improbability that such data exists, and since children usually gain full independence between their 18th and 19th birthday, I have decided to narrow my question down so as to focus on just the average ages of the parents when their youngest turns 18.
",['us-census'],
Laser scans of buildings / cities,"
I am looking for a point cloud source of laser scanned building. I have found Laser scans of Earth surface, but there is no open archive of scanned cities / buildings. Or is there something?
I dont care about location, I just need some real-life data for testing.
","['data-request', 'city']",
Satellite Images of Earth from low altitude,"
I am looking for satellite images of the US with a high resolution. I would like the images to be the same resolution as Google maps when all the way zoomed in. Is there open satellite images like this? I do NOT need any additional information in the image like highways or altitudes.
",['geospatial'],
"Lending Club dataset ""complete"" with credit scoring","
I would like to do some data analysis on the Lending Club dataset.  The Lending Club dataset is really interesting and there are quite a few attempts to analyse it.
The data is available here but for those not registered with Lending Club the data is not complete.  This ""partial"" kind of data is the type  available for example on Kaggle. 
Most importantly for me, this data does not contain the credit score (either the LC internal one or the FICO one).
The problem is that to get the ""complete"" dataset it is necessary to register, which prevents all people leaving outside of the US to get this data (the registration process is the same as the one for those wanting to invest and it is restricted to US residents).
I wonder if anybody is aware of a complete version of the date posted on message boards or similar?
",['bank'],
Wikidata label language: How to fallback to ANY language?,"
In Wikidata, this shows labels in English, and falls back to Russian if no English is available:
SERVICE wikibase:label {
 bd:serviceParam wikibase:language ""en, ru"" .
}

QUESTION: How to fall back to ANY language?
I could list all Wikidata languages (""en, ru, [... hundreds of languages ...]""), but that would be hard to maintain. Is there a more elegant solution?
Context: My app displays local monuments around you with a picture/name/map. Users have no idea what Wikidata is, so showing ""ハチ公"" or ""ගල් විහාරය"" is much better than showing ""Q435398568"", even if their phone is not set to these languages. Since the app is mostly used by locals and Wikidata usually has labels in the local language, even languages I have never heard about are often actually providing value to the users.
","['language', 'wikidata', 'global']","As optional get the label in English and in any language, then coalesce:Example query"
Finding patients who went under vasopressor use in MIMIC-III,"
I am interested in exploring Vasopressor use in MIMIC-III. I googled Vasopressor some drugs. I also tried to identify the relevant itemid in the d_items table. I figured out that those Vasopressor drugs are also existing in the MIMIC-III. Those are ""Isuprel"",""Nitroglycerine"",""Dopamine"",""Dopamine Drip"",""Levophed"",""Epinephrine-k"",""Phenylephrine"",""Epinephrine"",""Dobutamine Drip"",""Levophed-k"",""Epinephrine Drip"",""Nitroglycerin"",""Vasopressin"",""Lidocaine"",""Insulin"",""Nitroglycerine-k"",""Dobutamine"",""Milrinone"",""Norepinephrine"".   I am wondering if it is reasonable to consider them all as vasopressor drug and to consider those itemid as vasopressor drugs in my research.
",['mimic-iii'],
TED-LIUM transcripts (text files only),"
Where can I find just the text files of the TED-LIUM v2 corpus, without the audio?
The official site has everything in one huge file (~30GB), which I'd rather not download.
",['data-request'],
price of commercial real estate (office space) per zip code,"
I need a table that will map each US zip code to the average price of commercial real estate (office space) in that zip code.  It doesn't matter to me if the prices are to rent or to buy.  It also doesn't matter if the figure is limited to just office space or if it includes all commercial real estate.  What does matter is that the same thing is measured in each zip code, so that I have an apples-to-apples comparison.
","['postal-code', 'real-estate', 'database']",
Clickstream sample data set,"
I am currently searching for a clickstream sample data set, ideally from an e-commerce shop, to test some classification algorithms for a clickstream scenario.
Does anyone have a link to some sample clickstream data set?
","['data-request', 'machine-learning']",
Mapping Embase Accession Numbers with other paper IDs,"
Is there any publicly available mapping between Embase Accession Numbers and other paper IDs such as DOI, Scopus ID, or PubMed ID?
","['data-request', 'research']",
Does an anonymous (personal) financial portfolio data collection exist?,"
I am looking for something like this - 
Age     Location     Martial status     Dependents     Job     Portfolio
25-35   New York     Married            2              Engineer  20%: stocks, etc.
",['finance'],
How to get the Status of the LCA using Its ETA CaseNumber?,"
Is there any option by using API provided by DOL that makes it possible to get the Status and PDF from Icert Site using ETA Case Number?
",['labor'],
House Price Data in UK by LSOA,"
I'm looking to get average house price data (more realistically, this will probably be data for house sales) by the Lower Super Output Area in the UK
Alternatively, getting it by postcode could work as I could cross reference that to the LSOA.
Would anyone know of a source for this type of data that is easily accessible (i.e. not having to search for each individual Post Code area to get the list and then joining)
","['data-request', 'uk']","To add to Steven Lee's answer, the entire transaction level dataset from England's Land Registry can be downloaded from the Land Registry site.This dataset contains every house price from house sales since 1995 and contains both the full postcode, the street name and the street number. If you can handle the entire dataset (~20 million rows) it is not immensely hard to aggregate to LSOA (at least approximately even though postcodes don't map neatly onto LSOAs). An exact mapping might be possible with a little GIS wizardry but the approximate mapping is available using the postcode to LSOA lookups from The census service here. The tables provide lookups to most higher-level geographies from full postcodes. The datasets are a little large to handle in Excel or Access (there are >2 million postcodes never mind the 20m house prices) so it is worth looking for better tools to process them. My personal choice is Google's BigQuery which is designed for large analytical workloads but is cheap (and for small workloads, free) and available to anyone with a web browser and a Google account."
Comprehensive database of world universities,"
There are quite a lot of university rankings available on the web. Unfortunately, in most of them the data display is limited and is hard to extract systematically. 
What are good sources for comprehensive datasets on world universities? For example, datasets that include the performance in several knowledge areas, teaching, research, etc. 
","['data-request', 'education', 'global']",
Dataset with the location of world fishing grounds,"
Does anyone know of a good source for the location of fishing grounds?
I have looked at the resources mentioned in this question but have not found anything relevant.
",['data-request'],"Selected list of resources for data regarding world fishing grounds:
Human Impacts to Marine Ecosystems: Data from the National Center for Ecological Analysis and Synthesis on human impacts to marine ecosystems. Includes fishing impacts, ocean acidification, sea surface temperature, pollutants and more.
Aquamaps: Standardised distribution maps for over 11,000 species of fish, marine mammals and invertebrates. *Data available for download under High Resolution Maps and Environmental Data links.
Ecology Section
U.S. Bathymetric & Fishing Maps - NOS Office of Coast Survey -- NOAA
Global Data - dataMares provides ""free public downloadable data sets relating to various marine topics and coastal science research""...quick glance-> the first three general database portals are all applicable, and I'm assuming more of them are too. The ""Focused Database Portals"" section also looks highly relevant here.
Global Fishery Databases
Marine/Coastal GIS | Data & Image Portals (includes Metadata Catalogs and Atlases)
OBIS-SEAMAP (Ocean Biogeographc Information System Spatial Ecological Analysis of Megavertebrate Populations) - spatially referenced database aggregating global marine mammal, seabird, sea turtle, ray, and shark observation data
Sea Around Us
has extremely detailed data regarding catches
GISFish
FAO (Food and Agriculture Organization of the United Nations) has a Fisheries and Aquaculture Department which houses more data pertinent here:
FIGIS - Fisheries Global Information System
DIAS - Database on Introductions of Aquatic Species
Atlas of Tuna and Billfish Catches
Global Tuna Catches by Stock
NASO - National Aquaculture Sector Overview
ASFA - Aquatic Sciences and Fisheries Abstract This list of resources may have more information:  Census of Marine Life
Ocean Biogeographic Information System (OBIS)
Global Biodiversity Information Facility (GBIF)
Global Change Master Directory (GCMD)
Marine Geospatial Ecology Tools (MGET)
Satellite Tracking and Analysis Tool (STAT) "
How does the NAICS system worK?,"
Is it something like the Dewey Decimal System for libraries?
My understanding is that NAICS, like Dewey, has first digits for broad categories, then second digits for subcategories, third digits for narrower categories, etc.
Dewey has six or more digits, but only the first three are whole numbers. (There is a decimal point after the first three). NAICs seems to have five or six digits, all whole numbers.
How do I tell where the NAICS numbers start and stop. And if I see a NAICs number like ""511,"" does it mean something like 511xxx, or more like 000511?
",['government'],"The first two are the sector code and are the only digits that are related, so break each digit down individually after the first two. Thats how I visualize them, especially in this sense. Or rather, if I were writing code to read the strings, I would chop them off in pieces like I described: first two are together, everything else is every person for themselves.
NAICS Code Definitions
NAICS Code 91 - Has examples of varying lengths showing it different usage."
How to extract data from web files? [closed],"







Closed. This question needs to be more focused. It is not currently accepting answers.
                                
                            











Want to improve this question? Update the question so it focuses on one problem only by editing this post.


Closed 6 years ago.







                        Improve this question
                    



Looking for some brief information on how to extract data from files on the web? If there are any tutorials or pieces that you know of, it would be great help.
","['metadata', 'data-format']",
How to get all Wikidata items in a country?,"
Using SPARQL I want to show all French embassies in Liberia (spoiler: there is exactly one)
So I wrote this naive query:
SELECT ?item WHERE {
    ?item wdt:P17 wd:Q1014.    # country: Liberia
    ?item wdt:P31 wd:Q3917681. # instance of: embassy
    ?item wdt:P137 wd:Q142.    # operated by: France
}

PROBLEM: It finds zero items. Even though there is such an item in Liberia, more exactly it is located in the administrative territorial entity of ""Monrovia"", which itself has a country value of ""Liberia"".
More generally, I want to get ALL Wikidata items that are in a particular country. How to do?
It must also work if you replace Q1014 (Liberia) with Q183 (Germany), which is even trickier.
","['geospatial', 'wikidata', 'sparql']","This query does the trick:It includes all sub-regions of the country.
It does not show any duplicates."
"How to include sub-classes in a Wikidata SPARQL query? (example: when querying ""bands"", include ""rock bands"")","
Here is my naive query for bridges:
SELECT ?item WHERE {
    ?item wdt:P31 wd:Q12280.  # Item's type is: bridge
}

Problem: It only returns a small fraction of all bridges, because railway bridges (and all other subclasses of ""bridge"") are not counted.
How to retrieve all items, including sub-classes/sub-sub-classes/etc?
It MUST be with SPARQL.
","['wikidata', 'sparql']","The right expression to use here is p:P31/ps:P31/wdt:P279*.Explanation:So, it means instance of this class or of any of its sub-classes/sub-sub-classes/etc.The request becomes:Try this query on query.wikidata.org"
"Any data on average income by district in Seoul, South Korea?","
I would like to access to any data on average income (or average household income or disposable income or whatever other similar statistics) depending on each district in Seoul, South Korea.
If the data includes other districts in other cities such as Daegu or Busan, it sounds amazing.
Is there anyone that knows this kind of data source?
","['data-request', 'income', 'korea']",
Bulk genealogy data,"
I'm wondering if there is a source for bulk US genealogy data (e.g. a database containing ids for individuals and relationships between parents, siblings, children and spouses). 
I know there exist commercial sites like ancestry.com, but they do not expose their data to researchers or developers for analysis.
",['usa'],
Adverse Events Reported Term + MEDDRA coding dataset,"
I just wanted to kindly ask if anyone is aware of the presence of a repository of datasets containing both the Reported Term (usually collected in the CRF as free text by the investigator) and its relative MedDRA coding.
I tried to check the FAERS databases, they could have been my perfect solution, but they don't include the Reported Term, only the coded term from the MedDRA dictionary.
","['data-request', 'openfda', 'medical']","I'm one the many folks working on Open FDA. We've searched across FDA data sets open to the public and, unfortunately, did not identify one that would  meet your requirement at this time."
What is the simplest way to gather twitter data ongoing?,"
I would like it to go into a google sheet. I thought I'd give super metrics a try, but it doesn't return data related to my keyword. I'm using the free trial to try it out.
With SuperMetrics I tried two ways. 1 - I set up my own query and got results. When I refresh it, it clears out the past results. 2 - I used a SuperMetrics template, and when I refresh, the data doesn't refresh - it just shows the SuperMetrics sample data. I have edited the query tweets. the query sheet shows ""results contain sampled data"" but the results are not related to my query.
I want to analyze the data for a non-profit.
Many thanks!
",['uses-of-open-data'],
"Which RDF predicates to use to annotate: fileX ""has hash"" 01ABCF ""of type"" sha256 ""downloaded from site"" http://url/to/page?","
Which predicates to use:
(let's use Turtle syntax)
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix file: <http://domain.I.own/my_rdf_space_for_file_ids/> .
@prefix q?: <predicates and entifies I am looking for>

file:f20160905_00123456
   dc:title ""Example Site with Video"" ;
   q?:downloaded_from ""http://url_to_size/video_xyz12345""
   q?:has_hash [
     q?:hash_type q?:sha256;
     q?:hash_value ""literal_with_hash_value_01234ACBDEF""
   ] .

The more standard/canonical predicates, the better :) 
( @prefix dc: <http://purl.org/dc/elements/1.1/> . ? Schema.org ?).
Use case:

I have url of site of given video, let it be some vimeo video.
URL does not result to file directly
However main content is video
Which I can stream of download in various resolutioms
So I downloades on of those for offline view
And got file with given hash
Now I'd like to make assisting '.ttl' file, with annotation that given hash is hasg of given type and payload comes from site od given url.

","['rdf', 'ontology']",
"Given an EmbaseID, is there any way to programmatically retrieve the abstract?","
Given an Embase ID (= ID to identify a record in Embase), is there any way to programmatically retrieve the abstract of the corresponding research paper? 
","['data-request', 'api', 'medical']",
annotated flower / plant image dataset,"
I'd like to try and build a classification model for plants and flowers pictures, similar to what Daniel Nouri did with his app: http://danielnouri.org/notes/2014/09/13/identifying-birds,-butterflies,-and-wildflowers-with-a-snap/ 
For this I'd need an annotated set of plant and/or flowers (I don't have a definite goal) to start training with. I tried contacting the author, to no avail and I haven't been able to find anything interesting.
Kaggle released a dataset of leaves ""shadows"": https://www.kaggle.com/c/leaf-classification
which can be interesting to work with, but makes the transition from raw picture to classification hard.
Any idea where I could find such a dataset?
","['data-request', 'images']","I finally found exactly what I was looking for : 113,205 pictures of 1000 different plants.
It was curated and is hosted as part of the CLEF competitions held every year, and it is therefore enriched every year through crowdsourcing.http://www.imageclef.org/lifeclef/2016/plant"
Neutral sentiments training set - Resources,"
I'm training a sentiment classifier based on DNN. Currently my training set is made out of 45% positive sentiments, 45% negative sentiments and only 10% of neutral sentiments. As you probably guess, the precision I get is low, especially for the neutrals.
I'm looking for a source where I can create such neutral sentiment corpus. I was thinking about articles but it's too literature language while I'm looking for more 'social language' sentences. I came to think about using Wikipedia's corpus as my neutrals corpus but still I'm not sure it belongs to the profile of 'social language' that I'm looking for. Facebook & Twitter are out of question because the sentences may be positive, negative or neutral.
I'm looking for suggestions for my problem.
","['machine-learning', 'nlp', 'sentiment-analysis']",
"Chance of dying within a year by age, gender, and country?","
I want to get the dataset that shows a chance of dying within a year (or succeeding survival rate) by age, gender, and country?
For example, I want to know how likely the age 20-24, male is alive next year depending on each country.
Is there any dataset that shows it?
",['data-request'],
is there a search class for whether the drug was taken in hospital or not?,"
is there a search class in open FDA Drug Adverse Event Report Browser for whether the drug was taken in hospital or not?
","['openfda', 'medical']",
Case studies on community capacity to use or create open data?,"
I'm looking for detailed and objective accounts of projects etc, that include coverage of the skills and capacities of individuals and community organisations to harness open data. I am interested more in discussions around specific technical and practical skills rather than more nebulous political or institutional issues.
These might be academic papers, organisational reports or longform blog posts.
This is the kind of thing I'm looking for, though accounts of specific projects would also be great:
Johnson, M. P. (2014). Data, Analytics and Community‐Based Organizations: Transforming Data to Decisions for Community Development. I/S: A Journal of Law and Policy for the Information Society, 11(1), 49–96. Retrieved from https://www.researchgate.net/publication/263200235_Data_Analytics_and_Community-Based_Organizations_Transforming_Data_to_Decisions_for_Community_Development

",['education'],
Vending Machine Transaction logs,"
Can anyone help me find/locate/create transaction logs for a vending machine?
How it records or structure sale of the product?
How does it store empty rows?
This is my first post in this forum....let me know if I have missed anything here.
",['data-request'],
Find relative frequency of file or MIME types,"
I want to use Google or some internet search service to gauge the popularity of competing file types or MIME types. Has anyone done this? Any suggestions?
",['data-format'],
Is there a dataset having multiple files and multiple data formats (JSON+CSV+XML) for research purpose etc.?,"
I have been working on data science problems with one format(JSON or CSV).I am planning to explore datasets with multiple data formats. Any links to such datasets would be helpful.
For example:
1) Consists of related data in multiple files and formats such as CSV, Excel, XML, JSON etc.
2) Has both single and multiple records in each file. For example there is 1 file for each patient, or a
file has multiple patient records.
3) Has both single and multiple files for each record. For example, 1 patient record is split across
multiple files.
","['data-request', 'releasing-data', 'uses-of-open-data']",
Crosswalk for State Crime Statutes,"
I have arrest data from a number of cities across the United States and I'd like to make comparisons for the reasons of arrest. In this data, the reason for arrest is the state statute that the arrestee allegedly violated.
Are there resources that provide cross-walks between state crime statutes? I understand that statutes can be pretty different, but it would be very good to know, for example, the statutes that are related to the possession of drugs in different states.
Maybe one way of doing this would be to find a mapping of state statutes to Uniform Crime Reports.
","['data-request', 'metadata']",The reference librarians at a local law library were very helpful:
Binary classification: Datasets in which people make binary decisions about binary outcomes,"
As an example, you might have people looking at photos of skin lesions and saying ""It's a melanoma/It's not a melanoma"" and then in the dataset we also find out whether it was a melanoma or not.
The datasets needn't have a medical context. They could, for example, be student answers to a true/false test.
Ideally there would be a good number of people (50+) making a good number of decisions (10+) but smaller datasets are of interest too. Furthermore, ideally there would be either 100% overlap or a good degree of overlap between the items that are responded to. To take my example from above, it'd be best if the people were responding independently to the same skin lesion photos, rather than everyone seeing different skin lesion photos.
",['data-request'],"Here are a couple sources for binary datasets:Kaggle has a Binary Classification tag. While only one dataset currently shows up under that tag, there are 6 competitions involving binary classification.UIC’s Machine Learning Data Sets has 8 binary datasets."
"Does MIMIC-III have imaging data? If so, how can i access it?","
The MIMIC-III data download consists of csv files. Publications such as http://www.nature.com/articles/sdata201635 mention that reports of imaging studies are available. However, I wanted to know if the images are available.
",['mimic-iii'],"Imaging reports are currently available (as of MIMIC-III v1.3), but the images themselves are not. It is possible that images will be released at a later date, but we do not expect this to happen in the near future due to the challenges of preparing imaging data for release (for example, robust deidentification), as well as resource limitations (for example, researcher and clinician time)."
openFDA: Is There an Open Database of Which Drugs are Approved for the Treatment of Which Illnesses?,"
Is there an open database which lists FDA or EMA approvals of drugs for the treatment of specific illnesses?
","['openfda', 'medical']","Not sure exactly what the question is here.. Yes, openFDA is a database that is free to use, has it's source code on github, and can be queried to find drugs for specific treatments. Part of the api query has a field called ""purpose"" that should be what you are looking for. (Github Profile) https://github.com/FDA/openfda
(API guide) https://open.fda.gov/drug/label/"
LIDAR data for Japan,"
Is there any public or private sources of LIDAR data in Japan? Searching online did not lead me to any sources.
",['japan'],
Is there any international public transport data?,"
I want to create some proof of concept for an international public transport service. Is there any data or an API available that already normalizes this data across multiple countries, besides Google Maps?
","['data-request', 'transportation', 'public-transport']",TRAVIC has a list of public transport service APIs that conform to the GTFS standard: http://tracker.geops.ch/EDIT: I found a couple of more-direct links to GTFS feeds internationally:
Open anonimized ATM transactions dataset,"
I have a hard time to find an open data with ATM transactions. I need to train a machine learning model for detecting frauds. This is my Master theses topic.
I know that this is a very sensitive topic. That's why even the tiniest hint will be highly appreciated.
",['data-request'],
Dataset of hardware benchmarks,"
I want to buy a new computer, but I am limited in money, so I need to decide which components to chose in order to maximise performance. I want to make this choice in most scientific way, so I need some open dataset which will tell how component affect performance. I know, that price depends on performance non-linearly, so I need dataset to determine optimal investing.
","['data-request', 'computing']",
Where to get data list of Corporate Meeting Planners?,"
Looking for an open source data list/link of national and/or corporate meeting/event planners.
","['usa', 'uses-of-open-data']",
Get section and page title from a list of articles in Wikipedia via API,"
I want to get the different sections with their pages from the Wikipedia:Featured articles. 
By following this answer, I know I can get page titles of links as follows:
https://en.wikipedia.org/w/api.php?action=query&format=json&titles=Wikipedia:Featured articles&prop=revisions&rvprop=content

The result looks something like this:
{
  ""continue"": {
    ""plcontinue"": ""5921878|0|Barack_Obama"",
    ""continue"": ""||""
  },
  ""query"": {
    ""pages"": {
      ""5921878"": {
        ""pageid"": 5921878,
        ""ns"": 4,
        ""title"": ""Wikipedia:Featured articles"",
        ""links"": [
          {
            ""ns"": 0,
            ""title"": ""...And Justice for All (album)""
          },
...

However, like that I don't get the section name under which each page/link is. For instance, ""...And Justice for All (album)"" lies under the Music section/header. 
Is there a way to get 
i) the section each page belongs to or 
ii) the pages belonging to a section 
in the same or in a different query?
","['wikidata', 'wikipedia']",
postcode mappings for English/England regions,"
I'm looking for a set of English postcodes where the 'Region' is matched for some mapping in R
I've found a version here: https://www.doogal.co.uk/PostcodeDownloads.php but it's a bit old.
The OS files from Code-Point® Open don't seem to contain this information, the closest they get is area3, but I believe that they are 10 NHS regions:
c(E18000006,E18000005,E18000004,E18000010,E18000002,E18000003,E18000009,E1800000,E18000007,E18000001).
I'm looking for the 9 regions of England.
Does the OS provide such information or can I get it elsewhere?
","['uk', 'postal-code']",The Office for National Statistics Postcode Directory contains:Regions (Former Government Office Regions - GOR)The 9 GORs were abolished on 1 April 2011 and are now known as 'regions' for statistical purposes. They were the primary statistical subdivisions of England and also the areas in which the Government Offices for the Regions fulfilled their role. Each GOR covered a number of local authorities.http://geoportal.statistics.gov.uk/datasets?q=ONS%20Postcode%20Directory%20(ONSPD)&sort_by=name
How to get urls of entries in wikipedia list articles?,"
I am trying to retrieve the URL of all articles listed inside wikipedia list articles. For concreteness lets consider the wikimedia list article List_of_American_scientists
I know how to use the wiki api and the following query gives a decent result:
https://en.wikipedia.org/w/api.php?action=query&prop=revisions&rvprop=content&format=jsonfm&titles=List_of_American_scientists
But the result that it returns is a list in a single string. I will have to parse this string and convert the names to wikipedia urls myself. Is there a better way to retrieve the answers that can directly gives me the urls of the pages? 
","['wikidata', 'wikipedia']","You can use the links API property to get the titles of all the links on the page: https://en.wikipedia.org/w/api.php?action=query&format=jsonfm&titles=List_of_American_scientists&prop=links&pllimit=500. Note that this gives only the first 500, so you will need to make multiple queries to get them all, using plcontinue."
How to access DOL's ETA data?,"
Is there a way to access DOL's ETA data through the DOL's API? I am particularly interested in H1B/LCA and PERM data. 
","['usa', 'labor']",
Where to get usa coastline/shoreline data,"
From where I can collect the USA coastline/shoreline data classified by name. I have the shoreline data but not classified. By classified I mean name of the coastline in different region. e.g.
'Pacific', 'Gulf', 'Great Lakes' ,'Caribe' ,'Caribbean' ,'Atlántico' ,'Atlantic', 'Arctic'
I have collected the tiger data that have those classification but it so much generalized as seen in the below image.
So I need detailed coastline/shoreline (may be USGS) with classification name.

","['data-request', 'usa', 'geospatial', 'data.gov', 'usgs']",
Where can I get list of states of all countries?,"
I need a list of all countries and their states or providences. Is there a authoritative source I can get this from?
","['data-request', 'global']",
Data set for Mcdonalds,"
Searching for any dataset on McDonald's Corporation; it doesn't necessarily have to be recent data. Any data on sales, employee, how they did during promotions, etc. 
","['data-request', 'data.gov', 'releasing-data', 'uses-of-open-data']",
How to Navigate Wikileak Torrents (wlstorage.net)?,"
I can download Wikileak files from either wlstorage.net or file.wikileaks.org but I'm having difficulty identifying the files of interest.
For example, at http://wikileaks.org, you see ""DNC Email Archive,"" and ""AKP Email Archive,"" but I have been unable to match those with an entry for the Wikileaks archives. Dates don't help because the archives all list as 01-Jan-1984.
Am I missing a well-known mapping file to the archives?
","['data-request', 'leak']",
AP Newspaper Membership Records,"
Any data on historical AP (associated press) newspaper membership records (from founding to today)?
","['data-request', 'media']",
"Given start & end dates without year, where can I find average daily high & low temperatures for a given city?","
I'm looking for a simple site that offers daily high & low temperature averages for a given city.  For example, I'd like to get the average high & low temperatures by day for Cabo San Lucas from Oct 1 through Apr 30.
Ideally, it would be via a simple HTTP GET request, like: GET http://somewhere?city=Cabo+San+Lucas&start=0110&end=3004 and return data in JSON or CSV format, like

date,hi,lo
0110,83,74
0210,83,73
0310,82,73
...
3112,78,67
0101,78,67
0102,77,66
...
2904,80,72
3004,80,72

It wouldn't matter which units are given (my example is in degrees Farenheit, but any unit would do).  It would be very similar to http://www.melissadata.com/lookups/ZipWeather.asp, except that it should support international cities and not require postal code.  Ambiguous city names should result in a 400 or similar.
Anyone know of such a site?
","['data-request', 'weather', 'city']",
Sequential Compression Device (SCD) records in MIMIC,"
I am trying to determine if ICU patients were issued sequential compression devices (SCD). Is this information captured anywhere other than the TEXT field in the NOTEEVENTS table within the MIMIC database?
",['mimic-iii'],
openFDA - update notice:: further clarification,"
A little more clarification, please.  I see the Q/A here openFDA endpoints not updated in over 2 months. Has this project been abandoned?
regarding the bug and update status.  
Did the bug and will future fixes also relate to the values of the  tags in the XML provided via download.open.fda.gov?
I have been using that xml to ""automatically"" check whether stuff has changed, and just over the weekend, I noticed that dates that appeared in the LastModified json field within some of the files themselves were newer than the xml tag contents.
Of course the premise of my questions could reveal other confusion.  Any redirection most welcome.  Thanks!
",['openfda'],
House of representatives elections data from 1996-2012,"
Is there an open access source for U.S. House of Representatives congressional district election results in data sets (preferably Excel) for the elections 1996-2012.   I have tried Dave Leip's site uselectionsatlas.org but the cost of getting the data sets needed will cost thousands of dollars.
",['data.gov'],
Sales Tax Data for NYC,"
Sales taxes collected (from retailers) would be a great proxy for general economic activity. Using sales tax data, you could get a rough idea of the revenues collected by retailers in a given area. Since it's tax information, my gut tells me this type of information should be available. Unfortunately, I haven't been able to locate anything like this so far (I filed a FOIL request a few months ago and never heard back). Specifically I'm interested in sales taxes in NYC, but any info on taxes collected in the US could be useful. Any ideas?
","['data-request', 'taxes']",
Medication order in Prescription table,"
Can I know the med schedule in the Prescription table? For instance, one row indicates 'Hydromorphone 20mg vial is used for a patient' but I cannot find the detailed schedule. 
20mg of of hydromorphone is lethal dose and it must have been ordered as something like '2mg PRN q3h' via CPOE, but I cannot find any dose scheduleing. Is there any way to get info regarding the detailed schedule doses? 
Thank you. 
",['mimic-iii'],
Sample datasets for machine learning application in hiring,"
As part of a project we need to explore machine learning applications in candidate shortlisting on applied jobs via job boards.
Looking for sample datasets in the area of recruitment to get started.
Any pointers will be helpful.
","['machine-learning', 'uses-of-open-data']",
USAID Historical Data Access,"
I used to come to this website to get some information about the history of Usaid from its documents. But now I'm not being able to find the place to make the search anymore, isn't it possible to do anymore?
",['usaidopen'],
Where to get basic business info such as address and phone number?,"
I've read a few answers but they all have answers that have broken links or outdated info.
I need to find a way to get very basic information about businesses in the United States.  For example, let's say I want to get a list of all Subway restaurants in the USA.  I need their address, city, state, zip, and phone number.  
At first I thought about using Google Places API for that, but they don't really allow anything on a mass scale like that. 
Is there anywhere this data can be accessed for free? I could always create custom crawler to crawl their public restaurant locator tool, but since I need this information from hundreds of businesses, it would take a very long time and would be a maintenance nightmare since they change their websites or restaurant locator tools often.
This all seems like public information but I guess the question is whether it's available anywhere to be accessed easily.
","['data-request', 'business', 'address']",
Major Flood Events in Indonesia,"
Seeking data regarding Major Flood Events in Indonesia during 2000 - 2010.
Could be GIS or just informational product.
NASA's SEDAC (Socioeconomic Data and Applications Center) does this but only provides tallies and the data ends in 2003
I've also tried the International Disaster Database, however it does not have coverage good enough for my needs.
",['geohazard'],
Fracking Cost per Barrel of Oil,"
I am looking for a historic and on-going source for fracking cost per barrel of oil.  Ideally for the USA with regional and/or State values.  However, larger sources are welcome.
Any ideas?
","['data-request', 'api', 'finance', 'economics']",
World Cup Winners,"
I am looking for a data set that includes World Cup winners, the host country, runners up, etc. I have the winners currently, but would like to see more information. Scores and such for each would also be a bonus!
","['data-request', 'sports']","There is a dataset hosted here: https://www.datazar.com/file/f89abbe09-f107-4ea6-855e-86a9ea9e598f that includes winners, runners up, host country and additional notes for every year the World Cup was played. In a separate dataset here: https://www.datazar.com/file/fdd9b39bb-1a23-4df2-8a3e-d0dba6a3c9fd there is information about scores, attendance and other additional information about each year. I hope this is helpful :)Full Disclosure: I work at Datazar (A collaborative open data Library) where this project is hosted"
Database of Cars in Qatar,"
Seeking a database of all cars in Qatar, by name of car manufacturer and model (make/model). Any other data is helpful, particularly a tentative price list, but not required.
","['cars', 'database']",
National Incident-Based Reporting System (NIBRS) Data?,"
I've read about the National Incident-Based Reporting (NIBRS) data at the Bureau of Justice Statistics site. But I'm not able to actually find the data available for use/analysis anywhere. 
Does anyone know where this data might be available? 
",['data-request'],"You can download the public-use version of the dataset through ICPSR at this page. Make sure to register an account through ICPSR. If you don't have an account, then I highly recommend making one. ICPSR is an awesome repository of social science data."
Fire incidents data,"
I'm looking for a regularly updated list of urban fire incidents in North America or Western Europe, including:

The date of the incident
Address
The type of the building: residential, business, outdoor
Severity

Fires are the city-level issue, so cities are supposed to publish it. However, most cities publish only 311 calls, not 911 calls (except crimes).
The fire datasets I've found so far:

London, UK: http://data.london.gov.uk/dataset/london-fire-brigade-incident-records. Meets all the requirements.
New York, US: http://data.beta.nyc/dataset/fdny-fire-incidents. Outdated (2013).

Besides, fire departments accept FOIA requests for fire incident data (e.g. Chicago) and offer on-demand reports (like San Francisco).
Does anyone know more of the sources like these?
","['data-request', 'city', 'security', 'fire']",
How to obtain airline data,"
I am looking to obtain data on daily (or even weekly) airfares but am not sure if this type of data publicly exists or not. The bureau of transportation seems to have some of this type of data, but the data is all over the place and not in one readily available file. 
Also, would the available data out there probably be only for major airports? 
If this data isn't publicly available would the only feasible solution be to set-up a webscraping program to collect this type of data?
Ideally I would like something like this: 
rita.dot.gov/bts/airfares/compare/airports-metropolitan-area‌​s but instead of quarterly data I would prefer weekly data.
","['data-request', 'web-crawling']",
Quebec Provincial Crown Lands,"
I'm attempting to gather and identify limits of Crown Land in the province of Quebec, Canada.
I'm coming at this from a GIS background and am trying to create a database that resembles the information available on this portal: Crown Land Use Policy Atlas Ontario. Crown land is generally federal land that isn't zoned as urban/developed, agricultural, privately owned, or an environmental protected area.
Since a portal like this doesn't exist for Quebec, I figured that this could be teased out using the following open licensed information and data:

Census Boundaries for Land, Water, and other limits (StatsCan)
Administrative Regions of Quebec (MERN)
Unorganized Regions of Quebec (Wikipedia)
Protected Areas Boundaries for Quebec (NRCan)

I would like to know if there exists either an open licensed shape of crown lands available for Quebec or, alternatively, an open licensed boundary of Resource Extraction Areas (French: Zone d'exploitation contrôlée, or ZECs, Wikipedia), as that is the final piece of information I need to ascertain what is technical ""Crown Land"" from the information I've gathered.
Any advice on the Crown Land identification approach is also appreciated.
","['data-request', 'government', 'geospatial', 'canada']",
Regarding Fortune 500 Companies,"
Are the “Fortune” rankings the same as “Inc”?  Who can file (CEO, COO, CFO, CPA)? Where does one file?  How are financials verified?
",['data-request'],
TV viewership data,"
I'm looking for a dataset of TV viewership or ratings over different networks/shows. Specifically I need this for NBC's broadcasting of the Olympics. I've found various articles discussing numbers for different days, but not a single dataset covering all days. Online streaming numbers would also be useful, but not expecting any structured dataset around this. 
",['data-request'],"Here is a dataset containing viewership and rating numbers by day for the first week of Olympic games in Rio this year. It also contains data from London 2012 for comparison. https://www.datazar.com/file/fcf5766ab-2c8a-4ced-8b4b-a7381d9cab09I feel that it will be much easier to find more ratings like this, if not more extensive ones, in a few weeks or so.Full disclosure: I work at Datazar (A collaborative data library where), where this file is being hosted."
How to be resourceful in finance data science area?,"
can I ask how to be resourceful in finance/banking data science area, here? What I mean being resourceful means, knowing top data science trending in finance/banking area, knowing what are the creative companies doing in finance/banking area with data science, knowing major open data sources can be used in finance/banking in Canada. Right now I am subscribing to several data science news but none of them focus on finance/banking area. If I could get daily/weekly news report related to data science development in finance/banking area will be great. My manager in the mid-term feedback for my internship suggested I should be more resourceful, so I really want to improve as fast as I could.
Any suggestions? Thank you very much!
",['finance'],
Global Fiber Optic Data,"
Are there any Open data sources for fiber optic cable locations.  Specifically sub-sea.  I've been searching online and unable to find anything, besides paid services.
","['data-request', 'telecom']",I went with this one.  http://www.cablemap.info/ has current and future cables.  Data can be downloaded as shp and kml.
Data on cultural diversity dimensions,"
I am looking for data on cultural differences across nations (regions), specifically:

Power Distance
Individualism vs collectivism 
Uncertainty avoidance
Long-term orientation
Personal Achievement (Masculinity vs Femininity)
Loose vs Strict
Universalism vs particularism
Time Accuracy
Directness vs indirectness

","['data-request', 'research', 'demographics', 'global', 'social-process']",
"What are the most common issues with data cleaning (e.g. outliers, duplicates)? Who has data sets that need to be prepared for analysis?","
When preparing data for analysis, I often encountered issues such as outliers, data entries that are logically inconsistent (e.g. age=150/age=-2), duplicates (that are not exactly equal) etc. When integrating data sets from different sources, there might not be a unique identifier oder data entries follow different standards (e.g. US vs. United States), which makes matching hard. 
What are the issues you experience most commonly when working with data? 
","['data-request', 'releasing-data']",
"Will open data foster a common set of ""metadata"" standards?","
This is just one example, but I'm sure that there can be many others.
Government open data will have links to all the relevant license information, which will be found in the metadata. That represents an information ""standard.""
Does this apply only to ""open data"" produced by the government, or are such standards mandated for privately gathered open data sets as well?
More to the point, is there, or will there be a push for ""non"" open data sets to source e.g. licensing information in the same, or similar fashion?
",['metadata'],"Our hope with the Frictionless Data project is to create a set of standards that apply equally to open and non-open datasets.  These standards did, in fact, grow out of experience with distributing open data.Check out the Data Package spec here: http://specs.frictionlessdata.io/data-packages/"
Historical Summer Olympics Medal Counts?,"
Anyone have a file/group of files containing medal counts by country over time? The past few aren't hard to get, but before that I'm not sure.
","['data-request', 'sports']",
Twitter - Labelling system for sentiments and other things,"
I have build a program that log tweets from stream by hashtag into a MongoDB database and a website to label them.
The website loads a random tweet and allows me to label them with three buttons (Negative, Neutral, Positive). My goal was to make a huge database of tweets and labels for machine learning purpose. 
I was wondering if putting it online/making it available, others will find it interesting and allow them to classify tweets to add to the data. I don't want to build a full website that no one will use. I was thinking about give it as an open source platform.
Do you think this project is interesting? Is it worth finishing it? 
As I store the full tweet I thought that in the future I will allow different classification e.g. (Pos, Neutrale, Neg / Categories ex: US. Politics, etc.) and people will be able to build a training set off of it, for example Negative/Positive tweets about location (browsing tweets with geolocation) etc.  
In the future, maybe give incentive for people to rate them, add advertisement to finance it maybe. For example a tree learning for label questions (Ex : Categorie ""US. Politics"" -> ""Is it about Hillary Clinton ?"" -> Is it positive ? ... a bit like akinator)
Any comment / critic / encouragement / support is welcome.
I hope I was clear in my explanation and that I am not off topic on this forum.
","['releasing-data', 'machine-learning', 'sentiment-analysis']",
what are the best ways to build / scrape an open-sourced data set of a retailer type (e.g. tobacco retailers?),"
I'm a public health epidemiologist, and this question has come up in a number of contexts. I've heard tell of people using Google or Yelp for limited uses, but we'd be building state-wide datasets of certain retailers for public health questions. 
As a specific example, a tobacco policy nonprofit I work with has been purchasing a business list, updated every year, at significant cost. They use their own coding to guess tobacco retailers from that generic business list (gas stations, pharmacies other than CVS, grocery stores, stores with ""smoke"" or ""tobacco"" in their names, etc.) for likely retailers. They then compute density measures, visit a sample of stores to validate them, do store surveys that inform policy, etc. But the same could apply to questions like parks, food deserts, etc.
Historically these datasets were prized and pricey possessions. Moving forward I have a half-dozen projects interested in moving to open-data solutions - not just for money reasons, but for keeping data current, living ""live"" on user-generated data, for instance. But specific APIs (google, yelp, etc.) have APIs that generally limit bandwidth. Has anyone had luck with specific databases / APIs more than others, or with reaching out to companies to ask for ""public benefit"" arrangements?
","['data-request', 'geospatial', 'api', 'releasing-data', 'business']",
Where can I find a database of scholarships?,"
I'm looking for an open database of scholarships to download. It seems that many of the scholarships sites like to keep their info under wraps so you'll use their site. 
",['data-request'],
Audio Datasets Featuring Different Speakers Saying the Same Sentence (English)?,"
Seeking a dataset of audio files consisting of recordings featuring different people saying the same sentence in English for deep neural network (DNN) training and testing.
","['data-request', 'language', 'audio']","The speech accent archive:uniformly presents a large set of speech samples from a variety of
  language backgrounds.As for English, the following subset contains the sentences:Please call Stella.  Ask her to bring these things with her from the
  store:  Six spoons of fresh snow peas, five thick slabs of blue
  cheese, and maybe a snack for her brother Bob.  We also need a small
  plastic snake and a big toy frog for the kids.  She can scoop these
  things into three red bags, and we will go meet her Wednesday at the
  train station.It stands under a Creative Commons License. It is described in The Speech Accent Archive: towards a typology of English accents, Steven H. Weinberger  and Stephen A. Kunath.The ELSDSR (English Language Speech Database for Speaker Recognition) is another choice. It is not so open directly, but you can ask for the full version. It contains voice messages from 22 speakers (12M/10F), and the age covered from 24 to 63. You can find a few .wav on the example page.On a funnier note, requiring a little more work, Peter Sellers Reads The Beatles’ “She Loves You” in 4 Different Accents."
Get coordinates form TMC (Traffic Message Channel) location codes,"
I'm just getting started working with TMC (Traffic Message Channel) data and I'd like to know how to use the location codes to get coordinate data for points. Is there a mapping somewhere I could use? I'm considering using traffic data from TTWN for the US.
","['geospatial', 'traffic']",
mean/median age for each US zip code,"
I need a table that will map each US zip code to either the mean age or the median age of the population in that zip code.
I see that https://www.census.gov/popest/data/counties/asrh/2015 provides estimates of this data at the county level.  I am ok with estimated data, but I need to be able to look up the data by zip code.
Alternatively, perhaps there is a way to get the info from the census demographic profile (http://www2.census.gov/census_2010/03-Demographic_Profile/), but I haven't been able to figure it out.
","['us-census', 'demographics', 'postal-code', 'database']",I did a quick export of data from the 2014 5-year ACS of the population and median age of every ZIP code: https://www.dropbox.com/s/utnthc601i82iff/census.csv?dl=0
How does the U.S. government prioritize open data gathering?,"
One way is in response to what I call ""demand,"" or ""traffic."" That is, people ask more questions about the weather than about education, so ""weather"" gets a higher priority in data gathering.
Another way is what I call ""mandate"" (by department). That is, the health department is tasked with gathering data about various diseases, the education department will have a comprehensive database about all educational institutions, and each department will gather all relevant data that falls under its mandate, etc. That is what I call a ""Dewey decimal"" approach to data gathering, where pieces of data are gathered according to ""maps,"" each piece of data is considered to have comparable importance to others, and the various departments all have similar budgets.
Which of these models more accurately describes the data prioritization process? Or could it be a ""blend"" of the two, or even a ""third"" process that I haven't covered.
",['data.gov'],"I do not think there is a definitive answer for this; not that it doesn't exist, rather because no one in government has that much oversight/incite to give you a complete overview/opinion.  The mandated model is overwhelmingly the majority of models in place, but the demand/traffic model is growing; ""data-driven"" to use the buzzword of the day, is being adopted/modeled across the board, from federal to local departments/agencies.  Regarding which more accurately describes the prioritization process, they seem to go back and forth. Mandating places a clear priority on data; when mandated, the data is required to be gathered. The demand/traffic model takes a back seat here, however other forces can/could/will be at play unbeknownst to outsiders: pressure to release demanded data from citizens (FOIA, etc.), pressure from superiors to release demanded data, etc. Demand/traffic model levels the playing field with the mandated model when the dataset/department decides to simply open said data by default. For example, a department can significantly reduce FOIA costs/overhead/etc. by examining the history of the FOIA's they receive. Releasing the most popular FOIA'd datasets proactively (open by default) places a ""mandate"" (no pun intended) on said datasets that is equal to datasets under the mandated model.  Essentially, its a blend of both, with mandated taking a much larger share (historically), but demand/traffic growing, as well as leveling the playing field."
Intelligence quotient (IQ) data based on birthdate and/or other factors,"
Where can I find raw intelligence quotient (IQ) data, ideally with age/birthday/etc? I followed the links in the answer to IQ scores from individuals and their siblings and/or twins but nothing there appears to be helpful.
I've found and read several studies that discuss IQ-to-birthdate correlation, but many of them refer to previous studies, and I can't find the original studies and/or the actual raw data used by those original studies.
",['education'],
Where can I find university/college addresses for the entire world?,"
I need to make an address locator to associate my data set to universities. In order to do this I need reference data that has the university addresses everywhere in the world. Can someone direct me toward a database with all the universities and colleges found across the world?
","['data-request', 'education', 'global', 'address']",
"Product data (Images, nutritional, ingredients, descriptions etc.) for vitamins & supplements","
Where can I find product data (images, nutritional data, ingredients, descriptions etc.) for vitamins & supplements? I have the UPCs.
In the electronics and consumer products there are few providers, cannot find for the vitamins & supplements.
This is needed for a commerce site.
If there is no provider, is there another way that is recommended to semi automate the information gathering.
",['data-request'],
download Great Britain boundaries as shapefile for GIS,"
I am looking for a shapefile (readable e.g. in QGIS) which only contains the Great Britain boundaries. In other words, I only need the island/s boundaries.
I have already checked and downloaded the 'Boundary-Line-GB' from OS Open Data (https://www.ordnancesurvey.co.uk/opendatadownload/products.html) but the shapefile has been showing also the GB regions' boundaries (which I don't need).
Any suggestion on where I can download it for free?
",['geospatial'],"I found it here: https://census.edina.ac.uk/easy_download.htmlJust click on InFuse Great Britain, 2011 and select the shapefile format. Direct link for download: https://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/infuse_gb_2011.zip"
How can I access open data for non-U.S. governments?,"
If I wanted to access US government open data, I would go to data.gov.
What would I do for other countries such as Canada, the UK, or Germany? Is there a master list of open data websites for at least the major countries?
",['data-request'],"Disclaimer: I work for OpenDataSoft which is behind Open Data Inception project.Open Data Inception is a project that aim to give a master list and a master map of every Open Data Websites. The data have been both gathered by us and crowdsourced.There are other similar project if you prefer, Open Data Websites by the OKFN, OpenGeocodes, and tons of Github accounts listing datasets and databases.Cheers"
Recent statistics for average percentage of first-generation college students at 4-year institutions?,"
I am looking for recent statistics on the average percentage of students at 4-year institutions who are first-generation.  This is for a grant I am writing for a summer program intended to focus on recruiting talented 1st-gen STEM students.  I found exactly the graph I want with data up to 2005, but I think the numbers have increased a bit.  Here is what I found:

in this report (see p. 7):
http://www.heri.ucla.edu/PDFs/pubs/TFS/Special/Monographs/FirstInMyFamily.pdf
But here is a clip from the New York Times (""First-Generation Students Unite"",
by Laura Pappano, April 8, 2015) which makes me think the percentage is a little higher now:
""Of the 7.3 million full-time undergraduates attending four-year public and private nonprofit institutions, about 20 percent are the first in their families to go to college. While the number has ticked up as college-going has increased over all, the proportion has actually declined from 40 years ago, when 38 percent were first generation, according to the annual U.C.L.A. survey.""
Now, I trust the NYT article, but I would feel better directly citing the UCLA study they mention.  I'm guessing it's a continuation of the plot shown above, because that report is on the UCLA domain.  But I haven't been able to turn it up, and wondered if anyone here could point me in the right direction.  Thanks in advance!
",['education'],"You can find the data here -: https://www.datazar.com/project/p2e01002e-e9e4-48bc-9b04-2afbea7a817eand the data dictionary can be found here -: https://www.datazar.com/file/f0957f34a-c87a-4317-bff2-8c99e980468aP.S- I work at @datazar which is an open source data library, where people can view, share and work with data."
Traffic/roadworks record for Greater London,"
I am looking for a dataset which provides a record of roadworks operations in and around London. Alternatively, I might be able to make use of a log of traffic/congestion much like what Google maps provide for road trips. Please let me know if you are aware of such a record.
","['data-request', 'uk', 'traffic']","You can find the data here -:https://www.datazar.com/file/fc210d5e3-f0a6-489a-9fe0-e06f3da140cbP.S - I work for datazar, an open data library, where people can share, discover and work with data."
A sample historical online trading data to download?,"
I am working a part time project (a hobby project) and I am looking for some data dump for historical online trading data. By trading data I mean the online trade that goes on in like Wall street and other financial markets. I tried to look for such a data but all I could find was stock data which is not what I am looking for.
Does anyone know from where can I download(preferably as a csv or excel format data) a sample of such online trading data?
","['data-request', 'finance']",
Gold standard dataset for entity recognition in email,"
I'm looking for an annotated dataset for named entity recognition and classification which I could use as a gold standard. Preferably I'm looking for an email dataset, something like Enron (though I couldn't actually find a version with named entity labels anywhere). However other informal text would also do.
",['machine-learning'],
Does MIMIC-III have patients with atrial fibrillation & knee osteoarthritis?,"
Do you know if the MIMIC-III database includes patients (in parcticular their free-text notes, medications & demography) - that have either atrial fibrillation,  knee osteoarthritis or closely related diseases?
",['mimic-iii'],
Problem submitting form in XML format - Can we submit it in CSV format?,"
We registered a dataset on the Development Data Library (DDL) website, and in the form we said that we planned to submit it in XML format, but we are having problems converting the dataset to XML.  Can we submit it in CSV format?  Do we need to resubmit the form?
",['usaidopen'],
how to download database from united nations website [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 4 years ago.







                        Improve this question
                    



i need to get database for translation system and the UN databases provide what i need in the web page but i don't know how to download it?
how can i download database from united nations databases that contain translated words from English to Arabic?
thanx
","['data-request', 'uses-of-open-data', 'database']",
News events around the world,"
Is there a website/ API that can tell you the number of news articles that talks about a specific country? For example the number of news sources about Brazil ought to be extremely high (Olympics) right now.
It would be great if there was a read count on it as well (like reddits up and down voting of news), but I can do without it.
","['api', 'global']",
What are the current most challenging MNIST-like tasks aiming to achieve the lowest error rate?,"
For example there is the MNIST database which is used to test ANN, however it's not so challenging, because some hierarchical systems of convolutional neural networks manages to get an error rate of 0.23 percent and the same with other OCR tests.
Therefore OCR datasets are 'no longer perceived as an exemplar of ""artificial intelligence""'wiki.
Are there any similar equivalent image-recognition tests, especially these which have the most challenging tasks with dataset which are commonly used as benchmark tests to challenge the AI which are fairly reliable and they're possible to pass (e.g. by humans), but most AAN are struggling to achieve the lower error rate?
","['data-request', 'ai']","I'm not sure if this is what you're looking for, but I've recently published the HASYv2 dataset. It contains 369 classes and 168233 recordings in total. The best classification result I could get was about 82% accuracy.The data is extremely similar to MNIST. For more information, I recommend reading the paper. But if the paper doesn't answer questions, feel free to ask me :-)"
Solved Programming Challenges Dataset,"
I'm looking for a dataset of solved programming challenges, like the ones on http://codeeval.com. The dataset should have the natural language description of the problem and N solutions for each problem, possibly in different programming languages. 
An API for extracting this kind of data from some programming challenges site would fit too.
","['data-request', 'api', 'nlp', 'programming']",
"Berlin, Germany building data set","
I am working on building foot print comparison.  I would like to know the open data sets available to compare.
I found the OSM  data from goefabrik: http://download.geofabrik.de/europe/germany/berlin.html 
","['data-request', 'images', 'germany']",
Vasopressor and antibiotics in MIMIC3,"
I think I noticed an issue, but not sure whether it is correct.
It looks like the administration record of antibiotics/vasopressor are found in the PRESCRIPTION table. However, I discovered that the table is only about CPOE entry, and not about whether the certain drug was really administered. For instance, I cannot find the trend of doses of norepinephrine infusion in the table.
INPUTEVENTS_MV has the data of real-time administration. (for instance, a row in the table might tell you that a patent was given 5ug/hr of vasopressor between 7-9 pm). However, I cannot find anything about med administration in INPUTEVENTS_CV (only fluid administration).
My understanding is that INPUTEVENTS_MV is for patients who visited the hospital after 2008 and INPUTEVENTS_CV is for 2001-2008. My question is whether the only option for me is just to use the data after > 2008 if my research requires the trend of vasopressor administration?
",['mimic-iii'],
How does open data differ in quality depending on the source?,"
Let's talk about government data, e.g. data.gov, first. Putting aside ""outliers,"" are most government data sets guided by e.g. ""mandates"" by the government? If not, how does the fact that say weather, vs. health data are put out by different departments affect difference in quality? Is British or German data quality likely to be either much better or worse than U.S. data?
As between open data from government versus private sources, does the quality of private sector data ""converge"" to best practices set either by the government or private parties? Or is it ""all over the map?""
Data quality can be defined in many ways, but one that I am particularly interested in is metadata standards between various types of databases.
","['data.gov', 'best-practice', 'metadata']",
Highly periodical time series datasets?,"
I'm looking for a highly periodical time series dataset. Mainly, this is what I am looking for:

Periodic time series. No preference over the frequency, it can be annual, monthly or even daily.
The time series can be fine even in case it is periodical in some parts of it but not periodical in general
At least 100 observations would be nice
The dataset should be free to use to everyone and publicly available.

","['data-request', 'time-series', 'seasonality']",
Attacks on refugee homes in Germany,"
I'm trying to find reliable data on attacks on refugee homes in Germany/Poland in recent years. I know that there were several projects initiated to collect such data, however so far I can't find the output anywhere. All suggestions are welcome.
There's a badly maintained (not consistently formatted) table on Wikipedia: Liste von Angriffen auf Flüchtlinge und Flüchtlingsunterkünfte in Deutschland 2015
There's a project bei ZEIT which collected cases, but afaik never published the data: Es brennt in Deutschland
Are there any other official/community-driven data bases? 
I don't want state-level aggregates
","['data-request', 'geospatial', 'germany', 'terrorism']",
"Data about olive fruits, oil, pomace","
I would like to get the large data set of polyphenols content and antioxidant activity in olive fruits, oil and pomace. Ideally from different countries. Is anyone aware if such data is available? 
",['data-request'],
Where can I find data on school holidays in Spain?,"
I am currently looking for historic data (last 15 years) on school holidays in Spain on comunidad (Spanish ""state"") level. Anyone has an idea where I could find such information?
",['calendar'],
US Urban Areas 15k+ in KML?,"
Anyone know where I can get a KML of US urban areas with a population of 15k+?
","['geospatial', 'us-census']",
Seeking a food product taxonomy,"
I am needing to develop a product taxonomy for foods and beverages that would work across multiple food providers. I need this to provide a code hierarchy for mapping specific products in a categorical fashion, e.g.
Large Latte -IS-A-> Coffee Beverage -IS-A-> Beverage
Double espresso -IS-A-> Coffee Beverage -IS-A-> Beverage
The only thing that I've found so far is a USDA Food Group dictionary that has some high level categories.
So, to be clear, in response to the confusion I seemingly have caused others trying to help, I'm looking for a code-dictionary that provides hierarchical (taxonomic) categories of food products typically found in restaurants. 
","['food', 'restaurant', 'categories']",
MIMIC-III: How the patients take their prescriptions exactly?,"
For example, there are three prescriptions for a patient named Jam:
prescription 1: Drug A, startdate: 2016-08-01, enddate: 2016-08-08,
prescription 2: Drug B, startdate: 2016-08-03, enddate: 2016-08-09,
prescription 3: Drug C, startdate: 2016-08-05, enddate: 2016-08-09.
In my understanding, Jam will only take drug A on the first two days (08-01 to 08-02), and then he will take both drug A and drug during 08-03 to 08-04, then he take three drug (A, B, C) until 08-08. On 08-09, he will take B and C.
Am I right about the meaning of startdate and enddate of one prescription?
Or otherwise the later prescriptions will replace the prior one which means that Jam only takes drug B during 08-03 to 08-05 and he only takes drug C during 08-08 to 08-09?
Someone has any idea about the correct explanation?
",['mimic-iii'],"Active prescription orders: 
Drug (A): 08-01 to 08-02
Drug (A, B): 08-03 to 08-04
Drug (A, B, C): 08-05 to 08-08
Drug (B, C): 08-09Keep in mind that the prescriptions table is a record of medications that were ordered. It does not indicate whether or not the medication was administered.  This data is extracted from a Computerized Physician Order Entry ('CPOE') system."
US Universities and colleges with city/town state?,"
Is there any database or list that has the major US universities and colleges with the city/town, state they are located in?
","['data-request', 'usa', 'city']",
Find Density and/or Height of a Storm Cloud in a given Location,"
I'm looking for a place that can provide either Historical or Current information about clouds. I'd like it to provide information about the Density of a cloud and the Height of a cloud - this would specifically apply to storm clouds. I've found that some API's provide cloud cover but this does not contain such information I need.
",['weather'],
Load NSF Research Award Abstracts in Python or R,"
I want to work on NSF Research Award Abstracts 1990-2003 Data Set in R. Every record of the data is stored in a text file and text files are grouped in folders (See data files here)
Is there any easy and straightforward way to load the NSF data in Python or R?
","['programming', 'python']",
Pokemon Go Data API,"
I wanted to know if anyone knows of a website that provides free information related to Pokemon Go. I am creating an application. I'm interested in the following:
Pokemon stats
Pokemon location
Information teams
Any other values that provide the site

",['api'],
Looking for extensive world population time series including both data and estimates,"
Does anyone know of a source for whole-world population data, including extrapolated estimates for the times before whole-world demographic records are available?
",['demographics'],
openFDA endpoints not updated in over 2 months. Has this project been abandoned?,"
We are specifically interested in the ""Devices › Adverse Events"" data which until recently seemed to get updated monthly, usually within 2 weeks of the end of the month.  We realize that this is a beta project, but would like to know when we can expect updated data to be available?
",['openfda'],
Pasadena - Mobile sightings data,"
US Department of Transportation is offering different data sets for research on mobility. Unfortunately, one of those data sources, have been removed because ""US DOT currently does not have the rights to distribute this data set""
https://www.its-rde.net/data/showdf?dataSetNumber=10055
Does anyone know is this data set available elsewhere?
BR
Toni
",['data-request'],
UK lookup table for Postal Code (explicitly),"
Is there any lookup table for UK which translates the MSOA(middle layer super output area) codes into the Postcodes division (i.e. EI2 XXX, where XXX can be anything else). 
I have found lookup tables which match every postcode to MSOA but grouping the postcodes in greater divisions seems to be a real headache as they are not clear enough(for instance Scottish postcode and English may be belong to the same MSOA but their postcode totally differ since one may start with ""S"" and the other one with ""E"").
P.S. if it is LSOA or other geography domains please do not be discouraged to include.
","['uk', 'postal-code']","The UK Data Service has files containing every single postcode and the broader geographical boundaries to which it belongs, including the MSOA (and LSOA) you are looking for. They include plenty of other geographical units - perhaps the most comprehensive set of units available.More details can be found in the User Guides (for example here for February 2015 edition)."
Historical (pre-war) data on cities and towns in Germany,"
What I do:
I'm trying to find and merge city-level data from various time periods:
~1900, ~1930 and ~1990. I already have data on election outcomes, and a few related measures.
What's difficult:
Obviously some cities merged, new places were founded after 1900, and again others are in nowadays Poland or France. 
I am mainly interested in finding data on population densities and further demographics, but would need to know in detail whether some data point pertains to exactly the same unit of observations. 
Example: Older data might have an entry for ""Ebingen"" in Baden-Württemberg. In 1975 Albstadt was founded and Ebingen bekame a part of Albstadt so more recent data will have Albstadt not Ebingen, but Albstadt also contains other places.
What I need:
Is there any public dataset available that provides

provides information on such changes,
provides pre-war demographics, and ideally
links pre-var town names to today's municipality-IDs (GKZ)?

If there's data fitting only one of these points I'm grateful too.
","['city', 'historical', 'census', 'germany']",
Hospital infection data,"
I am looking for hospital infection data sets for modelling purposes: time series about infections such as MRSA, VRE, etc. The data set should contain incidence/prevalence time series in a hospital ward and admission/discharge data.
Is there any available data set like this?
","['data-request', 'medical', 'time-series']",
"Are there datasets of latitude, longitude, and a land/water indicator?","
This is a related (on a lower level) to my other question. Are there any open datasets that contain latitude, longtitude, and an indicator of whether or not the point is land or water? The resolution doesn't need to be that fine (maybe 0.01 decimal degrees?).
There are some datasets that work with ocean coastlines, like the NOAA data, Natural Earth, or Landscan, but the latter is proprietary, and I don't think the first two include all water. Just oceans, from what I can tell.
If data like these are available, my plan is to create a connected graph of latitude/longitude ""water cells"" and use that and a shortest path algorithm to create an extremely rough estimate of distance between two points.
EDIT: I should clarify that I'm interested in a dataset that's worldwide, not just for one specific country or body of water.
","['geospatial', 'transportation', 'global', 'land-cover']","You can search for a ‘global water mask’Here is one at 250m resolution from the Global Land Cover Facility (GLCF) at the University of Maryland based on data from the MODIS satellite:http://landcover.org/data/watermask/citation: Carroll, M., Townshend, J., DiMiceli, C., Noojipady, P., Sohlberg, R. 2009. A New Global Raster Water Mask at 250 Meter Resolution. International Journal of Digital Earth. ( volume 2 number 4)"
Difference of implementations of the SQL standard in different relational database management system (RDBMS),"
I am looking for a dataset that comparing the difference of implementations of the SQL standard in different relational database management system (RDBMS).
Ideally, it should contain the list of rows such as:
SQL feature ID, SQL feature name, SQL feature standard, MariaDB, MySQL, Oracle    
0, CHARACTER_LENGTH, 1992, yes, yes, no
1, FETCH FIRST, 2008, no, yes, no

I am aware of some free-text resources such as http://troels.arvin.dk/db/rdbms but I am looking for some more machine-readable format.
",['data-request'],
Visualizing what airlines fly in the US Airports,"
I am interested in understanding which US airports are used by various airlines.  One could visualize this with a spreadsheet:

​
​
This examples shows that Southwest flies out of Midway, but not O'Hare.  Delta flies out of O'Hare, but not Midway.  Both fly out of Baltimore.
I'm wondering if there is a clever way to tease out a matrix from openflights.org.
A spreadsheet would be preferable although, I suspect that if the data is out there, it is stored in a RDBMS.
",['uses-of-open-data'],
what is the exactly relationship between the diagnoses priority and the treatment in MIMIC-III?,"
What is the exactly relationship between the diagnoses priority and the treatment in MIMIC-III?
The website mentions:

SEQ_NUM provides the order in which the ICD diagnoses relate to the patient. ICD diagnoses are ordered by priority - and the order does have an impact on the reimbursement for treatment.

in the diagnoses_icd table in MIMC-III.
I want to know how the priority impact the treatment exactly.
Does the diagnoses with HIGH priority (seq_num with large number) will be treated as the major (the most important) diagnoses or the one with LOW priority (small number)?
",['mimic-iii'],"I want to know how [how] the priority impact[s] the treatment exactly.The ICD codes are used for billing and do not impact treatment. This is an important point to understand when carrying out research using databases such as MIMIC.[Is] the diagnoses with HIGH priority (seq_num with large number) treated as the major (the most important) diagnoses or the one with LOW priority (small number)?My understanding, based on conversations with nursing staff at the hospital, is that the first number in the sequence (seq_num = 1) generally indicates the primary diagnosis, which is often the reason for admission. The order of later codes in the sequence (seq_num = 2+) has less significance and indicates additional diagnoses relevant for billing."
"Are there any APIs that find the shortest sea distance between two points, given the latitude and longitude?","
Searching online turns up websites like this one, which can return the shortest over-water distance between two ports, but I'm looking for something more general. Are there APIs or datasets that would allow me to calculate the shortest over-water distance between two points, given the points' latitude and longitude?
From what I've read, this is non-trivial to implement using Google Maps and the Google Maps API.
","['api', 'geospatial', 'transportation']","There are free data sets available for distances between ports:
www.nauticalcharts.noaa.gov or
msi.nga.milAlso you will find some providers that give you distances between ports depending on AIS data like marinetraffic.com.If you look for an API that gives you the shortest path between two coordinates on sea, there is AquaplotDisclaimer: I am the co-founder of Aquaplot."
Where is the real beginner's guide,"
I am trying to learn something about how APIs work. I was told that DOL has the best API and supporting documentation in the federal government.
So here I am, on page 1 of the beginner's guide, and find this completely contradictory information:
Result Format
By default, the DOL V1 (api.dol.gov) API's responses are in XML format. To receive the data in JSON, send an ""Accept"" header with ""application/json.""
Result Format
Data.dol.gov sends responses by default in JSON format. To customize the return format, simply add /format/xml or /format/json to the request URL.
What on earth is going on here?
","['api', 'programming', 'labor']",
Water Pollutant or Contaminant Dataset,"
I am looking for any water dataset for pollutant or contaminant in water (like mercury, arsenic, etc) and I need the dataset include data of ph, do, ec, orp, and temperature as well. Where I can find those things?
I haven't found a relevant dataset.
",['data-request'],
"Team-sport play data, in particular ball passes","
I am looking for game-play data of any team sport which include ball passes between players and who passed the ball to whom. Ideal games include (with order of importance) basketball, handball, football (soccer), lacrosse, rugby, American football, hockey. Volleyball is not acceptable because it limits the number of passes.
","['data-request', 'sports']",
Time series data on construction cost,"
I am looking for some time-series data on construction costs in Australian property markets. 
Ideally the data would have information including city, property type (industrial, residential, etc), and $/sqm. Any relevant data would be welcome, even if it isn't specific to Australia.
","['data-request', 'time-series', 'prices']",
Need list of cities/municipalities of Germany along with population density,"
I need a list of cities/municipalities/towns/districts of Germany with their associated population density. Is there any free API providing that or a free database?
","['data-request', 'germany', 'population']",
Are doses in inputevents_mv correct?,"
Just trying to get some drug doses out from mimic-iii but having a little trouble making sense of the data.
I'm trying to find the doses of morphine sulphate given to patients in their first day but the ""amount"" column seems to be out by a factor of 1000.
Looking at inputevents_mv.row_id being 9902. It states that Morphine Sulphate was given as an infusion at 10mg/hr for 6 hours and 13 minutes. I expected the amount to be 62.167mg yet the ""amount"" column reports that as 0.0621670036 with a unit of measurement (amountuom) being ""mg"".
The same occurs for all patients - some of them have been given 0.002 of a mg of morphine which again isn't really an actual dose. It's far too homeopathic for adults. 
Is it safe to presume that all morphine doses are out by 1000? What about other drugs?
Best Wishes,
-Ahmed :)
",['mimic-iii'],
Dataset of documents and user libraries,"
I'm looking for a decently sized dataset (more than 100k docs) which consists of bag of words documents along with a list of users where associated to each user is a list of those documents the user has in his or her library.  Or even better, where associated to each user is a list of ratings that the user gave to those documents they viewed.
Does anyone know of such a dataset?
I'd really like to get my hands on the Mendeley DataTEL dataset, but they won't respond to my emails.
","['data-request', 'nlp']",
Where can I find data set of tweets of users? [duplicate],"







This question already has answers here:
                                
                            




Twitter open datasets

                                (7 answers)
                            

Closed 7 years ago.



I am doing a project ""Emotional prediction of user based on tweets"", using data mining techniques. For this purpose, I need a data set of tweets of users.
Please help.
","['data-request', 'machine-learning', 'nlp', 'social-media']","It's against Twitter's policy to provide datasets of more than user and tweet IDs.However, as lots of people are tweeting every day, you can construct your own dataset using the twitter api: https://dev.twitter.com/rest/publicThere are many guides on how to mine tweets, for example: https://marcobonzanini.com/2015/03/02/mining-twitter-data-with-python-part-1/"
Non-ASCII Unicode symbols with their word equivalents,"
I am looking for a dataset containing Unicode symbols with some word equivalent.
Examples:

©: copyright
€: euro
√: square root 

","['data-request', 'nlp']",
Where to find ATM/branch cash replenishment dataset?,"
Where to find bank ATM/branch cash replenishment dataset? It should have daily data for deposited money, withdrawals, opening balance, and closing balance columns.
","['data-request', 'time-series', 'bank']",
Downloading wikipedia data from specific url,"
I want to download data from Wikipedia page
I am a rookie at this and can'T find any relevant articles. Most of them are on downloading full Wikipedia. I need just one specific URL data.
","['wikidata', 'wikipedia']","Copy/paste into spreadsheet tool? If you are doing it once, why get any more complicated?http://pastebin.com/raw/bKAFbReVOr, https://www.google.ch/search?q=wikipedia+table+to+csv"
"Where can I find a database with indexes, equities, forex, etc?","
Where can I find a dataset with indexes, equities, forex, etc for, at least, the last 10 years? The more data the better :)
","['data-request', 'finance']",
find all renault garages in France,"
I need to have all the addresses of Car-dealer [occasion] and mechanics
in France.
How to achieve this - how to obtain the data?
[out:csv(::id,::type,""name"",""addr:postcode"",""addr:city"",""addr:street"",""addr:housenumber"",""website"","" contact:email=*"")][timeout:300];
area[name=""France , Allemagne etc... ""]->.a;
( node(area.a)[amenity=Car occasion - Renault];
  way(area.a)[amenity=Car occasion - Renault];
  rel(area.a)[amenity=Car occasion - Renault];);
out;

Any and all help will be greatly appreciated.
","['data-request', 'geospatial', 'transportation']",
Dataset of judicial decisions in France,"
I am looking for datasets containing judicial decisions in France.
","['data-request', 'legal', 'france']",
Pharmaceutical firm data,"
I have a query regarding pharmaceutical data. As part of my Ph.D. in Health Economics, I am interested in research questions such as the impact of mergers, competition, etc. on the pharmaceutical industry or firm innovation let's say.
Could you please suggest to me where I can access firm-specific pharmaceutical data to address the above type of research questions?
",['data-request'],
How do we query the college score card and just get all data but only for a given year?,"
When querying the college score card, data for all years are returned, how do I query to return all data for a given year?
","['data.gov', 'collegescorecard']","Instead of querying the API, you can download the raw CSVs for each year: CollegeScorecard_Raw_Data.zip. There are occasional variables with all missing values that you may need API calls to fill in, however. "
"Where is the ""MIMIC-III Waveform Database""?","
Can somebody help to clarify that if there is such thing as  ""MIMIC-III Waveform Database"" that is available for downloading? or this is the same thing as the mimic II waveform data available from here? 
https://physionet.org/physiobank/database/mimic2wdb/
I understand that the linkage between waveform and clinical data is not available for MIMIC III? but I am looking for the waveform database itself.
",['mimic-iii'],
Scraping data from a PDF in HTML - table recognition,"
I have a simple looking table in a pdf file: one column containing company names. I don't know how many there are in each group but groups are separated by a bold line (the lower border of a table).
In Python2.7 I have used pdfminer.HTMLConverter to get HTML from the PDF document.
I need to say how many company names are in each group.
The HTML from the PDF does not include any tags which I associate with HTML tables i.e. < table >, < tr >, < td >. 
There is no link to a CSS file. What information is there about the table in the HTML?  
","['python', 'opencorporates', 'html']",
Looking for Hotel prices dataset,"
I am looking for a dataset of hotel prices, I am couldn't find any public dataset. Anyone to have an idea on where can I find these information ? 
",['data-request'],
is there data sets for emojis?,"
I am looking for research data on emoji.  I found a real-time data source that I could scrape myself but I am wondering if someone already scraped the twitter firehose http://emojitracker.com/
","['nlp', 'social-media']",
Library methods with date of introduction,"
I am looking for a dataset containing a list of libraries with the methods they contain and the date or library version when each method was introduced/changed.
Example: the method pandas.io.sql.read_sql in the pandas library was introduced in pandas 0.12.0 (release date: 2013-07-24).
","['data-request', 'computing']",
Where is a lookup table for rail stations in ERPC – Eastern Railroad President's Conference Codes?,"
I have a data set with rail station information that is in ERPC for all the stations. It would be great to find a lookup table to translate these into actual station names.
Currently, the only reference I can find is in the documentation for a product called PC Miler
http://www.pcmiler.com/support/Guides/PCMILER_GeocodeFilesReferenceGuide.pdf
There are some definite rules on how they form the ERPC code: 1. Max of 9 characters 2. all spaces removed 3. Saint/Fort always translated to ST or FT
Here are some examples of the rail station names and how they translate:
Fort Worth becomes FTWORTH Cunningham becomes CUNNINGHA
In some cases it obvious what city is being referred to and in others it is not.
","['data-request', 'usa']",
Football (Soccer) player physical data (weight and height) over time,"
Is there any open dataset of physical data (e.g. weight and height) of elite football players in european leagues over time (the last 15 years)? 
","['medical', 'football']",
How can I deploy a sci-kit learn model when the data in use are .csv files?,"
I am dealing with accelerometer data (csv) as well as audio data stored in FTP server coming from an android app. Data is loaded from FTP in my notebook for exploratory analysis to extract features from both type of files, i used libraries such as PyAudioAnalysis and Pandas. My aim is to understand the process of deploying the model i am gonna build later while keeping in mind that i rely heavily on csv files for the training.
","['machine-learning', 'csv', 'audio', 'python', 'accelerometer']",
"If Wordpress is an appropriate tool for loading open data into a system's front end, what would I use for the backend?","
This question was inspired by this one.
I want to load open data into the backend of my system. That is, I want the data to be accessible to my developers, but not the public. I was told by an IT professional that I need an ""FTP"" (file transfer protocol). Is this correct? If not, what is the appropriate tool?
",['tool-request'],"Wordpress is the backend of Wordpress sites.
You can use an FTP connection, but you do not have to have one.
I run WordPress blog, and various installations for clients/development on my server, which has been configured to run PHP (WP is (mostly) PHP). I can log into my wp blog at http://mywpblog.com/wp-admin which is public facing, but only pre login.
Boring (and archaic!) details of my setup, but as you can see I don't need/use an FTP here.  Wordpress offers many solutions (including hosting, development, etc.), as well as can be configured to offer any variety of others...my point is, you don't necessarily have to have any one thing to do this, except for Wordpress.  "
"What is a ""featured site"" in the context of open data?","
Is open data a government initiative or are there non-government sites such as Project Gutenberg that are part of open data? How does a ""featured site"" work? Is it somehow linked to data.gov, or does it operate independently?
",['data.gov'],"While open government initiatives are often led by governments and their agencies, non-governmental groups are participating in open government programs. Resources: 
https://www.whitehouse.gov/open
http://www.opengovpartnership.org/"
Small Sample of Clickstream data,"
I am looking for a sample of web traffic or click stream data set, please let me know sources from where I can get the sample data?
",['data-request'],
Federal Reserve - Tremendous amount of data,"
In the world of stock and hedge funding, does there exist, for instance, a way to gather a tremendous amount of data on the price of wheat from 20 years on the stock exchange (For instance, on Wall Street stock)? In fact, I'd like to treat, statistically, the price of a stock product, but I don't know where we may find out that type of data.  
In the James Simons's discussions (A rare interview with the mathematician who cracked Wall Street), Simons explains that ""The real thing was to gather a tremendous amount of data -- and we had to get it by hand in the early days. We went down to the Federal Reserve and copied interest rate histories and stuff like that, because it didn't exist on computers."" (Time : 11:26), but where is that Federal Reserve?
",['data-request'],"If you can program, I would pull data from the Yahoo finance API.
Otherwise, eoddata seems to have what you are asking for. 20 years of end of day data in a number of file formats."
Finding central line placement date on MIMIC-III Dataset,"
I'm trying to find a record on MIMIC dataset showing that a patient being placed with a central line (aka central venous catheter) and I need this information only for CLABSI patients (i.e. diagnosed with ICD 9 codes '99931', '99932', '99933', '99662', '9993’). Here are the tables I looked and the problematic things about them:
-Procedure_icd (Dictionary table: D_icd_procedures): Contains the most through information. I checked the icd 9 code 38.93 (Venous catheterization, not elsewhere classified). Among 1300 total CLABSI patients, 1039 of them has a record in this table. However, there is no date and caregiver information (who placed the central line) in this table, so we cannot use this table.
-CptEvents table: I found out that the CPT codes for central line placement are 36555-36771. Among 1300 total CLABSI patients, only 261 has a record in this table.
-XEvents tables which uses D_items table as their dictionary table (ChartEvents, DatetimeEvents, InputEvents, etc.): I searched D_items table to find the codes for central line placement. I found 158 different codes. (Eg: 117;""Catheter Insert Date"", 5442;""pic line placement"", 4476;""PICC line placement”). Among 1300 total CLABSI patients, chartEvents and DatetimeEvents tables have the most record with 429 total unique patients, but none of these tables have more than ~250 records. 
Why most of the patients do not have a record about being placed with a central line? Am I missing some codes/not looking at the correct place, or is it just missing data? 
Thanks
",['mimic-iii'],
Dataset of English Poetry,"
Is there a dataset containing a group of poems in English? I couldn't find any resource online. I could web scrape poetry sites, but I want to avoid copyright issues and even a dataset of older poems would do
","['data-request', 'language', 'english']","To ensure public domain poetry, you can use Project Gutenberg. In particular, they have a ""Bookshelf"" specific to poetry. With some exceptions, Project Gutenberg is mostly English.You can download all of Project Gutenberg, with their Harvest site. See here for more details - downloading with wget.Probably more useful is to use a wrapper library like Python's Gutenberg. In this case, you would feed a list of e-book IDs (e.g. 12924) from the Bookshelf link to a python code, then download all the TXT data.Other languages have wrappers, too."
How would I get data on people with disabilities?,"
How would I get U.S. data on people with disabilities? I want the total number tracked (however defined), and also broken down by disability,e.g. blindness, deafness, etc., on a state by state basis, if possible.
","['data-request', 'usa', 'disabilities']","Quandl has a database called Social Security Administration, which has data on number of disabled workers, but it unfortunately doesn't show the disability eg. blindness or deafness and the data isn't broken down on a state-by-state basis. Check it out here: https://www.quandl.com/data/SOCSEC/DISABWORK-Social-Security-Beneficiary-Data-Disabled-WorkerIf you're interested in regional sales of hearing aids, though, or any other products for those with disabilities, you can search for the product name in the search bar at https://www.quandl.com and see what results show. For ""hearing aids"", for example, check out the following databases: https://www.quandl.com/data/FRED?keyword=hearing%20aid
https://www.quandl.com/data/OECD?keyword=hearing%20aid[Disclosure: I work for Quandl]"
"Secondary schools Ireland, UK & Finland","
Does someone know where to find the contact information of all the secondary schools of Ireland, Finland and UK? I am researching for schoolnames, place, e-mail and post adress. I found already some schools, but I am still missing a lot of schools.
So far I have found these lists: https://en.wikipedia.org/wiki/List_of_schools_in_Northern_Ireland
https://en.wikipedia.org/wiki/List_of_schools_in_Finland
","['data-request', 'education', 'uk', 'ireland']",
Filter in Get Request from DOL data,"
I am trying to filter my search on the DOL API to capture only observations meeting a particular criteria. In addition, I will need to skip some observations.
This is the code I am using below. Number 1 works, but when I try to introduce a filter, as in number 2, I get an error. Ultimately, I would like to include both a filter and skip.
1)  
msha_api <- GET(""http://api.dol.gov/V1/Mining/FullMineInfo/MSHA_mines/?Key=xxx&$skip=100"", accept(""application/json""))
2)  
msha_api <- GET(""http://api.dol.gov/V1/Mining/FullMineInfo/MSHA_mines/?Key=xxx&$filter=PRIMARY_CANVASS eq 'Coal'"", accept(""application/json""))
Any advice/help on how to go about including both a filer and a skip in the DOL API call?
",['labor'],
Precomputed Eigenfaces,"
I know how to compute eigenfaces from a faces dataset, but before doing it, I'd like to know if there is some precomputed eigenfaces dataset. 
So, instead of downloading thousands of faces (for instance, from the FERET dataset or the LWF dataset) and applying eigendecomposition, I could get some (say, the top 100) eigenfaces (+ average face) directly, like the image below. 
For now, I don't care from which dataset they are extracted. Also, my goal is to generate random faces from linear combinations of eigenfaces, not to do face recognition.

","['data-request', 'images', 'faces']",
Looking for geospatial .shp files with specific format,"
While reviewing this piece of work I found out I need a file with a specific format. I don't happen to have those laying around and I wouldn't know where to get one either.
I'm looking for a .shp file, content doesn't matter. Attributes should be:
ID
IDsub
ValueSum

What kind of data is this and where do I get a file to test the code on?
","['data-request', 'geospatial']","content doesn't matter.Shapefiles (.shp) come in sets of files - you should have at minimum a set of 3 files with the same filename and different extensions - a .shp, .shx and .dbf (there may be others alongside). The attributes are stored only in the dbf file, specifically it's dBase IV format, so if the actual content in terms of the shape doesn't matter, you can just edit the dbf file. As lots of applications can write out dBase IV (although it's a bit old!), you can get any shapefile and just edit the .dbf to contain the attributes with the names that you want. I'd refer to this other question for recommendations on .dbf file editing. What kind of data is this [...] The attributes you've listed don't look like any specific standard of data I recognise, but spatial datasets are very variable, it might not be any kind of standard or known open dataset. But sounds like that's maybe not important to you. where do I get a file to test the code on?Like Mike Dolan suggests above, USA tiger datasets are available as shapefiles. Or (as I see from your profile you're in the Netherlands) here's some shapefiles you can download of the Netherlands: http://www.eea.europa.eu/data-and-maps/data/eea-reference-grids-2/gis-files/netherlands-shapefile."
Opinion surveys about specific tax rates,"
I'm interested in data from public opinion surveys that have asked people about tax policy in terms of specific tax rates about specific levels of income (or other taxable quantities, like inheritance amounts).  That is, I want data from surveys that have asked questions like ""Suppose a person earns $100,000 a year.  How much do you think that person should pay in income taxes?""  (Or, alternatively, ""How much do you think that person should have left after paying income taxes?"")  I'd be okay with multiple-choice answers if they were fairly granular (e.g., ""less than $10,000"", ""$10,000-2000""), although I'd prefer data where respondents could give any number they liked.
There are three things I specifically want to avoid (and which are present in tax-policy survey data I've seen so far).  One is asking people only about their own situation (e.g., ""How much tax do you think you should pay?"").  Another is asking only about broad socioeconomic categories that are not defined by actual numbers (e.g., ""How much should a lower-class family pay?"").  The third is asking for opinions only in relative terms rather than in terms of actual numbers (e.g., ""Do you think people earning more than $250,000 per year currently pay too much in income tax, about the right amount, or too little?"").  That's why I'm interested in questions that use specific numbers for both the hypothetical income level and the hypothetical tax burden.
I'm looking for opinion surveys from the USA, although I'd also be interested in data from other countries for comparison, or in data from segments of the US population (e.g., individual states).
","['taxes', 'survey']",
Veteran employment statistics,"
I'm looking to find a source of data for employment statistics regarding veterans and transitioning military personnel. Specifically, how many new veterans and transitioning military enter the workforce per month, states where they end up settling, and the industries they end up working in.
I appreciate any guidance you can provide.
","['usa', 'labor', 'military']","the National Center for Veterans Analysis and Statistics is a good general starting spot for knowing what data is available about veterans. The ""reports"" page there includes some higher level data about Veteran employment, income, and poverty status. However, this is mostly aggregate and historical data.Generally, the source for monthly employment information (not limited to veterans) is the Current Population Survey. The CPS makes a special data collection about veterans every August. (Technical documentation for the August 2015 Veterans' Supplement) The main page for data and reports from the Veterans' Supplement is http://www.bls.gov/news.release/vet.toc.htm  As far as I can tell, the CPS only publishes annual counts of veteran employment status, and that page only has 2015 data, and for one table 2014/2015 comparable statistics.Getting access to bulk data from the Current Population Survey is complicated, and not something I'm very expert in. You might be able to get historic data from DataFerrett, but you have to be able to run Java applets in your browser, which is increasingly difficult to do for security reasons. (This answer on the Open Data SE has some more about getting DataFerrett to run.)It looks like this big, um, colorful page from the National Bureau of Economic Research (NBER) provides direct access to download the data -- you'd be looking at the ""August"" column.Another source for historic CPS data is IPUMS -- here's their page about the Veterans supplement but IPUMS is pretty complex also.If all of this seems harder than it ought to be, I'd agree. You might consider trying a local library, where reference specialists are often available to help with this kind of research. The Census also organizes networks of State Data Centers and Census Information Centers who are often good resources for this kind of thing."
Unemployment benefits coding in U.S. SIPP data,"
I'm having a good deal of trouble navigating the data dictionary for variables in the U.S. Census Survey of Income and Program Participation (SIPP). Here's a specific puzzle I've been unable to solve:
I'm looking for data on an individual's receipt of unemployment benefits. However, there are at least two different variables with the same label in the core wave files:
euectyp5        byte   %15.0g      euectypm   GI: Receipt of State unemployment comp.
er05            byte   %15.0g      er05l      GI: Receipt of State Unemployment Comp.

And the variables do not have equivalent values:
. ta euectyp5 er05, mi

 GI: Receipt of |
          State |       GI: Receipt of State
   unemployment |     Unemployment Comp. (ISS
     comp. (ISS | Not in Un        Yes         No |     Total
----------------+---------------------------------+----------
Not in Universe |   416,059          0          0 |   416,059 
            Yes |         0      3,746      1,790 |     5,536 
             No |       316          0          0 |       316 
----------------+---------------------------------+----------
          Total |   416,375      3,746      1,790 |   421,911 

(This is all from 2008 Panel, Wave 1, but appears to be true in other waves as well. Have not checked other panels.)
The only thing I can think to do is to cross-reference with the questionnaire to determine what each question was actually asking, but the questionnaire itself (as downloaded here) does not actually have these variable names in the file. I started trying to read the 400-page questionnaire to deduce where each were coming from, but this was unsuccessful, not to mention unbearably tedious because the questions are full of stuff like [fill OTHSRCE_ARR(<33>):l](33) and other such macros that it is hard to track down the meaning of.
What am I missing? What is the difference between these variables: and, more generally, how do I go about figuring out other such puzzles when the variable names do not actually match those in the questionnaire and the questionnaire is so hard to read?
UPDATE:
I also wrote the census, as Albert recommended. they wrote back immediately and very helpfully. Here is the complete response:

The structure of the EUECTYP5 and ER05 variables can be confusing. 
EUECTYP5 covers the entire reference period.  So, respondents who have
  a 1 in this field have received state unemployment compensation at
  some point during the four-month reference period. 
You can see this in the question for EUECTYP5 on page 7-189, from the
  data dictionary, SIPP 2008 Panel Waves 01-10 - Core Data Dictionary,
  available here: 
  http://www.census.gov/programs-surveys/sipp/tech-documentation/data-dictionaries/data-dictionaries-2008.html
  Did ... receive any state unemployment compensation during the
  reference period?
ER05, however, is a monthly variable.  So, it records receipt or
  non-receipt in each month.  It appears on page 7-229 of that same data
  dictionary.  Did ... receive income from State unemployment
  compensation in this month.
Usually, you could also see this in the universe statements, but
  unfortunately, there is an error in the EUECTYP5 universe statement
  posted in the data dictionary.  It should read All persons 15+ at the
  end of the reference period.
The ER05 universe, however, is correct as posted: All persons 15+ at
  the end of the reference period indicating receipt of State
  unemployment compensation sometime during the reference period.
  (EUECTYP5 = 1)
So, the ER05 recipients are a subset of EUECTYP5 recipients. 
  Respondents who received unemployment compensation in all 4 months of
  the reference period will have a ""1"" for both ER05 and EUECTYP5 in all
  4 months of a wave.  But, respondents who only received UC in one
  month will have ER05 and EUECTYP5 = 1 in that month, and will have
  EUECTYP5=1 and ER05=2 in the other 3 months of the wave. 
As far as trying to figure out variable names from question fields, it
  really depends on the variable you are looking at and the section in
  which it appears.  For some fields there is a pretty easy one-to-one
  correspondence between the variable and the relevant question.  For
  others, however, it isn't as clear what the connection is.  
I suggest looking at the user's guide, data dictionary, and user's
  notes, as you have been doing, and then writing in with questions. 
  We're happy to help in whatever way we can.

","['usa', 'us-census', 'census']",http://thedataweb.rm.census.gov/pub/sipp/2008/l08w11d.txt
Ground truth dataset,"
I need to check the quality of my causality inference algorithm, so i want to check it with a dataset in which the causal relationships are already given. Is there a particular place for me to look at? 
Edit :   
Example of a dataset :
X1 X2 X3
1.0 2.0 3.0
2.0 3.0 4.0  
The columns are the variables . I want to have a dataset like that with given causal relationships between the variables
",['data-request'],
Is there any dataset for images which contains each object name?,"
Is there any image dataset which has labels for image itself and also includes  labels for every object in that image? I need a dataset which is publicly available. 
","['data-request', 'images']",
"Where can one find reliable, canonical (geo) data for Germany PLZ (postal zip codes)?","
Does anyone know please: Is there a reliable, ""official"" list of postal codes and cities (additional data like lat/long welcome) in Germany, available for download?  At a minimum, I'm looking for the PLZ (5 digit zip code) and city/location name.
","['germany', 'postal-code']",
priority roads data,"
Is there any data source for priority roads(: roads which are indicated to have priority with a traffic sign on site, overriding the 'priority to the right' rule) excluding OpenStreetMap?
The bigger the coverage, the better.
Sadly, OSM almost only contains this tag in some European instances, having a total of 10k OSM ways tagged as priority roads worldwide.
http://wiki.openstreetmap.org/wiki/Key:priority_road
","['data-request', 'geospatial', 'transportation', 'traffic']",I used to work in this field and this data for any large geography is not available from an open source that I know of. I know at least three private companies that hold such data.
"Is there a geo-referenced directory of hospitals, labs, providers and their network affiliations for the US and Canada?","
Is there a geo-referenced directory of hospitals, labs, providers and their provider network affiliations for the US and Canada? I would prefer a dataset that has both street address and lat lon, but street address will do.
","['geospatial', 'medical']",
Machine readable format to report results of randomized control trials,"
Results of randomized control trials are typically reported in free text contained in a PDF or HTML. Are there any proposal of machine readable format to report results of randomized control trials (RCTs)?
","['medical', 'data-format']",
"Chinese demographic data (age, gender)","
I am on a quest to find areas in China with disproportionate gender and/or age distributions.
I don't really care if these areas are defined by political boundaries. 
Since map-making is largely illegal in China, I'm not having a very easy time finding rich, open data sets. Any guidance would be appreciated.
","['data-request', 'demographics', 'population', 'china']","The official stats page of China has a table with gender per political region, in Chinese, with the data you are looking for (source is Wikipedia Sixth National Population Census of the People's Republic of China)http://www.stats.gov.cn/tjsj/ndsj/renkoupucha/2000pucha/html/t0102.htmGoogle translationAdditionally, the UN data portal has gender data for China from the 2010 census. You have to select China, 2010, and then with ""More filters"", select Male and Female. This will give you age and gender groups, but not geographical."
OutPan Question,"
I have managed to build a VB.Net app to look up UPC/EAN codes on OutPan, but cannot get it to accept my attempts to add new items. My url is ...
https://api.outpan.com/v2/products/9300617041207/Cadbury+Crunchie?apikey=[MyAPIkey]
Clearly, I have this malformed. Can you tell me what is wrong?
Jeff Law
",['barcodes'],
Open database with incidence of diseases by their ICD-10 codes?,"
Is there an open database that gives links ICD-10 codes with the prevelance of the diesease they represent?
",['medical'],"One realistic way to get what you're looking for is to get a large set of de-identified clinical claims, with ICD-9 codes (there aren't yet many large sets with ICD-10), aggregate to calculate the distribution per specialty, and then use an ICD 9 to 10 mapping to get approximate ICD-10 distributions.Another option is to consider the fact that the distribution of codes, especially with ICD-10, is such that in every specialty there is a short tail of very common codes, and then (many) codes that almost never happen. Starting with lists of the most common codes per specialty can be a good start to approximating this (I'm assuming you're looking for a-priori numbers to train a classifier/ranker, so approximation is reasonable):
http://www.nuemd.com/icd-10/common-codes
http://htpnmarketing.com/icd10/resources/top-25-icd-10-codes-by-specialty/Good luck, and please share if you find a better or more accurate data source."
"How does a company upgrade open data to the point where it is proprietary, or copyrightable?","
Ideas and facts are not ""copyrightable."" But original expressions of ideas and facts are.
What are ways to upgrade open data so that copyright can be obtained on the database? Things that I can think of include formatting, presentation, aggregation, analyzing, etc.
What have users done with open data to make it sufficiently ""original"" in this way? For instance, does upgrading the data to five star data (linkable to other people's data) qualify?
",['uses-of-open-data'],
"A few datasets: IP4/6, MAC, Cell ID","
I'm looking for all or either of these datasets:

MAC addresses with some additional info such as geo, may be something else
all IP4 and IP6 addresses with some additional info such as geo, may be something else
WiFi addresses or names of spots with probably MAC addresses and some additional info such as geo or frequency, may be something else
cell IDs with some additional info such as geo, may be something else

Either of these datasets can be splitted into small ones from different providers and I don't mind assemblying it myself. Preferably a dataset, not an API webservice, although if there's no other option....
Your suggestions?
","['data-request', 'geospatial']",
Semantic dictionary of English language,"
I am looking for a dictionary of English words tagged with their semantics. Like:
red      t:color
green    t:color
long     t:size     t:max
huge     t:size     t:max
tiny     t:size     t:min
hot      t:temp
cold     t:temp
...

","['nlp', 'english']",
Where can I find open database with food product names and their calories?,"
Searching for open data with food products and their calories and nutritional values?
",['food'],
Where do I find data of all companies in this world?,"
In sites like facebook, a user can add his work position by typing few words and selecting the company
How do they get that data and how can I get that data so our users can also add work position the same way ?
","['data-request', 'data.gov']",
General Debate in UN General Assembly,"
I'm looking for general debate transcripts of UN General Assembly. Recent years (2011-2016) can be found here. But is there a way to get data before 2011?
I found there is a United Nations documents search service, but I don't know how to use it.
",['address'],
"Average monthly weather data by city, over the world?","
I'm searching for any website or dataset that provides average monthly weather, such as highest and lowest temperature, humidity, and number of rainy days, by city over the world (major city).
For example, the dataset that consists of the following:

Highest average temperature

City | January | February | March | ...
Seoul | 8.3 | 9.3 | 11.5 | ...
Hong Kong | 15.5 | 18.3 | 23.6 | ...

Lowest average temperature

City | January | February | March | ...


Is there any website or dataset that provides them? I don't like a website that you must dig up all the cities one by one, like the following (which you can find many, many on the Web). I mean, I want to get all the cities directly in comparison.
","['data-request', 'api', 'weather']",
"Race, cross-race, and cross culture tolerance data","
Where can I find since done per-country data on people's attitudes towards people of other race and/or culture living within the same country and children of mixed race living within those countries.
I would like to see some polls, perhaps with a listing of which countries are overall more accepting of these differences and which are more opposed to it (within-country variation data would also be appreciated).
Interesting to see whether age is a contributing factor as well. Other factors would be interesting as well.
P.S. As a result of the recent BREXIT results, this post should be of global concern I suppose.
","['data-request', 'linked-data', 'wikidata', 'state', 'database']",
Randomized control trials with budget,"
I am looking for a dataset containing a list of randomized control trials with their budget.
I am aware of https://clinicaltrials.gov and Cochrane Central Register of Controlled Trials (CENTRAL) but the budget isn't mentioned (perhaps it is for some exceptions?).
","['data-request', 'medical']",
Supermarket Product Data [duplicate],"







This question already has an answer here:
                                
                            




Where can I find a downloadable grocery store food ingredient database / data set?

                                (1 answer)
                            

Closed 7 years ago.



We are looking for super market product data that includes:

Food products
Ingredients
Nutritional values
Price

Any suggestions on how to find this information? I'm a non-tech person and have found this a big challenge! 
","['data-request', 'food']",
Australian Crime Data,"
Is there a place that I can get Australian crime data? I was hoping to get a database (or at least be able to crawl such a page) where it is in the format of: [date, incident, location].
The closest that I got to was the Institute of Criminology which has aggregated data and some figures http://www.aic.gov.au/statistics.html. There is also this map: http://crimetool.bocsar.nsw.gov.au/bocsar/ which is clearly querying some database, but I don't know of the API or where the database is.
","['data-request', 'crime', 'australia']",
Where to find Rule based classification data,"
I was wondering whether I could find any rule based classification data. In the sense I want a data where the output classification is done based on rules.

Example:
Let F1, F2, F3 be 3 numerical attributes and Y being the output column with classes (0, 1). Say Y value will be 1 if and only if (F1 > 0.6 or (F2 > 0.7 and F3 < 0.01)) else the value will always be 0.

Can I find data sets with rules defined for classification?
",['data-request'],
Where to find medical related data?,"
I am wondering where to retrieve medical related data, particularly those related to Tropical Medicine? It would be wonderful if anyone can suggest where to find these:

A collection (I mean thousands if not hundred of thousands) of parasite and parasite ova images.
Medical corpus related to medical parasitology or medical microbiology focusing on Infectious Tropical Diseases.

","['nlp', 'medical', 'images', 'biology', 'disease']",
I get 'certificate verify failed' URLError when trying to download data from openFDA,"
I'm using Python and pandas to try to download the data in the FDA's 'Adverse drug event reports since 2004'.
Here is my code:
import pandas as pd
import json
from pandas.io.json import json_normalize
my_api_key = '..(my API code which I requested)...'
from_date = '20040101'
to_date = '20041231'
url = 'https://api.fda.gov/drug/event.json?api_key=' + my_api_key + \
    '&search=receivedate:[' + from_date + '+TO+' + to_date + ']'
print url
json_df = pd.read_json(url)

Here is the traceback on the error:
https://api.fda.gov/drug/event.json?api_key=.....&search=receivedate:[20040101+TO+20041231]
---------------------------------------------------------------------------
URLError                                  Traceback (most recent call last)
<ipython-input-47-dcb3adcfb254> in <module>()
      3 #TODO: This is not working.
      4 # URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:590)>
----> 5 json_df = pd.read_json(url)

/Users/billtubbs/anaconda/lib/python2.7/site-packages/pandas/io/json.pyc in read_json(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit)
    185     """"""
    186 
--> 187     filepath_or_buffer, _, _ = get_filepath_or_buffer(path_or_buf)
    188     if isinstance(filepath_or_buffer, compat.string_types):
    189         try:

/Users/billtubbs/anaconda/lib/python2.7/site-packages/pandas/io/common.pyc in get_filepath_or_buffer(filepath_or_buffer, encoding, compression)
    306 
    307     if _is_url(filepath_or_buffer):
--> 308         req = _urlopen(str(filepath_or_buffer))
    309         if compression == 'infer':
    310             content_encoding = req.headers.get('Content-Encoding', None)

/Users/billtubbs/anaconda/lib/python2.7/urllib2.pyc in urlopen(url, data, timeout, cafile, capath, cadefault, context)
    152     else:
    153         opener = _opener
--> 154     return opener.open(url, data, timeout)
    155 
    156 def install_opener(opener):

/Users/billtubbs/anaconda/lib/python2.7/urllib2.pyc in open(self, fullurl, data, timeout)
    429             req = meth(req)
    430 
--> 431         response = self._open(req, data)
    432 
    433         # post-process response

/Users/billtubbs/anaconda/lib/python2.7/urllib2.pyc in _open(self, req, data)
    447         protocol = req.get_type()
    448         result = self._call_chain(self.handle_open, protocol, protocol +
--> 449                                   '_open', req)
    450         if result:
    451             return result

/Users/billtubbs/anaconda/lib/python2.7/urllib2.pyc in _call_chain(self, chain, kind, meth_name, *args)
    407             func = getattr(handler, meth_name)
    408 
--> 409             result = func(*args)
    410             if result is not None:
    411                 return result

/Users/billtubbs/anaconda/lib/python2.7/urllib2.pyc in https_open(self, req)
   1238         def https_open(self, req):
   1239             return self.do_open(httplib.HTTPSConnection, req,
-> 1240                 context=self._context)
   1241 
   1242         https_request = AbstractHTTPHandler.do_request_

/Users/billtubbs/anaconda/lib/python2.7/urllib2.pyc in do_open(self, http_class, req, **http_conn_args)
   1195         except socket.error, err: # XXX what error?
   1196             h.close()
-> 1197             raise URLError(err)
   1198         else:
   1199             try:

URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:590)>

Any ideas on what this is caused by or how to fix it?
","['openfda', 'api', 'json', 'python']","I'm not sure what underlying HTTP packages pandas uses, but I found that the default settings of the requests package in python does not work with SSL and this site:gives an error like:But if you add verify=False to the options, then it works correctly:Requests can also ignore verifying the SSL certificate if you set verify to False. (source)Probably you can then import requests and then use this line of code:"
Individualized heart beat data linked with heart disease,"
Do you know of any open data set recording individualized heart beat time series as well as occurrences of heart diseases?
I am thinking of something like a database from health monitoring wrist bands coupled with an indication of whether and when the person wearing the band was affected by some common heart diseases.
If none are available, I would still be interested in any individualized data from health monitoring wrist bands linked to some record of medical conditions.
","['data-request', 'medical']",
Where can I find some open datasets of biological data and biomedical informatics data?,"
I am looking for open biological datasets and open open health informatics datasets, to test some machine learning algorithms that I designed.
Specifically, I am looking for datasets in which each element has a binary label (e.g. true/false, dead/alive), or a real valued label (e.g. score=0.7/1), to run some supervised learning approaches.
Can anyone send me to any open datasets of this kind? 
","['data-request', 'medical', 'biology']","From the University of California-Irvine (UCI)  Machine Learning Repository.  On this landing page, there is a link out to all datasets on the upper right.     "
Are there any examples or best practice for encapsulating large open data sets into R packages?,"
I've recently been experimenting with UK government open data with R, and it seems like I could usefully wrap up some of my work into an R package. 
I'd want the package to download the data either as an installation step or the first time the user wants to use it, rather than include it directly in the package.
Are there any examples of or guides for this kind of R package?
","['releasing-data', 'uses-of-open-data', 'programming']",
Is there a newspaper or online magazine with a REST API for article comments?,"
I wonder whether there is a newspaper website or an online magazine that has a REST API for querying articles, but also for fetching comments from the readers. Not comments on scholarly information, but comments on current events.
For which media outlet can this be done without web scraping, just with a few API requests?
This could be useful for text mining (sentiment analysis, and categorization, user analysis).
I'm only familiar with the Guardian API and the API of ""Die Zeit"" (a German weekly)
Can I use one of Facebook's APIs for this (I think some newspapers recently decided to become, somehow, embedded inside Facebook)?
","['data-request', 'media']",
Injuries caused by celebratory gunfire,"
I'm looking for a dataset containing injuries caused by celebratory gunfire, if possible with:

datetime
location
victim's demographics
shooter's demographics
type of weapon


What I've found so far:
Ordog, Gary J., Peter Dornhoffer, Greg Ackroyd, Jonathan Wasserberger, Michael Bishop, William Shoemaker, and Subramanium Balasubramanium. ""Spent bullets and their injuries: the result of firing weapons into the sky."" Journal of Trauma and Acute Care Surgery 37, no. 6 (1994): 1003-1006. http://www.ncbi.nlm.nih.gov/pubmed/7996596

People often celebrate holidays by firing guns into the air without realizing that this can cause serious injury or death. The present study identified 118 patients treated since 1985 who were hit with spent bullets. Most (77%) were hit in the head. The mortality rate was 32%, which is significantly higher than for all gunshot wound victims in general seen at the same medical center. Laws have been enacted to help prevent people shooting into the sky, but more education and enforcement are required to prevent these serious and preventable injuries.

http://www.cdc.gov/MMWR/preview/mmwrhtml/mm5350a2.htm :

Bullets fired into the air during celebrations fall with sufficient force to cause injury and death (1). However, few data exist regarding the epidemiology of injuries related to celebratory gunfire. In Puerto Rico, where such celebratory actions are common, news media reports have indicated that approximately two persons die and an estimated 25 more are injured each year from celebratory gunfire on New Year's Eve. The Puerto Rico Department of Health (PRDOH) invited CDC and local law enforcement agencies to assist in the investigation of injuries resulting from celebratory gunfire that occurred during December 31, 2003--January 1, 2004. This report summarizes the findings of that investigation, which determined that 1) bullets from probable celebratory gunfire caused 19 injuries, including one death and 2) such injuries affected a higher percentage of women and children aged <15 years than injuries from noncelebratory gunfire, with the majority occurring in certain public housing areas in densely populated, metropolitan San Juan. Education and enforcement of existing laws are needed to prevent these injuries.

","['data-request', 'medical']",
Slimmed Down Nutrient Composition Database,"
I am working on a project that needs to recommend appropriate foods for people with nutrient deficiencies. 
This needs a database with foods and all their nutrient information (All vitamins, magnesium, iodine, zinc, riboflavin etc)
I've looked at plenty of massive datasets such as the USDA Food Composition Database and The Canadian Nutrient File.
While these datasets are excellent, they are too large for my work in their current state. 
As an example if someone is low on b-vitamins and iron the recommendation would likely be beef. So the data base needs a single option for ""beef"" (or max 2/3 different cute). The Canada dataset has about 30 with long obscure names such as ""ground beef, lean, 0% trimming etc..."" 
I am looking for a dataset that simplifies all items that are beef and provides it as beef, doing this for all other items.
Manually refining down the 6000 items from the large datasets would take a long time. Does anyone know of a set that meets this slimmed down requirement? 
","['data-request', 'medical', 'food']",
"Yelp datasets: Business name, phone number, and address","
I am looking for business data via a query search by geography. I would like to have:

Business Name
Phone Number
Address, either from Yelp or the Yellow Pages

As an example: Coffee Shops in California listed on Yelp.
","['data-request', 'business']",
Dataset on molecular temperature / speed,"
I am looking for a dataset on molecular temperature / speed for educational uses, so students might model the Boltzmann distribution. Does anyone know of such a (publicly available) dataset?
",['education'],
Physical exercises with muscle activation,"
I am looking for a dataset containing a list of physical exercises with muscle activation and ideally the reference that quantified the muscle activation.
For example, the physical exercises Crunch, Abflex, Nautilus, Nordic, Abroller, and Sit-up have the following muscle activation according to (1)






(1) Beim, Gloria M., Jorge L. Giraldo, Danny M. Pincivero, Matthew J. Borror, and Freddie H. Fu. ""Abdominal strengthening exercises: a comparative EMG study."" Journal of Sport Rehabilitation 6 (1997): 11-20. https://scholar.google.com/scholar?cluster=14268144323214177148&hl=en&as_sdt=0,22 ; http://journals.humankinetics.com/AcuCustom/Sitename/Documents/DocumentItem/2115.pdf ; http://pitt.edu/~neurolab/publications/1997/Articles/BeimGM_1997_JSportRehab_Abdominal%20strengthening%20exercise-a%20comparative%20EMG%20study.pdf

","['data-request', 'medical']",
What fraction of digital health care data is openly accessible?,"
(1) says that:

In 2012, the worldwide
  amount of digital health care data was estimated to be around
  500 petabytes, expected to reach 25,000 petabytes in 2020, of
  which approximately 80% is unstructured.

What fraction of it is openly accessible?

(1) Van Poucke S, Thomeer M, Heath J, Vukicevic M
Are Randomized Controlled Trials the (G)old Standard? From Clinical Intelligence to Prescriptive Analytics
J Med Internet Res 2016;18(7):e185
URL: http://www.jmir.org/2016/7/e185
DOI: 10.2196/jmir.5549
PMID: 27383622
",['medical'],
"prison population by ethnicity, nationality, and year, for each country","
I am looking for some data which will let me, for each of the world's countries, inspect the number of prisoners and a breakdown of its prison population by ethnicity and nationality as a percentage of total prison population. Sex and age would also be relevant.
If possible, I would also like this information to also be available separately for each prison, while listing prison name and number of prisoners for each such prison.
Pie charts would be nice.
(relationship to immigration and birth by ethnicity data would also be helpful and could somehow provide some insight on what has been happening and where things are going or where things will be expected to be going)
","['demographics', 'population']",
OpenFDA API - how to query on drug name with more than one word,"
Try running this query: https://api.fda.gov/drug/label.json?&search=brand_name:tylenol+number+three
I've also tried the %20 instead of '+' and it didn't work either.
I'm trying to pull up the information for brand name drug Tylenol #3.
It returns the drug Silicea (silicon dioxide).
I'd have to assume then that my syntax is incorrect, but I can't seem to find what the correct syntax is.
Does anyone else have experience with this?
","['openfda', 'api']","This query appears to work for a two-word query of ""infants tylenol""%22 is for a double quote and %20 is a spaceI wonder if there is a brand name drug named tylenol #3 based on my searches though, considering the following query doesn't return any matches for that"
Transport related data set - Milano or Trentino,"
Does anyone have an idea where traffic data set/s (traffic volumes, OD-Matrix, models?) can be downloaded for Milano or Trentino regions in Italy, for 2013.?
I tried on http://dati.trentino.it/ and http://dati.comune.milano.it/, but either this data does not exist, or is not available in adequate time frame...
BR
Toni
",['data-request'],
Accuracy of LODES dataset,"
Has anyone used the LEHD Origin-Destination Employment Statistics (LODES) datasets? I'm using the data from the Census FTP for LODES7 data. I want to understand how this data was calculated and what's the accurancy. Since, most of the census data comes with a margin of error (MOE), I assume this data also has some MOE but not mentioned in the tables.
","['us-census', 'census']",
openFDA: 510k update frequency,"
How often is openFDA 510k database updated?
Through the FDA website I see a new batch of 510k clearances from June 2016. However, openFDA has not been updated since May.
",['openfda'],
Public Company Subsidiary Data,"
I have put together a number of tracking systems for public companies. They look at things like news articles and patent filings, and I got my list straight from the NYSE.
What's missing now is subsidiary data. 
Public companies have to publish lists of their subsidiaries, and I'm looking to get that list. Thoughts? I usually go to Quandl with these sorts of questions, but they don't seem to have that. Neither does the NYSE.
Let me know if you need any other information.
Best Regards,
-Alex
",['companies'],
2-Yr Colleges' Salary Data In College Score Card,"
Using the College Score Card database, does the salary earnings for a 2-yr/community colleges' grad consist of only the students who graduate with a 2-yr degree or less; or does it also include salaries of students who get a 2-yr degree then transfer to a 4-yr university?
",['collegescorecard'],
Dataset of cars with required steering effort,"
I am looking for a data set listing car models along with the required steering effort (= how much force the driver needs to exert to steer the wheels of a car).
","['data-request', 'cars']",
Is there a free collection of icons like the Noun Project?,"
I am wondering if there a free collection of icons or images that I can download like the Noun Project that correlates an image for each word or noun in the dictionary.
",['images'],
"Any libraries for SEC Forms, such as a 10Q, as an Interface?","
I'd like to process some SEC data, such as a 10Q, but don't want to build a parser for the data myself. Are there any existing libraries that can parse or represent these types of forms?
","['api', 'data-format']",
Number of ultrasound machines per country,"
I am looking for a dataset listing how many ultrasound machines there are each country normalized by the population or number of physicians. Ideally, with some numbers showing the evolution over the year.

E.g., for MRI scanners, that would be:


","['data-request', 'medical']",
Writing a script to mimic openFDA's count query,"
I downloaded all of the JSON files from openFDA (2004Q1-2015Q4) so I could run my own python scripts to mimic the count query provided by the API. My goal is to get the counts of adverse reactions with drugs, without the prescribed limit of 1000 online. I want my JSON file to have results like this query (fatigue as an example reaction): 
https://api.fda.gov/drug/event.json?search=patient.reaction.reactionmeddrapt:fatigue&count=patient.drug.medicinalproduct.exact
Here is my code now (based on this example https://gist.github.com/HansNelsen/aeec93279dcd1792855d39fc37bead2e):
#!/usr/bin/env python

''' Simple example of reading all of the zip files from the openFDA download
    and doing something with them. In this case, we are building an index
    of all the medicinalproduct and drugcharacterization values and a count
    of how often each occurred.
'''

from collections import defaultdict
import glob
import simplejson as json
from os.path import basename
import re

DATA_FILES = glob.glob('./*/*.json')

reaction_drug_counts = {}

for filename in DATA_FILES:

    print(filename)

    file = open(filename)
    json_data = json.load(file)
    file.close()

    for row in json_data['results']:

        for reaction in row.get('patient', {}).get('reaction', []):

            MedDRA_term = reaction.get('reactionmeddrapt','unknown')

            if MedDRA_term not in reaction_drug_counts:

                reaction_drug_counts[MedDRA_term] = {}

            for drug in row.get('patient', {}).get('drug', []):

                characterization = int(drug.get('drugcharacterization', '0'))

                # if characterization == 1:
                # additional restriction to only collect counts of ""suspect"" drugs

                product = drug.get('medicinalproduct', 'unknown')

                if not product or re.search(""^[\W_]+$"", product):

                    continue

                current_counts = reaction_drug_counts[MedDRA_term]

                if product not in current_counts:

                    current_counts[product] = 1

                else:

                    current_counts[product] += 1


f = open(""my2.json"",""w"")
json.dump(reaction_drug_counts,f, indent = 4, sort_keys=True)

This should result in a JSON file that contains the results if I performed a count query on every adverse reaction in FAERS. The problem I'm getting, however, is that it's not matching to the original query, specifically when I look for ""FATIGUE"", the drug ""TYSABRI"" should be getting 15214 unique counts, but my script only shows 9554.
Originally, I had a restriction where it would only count ""suspect"" drugs (given by a drugcharacterization value of 1), and resulted in 9529 counts for ""FATIGUE"" and ""TYSABRI"". I assumed that it was because of this original restriction, but indeed, after taking it out, it still didn't match the API results (In fact, it barely increased).
Is there something I'm missing in my code? Or could it be that the API has connections between drugs (such as counting ""NATALIZUMAB"" reports in the ""TYSABRI"" count)? 
EDIT: What ended up happening is that the dictionaries were case sensitive, so I added a .upper() for the terms to be saved. In addition, it was possible that a certain drug/event could be found in the same safety report, so I implemented it so that it could be added to the count only once. The results are nearly identical, and if anyone wants the updated version, just let me know.
",['openfda'],"I would check to make sure that you are processing all of the files. Start by printing out filename variable or len(DATA_FILES). It may be the case that you are missing some downloads.Also, are you using .exact queries on your API search? I ask, because what you are doing in the code would be the same as counting and search with the .exact suffix.As a side note, the API counts documents not instances of a term, so if a term is on document more than once, then that could explain the difference."
Looking for an open database of individual human whole-head structural magnetic resonance images,"
I'm looking for an open data source with single-patient human whole-head structural magnetic resonance images, preferably in NIfTI format. Healthy adults, high SNR and citeable source would be pluses. 
Problem that I'm facing now is that it seems that most of the available MRIs are either cut, so that only brain is visible or require jumping through a whole bunch of hoops before they allow access. 
",['medical'],
openFDA API - ingredient and product name queries give bad results - is it me?,"
Try running this query:
https://api.fda.gov/drug/label.json?&search=generic_name=hydrocodone - returns Oxycontin, not Norco or other hydrocodone containing drugs
https://api.fda.gov/drug/label.json?&search=brand_name=norco - returns inhaled nitrogen product
I've tried a number of variations here, but all name/ingredient queries return strange and unintended results.
Am I writing my queries incorrectly?
","['api', 'openfda', 'drugs']",I think you might be using the wrong query syntax for the openFDA API.Try: https://api.fda.gov/drug/label.json?&search=generic_name:hydrocodoneNote the : instead of the = in the search value. More details are provided at https://open.fda.gov/api/#query-syntax
Database of Diacritics,"
I'm working on a project to map Unicode English characters to diacritic characters in Javascript. When the user enters e.g. ""doner"" the search engine should also find e.g. ""döner"". So it should be completely diacritics insensitive. 
Is there a single source where absolutely all (trustful) diacritics are listed?
Example of the conversion:
var DIACRITICS = {
    'a': '[aÀÁÂÃÄÅàáâãäåĀāąĄ]',
    'c': '[cÇçćĆčČ]',
    'd': '[dđĐďĎ]',
    'e': '[eÈÉÊËèéêëěĚĒēęĘ]',
    'i': '[iÌÍÎÏìíîïĪī]',
    'l': '[lłŁ]',
    'n': '[nÑñňŇńŃ]',
    'o': '[oÒÓÔÕÕÖØòóôõöøŌō]',
    'r': '[rřŘ]',
    's': '[sŠšśŚ]',
    't': '[tťŤ]',
    'u': '[uÙÚÛÜùúûüůŮŪū]',
    'y': '[yŸÿýÝ]',
    'z': '[zŽžżŻźŹ]'
}; 

I need to be sure that the list is complete, so just pointing out a code repository that uses diacritics isn't enough for me – unless it references the sources.
","['data-request', 'language']",
Customer Review Dataset with Label Classification,"
I am trying to check my model with the current state of the art models. I want a dataset with customer reviews and their corresponding class assigned. For example, a review like The car was very badly maintained should belong to the class - maintenance which has already been created before. So essentially, a review and it's corresponding class/label. I also want the current state-of-the-art precision and accuracy values. I can't seem to find both together.
","['data-request', 'machine-learning', 'nlp']",
Data on startups by Metro cities,"
I am looking for data on startups by growth levels. basically combining census and SOI data
",['data-request'],
ThemeClassification Datasets - Clean Versions,"
I am looking for some small datasets to do theme classification on text for example like reuters, 20ng with benchmarking and also their clean versions. I found one very useful site - Dataset. I want some more datasets in similar fashion. Where can I find them? I searched but I always end up with raw data which poses me a challenge to extract.
","['machine-learning', 'nlp']",
"How to add a claim to an existing Wikidata item, from command line?","
I want to add to Wikidata this claim:
Embassy of Switerland, London - is operated by - Switzerland
... using my Linux command-line.
Launching a web request via curl is OK too.
How to do?
I have seen Wikidata-CLI and Wikidata-sdk, unfortunately they only seem to support read-only operations. None of the external tools listed at Wikidata seem to apply either.
","['tool-request', 'wikidata']",
Can SPARQL modify data like SQL? Or is it read-only?,"
Despite being a query language, SQL can perform DELETE/UPDATE/INSERT operations.
Similarly, can SPARQL modify data?
If find SPARQL convenient so I would like to use it to modify data, for instance to add a property to all items that satisfy a particular WHERE clause.
Is it possible? If not, are there SPARQL extensions to do that? Is any such extension usable on live Wikidata?
","['wikidata', 'sparql']",There is SPARQL Update. It doesn't seem to be supported by Wikidata Query Service.
"Is there a site that has comprehensive list of data, along with descriptions, meta data etc?","
Is there a resource/website that has list of all possible datasets from around the world with links to the download page, names of columns in the individual datasets (so users can search by a particular column name if they wish to), descriptions, usage terms etc?
","['uses-of-open-data', 'metadata']",
Searching for data on breast feeding,"
I am looking for data on breast feeding practice in big American cities. Information I am looking for is like 

How many breast feeding and stay at home mothers are in a given city? 
How long does a mother nurse her child? 
What are the primary reasons of stopping breast feeding?

and other similar aspects. Any information or pointers are much appreciated.
","['data-request', 'medical']",
Dataset of shell commands with corresponding sentences,"
I'm looking for datasets that contain a list of shell commands (any kind of shell: bash, sh,  Windows shell, …) where each shell command is associated with at least one sentence written in English that explains what the shell command does. Examples:

what’s in this folder -> ls
how much available disk space do I have left -> df -h
install htop -> apt-get install -y htop

","['data-request', 'nlp']",
United States Ports of Entry -- Historical and Current,"
Is there a compilation of the US ports of entry and their changes over the past 100 years (or any time period within this range)?
Specifically interested in the US-Mexico port of entries. The wikipedia page (https://en.wikipedia.org/wiki/List_of_Mexico%E2%80%93United_States_border_crossings) seems to have a complete list of the current crossings, but not when they were built and their list of closed crossings is flagged as incomplete.
Having details, such as the type of traffic allowed and whether it was one-way or two-way, would also be useful, but not necessary.
","['data-request', 'usa']",
NEISS injury dataset - machine readable coding for characterizations,"
The National Electronic Injury Surveillance System (NEISS) database offers Excel downloads (example XLSX, ~50MB) on a year by year basis. The categorization of the injuries in the Excel files is given by codes, which may change or merge year to year. The codes are available in the Coding Manual PDF, and changes are available in the 2016 Comparability Table PDF.
The query tool hides the codes from the user and shows only the characterizations (e.g. Diagnosis).
Is there a machine readable source for the mapping between codes and descriptions?




","['medical', 'metadata']","Based on the PDF manual, there is an R package on Github called Neiss that has an excel file with mapping between codes and text descriptions.Direct link: https://github.com/hadley/neiss/blob/master/data-raw/NEISS-formats.xlsxSample screenshot:In addition to diagnosis there is also product code, race codes, etc."
Electricity consumption dataset,"
Where can I find a dataset of monthly or yearly electricity consumption from Latin America or from any related zone?
","['data-request', 'energy', 'latin-america']","Option 1:The World Bank data portal has a database called World Development Indicators. It has global yearly energy consumption (per capita) for each country and geographical or economic zone.You should select from the left navigation bar the WDI database, then select the individual countries, then the time series ""Electric power consumption (kWh per capita)"", then the years. There are other electricity consumption time series, and an entire database for sustainable energy availability.You can download the timeseries as a CSV or Excel from the top right.If you want total consumption, and not per capita, then you'll have to multiply each country and year by the population. Their data portal will have that data, too.Option 2The US Energy Information Administration (EIA) offers total yearly energy data for countries and regions. From their page you can select the countries or region and then the year, and then download to Excel. Direct Link. Years available are 1980 to 2012.Option 3:The International Energy Agency offers an Energy Atlas with aggregate electricity consumption per country (link). Years available are 1973 to 2013. I don't see a download link."
Historic Thompson-Reuters CRB Data?,"
Anyone know of a 20-30 year history of the Thompson-Reuters commodity index (example)?
I looked through Quandl, but I didn't find the commodity index that is tied to this one - I found quite a few others.
","['data-request', 'finance', 'economics']",
Geospatial data at a particular lat/long,"
I'm looking for a database of physical characteristics of the Earth at an arbitrary lat/long. 
For example, a lat/long in the general vicinity of: 

-1.710140, -52.961935 would result in river
27.987785, 86.925013 would result in mountain
-80.926282, 112.655179 would result in tundra
11.373333,142.591667 would result in oceanic trench
etc.. 

This would be the base set of data I would expect. Additional physical information such as elevation or urban, political information such as country and city, or biome information would also be great.
My searches so far has resulted in what seems to be map data when I was expecting something a bit more tabular (columns and rows). I'm sure my confusion is due to ignorance, but I'm at the point where I don't know what I don't know. 
","['data-request', 'geospatial', 'global']",
Blood pressure annotated with beat onsets,"
I am looking for a timeseries dataset containing recording of blood pressure annotated with beat onsets.
Example:

","['data-request', 'medical']",
UK river and catchment files for GIS,"
Is there any possibility to download for free the UK river and catchment files (e.g. vector or raster) readable for GIS?
I need them for research purposes.
","['data-request', 'geospatial', 'uk', 'network-structure']","FYI a colleague of mine suggested me the following website, where you can find the UK (detailed) river network: https://www.ordnancesurvey.co.uk/business-and-government/products/os-open-rivers.htmlOn this website there is also a lot more.."
How do I run openFDA API locally?,"
I'm currently working on a project that would greatly be assisted by running the openFDA API locally. I tried to follow the READMEs but I can't get it to work.
",['openfda'],
Nightclub flyer dataset,"
I am looking for a dataset containing images of nightclub flyers, if possible with:

name and location of the club
date of the event
type of music
type of event (e.g. student party, clubbing)
a short description of the event

Examples of images of nightclub flyers:

","['data-request', 'music']",
Where to get hourly weather data for Moscow region,"
I'm planning an outdoor event, and want to schedule it on a weekend with warmest nights, and the least probability of precipitation.
My first take was querying forecast.io for hourly historical data. It works, but I quickly ran out of free limit of daily requests. And I also want to extend my query, and find out which is the warmest location within 150 km of Moscow, and that would bring me way beyond the limit.
Is there more straightforward way of getting the data? 
","['weather', 'historical', 'russia']",
Where to save the event JSON files for openFDA locally?,"
I just downloaded the openFDA source code from the github, as well as all the event endpoint JSON files, and I wanted to know which directory to save the JSON endpoints. Some also seemed to have the same file name, e.g. when both 2004Q1 part1 and 2004Q2 part1 are extracted, they result in drug-event-0001-of-0002.json. How should I distinguish them within openFDA?
",['openfda'],
Catasto terreni ITALY,"
I need to obtain catasto information for all the Italy limited to terreni only, no urban zone.
Is it possible to obtain this information free?
Anybody know any services for WFS or SHP download?
","['data-request', 'data.gov']",I'm sorry but it's just a fee except for local governments that can trigger a convention
Land cadastre USA,"
I need to obtain cadastre information for all the USA limited to land terrain only, no urban zone. Is it possible to obtain this information? Does anybody know any services for WFS or SHP download?
","['data-request', 'usa', 'land']",
"Is it possible to request an api key for each one of my users, using their registered email?","
I am using the USDA food database in an app, however I will not being able to use it in the live version because of the API request limitations. One workaround would be to give each registered user their own API key, which would easily suffice the API limitations. Is there a way to programmatically get an API key for each user, using the email they submitted when they signed up on my app?
","['api', 'best-practice']",
"In the famous LaLonde dataset what treatment does ""treat"" represent?","
lalonde is an oft-used data frequently used for in statistical software packages. This data was drawn from the PSID and National Supported Work Demonstration.
Subsamples of the dataset are included with the R language's MatchIt and Matching packages.
I am using the data from these packages, yet I note that while one of the variables -- treat is defined as 

""the treatment assignment (1=treated, 0=control).""

it doesn't actually seem to say what the treatment was.  
Can anyone help me determine this?
","['economics', 'research', 'demographics']","This dataset was first used by Robert LaLonde in a paper published in the American Economic Review  1986: 
Evaluating the Econometric Evaluations of Training Programs with Experimental Data.The ""treatment"" refers to participation in the National Supported Work Demonstration (NSW), an employment program to help disadvantage to move into the labour market. Eligible applicants were assigned randomly into this program. So the ""treated"" are those assigned to the program and the ""controls"" those not assigned.But be careful, Lalonde has used several control groups. One groups stems from the experiment mentioned above other are ""non-experimental"" and stem from the Panel Study of Income Dynamics (PSID) an the Current Population Survey (CPS)."
"MEDLINE®/PubMed dataset as a relational database (e.g., MySQL)","
I am looking for a way to obtain the MEDLINE®/PubMed dataset (i.e., metadata of PubMed papers) as a relational database (e.g., MySQL). The MEDLINE®/PubMed can be downloaded as XML files, but I would prefer to write SQL queries when using it. I am fine if it involves running some script to convert.
","['data-request', 'pubmed']",
Where can I find gene expression data for melanoma?,"
I've already found a dataset for gene expression on melanoma from TCGA. However, I want a testing dataset and I have had trouble looking for a dataset with a large number of melanoma patients and their gene expressions. Any advice?
",['biology'],
Bulk processing XBRL into MySQL,"
I am working on a project involving processing a large volume of XBRL documents (> 1m separate files). I am totally new to XBRL and feeling quite lost at the moment, only downloaded Arelle 20 minutes ago). 
I have data relating to those XBRL documents in a separate MySQL database and I would like to add XBRL data into MySQL to store it in one db. 
What are the best methods to go about transferring data from the XBRL docs into MySQL?
Are there any bulk processing libraries available for it?
I've been looking for tutorials on those issues but couldn't find anything providing a basic introduction, just a lot of high level info. 
","['linked-data', 'sql']",
US Fire Database,"
I am searching for a website that will allow me to find wildfires/forest fire/small fires in the United States that has all the information in a database. What I would like to look it up the database to look for each fire incident.
","['usa', 'database', 'fire']",
why do legal descriptions of property differ from DB to DB?,"
So I was looking at deeds for a particular property and the legal description of a particular property is ""Lot 1 Block A Lastname Subdivision"". The appraisal district, however, gives a different legal description of that property: ""S9928 - Lastname Sub, Block A, Lot 1, Acres 3.03"".
It's clear that they match because the lastname matches as do the block and lot but the fact that they're different means that I can't just copy / paste the legal description from one database and search for it in the other database. And if ""Lastname"" were sufficiently generic there'd prob be nothing I could really latch onto to find the property info in the other DB.
So why do they differ in the first place?
","['usa', 'real-estate']","I work for an appraisal district and can say that the discrepancy between your deed record and the appraisal record comes from how the appraisal database is maintained. All real property accounts have an account number of some kind, and this can vary widely by county. Essentially, it is because there is a lack of standard(s) and best practices around the community.  If it were in my county, the ""9928"" would be the first four digit subdivision code, followed by a four digit block number (ie: block A would be 0001), followed by a four digit lot number (ie: lot 1 would be 0001), followed by an optional three digit split number (ie: if lot one were split into two, the two account numbers would be identical except for the -001 and -002 suffix. if no split, it would be -000). The account would also have an accompanying short code account number that is sequential in the database, and not based upon the legal description like the long form number. I'm not sure what ""Lastname"" refers to. Is that the last name of the owner? edit: I just saw this was a fairly old question, but hopefully anyone else that has this question might gain something from it."
Contractual data over multiple years,"
To build models to predict customer behavior, I am searching for individual-level contractual data over multiple years (i.e. > 3 years). My focus is to assess the quality of long-term predictions, thus the longer the time period the better. (See here for a similar question on transactional data.)
Minimum requirement in terms of variables would be:

Customer ID 
Start Date Contract  
End Date Contract 
Contractual Fees
(If firm sells multiple types of contracts: Contract Type)

In a perfect world, these datasets would be released under a GPL like license and also include information like:

Date of first contract ever (which facilitates cohort analysis)
Socio-demographic information on the individual customer

Examples are manifold and include data from insurances, SAAS firms, VOD subscription services, ...
","['data-request', 'longitudinal']",
Need dataset of english letters,"
I have done one assignment of classifying digits using Back propagation Neural Network. Now I want to test it on english letters.
Can anybody tell me from where can I get the dataset of English letters (letters of size 20 * 20 pixels would be more helpful). If possible then please provide dataset of letters of any other language also.
","['data-request', 'machine-learning', 'language', 'images']","Have a look at these datasets:http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/
http://archive.ics.uci.edu/ml/datasets/UJI+Pen+Characters"
USA National Power Grid Regions,"
I would like the polygons for the USA Western, Eastern and Texas Interconnects as well as their sub-regions.  These are illustrated here.

Any ideas where I can find shape files for these? 
I don't strictly need the power lines; just the regions. If major power lines are included I would like them to be in a different layer from the region polygon so they can be removed. I am hoping that these polygons would not require a license/subscription since they are not too detailed.
","['data-request', 'geospatial', 'energy']","This may take some digging through the EIA-861 dataset (http://www.eia.gov/electricity/data/eia861/). It contains a dozen or so tables, but the ones you may be able to piece together are:You will have to deal with the fact of utilities operating in multiple counties and NERC territories by making some simplifying assumptions.Using these tables you may be able to calculate which counties are in which NERC regions. Shapefiles for counties are easier to come by either from the census (https://www.census.gov/geo/maps-data/data/cbf/cbf_counties.html) or in the software package of your choosing.I am not sure whether this will work, but it may be a start. When I was doing an analysis involving utilities at the county level it suited my needs, but your request is obviously different. If I find myself tackling this exact problem in my research I will try to come back and post code."
List of Benign URLs,"
I'm looking for a list of benign urls. I've seen that others have used the Yahoo URL Random Generator (random.yahoo.com/bin/ryl), but that link doesn't seem to work anymore. The other thing that I thought might work was seeding a crawler with the Alexa list.
",['data-request'],"You can use the Common Crawl data, which is loosely related to the Internet Archive and Wayback Machinethe Common Crawl Corpus encompasses over two petabytes of web crawl data collected over eight years and ongoing. As the largest, most comprehensive, open repository of web crawl data on the cloud, we contribute to the thriving open data commons that drives innovation, research, and education.(wiki page)In particular, the URL index they use for the crawl"
"For openFDA, is there a way to get the counts of every drug for a particular adverse event?","
I'm working on calculating a PRR, but instead of using a drug-adverse event pair, I'm looking at the drug-SOC (system organ class) pair, which needs all the reports of every drug-ADE pair within a specific SOC.
So to do this, I wanted to know if there was a query that could get all the counts for a specific ADE; right now I'm running: https://api.fda.gov/drug/event.json?search=patient.reaction.reactionmeddrapt=fatigue&count=patient.drug.medicinalproduct.exact&limit=1000, using fatigue as an example ADE. 
The reason I'm looking for more results is because I want to implement all the counts greater than 10; which is not possible here since the lowest count for the query is 125. Does anyone know a workaround?
I also tried using openFDA's range function, for example: https://api.fda.gov/drug/event.json?search=receivedate:[20040101+TO+20160601]+AND+[10+TO+10000000], but I don't know if this is what I actually want. How would I specify that the range is for the count of each drug-ADE pair?
",['openfda'],
Library of human faces with tags for displayed emotions,"
Is there an open dataset with images of human faces that's labeled with the emotion that the face displays?
","['data-request', 'images', 'faces']",
French newspaper dataset,"
I'm looking for a large dataset containing french newspaper articles associated with a newspaper category.
The categories should match those of mediatopics.
It can be in any format.
I would like to use this kind of dataset to train a model to categorize automatically newspaper articles.
","['data-request', 'french']",
Where can I find city/town boundaries in UK? [duplicate],"







This question already has answers here:
                                
                            




Geodata to make a map of the UK with counties outlined

                                (3 answers)
                            

Closed 7 years ago.



Specifically, I am looking for the boundary of Barrow-in-Furness, a city in Cumbria, UK. GIS data in any format is preferable, but a scanned map with a clear boundary is also acceptable.
",['uk'],"Go to the UK OpenData products site and scroll down to the BoundaryLine dataset, this includes a GIS data download.Additional data sources can be found through this GIS StackExchange question from 2010."
Surveys which capture income of individuals and other details,"
Please provide list of surveys which capture income of individuals, income determinants like education, age, work experience, field of work etc and, details about his family particularly number of elder brothers. Geography of Interest is US, Europe, Japan and Australia. Time period of interest is post 1980.
",['data-request'],
"Given a PMID, how can I get the list of PMIDs of papers citing it?","
Given a PMID (=PubMed identifier), how can I get the list of PMIDs of papers citing it? Dataset, API, or any other solution is fine.
","['data-request', 'api', 'research', 'pubmed']",
Open databases on how doctors and their patients use technology,"
I'm on the hunt for some open-source online data resources on healthcare services, preferably that focus on how either MDs and/or their patients perceive the use of IT tools.  I hope to find data that are exportable to Excel.
Can you provide any suggestions?
","['data-request', 'medical']",
Vertical profiles of water vapor,"
Where can I access data for vertical atmosphere profiles? Specifically, I'm looking for measurements of water vapor as a function of altitude over the USA. It's a bonus if I can find vertical profiles for atmospheric gases (CO2, NO, etc.)
","['data-request', 'usa']",
Past medical/medication history in MIMIC-III,"
Aside from progress notes (using natural language analysis or by manual review), is there any method for extracting past medical history or a medication history prior to admission from the MIMIC-III database?
In looking at the D_ITEMS table, I found a few relevant ITEMID values (225059 - ""Past medical history"" and 225811 - ""CV - past medical history""), but there are no items in CHARTEVENTS that correspond to these ITEMID values.
",['mimic-iii'],This data was unavailable in v1.3 but has now been added and is available in v1.4 (released Sept 2nd 2016).
Setting up a private instance,"
In general, I want to use OpenFDA to look at the overlap between FDA drug data and cosmetics ingredients, primarily using the drug event and drug label data sets. Device and food questions might arise for me, but first things first.
I think I am that rare (not primary audience?) use case where my kinds of queries exceed use limits even with an access key; for example, when I am looking for how a given UNII appears in all records some result counts far exceed 5000.
I started to process zip files, then started looking into running my own server to remove the use limits.  I have a virtual machine (vagrant/VirtualBox, ubuntu, and elasticsearch) set up, and the openfda github code base (I also ran bootstrap rather on a whim/lark and can't tell to what effect, embarrassingly enough).  
Processing the fda data (maybe in zip files maybe not?) and inserting the results in elasticsearch seems to be part of the purpose of the opendfda github code base (deduping etc.), so I am very much rethinking trying to do that myself. Yet I am stuck on how to proceed.
Questions:
1. Do I need/want both the front and and backend github code if I am just trying to analyze the records that come back? (Doubtless, the answer takes some form of ""It depends..."" but I'm not sure even on what issues the decision/answer may rely.)

If I am on something close to the right track with the virtualmachine, what is the best way to set up my own server with drug event and drug label data into elasticsearch....so I can get back out responses to my queries? A mid-level (not 80,000-foot view and not a 1,000-foot bird's eye view) set of general steps to my goal would be awesome, and then I could struggle through the more detailed ""how"" parts on my own time is an ideal answer for me -- tho arguably still very broad.

I feel I've been through youtube (nothing to see, I think), SE and the FDA site and the github code README files, but I am still not getting a lot of ideas from those documents to suggest what I'm about is ... possible (or good or right) for me, even with a little help.  Maybe the human touch (or 2x4) here will help.  TY.
",['openfda'],
Livestock Diseases in Indiana,"
Does anyone know of any datasets regarding livestock diseases in Indiana? I am a GIS student in need of a unique data source; as I do not work in GIS yet, I have chosen a topic in a field in which I want to work. Specifically, I'm looking to locate a source from which I can practice manipulating raster data (comparing, reprojecting, clipping, extracting, making mosaics, creating TINs and 3D renderings, etc.). Data in any format is sought.
","['data-request', 'animals', 'agriculture']",
Using Google's Custom Search api [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 7 years ago.







                        Improve this question
                    



I am currently working for a social media site. We would like to use Google Custom Search Engine API and derive analytical insights from the results. My choice of development platform is R or Python. The following source code in R is used to fetch details about a person, whose details are publically available.
library(httr)
library(jsonlite)
searchword=""Bill+Gates""
query=paste(""https://www.googleapis.com/customsearch/v1?key=API_KEY&cx=ENGINE_ID&q="",searchword,""&alt=json&num=7"",sep = """")
results <- content(GET(query))
print(results)
results_JSON <- toJSON(results)
results_JSON <- fromJSON(results_JSON)
results_df <- as.data.frame(results_JSON)
titles_df <- as.data.frame(results_df$items.title)
pagemap_df <-
  as.data.frame(results_df$items.pagemap) for (dfindex in 1:length(pagemap_df$person)) {
    if (!is.null(pagemap_df$person[[dfindex]]))
      locationdf = t(as.data.frame(unlist(pagemap_df$person[[dfindex]])))
  }

We plan to customize the results and display it other details in a separate format. On client side review of this code, I got the feedback that the use of custom search API in this manner is not within the terms and conditions provided by Google. Does this kind of operation from an application is not permitted? Once it is hosted, this will be blocked by Google? If it is allowed, We are planning to add credits to the paid API program.
","['programming', 'python']",
How does PubMed obtain papers' metadata?,"
I wonder how PubMed obtains papers' metadata. 
In particular, I am interested in the metadata used for these filters: http://www.ncbi.nlm.nih.gov/pubmed?term=%22Review%22[pt]

",['pubmed'],
Linking PMIDs with ORCID iDs,"
I am looking for a dataset or API which would give the list of ORCID iDs  (=Open Researcher and Contributor ID) given a PMID (=PubMed identifier).
","['data-request', 'api', 'research', 'pubmed']",
Directory of publicly available polling data,"
I'm looking for (US) polling data, mainly presidential polling, for which the full source is available to work with. Specifically, I'm looking to be able to see results broken down by age groups.
Huffington Post offers a nice API, but I'm wondering if there might be other sources out there.
","['api', 'politics', 'polling']",
MOOC dataset with opening and removal dates,"
I am looking for a dataset on MOOC availability, including as many following fields as possible:

MOOC title 
MOOC platform
opening date
registration closing date (i.e., date after which new student cannot enroll into the course)
removal date (i.e., date after which nobody can access the course materials)

I am mostly interested in removal dates, and it particular in the list of Coursera courses that will be removed during the June 30 clean-up.
","['data-request', 'mooc']",
Open audio segmentation datasets?,"
Does anyone know of any datasets with annotated audio for audio segmentation, e.g., with speech and music? 
I know of Albayzin, but these datasets seems to be restricted to research. CMMSD seems to be for just monophonic music.
","['music', 'audio']",
Getting updated date for all the endpoints through an API,"
I am trying to build a code that download all files from the provided end points. However, I do not want to download the files everytime and will only download the files if the data in the endpoints is changed/added. I assume that this is provided by the ""last_updated"" field in the JSON as shown in the API reference JSON snippet - https://open.fda.gov/api/reference/.
What is the URL that provides me similar JSON output?
","['api', 'openfda']",
"Given a DOI pointing to a resource, how can I programmatically know whether the access to the resource is free of charge?","
Given a DOI pointing to a resource, how can I programmatically know whether the access to the resource is free of charge? E.g., if the DOI points to a research paper, how to programmatically know whether it is behind a paywall?
","['research', 'doi']","I know of three possibilities:Unpaywall's API. Use https://api.unpaywall.org/v2/{DOI} to access it. Not only does it provide a binary is_oa field (with the values true or false) and an oa_status field (e.g. green open access), but it even links to repositories and other locations where you can obtain a free version of the paper. Read more instructions here. One example: https://api.unpaywall.org/v2/10.1038/nature12373.OpenAccessButton's API. Use https://api.openaccessbutton.org/find?id={DOI} to access it. It contains a licence field from which you could infer the accessibility of the paper. Read more instructions here. One example: https://api.openaccessbutton.org/find?id=10.1371/journal.pone.0158765.CrossRef's API (as already hinted by Andrew Gilmartin). Use https://api.crossref.org/works/{DOI} to access it. Similar to OpenAccessButton, it contains the field name license. Read more on the documentation here. Example: https://api.crossref.org/works/10.1371/journal.pone.0158765."
Grocery store sales data in the US,"
I am looking for a source that would provide sales data for grocery stores in the US or companies that provide such data. 
","['data-request', 'geospatial']",
Where do I get data to train a program?,"
I am creating a learning program which should learn how to answer to a binary yes/no question given numeric information.
For now, I used this data to train it:
The problem is, I only have 569 records. It is not few, but I'd like more. Also, I should train it with other types of data (not related to breast cancer), to see how it does with different classes of problems.
What I need is a list of records each containing a bunch of numeric fields and a yes/no answer (such as ""Is this tumor malicious?"" in the data I already use).
Does anybody know where to find such repositories?
",['machine-learning'],
Molecular concentration versus altitude,"
I am looking for a database that supplies molecular species as a function of altitude over a specific location.  For instance, I might want to look at methane concentration versus altitude over Wichita, KS. I've tried radiosonde data, but that does not include molecular species.
","['data-request', 'usa', 'geospatial']",
Apple Product Sales,"
Is there somewhere I can get in csv format for the last five years of Apple sales, split by product, globally per week? I'm interested in units.
","['data-request', 'products']",
MOOC budget dataset,"
I am looking for a dataset containing MOOC (Massive Open Online Course) budgets, including as many following fields as possible.  The unit of observation is an individual MOOC:

MOOC title
platform (edX, Coursera, etc.)
provider name (Stanford, Microsoft, etc.)
pay to the teaching staff
number of students registered to the course
number of students who completed the course

","['data-request', 'finance', 'mooc']",
mimic-iii - Age adjustment for >89 year olds,"
This should be incredibly straightforward, but I'm struggling with a simple way of calculating dates for patients >89 on their first admission. Am I correct in thinking that their DOB should be (ADMITIME for their first HADM_ID) - 210 years? Has anyone scripted this simply as my brain is stalling here...
",['mimic-iii'],
CKAN Harvester Issues,"
I've been trying to set up a CKAN installation for use as a Caribbean open data portal for a few weeks now but I've been running into challenges when I try to set up the CKAN Harvester and import some data sets. More specifically, I'm running into two specific errors.
1) The Harvester does not work unless I start the gather and fetch queues manually in the command line. If I don't do that, I get a simple error when I try to run the harvester on a data source from the front-end. 
An error occurred: [2.0]
2) Like I said, I've been able to work around this error by starting those queues via the terminal but I'm guessing that isn't how it's supposed to work (I shouldn't need to do that right?). The second issue occurs when I resolve the first one and has to do with me trying to set the ""default_groups"" parameter.
If I set it to an empty set like so --> ""default_groups"" : [] 
There are no issues.
But if I try to include groups like so ---> ""default_groups"" : [""trinidad""]
I get this error : 

The form contains invalid entries:
Config: Error parsing the configuration options: default_groups must be a list of group names/ids (i.e. strings)

I've done my best to be thorough here but please feel free to ask me any additional questions for clarification. I'd be very grateful for any insight/help with figuring this out.
Lastly, I have a couple of hunches that I'm still exploring. One is that there might be a version compatibility issue with the more recent version of CKAN (2.5) and the current Harvester version. I suspect this because the other versions of CKAN where the Harvester is actually working are running 2.2.
Not sure if that will mean anything to someone more familiar with the platform.
I'm open to all ideas, solutions, hunches, or whatever else might help me resolve this! 
Cheers!
",['ckan'],
"Transactional data over multiple years (Customer ID, Date, Price)","
To build models to predict customer behavior, I am searching for transactional data over multiple years (i.e. > 3 years). My focus is to assess the quality of long-term predictions, thus the longer the time period the better. 
Minimum requirement in terms of variables would be: 

Customer ID 
Purchase/order/transaction date
Price of goods/services sold

In a perfect world, these datasets would be released under a GPL license and also include information like:

Date of first purchase ever (which facilitates cohort analysis)
Socio-demographic information on the individual customer 
Product ID, as well as further details of the products bought such as product category

Examples are manifold and include order/transaction/purchase histories from an online store, a car/bike share network, transactions from a gas station network, ... 
I do know about the Superstore dataset that ships with Tableau and has 4 years of transactional data (http://community.tableausoftware.com/docs/DOC-1236). However, this is simulated data and does not show the patterns one usually observes in real world transactional data.
","['data-request', 'business', 'companies', 'time-series']",
Open Human Computer Interaction datasets?,"
I am looking for open datasets containing logs of any Human-Computer Interaction (HCI) system. I am interested in analyzing sequences of different aspects of the system, such as:

User Interaction and commands sequences
System sequences (events and system state)

Any application domain is valid.
","['data-request', 'computing']",
List US supermarkets as defined by the Blue Cash Everyday,"
I am looking for a list of shops regarded as US supermarkets for the Blue Cash Everyday/Preferred Cards from American Express.
The Benefit Terms point to https://www.americanexpress.com/us/content/rewards-info/retail.html, which gives a vague definition of a US Supermaket along with a quite partial list of US supermarkets.

U.S. Supermarkets 
To earn additional rewards on supermarket purchases,
  the supermarket must be located in the U.S.
A supermarket offers a wide variety of food and household products
  such as meat, fresh produce, dairy, canned and packaged goods,
  household cleaners, pharmacy products and pet supplies.
(Superstores, convenience stores and warehouse clubs are NOT
  considered supermarkets.)
Examples of merchants* that accept the Card and where you can earn
  additional rewards include: 

Gristedes 
Foodtown
Pathmark
Shoprite 
Stop and Shop
Vons 
Whole Foods 
Winn-Dixie 
Online supermarkets such as FreshDirect

*This is not a complete list.
Examples of merchants where you will NOT earn additional rewards
  include: 

Specialty stores (e.g., fish markets, cheese shops, wine
  shops, and other specialty food stores ) 
Superstores (e.g. Amazon,
  Target and Wal-Mart) 
Warehouse clubs (e.g. BJ's Club and Costco
  Wholesale)


I did try calling Amex (800-243-3888). They told me they don't have any list, and that I should instead ask each shop whether they accept AmEx and are regarded as US supermarket. I am hoping that some AmEx customers may have aggregated some list.
","['data-request', 'usa', 'finance']",
Murder rate by city/state in Germany?,"
I would like to know the murder rate by city/state in Germany. For example, in Berlin the murder rate per 100,000 people is 1.3, in Hamburg it is 0.9, etc etc...
I don't mind if it is murder or homicide as long as it is consistent across the dataset. It would also be better if the dataset includes other crimes such as thefts or assaults.
","['data-request', 'crime', 'germany']",
Where can I find the possibility of a drought this summer in my area?,"
Specifically looking to find out the likelihood  that South Carolina will experience drought conditions during the summer of 2016.
",['weather'],
How to simulate stock exchange data (OHLC chart) realistically?,"
The stock market is described in many places (e.g. here) as a random walk. Among the various arguments against this hypothesis, nowhere is mentioned what struck me to be the most obvious one: every stock has a lower bound of 0. A random walk, however, is unbound.
I can think of various ways to implement such a bound in a simulation that generates artificial stock market data. But are there ways to simulate a stock market where a lower bound of 0 follows from economical considerations (i.e., a market theory) instead of practical improvisation.
",['metadata'],
FTPing the National Centers for Biotechnology Information (NCBI),"
I am trying to ftp to the NCBI to download some information. Upon connecting I recieve, I get this warning message.

Warning Notice!    You are accessing a U.S. Government information
  system which includes this  computer, network, and all attached
  devices. This system is for  Government-authorized use only.
  Unauthorized use of this system may result in  disciplinary action and
  civil and criminal penalties. System users have no  expectation of
  privacy regarding any communications or data processed by this 
  system. At any time, the government may monitor, record, or seize any 
  communication or data transiting or stored on this information system.

What constitutes unauthorized access? Is it illegal for a US citizen to download information from the NCBI? What does this mean?
EDIT:
Below is the command I entered
ftp ftp.ncbi.nlm.nih.gov

","['data-request', 'data.gov']",
US Individual Income averages by county and age brackets,"
I'm looking to create an average income for individuals based on their location and age. I have the average income by US county (census data), but I'm looking to combine this with age. Where can I find average income by age bracket and location? Gender income by state would also be helpful.  
","['data-request', 'us-census', 'income']",
Getting Started with the OpenFDA API,"
I am totally lost with the OpenFDA API. I've downloaded the API from Github, run the bootstrap.sh, run python setup.py install, and I have no clue what to do now. 
My specific questions:
1. Downloading data
The API Reference page mentions a way to write code to download the data automatically, and then it gives me a nice bit of ""download API query"" code without every telling me how to use this code from my machine (this means: to download the dataset, not as a query to retrieve database information using search or connect. This was already covered in excellent detail and I understand it quite clearly).
2. Running the API Locally
When I navigate to api/faers/ and open the README.md file, the first instruction tells me to ""Get an ES instance running locally with data in the FAERS mapping format."" 
Um, how do I do that? 
If I proceed with the other steps, I get connection refused errors on step 4. 
3. Querying from my machine
Similarly to question #1, I'm confused about how to query the database from my machine and especially how this relates to the API key. Can someone give me some example code or point to a tutorial on this---I can't seem to find any. 
As a final note, I am not interested in any links to sites you have made that have already done this for me; I am only asking for help with setting it up for myself.
Thank you!
","['api', 'openfda']",
dataset with date of birth of both partners and date of marriage/divorce,"
I'm looking for a dataset with the date of birth of both partners and the date of marriage/divorce. The reason why is to generate the zodiacal sign of both partners.
",['data-request'],
List of English Nouns and their Plural Form,"
Is there a list of nouns and their plurals?
E.g. apple apples, genius geni, roof rooves, etc.
I have the GCIDE dictionary but that only contains singular nouns.
",['english'],"This python package can pluralize words for you, you can just run your entire dictionary through it to get the plural forms: http://www.clips.ua.ac.be/pages/pattern-en#pluralizationFor this you first need Python, I myself use winpython, but any python installation would do. You can then download the pattern package here: http://www.clips.ua.ac.be/pattern"
Asking for Diagnostic database Chronic Lymphocytic Leukemia (CLL),"
I am an M.A. student of Shahid Beheshti university medical informatics. My thesis is about (Cancer DataMining, Chronic Lymphocytic Leukemia (CLL) diagnostic based on clinical registry. not genomes)... but I could not find these dataset.I could  not also extract diagnostic information from site SEER.
I need to clinical information and CBC: 100 Patient. 
please help me
I am looking forward to your reply.
Sincerely Yours
M.SH
","['data-request', 'machine-learning']",
Gas price per station dataset,"
I am looking for a dataset containing the following field:

history of gas prices
geolocation


I am mostly interested in the following locations:

California, United States
Massachusetts, United States
Paris, France
Seoul, South Korea

",['data-request'],
Get specific metadata from a group of open databases,"
Use case:
I am investigating common characteristics of chosen databases. By databases I understand collections of data, possibly with relations between them.  
I want to collect metadata for all databases that I could possibly find that meet some criteria. That accounts for two steps:

Getting a set of databases available publicly
Getting metadata that describe these databases e.g.


number of datasets/tables/collections
size of these datasets (filesystem, number of records)
etc.


Question:
Is it possible to find such data? I could possibly write a script that fetches that information if it is hard to access manually but is it actually possible to find?
",['metadata'],
Median age by state/city in Germany?,"
I would like to get any data that show median age by city/state in Germany (in English). For example, in Berlin it is 42.4, in Munich it is 43.7, etc...
It would also be better if I can get just the whole population demographics, such as in Berlin the number of males whose age is 20-24 is XXX, and male 25-29 is YYY, etc... for all states/cities. I would like to know which state is young and which is old, for your information.
","['data-request', 'demographics', 'germany', 'population']","It seems that the puzzle pieces to answer your question are available at https://ergebnisse.zensus2011.de/?locale=en#StaticContent:00,BEV_11_1,m,tableIt gives you population, by age and gender, for all of Deutschland as well as by Land, Administrative region, and District. Data is as of 2011.The site allows an export as XLS and CSV too"
Historical arthritis rates for Americans since 1990 to present,"
I'm looking for the percent of people with doctor-diagnosed arthritis in America, yearly figures since 1990 to present, or whatever you have in that date range. I'm looking for tabular data.

I found a CDC page on arthritis but cannot seem to find historical data. 
I found this report from a long Minnesota study but the data is only from 1955-1994, and 1994 is not new enough to take into account some variables I'm looking at. 
I don't know R and I don't have time to learn it, so things were I have to crunch numbers with more than a spreadsheet do not help me. :(

In return I offer a Google Docs spreadsheet with historical data of various diseases, especially inflammatory diseases in the US, since 1990. You may copy it but any changes you make will not be saved in the original. 
Thank you! :)
EDIT: I found some more data here. 

HP2020. This has more recent data.

",['historical'],
Cover letters written along with research paper submission,"
I am looking for a dataset containing cover letters written along with research paper submission (example). Ideally, with paper admission notification, and DOI of paper if published.
","['data-request', 'research']",
Outbound sales call center data,"
Is there an open / available data set that covers the operations of a outbound sales call center. The intention is to look at some of the following question

Sales per person per hour
Successful contacts vs non successfull contacts
How many are quick vs slow failures. e.g. immediate hangup vs no sale after spending some time
How much individuals effect the result

Even if i could get the top 3 it would be of interest.
",['data-request'],
Where can I find the data for secular bull and bear markets?,"
I'm interested in doing some analysis on the Secular Bull and Bear Markets graph as found on this page. Ideally I would like daily data, but end of year data would be fine.
The article also mentions ""adjustments"". I was wondering what type of adjustments were done and what were they for.
","['data-request', 'economics']",
"Data used in Reinhart & Rogoff's ""Growth in a Time of Debt""","
Is the data used in the infamous ""Growth in a Time of Debt"" paper available somewhere? (Either the uncorrected or the corrected version.)
More info about the paper: https://en.wikipedia.org/wiki/Growth_in_a_Time_of_Debt
","['data-request', 'economics']","RR never posted their working spreadsheet, however some of the supporting data can be found on their website. That being said, the exact data used in their spreadsheet was posted with the Herndon, Ash, Pollin replication working paper here: http://www.peri.umass.edu/236/hash/31e2ff374b6377b2ddec04deaa6388b1/publication/566/ The final version of the HAP paper can be found here: http://cje.oxfordjournals.org/content/early/2013/12/17/cje.bet075 "
Reliable point spatial data of cities of New Zealand,"
Can anyone refer to the reliable and freely available point location spatial data source of the cities of New Zealand?
N.B. I used several data sources but found all of them are not accurate e.g. this and this.
","['data-request', 'geospatial', 'releasing-data']",
First and last date in YYYY-MM-DD format of ISO 8061,"
Which is the first date of ISO 8061 format? Is it by Georgian Calander (1582-1-15) or 0001-1-1 ???
Which is the last date? I guess it must be 9999-12-31. Am I right???
The citations given in Wiki are not proper.
",['data-format'],
Garages known to fraudulently upsale,"
I am looking for a dataset containing a list of garage known to fraudulently upsale (=inducing the customer to purchase unnecessary items, upgrades, repairs or other add-ons in an attempt to make a more profitable sale. example, mirror). 
Ideally, the dataset should contain information pertaining to the detection of the fraudulent upsales (e.g., fraudulent upsale detected by CBC Marketplace on  2016-06-16).

I am mostly interested in the following locations:

California, United States
Massachusetts, United States
Paris, France
Seoul, South Korea

",['data-request'],
The unit for blood cell number is different in labevent. How could I unify them?,"
I just want to unify the unit for lab measurement data in labevent table for mimiciii. But I found there are two types of units for counting numbers of blood cell: #/uL and %. I could not find the source of this unit ""%"".
I guess the unit is different according to different types of blood cell. How should i unify them? The table below shows the question. The first column is loinc_code. The third column is value. The last column is unit for this value

Thanks for answering!
",['mimic-iii'],
A list of all the banks by country,"
I'm looking for a list of all the banks and their details, or just the biggest ones, by country. Is there any? 
","['data-request', 'finance', 'bank']",
Ookla/NetIndex data dump,"
A wonderful resource that earlier used to exist for researching global Internet speed and quality was Ookla's NetIndex. Ookla has discontinued public download, I believe since 2015. Does anyone have a dump of the last publicly available source data? 
","['data-request', 'internet', 'global']",
Time Series for Regression,"
I am searching for time series data for regression problems. To clarify: I want to do machine learning on a time series and predict a single real continuous value for each time series, but I do not want to do forecasting (so I do not want to predict the next value in the time series).
An example would be to predict the lifetime of different components, which are monitored by sensors.
Does anyone have a good idea, where to get such data (does not have to be the component example)?
","['data-request', 'time-series']",
NBA game timeseries data,"
ESPN provides NBA ""game flow"" data, which show the score for each team over the course of the game. It's just a timeseries - score per team per timestep (assuming minute) of the game.  
Other posts have asked for game scores, which appear to be available here. I want the timeseries of score per team per timstep for each team, which isn't addressed by the prior post. 
Where I can find (or scrape) this kind of data for historical NBA games (e.g., this season)? 
","['data-request', 'sports']",
Is the protocol different for accessing data.dol.gov and api.dol.gov?,"
Trying to access the DOL API - specifically DOL OSHA Enforcement Data.   Currently using PHP to make the API Call however merely changing the host and URI (from api.dol.gov to data.dol.gov and from /priorDataSet/DataTable to /get/violation/violation for example) does not work...    
***Edit***
Don't think the SDK works for data.dol.gov - direct HTTP Requests may work
***UPDATE***
SDK is broken for data.dol.gov. Can be fixed by replacing 'http://quarry.dol.gov' with 'https://data.dol.gov'
","['api', 'labor']","Yes, it is different, though you can use the same key.  At http://developer.dol.gov/beginners-guide, right above the ""Accessing the API"" heading, are two tabs.  One is for api.dol.gov, the other is for data.dol.gov.We'll get the PHP SDK fixed momentarily."
MIMIC dataset : How to find time since first admission,"
In the process of creating a survival dataset the time to death after first admission needs to be calculated. For patients who are still alive how can the duration-alive from first admission be calculated. In other words from what date should date of first admit be subtracted.
",['mimic-iii'],
Getting a full list of companies registered in Malta,"
The Malta business registry provides a calendar option to download data on companies on 15 days chunks http://rocsupport.mfsa.com.mt/pages/RecentlyRegisteredCompanies.aspx
I am pretty sure the calendar tool can be tricked and an argument can be passed so that an entire list of all companies registered can be retrieved at once. I've tried several options with no luck.
Has somebody done it or has similar experience?
",['business'],
"DOI with source code, slide or poster","
Sci-Hub does a great job linking DOI with the associated paper. I am looking for a data set that links DOI with other materials pertaining to the paper such as source code, slide or poster.
","['data-request', 'research']",
Is there an open postgreSQL dump for geospatial data?,"
something along these lines:
https://wiki.postgresql.org/wiki/Sample_Databases
the open streetmap data is huge. I am looking for a small to medium dataset that is quick to download but diverse enough to play with and learn.
",['geospatial'],
Location of USPS Mail Boxes,"
Is there open data for the locations of USPS mail box locations? There are a number of sites that have this information like http://www.payphone-project.com/mailboxes/, but I'd like authoritative data.
","['data-request', 'federal']","Wow - this is way harder to find than I would have expected. I do think I found one potential lead for you from the source of truth (USPS themselves).As part of their API offering (https://www.usps.com/business/web-tools-apis/documentation-updates.htm) there is a ""Service Delivery Calculator"" service which takes an origination and destination zipcode and tells you the drop boxes nearby and what time you need to get the mail there for it to arrive by a certain time. This could be used to create a dataset of all the dropboxes in a given zip code. I hope there is a better way.You might also considering emailing USPS API folks at uspstechnicalsupport@mailps.custhelp.com."
Factoid question-answer pairs based on tables,"
I am looking for a data set that contains factoid question-answer pairs based on tables.
Example:

Table: 
Question: what is the capital of Egypt?
Answer: Cairo

Tables could be HTML, PDF or latex. I am most interested in table-question-answer written in English. 
","['data-request', 'nlp']",
From where can I get hourly weather forecast data of Europe?,"
The ECMWF website gives weather forecast data only twice a day (I'm only interested in temperature). Does anyone knows a reliable source for getting data hourly ? If ECMWF gives hourly data, then can anyone point me to that link ?
P.S. I don't want sources like forecast.io, wunderground.
","['data-request', 'weather', 'europe']",
Anti-infringment IP list,"
I am looking for an up-to-date, gratis anti-infringment IP list, i.e., a list of IPs of organizations searching for copyright infringement through peer-to-peer networks.
https://www.iblocklist.com/lists has such a list, but the access to it is not free of charge.
","['data-request', 'internet']",
"What are examples of open data platforms for government, with support for Arabic language?","
I would like to know which platforms can be used in government for open data access and customizable and support Arabic language.
",['data-portal'],
Deterministic time series,"
I need an example for pure deterministic time series which is not just dependent on time but on previous values, i.e $Y(t) =  βY(t-1) + f(t). It should not have stochastic trends in it. I need this for academic purpose.
Looking for an example of actual data, where I can explain the terms comparing to real world
","['time-series', 'analysis']","Exponential Decay formula would work.  is the remaining amout of material of the decay cycle is complete. 
If you start with 100 grams of x this is your 
If your decay rate is 2% this is your r. 
If you do 1 second increments that would be your t.
The remaining amount becomes your new initial amount  and you   It would take 230.258509299 seconds to only have 1 gram of material left.Actual examples of academic research, you can find at Exponential decay--Applications and examplesEdit: In my opinion another way of calling what you want would be a non-stochastic iterative time series. "
Where can I find the synset/name mapping for the ILSVRC2012 data set?,"
1) I have a list of 1.2 million ILSVRC2012 training/validation images with corresponding class codes, 000 to 999. Where can I find the name mapping for these codes?
2) Can anyone provide me a copy of the file ""synset_words.txt"" for the synset/name mapping of the ILSVRC2012 data set. Someone saw it mentioned on http://caffe.berkeleyvision.org/gathered/examples/imagenet.html but I can't find it anywhere on the web to include https://github.com/BVLC/caffe. 
","['machine-learning', 'images']",
API or dataset of fashion products,"
I'm looking for something like either an API that will let you query a catalog of products by category (for example trousers or shirts) and get comprehensive product information back or this same thing in the form of an offline dataset. The vendors doesn't matter but it has to be in fashion.
","['api', 'fashion']",
Scientific poster printing prices,"
I am looking for a dataset containing prices of scientific poster printing with as many following fields as possible:

Location
Poster sizes
Prices
Poster options (e.g., glossy)


I am mostly interested in the following locations:

California, United States
Massachusetts, United States
Paris, France
Seoul, South Korea

","['data-request', 'research']",
QCLCD vs. ISD Lite for U.S. data,"
I'm interested in using a NOAA dataset for daily/hourly weather data for the U.S.
Both the QCLCD and ISD Lite datasets contain the variables in which I'm interested for the time frame with which I'm concerned (QCLCD is only post-2005). However, I can't find any information about their differences in terms of coverage, construction, etc. in the U.S.
Does anyone have experience working with/understand the differences between these two datasets?
","['weather', 'noaa']","I emailed the NOAA and got a very fast response from William Brown:Both the QCLCD and ISD digital surface hourly data bases contain the
  same stations.  QCLCD is a 'subset"" of the much larger (global) ISD
  data base. Typically for research purposes I would recommend ISD.  You
  can download the data in bulk and, due to format differences only, the
  period of record is longer for ISD.So, it looks like the U.S. coverage for both is the same and that both are constructed from full ISD dataset."
What kind of spreadsheet/application are the Socrata datasets built on?,"
I have yet to see another online service for viewing spreadsheets that works as seamlessly as the Socrata sets. It seems no matter how much data or how many rows there are - it is always consistently fast. 
I'm curious to find out or  learn some details as to why it works so well, or who/what is powering the sheets, and if possible, what kind of code/language or application allows it to work so much better than sites that host spreadsheet services.
","['tool-request', 'software', 'socrata']","Socrata actually isn't built on top of an existing spreadsheet application or platform. We've built our own platform using a number of different open source technologies.Customer data is stored in our backend, where we use different datastores in a sharded configuration to make sure queries are performant while data remains highly available and safe. Long term storage in what we call our ""truth stores"" is managed by PostgreSQL while queries issued via our SODA API are dispatched to ""secondaries"" built on different technologies optimized for different query types. For example, a geospatial query might be sent to PostGIS while a free-text search would be sent to Lucene. Many of the components that make up our backend are open sourced on GitHubOur front-end is built in Rails and AngularJS, and the data grid is a custom component built with JQuery."
Want to understand MIMIC III warning in table Chartevents,"
In table Chartevents, there is a attribute named warning. What does it represent? for example if there is a data entry with ITEMID 220046 which represents Heart rate Alarm - High, what does warning value 1 means for that entry?
",['mimic-iii'],
Dataset of soccer betting odds and game results,"
There is already a question about soccer statistics, which summarises many data sources for team listings, game results, and many more fields for national and international teams.
What I am now looking for is a dataset (no API needed, a historical/static file is sufficient) that contains betting odds (e.g. 0: 1.7, 1: 3.6, 2: 6.0) before a football game and the game's result (e.g. 3:1).
Purpose: I want to write a small function that emits ""realistic"" game results when handed the odds, so I would like some historic data for estimating the results' probability distribution.
","['data-request', 'sports', 'football']",This might be exactly what you need:oddsportal historical oddsThis is a very neat data source. You can easily scrape the data with beautifulsoup (and you might have to work with a webdriver like selenium to control the page loading).
Where can I find UK local authority to county lookup?,"
I am using a dataset that has missing counties (UK). I think I can add these to the dataset where the record has a local authority.
I have searched the ONS website and OpenDataCommunities.org, as well as a general web search but have not found a straightforward mapping of local authority to county.
Ideally I'd like a csv file listing UK local authorities and the counties they belong in. 
",['uk'],"The Local Authority Service details holds the local council URLS for a number of services where the customer can directly transfer to the appropriate service page on any council in England.
http://local.direct.gov.uk/Data/The files downloadable are csv. "
high resolution (< 1.24km/pixel) physical map with global coverage?,"
I find ESRI's World Physical Basemap very good because you can see 1) topography, and 2) habitat. However, the problem is that it isn't very fine resolution (1.24 km/pixel outside the US), so it's only really useful for broader scale maps.
Does anyone know any high-resolution (<1.24km/pixel) physical map with global coverage?
",['geospatial'],
How to associate the MIMIC II Waveform Matched database to the MIMIC III Clinical database?,"
I am trying to associate the “MIMIC II Waveform Matched database” to the “MIMIC III Clinical database”, but my results are suspicious.
According to the documentation, the “sNNNN” identifier of the matched waveform database should be the same as the SUBJECT_ID of the Clinical database.
Citation from the documentation: 

…Each subdirectory of this directory contains one or more MIMIC II
  Waveform Database records that have been matched with a single subject
  (whose MIMIC II Clinical Database Subject_ID is the name of the
  subdirectory). The name of each mimic2wdb/matchedwaveform record is of
  the form sNNNNN/sNNNNN-YYYY-MM-DD-hh-mm where NNNNN is the matching
  MIMIC II Clinical Database Subject_ID, and YYYY, MM, DD, hh, and mm
  are the surrogate year, month (01-12), and day (01-31), and the real
  hour (00-23) and minute (00-59), derived from the starting date and
  time of day of themimic2wdb/matched record. The surrogate dates match
  those of the corresponding MIMIC II Clinical Database version 2.6 (or
  later) records; note that surrogate dates in previous versions of the
  MIMIC II Clinical Database differ from those in version 2.6 and later.
  …

However, doing so produces suspicious results. For example:

The first two patients (in them of numerical ordering) of the waveform matched dataset are “s00001” and “s00020”. The first two patients of the clinical dataset are “2” and “3”. 
The first patient ""in common"" in the two databases is the patient “20” (s00020 = 20). However, the record dates are not matching: The record of patient “20” starts at “2567-03-30 17:47:00” for the matched waveform dataset, while it starts at “2183-04-28 09:45:00” for the clinical dataset.

Any idea how to solve the problem?
Thanks,
Link to the documentation:
MIMIC II Waveform Matched database: 
http://www.physionet.org/physiobank/database/mimic2wdb/matched/
MIMIC-III Clinical Database
https://physionet.org/works/MIMICIIIClinicalDatabase/files/
",['mimic-iii'],
API for H1B Records,"
Is an API available for downloading DOL H1B application records?
If yes, would you please direct me to where I can find this API?
",['labor'],
Where can I find a products feed/catalogue .xml from any online store with <g:google_product_category>?,"
is there any online store that can share its XML catalog/product feed? I need mainly product  and <g:google_product_category> ... I'll be using this data to research word embedding models for product category classification. Shopping-related corpus is really hard to find and I really need a storage dump for this research.
",['data-request'],
"Rainfall, climate change data","
I'm looking for annual (or monthly) rainfall data over time and by country (specifically, for sub-Saharan African countries). I've been able to find data up to the year 2000. I know there has got to be more recent data but I'm having trouble finding it! Any suggestions would be much appreciated.
","['africa', 'climate']",
"The data from ""Data: A Collection of Problems from Many Fields for the Student and Research Worker"" by Andrews and Herzberg","
""Data: A Collection of Problems from Many Fields for the Student and Research Worker"" by Andrews and Herzberg : https://www.amazon.com/Data-Collection-Problems-Research-Statistics/dp/0387961259/ref=sr_1_1?s=books&ie=UTF8&qid=1465372463&sr=1-1&keywords=DATA+andrews+Herzberg
is a book with data and descriptions for teaching and learning statistics and data analysis.  The datasets from the book used to be on the internet, but now I cannot find them!  
Specifically, they used to be on statlib, but now that seems inaccessible too!
Anybody knows where that data collection can be found now?
",['data-request'],"The StatLib web site seems to be available again, but oddly, not all datasets from Andrews and Herzberg can be retrieved (20 out of 100 are missing).There is also a copy at Duke, with all datasets."
Wind region Data for New Zealand,"
Can anyone please refer me the vector data source of the wind region (LEE MULTIPLIER) of New Zealand as the map attached.

N.B.There are three data layers in this map-

Lee Multiplier
Coastal boundary
Cities

I need only layer 1
","['data-request', 'releasing-data', 'weather']",
Rules and regulations of all airlines in one site for consumers to compare,"
There are lot of rules and regulations that airlines have. At the same time, due to business dynamics and other changes in the environment, the rules get changed. It would be useful if there is a site where information from all the airlines were available under one roof and is parsed so people could compare on some functionalities without getting dodged by the length of reading material. 
It would be useful to two kinds of people. 
a. Newbie travelers or people trying to figure out the labyrinth of rules and regulations. 
b. Researchers who research trends about airlines and markets surrounding them.  
See https://travel.stackexchange.com/questions/70781/is-there-a-site-where-pdfs-of-all-airlines-related-to-passenger-rules-regulation/70782?noredirect=1#comment152300_70782 related to it. 
","['web-crawling', 'products', 'public-transport']",
Spatial Wind Direction/Speed Data,"
Does anybody know of a source for wind data ~04 - 14 for E. Africa or a larger area. I have looked at a number of sources but have not found anything for these consecutive years.
","['geospatial', 'weather', 'africa']",
Where can I get happiness data from the Gallup World Poll?,"
I'm looking for panel data for happiness and life satisfaction from the Gallup World Poll
","['data-request', 'survey']",
Telecommunication Customer churn Dataset,"
I am looking for a dataset for Customer churn prediction in telecom. I looked around but couldn't find any relevant dataset to download. Following are some of the features I am looking in the dataset:

Personal information: the date of activate, churn date...
Traffic details: Average of monthly calls number, daily average of calls minute...
Billing data: payment type, mean of monthly revenues, Delays in the payment of the bill...
Complaints information: number of register a complaint, number of repairs...

","['data-request', 'telecom']",
is there an open API for healthcare's medicaid / CHIP eligibility?,"
I'd like to make a healthcare website that would help customers find their healthcare plans easily. 
How can I check if the user is eligible for medicaid, or CHIP or medicare? I know how to get the FPL, but I'm still confused. 
","['data.gov', 'government', 'api', 'medical', 'healthcare-finder-api']",
Data about what kind of entities appear on public web pages,"
Schema.org is a vocabulary ""for describing the kind of entities the most common web applications need"" (source). But which entities would that be? Intuitively I’d say the most common entities are organizations (including companies, clubs, etc.), persons (authors, team members, etc.), products, and creative works (stories, movies, images, music, etc.).
Is there a data source that can give insight into which kind of entities appear on web pages how often? The source should make clear if it’s about entities the page is about, or entities that are described, or entities that are mentioned.
(The data source should of course not make use of Schema.org or some other vocabulary, because that would bias the results: you can only mark up content with existing types, but one of my goals is to find types that are missing.) 
To be clear, I’m interested in categories of entities (e.g., person, book, organization), not instances (e.g., Bazzel Baz, The Lord of the Rings, Internet Archive). 
Ideally with more specific categories, e.g. musician/author/CEO/etc. instead of person, and restaurant/political party/company/etc. instead of organization, etc.
","['data-request', 'web-crawling', 'internet']",
dataset on emergency response,"
Is there any open dataset on emergency response from the government agencies? Such as 911 or fire emergency.
Ideally, the columns would be emergency type, response time, geographic information of the caller and agency.
","['data-request', 'government']",Here are a few datasets that seem to meet your requirements:
Historic weather data for Germany in 1938,"
I am writing a book about my father, who was a Holocaust survivor. Does anyone know how I can find out what the weather was like in Bavaria, Germany (specifically, Weiden), on November 9-10, 1938 — kristallnacht?
","['weather', 'germany']",
List of countries that do not have psychiatric hospitals,"
Where can I find a list of countries that do not have psychiatric hospitals? I've searched on Google and Wikipedia but could not find any links.
","['medical', 'demographics']","It's not a sortable list, but the WHO keeps track of the mental health institutions per country and has a report on each country here: http://www.who.int/mental_health/evidence/atlas/profiles/en/They also provide a shaded map in their atlas which I copied below. You'll have to look up the reports on the lightly shaded countries to check wether they have any mental healthcare facilities at all."
World height and weight by age distributions?,"
Where can I find a map or distribution data got each country and even provinces within each country for body height and weight by age and how these very across the world? Thanks.
(Not sure if this question is more suited for this site or for the biology site. If the latter than please migrate my post).
","['data-request', 'demographics', 'global']",
"""Animals!"" decision tree dataset","
I think most of you remember that old game, called ""Animals!"", which is a binary decision tree (y/n) that stores animals and questions.
e.g. http://cs.smith.edu/~nhowe/112/Assignments/assign.dtree.html
I am looking for a database (as big as possible) containing questions and animals, as long as they're free to use.
",['games'],
"CC-SA (without BY) has been ""Retired"", but I want to use it anyway. Recommendations?","
I would like to release some content (graphics, text, and print designs), letting people reuse them with or without modifications. I don't require attribution, but I do want modified versions to also be ShareAlike.
Creative Commons has a ""CC-SA"" (no ""BY""), but it's retired and not recommended for use. 
CreativeCommons just says it was retired for low usage, is there any reason I shouldn't use ""CC-SA""? Is there a better alternative?
Thanks.
","['licensing', 'creative-commons']",
Extract all data from ckan,"
I'm trying to export all data from CKAN instances for a big data project.
How can I do this?
",['ckan'],
The W3C's tabular-data-model is de facto in use?,"
In nowadays (2016) what standard is a de facto standard for CSV file metadata,    W3C's tabular-data-model or OKFN's tabular-data-package?

NOTES
Important to remember: these metadata standards (W3C or OKFN) are machine-readable.  The question is not about human-readable standard, like a README format.
PS: original question at SO, checking if here is correct/better place.
",['csv'],
Precipitation and temperature GIS data for Pacific Basin,"
I need to know if there is any precipitation and temperature GIS data for these islands.

American Samoa
Federated States of Micronesia
Guam
Marshall Islands
Northern Mariana Islands
Republic of Palau

","['data-request', 'geospatial', 'weather']",
Is there a pre-2011 public version of USA's Social Security Death Master File?,"
I am trying to find an old version of the Social Security Master Death file. Specifically, one that has a county or residence zip code. The only public source for the full file that seems to continuously pop up is this: http://ssdmf.info/download.html
Unfortunately, it does not have the geographic information that I require as it is too recent.
I have tried to scrape some of the websites that list the geographic information. However, the process is very lengthy. Furthermore, their location search filters do not always function well. Recently, I tried to find the number of deaths in a given county for certain years. While some results made sense, others were way off of what they could realistically be.
Any help in this regard will be greatly appreciated!
","['data-request', 'usa']",
Large discretely labelled biological data sets,"
I'm currently investigating the utility of deep neural networks for classification for problems in biology. As such I am trying to find large (n > 1000) discretely labelled datasets to work on. 
I don't have any more specifications beyond this, any suggestions are appreciated. Thanks. 
Edit: I found kaggle competitions (old and new) to be a great source.
",['biology'],
Data on hurricanes?,"
As a programmer and meteorology enthusiast, I'd love to be able to get latitude/longitude of tropical storms/hurricanes (specifically in the Atlantic). Does anyone know of websites that can provide information regarding tropical activity? I looked at the NWS's API (http://graphical.weather.gov/xml/), but it doesn't seem to give such data.
","['usa', 'api', 'weather', 'programming']",NOAA's Hurricane Center has current gis as well as archived hurricane data
Open Data Portal/Software for Live Measurements: is there any?,"
I am working in meteorology/glaciology. We have quite a lot of observations (partly live!) and we would like to publish these data (live!) to the world.
So what we are looking for is a portal/software that allows publishing such ""time series"" data. This would include data such as temperature measurements, precipitation measurements, maybe glacier length changes, and so far and so on.
There is a chance to get some money of the national science fund - smaller projects to make data from past projects available to all of you. As I could not find anything suitable on the web:

Is there something like this but I was too stupid to find it?
If not: do you think that there is a need for it?

The idea - if not yet available - would be an open source software including a flexible backend, data upload interface (e.g., xml data xchange via scp/ftp/web upload), and a frontend offering ""simple"" data series plots, data exports, and that the uploader/maintainer of these data sets can write/upload notes, manuals, important information (e.g., instrument correction coefficients, when instruments have been maintained/replaced, ...).
Thank you very much for the input! We are currently in a ""discussion"" or ""rough project planning"" phase and all comments or hints will be more than helpful!
","['uses-of-open-data', 'time-series', 'real-time']","usual suspects:
CKAN
JKAN Plenario.io seems to be something along what you want...but I may be mistaken here NASA seems like they will/do have a solution for this: they publish vast quantities of data, that sound very similar to what yours sound like. It may be worth your while to check out:
NASA Open Source Software
openNASA
NASA's GitHub Profile "
Suggestions for Canadian (Metro Vancouver) Housing Open Data Sources,"
before doing data analysis, I have to find public data sources first. The goal is to find housing services related data, or people data related to these housing services, in different regions of Metro Vancouver.
Especially focus on those housing aims at improve individual well being or community well being.
I searched for many lists of this type of services, checking their websites, social media or reading their reports, but could not find public data for my data analysis.
I have also checked Canada Council, Statistics Canada, they don't have specific data for regions in Metro Vancouver...
Do you have any suggestions to find this type of data contains Metro Vancouver regional info?
","['data-request', 'canada', 'real-estate']",
Data on glaciers,"
I am looking for historical and current data on glaciers. Data such as glacier length changes, mass balances, imagery, flow speed, outline, runoff, etc. Does anyone know websites and databases providing these data?
","['geospatial', 'weather', 'climate']","The World Glacier Monitoring Service hosts database with mainly mass balance, front variation and thickness change data. The main website is: 
http://wgms.ch/ the map with data can be found here: http://www.wgms.ch/metadatabrowser.html The Global Land Ice Measurements from Space initiative hosts another extensive database on glaciers, this one mainly containing shapes of glaciers: the glacier outline and the basins of (parts of) the glacier. The main website can be found here: https://www.glims.org/ the map can be found here: http://www.glims.org/maps/glims and the downloadable inventory here: http://www.glims.org/RGI/rgi50_dl.htmlBased on the WGMS dataset it contains data such as location, area/lenth/width, elevation, classification, orientation, and ablation and accumulation area:
https://nsidc.org/data/docs/noaa/g01130_glacier_inventory/In my experience, the U.S. Geological service is happy to provide data when asking them. This is their website: 
https://www2.usgs.gov/climate_landuse/clu_rd/glacierstudies/default.aspThe NSIDC has gathered links to over 200 different data sets on glaciers, amongst which the glacier databases I named in this answer. They also have links to datasets on specific regions with various quantities, such as bedrock elevation, atmospheric values over the glaciers, images, etc.:   http://nsidc.org/data/search/#keywords=glaciers/sortKeys=score,,desc/facetFilters=%257B%257D/pageNumber=1/itemsPerPage=25Furthermore, a database on U.S. glaciers is being set up here: http://glaciers.research.pdx.edu/Several countries with glaciers prefer to keep all data on these glaciers confidential. This is especially true if the glacier's runoff feeds a river flowing into a neighbouring country. Parts of the Himalayas are a good example of this."
Download wikipedia dump and save in raw text form,"
I have been trying to use Wikipedia text data for my personal research.
I know that crawling is not good for the Wikipedia server so I downloaded a big XML file from https://dumps.wikimedia.org/jawiki/latest/, especially I downloaded 3 files jawiki-latest-pages-articles1.xml.bz2, jawiki-latest-pages-articles2.xml.bz2, jawiki-latest-pages-articles3.xml.bz2 and it was a success.
When I check the data using my python, I noticed it is in wiki-specific format (wikitext).
How can I parse wikitext into plain text?
I could not find any good third-party parser.
Most of what I found was no longer updated.
",['wikipedia'],
Lobby meetings of European Commission - Integrity Watch,"
The staff of the European Commission is obliged to keep a register of their meetings with lobbyists. The site Integrity Watch administered by Transparency International keeps track of these meetings on their webpage.
They pull together data from more than 90 original sources of the EC. All the links to the orginal sources can be found here. Instead of webscraping the original sources it would be great to just get the table from Integrity Watch. Unfortunately they didn't reply to my question about download options yet. My attempts to webscrape the page in R (rvest) failed because of the interactive nature of the table. Any experienced webscrapers who could give some hints and code chunks for R or Python? 
","['web-crawling', 'europe', 'programming', 'python', 'politics']",With a hint from a person from Transparency International and some further browsing through the source code this link eventually made it work: http://static.tttp.eu/doi/data/meeting.csv 
Indian Newspaper Archive,"
I want to present some data regarding the leaders of Indian constituency. So please help me to get available the newspaper archive of last 60-70 years.
","['data-request', 'media']",
Academic research laboratories,"
I am looking for a dataset containing academic research labs with as many following fields as possible:

Location
Field
Name of the head
Number of research scientists, post-docs, PhD students, SM students, and undergrads.

I'm mostly interested in the US and computer science.
",['data-request'],
Data on jcpenneys sales,"
I'm looking for a source for prices on jcpenneys items from the years 2010-2015. This is to investigate their fair and square marketing disaster. However, I cannot find any catalogs online or any sort of way to map out prices through those 5 years. 
Where can I get a data set for this?
","['data-request', 'web-crawling']",
Getting data on real property sales,"
Does anyone know where I can get data on real property sales and listings, for a certain area? I need data from just one neighborhood, green Valley Ranch in Henderson, NV. I would need the following: address (or map position) square footage bedrooms bathrooms date of sale recorded sale price, as well a measure of how fast the property sold, like days listed or time between listing and sale. 
I see there are some similar questions and I read all of them, but I was unable to find the answer I need. Do I need to scrape this data together by individual queries? Plus, I had the hardest time finding the recorded sales. Shouldn't this be public information?
",['data-request'],"It looks like you are looking for quite some specific information. I work at Quandl and we have this free database with real estate info: https://www.quandl.com/data/ZILL If you search for ""Henderson, NV"" within the database, you'll get data on home and rental prices in Henderson depending on number of bedrooms etc and there's also data on price per square feet. Actually, try this link to see Henderson data specifically: https://www.quandl.com/data/ZILL?keyword=henderson%2C%20nv And try this link to see data on Green Valley Ranch: https://www.quandl.com/data/ZILL?keyword=valley%20ranchIt might not show quite what you're looking for, but I hope it's close and is a good start."
feature importance analysis [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 7 years ago.







                        Improve this question
                    



I am having a very hard time in analysis of my features importance. What I am doing is I have 4 features and I incrementally add the features to see the effect of each feature on the final result. When I start with feature 1, for instance 300 out of 600 wanted data will be discovered. Then when I add feature 2, 100 out of 600 will be discovered and so on. However when I start with f2 then instead of f1 then 270 out of 600 will be discovered and this number for f1 will be for instance 200 out 600. So depending on which feature I incrementally add the importance of each feature varies and does not make sense. can any one suggest a beer way how I can analyze the imporance of feature in this case?
","['machine-learning', 'nlp']",
How to modify SOFA query to obtain daily SOFA up to day 7 in MIMIC 3?,"
How to modify  SOFA query to obtain daily OSFA up to day 7 in MIMIC 3?
",['mimic-iii'],
SWIFT routing codes for all global banks,"
Does anyone know if it's possible to get SWIFT routing codes for all banks, or only on a per-country basis?

(this came up in my Twitter feed - I thought it was a good question and I didn't find any easily usable data already available.)
","['data-request', 'finance', 'global', 'bank']","There are a number of paid API services that allow such requests. Trying to advertise commercial offerings as little as possible, I can mention the original SWIFT API.You could probably also scrape data from this site. I've been using another one that allows up to 20 free requests a day. However, these two, and possibly any other services might not guarantee to have all jurisdictions and all banks present. This is mostly due to the regional particularities of nomenclature that result in associations that might appear sometimes strange and not following an algorithmic approach."
Queryable source of large cities,"
I'm trying to get a list of major cities in the world: their name, population, and location.  I found what looked like a good query on Wikidata, slightly tweaking a built-in query example:
SELECT DISTINCT ?cityLabel ?population ?gps WHERE {
  ?city (wdt:P31/wdt:P279*) wd:Q515.
  ?city wdt:P1082 ?population.
  ?city wdt:P625 ?gps.
  FILTER (?population >= 500000) .
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". }
}
ORDER BY DESC(?population)

The results, at first glance, appear to be good, but it's missing a ton of important cities.  For example, San Francisco (population 800,000+) is not in the list, when I specifically asked for all cities with a population greater than 500,000.
Is there something wrong with my query?  If not, there must be something wrong with the data Wikidata is using.  Either way, how can I get a valid data set, with an API I can query from a Python script?  (I've got the script all working for this; I'm just not getting back valid data.)
","['data-request', 'geospatial', 'api', 'city']",
Citation Network Dataset,"
I am looking for an exhaustive Citation Network Dataset for research papers, ideally identified with DOIs.
So far I have found:

ACM-Citation-network and DBLP-Citation-network V8


which are quite small compared to the number of research papers (> 50 millions)

There is also the  Patent citation network, but it pertains to patents, and not research articles.

","['data-request', 'research']",
Are there any Open datasets for Human Resources?,"
Are there any Open datasets/Taxonomies/… for Human Resources ? They would probably have to be anonymized. On any of the following topics

Assessments/Background Checks
Benefits Enrollment
Recruiting
Salary
Timecard
Interviewing 
Assessments
Employee Benefits
Onboarding
Payroll
Performance Management
Screening
Stock Plans
Time Management
…

","['data-request', 'economics', 'labor', 'companies']",
"Sample Landbase data for Bharatpur Area,India","
Does anyone have sample landbase open data or any linked data (in .shp or .kml or personal geodatabase format) for Bharatpur and Kota Area in India?
","['data-request', 'uses-of-open-data', 'india']",
E-cigarette accidents,"
I am looking for a data set that contains e-cigarette accidents where e-cigs have exploded and damage someone around (e.g., the vapers), with as many following fields as possible:

timestamp
geolocation
casualties and nature of casualties
model of e-cig

","['data-request', 'medical']",
Netflix Data set,"
One of the canonical examples of a big data competition was the Netflix prize data set. It seems to have disappeared from the Internet. Is that the case, or is it still accessible somewhere?
",['machine-learning'],"It appears that the Netflix data set is no longer available. According to the UC Irvine Machine Learning Repository: Note from donor regarding Netflix data:  ""Thank you for your interest
  in the Netflix Prize dataset. The dataset is no longer available."" - http://archive.ics.uci.edu/ml/noteNetflix.txtBUT WAIT, there's more... perhaps it is available as an archive - https://archive.org/details/nf_prize_dataset.tar BUT WAIT, EVEN MORE, it is also up on the archive in its true form:
https://web.archive.org/web/20090925184737/http://archive.ics.uci.edu/ml/datasets/Netflix+Prize"
Publicly available high frequency financial datasets,"
I am looking for publicly available high frequency financial data e.g stocks, forex, etc. It would be great if someone can provide relevant links.
TIA!
EDIT: To be more specific, are there any open resources where I can get hourly/ minute level or tick data?
Regards,
Lesnar
",['data-request'],I just came across this yesterday: https://github.com/eliangcs/pystock-data powered by https://github.com/eliangcs/pystock-crawlerThere's also this measure of the CBOE Volatility Index on the Open Knowledge Labs datasets repository: https://github.com/datasets/finance-vix
Where is the 2014/15 College Scorecard Data (US Dept. of Education)?,"
The U.S. Department of Education's College Scorecard Data download is only giving me 1996 through 2013, yet the description under ""Download the Data"" implies that there should be 2014 and 2015 data in the download. The option to download the most recent data under ""Featured Downloads"" downloads data for 2013. Is the 2014/2015 data available? If so, where is it?
",['collegescorecard'],
Expamples of municipal decisions register published as open data,"
can anybody give me any examples of municipal decisions register (eg. planned road closures, approval of private use of public spaces, sanctions issued to citizens for not obeying municipal regulations, list of municipal regulations...).
","['government', 'city']",
Is there any source to download German data set for crop disease incidences for last 20-50 years?,"
I am looking for the crop (especially grapes) disease incidence data set for Germany for the last 30 to 50 years, but I am not able to find it.
Does anyone know of any data source?
","['data-request', 'germany', 'disease']",
MIMIC II WAVEFORM V2 and V3 annotation file,"
On MIMIC II Waveform version 2 (http://www.physionet.org/pn5/mimic2db/), have 
an additional .alM annotation file for the 498 records listed in RECORDS.alM and alarm annotation files, with ""chan"" field that has been used to indicate if the alarm was judged to be true (1) or false (3) by expert human review. 
Is mimics II version 3 (https://physionet.org/physiobank/database/mimic2wdb/) also contains this files?
another question about the annotation file - in the website is written ""The timestamp associated with each alert indicates when the definition for the corresponding alert is satisfied (not the time of onset of the condition)""
, what does it mean that the timestamp next to CHAN column indicate when corresponding alert is satisfied?
Thanks
",['mimic-iii'],
"Where can I get metrics data on one retail store, for 3 - 4 years time?","
Where can I get metrics data on one retail store, for 3 - 4 years time? I need data such as sales per day, conversion, number of transactions, number of units, etc. 
Granular data per hour or per sales person, even better. Conversion/traffic is an absolute must. It could be data for one store, but data on multiple stores, same company, even better.
I can use an API or scrape if needed.
","['data-request', 'finance']","It's not likely that this data set would be open, but you can use pseudo-data, for example the Superstore example from Tableau (there is an downloadable Excel file in the page).If you're flexible with the data-request, then I would suggest thinking of ""retail-like"" stores that may satisfy your need. For example, would a national park or museum work? For public or government entities, it's easier to find open data."
Historical and Current Houses Listed for Sale within Price Ranges,"
I am need of finding data for housing prices in aggregate values such as; 
Homes listed for sale or sold - 0 - 100k, 100 - 200k, 200 - 300k, etc. for a given time period, like as of 12/31/2012. 
I need this data in order to determine the availability of homes for sale for certain income levels within certain metropolitan statistical areas, I have searched the FHFA website but could not locate anything other than HPI and median household price for the given areas. 
So in essence I would need; 
In Metropolitan Statistical Area (41740 - San Diego, for example) 
As of 12/31/2015:
X amount of homes for sale between 0 - 100k
Y amount of homes for sale between 100 - 200k 
Z amount of homes for sale between 200 - 300k
etc. 
",['data.gov'],
USA Road Network Data Set Options?,"
I need a contiguous, nationwide USA Road Network with speed limits, distances, etc. I have been using TIGER but the challenge is at state boundaries - where contiguous road segments are split.
Is there any free or commercially available data set that provides this data, besides ESRI/ArcGIS?
","['data-request', 'geospatial', 'traffic', 'openstreetmap']",
De-duping follow-up reports,"
In openFDA's source code documentation, it's said that the FAERS pipeline includes a procedure for de-duping follow-up reports.
I don't find in the source code where it happens.
What does it mean? Only the last follow-up of each case is kept or what?
",['openfda'],This used to be handled within the source code. It is now handled by processing the quarterly reports sequentially and letting Elasticsearch handle the versioning. A basic last-one-wins approach. The openfda team added a feature to the pipelines for incremental indexing that allows this to happen without too much of a performance hit.I will have the documentation updated to reflect this change. Thanks!
Contaminated land data for Scotland?,"
I'm looking for contaminated land data for Scotland. I know this is managed by SEPA, but I can't find any links to download this data.
","['environment', 'land']",
where can i find time series data sets of Australian beer consumption?,"
Where can I find time series data sets of ""Australian beer consumption"" and the amount of carbon dioxide measured monthly in the Ankara capitol of Turkey (ANSO)?
","['data-request', 'time-series']",Google?50 years of Australian beer consumption - (my source)Google?Air Quality Index and official data source from Turkish government.
Is there any picture corpus?,"
By ""picture corpus"" I mean the picture collection each illustrating one word in the usually used vocabulary, such as words in Google 10000 English I found on GitHub.   
For instance: vocabulary

source: Youdao
I've crawled 2033 pictures for 2033 words (mostly nouns) in the aforementioned Google wordlist from Youdao, but it's not enough.
","['data-request', 'language', 'images', 'corpora']","You may be able to use the International Picture Naming Project (IPNP), but I think the total pictures are way less than 10k.Here's a link to the query tool.You may get lucky searching through ""image recognition"" research websites. Here's one compilation of online resources, and a particular one."
Daily access pattern of a real cloud storage,"
for a current research project I would need file access traces of real world cloud storages. Unfortunately I was not able to find any yet. 
More precisely I need real world traces with at least the following information: filename, file size, access time, operation (put, post, get, delete). The kind of data (if the files are images, textdata or something else) does not matter. Furthermore, it is also ok if it is not a cloud storage, but for example an online image gallery, as long as all 4 operations (put, post, get, delete) are included its fine for me.
Any help would be appreciated.
",['data-request'],
Bids on apartments,"
In some countries, such as the USA, apartments are usually sold through real-estate agents: the buyers send bids to the agent, the agent forwards the bids to the seller, and the seller selects the winning bid.
It is easy to find data on the final price for which a house was sold. Where can you find data on the other bids - the losing bids?
My goal is to build a model for the distribution of bids above the final price. 
Probably, real-estate agents have such data, but do they make it public?
EDIT: I will be happy for data from any country.
","['economics', 'real-estate']",
Data on percentage of name in the UK and US,"
Where could I find datasets of the percentage of name in the UK and US? I am looking at both first name and surname. And is it even possible to find such dataset?
","['usa', 'uk', 'names']",
Any geospatial irrigation data for the UK?,"
Are there any geospatial datasets for irrigation in the UK?
I've had a look through https://www.ceh.ac.uk/data but there isn't anything for agricultural irrigation in the UK.
","['data-request', 'geospatial', 'uk']",
Mobile applications usage,"
I am looking for a dataset that contains information on users' usage of different applications on their phone. I couldn't find any related data in this context. 
",['data-request'],
Directory of professional vertical web services,"
I have a made full business solution for small businesses on construction sites and want to publish it in a directory to better find it. I don't want to rely on SEO only.
There are either horizontal services every business needs, as webmail, online spreadsheets, hosting services 
OR 
vertical services for specific businesses, e.g. a tennis court rental solution, a barber shop online solution, a pizza delivery service solution or whatever a business is targetet to. 
Having googled for a long time, i just can find directories for horizontal services but not for professional vertical services, with 

online registration for the business owner
billing on a monthly basis
ready to use customer frontend
hotline services and so on. 

such a service replaces the need of lots of software to be installed on a pc/notebook/server and can be set up within minutes. 
already tried yahoo, google, dmoz, ... for weeks but there is no way to filter and find such vertical services. 
EDIT: Is there a protocol to publish such services? In the webservice definition once there was UDDI specified but I don't this of great relevance today.
",['data-request'],
Basepairs from the Human Genome Project,"
How do you use GenBank to pull the count of actual base pairs (and actual bases) that were uploaded week-by-week across the entire Human Genome Project in its early years 1990-1998?
Ideally, we want to be able see the count of base pairs as reflected in this graph - and pull the base pairs too. 

","['research', 'genome']",
Automating NOAA reanalysis data download,"
Not sure if this question is on topic but I want to be able to automate the download of data from this site using a script- http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.pressure.html
Currently I can go here and manually download by clicking the variable that I want (such as surface pressure, time of day that I want the data , subset for the region and the pressure level(such as 500 hPa etc).
The same can be accomplished by harcoding the value of file that I want to download in a script.
I want to automate this process with some intelligence using a script. I want to pass as input the following
a) type of variable that i want to download such as surface pressure or temperature
b) time i.e data corresponds to which day
c) latitude /longitude of the subset that I want to download
d) pressure level( 500 hPa, 850 hPa etc).
These four variables will be sent each time for each HTTP download request.
Is that possible ? 
","['api', 'noaa']",
Is there an open standard for the CAFR (Comprehensive Annual Finance Report)?,"
I would like to push my local government to provide the Comprehensive Annual Financial Report (CAFR) as an open data source.  I was wondering if we could go one step further by providing it in a particular open standard. 
","['government', 'finance', 'standards']","There does not seem to be a separate data standard for CAFR, but you may want to consider XBRL (eXtensible Business Reporting Language). The State of Oregon piloted providing CAFR in XBRL format and there are some tools that exist to help provide XBLR formats of a CARF.  "
Past Lightning (weather) data,"
I am looking for data about lightning for the state of Colorado. I'd like to get them in geospatial data.
I want to display them in point showing them each county especially up in the mountains.
I am aware that the NWS in Pueblo has their map showing each county in percent numbers but that does not provide us information about each lighting strike..
","['data-request', 'geospatial', 'weather']",I know that 'Convective available potential energy' has a very strong correlation with lightning probability. This data you can get here at 6 hour intervals worldwide since 1979.
Is the data on the OpenFEC API current?,"
Is the data on the OpenFEC API current as my team seems to be noticing descrepancies between data pulled down from OpenFEC API and Fec.gov
",['openfec'],
Same-sex couple data from American Community Survey (ACS),"
I tried to find the same-sex data from ACS and collect them at the census tract level. There are some good information in the website (see below) but it doesn't specify which tables have such information.
http://www.census.gov/hhes/samesex/data/acs.html
After some research, I did find the ""unmarried partner household"" information from table B11009. According to census analysis, same-sex couples include ""same-sex spouses"" and ""unmarried partners"". Could someone help me identify the table(s) which includes the same-sex spouse information?
","['data-request', 'us-census', 'lgbt']",
Natural language corpora dataset with time stamps,"
I'm looking for a dataset of documents (bag of words style is fine) which include time stamps.  
I also need it to be semi-coherent, for instance a years worth of news articles which all focus on the economy/finance, broken down by day, or something like that.  If it's just a broad collection of documents that aren't really related that doesn't work for me.  Something around 30k to 100k documents would be ideal.
I have scoured the internet but haven't really found any datasets of this type besides the NSF abstracts corpus, and unfortunately that doesn't really contain enough in the way of changing temporal dynamics.  I need something that's either faster changing (like news), or spans a much larger time interval.
","['data-request', 'nlp']",
Data from the Great Lakes Science Center's Annual Bottom Trawl and Acoustics Surveys,"
The USGS's Great Lakes Science Center surveys fish populations every year in the Great Lakes. The results are compiled into reports, but is the underlying data available anywhere?
","['data-request', 'federal', 'usgs']",
Progresa/Oportunidades dataset,"
Progresa/Oportunidades is a large scale social welfare program that was conducted as an RCT and that has been widely evaluated (for a list of econ papers using this data see here).
When trying to find the data sources, links (e.g. on dataverse.harvard.edu) point to a website that doesn't exist: http://evaluacion.oportunidades.gob.mx:8010/en/index.php
There is main website has a ""Databases"" link, but provides just a bunch on individual datasets, without a clean documentation, and apparently without the data on treatment assignment.
Hence my question: Does anyone know of a reliable source for pre-compiled Proresa data including the treatment indicator and post-treatment outcomes?
Edit: Data should be on the household/individual level
","['data-request', 'latin-america', 'randomized-trial']","Wayback Machine has this indexed a few times. Remember, when dealing with linkrot, the Wayback Machine is your friend:
https://web.archive.org/web/20150421004546/http://evaluacion.oportunidades.gob.mx:8010/index1.php Edit:
Why would it not give you access to the data? I can only think of a few occasions where this would be the case, and in this one, it is not. All you had to do was look...Better Edit:
The data you seek is here: https://www.prospera.gob.mx/EVALUACION/index1.php
From navigation: Evaluation and Indicators -> External Evaluation Reports & Studies -> Oportunidades
Double clicking on each datasets' header (colored background) displays dropdown with data for downloading.
You can compare the original 2003 docs to current, they are the same:
2003 Original
2003 Current"
Should the testing of my learning algorithm be restricted only on standard datasets or can I use any dataset to publish my results?,"
I've trained a speech recognition model using the LibriSpeech database which isn't as widely used as other datasets like TIMIT or MNIST. Does that factor in any way or can I publish the results irrespective of what dataset I use?
The reason I ask this is, if we only use datasets like TIMIT, models could be made to overfit those datasets for greater accuracy.
Is there a thing such as standard datasets in speech recognition?
Or else, which are some other easily available speech datasets for multiple languages?
","['language', 'best-practice']",
Need Resource suggestions about Indicators and Signs in Governmental Open data,"
I am studying for my master’s degree in the Interaction Design domain. For my upcoming Capstone project, can someone please direct me to good resources that talk about governmental open data at the community level :

Why do cities in the US and around the world use open data. What was
the need in the first place? (long-term view)

What are the pros and cons of using Indicators/ Signs. (History and
current usage). A good or a bad example.

Any academic study that is done from the user's perspective. Who uses open data. What decisions do they make? Challenges users face. (This is huge for me - users, audience. My goal is to understand the open data users - make it a little easy for them and ultimately help the end users.)


Pl let me know if I need to refine my questions or if these are good to start.
","['data-request', 'government', 'uses-of-open-data', 'releasing-data']",
Publish Media content data to omni channel [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 7 years ago.







                        Improve this question
                    



This is a very common scenario. 
What is the best way to implement publishing media content (Audio or Video) to different channel for same user?
e.g. If an user access a particular content in desktop and then close/pause the same and try to open in another channel say iPad. How the same content gets served and ensure where the user stops earlier and where to start with?
Moreover how to publish the media content at large scale?
",['releasing-data'],
Are there relationships between Knowledge Management and Ontologies?,"
I'm working on a research project to develop an ontology for wetlands in PROTEGE, but I have doubts about the relationship between ontologies and knowledge management, I understand that ontologies are used for the representation of knowledge, but I can not find an academic text about the relationship between ontologies and knowledge management, specifically I find information on knowledge management.
",['ontology'],
Individual-level data (e.g. survey) with information on sexual orientation,"
I am looking for data on the individual-level that contains information on the sexual orientation (or a reasonable correlate thereof). I would ideally like a data set like  from the DHS program or the WV-Survey, so that it contains biographic or other answers to survey questions.
Clarification: I am not looking for a dataset of LGBT individuals, but for a dataset with an indicator for sexual orientation. Obviously it would be okay if non-hetero individuals were oversampled, given that I want to run statistics pertaining to them, but I still need all kinds of respondents in there.
","['data-request', 'survey', 'lgbt']",
Looking for patients who took stool softener drugs on their first admission,"
I am looking for patients in MIMIC-III v1.3 who took stool softener drugs listed as ""Senna, Dulcolax, docusate, milk of magnesia,Colace, MiraLAX, and bisacodyl""  on their first ICU stay during the first hospital admission.
I found that the resulting number of people is disproportionately high.
I wonder if someone can provide any insight into this issue.
This is my code:
with first_admissions as (
SELECT
      p.subject_id,p.hadm_id
    , row_number() over (partition by p.subject_id order by p.admittime ASC) as r
  FROM mimiciii.admissions p
),
first_icustays as (
SELECT
      p.subject_id,p.hadm_id, p.icustay_id
    , row_number() over (partition by p.subject_id order by p.intime ASC) as rn
  FROM mimiciii.icustays p
)
,
first_stays as(
select a.subject_id,a.hadm_id,i.icustay_id 
from first_admissions a
 join first_icustays i on  a.subject_id = i.subject_id where r=1 and rn=1

)

SELECT distinct on (p.subject_id) p.subject_id
FROM firststays a, mimiciii.prescriptions p
where  a.subject_id = p.subject_id
and a.icustay_id = p.icustay_id
and a.hadm_id = p.hadm_id 
and p.drug @@ to_tsquery('senna | Dulcolax | docusate | magnesia | Colace | MiraLAX | bisacodyl')
order by p.subject_id;

","['medical', 'mimic-iii']",
Financial agricultural data for Chile's different regions,"
I am trying to find financial agricultural data for Chile, not as a whole country but for its regions.
I found data on FAOSTAT for Chile as a whole country but want more detailed data.
","['data-request', 'agriculture', 'chile']",
Where can I find automobile insurance claims data set?,"
I really need a dataset about automobile insurance claims to train and test learning algorithms.
I found references to Masachussets PIP claims data and to Spanish claims data in many scientific articles, but I couldn't find them...
The best would be to find claims which concern just insurance third party liability extensions: I mean theft, fire, acts of vandalism, atmospheric agents. But also claims concerning third party liability insurance would be great.
",['machine-learning'],
Extracting Twitter profiles based on page followed,"
Is there any way to extract twitter handles, bio and location of people following a account?
","['data-request', 'api', 'social-media']","Yes, this information is publicly available from the Twitter REST API. You will need to register an application on https://apps.twitter.com. You can make the calls with Python or R. My R example:"
Whats the simplest way to get 1000 twitter handles of users in USA who are less than 21 years of age?,"
Need 1000 twitter handles of users who are below 21 years of age and residing in US
","['data-request', 'usa', 'tool-request']",
Automobile accident data in India,"
I want accident data in India along with gender of the driver. Actually I want to find out that whether the following statement is true or not: 'Are Men Better Drivers Than Women?'.
","['data-request', 'traffic', 'india']",
"what is the api call for getting all the inspection records, instead of getting default 200 records","
what is the api call for getting all the inspection records, or how to know the sequence numbers to be used for multiple calls to the same api, so that we can  get all the inspections records, instead of just getting default 200 records
https://data.dol.gov/get/inspection/format/xml/orderby/asc/columns/{activity_nr:open_date:site_address:site_city:site_state:insp_type:close_conf_date:close_case_date}
","['api', 'labor']",
"Age, Weight and Height dataset","
I am trying to get a dataset (preferable worldwide) that has the attributes (height, weight and age). The only decent dataset that I have been able to find was from here: https://stats.stackexchange.com/questions/20265/human-body-organs-growth-graph-or-data which just gives you the percentiles for a certain age.
Ideally I would love to get a dataset that allows you to differentiate this by sex, ethnic background etc. If a open dataset exists it would be good to hear of it.
","['data-request', 'medical']","Try the Demographic and Health Survey (DHS). They have what you are looking for, for a large set of countries. On top of that you will in part be able to identify family ties, and you can even get access to geo-coded data. The data has answers to an extensive questionnaire. You have to ""apply"" to get the data. But that is just a formality -- even as a undergraduate student with just a one-sentence research proposal you are likely to get access within a few hours.Edit: The surveys consist of several modules, some modules are only administeed to female respondents, some only to children and so on. Sometimes different waves in different coutnries contain a different combination of modules. Depending on what exactly you're studying you'll need to figure out what exactly your needs are. To show you that the data exists I pick on example: Egyptian women in the 2014-wave. You'll find the data here:Egypt: Standard DHS, 2014 > Household Member Recode > Variables: ha*Here, you see a hight/weight scatter (scatter ha2 ha3 in Stata):
"
"Historical rates of depression, anxiety or any mental illness","
I'm trying to look for historical rates of depression, anxiety or any mental illness really for America, going back from 1980 to present. Even if the data is spotty, like every 5 years, if it's from the same source that would be my ideal.
I've tried regular Google, and the Google Dataset search engine, which has taken me to the CDC, NIMH and the SAMHSA NSDUH, but they only have 1-4 years of consecutive data at best. Searching Opendata didn't help either.
I don't have SPSS and I don't know how to use R. So data in those formats won't help me. I am a Perl programmer so I can parse textual data well enough.
Does anyone have any ideas on where to get this?
Summary

Data for America.
Historical prevalence data for depression, anxiety, or any mental illness, from 1980 to the present. An earlier starting date is ok.
Data should be from the same source even if it is only every 5 years or so.
Data from different sources are not comparable as this data will be graphed.


EDIT: I've marked one as an answer, but as always, more suggestions are always good to peruse. Oh, and thanks for adding a couple of tags, Mystery User.
","['data-request', 'medical', 'depression', 'anxiety', 'mental-disorders']","The CDC's National Center for Health Statistics (NCHS) publishes a report called Health, United States each year and the following link includes links to PDFs and XLS files that are relevant to Mental Health: http://www.cdc.gov/nchs/hus/mentalhealth.htmThe following seem most promising for you and are available from that page and its linked resources:Edit 1: Also, this 2014 report from SAMHSA NSDUH has trend data from 2008 to 2014 -- better than nothing! http://www.samhsa.gov/data/sites/default/files/NSDUH-FRR1-2014/NSDUH-FRR1-2014.htm#idtextanchor073"
Government procurement bids,"
The US federal government publishes contracts on USASpending.gov and RFPs on FBO.gov.
Contracts contain extensive description of the vendor. But I haven't find the similarly detailed data on RFP results. Namely, for competitive purchases (like those on FBO.gov):

DUNS number of each bidder
Region, revenue, and number of employees of the bidder
Price offered by the bidder
Status (minority-, woman-, veteran-owned)

FBO.gov requires a login to view the list of interested vendors (eg this RFP). But it does not seem machine-readable anyway.
I haven't found it on Data.gov either.
Is this information available or bidding data is closed?
","['data-request', 'usa', 'government', 'spending', 'fbo.gov']",
Dataset of spirometric surveys,"
For a school project I am making an analytical engine for a spirometry platform (pulmanary function test, measuring lung function). The idea is that measurements made with our spirometer infrastructure automatically get uploaded to a database, where meaningful statistical operations can be conducted.
As we don't have a deployed physical product yet, we also don't have a data set. Nonetheless, I would like to have a representative (not necessarily big) set of data across ages, sexes, ethnicities... This will allow us do perform demonstrations and perform tests of how the analytics and visualisations work on real-world data.
Specifically, I'm looking for a data set that has per entry (person):

FVC (Forced Vital Capacity) - Critical
FEV (Forced Expiratory Volume) - Critical
Age - Very important
Sex - Very important
Ethnicity / length / other factors - Very welcome but not required

",['medical'],
A calendar of future EO satellites pass based on location,"
There are several Earth Observation satellites with known orbit paths and return time. (ex: Landsat 8: 16 days, Sentinel-2: 12 days).
Is there a shared calendar or a web-app that shows you future passing dates for a specific location on earth, be it Path/Row, UTM Granule, or a simple Coordinate ? 
","['geospatial', 'calendar']",
Where to find a complete list of products by model number of all major US brands?,"
Is there such open database or directory available online? 
For example, I would like to find out a list of all Samsung products by model number, I would get:
Samsung: UN65KS8500, UN55KS5500, UN95KS00, ....

The closest that I can find is outpan but it's for barcodes. Any help is greatly appreciated!
","['data-request', 'products']",
Statistics for Disabled Veterans in Residential Homes,"
I am looking for the data/statistics for the disabled veteran population in California that are currently living in adult residential care homes. 
","['usa', 'data.gov', 'real-estate']",
Maritime traffic data as bulk download or API,"
I am looking for a dataset of global maritime traffic which would include basic metadata such as port of departure/arrival, date, vessel name. 
I am familiar with proprietary online services, such as marinetraffic, but would be interested in a free API/bulk download option.
","['data-request', 'api', 'transportation']",
Cochrane Database of Systematic Reviews dataset,"
I am looking for a dataset that would contain Cochrane Database of Systematic Reviews. Ideally, with some structured format, e.g. separating each section of the systematic review, or with some organized references.
http://www.cochranelibrary.com/help/open-access-options-for-the-cochrane-library.html does mention

Machine readability is one of the core components included in the guide. Contact Deborah Pentesco-Gilbert (dpentesc@wiley.com) to discuss permission to crawl or access the article full-text, metadata, and citations, and the use of an API for this purpose.

however, emailing them was fruitless. So I'm hoping someone scraped the data independently and made it available online.
","['data-request', 'medical']",
How can I validate OASIS XML files?,"
I need to check OASIS export files.I would like to know if there is an API/service(s) for checking/validating reports in OASIS XML files.
","['medical', 'healthcare-finder-api']",
USA census historical demographic data,"
I am currently working on a project where I am responsible for calculating the mean temperature and precipitation data across the USA.
My calculations are made for metro census data and county census data and it would be greate for me to add some information about population in those areas. The problem is that I can't find any data for metro areas that are older than 1970 and I need to have a data from 1950.
I am wondering if there is some dataset with demographic data on metro or county level that will have an information about population starting from 1950 or even older?
","['data.gov', 'us-census', 'census', 'demographics']",
Machine Learning Data Sets searchable by statistical properties,"
There are a number of collections of open example data sets for machine learning, e.g., the one of the UC Irvine. However, they are usually organized by source or topic. Does anyone know of a list or search engine for this kind of data set, which is organized by statistical properties like number of rows/columns, scale level of target variable, rare events data, etc. ?
","['data-request', 'machine-learning']",
Getting drug register information through API,"
I am trying to find the drug registration info. Is there any FDA API available to gather drug register data set.
Please suggest.
","['data.gov', 'openfda', 'api', 'json', 'xml']",
Index in Google Trends,"
For a research project, I am attempting to create a model that uses google trends results as its independent variable. As you probably know, google trends standardises its outputs on a scale from 0-100. The goal is to find out whether an increase in searches for particular words results in higher unemployment rates. Google trends has the option to select an index relating to unemployment already. However, I would like to select the words that are in the index myself. For simplicity, I really want to combine these words into a single index and not obtain their search results separately. Unfortunately the option to search for a combination of words in an index has not been given by google trends as for as I know. Is there a way to compromise the outputs into one single independent variable?
",['trends'],
Master Song Database containing popular titles and artists,"
I'm looking for a song database (sqlite, csv, etc.)  Right now I'm searching through a list of songs from late 60s and early 70s on ""http://www.song-database.com/"" but I'm searching manually on the internet by clicking through charts on webpages showing week by week top-20 hits across the USA.  
I'd like a more complete listing with the title, artist and year at the bare minimum.  It would be wonderful if there's a database containing every song ever published by major labels, with extra fields like ""genre"" and when and if they became hits, and how big of a hit, and how long. 
","['usa', 'csv', 'music', 'sql']","If you're looking for some other options, I suggest checking out the Wikipedia page on this topic.  You can find it at the link below:I have not used them all, but AllMusic is quite good.Have fun exploring the others and let us know what you think of them.  You could even do this by using the ""answer your own question"" feature Stack Exchange has."
Open-source DB of consumer package goods attributes,"
I am searching for an open-source (or cheap/easily available) dataset of consumer package goods that contains information about brand/item attributes, e.g., size, color, flavor, package type. Ideally I'd like an acyclic directed graph showing attributes at varying levels of abstraction -- think subclasses in OO terms, e.g., ""Tide Pods Ocean Mist 77ct"" inherits attributes of it's parent ""Tide"" which in turn inherits from it's parent ""Laundry Detergent"". 
Specifically I'd like to leverage product attribute information to deal with the sparsity problem in product recommendation systems as discussed in the section 'Content Description' of this article on collaborative filtering. I'd prefer to do this using an existing dataset rather than creating a bag-of-words attribute set by parsing product descriptions.
This closed ticket points to the product open data repository which is an extensive dataset, but whose fields are limited to size, weight, and volume. And there is the Factual database, but it appears limited to food stuffs and nutritional information.
",['data-request'],
GTINs (Global Trade Item Numbers) - Database New requirement for Google shopping,"
I recently realized that Google will make it mandatory to have a list of GTIN numbers for each product you do e-commerce for on Google Shopping (See details here).
Is there any way to easily obtain these numbers or a database where I can search for the ones which correspond to the products I work with (Luxury watches)?
Here you can see more detailed information on the unique  identifiers.
","['data-request', 'products']",
Images of Cars with License Plates from Respective Countries,"
I am looking for a database of images of cars with license plates from one country, like France or the USA.
",['data-request'],
Plastics dataset (US),"
I'm looking for any type of plastics data in the US. Is there a dataset around the waste or use of plastic materials? 
","['data-request', 'usa', 'environment']","Check www.quandl.com and search for ""plastic united states"" in the search bar at the top left corner. The results will show several free databases with plastics data from databases like the US Census Bureau which shows data on the imports or exports of plastic materials, or the United Nations Industrial Development Organization which shows data on employees and outputs in the plastics industry, or the US Energy Information Administration which shows manufacturing data for plastic products. Hope this helps in some way. [Disclosure: I work for Quandl]"
Database or list of romanized Chinese names and last names?,"
Is there any easily accessible datasource where I can find a complete list of romanized Chinese given names and family names?
I tried using Searching for list(s) of babynames containing huge (10k+) amounts of unique names but unfortunately it only provides an accessible source for gender of names, not nationality which is what I need.
","['data-request', 'names']","Pinyin is a wide-spread Romanization system for Chinese words. The Comprehensive Database of Chinese Name Variants is a repository of Chinese names and their various Romanized counterparts. According to their website, the database contains ""over 1,650,000 Chinese seed names (surnames and given names) and approximately five million romanized variants for these names."""
Any Open Data Sets for the (Football) Euro Cup (in France 2016)?,"
Are there any public data sets for the European Championship ""Euro"" Cup in France 2016?
Didn't find anything for download on the official UEFA site (besides a single-page PDF booklet for the match schedule).
Ideally the data set includes groups, teams, players, squads, matches, stadiums and so on and is in an open plain text format such as CSV (comma-separated values), JSON (javascript objects), SQL (structured query language), etc.
Any insight appreciated. Cheers.
(Update Jun/14th) Kick off! Any news?
PS:  Disclosure: I'm the project lead of the football.db project collecting open public domain football data e.g.

openfootball/euro-cup Euro Cup Datasets (1960-2020) - not complete in any way :-(

","['data-request', 'sports', 'football']",
Number of lines of codes an average programmer touches per year?,"
It is well-known that measuring the number of lines a programmer produces per year is a bad metric of his/her productivity.
For statistical purposes, I need a number of lines of lasting code a programmer touches annually. Here, a 'lasting' code line is a line that makes it into a released version, not just a beta version, and 'touching a line' means (reading and (deleting or modifying or adding)) the line. Notice that 'touching a line' is equivalent to ((reading and deleting) or (reading and modifying) or (reading and adding)). The term reading is difficult to count right, so I'm open to under- and overapproaximations of reading and X which are better than the trivial false ≤ (reading and X) ≤ X.
After getting the data, I would compute some average with error bars.
We are speaking about a programmer acting as a programmer, not as a reviewer who just reads someone else's code.
The used terms are, of course, imprecise. So please feel free to make them precise if you need that for your answer or to restrict them if your data is covering only a subindustry of software.
","['data-request', 'software']",
Repository for published data from medical studies,"
Is there a repository for data from medical studies, in particular clinical drug tests? I am looking for data at the patient/mouse level, optimally from larger studies (exceeding 1000 individuals)
","['medical', 'drugs']",
Roadworks datasets or API services,"
Hi guys I need to integrate into my app data about road conditions for major cities in Europe and U.S. initially. I'm looking for data about roadworks mainly but would be cool to find a feed for road conditions and hazards like uneven surfaces or potholes.
Ideally I'd like use some API-based service but I'd be ok also referring to some dataset periodically updated.
Thanks
","['data-request', 'usa', 'api', 'europe']",
Incidence and prevalence of tendinopathies,"
I am looking for a data set that contains the incidence and prevalence of tendinopathies,  with as many following fields as possible:

Year
geolocation
location of the tendinopathy (rotator cuff, the Achilles tendon, the patellar ligament, the adductors of the hip, the triceps, the flexors and extensors of the elbow, the plantar fascia, …)
patient demographics
patient's main activity

","['data-request', 'medical']",
Wiki site for consumer medical device feature comparison tables?,"
With the increased marketing of sophisticated medical devices to consumers, it would seem that a central repository for public, wiki-based feature comparison tables would be a big help.
But AFAICS, no such tables exist as a public wiki that could be maintained as new technologies appeared. Those tables that do compare devices (e.g., for diabetes, sleep apnea) seem to be non-wiki, not current, and hosted on sites specific to particular conditions. 
As a first cut design, each wiki page would be dedicated to a product category, with a table indicating brand, model, features relevant to the product category, links to reviews, links to manuals.
The site would also serve as a repository for manuals not available elsewhere online.
So, I’m raising the topic here to prompt discussion of the merits, hosting possibilities, etc.
Thoughts, anyone?
",['medical'],
"Implications of ""For official use only""","
Certain US government websites (fpds.gov, sam.gov, among others) have a footer saying something along the lines

This is a U.S. General Services Administration Federal Government
  computer system that is ""FOR OFFICIAL USE ONLY."" This system is
  subject to monitoring. Individuals found performing unauthorized
  activities are subject to disciplinary action including criminal
  prosecution.

Wikipedia mentions this term, but it refers to unpublished documents.
These websites are freely available (no IP, login restrictions) and often contain the same data as government websites without this note, like fbo.gov.
What are the implications of this note in the context of such public websites? What license agreements apply in this case?
","['usa', 'government', 'releasing-data', 'uses-of-open-data']","The warning says nothing about using the data. Unauthorized activities are prohibited. Don't set up your own website or store your vacation images on their servers even if there is unfettered access or because your special set of skills  make it easy to gain unfettered access. Storing your images is not an official use.Inside the US gov't we have similar warnings about accessing systems. Although US federal law prohibits unauthorized access and activities the warning you see on-screen is one more in your face warning that helps to defeat the ""I didn't know I couldn't do that"" defense."
Are there translation probabilities for major language pairs?,"
Are there reasonable alignment probability files for major language pairs?
Specifically, given a target language and a target word/phrase, what are the translation equivalents in other major languages and what are the associated distributional probabilities of that word. For example, given language English and phrase ""to be"" the results for Spanish might be: ser (0.55) and estar (0.45).
Most likely from GIZA++ train ([prefix].actual.ti.final), but others would be interesting too.
Ideally news or user-generated data, but any reasonably large domain or a mix of domains is acceptable.
","['nlp', 'language', 'translation']",
wikidata: (when) will it be possible to query for wikipedia page links?,"
(When) will the following be possible:

For a wikipedia page: get the list of all wikipedia links on that page with their respective wikidata IDs in a single query/API call.
Receive additional information of the respective wikidata items like a property value with the query.

","['wikidata', 'wikipedia']",
Postal codes of China,"
Where can I find geodata with postal codes of China with an open license (commercial use is allowed)? It may be shp, csv, kml. any geodata.
","['geospatial', 'csv', 'postal-code', 'china']",
How to download geology data for Argentina and Chile,"
I found on the OneGeology website geology layers for Argentina and Chile but am unsure how to donwload them. http://portal.onegeology.org/OnegeologyGlobal/
Chile's data source http://www.sernageomin.cl/
Argentina's data source http://www.segemar.gov.ar/
And nowhere on either of their data source websites I can find a place to download the digital data. Can anyone find a way to get access to this data?
","['data-request', 'chile', 'argentina']",
Finding Reasonable Global Unemployment and Literacy Data,"
Does anyone know of great datasources that catalog unemployment and literacy rates across the world?
Ideally, I'd like to have statistics as granular as possible (country level, city level, regional level), but I'll take what I can get.
",['data-request'],
What is the latest US Census Data I can access to? [duplicate],"







This question already has answers here:
                                
                            




What is the latest census statistics on US demographics

                                (2 answers)
                            

Closed 7 years ago.



I am trying to find the latest census data that I can use to study US Cities. 
Is American Community Survey (ACS) the latest survey I can use? 
","['data-request', 'data.gov']",
Where to find georeferenced VFR Navigation Chart,"
I am looking for Canada coverage VNC map for my GIS project. I've looked for it, but haven't been able to find anything.  Ideally, a geoTiff or vector would do, or a WMS would be great.
",['geospatial'],
wikipedia page: get the list of all links with their wikidata ids,"
For a Wikipedia page: is it possible to get the list of all Wikipedia links on that page with their respective wikidata IDs in a single query/API call?
Optional: can additional information of the respective wikidata items like a property value also be received with the query?  
","['wikidata', 'wikipedia']","That doesn't seem to be possible using the Wikipedia API.You can get a list of all links from a certain article: https://en.wikipedia.org/w/api.php?action=query&prop=links&titles=LondonYou can also get information about description, alias and label from Wikidata for all links from an article: https://en.wikipedia.org/w/api.php?action=query&generator=links&titles=London&prop=pagetermsBut there doesn't seem to be any way to get any other information from Wikidata on Wikipedia.If you use Wikidata API, you can get all the Wikidata-related information you want, but there is no way to get the links of a Wikipedia article there."
searching for WMS for canada weather,"
I need WMS server links for

metar
radar
satelite

I have Environnement Canada but there's no metar
","['weather', 'canada']",
"UNIFIL ""Blue Line"" barrel marking coordinates","
I'm looking for a dataset of UNIFIL's Israel-Lebanon ""Blue Line"" coordinates, preferably with the barrel marker name.
I've already looked in UNIFIL and UN's peacekeeping sites, as well as UN data portal, but no luck.
I've collated a few tidbits of coordinates from technical specifications here and there, but since there are ~500 markers, that's not good.
For those wondering, I'm trying to see the effect of the border demarcation on ecologic succession and vegetation dynamics in the region.
","['data-request', 'geospatial']",
Where to find source data for incubation/onset/duration time of reported US cases Salmonella food poisoning?,"
I would like to be able to create a histogram showing the onset of illness and duration of symptoms reported within the USA for Salmonella enterica infections (or some other common foodborne illness). I am able to find published information from reputable sources like this that simply declares what the known onset time (6-48 hours) and duration (4-7 days) of the illness is, but I can't find actual source data on this. 
I should clarify that I'm not interested in identifying information about reported cases, just the raw numbers of those individual cases. I want to be able to either confirm or refute the blanket declarations about onset time and duration of an illness that are found all over the web (and don't always match up).
The CDC has made available this database which appears to be compiled from individual hospitalizations (I can see where the person recording the info would choose the option other - please describe in remarks but no remarks are included in the data), but this particular dataset lacks any information regarding the timing of the illness. 
I've contacted the CDC and the FDA for assistance but I have not yet heard back. I'll update this if and when I get an answer from them that might resolve this question. 
Is there an already public source of this information available on the web? Or, if not, what organization would be best to contact for this info? 
Is this the kind of dataset that is a good candidate to be acquired through a Freedom of Information Law (FOIL) request? 
","['data-request', 'medical', 'food', 'disease']",
Shape files for Colleges/Universities?,"
I was wondering if anyone has ever found shape files for all colleges/universities (both 2 and 4 years) in the United States.
The closest thing I've found so far is the 2015 TIGER U.S. Census AREALM shape file which includes the vast majority of colleges/universities but leaves out some smaller colleges, community colleges, and university branches (i.e. North Lake College (TX), College of the Sequoias (CA), and Florida State University - Panama City (FL), etc.)
","['data-request', 'geospatial', 'us-census']",
"Granular Data of US Census Population (zip code, block or household)","
I have analyzed zip code data and block data of us census 2010. But I am unable to find which data is more at a granular level. I want to say that household data is more granular. Where can I find household data if it is more granular?
","['usa', 'us-census']",
Node-attributed graph datasets,"
Do you know of some nice attributed graph datasets I can use? To be more clear I need some dataset such that:

There are nodes (for example proteins, users, sensors)
There are edges (for example interaction between proteins, friendship between users, proximity between sensors)
There are attributes for each node (for example some properties of the proteins/gene expressions, descriptions of the users, the sensor data, etc.)

Then given the network structure (nodes and edges) and given the node attributes I want to do some classification/clustering. Therefore it would be nice if there is some ground truth as well.
I did find these co-authorship network datasets.
Most of the other node-attributed datasets I found have simple binary/categorical attributes, however I am more interested in numeric attributes. However, any attributed graph dataset would be appreciated.
","['data-request', 'network-structure']",
Rental Prices in US Cities,"
I am conducting a study on different cities, and I am interested in highlighting and comparing rental prices in different US cities. In case you can share some websites (Other than Zillow) where I can these datasets, I would appreciate that. 
",['usa'],
nhamcs design on survey package (R),"
I am trying to analyze nhamcs http://www.nber.org/data/national-hospital-ambulatory-medical-care-survey.html using Lumley's survey package but getting the wrong standard errors when comparing them against http://www.cdc.gov/nchs/data/ahcd/nhamcs_emergency/2011_ed_web_tables.pdf
current design object is defined as:

data.design <- survey::svydesign(id = ~CPSUM, strata = ~CSTRATM, 
     weight = ~PATWT, data = data, nest = TRUE)

but this gives me the wrong s.e. for example, for the total population number of visits I get:

    total      SE

[1,] 136296400 7370965

while the pdf above reports (in thousands for both totals and s.e.):

136,296 (6,413) 

would appreciate any thoughts on where I might be going wrong
","['programming', 'survey']",
MRI scanners in the United States with teslas,"
I am looking for a dataset listing MRI scanners in the United States with as many following fields as possible, ordered by descending importance:

Location
Number of teslas (as of now, commercial systems are available between 0.2T–7T, and sometimes even up to 10.5 Teslas (Siemens MAGNETOM 10.5T))
Whether it is publicly available (i.e., whether a patient can book an appointment)
Date when it was made available
Model name

I am mostly interested in the state of Massachusetts.
","['data-request', 'medical']",
"postal code boundaries for Yukon Territory, Canada","
can you download spatial data representing postal code boundaries for Yukon Territory, Canada?
","['geospatial', 'postal-code', 'canada']","The location datasets page for Canada on OKFN's global open data index seems to contain a pretty comprehensive yet short review on the state of postcode data:Canada Post is a Crown corporation of the Government of Canada. Commercial use of Canada Post's Postal Code Address Data (PCAD) product has been quoted at $50,600 per year. Canada Post claims copyright in its database of postal codes. It has recently [Apr 2012] defended its claim by filing a lawsuit against Geolytica [...]The lawsuit seems to be still ongoing. And: the operator of Geolytica seems to still offer a download of a crowd-sourced postal code dataset for Canada (polygon, ESRI shapefile format, last updated Sep 2015), licensed under CC BY.However, I had a cursory look on the postcode polygons in that file. It might need a bit of processing before being ready to be used:UPDATE TO accepted answerLegal News, May 2016 - In regards to Canadian Postal Code data on Geocoder.ca: Canada Post commenced court proceedings in 2012 against Geolytica Inc. for copyright infringement in relation to Geolytica Inc.'s Canadian Postal Code Geocoded Dataset and related services offered on its website at geocoder.ca. The parties have now settled their dispute and Canada Post will discontinue the court proceedings. The postal codes returned by various geocoder interface APIs and downloadable on geocoder.ca, are estimated via a crowdsourcing process. They are not licensed by geocoder.ca from Canada Post, the entity responsible for assigning postal codes to street addresses. Geolytica continues to offer its products and services, using the postal code data it has collected via a crowdsourcing process which it created."
What year do the BLS occupational datasets represent?,"
The BLS releases data on occupational level employment here: http://www.bls.gov/oes/tables.htm. Each section is labeled with a year (such as ""May 2015""). 
What year does the May 2015 data represent?
Is it employment in 2014? 
",['labor'],
Is it possible to find a torrent that is not linked to from a site?,"
And I mean besides people explicitly choosing to share a .torrent file with each other. Here's why I'm asking. I created a torrent using videos that I downloaded from a website. As far as I know it contains material unique to the bittorrent network, which is why I made it to begin with. 
I added 15 or so trackers to it, uploaded it to a site, and set it to priority seed. Within a surprisingly short amount of time it started uploading data to several people & my client showed peers and even a couple seeds from time to time. This isn't anything hot or popular. 2 weeks later the stats from the website show no downloads of the torrent. I'm aware the site doesn't appear track how many clicks on the magnet link there are, so I'll leave that possibility open there. But to all appearances it looks like no activity, with 0 seeds and 0 peers. I also uploaded one with the same trackers simultaneously which has much more statistical activity. I only say this to clarify that I trust the sites stat mechanism.
Still somehow I've seeded multiple gigs worth of data, over 10 times the amount of data that the torrent contains. How are people finding it? Are there other sources for torrents that I don't know of? Like if a torrent is announced on a network via a tracker can people just start downloading it then, using their client only without ever visiting a website?
",['bittorrent'],
Flipping through API pages,"
To Whomever It May Concern: 
My name is Casey Bischel, and I'm a reporter on deadline for the Belleville News-Democrat in Southwestern Illinois. I'm trying to find a record in Senator Roy Blunt's (R-Mo.) filings, but there are 43 pages of records with 100 records apiece on them. I am new to APIs, and I need to know how I can either get all of these pages or search for the specific entity the senator gave money to. It was in 2015. 
Thanks, 
Casey Bischel 
",['api'],
NYC Crime Dataset,"
I am looking for detailed dataset for NYC Crime similar to the one of Chicago.
This dataset doesn't contain a lot of information on when/where and what kind of crimes happened at NYC.
","['data-request', 'city', 'crime']",
Android TV - Software Manual - Structure of Each Screen (UX look),"
I have to map all Android TV screens that End User has in Android Tv. Is there a Structure Map of Android TV ? Something like manual ?
I am looking for Manual/Specification for Android TV. In this manual : - Structure Map - Each TV Option shown - Options Map - EPG, Smart TV, Options with all options - Module Map - HDMI, USB, WiFi
Any vendor ? LG , Philips , Sony ?
","['data-request', 'releasing-data']",
"O-ring dataset with thickness, Shore hardness, and diameter","
I am looking for an o-ring dataset containing as many following fields as possible:

o-ring model name and manufacturer
thickness
Shore hardness
diameter (inner and outer)

I am only interested in o-ring that can be used in keyboards.

Some terminology:
Shore hardness:

Diameter (inner and outer):

",['data-request'],
MIMIC-III: Negative cultures and microbiologyevents,"
In MIMIC-III, where do negative cultures appear? Is this different between CareVue patients and Metavision patients? 
Despite the documentation's assertion (here) that ""If the specimen is null, then the culture had no growth reported."", there are very few cases where either the spec_itemid or org_itemid are empty in the microbiologyevents table(I think it's less than 2k out of 328k).  Also, in a manual inspection, it looks like most rows have an antibiotic test done, so as to determine sensitivity of the culture.
PROCEDUREEVENTS_MV seems to have information on cultures for Metavision patients, but this whole table confuses me too.
Edit: Clarified that paragraph 2 refers to the microbiologyevents table.
",['mimic-iii'],Negative cultures were added to the microbiologyevents table in version 1.4 of MIMIC-III: http://mimic.physionet.org/about/releasenotes/Negative cultures were not available in prior versions of MIMIC-III.
USA FEMA Flood Zone Polygons and Metadata,"
I am looking for the FEMA flood zone GIS files.  The portal lets you look at a single address but I would like to get for each zone its geographic polygon and related FEMA metadata.
It appears from the portal that each zone is subdivided into smaller grids. It would be great if I could get this as well.
",['geospatial'],It looks like you can download the shapefile for the National Flood Hazard Layer from data.gov:http://catalog.data.gov/dataset/national-flood-hazard-layer-nfhle9690
I have downloaded a map of a small region in .osm format . But as a newbie I dont have any idea how to access it using any programming language,"
I need this map data to provide the location of nearest business facilities like restaurant to the user .  But I don't know how to access it . And it will be of great help if you can provide me any link /tutorial /suggestion to do this using any programming language (preferably using Python )
","['geospatial', 'uses-of-open-data', 'city']",
Querying Department Of Labor Basic Mining Information API,"
I'm attempting to use the Department Of Labor Basic Mining data (developer .dol .gov/health-and-safety/basic-mine-info/). I have two issues:
1)The SendingRequest method is marked as deprecated, but the current SDK GOVDataUtil object doesn't support the new SendingRequest2 method
2)If I do use the deprecated SendingRequest I get the first 100 records,  but I don't see any documentation on how to query it. Poking around I found this page http://developer.dol.gov/accessing-the-apis-using-http-requests/#filter_multi wich seems to indicated you can pass filters to the Uri, but doing so I receive an exception ""Expected an absolute, well formatted URL with out query or fragment""
Unfortunately their documentation page is a dead link http://developer.dol.gov/DOL-MINE-ADDRESS-OF-RECORD-DATASET.htm 
Update: On #2, querying the data. I finally determined that you just use LINQ on the object, which will append the filter info for you. So the following will work:
var mshaMines = new BasicMineInfo(new Uri(""http://api.dol.gov/V1/Mining/BasicMineInfo/""));
mshaMines.SendingRequest +=new EventHandler<SendingRequestEventArgs>(GOVDataUtil.service_SendingRequest);
var minesQuery = mshaMines.MSHA_addressOfRecord.Where(m => m.stateAbbr == ""TX"").OrderBy(m => m.mineName);

","['api', 'labor']",
new user - need pediatric data for various vitals parameters,"
I'm new to physionet and am attempting to dig/find a data set for various vitals parameters for a 48 hour period for a pediatric patient (say somewhere between 2-18), specifically heart rate, respiratory rate, temp, mean arterial blood pressure, and O2 saturate percentage.  I'm interested in a data set with fidelity along the lines of maybe a data point of once a minute... possibly every 30 seconds.  I'm open to any data fidelity that is available, but the 1 or 2 data points a minute would be ideal.  Can anyone provide me with guidance for how to gain access to a data set like this within physionet?
","['data-request', 'uses-of-open-data']",
Looking for IOT sensor data for the task of classification,"
Is there any dataset of IOT sensors labelled for the task of classification ?
",['sensors'],
ISO 3166-1 country codes in DBpedia,"
How can I get a two-letter ISO 3166-1 country code in DBpedia?  More specifically, I'm querying the SPARQL endpoint like this:
SELECT DISTINCT ?iata ?country where {
  ?airport a dbo:Airport.
  ?airport dbo:iataLocationIdentifier ?iata.
  ?airport dbp:location ?country.
  ?country a dbo:Country.
}

I'd like to get ISO 3166-1 code instead of country name.  I couldn't find a predicate for that property, even though the codes are present in country infoboxes in Wikipedia. How can I achieve my goal?
","['wikipedia', 'dbpedia']","There is dbp:iso3166code, but it seems it's not set for a lot of countries."
Open datasets for educational use,"
I'm interested in compiling open datasets for educational use. For example, this page from the State University of New York Geneseo includes open datasets by topic.
I'm especially interesting in datasets that may be appropriate for K-12 use, so I think it is important the data are a) cleaned and b) possibly relevant / interesting. Are there other sites, repositories, or resources with open data sets for educational use?
","['data-request', 'education']","Quandl has open datasets. There are many that are free and although Quandl's focus is financial and economic data, there's also data on Countries, Society, Demography, Energy and Education. I hope they'll be useful for K-12 learning. You can browse Quandl's collections here: https://www.quandl.com/collections When you click on a collection, the articles written are meant to be educational for readers. Also, the sources of open, free data on Quandl are listed here: https://www.quandl.com/blog/free-data-on-quandl They include sources like the United Nations, World Bank, World Health Organization and many more. Hope this helps! [Disclosure: I work for Quandl]"
300 TB dataset for LHC,"
Last week it was in the news that LHC (Large Hadron Collider) research team has just released a 300 TB dataset. What is this dataset and how can I start experimenting with it?
",['research'],"From here:The information is available for download in two formats: ""primary
  datasets"" used by CERN researchers, and lightweight ""derived datasets""
  intended to be accessed by a wider audience.http://opendata.cern.ch/about/CMS"
"Data request: how long do consumers wait for certain discounts, savings, and bargains?","
I'd like to know where I can find data regarding consumers' willingness to wait for discounts, bargains, savings, and so forth. Units can be in time, or in time per discount percent, etc.
Related data such as whether consumers use the internet to cross-check prices, and if so, how often, would also be welcome.
I was going to try collecting the data myself, but I figure that economists/business analysts may have tried this data mining themselves (and thus, it wouldn't be wise to recreate the wheel, etc).
","['data-request', 'economics', 'research', 'business', 'historical']",
Looking for gridded wind field data for Sicily and surrounding region,"
I'm trying to locate gridded wind field (wind direction and speed) data for Sicily and surrounding region, including surrounding sea and southern part of Italy? It's for a student practical here at Portsmouth University. 
Any pointers would be very welcome. 
","['geospatial', 'weather', 'europe']",
Index People Living in New York,"
My current project involves indexing people from the city of New York. Using various sources and data mining techniques I am supposed to give a confidence rating whether a certain person lives in New York or not.
The problem however is finding public information on people legally. I am able to use Twitter's API to feed tweets from New York to get some names. Further analysis would then be required to determine whether the person is real.Facebook prevents developers from scraping and searching for users. Instagram is a hassle as well. 
Do you guys have any suggestions of finding public information on people easily and legally? I don`t need to know where in New York the people live, only that thy live there. Name and Surname is required and any additional information is a bonus.
","['usa', 'api']",
Nation Builder Voter Database Leak,"
Does anyone know if the data leaked from Nation Builder (http://www.databreaches.net/191-million-voters-personal-info-exposed-by-misconfigured-database/) this past December is available anywhere? I know voter records are available on a state-by-state basis but I'm wondering if the full dataset is online anywhere.
","['data-request', 'usa', 'government']",
Network of medical treatment comparisons per disease,"
I am looking for a data set that would contain one network of comparisons between medical treatment, for each medical condition.
For example, for lateral epicondylitis (lateral epicondylopathy), one network of comparisons between medical treatments could be:

( example taken from Krogh, T., E. M. Bartels, T. Ellingsen, K. Stengaard-Pedersen, R. Buchbinder, U. Fredberg, H. Bliddal, and R. Christensen. ""OP0072 Comparative effectiveness of injection therapies in lateral epicondylitis: A systematic review and network meta-analysis of randomized controlled trials."" Annals of the Rheumatic Diseases 71, no. Suppl 3 (2013): 77-78. link  )
I am mostly interested in randomized controlled trials.
","['data-request', 'medical']",
Long list of attributes that make typical graph labels,"
Sort of similar to the fantastic ""Spurious Correlations"" page, I'm looking for long lists of typical x or y axis labels from graphs (as keys, attributes or column names). For example (and see image below):

Per capita cheese consumption
Number of people who died by becoming tangled in their bedsheets

I'd prefer as many diverse themes, topics and categories as possible. Data can be collected live from an API, or from a scraped site or parsed file (any format).

One way may be to use the API from data.gov - does anyone know how I can get column names from files or DB exports using this or another CKAN API?
 
","['data-request', 'data.gov', 'api']",
Indian Election Results,"
I am looking for results of Indian elections by district (or ward). Does anyone have an idea where can I find such dataset ?
Best, 
",['data-request'],
US House Sale Data,"
In the UK we have open data which gives up to date information on house transactions. This includes the address of the home and the price it sold for. It includes detailed data on the type of property. It does not include names of those involved etc.
Is there any similar data open or otherwise for the US?
","['data-request', 'data.gov', 'real-estate']",
looking for a list of certifications and licences relevant for US jobs,"
A similar question has been asked here: What are the different types of Degrees, Diplomas and Certifications and Industry types?, but the answer refers to a EU site, and the certifications are different in the two markets.
","['data-request', 'education', 'labor']",
"Keyboard dataset with travel distance, operation point, actuation force, and force to bottom out","
I am looking for a keyboard dataset containing as many following fields as possible:

keyboard model name
actuation force
travel distance
operation point
force to bottom out
shock absorption
layout (I am mostly interested in qwerty keyboards)
travel vs force plot

",['data-request'],
MRIs of tendinopathies,"
I am looking for a dataset containing MRIs showing tendons with as many following fields as possible:

diagnosis ( e.g., normal tendon, minor tendinopathy, etc.)
MRI device model (I am especially interested in how many Teslas it has)
year
patient demographics
which tendon(s) are affected

","['data-request', 'medical', 'images']",
Patents in academic institutions,"
I am looking for a dataset containing information regarding patents owned by academic institutions with as many following fields as possible:

name of the academic institution
number of patents 
amount of revenue from patents 

Ideally, broken down by field ( e.g., biology, or computer science ) and year.
","['data-request', 'research']",
Dataset of hand images and keypoints,"
Is there any FingerSpelling Dataset like this one, that includes coordinates of keypoints on fingers ?

Something like this, but for a hand

",['data-request'],
Looking for text-to-phoneme or pronunciation data for English words,"
I am looking for data of text and their corresponding phonemes for the purpose of training a classification tree and a neural network. 
Example: cat = k-a-t or something similar
I am looking for at least a few hundred words. If you have anything that will point me in the right direction, please do tell. 
","['data-request', 'nlp']","#1 - For phonological equivalents of English words check out the Irvine Phonotactic Online Dictionary (IPhOD) which is a collection of English words and non-words primarily intended for work in psycholinguistics and speech perception. You can download the entire database and see phonological entries like the following:

A corresponding table shows correspondence with the IPA:
#2 - Another possibility is the MRC Psycholnguistics database, a searchable repository of words with accompanying properties of interest to psycholinguists: frequency, syntactic category, age of acquisition, pronunciation variability, etc.Results are returned in text format with the accompanying features:#3 - Another possibility is the USENET Orthographic Frequencies for 111,627 English Words - this data set is comprised of nearly 8 billion English-language tokens extracted from USENET 2005-2006. It includes the usual psycholinuistic suspects including a phonological translation.#4 - The Carnegie Mellon University Pronouncing Dictionary, which is open-source and machine-readable, contains over 134,000 words and their pronunciation is North American English. Their phoneme set has 39 phonemes, not counting variation due to lexical stress.  "
Standard datset of Animals with a mixture of popular animals,"
I am developing an image classifier that classifies vehicles and animals. For the testing purpose i need a medium size dataset of animals. Where can i find a standard datset of animals which include almost all popular variety of animals like tiger, lion, dog,bird etc.?
",['data-request'],"Since your sample size is pretty small, depending on the way you are using the material, I would be tempted to use google searches then utilise free pictures from the searches you find.If you write a R script with RSelenium/Rvest and do searches like ""dog picture free"", etc. and loop through the popular names of animals that should do the trick."
Is there a public source for the metadata describing English GP prescribing data?,"
The Health and Social Care Information Centre (HSCIC) publishes data every month (see here for an example) describing the number of drug prescriptions issued by England's GP practices. The data shows the practice level number and cost for every prescribable drug or device (about 30,000 different things at any one time down to different formulations/strengths of the each drug). 
Each individual item is described by a BNF (British National Formulary) code that simplicity groups the items into a hierarchical structure (e.g. there is a chapter for ""respiratory"" with subsections such as ""bronchodilators"" or ""corticosteroids""). There can be four or five layers in that hierarchy. When new drugs are introduced they sometimes require new entries in the hierarchical structure and new BNF codes.
Is there a source for that hierarchy that can be used to keep it up to date with the prescribing data?
","['medical', 'uk']","If you login to: 
https://apps.nhsbsa.nhs.uk/infosystems/welcomeUnder the top left ""+Data"" tab, select the folder ‘Drug Data’You should see a report ‘BNF Code Information’Select it, and you will be given options to select the version of the BNF you require.Hope this helps."
What is the best source for up-to-date postcode locations in the UK?,"
The UK has unusually detailed postal location codes. There are about 2 million unique postcodes in use at any one time. Each code represents a business or a couple of handfuls of household delivery locations. The overall data is updated frequently as old locations are removed from use and new codes are issues because new housing are businesses are created.
What is the best source for the geographic locations (e.g. the lat/lon centroids) of those postcodes? What restrictions apply to their use?
","['geospatial', 'uk', 'geocoding', 'postal-code']",Ordnance Survey is an open data site you may find helpful.
How to organize and retrieve list of publications/studies?,"
This question is about organizing and retrieving data, which in this case is a list of studies in medical journals. I thought many other people might want to do something similar also: collect studies and allow the public to search them by topic or #tag.
I want to make the list in a single table, one column for the authors, one for the year of the study, and one column for one or more #tags which would be topics covered in the study, etc.
Google Spreadsheets work fine for entering data but I want
the public to be able to search the data, and I want to present it in a more easily readable form, like an HTML web page.
Is there a website that can help me implement the searching and display part? 
I've looked at TiddlyWiki. While it has tags, and fields, the format does not lend itself to exporting to other formats like a database or spreadsheet would. 
EDIT: 

Bibtex: ""Used for formatting lists of references."" But I want users to search on the references by clicking one or more tags. 
I don't know that much about searching and filtering XML. Could that be an option? Where could I get more information on filtering and showing XML? What are your favorite sites for that?

There are 2 tag columns right now: substance studied (some studies look at multiple substances), and body system affected (the study could talk about one or more body systems that were affected by Substance A.
EDIT 2: Publication fields I would like to track: 

Authors (one field can hold up to 20 authors)
Tags for substance tested. 
Tags for body system affected. 
Publication name, a medical journal for example. 
Date of publication of the study. 
Title of study. 
URL of abstract.
URL of full study.
DOI data if any. 
Other data that doesn't matter to me.

EDIT: 5/3/2016
I'm currently looking at Zotero.com which is free and I've seen no ads yet when using the FF addon. It has a Firefox and Chrome plugin to help you site any given webpage, it will extract many fields from webpages like Pubmed, you can add your own tags, but it does not have user-defined fields. (I wanted tags for symptoms, substances tested, and type of subjects (human, rat, mouse, plant,etc). I also wanted a user-defined field for number of subjects tested. A study with only 5 subjects is virtually useless.) 
It seems to meet most of my needs anyway as the search system can be restricted to only 1. title, creator and year, 2. all fields and tags, 3. everything. And it syncs with their server so you can use it on any desktop. 
",['research'],
MIMIC-III PROCEDUREEVENTS_MV overlapping invasive ventilation time,"
I am working on invasive ventilation records in PROCEDUREEVENTS_MV.
I found a few records where there are overlapping times. I already checked that those records has cancelreason = 0 and statusdescription in ('FinishedRunning', 'Stopped', 'Paused').
Do you have any suggestions / guidelines on how I should clean them up?
From my understanding, I have two options: take the last record stored or merge them.
For instance (PostgreSQL),
select hadm_id, icustay_id, itemid, label, starttime, endtime,
value, valueuom, storetime, cancelreason, statusdescription
from procedureevents_mv join d_items using (itemid)
where hadm_id = 103885 and itemid = 225792 and cancelreason = 0
order by storetime;

returns
hadm_id icustay_id  itemid  label                   starttime           endtime             value   valueuom    storetime           cancelreason    statusdescription
103885  286523      225792  Invasive Ventilation    2174-02-24 14:05:00 2174-02-24 18:09:00 244.0   min         2174-02-24 14:08:00 0               FinishedRunning
103885  286523      225792  Invasive Ventilation    2174-02-24 10:03:00 2174-02-24 18:07:00 484.0   min         2174-02-25 17:51:00 0               FinishedRunning

",['mimic-iii'],It's hard to give a generic answer - I'd read the patient nursing notes to get more information about what may have happened (e.g. a spontaneous breathing trial). Merging the times seems reasonable. An alternative option is to use the ventilation duration query I wrote which uses ventilator settings instead of the PROCEDUREEVENTS_MV table: https://github.com/MIT-LCP/mimic-code/blob/master/etc/ventilation-durations.sql
methods to build your own data set from public domain data sources,"
Data sets can originate from government sources, corporations, or individuals.
When an individual collects data, the exercise of collecting data falls into at least two categories:

The individual collects data easily available for him/her to capture without any need for third party sources. For instance, the individual could daily and hourly record the temperature reading outside his/her residence for an entire year using a thermometer placed outside his/her window.
The individual collects and organizes data from third party sources in a way that the data he/she organizes and collates becomes its own unique set. (And perhaps proprietary?) An example of this might be Sean Lahman's ""Lahman's Baseball Database"". 

In the case of the baseball database, by what means does a person even begin to collect all the data points? Obviously Sean Lahman did not look out his window every morning to watch every single baseball game in every season to collect the data filling his database. So how does he do it?
And more generally speaking, are there established methods or principles he used for collecting data that can be applied to other domains?
If this is not the right place to ask this question, please advise an appropriate place.
","['uses-of-open-data', 'best-practice']",
word2vec Analogy Task Data Set,"
Word2Vec is famous for demonstrating local linear properties on analogy tasks.
The task and dataset were introduced in Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig
, Linguistic Regularities in Continuous Space Word Representations (NAATL 2013).
That paper gives a link to where the Syntactic task set can be downloaded from. Unfortunately, it is broken.
Googling for it has not yielded me anything.
The semantic set is derived from SemEval-2012 Task 2, so I am pretty sure I can track that down (haven't tried yet). 
I know these both exist, and are generally available.
People are still using them to benchmark variations on word-embeddings.
","['data-request', 'nlp']",The Syntactic task set can be downloaded from https://code.google.com/archive/p/word2vec/source/default/sourceFYI What percentage of links posted in published articles are dead?
Free UK Company Database,"
I have a company review and rating website but I need a faster way to populate my database with UK Companies. What I need is the full company name, address and telephone number only so I can import it in CSV format. I have tried companies house but does not provide the contact number within their databases. Where could I find a free open up to date database so it can be imported into my website?
","['data-request', 'business']",
Freely available geospatial data for the capital cities in Southeast Asia,"
I'm currently looking for the transport (mainly public transport - route lines and stop locations) and urban (public amenities, population density etc) geospatial-data on the capital cities in Southeast Asia. For now, Bangkok and Phnom Penh would be just enough. Any idea where I might find them?
I have already checked the OSM data. For example, while MRT and BTS routes are available for Bangkok, the bus routes there are highly incomplete. 
","['data-request', 'geospatial', 'transportation', 'public-transport', 'asia']",
Trend on 3D Printer Filament Costs?,"
Some have suggested that filament costs are asymptotically approaching a baseline cost - others that costs are linearly decreasing. 
Does anyone know where to find the trending costs on a single class of filament over the past decade or more?
","['trends', 'cost']",
British Newspaper Archive,"
Anyone know if there is a way to obtain the OCR txt files from the British Newspaper Archive via some bulk download API?
Some more details:
This is the British Newspaper Archive: http://www.britishnewspaperarchive.co.uk/
It's provided in partnership with the British Library according to the footnotes on the site. The site has a service fee to use it and has severe limits on the number of pages you can view per month (3000). I'm wondering if there is an alternative method of accessing the digitized newspapers for research purposes. My thoughts are that perhaps you are just paying for the nice interface and then maybe the British Library has some other way of accessing the OCR texts.
This might be wishful thinking that such an alternative exists. If no alternative exists, it definitely makes you appreciate Chronicling America (http://chroniclingamerica.loc.gov/). 
","['data-request', 'api', 'nlp', 'uk']",
List of database of clinical trials,"
I'd like to have a big list of database of clinical trials, both general and of pharmaceutical industries.
I know

https://clinicaltrials.gov/
https://www.clinicaltrialsregister.eu
http://apps.who.int/trialsearch/

any others?
","['data-request', 'medical']","OpenTrials is building a database of all the data on all clinical trials.  As part of that work, we've created a Data Package of Clinical Trials registers here: https://github.com/opentrials/registersHere's the CSV:https://github.com/opentrials/registers/blob/master/data/registers.csv"
Where is the data cohort map?,"
In replay to question ""Ns for the earnings cohorts"" @Brian1_at_Dept_of_Edu refers to a ""data cohort map.""  Where does one find this ""data cohort map""?  There is no file with this name in any of the College Scorecard data downloads, nor any mention of it in the documentation.
",['collegescorecard'],
Corruption Perception Index (CPI) by Transparency International,"
I need the indeces in analyzable format, i.e. csv, xls, from the year 2005 to 2015. The results are in HTML table/PDF format on the TI website. Can anyone link a source or write a script to scrape the data?
","['data-format', 'programming']","In the Github link there is a file acquire_data.r. It has the exact URLs for datafiles from 2010 to 2015. Inside those zip files are XLS files. I looked at one. You can now copy and paste and assemble the data yourself. There are earlier years here. That will get you part of what you need.For the earlier years I went to the 2009 webpage (http://www.transparency.org/research/cpi/cpi_2009/), I selected the table in my browser, and pasted the content into a text editor. From there it should be easy to save the text editor file to a .txt file, then import to Excel as comma-delimited. In the text editor data I pasted there are actually tabs between the columns, so it shouldn't be hard."
Is it possible to get only opinion based tweets from twitter APIs or any other dataset?,"
Opinion based tweets such as Product X is portable, has a good performance etc. Using the search API, i get mostly promotional tweets and after filtering i am left with almost nothing. 
","['data-request', 'api', 'social-media']",
Macomb County/City of Warren GIS data,"
I am looking to download datasets or shapefiles of parcel data, zoning districts, schools, childcares, recreational facilities, public libraries, and public parks for Macomb county Michigan. I found this GIS data viewer that has all the data I need but I cannot download any of it! Here is the data viewer http://gis.macombgov.org/flexviewer2/ 
I sent the county an email, but they have not responded to me yet. So my questions are where else can I find this type of data? and would they give me the data if I file a FOIA request? 
",['geospatial'],"that site requires flash, which I'm not going to install.
here's some data about Macomb County.
https://www.mcgi.state.mi.us/mgdl/?rel=cext&action=Macomb There's also the Michigan Open Data Portal, however you're going to have to pull Macomb County's data out of each dataset:
http://gis.michigan.opendata.arcgis.com/ EDIT:
To answer question in comments about FOIA'ing for it, I seriously doubt they'll care, after coming across this:
http://ped.macombgov.org/sites/default/files/content/pdfs/Macomb%20County%20Enhanced%20Access%20to%20Public%20Records%20Policy_0.pdf You can view more info about each set here:
http://gis.macombgov.org/portal1/home/gallery.html#c=organization&o=modified You can also tinker around with the API, I've had some success with this approach, but few and far between. I snagged the .kmz file from here, but they have networked links so they don't work if you download them. This seems like something that is an easy fix, but I've yet to figure it out or find a solution.
http://gis.macombgov.org/arcgis1/rest/services/FLEX2/Community_Map/MapServer You can use the individual dataset pages to view detailed information about the data being rendered, which can then be copied. I've had mixed results with this, but even the wins were manual-labor intense and hair-pulling maddening. I tinkered with one for you, only realizing after the fact they do not include lat/lon:
https://docs.google.com/spreadsheets/d/1H1bDDP9fDF0tE4jjmxuPPbE1pRVfIRQfoNHh_yo5G9U/edit#gid=0 Last Chance Resort: I noticed in the portal that they have an older Flexviewer setup...no clue if this is doable, but perhaps you can rip through that files source code and look for the data or urls or paths to things that you seek.
http://gis.macombgov.org/flexmobile2/"
Looking for data on British car specs/list prices/MSRP's for website design project,"
I am British and making a website about cars in the United Kingdom; it's not a consumer-type site (like Consumer Guide, Motor Trend etc.) but a personal site with opinions and some facts about the cars (engine size, cc etc.).
It is not a car valuation site but an opinion site, and the site's footer indicates this. Consider it as a personal opinion and automobile history site.
I did look up ""new car prices [year] UK"" or ""new car specs [year] UK"", ""list price cars [year] UK"" on Google but couldn't find them at all, or indeed any results that were relevant.
I was looking for new car prices [list price/MSRP] from the 1979 to now - and would really appreciate it if someone could find the data for me, preferably in XLS format for Microsoft Excel (2003) as I am using Excel 2008 on OSX. I was trying to categorise prices by reg-plate/year, e.g. 1979 V, 1980 V, 1980 W, 1981 W etc. as specs and prices do change per year. This also applies to commercial vehicles too [Ford Transit, Volkswagen Transporter etc.] for specs and prices, not just automobiles.
The only reason I need this data is twofold; it is being used as a primary/secondary source, and additional data for with the car pages, e.g. specs and new prices for a Ford Fiesta with 1994 L-reg, 1994 M-reg, 1995 M-reg etc. but the XLS file would be split by year/reg plate, e.g. Sheet1 is 1979 V, Sheet 2 is 1980 V, Sheet3 is 1980 W etc.
This is (at a guess) an example of how the data would be:

AUDI
Model        No. of Doors  Bodystyle   Engine          List Price
A4 2.0 SE      4             Saloon   4/1984cc         £17,885
2001 Y New Car Prices

(This is only a hypothetical; I don't actually have the data to hand but it's an example of how the Excel columns would be, and my attempt at rendering them within the syntax here).
I have also got a Javascript inflation calculator so people can work out what their car cost in today's money (embedded as per the rules on the script at enter link description here ) which is one reason I am looking for the old list prices - in the footer of the site is a PHP link which is basically ""How much was your car in old money? Click here to convert to today's money now"" using PHP's include function.
I looked online but could find only SIMI Ireland's data here and Autoweek.nl's prices here for the Dutch market - link but none on British car prices.
The site is a PHP-powered one, and I am going to use the data on all the pages about the cars. Currently the website is non-public, being on an AMPPS server on OSX.
One final question, would there be any legal problems using this data or not publically, considering that it's facts, which aren't protected by copyright, only the expression of facts? I'm not sure where this falls legally, considering the nature of the data.
","['data-request', 'historical', 'uk', 'prices', 'cars']",
Dataset listing datasets for natural language processing,"
I am looking for a dataset listing datasets for natural language processing with as many following fields as possible:

name
annotations (e.g., part of speech, dependency parses, or named entities)
annotation scheme
size 

","['data-request', 'nlp']",
Historical weather forecast API,"
For a college project I need historical weather forecasts for Europe up to 14 days for 2015 and 2016. The last two days I was desperately searching for APIs with such data, but usually there is just observed data for historical dates.
I know this question got asked a lot in here but I cant find any answer which fits my requirements.
Does anyone knows a good source where I can get these kind of data like described above? Where I can send a request with a date range in the past and some latitude and longitudes and get the weather forecast up to 14 days for each day in date range?
","['data-request', 'api', 'weather', 'historical', 'europe']",
Vehicles Data and Images API,"
Are there any APIs available for vehicles? I am going to use this for Android Studio programming.
I want basically the vehicles, models, makes api. But if there are any apis which include more information it is better.
","['data-request', 'api', 'cars']",
data.gov GIOVANNI Portal Data Missing,"
I am not able to find the some data sets on the new GIOVANNI portal.
Sample file names of the data I had downloaded a year ago from the portal are given below. I am not able to find same file names or file names which match description. 
TRMM_3B43_ACC.007_20141101_000000.G3.txt
GLDAS_NOAH10_M.001.soilm4.201404.G3.input.txt
GLDAS_NOAH10_M.001.swe.200205.G3.input.txt
",['data.gov'],
OpenStreetMap freeway signs,"
I am looking for a dataset that includes freeway exit and ramp signs used for navigational purposes.  Signs such as ""Exit 25, Campbell Avenue"" or a sign indicating to keep right to merge onto a different freeway.  Does this data exist in an open source format?  If it is compatible with OSM data that would be amazing, but I can process it if not.  I know mapquest, google, etc have it because they include that sort of info in their routing, but I'm not sure if it is available to the public anywhere.
","['geospatial', 'openstreetmap']",
What is the easiest way to map NDC therapeutic class to broad condition?,"
I have a list of NDC therapeutic classes (and individual NDCs) that I need to map to broader classes of conditions (like ""diabetes"" or ""high cholesterol""). What is the easiest way to do this? 
I could do something like this:
use http://www.accessdata.fda.gov/scripts/cder/ndc/default.cfm to match NDC to drug name, then Google drug name to find condition. 
Is there a better way?
Edit:
I found this site: http://www.ncqa.org/hedis-quality-measurement/hedis-measures/hedis-2013/hedis-2013-final-ndc-lists
That seems like I could use the linked excel files that map NDC to broad classes like ""insulin.""
Is there a way to use NDC classes?
","['data-request', 'medical']",
Auto dealers database,"
Where can I find an auto dealer database?
Format database: Dealer name, address, brand, phone, website, and more other information. If possible, the worldwide. If it is impossible for the world, I will be glad and individual countries (interested in any of the countries).
I can parse results from website or database XML, but I don't know where to find it.
","['data-request', 'address', 'cars']",
OData HTML Visualizer,"
I developed an OData web services which exposes my entity framework model, now I need to develop a Query Builder like this,
http://odata.intel.com/QueryBuilder
Are there any HTML or JS plugin I could use, I am open to JQuery or Angularjs, bootstrap or any other plugin available instead of recreating wheel.
",['odata'],
I'm trying to collect some YouTube usage data so I can run clustering for personality types,"
I'm in the initial stages of a project and I are looking to just collect some initial data based on youtube watch category usage. Requirements are: you have a google acc linked to your youtube acc with likes, watch laters, etc.
http://youtubeprofile.herokuapp.com/
Right now we've (poorly) manually created some personality archetypes (wtf is clubber/basic anyways???) but our plan is to cluster the data to provide more insightful information. If you guys can help out, maybe OP will deliver...
",['data-request'],
Need email Contact information for domestic trucking indusrty,"
Looking for solid, current email database for transportation/trucking companies in the U.S, particularly in Utah, Nevada, and Phoenix, Arizona.
",['transportation'],
Groundwater Basins,"
Is there a global database available for groundwater basins (Aquifers), similar to gdbd for surface water? 
","['geospatial', 'environment']",
Real estate investment and growth data sources,"
I am searching for public sources of real estate / property investment activity / levels from which to find trending data for countries. I've looked through the World Bank data catalogue and found nothing on housing, I've looked through IMF and don't see anything that focuses on property markets. Are there sources for this kind of data available?
","['real-estate', 'global', 'economy']",
Looking for historical daily quotes for USD,"
I am trying to find USD currency rate to the Germand Mark, ""Deutsche Mark"" (DM) back till 1959. The ""Deutsche Mark is the ancestor of the euro. The data should be daily. OHLC is super, but just Close would be good enough.
If needed i can pay a smaller sum. Really need this data for testing some models! Please help!
Greetings
","['data-request', 'economics']","Thank you for your answer. I found the data now online on the website of the german Bundesbank (german federal reserve):https://www.bundesbank.de/Navigation/DE/Statistiken/Zeitreihen_Datenbanken/Aussenwirtschaft/aussenwirtschaft_node.htmlYou can pick resolution from yearly, to monthly to even daily back till 1953!hope that helps..."
Multi-target regression Dataset,"
Looking for dataset(s) with more than 100k instances for multi-target regression.
I have found several but these datasets have few instances with more 100k instances.
Anyone knows where I can find it besides kaggle datasets?
","['data-request', 'machine-learning']",
Business Street Address with street and zip,"
I'm trying to find a database of street addresses that includes a zip code for major metro cities in the USA. Can anyone help?
",['data-request'],
buildings height data,"
I`m working on Communication System Modeling. In order to be more accurate, I want to know urban buildings height or distribution.
Anyone knows where I could find them?
","['data-request', 'data.gov']","Open Street Map has the building heights for many buildings, particularly in the core of large cities. http://wiki.openstreetmap.org/wiki/Simple_3D_buildings#Demo_areas"
Rental Prices in US Cities,"
I am conducting a study on different cities, and I am interested in highlighting and comparing rental prices in different US cities. In case you can share some websites (Other than Zillow) where I can these datasets, I would appreciate that. 
",['usa'],
Where can i find domain specific data set of opinion tweets about a product/brand?,"
I am working on a project to find the opinion of a product/brand on twitter. Is there any sample dataset of opnion base tweets ? If possible labelled data - Positive/negative/neutral
","['data-request', 'nlp', 'social-media']",This might help if you can't find an actual dataset:
Transactions Between Financial Intermediaries,"
There was one question similar to what I am about to ask, but it is too narrow.
Does anyone know of any data that give transactions, financial obligations, financial deals/agreements, or other major interactions among specific financial intermediaries (e.g., commercial, investment banks). A specific example of the type of interactions/data I'm looking for can be found in this paper. The authors supposedly* had data allowing them to model things such as

derivatives,marketable securities, repo, unsecured lending and secured lending

in the UK's interbank market.
","['data-request', 'finance', 'economics', 'companies']",
MIMIC-III - days of the week?,"
Although dates in MIMIC-III are shifted for patient confidentiality purposes, is there any way to extract days of the week? This would be useful for e.g. calculating severity of admissions on Saturday/Sunday vs regular week days.
",['mimic-iii'],"Days of the week and approximate seasonality are preserved in the date shift - see section 1.4.4 of the MIMIC II user guide for more details: http://mimic.physionet.org/archive/mimic-ii-guide.pdf (the deidentification done in MIMIC-III followed the same process, with a few improvements but no systematic differences). This means that any analysis using day of the week can simply use the anonymized dates (i.e. 2154-03-09 can be treated as a Saturday)."
Map SFMTA AVL GPS lat long to routes,"
SFMTA has historical AVL GPS data for their buses at ftp://avl-data.sfmta.com/avl_data/avl_raw. In each record, there is a train_assignment, which you should be able to link to the route information, however, I am unable to find a match.
from the readme file (ftp://avl-data.sfmta.com/avl_data/avl_raw/read_me.txt)

Linking Data to the SFMTA Schedule:   To link the raw AVL data to a
  schedule you will need to use (1) the GTFS data at -->
  http://www.sfmta.com/cms/asite/labsindx.htm, (2) file
  ""lookUpSignUpPeriods.csv"" and (3) file
  ""lookUpBlockIDToBlockNumNam.csv"".     File
  ""lookUpBlockIDToBlockNumNam.csv"" will allow you to link the
  block/train numbers in field ""TRAIN_ASSIGNMENT"" to field ""block_id"" in
  file ""trips.txt"" of the GTFS dataset.     File ""lookUpSignUpPeriods.csv""
  gives the dates for which each signup ID is valid.

The GTFS transit data is now found at http://archives.sfmta.com/transitdata/google_transit.zip.
","['data.gov', 'transportation', 'city', 'public-transport']",
Understanding wind speed data,"
I am trying to understand wind speed as time series from a mast (tower). The names of the fields are v80a, v80b, v60a, v60b etc. Now I do know that v80 is the wind speed at 80 meters. But why use v80a and v80b etc.? 
Can you please explain this or point me to some resources that provide an explanation?
","['time-series', 'energy']",
Protected health information in different countries,"
I'm looking for a dataset that would gather the different categories of protected health information (PHIs) in different countries. I am only interested in electronic health records.

For example, in the United States, PHIs are defined in Health Insurance Portability and Accountability Act (HIPAA) rules (US regulations), and are classified into 19 categories:
(i) Names of patients and family members
(ii) Addresses and their components
(iii) Dates (month and day parts, unless the inclusion of the year part identities an individual to be older than 90 years old)
(iv) Explicit mention of ages over 89 years old
(v) Telephone and fax numbers
(vi) Social Security numbers
(vii) Medical record numbers
(viii) Health plan beneficiary numbers
(ix) Account numbers
(x) Certificate or license numbers
(xi) Vehicle identifiers and serial numbers
(xii) Device identifers and serial numbers
(xiii) Electronic mail addresses
(xiv) Web universal resource locators (URLs)
(xv) Internet protocol (IP) addresses
(xvi) Biometric identifiers
(xvii) Full face photographic images
(xviii) Employers
(xix) Any other unique identifying number, characteristic or code

","['data-request', 'medical', 'privacy']",
Is the Foundational Model of Anatomy Ontology an Open Data that can incorporated in other Open Databases?,"
At the moment I'm investigating the state of anatomical knowledge on Wikipedia/Wikidata. I noticed that the Foundational Model of Anatomy has a lot of useful data and while the ID's are usually referenced in Wikipedia the other information isn't used.
They say on their website: 

The Foundational Model of Anatomy ontology (FMA) is OPEN SOURCE and available for general use. 

But they also say:

To obtain a copy of the FMA database either click the ""Get the FMA"" link to the left or see: FMA Licenses. 

The link to FMA Licenses is a broken link. 
Is the database supposed to be really open and could be incorporated in Wikidata, or is that something that's not allowed?
","['licensing', 'wikidata', 'biology']",
Clothing Dataset,"
I just want to play with a clothing related dataset. I didn't find any free one. I see that a company called Semantics3 offers something related to that for a certain price. 
The database I'm looking for would have information about the size, retailer, price, color, maybe a unique barcode, etc.
",['data-request'],
dataset for webpage clustering,"
I am looking for dataset in arff format to deploy it in weka for web clustering.
the data should be classified and i need to apply it for hybridization of cuckoo search and kmeans.
","['data-request', 'machine-learning']",
Open dataset with historical plates/slides from astronomical surveys (absorption or emission spectra)?,"
The article 1917 astronomical plate has first-ever evidence of exoplanetary system inspired my inquiry, as the question has been on my mind for years:
Where can I find star charts/plates from days long past, or more current data collections.  
","['data-request', 'images', 'historical', 'astronomy']",
Which database should I search to find the year that homes were built?,"
I am working on a research project right now and need to find out what year every house within the Denver metro area was built. I have searched through DRCOG and Census data, but have been unable to find it. It would be great to get this as a .shp file, but I'm dubious on whether or not this exists so any .csv or excel file will work as well.
","['data-request', 'real-estate']",
26 letters probability: how many combinations do you have to make? [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 7 years ago.







                        Improve this question
                    



How to calculate soccer result with propability
",['education'],
Japanese gairaigo database,"
The Japanese language has many terms imported from foreign languages, for instance タワー (pronounced ""tawaa"") means (and comes from) Tower.
I am looking for a database of such term and the original word they come from. Example:
タワー , Tower
ビルディング , Building
… , …

It should not include wasei-eigo and terms whose meaning in Japanese does not match at all the meaning in the original language.
Context
I wrote a tool to transliterate Japanese place/business names to Latin characters, it works well except it could do better for garaigo terms, for instance now it transliterates 六本木ヒルズ森タワー to Roppongi Hiruzu Mori Tawa-. If I find the database described in this question I could improve that to Roppongi Hills Mori Tower which would be ideal.
","['data-request', 'japanese', 'translation']",
Ns for the earnings cohorts,"
The ""most recent cohorts"" has earnings for cohorts at 6, 7, 8, 9, and 10 years after entry.  Questions:

The documentation appears to indicate that these are earnings for different cohorts with different entry years, not earnings at different points in time for the same cohort.  Is that correct?
According to the data dictionary, ""count_ed"" variable is ""count of students in the earnings cohort.""  But since there are 6 earnings cohorts, which cohort is it for?
The ""count_ed"" from the raw data file merged_2005_PP appears to match the count_ed in the most recent cohort file.  This makes it seem like the count_ed in the most recent cohorts data is for the cohort entering in 2005, and Ns for other cohorts might be obtained by looking in later raw data files.  However, the count_ed field is NULL in all the merged_YYYY_PP where YYYY>2005.  Is there another way to get cohort sizes for the earnings data for any cohort other than the 10 year?

",['collegescorecard'],
A graph of North American railroads,"
I look for a graph-based stats of the US railroad waybills. That is, the freight transported over a particular railway over a year.
So far I found:

National Atlas 2015 - The railroad graph (network) as a shape file that can be imported in Python's networkx and other SNA software.
Surface Transportation Board's Public Waybill Sample - A sample of a sample of the official stats collected from large railroad companies.
Bureau of Transportation Statistics - Various stats for free. For example, the cross-border freight.
Association of American Railroads Online Catalog - Various stats, but non-members must pay.
Regional railroad networks (state, etc.)

A map based on STB's Sample:

The Waybill Sample is close to what I need, but I didn't find how to read their space-separated stats (no headers, codebook, or dictionary file).
So have you seen the freight stats that could be converted to a connected graph with edges like (station 1, station 2, freight)?
","['data-request', 'usa', 'geospatial', 'transportation']",
"In the MIMIC II database, where can I get the ""type of admission"", which could be scheduled surgical, unscheduled surgical or medical?","
In the MIMIC II database can we use the comorbidity_score table to get which patients have AIDs, metastatic cancer and hematologic malignancy (as these three diseases are included in the table as boolean variables - 1 means diseased and 0 means healthy from disease)
",['mimic-iii'],
"Dataset for humans,man and woman?","
I am developing a image classifier that classifies animals and humans.I have found lot of images on google but most of them are watermarked.Is there any good dataset of humans-""man and womam separately""- available? 
","['data-request', 'machine-learning']","Have you tried ImageNet? There are 14 million images which have been tagged through crowdsourcing. Here is a search for man:
http://image-net.org/search?q=man"
Customer review dataset,"
I would like to get customer review data set like amazon customer review data.
I would like to have rather unique review data instead of amazon review data, 
because amazon data sets have been heavily used by many papers already.
I am even thinking of purchasing data and wonder if there is any company 
where I can purchase quality review data.
","['data-request', 'nlp']",
Dataset of common typos in English,"
I am looking for a dataset of common typos in English. Ideally, it should mention the frequency of typo.
","['data-request', 'language', 'nlp', 'english']",
Petition for writs of certiorari to SCOTUS,"
I'm looking for the petitions used to ask the supreme court to hear a case -- they are called petitions for writ of certiorari -- there should be about 7000 new ones generated each SCOTUS season, where about 100-200 of them are granted by the court. I don't have law school db access, and the resources available on supremecourt.gov are not comprehensive or easily available. The scotus blog has some hosted on their S3 bucket, but again there are not many.
","['data-request', 'legal']",
Most popular twitter hashtags,"
I am looking for a list of most popular twitter hashtags for the last one year. Popularity means the number of time a hashtag was used. I need at least 1 thousand of them (the more the better).
Twitter API allows me to get only 50 top hashtags. Does anyone know any open source resource that has this information?
","['data-request', 'social-media']",
Publisher costs to publish a book,"
I am looking for a data set listing publisher costs to publish a book. There can be many types of costs, ranging from editing costs to marketing costs and print/server costs.
I am interested in both textbooks and research books.  I am mostly interested in the fields of computer science and maths, and English-speaking venues, but I am curious about other fields and languages as well.
","['data-request', 'finance', 'research', 'publications']",
Estimation of intubation time,"
If I would need the estimated time of intubation for our project, what would be a good proxy. I have found several ventilation-related codes in the MIMIC-III GitHub repo (https://github.com/MIT-LCP/mimic-code).
The duration (beginning and ending) of ventilation seem to be estimated based on a number of ventilation setting. So is it right for me to estimate the time of intubation as the beginning time of ventilation?
",['mimic-iii'],
Medical research articles annotated with quality of evidence,"
There exist several criteria for assessing the quality of evidence in medical research articles. I am looking for a data set listing medical research articles along with some notation assessing the quality of the evidence given in the article.
E.g.: article X used randomized controlled trials with sample size 200 and no comparison with placebo.
I am mostly interested in medical research articles that study the impact of drug X or medical treatment Z on medical condition Z.
","['data-request', 'medical', 'research']",
Does anyone know of any datasets which have audio and accents?,"
I'm trying to do an accent detection project. 
",['data-request'],
Database of cities with coordinates and timezone,"
I'm looking for a database containing city name, location coordinates, and timezone. I thought this would be simple to find, but it has proven difficult.
(I don't see this question covered elsewhere on the site. Perhaps because it's just too basic. Also, I probably need tagging help.)
","['data-request', 'geospatial']",The GeoNames database gives you both the geo-coordinates and the timezone for each city with a population greater than 1k.Here's a version of that DB with a direct access to an API and a map on OpenDataSoft (disclaimer: I work for OpenDataSoft).Cheers
Where can I download powersports oem microfiche schematics?,"
Where can I download powersports oem microfiche schematics? I have wrote to a few companies and they smaller ones have provided me with some data. But what about the others?
",['data-request'],
I'm looking for panel data on Merger and Acquisition,"
I am looking for sources of available datasets on M&A. My preference would be for a clean panel dataset that might have previously been used for the purpose of studying the effect of M&A on either firms profits, or their R&D activity. I know that this is rather specific, but any broader suggestions on good sources for M&A data would also be appreciated.
","['data-request', 'machine-learning', 'economics', 'time-series']",
Impact of move X on tendon Y,"
I am looking for a dataset that contain relationships between moves and tendons, for humans. Specifically, the dataset would indicate what is the impact of move X on tendon Y. 
For example (fictive), typing on a keyboard causes an effort of 10% on the lateral epicondyle of the humerus.
The effort metric would probably need to be defined, and the move may be accompanied by its duration or some other properties (e.g., keyboard type, postures, etc.).
I would be interested in any dataset that attempted to capture move vs tendon relations.
","['data-request', 'medical']",
Japanese place/building names English translation database,"
Context
OsmAnd is an OpenStreetMap-based map app. For Japan localities that don't have a name:en= parameter it displays junicode transliterations which are always wrong. rrobek has created an improved map that uses a better transliteration algorithm. But rather than using general-purpose transliteration, using a database of translated place names would be the best.
Question
I am looking for a database that tells me how Japanese places/shops/houses names are usually written in English:
日本 → Japan
原野ビル → Harano building
ニセコバックパッカー　アスパラロッジ → Niseko Backpacker Aspara Lodge
鉄砲町停留場 → Teppocho station
吾妻古墳 → Azuma tumulus
ミニヨン南堀江駐車場 → Miniyon Minamihorie parking lot
藍場浜公園 → Aibahama Park
ふじ鮨 ニセコ店 → Fujizushi Niseko

Requirements
Ideally the license should be compatible with OpenStreetMap, but databases with more restrictive licenses are OK too.
I am aware that no database is perfect, for instance 大分村 translates as Daibu or Oita depending on the prefecture. The database should provide the most common (or even better provide the translation depending on approximate latitude/longitude, but I guess it is too much to ask for).
","['data-request', 'openstreetmap', 'japan', 'japanese', 'translation']",
Where can i find a Dataset for history of Australian federal politicians,"
To answer this question https://politics.stackexchange.com/questions/10519/what-is-the-most-common-surname-in-the-history-of-australian-federal-politics I want to find the dataset that contains all the australian federal politicians and their names.  I could not find a dataset on the australian parliament website. 
","['data-request', 'australia']",
Where can I find downloadable smartphones data rating?,"
Currently I need to find smartphone product data rating for testing. Does anybody have more info on this? Is there someone who provides a downloadable dataset like that? Or maybe some technique to get the data?
","['data-request', 'products']",You should be able to get Amazon's reviews for the products (including smartphones) though it's Product Advertising API here: https://affiliate-program.amazon.com/gp/advertising/api/detail/main.htmlCheck the T&C's on usage though.
"Dataset for emotion classification into happy, sad, angry","
I am looking for a dataset for Mood or emotion (Happy, Angry, Sad) classification.That is to classify a text is it a happy, angry or sad related sentential text. I have used naive Bayes classification for this analysis. Now just to train and test the model with the dataset, we require a strong one. We are not getting a good efficiency with the current datasets that we are using, can you  please suggest a strong one?
","['data-request', 'machine-learning', 'research']",
Sentence segmentation dataset,"
I am looking for datasets that contain texts as well as notations for sentence boundaries. I plan to use it to assess a sentence segmentation system. I am mostly interested in texts in English at the moment, but curious about other languages as well.
","['data-request', 'nlp', 'corpora']",
which countries belong to which synchronous electricity grids?,"
I'm looking for a list of synchronous electricity grids, and the countries and regions that they consist of.
Iceland is an unusual country in many ways. One of which is that its electricity grid is frequency-isolated - it has no synchronous (AC) connections with any other country's electricity grid. Wikipedia has a map of some synchronous grids (each different colour represents a different synchronous area; and yes, Denmark is indeed split across two separate grids):
CC-BY-SA 3.0
But it's not referenced, and only covers part of the world.
The Power Information Technology Laboratory at the University of Tennessee has a rather funky map of real-time grid frequencies, and an accompanying table, which provides more information, and covers a wider area. However, it's not entirely consistent with the wikipedia map.
So, I'm looking for a list of synchronous electricity grids, and the countries and regions that they consist of.
","['data-request', 'energy']",
Anyone need data transforming/cleaning?,"
I want to practice my data wrangling skills but can't seem to find any dirty data.
Trifacta is my main focus right now
At the very least can you help me with ideas on how to practice this?
",['data-request'],
Places to find credit risk data-sets,"
I am looking for places to get datasets regarding credit risk and risk analytics in financials services.
I have tried many places but was unable find what I am looking for. Can I get any pointer or link to find these?
","['data-request', 'finance']",
Modeling Stakeholder relationships in ontologies,"
First: I hope I am in the correct place of StackExchange to ask Ontology related questions.
I want to model relationships between agents and projects. There fore i have objectProperties of the kind: isStakeholderAgentProject, where i have sub properties representing the actual stakholder type (e.g. isManagerAgentProject).
Additionally I have SystemRightsStatements (sub class of dc/terms/RightsStatement). 
How can I associate RightsStatements to object Properties?
",['ontology'],"Ok. The answer was fairly simple.What I was looking for was N-ary relations. 
How this can be achived is documented by the W3C: ""Defining N-ary Relations on the Semantic Web"""
How to make a query to get all contributions from a certain donor?,"
In https://api.open.fec.gov/v1/schedules/schedule_a/
the maximum results per query are 100, e.g. the following large FEC query will result in:
{
  ""message"": ""Parameter \""per_page\"" must be between 1 and 100"",
  ""status"": 422
}

If I want to get all contributions from a certain donor, how should I formulate my query?
",['openfec'],
Downloading the Panama Papers,"
I wonder where the Panama Papers can be downloaded. I have looked around, I couldn't find them.
Where can I find them? 
What is the legality, and sensibility of requesting and downloading leaked data? Is now that it's leaked it's in the public domain? 
Bounty edit: Summarise all current sources of data, and explain what's in them, what format the data is, etc. 
","['data-request', 'finance', 'nlp']","The Panama Papers database has just been published at this link
https://www.occrp.org/en/panamapapers/database.htmlThis ICIJ database contains information on almost 320,000 offshore entities that are part of the Panama Papers and the Offshore Leaks investigations. The data covers nearly 40 years up to the end of 2015 and links to people and companies in more than 200 countries and territories."
"Open flight simulation data (trajectory, aerodynamics, wind tunnel simulations.. etc)?","
Are there any open datasets with flight simulation results?
I am looking for anything related to flight trajectory simulation, aerodynamics simulations, wind tunnel simulation. Anything that is used before actual flights (during prototyping).
I found a single set of data from NASA DASHlink:
https://c3.nasa.gov/dashlink/resources/140/
However, I would prefer to have a larger dataset, and possible from collection which is widely known and used before by other people (researchers).
",['data-request'],
Where I can get financial tweets and financial blogs datasets for sentiment analysis?,"
I'm learning sentiment analysis. I need financial tweets and blogs dataset for supervised learning.
Right now I'm trying lexicon based sentiment analysis on a small dataset of  financial tweets from stocktwits.
Can someone guide me where to find other sets?
","['data-request', 'sentiment-analysis']",
Why do patient notes contain so many newline characters?,"
As indicated in the documentation, MIMIC-III's patient notes contain so many many newline characters. Why?
Some statistics on MIMIC-III v1.3:
SELECT AVG(CHAR_LENGTH(text)) avg_nb_of_char, 
AVG(CHAR_LENGTH(text) - CHAR_LENGTH(REPLACE(text, '\n', '')) / CHAR_LENGTH('\n')) avg_nb_of_new_lines,
AVG((CHAR_LENGTH(text) / (CHAR_LENGTH(text) - CHAR_LENGTH(REPLACE(text, '\n', '')) / CHAR_LENGTH('\n')))) avg_new_line_every_x_char,

MIN(CHAR_LENGTH(text)) min_nb_of_char, 
MIN(CHAR_LENGTH(text) - CHAR_LENGTH(REPLACE(text, '\n', '')) / CHAR_LENGTH('\n')) min_nb_of_new_lines,
MIN((CHAR_LENGTH(text) / (CHAR_LENGTH(text) - CHAR_LENGTH(REPLACE(text, '\n', '')) / CHAR_LENGTH('\n')))) min_new_line_every_x_char,

MAX(CHAR_LENGTH(text)) max_nb_of_char, 
MAX(CHAR_LENGTH(text) - CHAR_LENGTH(REPLACE(text, '\n', '')) / CHAR_LENGTH('\n')) max_nb_of_new_lines,
MAX((CHAR_LENGTH(text) / (CHAR_LENGTH(text) - CHAR_LENGTH(REPLACE(text, '\n', '')) / CHAR_LENGTH('\n')))) max_new_line_every_x_char,

STD(CHAR_LENGTH(text)) std_nb_of_char, 
STD(CHAR_LENGTH(text) - CHAR_LENGTH(REPLACE(text, '\n', '')) / CHAR_LENGTH('\n')) std_nb_of_new_lines,
STD((CHAR_LENGTH(text) / (CHAR_LENGTH(text) - CHAR_LENGTH(REPLACE(text, '\n', '')) / CHAR_LENGTH('\n')))) std_new_line_every_x_char

FROM mimiciiiv13.noteevents;

returns:
        nb_of_char      nb_of_new_lines         new_line_every_x_char
AVG     1824.8          42.98                   63.2
MIN     3               1                       1.0
MAX     55725           2990                    2753.0
STD     2510.5          67.2                    70.7

",['mimic-iii'],
Where can I get the images data set of skin diseases?,"
I want to search on images of skin diseases corpus. I need this dataset to index images in my search engine. Please suggest me how and from where i can get those images.
","['data-request', 'medical', 'disease']",
Risks per medical treatment,"
I am looking for a data set on risks per medical treatment as many following fields as possible:

list of risk factors per medical treatment 
some quantification of the risk (e.g., an autologous blood injections to treat a lateral epicondylitis of the humerus carries a 1% chance of injury to structures near the tendon).
references for each risk (i.e., in which research study medical treatment X was shown to have a risk of y%.)

","['data-request', 'medical']",
Time of death in-hospital?,"
How do you determine the exact time of death for in-hospital deaths?  I see DOD (day of death) but not a time stamp.
",['mimic-iii'],
"Global ""bare earth"" dataset, in GeoTIFF format","
There are many options for downloading elevation data for the Earth (e.g. USGS Earth Explorer), but some of these include vegetation (trees) and structures (buildings). 
However, I am looking for a ""bare earth"" dataset that covers the full globe, downloadable in GeoTIFF format. I would love some suggestions, if anyone is aware of a specific dataset that provides this, or something similar.
","['data-request', 'geospatial']",
Open data sources similar to the Workplace and Employee Survey (WES),"
I've read some interesting analysis papers based on the Workplace and Employee Survey (WES), however it seems the data for this survey is not open to the public: http://www.rdc-cdr.ca/datasets/wes-workplace-and-employee-survey
Does anyone know of similar sources with datasets?
","['data-request', 'business', 'big-data']",
"Do we have any API for ""all"" Drugs ?","
Its there any API for all Drugs existed if yes can you explain when can I find IT.
",['medical'],The BnF in the UK has plans for an API - http://www.bnf.org/products/data-licenses/There is a proof of concept at http://www.openbnf.org/
I need a dataset in which different facilities are situated on the roadnetwork?,"
I am working on a project of partitioning the road network for improving recommendation system . In this project I have to recommend nearest facilities such as restaurant , hotels, movie theaters etc based on road network distance . So I need a dataset for such activity . Can you suggest me some database . I am looking data any small city of Canada like calgary etc .
",['data-request'],
Experience in transforming MIMIC-III dataset to follow EHR standards?,"
I wonder if anyone has attempted to transform MIMIC-III dataset into a format following some EHR standards, such as openEHR or HL7?
If not, any examples of how people use the dataset in non-relational DB fashion?
",['mimic-iii'],
Personal deductions when filing taxes in the US,"
I am looking for a data set listing the amount of personal deductions from the federal tax income as collected by the Internal Revenue Service (IRS) in the United States, broken down in deduction categories (such as medical expenses or giving to charity).
By amount of personal deductions, I mean the total amount as summed over all taxpayers in the United States.
E.g.:

In 2015, 1.2 billion USD were deducted as medical expenses.
In 2015, 30 million USD were deducted as lifetime learning.

Ideally, I would like to have a historical overview. (i.e., the evolution of these numbers over the years)
","['data-request', 'usa', 'taxes']",
Open API for currency conversion / exchange rates to EUR/USD/GBP (daily settlements),"
I'm looking for free open APIs (XML or REST(JSON)*) that I can access from my program code to get the (daily) exchange rate for foreign currencies to the Euro, Dollar or British Pound (especially from non-Euro European countries and the US).
No historical data required, I just want to query (on demand or each night) What is the exchange rate today? and store it in local database tables.
The source data should be updated at least once per day.
Ultimately, I want to encapsulate (updates from) several of these into my code (a standalone Windows program), so that our customers can choose which source they want to use for the exchange rates to their 'base currency' EUR or USD or GBP.
(This also means that the API should be free for commercial use, that it has a reputable source - i.e. it is not likely to disappear overnight, and that it can handle several 1000 requests/day).
From Philshem's answer I understand that in my case daily 'settlements' are preferable over  real-time currency data.
* Actually, any parse-able format will do, but JSON or XML is preferable because more structured.

[Added 4-4-2016 by OP]
While my question was out, I kept searching and found this June 2010 post on StackOverflow: How do I get currency exchange rates via an API such as Google Finance? 
.
Since that is an old post and not limited to free APIs, I have verified which ones are still active and partially meet my requirements, and I have added these as an answer to this post, together with the European Central Bank resource that I mentioned here earlier.
Any APIs I find that meet all requirements, I will add as separate answers each.
","['data-request', 'api', 'finance', 'rest']",
"What are the most comprehensive examples of businesses making strategy, marketing and performance data publicly available?","
Everpix recently gave an interesting look (https://github.com/everpix/Everpix-Intelligence) into the shuttered startup by providing everything from pitch decks to website analytics and subscription revenue data. A more intimate look than what you would see in SEC filings or quarterly earnings. What other companies, startup or established, have provided such an in-depth look at the business?
","['data-request', 'finance', 'business']",
Climbing cost per mountain,"
I am looking for a data set listing the cost of climbing a mountain, with as many following fields as possible:

mountain name
location
climbing time 
price breakdown (insurance, porters, etc.)

","['data-request', 'sports']",
How to use FEC data to search for campaign contributions from a list of people?,"
If one had a list of campaign contributors and wanted to generate a document listing all of their historical campaign contributions from the FEC data, without having to query each name individually, how would one do that?
Note: my own coding skills are slight, so while a technical answer is good, even better would be a pointer to some utility that someone has already developed to do this. (Worst case, some advice for extracting the data from the FEC's bulk downloads in a non-clunky fashion would work.)
",['openfec'],
Are there any open data sources on business strategy?,"
I am looking for data on strategy selection and impact on financial results.
Data from the strategy models used in the analysis would also be very useful indeed.
Most of the data I can find is in 'case studies' created by MBA students; but it seems there is not a database compiling this research
","['data-request', 'finance', 'business']",
"MIMIC III : Date and Time when Diagnosis Code was determined for the patient, say Septic Shock","
I am working on a project to predict Septic Shock on the MIMIC III data set.
I am using the following ICD9-CODes to detect Sepsis but not sure how to get the date + time stamp when the patient was diagnosed. diagnoses_icd table does not have a date and time stamp.
""99591"";""Sepsis""
""99592"";""Severe sepsis""
""78552"";""Septic shock""
Not sure how the diagnoses_icd table was linked to the Date and Time for the patients, say Septic Shock.
",['mimic-iii'],
Speeding ticket cost,"
I am looking for a data set listing the cost of speeding tickets, with as many following fields as possible:

Area (e.g., country)
Speed over the limit
Cost of ticket
Indirect costs (E.g., insurance raise, or driving school lessons)
Consequences other than financial ones (e.g., jail time, or loss of drive license points)
Year (since data may change over the years)

","['data-request', 'cars']",
"Machine readable list of monetary currencies, including symbol","
Does someone know a machine readable currency list, that includes the symbol?
For example
Aruba Guilder,AWG,ƒ,ƒ
Australia Dollar,AUD,$,$

I've found various sources, but they either lack the symbol (e.g $)

https://opendata.stackexchange.com/a/3984/1511 (although perhaps I don't know enough about how to use Wikidata to find the symbol)
http://www.currency-iso.org/en/home/tables/table-a1.html
https://github.com/datasets/currency-codes/blob/master/data/codes-all.csv

Or the lack the machine readability (would require scraping)

http://www.xe.com/symbols.php


(I've added a self-answer with the few resources that I've found.)
","['data-request', 'finance', 'programming']","There are at least three github reposCurrency-List - many formats - ""List of all currencies with names and ISO 4217 codes in all languages and all data formats.""JSON (gist) - (I'll use this one for now)YAML or gem - ""It contains every currency in the ISO 4217 standard"""
Time series data to predict the health of vehicle,"
I am looking for the data sets which were extracted using On-board or off-board dignostic (OBD). I need data which can help me to predict the health of the vehicle and its parts.
","['data-request', 'machine-learning', 'time-series']",
World sports with leagues and teams,"
I'm trying to find a simple json or xml (not feed) containing all sports. sport leagues and league teams around the world (or at least some sports)
I can't seem to find such a file
",['sports'],
ASIC designs for high-efficiency Bitcoin miners,"
I'm looking for available open-source ASIC code designs which can be used to produce high-efficiency Bitcoin miners (similar to Butterfly Labs, etc.)
Either HDL or VHDL, or any other kind of implementations for ASIC devices would be useful. This could be open data in the form of some logic representation (such as HDL), which can be used to simulate such miners for ASIC chip. This is similar to software to simulate ASIC chip logic, but I'm looking for available data.
","['data-request', 'programming']",
Duplicates in device recall data?,"
Is it just me or almost all of the device recall data duplicated in OpenFDA? For example, why are there 4 nearly identical entries for recall ""Z-3261-2011"" when a query for this recall number is made via openFDA, but there is just one when using the web interface?
",['openfda'],
Why does inventory.data.gov exist?,"
I've just started exploring the world of open data and towards that aim I've been looking the data sets on catalog.data.gov and inventory.data.gov.
What I'm struggling to understand is the purpose of inventory.data.gov. The about page states:
""Inventory.data.gov is a tool for federal agencies to create and publish metadata catalogs""
Isn't the metadata for each data set published on catalog.data.gov as well? If so, then what purpose does the inventory.data.gov site serve?
",['data-portal'],
Download all drug adverse events,"
I downloaded the adverse events quarterly data files from the FEARS website and I merged and cleaned them to use them in my next analytics pipeline. I was asked if I can download all the drug adverse events with demographic information (sex, age,..), drug name, indication for use, reactions, outcome, etc directly from the openFDA API. Is that possible?
",['openfda'],
Data sets about nutrition/diseases,"
I have to do analysis about correlation between diseases and nutrition consumption. Where I can find data sets about food (nutrition) consumption, divided by diseases (I can also use two data sets: nutrition ~ country and country ~ diseases?
","['data-request', 'medical', 'food', 'global', 'disease']",
Breakdown of absentee vs. in-person voting in the 2016 presidential primary,"
I am looking for the breakdown of the 2016 presidential primary results on the state or lower level by absentee, early, and in-person voting. I've found a few resources that have aggregated primary results, but none of these seem to touch on early or absentee voting:

the US election atlas. There are a few paid data sources on the website, but none of them mention anything about absentee/early voting in their descriptions.
openelections. They don't seem to have aggregated 2016 data yet, and again, no mention of absentee/early voting.

I've also looked at a few previous results ((1), (2)) that suggest that it's hard to find a centralized source for any of this information. I'm just surprised that I haven't been able to find absentee vs. early vs. in-person information for any state. Is this required information for a state to report? Should I be looking elsewhere on their sites? Has anyone (fingers crossed) aggregated this yet?
Edit: It looks like TargetSmart offers this commercially in their VoterBase (found via this article).
","['elections', 'politics']",
Timeseries from the CIA World Factbook,"
We're looking for some datasets (preferably time-series) on the percentage of people in different countries who adhere to different religions (like here), speak different languages (like here) or belong to different ethnic groups (like here - oops I can only post two links...).
I have heard that there are parsers for the CIA World Factbook (WFB). But does anybody know whether those also work on 'old' versions of the WFB, and if so - how far back? So if we were to run them on older versions of WFB on Wayback Machine - would they work? Or better yet: is there anybody who's already done that?
I'd be very grateful for any hints. 
-Stephan
",['data-request'],
Overfishing dataset,"
We are joining a datathon tomorrow with the goal to get insight in the whole ocean overfishing situation and we are looking for data to prepare a little bit. Global Fishing Watch seems interesting however we cannot find the data online. Does anyone have any good open datasets that could be relevant for this project?
","['data-request', 'geospatial', 'environment']",
What's the license of MIMIC-III?,"
What's the license of MIMIC-III, if any?
I could only find the MIMIC II Clinical Database Restricted Data Use Agreement, which I copy below:

If I am granted access to the MIMIC II Clinical Database, I agree to
  the terms and conditions below:

I will not attempt to identify any individual referenced in restricted    data from PhysioNet.
I will exercise all reasonable and prudent care to avoid disclosure of    the identity of any individual referenced in
  restricted data from PhysioNet    in any publication or other
  communication.
I will not share access to restricted data from PhysioNet with anyone    else.
I will exercise all reasonable and prudent care to maintain the physical    and electronic security of restricted data from PhysioNet.
If I find information within restricted data from PhysioNet that I    believe might permit identification of any individual, I will
  report the    location of this information promptly by email to
  mimic-support@physionet.org, citing the location of the specific
  information    in question so that it can be investigated and removed
  if necessary.
I have requested access to restricted data from PhysioNet for the sole    purpose of lawful use in scientific research, and I will
  use my privilege of    access, if it is granted, for this purpose and
  no other.
I have completed a training program in human research subjects    protections and I am submitting proof of having done so.
This agreement may be terminated by either party at any time, but my    obligations with respect to restricted data from PhysioNet
  shall continue    after termination.


","['mimic-iii', 'licensing']",This is the new data use agreement for MIMIC-III as of v1.4 (current version at time of writing):
Tagged (non-anonymized) GPS driver trip database,"
The AXA Kaggle challenge Driver Telematics Analysis provides a dataset of over 50,000 anonymized driver trips. 
Are there open databases of tagged, non-anonymized trips, with several trips for each driver, with car ID identified (if the driver drives several different cars), that could serve as  training data for a data science newbie, and that could be distorted (jitter, noise) to test the robustness of driver detection/clustering algorithms (since we know the ground truth)? 
Weather conditions could be a plus.
I am checking the Publicly available taxi GPS data aside.
","['data-request', 'machine-learning', 'weather', 'transportation', 'traffic']","OpenStreetMap hosts GPS Traces that are uploaded by the community. Not all are for driving, but you can probably screen GPS tracks for total distance to find driving ones. Or screen for users that meet a criteria, like this oneFiles are downloadable as GPX format, which has many libraries that support parsing and analyzing.Bulk download of OSM's traces is possible: Blog post and download siteWith GPS coordinates and time you could join to a global weather database (example)."
Long-term search trends by domain,"
I want to know what people are searching for in a particular domain (the domain is enterprise software, if that matter). The goal is to discover new trends.
I tried the Hot Trends feature which is part of the Google Trends tools, but unfortunately:

It only gives trends for the last 24 hours.
No way to divide by domain, so all results are sports/politics and other topics more popular than the particular domain I am interested in.

Is there a trends viewing tool that fits my requirements?
Trends could be measured with another metric such as hashtags or word use, but I would prefer the number of searches metric.
Open data would be the best, but just free is OK too.
Example usage:

Me: What are the top trending searches in enterprise software in 2016?
  The service: Nuxeo (3m searches), Salesforce (700k searches), etc

","['tool-request', 'trends']",
Historical Twitter Data,"
I'm trying to get historical twitter data starting from 2010 with specific keywords related to S&P500 companies. I will probably end up using their tickers as keywords once I finalize my list of specific companies. 
I'm unable to go back more than a week. Has anyone found a way to get around this? I need to be able to have code available for my research paper/presentation. I've tried TwitterSearch and Tweepy packages. 
This is the code using TwitterSearch:
import datetime
from TwitterSearch import TwitterSearch, TwitterSearchOrder, TwitterSearchException

#the start and end of our twitter data
mindate = datetime.date(2010, 01, 01)

maxdate = datetime.date(2016, 01, 01)


try:

    tso = TwitterSearchOrder() # create a TwitterSearchOrder object

    tso.set_keywords(['sp500', 's&p500']) # let's define all words we would like to have a look for
    tso.set_language('en') # English tweets only
    tso.set_include_entities(False) # entities...
    tso.set_until(datetime.date(2016, 01, 01))  #this doesn't work...

    # it's about time to create a TwitterSearch object with our secret tokens
    ts = TwitterSearch(
        consumer_key = 'REMOVED',
        consumer_secret = 'REMOVED',
        access_token = 'REMOVED',
        access_token_secret = 'ALSO REMOVED'
     )

     # this is where the fun actually starts :)
    for tweet in ts.search_tweets_iterable(tso):
        print( '\n@%s tweeted: %s' % \
             ( tweet['user']['screen_name'], tweet['text']) )

except TwitterSearchException as e: 
    print(e)

I also need to be able to print the date of the tweet, how many likes/retweets it had, and possibly the number of followers the user has. Lastly, I need to be able to save all the data in a csv file. 
Any help is greatly appreciated!
","['programming', 'social-media', 'python']",
What methods are used to prepare sensitive data for public access?,"
I am a policy researcher looking for the best technical methods to sanitize data so it can be uploaded to data portals. I am not working with a specific dataset but looking to gain an understanding of the methods used and the tradeoffs between usability and risk of re-identification. Are there scripts, open source applications or services that can be automatically applied to large varieties of datasets? 
","['releasing-data', 'privacy']",
Chronicling America Bulk Downloads,"
Any packages written that assist with bulk downloads from Chronicling America's API? I'm interested in both obtaining the OCR text of the newspapers and the newspaper directory.
","['data-request', 'media']",
Year Structure Built of housing units,"
I need to find the age of housing units? where specifically should I look and download a GIS file
","['census', 'real-estate']",
"What's the difference between ""Nursing"" and ""Nursing/other"" notes?","
What's the difference between Nursing and Nursing/other?

",['mimic-iii'],
Examples of (near) real-time energy dashboards or portals,"
What are some examples of real-time or live data dashboards related to consumption, production or transmission of energy?
","['data-request', 'energy', 'real-time']","CitiesState/RegionCountriesU.S. Electric System Operating Data (see below)Switzerland - Swissgrid wide area monitoringSweden (and neigbhors) - The Control RoomDenmark Energinet (requires Flash)Great Britain GridwatchSpain - real time production and demand (flash) - and super datavizWinderful - UK wind energy Ireland EirGrid SmartGrid France Gridwatch (direct CSV download)Australia - Live photovoltaic performanceMulti-countryENTSO-E Transparency - Cross-border flows - European organization of transmission service operators (TSOs)EEX Transparency (mostly production availability and forecasts, to avoid market manipulation - example Actual Production, Germany)European Grid Frequency - Wide Area Monitoring"
Texas Parcel Data,"
Currently, I download any parcel data that I need from the specific county appraisal district for the area that I am working on, or the regional council of governments. The issue is that we spend a ton of time formatting the data we receive from them because it all comes in different formats. 
So, I wanted to ask, where do you get your parcel data? I am interested in keeping fields like Ownership, Appraised/Land Values, Land Use, etc. How accurate is this data, and is it affordable?
","['data-request', 'geospatial', 'government']",
"Any benchmark data available for average wages,benefits based on job position and state wise?","
I am looking for some data that I need for benchmarking purpose. The fields that I am interested in are:

Average salary/wage
Average benefits (like average bonus etc.)

Apart from this I am also optionally looking for some stats regarding average training time and cost for new hires based on job position.
I am looking for data which has position(like software engineer,financial analyst,marketing manager and so on) and state wise data and which I can download.
I found this website upon looking. It does have salary info and bonus info based on job positions and state wise but I don't find any way to download this data and I sure cannot do that manually as there are far too many positions.
Can anyone point to me where I can find such a data or if anyone knows how can I download the whole data from above website I mentioned?
",['data-request'],
Sensor data from wind turbines,"
Are there any data sets available for sensors of wind turbines? I'm looking for sensor data off the actual wind turbines, not the wind speed or energy data. This is for a preventative maintenance use case (i.e., pulling sensor data off the wind turbines to detect any mechanical issues and implement predictive maintenance).
I'm also curious how much data is generated per day from all the sensors on these turbines.
","['data-request', 'energy', 'sensors']",The Engie Group has just published operational data of one of its wind farms under the Open License 2.0 of Etalab. See here: https://opendata-renewables.engie.com/
Dataset for Device fingerprints?,"
For research purposes, I'm looking for Device Fingerprint datasets.
A device might be a browser, a headless browser or even a network library capable of HTTP traffic.
A device fingerprint might include any information regrading the device, from its network behavior to its javascript and plugin extracted information (screen resolution, timezone, etc..)
","['data-request', 'internet']","FingerbankFingerbank accurately determines what kind of device is connected on a network based on its MAC [External] address, its DHCP [External] fingerprint and its User-Agent [External].When you query the Fingerbank database using the API, if this combination of data is unknown to Fingerbank, it will be automatically added to the Fingerbank database.Access options:Query the fingerprints onlineDownload the data as an SQLite databasePublic API (requires registration)License"
Data Set for Quantile Regression in Survival Analysis,"
I am new to Open Data SE and to Survival Regression: I must prepare an essay about using Quantille Regression in Survival Analysis and I have no idea which data would be proper. I think that when I want to use Quantille Regression this data should have particular structure. Could anyone recommend a specific data set?
",['medical'],
Getting metadata of all databases available on the Internet [closed],"







Closed. This question needs to be more focused. It is not currently accepting answers.
                                
                            











Want to improve this question? Update the question so it focuses on one problem only by editing this post.


Closed 7 years ago.







                        Improve this question
                    



I would like to get metadata for all (or as many as possible) databases that are available online. It does not have to be an open database. It is only the metadata that is important for me. The data I am interested in are e.g.:

Number of tables
Number of relations
Number of rows in each table (or average for whole database)

Is there a place that gathers such information?
","['metadata', 'internet']",
Where can I get previous versions of MIMIC-III?,"
The current version of MIMIC-III is 1.3, and can be obtain here. Where can I get previous versions of MIMIC-III? Namely, versions 1.1 and 1.2?
",['mimic-iii'],"Only the most up-to-date version is made available to the research community via PhysioNet, but past versions are archived and may be shared upon request. Contact information is available on the MIMIC website (http://mimic.physionet.org/help/)."
Extensive Weather or Sea State API?,"
Please bear with me since this is my first time asking something Weather related.
What would be the best source for getting Sea and Weather related data like 

Wind Wave Height (m)
Wind Wave Period (s)
Wind Wave Direction
Significant Wave Height (m)
Swell Height (m)
Swell Period (s)
Swell Direction
Surface Currents (kts)



Air Pressure (hPa)
Wind Speed @ 10m (kts)
Wind speed and direction (barbs)
Relative Humidity (%)
Air Temp @ 0m (C)
Air Temp @ 2m (C)
Cloud Cover (%)
Precipitation (mm)
1000-500mb Thickness
Ice Cover

Might be to much to ask but I searched many online API's but many of them were not provide most of it. 
","['data-request', 'weather', 'oceanographic']",
Is there a dataset with the MGRS 100Km square id for every such square on world map?,"
I'm trying to compile a list of MGRS 100km square identifiers for every such square (eg 4QFJ for Honolulu Hawaii); excluding the poles (85 to -85 latitudes).
Does anyone know of a dataset or can point me in a good direction?
","['data-request', 'geospatial']","You can download selected squares from Military Grid Reference System (MGRS): Downloads, or get a large grid file from GIS MGRS Grid Data layers in GIS Format.These are likely to be free of copyright, since they are US Government publications."
How to retrieve discharge summaries?,"
How can I get the discharge summaries in mimic III, I tried putting 'Summary' as a category but didn't work.
",['mimic-iii'],
Dataset of accidents and incidents involving drones,"
I am looking for a data set listing accidents and incidents involving drones, with as many following fields as possible:

timestamp
location
number of casualties
description of the accident/incident

",['data-request'],
MODBUS device register definitions,"
MODBUS is a common and widely used protocol in industrial applications for connection sensors, plc's and machines. When accessing MODBUS devices the core are register definitions. These vary from device to device, even if the devices are from the same manufacturer.
I am looking for a global directory of register definitions for MODBUS devices. 
",['industry'],
Risk factors per disease,"
I am looking for a data set on risk factors for diseases as many following fields as possible:

list of risk factors per disease
references for each risk factor (i.e., in which research study X was shown To be a risk factor for disease Y.)

I'm also interested in negative results, i.e., results showing that X is not a risk factor for Y.
","['data-request', 'medical']",
Combining (aggregating) county data,"
For research, we are using county-level data for fatal car accidents. However, this data is very sparse for counties with small populations. I would like to know if there is a guideline for merging (aggregating) data of counties with small populations.
In other words, is there any unit of analysis that is finer than states but larger than counties with a considerable population?
","['data-portal', 'state', 'county']","Census has Metropolitan and Micropolitan Statistical Areas
https://www.census.gov/population/metro/
as well as Combined Statistical Areas (CSA):
https://www.census.gov/geo/reference/webatlas/csa.html
and CBSA (Core Based Statistical Areas):
https://www.census.gov/geo/reference/gtc/gtc_cbsa.html"
Where can I get the coordinates datasets of water bodies of a country?,"
I'm in need of acquiring the coordinates of the outlines of all the water bodies inside a country, with the exception of ""Sea"" or ""Ocean"" water. Right now, I'm manually outlining the lakes and rivers but it is not a sustainable solution for the magnitude of the research I'm doing.
Even if I can only obtain the data of Lakes or Rivers, that would be a great start. I'm specifically interested in the countries of Malaysia, Brazil, and the Dominican Republic.
My situation brings me to the question of, where does Google Maps obtain its data? Are these data sets available?
","['data-request', 'geospatial']","I don't know of any sites where you'll find pre-existing lists or databases with coordinates for the shapes of water bodies. Most gazetteers will only give you coordinate centroids, or bounding boxes at most. However, it's relatively easy to generate this data from shapefiles or KML files using desktop GIS software. There's a lot involved with learning GIS, but if this operation was all you need to do it's straightforward.You can download an open source desktop package like QGIS: http://qgis.org/en/site/ and then as another post suggested, you can download shapefiles for water features from a site like Natural Earth. The shapefiles consist of geometry - strings of coordinates stored in a specific format - so they can be represented visually in the software. If you add the water shapefile to the GIS software, you can export the shapefile out as a CSV and generate the underlying coordinates for each feature out into a text format.  Essentially: There are a number of posts on the GIS stack exchange like this one: https://gis.stackexchange.com/questions/8844/get-list-of-coordinates-for-points-in-a-layer that also show how you can accomplish this."
Download customer purchased data [duplicate],"







This question already has answers here:
                                
                            




Transactional data over multiple years (Customer ID, Date, Price)

                                (2 answers)
                            

Closed 7 years ago.



I want to do customer behavior analysis for a retail store. Could you tell me where can i download customer purchased transaction/data?
","['data-request', 'shopping']",
"what was the weather in red rock, nv March 14, 2016","
What was the weather in Red Rock, Nevada on March 14, 2016? Specifically, what were the wind gusts?
",['weather'],
Impact the boiling time on nutritional content,"
I am looking for a data set on the impact the boiling time on the nutritional content of the cooked food with as many following fields as possible:

type of food (e.g., potatoes),
curve showing the nutriment loss over cooking time, if possible for each nutriment the food contains.

","['data-request', 'medical', 'food']",
Some random person name and details generator?,"
I am looking for some website/tool that can allow me to generate names, some random id for certain number of people at once. I came across some websites but they only do one at a time and there was no easy way to download those. I am looking to generate for about 10K names and ids (other details will be more than welcome). Is anyone familiar with any such tool that can allow me to generate names and unique ids?
",['data-request'],
Is data becoming more or less concentrated globally? [closed],"







Closed. This question is opinion-based. It is not currently accepting answers.
                                
                            











Want to improve this question? Update the question so it can be answered with facts and citations by editing this post.


Closed 7 years ago.







                        Improve this question
                    



There are lots of books and research about the distribution of wealth, income, etc both at a national and a global level.
What is the trend with the data? Of course there are more and more data available openly. How about the data that is not open? How concentrated is it? Is the concentration increasing or decreasing? Is the fraction of open data increasing? Have there been any attempts to estimate this?
",['trends'],
Bibliometric data to rank research institutions,"
I would like to rank research institutions on its impact in scientific fields like bioinformatics or molecular biology.
Are there repositories of bibliometric data (aggregated by research institution, and research field) that can be used to this purpose?
","['data-request', 'research', 'bibliometrics']",
Where can I get the wind data for Nepal?,"
I am planning for a small scale distributed wind farms in whole country and a foreign agency is interested in helping. I want to have wind data to show them and I cannot find this data online. Also, if I have to gather it by my own it would take a lot of time so I am searching for open data if I can get it.
","['data-request', 'weather', 'energy']",
Survey raw data,"
I would like to perform some kind of analysis on survey raw survey data. That is on the actual answers, not on the processed results.
Where can I get such data?
","['data-request', 'survey']",
.How can I get the list of drugs that interact with a particular drug in openFDA,"
I am trying to get a list of ingredients/drugs that might interact with a particular drug or check if a list of drugs might interact with each other.
How can I achieve it using openFDA API.
","['openfda', 'api']",
"Wikidata SPARQL, why an intermediate item is needed in this sample query?","
In the Wikidata SPARQL samples, I found this query:
What is the relation between Terrell Buckley and Miami Dolphins?
Items used: Terrell Buckley (Q5571382), Miami Dolphins (Q223243)
SELECT ?l 
WHERE
{
    wd:Q5571382 ?p wd:Q223243 .
    ?property ?ref ?p .
    ?property a wikibase:Property .
    ?property rdfs:label ?l FILTER (lang(?l) = ""en"")
}
LIMIT 10

Try it
I found really hard to know why you can't simply write:
SELECT ?l 
WHERE
{
    wd:Q5571382 ?property wd:Q223243 .
    ?property a wikibase:Property .
    ?property rdfs:label ?l FILTER (lang(?l) = ""en"")
}
LIMIT 10

Removing the ?p intermediate variable.
The fact it doesn't work numbs me beyond comprehension, I don't know if I'm simply too stupid to understand it, but, could you help me, guys?
","['wikidata', 'sparql']","In the original query ?property and ?p are distinct values: ?property is wd:P54 (short for <http://www.wikidata.org/entity/P54>) and ?p is wdt:P54 (short for <http://www.wikidata.org/prop/direct/P54>). Notice that both refer to P54, but they are not the same. The two are connected by ?ref, which is wikibase:directClaim.This is why your simplified query doesn't work."
Collection of large geospatial datasets,"
This post is in the spirit of ""big-lists"" on tex.se and other sites
Purpose of this post...
...is to collect (in separate answers, unless clearly related) open datasets containing detailed geospatial information.
Geographic coverage
The datasets should be worldwide or covering at least areas exceeding single counties or small (sub-)continents.
Content coverage
I believe the other restrictions already limit the sets substantially. In terms of content anything is fine, as long as it contains detailed geospatial information, be it raster-data, point data or.
To me, info that is built into standard packages (such as a worldwide city list) is boring. It's left to the community and the rating system to discourage those.
Posting format
Post a link and a brief description of what the data contains.
Reward
If this resonates sufficiently (five or more answers which aren't mine) I'll place a bounty of 100-200 to reward the user with the most above average ranking answers (most likely just the highest ranking answer).
","['data-request', 'geospatial']",
Detailed data about Medicare Enrollment?,"
I found CMS Medicare Enrollment Reports broken down by different parts, regions... I'm wondering if there are more detailed open data sources from which these reports are generated?
For instance, I understand that about 10,000 baby-boomers per day are aging into Medicare. I'd like to know how many folks are first-time enrollees versus those who needed to go back and re-enroll (because of life qualifying events and such).
",['data.gov'],
Data on (non-sexual) child abuse,"
I am looking for data on child abuse, broken down by sex of the victim and, if possible, sex of the perpetrator and relation to the victim. Age of child would be useful, too.
There is a lot of data on child sexual abuse, but I can only find very brief summary statistics on non-sexual child abuse.
I may not be searching in the right way or the right places, so I'd be happy for any and all help.
",['data-request'],"Curious to what you are searching and where? Searching Google for ""non sexual child abuse statistics open data"" gave me multiple resources on first page of SERPS. You're going to have to pick through these, but they all separate sexual/non-sexual in one form or another.
Childstats.gov
Kids Count
Child Abuse Statistics, Research, and Resources - If you use this one make sure and double check the legitimacy of the site. Looks ok from brief glance, but I would not take that chance doing any real work with this data prior to confirming
Abuse/Bullying - Alberta Gov
UK Child Abuse Statistics
Child Abuse Statistics - Iowa"
Leaked Daesh (ISIS) Documents,"
This: dailymail - Names and family details of 22000 jihadis revealed by huge cache of leaked ISIS HR-forms. Of course, whether the names of family details should be published is debatable. But the other variables seem to be less sensitive and could potentially be made public. 
Are they or a subset of variables available somewhere?
If not, who would one have to approach to get an (anonymized) version of the data?
","['leak', 'terrorism']",
Campground data or maps,"
I am seeking to get data or map that has campground in the United State but more specifically Colorado. They can be either on the internet, download data, or have maps that done by someone who did the mapping. 
I am looking at the Cottonwood Lake campground which lacks the information for me to gather the information. This campground is part of the USDA US Forest Service.
","['data-request', 'geospatial']",
Most common words in English,"
I am looking for a machine readable data set (e.g., a mere txt file with one word per row) containing the X most common words in English, excluding proper nouns (unlike this list). If possible, ordered by frequency.
","['data-request', 'nlp', 'english']",
Vaccination success rates,"
I am looking for a data set containing vaccination success rates with as many following fields as possible:

percentage of patients who received the vaccination but are not immune to the medical condition they have been vaccinated against;
percentage of patients with strongly negative reaction to the vaccination;
year
patient demographics

","['data-request', 'medical', 'global']",
VETS-4212 Dataset,"
I'm wondering when the VETS-4212 dataset will be available via the Department of Labor's API, like the VETS100 and VETS100A datasets are at:
http://developer.dol.gov/others/vets100/
","['api', 'labor']",
Online financial help (donation) dataset,"
I am looking for datasets for online donation for people who need help.
Something like Kiva
",['data-request'],
Can we use the DDL as a data repository for reference in publications with DOI?,"
In cases where journals require us to share a DOI or URL link to a stable public access data repository, can the DDL be used, and how? 
The DOI or URL for this purpose may be intended to link a limited dataset corresponding only to the specific analysis for the manuscript or publication. 
Can the DDL be used in this very limited way and if so, is there any guidance for how this can be done? 
","['usaidopen', 'doi']",
Need help decoding OSHA datasets numeric codes,"
I need reference tables to decodify OSHA numberic codes for the multiple fields in the OSHA datasets. Many of these fields reference numeric codes for which I have not been able to find anywhere. 
The list of data tables I am working with are located at: 
http://developer.dol.gov/health-and-safety/dol-osha-enforcement/#osha_accident_injury
Below is an example column from the accident_injury table:
COLUMN NAME = fat_cause     
COLUMN DESCRIPTION = Construction - cause of fatality (code table CAUS)
Under this column are numeric codes that range from 1-30. I would like to know where I can access the code table CAUS referenced in the table dictionary as well as all the other codes.
Thanks.
",['labor'],"Here is the information you need: http://www.dol.gov/open/xls/IMISCodes.xlsxWe will also be updating developer.dol.gov shortly.If you have any more questions about it, please don't hesitate to ask.  EDIT 2018-01-29: IMIS Codes live here now"
Relation of MIMIC-II v2.6 and MIMIC-III v1.3 patients records,"
Are all patients' admissions and ICU stays from MIMIC-II included in MIMIC-III?
",['mimic-iii'],"The vast majority of patients who appear in MIMIC-II v2.6 also appear in MIMIC-III v1.3. These patients retain the same subject_id and can be selected across versions of the database using the following query:A small proportion of patients were not included in MIMIC-III for various reasons, mostly relating to missing data in a later data dump. These patients may be added in the future.Note that MIMIC-II and MIMIC-III are significantly different in structure and content. We recommend treating MIMIC-III as an entirely new database, unless there are strong reasons to attempt to link across versions."
Music Artists On Tracks,"
I am trying to find the artists on songs for appropriate credit to those artists musicians vocalists. Is there a way to look up the complete music artists (such a vocal, dj, band) on songs?
",['music'],
Pension liabilities data sample,"
Does anyone know where I can find a sample of pension liabilities (age-sex-liability)?  
I already tried some of the proposed databases over here:
https://stats.stackexchange.com/questions/7/locating-freely-available-data-samples
",['data-request'],
Data with trips,"
Any idea if there`s any source from where I can get publicly available data of trip details?
",['data-request'],the only source I know is a freedom of information request to NYC's Taxi & Limousine Commission made by FiveThirtyEight. The data are avaible on this Github repo. Part of the data are also directly available through an API on OpenDataSoft if you prefer ;). Disclaimer: I work for OpenDataSoft.There are not a lot of trip details but it's a good start. Hope it will help though.Cheers
Inquiry about number of adults in MIMIC-III v1.3,"
I need to verify the number of adults I found in MIMIC III v1.3.
Based on the fact that age is defined by this formula:
((extract(DAY from admittime - dob) 
 + extract(HOUR from admittime - dob) / 24
 + extract(MINUTE from admittime - dob) / 24 / 60
  ) / 365.242)

and that adult is patients who are aged above 15 at the time of their first admission, there are 38,645 adults in the database among a total of 46,520 patients.
Could you please confirm or reject this number by giving the exact number of adults?
",['mimic-iii'],"The following query confirms that there are 46,520 distinct patients in MIMIC-III v1.3:The following query confirms that the there are 38,645 distinct adult patients in MIMIC-III v1.3, based on the definition of 'adult' provided in the question:"
Georeferenced data on animal sightings,"
I once came across a website offering datasets of animal (mainly birds) sightings from all over the globe. If I remember correctly that data was combined from different sources, including crowd-sourced locations (some observations had a column with free text such as ""saw it in the garden of my hotel in Addis"").
I can't seem to find that data set anymore. Does anyone know this or a comparable dataset?
","['geospatial', 'geocoding', 'biology']",
StateWide Collated Public county data set,"
Is there a easier way to download public data from county government website ( property sales) other than individually from each county?(USA) Is there a collated data set state wise that is available for download?
",['county'],
College Scorecard data dictionary missing academic.program_available.XXX entries,"
I'm looking at the College Scorecard raw data zip downloaded from https://collegescorecard.ed.gov/data/ (""All Data"") and the included data_dictionary.yaml that defines the data fields and their source in the included .csv files.
My issue, if I understand correctly, is due to the included data_dictionary.yaml missing entries for:

academic.program_available.assoc
academic.program_available.bachelors
academic.program_available.assoc_or_bachelors

These are the fields that allow the search to query on schools that offer different degree types, either 2-year, 4-year, or both. Without these entries in the yaml, I don't know what they should link up to in the source csv columns and I'm not sure how the college scorecard site is able to query on these variables if they are not defined in the yaml (or in the csv?).
Perhaps the download doesn't contain the most recent dictionary_data.yaml file that the https://collegescorecard.ed.gov site is using? The file version is: Aug27-2015-09-04-15:41-0700-allyears
","['api', 'collegescorecard']",The latest data dictionary is available in JSON format here:https://api.data.gov/ed/collegescorecard/v1/data.json?api_key=YOURKEYHERE
College scorecard data dictionary Stata code?,"
I have downloaded the full (""all data"") version of the college scorecard data form https://collegescorecard.ed.gov/data/. Along with the data it contains an extensive data dictionary listing variable names, descriptions and labels for categorical variables. The team I am working with prefer to use Stata, so we would like to load this dictionary in along with the data. Has someone already written Stata code to do this?
Edited to clarify:
The data have a large number of categorical variables stored as numbers. For instance, the variable ""CONTROL"" can take values 1, 2 and 3. According to the data dictionary (CollegeScorecardDataDictionary-09-12-2015.csv) these values correspond to Public, Private nonprofit and Private for-profit respectively. To have Stata recognize these labels I could manually enter the command:
label define CONTROL 1 ""Public"" 2 ""Private nonprofit"" 3 ""Private for-profit""
In R we would run something like:
CONTROL <- factor(CONTROL,
levels = c(1,2,3),
labels = c(""Public"", ""Private nonprofit"", ""Private for-profit""))
I want to do this so that my software automatically gives meaningful names when preparing tables and so I don't have to go searching through the data dictionary manually whenever I want to look at the data directly.
Now obviously I should not write code analogous to the above for all variables by hand. Instead I can write some code that loops over all the variables in the data dictionary and, for those with labels, loops over those labels and assigns them to the relevant number. Before I do this task I thought I would ask if someone had already solved this problem.
",['collegescorecard'],
Is there an open database with characteristics of tree species?,"
I am looking for a downloadable/queryable database which lists tree species with their characteristics (e.g. average height, preferred temperature, etc.), I am specifically interested in flowering times. There are some websites where one can look up a specific species like worldagroforestry.org or feis-crs.org, but I would like to be able to query it (e.g. list all trees that blossom in July).
Has anyone came across such a database or service?
","['data-request', 'research']","The National Phenology Network has data for flowering dates (and other phenological characteristics) for trees in the United States. Using their download tool, you can specify a season of interest (if you select ""Other"" under Year Options, you can narrow it down to specific dates) and a range of species (selecting all the broadleaf and conifer Functional Types will give you most trees and shrubs) to download. Checking ""Flowers"" under the Phenophase Categories will return only the data pertaining to flowering.Even their summary data are more detailed than simply a list of species matching the criteria, so you will need to do some additional analysis/interpretation to answer your question. The parts of interest to you will be the First_Yes_* and Last_Yes_* describing the dates of the flowering events.Also, as you will no doubt notice, the flowering date of a particular species will vary by latitude and elevation (as well as other factors correlated to temperature), so the answer to the question of ""all trees that blossom in July"" will depend on where those trees are located.Good Luck!"
Open data GeoRSS feeds,"
I am building a GIS platform for security management purpose. I would need to display POIs that would be geolocated about events occurring on the globe. Do you guys know open data geoRSS feeds available that I could use and import in my platform?
","['geospatial', 'geocoding']",
Is there a vocabulary for linking machine data on the shopfloor?,"
I've got a gateway that reads machine data on the shopfloor, e.g.

running hours
notifications (""low oil pressure"",...)
temperatures inside machine

The gateway should publish this data in JSON-LD.
For the context file I'm looking for a vocubulary to express the machine data. Is there already a vocabulary or 'setup' for this kind of data?
Are there sample immplementations for this domain?
","['data-request', 'linked-data', 'ontology', 'json']",
Is there an API for soft erotic pictures?,"
Just a wonder I had, does somebody know an API which with we can retrieve soft free-to-use erotic photos and pictures ?
I have seen a lot of APIs and datasets, but never heard of this kind.
Looking for answers !
Kind regards, 
Shade 
",['api'],"Not specifically a soft erotic API, but you can use flickr and I'm going to assume tumblr, to get what you are asking for.
flickr's API is incredibly stable, you'll just have to filter out what is/is not soft erotic. under the erotic tag in flickr, you'll get mixed results; heads up, some may be NSFW:
https://www.flickr.com/photos/tags/erotic
I'm assuming tumblr because it has similar content as well as a stable API, however I'm not very familiar with it. Although I've seen quite an uptick in porn there lately, so if you do use tumblr you may have to double down on your filter(s)."
Where can I get the images data set of skin diseases?,"
I want to search on images of skin diseases corpus. I need this dataset to index images in my search engine. Please suggest me how and from where i can get those images.
","['data-request', 'medical', 'disease']",
College Scorecard Raw Data Question,"
on the data download page, there is a file called ""Most recent data 124 MB csv"", Does anyone know what the time period is? 2014? 2015? Or something else?
",['collegescorecard'],
Property tax assessment,"
What would be the best source for data set of property tax assessments for all counties other than going to individual counties and requesting them?
","['data.gov', 'uk']",
Corpus of tagged text (English newspapers or any tagged text),"
I'm developing a system to extract tags from text (English) and currently I have no dataset to test the system and evaluate, could someone point me to a source (preferably a free one) thanks.
NOTE:
By Tags I mean if there's an article about let's say new album of a musician then Tags should be something like [""music"",""new album"",""name of musician""] something along these lines.
","['english', 'corpora']",
GIS and/or Maps regarding Ginseng in the United States.,"
Does anyone know of any spatial data on Ginseng in the United States other than USGS range maps? 
",['geospatial'],
Where can i download spatio-temporal landslide station based dataset for india in .csv format,"
Looking for landslide spatio-temporal station based dataset for India or Global region. Need to analyze the characteristics of landslide attributes such as soil type, slope aspect, date, latitude, longitude, Date/time, rainfall and climatic factors.
","['geospatial', 'weather', 'research', 'india']",
Wikipedia database: categories and category mapping across languages,"
I've imported the wikipedia database in four languages with the goal of running some machine learning algorithms on it for text classification. The import doesn't populate the ""category"" table though. Am I missing something?
I would also like to know if there was a way to map categories across the different language databases? i.e. know which category in English represents which category in German for example?
Thanks!
",['wikipedia'],"For the second question, the answer is in the langlinks table (categories have page_id just like pages). Se more here: https://www.mediawiki.org/wiki/Manual:Langlinks_table"
where can i find sample free data set from super market purchase history with customer id?,"
I tired with many open sources like https://archive.ics.uci.edu/ml/index.html but i couldn't able to find any grocery supermarket data.I am looking for Like purchase history stored in Loyalty card. i am looking for data set with item id,
item name,quantity,price, purchase date , customer id or loyalty id.
","['data-request', 'machine-learning', 'research']",
UN Comtrade Database- what is the difference between a partnercode and reportercode,"
I am working with the UN Comtrade database. Each observation is 2-dimensional and contains a partnercode and reportercode. What do these terms mean? I have tried to search the website for it, but to no avail.
",['trade'],
Where i can get a list of most popular browsed servers domains by users of a specific country?,"
I'm pretty sure that some net index study like this was already carried out.
I would like to obtain a list of top 50-100 most frequently accessed locations by users of a specific country.
An example:
Let's say I'm interested in users coming from germany. Wich are the most popular browsing locations by users coming from ""germany""?
German users connect mostly on servers in this order:
1) us - usa servers (facebook, linkedin, google, ..) 65% of requests
2) de - germany servers (for all .de websites locations) 30% of requests
3) gb - uk servers 2% of requests
4) nl - netherlands servers 1% of requests
5) fr - france servers 0.5% of requests
6) it - italian servers 0.3% of requests
8) cn - china servers 0.01% of requests
9) jp - japan servers 0.004% of requests
10) ca - canada servers 0.004% of requests
11) kr - korea servers 0.001% of requests
...
...
...
49) ar - argentina servers 0.0005% of requests
50) br - brazil servers 0.00001% of requests

This way i know for example that generally users coming from Germany are not really interested in servers or domains present in Brazil
",['data-request'],
Search engine keyword relevance,"
I am looking for a dataset of search engine queries with qualitative assessments of the search results' relevancy.
I have such data from Kaggle in the case of The Home Depot website search queries, however I'm searching for comparable data from another source, so that I can understand the difference between portal-specific effects and portal-robust effects.
For instance, the data I have lists:

Relevance on a scale of 1 to 3, rated by a panel with given instructions
The search query
The top search result's title
The top search result's description
Miscellaneous session and search result contextual data 

",['search-engine'],
Text annotation tool dataset,"
I am looking for a dataset containing text annotation tools, with as many following fields as possible:

name of the tool
date of first release
date of last release
programming language
license
price
which natural language processing task(s) does the tool target
free-text description
university or company developing it
source of funding
research groups that used the tool
research articles that used the tool
natural language(s) that the tool uses for its interface

Examples of text annotation tool:

brat
gate

","['data-request', 'nlp']",
loading MIMIC III into SQL Server [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 7 years ago.







                        Improve this question
                    



I'd like to load the MIMIC III data into SQL Server because that's what I know best. The problem with the csv files is that some fields contain commas as part of the data. It would be far easier to work with a unique delimiter instead of trying to implement workarounds for comma data inside csv files. I've searched all of the MIMIC III csv files and the following characters are never used:
Ⅎ ❶ ① ↘
If the data could be extracted into flat files using a delimiter that never appears in the data, it would make it trivial to load the data into SQL Server. Using an alternate, well chosen delimiter character is a far more robust solution to the problem than continually implementing workarounds for csv files.
",['mimic-iii'],
What is the latest census statistics on US demographics,"
I am looking for sources about US demographics, when i started collecting data, i found that there are different statistics inside census data portal.what is the latest +to date+ statistics that I can use. 
I found this one.
https://www.census.gov/popest/data/state/asrh/2014/index.html
Can you share any page explaining time/process of collecting census data 
","['usa', 'us-census', 'demographics']",
ZCTA regions in census files,"
I am trying to analyze census files but I find it confusing to define regions of tracts or zipcodes. I noticed that the postal ZipCodes are messy as there are some overlapping {some zipcode regions are within others, as an example in new york there are some empires as zipcodes}.
A quick look on http://geocommons.com/search.html I could find a lot of options, but couldn't decide.
What I found: 

NYC Zip Code Tabulation Areas 
In this file, some regions are within others.
ZIP Code Tabulation Areas (ZCTAs)
It hold the same name as the previous one, but it's different
https://www.census.gov/geo/maps-data/data/cbf/cbf_zcta.html
My second question, Does census zipcode regions vary from a survey to another ? 

As an example, In this link I found two files. 
","['us-census', 'census']",
How many sample sentences are required to train a model in opennlp?,"
I need to create my own model in opennlp. I have to create my own dataset since I couldn't get the calendar events dataset. Can anyone tell how many sample sentences are required to train a model?
","['data-request', 'machine-learning', 'nlp']",
How to collect hand-writting data,"
I'm working on machine learning project that requires I collect hand-writing data of alphabets from an uncommon language (I'm 100% there is no available data out there). My question is how should I collect this data?
The approach I'm currently thinking of taking is asking about 20 people to write the letters (about 10 times for each letter) on a piece of paper and scanning that sheet, to have it in digital form. But what should I do next? Should I just vectorize the RGB value of each  pixel? Should I use an entirely different methodology instead?
What are the textbook approaches and best practices?
","['data-request', 'machine-learning', 'language', 'best-practice', 'research']","The first step is splitting the image into character arrays. To do that, check out the answers in this question: Separate image of text into component character images. In particular, the ImageMagick answer from 2015.(If you can determine how the input is given, then collect the characters as separate images.)To convert the image into a 2D array, you can use Python with the Image and Numpy libraries- see for example"
Physionet.org - Sepsis Data Files?,"
I am searching for ""Pre"" and ""Post"" Physiological Data Files from Patients that have Sepsis. They can be in just about any format such as Excel, CSV, etc. but contain a Time Stamp, Heart Rate, BP(s), Temperature, Respiratory Rate, etc.
","['data-request', 'medical', 'mimic-iii']",
Consumer Demographics for Individual Products,"
I am hoping to find a dataset of consumer demographics for individual products (e.g., age, gender, income, education level). 
For example, say 40% of people with an Iphone are women, 32% are between 24-34, and 20% make over $100,000 a year. Whereas maybe Android users are 45%  women, 28% between 24-34, and 25% make over $100,000 a year (arbitrary numbers). 
Or for example, people that buy Snickers Bars are 12% women, 78% between 24-34, and 11% make over $100,000 a year. 
I have been able to find demographic information for website traffic using Quantcast but I would like to augment that information with demographic information for individual consumer products/brands.  
I suspect that this data exsists but I'm not sure if there's an open dataset available for it. 
More directly, I would like to use this data to infer a user's demographic information from something like the twitter handles they follow or the products they Like on Facebook. 
","['data-request', 'business', 'products', 'demographics', 'income']",
Vaccination policies,"
I am looking for a data set containing vaccination policies by country, and if possible by year. Ideally, the vaccination policy would be stored in some machine-readable format.
","['data-request', 'medical', 'global']","The WHO has some Excel tables that indicate vaccination policy for individual countries and individual vaccinations.http://www.who.int/immunization/monitoring_surveillance/data/en/6. Immunization schedule. Data are available for:6.1 Reported immunization schedules by vaccine in html and in excel6.2 Year of introduction of selected vaccines database in excel6.3 Immunization schedules by disease covered by antigens within age range 
  in html6.4 Immunization provided at school in excel6.5 Slides on introduction status of selected vaccinesThe the 2nd sheet in the Excel file for point 6.1 above has the data you are looking for."
"Nuclide database - A, Z, BE, half-life, etc","
I'm developing a semi-realistic idle game based around the fusion and fission of elements to generate energy or for sale. For this, I need a data sheet for the Table of Nuclides (http://www.nndc.bnl.gov/nudat2/) which includes, for each nuclide:

Atomic number (Z)
Atomic mass (A)
Half-life
Decay method (alpha, beta, etc.)
Binding energy (either straight, per nucleon, or I can use the liquid drop equation to approximate it)

I've checked the NNDC website, but I couldn't find a configurable data download. The closest is the Nuclear Wallet Cards, but it just doesn't have the fields I need and it has to be multiple downloads. 
",['data-request'],"You're looking for the NuBase table here, but unfortunately that file doesn't have a header. The PDF of the journal article (linked on the same page) has the same data with more explanation.If you grabbed this code before 18 July 2016 then the mass excess values are wrong. They're correct now.Depending on one's level of experience with nuclear data, that table might be a bit hard to handle by itself (plus the entries are fixed width instead of delimited). I wrote a Python 2.7 script which takes the nubase.mas12 file at the link and writes data for ground state nuclei, whitespace delimited, into the file nubase.edit. Columns areYou'll have to parse the decay modes yourself. Two caveats: 1) This table includes both measured and projected mass values (binding energies), and my script doesn't distinguish between the two. 2) The half lives and uncertainties in my output table may only be upper or lower limits, not the values themselves. The original table is specific."
Lake Bathymetry Open Data,"
I would like to know if anyone knows a good open source where I can get Lake bathymetry raster. I need to extract depth values from it.
","['data-request', 'data.gov', 'environment']",
Database world cities with their names in all languages of the world,"
I'm looking for a database of cities in the world with their names in all languages of the world. Where it is possible to download?
","['data-request', 'language', 'city']",
How to download issues from ASF Jira,"
I am currently working with unstructured data, planning to mine the unstructured data present in bug reports.  
For this I tried to download the issues from the ASF (Apache Software Foundation) Jira for the project PIG.  
The issue tracker allows me to export issues in XML, Excel and Word formats, but I need JSON. The issue tracker throws an 404 forbidden error when I try to export in JSON format.  
How can I download the JSON?

Must I use the REST API?  
Does asf jira support a REST API?  
How to formulate a curl command which uses REST and JQL to accomplish the task?

I tried the following and got an error. What did I miss?

curl -D -u $username:$password -X GET -H ""Content-Type: application/json"" ""https://issues.apache.org/jira/issues/search?jql=project=%3DPIzG""

I am trying to download all the issues of the project PIG. 
","['data-request', 'api', 'data-format']",
College Scorecard API call returns all data in .json but only two fields in .csv,"
I'm trying to pull debt data from College Scorecard for Texas institutions using the following call: 
https://api.data.gov/ed/collegescorecard/v1/schools.csv?school.state_fips=48&_page=0&_fields=ope6_id,school.name,2011.aid.loan_principal,2011.aid.median_debt.completers.overall&api_key=xxxx
I get no errors and all available data in .json, but as soon as I switch to .csv the resulting spreadsheet contains only ope6_id and school.name.
I'd welcome any advice on troubleshooting the issue or converting the results from .json into something easier to work with for a novice.
Thanks!
","['collegescorecard', 'csv', 'json']",
Dataset from Nasa website,"
I am currently working on my graduation project ("" failure prediction models in FoF"") and I will be using RapidMiner as the tool, I need dataset to run the tool on , and I found a suitable description in the Nasa website https://data.nasa.gov/external-dataset?datasetId=dc5d-zf5v However I do not know how to access the data itself in form of CSV file in order to start working on it, I have been recommended to using API but I do not know how it exactly work 
",['data-request'],
Looking for admitting SAPS score for first hospitalization of patients in MIMICIII [duplicate],"







This question already has answers here:
                                
                            




MIMIC-III severity score

                                (2 answers)
                            

Closed 7 years ago.



There is a table in MIMICII named ""MIMIC2V26.ICUSTAY_DETAIL"" and there is a field named ""SAPSI_FIRST"" inside the table. It seems that this field contains SAPS score for the first hospitalization of patients in MIMICII.
Based on the fact that there were some patients in MIMICII who did not have any SAPS score in their first hospitalization. So:
How could I find recorded SAPS score for the first hospitalization of patients in MIMICIII v1.3?

As I understood, severity scores (I mean SAPS) is not a recorded distinct data in MIMICIII and it can be calculated based on other parameters found in MIMICIII(Vital signs, etc,). So, there is a SAPS score available for all patients ICU stay in MIMICIII. However, it seems that in MIMICII v2.6, there were some patients that did not have any recorded or calculated SAPS score at least on their first admission. Am I right? If yes, how could we recognise patients that did not have SAPS score on their first admission? 
I am asking cause that I am going to reproduce a paper result but with new database version. In the paper, authors filtered out the patients that had recorded SAPS score on their first admission. So that I am looking for the same records but in the MIMICIII database. 
I appreciate it if someone guides me to find such records but in the new database version.
Thanks a lot, 
",['mimic-iii'],Code for severity scores and other related clinical concepts can be found in the mimic-code repository: https://github.com/MIT-LCP/mimic-code
Length (Belgian) railway tracks,"
Where can I find the length of the individual railway tracks in Belgium?
If you happen to know them for another country, please post them. It might interest someone else.
","['data-request', 'geospatial', 'europe', 'public-transport']",
Where can I get annotated data set for training date and time NER in opennlp?,"
I need to build a model to extract the calendar event information from text format. The model should be able to detect the data and time in any format. Is there any annotated data set for data and time finder in all possible formats?
","['data-request', 'machine-learning', 'nlp']",
data set of family trees in GEDCOM format?,"
Are there any GEDCOM files of family trees freely available? 
It should be of real persons, not artificial data. 
The genealogy of famous people or very big family trees that go back in history would be especially interesting. 
",['data-request'],"There is an option to download GEDCOM family trees on the WikiTree genealogy website. No member can request more than six files per day. Repeatedly requesting six files per day is also prohibited. I've just tested it with the family tree of Elvis Presly (WikiTree ID Presley-155), it took a while to compile it and I was informed by email when the file was ready for download. It looks quite extensive (the GEDCOM file has more than 35000 lines). I couldn't find any license information."
Wikidata item add form template,"
Is it possible in wikidata to make a template form from which wikidata item is created? If this is not yet supported, what would be simplest way to make (program) such implementation integrated into personal wikidata instance.
I'm looking for something similar as Semantic forms in semantic media wiki, but for wikidata.
","['programming', 'wikidata']",
Where can I get calendar events dataset in text format?,"
I need to create a model in opennlp for identifying event information in text. I need a calendar events dataset for training this model. Can someone suggest any available open source dataset for getting calendar events?
I need sample sentences which contains calendar events in text description. For example, The IEEE conference on emerging trends and technology in communication begins from 5th Mar and continues till 10th Mar 2016 in NIT campus at Trichy.
","['data-request', 'machine-learning', 'nlp']",
"World city database (with longitude, latitude) and population per year","
I'm building a visualisation with cities' population around the globe for a website. I found the MaxMind free database that includes most cities around the globe with coordinates and population, which is awesome. 
What I'd like to do is have something like a timeline, to show which cities have increased their population in the last years (even from 2005-ish to 2012 would be great).
To do so I would need the same database, but of previous years.
I looked at the Maxmind site, but couldn't find any older versions of their database.
Do you know a place where I can find such a database?
","['data-request', 'geospatial', 'demographics']","The United Nation Statistics Division publishes population totals and by demographics per country on an annual basis. This is called the UN Demographic Yearbook. It is normally in PDF format, but there are various areas on the unstats.un.org site that you can download EXCEL and CSV files.A good start is here. This has downloadable tables between 2007 and present.http://unstats.un.org/unsd/demographic/products/dyb/dybcensusdata.htm"
Looking for open dataset containing vacation / annual leave data for counties of the European Union?,"
I am looking for a preferably open dataset that contains information regarding the dates that that employees took days off their annual leave for the countries of the EU. Is there any similar information available for other countries anyone is aware of?
To avoid misunderstanding: I'm not looking for public holiday dates themselves.
","['data-request', 'economics', 'europe']",
Data on press conferences from English-speaking press conferences,"
I looking for open data on press conferences from English-speaking football/soccer leagues, preferably from the EPL, Champions League, or MLS but any English-speaking league would do. I need transcripts of the press conferences and game data to go with it.
","['data-request', 'sports', 'nlp', 'english']",
Micro data on parental education,"
I am looking for a dataset that contains data about mother's education and father's education for adults (data just for kids I've found to be not sufficient). I am writing my Thesis about effects of the parental education on an individual's education and how it varies, so I would love to has the data for various low and middle-income countries. Do you know, where can I find it?
P.S. DHS program should contain those variables in older releases(  manual  - see page 111), but I found only data for Mother's education there (Household members recode).
",['data-request'],"i believe all of these microdata sets have education of both parents and children, although some of them are limited to parent-child while they are co-habiting.international:  http://www.asdfree.com/search/label/program%20for%20international%20student%20assessment%20%28pisa%29has education level of parents, for example HISCED on pdf page 244 https://pisa2012.acer.edu.au/downloads/M_stu_codebook.pdf#page=244http://www.asdfree.com/search/label/programme%20for%20the%20international%20assessment%20of%20adult%20competencies%20%28piaac%29also has it, for example see pdf page 1492,
www.oecd.org/site/piaac/codebook_synthetic.pdf#page=1492within the united states:http://www.asdfree.com/search/label/current%20population%20survey%20%28cps%29http://www.asdfree.com/search/label/survey%20of%20income%20and%20program%20participation%20%28sipp%29http://www.asdfree.com/search/label/national%20longitudinal%20study%20of%20adolescent%20to%20adult%20health%20%28addhealth%29http://www.asdfree.com/search/label/national%20longitudinal%20surveys%20%28nls%29http://www.asdfree.com/search/label/youth%20risk%20behavior%20surveillance%20system%20%28yrbss%29http://www.asdfree.com/search/label/panel%20study%20of%20income%20dynamics%20%28psid%29"
MIMIC-III linking d_icd table with diagnosis_icd,"
I wanted to map the DIAGNOSES_ICD codes and PROCEDURES_ICD codes to D_DIAGNOSES_ICD and D_PROCEDURES_ICD code but I get a Relationship doesn't exist error. Is there a way around it?
",['mimic-iii'],
Datasets based on casual conversations for chatterbots,"
I am building a chatterbot that can answer questions related to tennis. I wish to know if there any any available datasets than can answer casual questions like ""How are you"", ""How is the weather today"" so on and so forth. 
Edit 1: I am using Python and MongoDb
","['data-request', 'nlp', 'python', 'ai']",
"Number applications to the French Government Defense's PhD grant (Direction Générale de l'Armement, in short DGA)","
I am looking for the number applications to the French Government Defense (Direction Générale de l'Armement, in short DGA)'s PhD grant (a.k.a. ""Bourse DGA"") each year. I know that the number of accepted candidates is around 130 (source 1, source 2), but I wonder how many applications there are, and how this number of applications has changed throughout the years.
","['data-request', 'research', 'france']",
Getting the complete list of AEs x drug with openFDA,"
Can one get ALL AEs per single drug instead of the most frequent ones? Example Ibrutinib 2,921 reports; AEs reported 1,696 in 10 categories. How can I get the remaining list of less frequent events up to the last one?
",['openfda'],
Database of Vehicles/License Plates,"
I'm in research of a databases of vehicles with her license plates because I have a project of recognition of license plates but I don't have any idea where I can find this database
",['data-request'],
Downloadable Projected rainfall estimates for Ghana for the year 2016,"
From which website can I download rainfall estimated data for use in ArcGIS?
","['data-request', 'geospatial']",
US Senate/Congress Contact Info API,"
Is there an API to get the email addresses or other contact info of US senators and representatives by postal code? Or, is there some way of getting the email addresses of all US senators and representatives linked to postal codes (perhaps in JSON of CSV format)?
Also, which states' representatives have publicly disclosed email addresses? Are there any APIs for those as well?
","['usa', 'government', 'api']",
USCIS processing times history,"
The current USCIS processing times are on available on this page. Is there any dataset containing the historical USCIS processing times?
","['data-request', 'usa']",
Does the scorecard have data to determine revenues for the purpose of the 90/10 rule?,"
Are there any variables in the scorecard data set that would allow me to get at the ratio of for-profit institution's revenues that come from federal student aid sources?  Specifically, I'm trying to find 90/10 compliance ratios over time.  Does IPEDS have more info not included in the scorecard that would be more helpful?
",['collegescorecard'],
Free Archive of Africa weather data,"
Is there any archive for Africa weather station data? What i know exists is the GHCN database and other gridded sources. 
","['data-request', 'weather', 'africa']",
"What is up with the ""no adjusted gross income"" data in the IRS SOI?","
This is a rather specific question, but I'm wondering if others who have used IRS data have encountered this oddity.  I'm looking at the IRS Statistics of Income for individuals here, specifically the most recent Publication 1304 Table 1.2.
This table has the data broken down by the level of adjusted gross income.  The first such group is listed as ""No adjusted gross income"".  Under the ""All returns"" section, the column for ""Total income tax"" shows 177,444; since it says money amounts are in thousands, this would be $177,444,000.  But the ""number of returns"" column shows only 6231 returns.  This comes out to an average of more than $28,000 in tax paid per return, which is far more than the corresponding numbers for other income levels until you get to $100k+ AGI.
Why does this IRS data seem to show that people with zero income were paying an average of $28,000 in taxes?  Am I missing something about how to interpret these values?
","['taxes', 'irs']",
Rate of nutrient decay in fruit/vegetable juice,"
I am looking for a dataset containing rate of nutrient decay in fruit/vegetable juice. It will probably depends how the juice is stored. The juice was made using a personal juicer.
The goal is to make an educated decision about whether to use the juicer as needed (maximizing nutrient content but increasing cleanup effort) or to produce fruit/vegetable juice 6/12/18 hrs ahead of time (reducing cleanup effort but perhaps reducing nutrient content).
(The question was asked in a slightly different form on Seasoned Advice Stack Exchange by sibbaldiopsis but was closed there.)
","['data-request', 'medical', 'food']",
Searching data for habits,"
I am searching for open datasets which has tags of habits.
A habit could be : eating, drinking, everyday activities, anything.
The type of data could be text, no images are required. 
This dataset will be used for machine learning.
Can anyone give any input?
","['data-request', 'machine-learning', 'uses-of-open-data']",
Convenient way to get time of surgery in MIMIC-III,"
In the MIMIC-III database there is a PROCEDURES_ICD that gives ICD9 codes for procedures such as surgeries that were performed on patients. The corresponding description of these codes are nice and detailed, but in the table there is no date time saying when these procedures were performed.
On the other hand, the CPTEVENTS table gives less detailed surgery descriptions, but gives the exact date time the surgery was performed. 
Has anyone tried coalescing these two sources to get detailed procedure information AND datetime information? Perhaps there is a better table I should look at?
",['mimic-iii'],
Is there a difference between open data and public data?,"
I was wondering if there were differences between ""open data"" and ""public data""? In this SE group, the two terms seem to be used interchangeably, but I feel that they are not interchangeable.
This excellent page gives a very good definition of open data.
I would contend that public data set, are data in the public domain, but restricted by the data owner's usage and distribution choices, which may bear no resemblance to the . So one set of public data may have a very different usage licensing or distribution restrictions.
Do others have a view on this?
If they are deemed to be different, does Open Data SE also include Public Data?
",['licensing'],
Historical events calendar database,"
I'm looking for a database that contains information about events, specifically in NYC. Categories include these:
 ""Athletic"",
 ""Business & Finance"",
 ""City Government Office"",
 ""Cultural"",
 ""Education"",
 ""Environment"",
 ""Featured"",
 ""Free"",
 ""General Events"",
 ""Health & Public Safety"",
 ""Hearings and Meetings"",
 ""Holidays"",
 ""Kids and Family "",
 ""Parks & Recreation"",
 ""Street and Neighborhood"",
 ""Tours"",
 ""Volunteer""

I've found this one but no matter my query it just returns data starting from the current date. I need historical data, like from 2015.
","['data-request', 'calendar']",
FCC ASR - Strucht Incorrect?,"
The strucht on the FCC's GIS tower information seems way off? Most of the cell towers are only 50-60' when they are clearly over 100' when you inspect them. 
What is the StucHt information based on? Do I need to base it on some calculation like add 100' or something?
","['geospatial', 'data.gov', 'fcc']",
Where can I get data for the popularity of a book?,"
I need to collect some data to find the popularity of books.
The first thing that came in my mind was to find the number of sales of the books, but I soon found that the authors don't easily tell their book's total sales so my data would be unreliable and hard to find.
Do you know where I can get reliable data for the popularity of books?
","['data-request', 'books']","Goodreads has an API: https://www.goodreads.com/apiand specifically the Review ProgramReview Syndication: Goodreads has 10 million reviews across 700,000 titles - one of the largest and deepest collection of quality book reviews on the internet. Our API makes it easy to display these reviews on your website. Reviews WidgetReviews API method (must be whitelisted)To get data on popularity you could find highly-rated books, or books with many total ratings."
How is the repayment rate for College Scorecard calculated?,"
How is the repayment rate for College Scorecard calculated?
Specifically: 

How does the Scorecard repayment rate methodology incorporate loan consolidation? For example, what if a student receives loans from different institutions at different times and then consolidates those loans?
How does the Scorecard repayment rate methodology incorporate loan
defaults? For example, if a borrower defaults and then pays off the
defaulted loan in full, is that borrower included in the numerator?
What if a loan goes into default, is then consolidated, and then
paid in full?
How does the Scorecard repayment rate methodology calculate
exclusions for forbearance, deferment, and discharge for death and
disability? For example, what if a student goes into repayment for
school A, then borrows at school B (with in-school deferment), and
then goes into repayment for school B in less than three years? Is
all the interest accrued for school A is still factored into the
three-year repayment rate for school A?
What constitutes a default for repayment? Is the NSLDS “DF” code the
only code that is considered a default in measuring repayment?

","['usa', 'collegescorecard']",
What is meant by rolling 2-year averages in College Scorecard?,"
What is meant by rolling 2-year averages in College Scorecard?Is this simply including two cohorts in a single calculation?  
",['collegescorecard'],
Historical Wave and Current data,"
I am looking for an archive with historical predictions as well as actual measured currents, wind and waves for the baltic sea.
http://forecast.io covers other data points that I need, but wave and currents are missing.
OAA National Oceangraphic Data Center seems to have the data I need, but not for the Baltics :-/ [0].
I would appreciate any hint for data archives. Thanks.
[0] http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS?service=SOS&request=GetObservation&version=1.0.0&observedProperty=currents&offering=urn:ioos:network:NOAA.NOS.CO-OPS:All&procedure=urn:ioos:network:NOAA.NOS.CO-OPS:CurrentsActive&featureOfInterest=BBOX:9,54,12,57&responseFormat=text%2Fcsv
","['data-request', 'weather', 'historical']",
How can I find out how many socks strideline and happysocks sell a day?,"
I am an MBA student looking for information for my final course.  Is there a way to find out how many socks strideline.com and happysocks.com sell per day?
","['data-request', 'usa']",
How do I access ten years of craigslist archives?,"
I have a craigslist archive from which I am trying to extract details and prices about products. I want to extend my search back to the year 2005, but the tenth page tells me ""There is nothing here."" The ninth page is from April 3 of 2015, so relatively recent. How can I access craigslist listings from further back than 2015?
","['data-request', 'prices']",
2D Digital Subraction Angiography,"
I'm searching the web for an open dataset/database with 2-dimensional medical x-ray images, I can use to perform a DSA for quite a while now. Until now I found a good example on http://www.isi.uu.nl/Gallery/DSA/.
But I can not find any images that are suitable to perform a DSA. Does anybody have a movie during an intervention? The best possible dataset would contain an intervention of a hand or other extremities in 2D. Maybe in a high resolution with a lot of frames? I need to have the mask image and the live image.
I do not need to have any copyright. I just want to play around. And publish (if anybody wants it) the source code. But won't republish the images if there is any restriction.
","['data-request', 'medical', 'images']",
Medical text corpus,"
This should be a simple question to many in the area, but for the life of me I can't find a solution by myself.
I need a corpus of medical text for the purposes of training a spell checker which will be used on... medical text. For this I need a large amount of text that has few (or ideally no) errors in it. The abstracts from Medline articles would be a good bet.
However, while I can many solutions that are grossly more complicated than I require (such as treebank) designed for tree-building or POS tasks, and would require significant work to remove annotation and compile into a single .txt, surely such a resource already exists? 
Alternatively I could just visit a hundred or so Medline articles and start copy-pasting their abstract details I suppose... 
","['data-request', 'medical', 'machine-learning', 'nlp']",
Historical flight path data,"
Im looking for open data on historical US flight paths. I know the FAA has a real-time data stream that gives the flight, latitude, longitude, and altitude of planes. I want this data for the past 10 years. Anyone know if this is available?
","['data-request', 'government']",
Fruit ripening dataset,"
I am looking for a dataset containing how fast each fruit ripens, given different conditions such as: 

temperature
humidity
other fruits located nearby

",['data-request'],
Archive of FedWire participants,"
I'm looking for an archive of institutions that have participated in the Fed's FedWire service -- preferably back to before 2004.
The Fed hosts an up-to-date participants list, but I haven't been able to find an archive of it. Closest thing I've found is this Github repo that's been archiving a similar list of FedACH institutions for the past couple years.
Anyone got any ideas? I really hope this publicly available time-series hasn't just vanished from history.
","['data-request', 'usa', 'finance', 'bank']",
Looking for equivalence of MIMIC-II v2.6 dataset in MIMIC-III v1.3,"
There is a table in the MIMIC-II v2.6 database named ""mimic2v26.d_codeditems"" which includes a category named ""type"". One of the specified types is ""procedure"". I am looking for the equivalent data in MIMIC-III v1.3.
I am not sure but I think ""mimiciii.d_icd_procedures"" contains the procedure data that I am looking for. Could you please help me to identify the equivalence in MIMIC-III?
Thanks,
",['mimic-iii'],"You're correct - the category type ""PROCEDURE"" in the mimic2v26.d_codeditems table refers to ICD-9 procedure codes. These have been more explicitly delineated in MIMIC-III: the equivalent definitions are in D_ICD_PROCEDURES, and the actual codes for patients are in PROCEDURES_ICD."
Is a dataset of Paint-like paintings available?,"
In ML-KA, a machine learning group in Karlsruhe, we recently had a discussion about features learned by CNNs. It is often said that they learn general features in the first layers which are usable for arbitrary vision tasks. One idea to check that was to apply them to paint-like paintings. By ""Paint-like"" I mean a specific style of image which is often created by children / non-professionals. Here is an example:

Is there a big repository of paint-like images available? (Preferably with labels / descriptions / tags / categories.)
","['data-request', 'images']",
Looking for an open API for to get tracking information from an EMB code,"
This might be a lost cause, but been searching for a couple of days now.
I'm looking for a way to track an item of food from it's origin to the supermarket. I have the EMB code for an item, e.g. UK 1715 EC
Any suggestions would be much appreciated!
","['data-request', 'food']",
Recommendation letter dataset,"
I am looking for a dataset containing academic recommendation letters, written in English, with as many following fields as possible: 

content of the letter
date of the letter
purpose of the letter (e.g., faculty application, visa application, internship application, etc.)
relationship between recommendee and recommender
demographics on recommendee and recommender

","['data-request', 'nlp']",
What is the percentage of degrees at each school earned through an exclusively distance-education program?,"
I have been trying to get at this question by looking at the percentage of degrees granted in each subject area and then examining whether the degrees offered in that subject area are offered online. The problem, however, is that the available data does not indicate what percentage of the degrees awarded are associate's degrees and what percentage are bachelor's degrees. Therefore, I am unable to determine what total percentage of degrees are earned through an exclusively distance-education program in each subject area. Does anyone have any advice on this? Thanks so much! 
",['collegescorecard'],
getIFPPlanQuotes - what is InsuranceEffectiveDate?,"
Why are my results different when I change the InsuranceEffectiveDate field? For example in the below request I changed the InsuranceEffectiveDate from 2015-01-01 to 2016-03-01 and received 50 less plans. I expected the field to represent when a insurance can start to insure you, which should lead to a increase of plans for future dates, but I saw the opposite result. How does a effective date make sense to be in the past?
<?xml version=""1.0"" encoding=""UTF-8""?>
<p:PlanQuoteRequest xmlns:p=""http://hios.cms.org/api"" xmlns:p1=""http://hios.cms.org/api-types"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://hios.cms.org/api hios-api-11.0.xsd "">
  <p:Enrollees>
    <p1:DateOfBirth>1990-01-01</p1:DateOfBirth>
    <p1:Gender>Male</p1:Gender>
    <p1:TobaccoLastUsedMonths>0</p1:TobaccoLastUsedMonths>
    <p1:Relation>SELF</p1:Relation>
    <p1:InHouseholdIndicator>true</p1:InHouseholdIndicator>
  </p:Enrollees>
  <p:Location>
    <p1:ZipCode>10075</p1:ZipCode>
    <p1:County>
      <p1:FipsCode>36061</p1:FipsCode>
      <p1:CountyName>NEW YORK</p1:CountyName>
      <p1:StateCode>NY</p1:StateCode>
    </p1:County>
  </p:Location>
  <p:InsuranceEffectiveDate>2015-01-01</p:InsuranceEffectiveDate>
  <p:Market>Individual</p:Market>
  <p:IsFilterAnalysisRequiredIndicator>false</p:IsFilterAnalysisRequiredIndicator>
  <p:PaginationInformation>
    <p1:PageNumber>1</p1:PageNumber>
    <p1:PageSize>500</p1:PageSize>
  </p:PaginationInformation>
  <p:SortOrder>
    <p1:SortField>BASE RATE</p1:SortField>
    <p1:SortDirection>ASC</p1:SortDirection>
  </p:SortOrder>
</p:PlanQuoteRequest>

","['medical', 'healthcare-finder-api']",
Is there an API for user-defined song tags?,"
I am interested in collecting many user-defined tags for songs (primarily popular songs). These tags need to be descriptive of the song, but not standard metadata (like artist or album), because that information is very easy to obtain.
",['music'],"Last.fm lets certain users add/create tags for songs; not 100% sure who is a ""certain user"", but I'm assuming that it is related to longevity/activity on the site.
Here's a list of song tags that are included in the Last.fm dataset contribution submitted to the 1,000,000 song dataset:
http://labrosa.ee.columbia.edu/millionsong/sites/default/files/lastfm/lastfm_unique_tags.txt
The Last.fm Dataset - Million Song Dataset
http://labrosa.ee.columbia.edu/millionsong/lastfm
And of course Last.fm's API:
http://www.last.fm/api
Topped off by the track.getTags method call:
http://www.last.fm/api/show/track.getTags"
Employee Churn dataset?,"
I am looking for a dataset for Employee churn/Labor Turnover prediction. I looked around but couldn't find any relevant dataset to download. Following are some of the features I am looking in the dataset (Its not mandatory feature set but anything on this line will be good):
Age
Degree
Salary
Promotion in last year?
score of employee
Tenure
Performance rating  

Can anyone provide me link where I can download such dataset?
",['data-request'],
Synchronize with the openFDA S3 bucket,"
When i'm try to synchronize my s3 bucket with openFDA S3 bucket ( aws s3 sync s3://my-bucket s3://download.open.fda.gov/), error occurce: 

""A client error (AccessDenied) occurred when calling the ListObjects
  operation: Access Denied""

Can you tell me, what am I doing wrong?
",['openfda'],"It took quite a while to figure this out myself, so I thought I'd share!The openFDA bucket is Requestor Pays, so you have to enable yourself -- in your amazon account -- to pay for requests to that bucket.  To do so, create a policy document on a group that you are in.Steps:
1. Create an IAM group called openFDA.
2. Create a policy called openFDABucketAccess
3. Attach the policy to the group.
4. Add your id to the group.
5. Test it using policy simulator.  Try to simulate a getObject request on arn:aws:s3:::download.open.fda.gov.  It should work!In the following policy, the only thing you should change is 'my-open-fda-bucket' to your real bucket name that you plan to sync to.
{
    ""Version"": ""2016-03-14"",
    ""Statement"": [
        {
            ""Effect"": ""Allow"",
            ""Action"": [
                ""s3:ListBucket"",
                ""s3:GetBucketLocation"",
                ""s3:Get*"",
                ""s3:List*""
            ],
            ""Resource"": ""arn:aws:s3:::my-open-fda-bucket""
        },
        {
            ""Effect"": ""Allow"",
            ""Action"": [
                ""s3:ListBucket"",
                ""s3:GetBucketLocation"",
                ""s3:Get*"",
                ""s3:List*""
            ],
            ""Resource"": ""arn:aws:s3:::download.open.fda.gov""
        },
        {
            ""Effect"": ""Allow"",
            ""Action"": [
                ""s3:PutObject"",
                ""s3:GetObject"",
                ""s3:DeleteObject"",
                ""s3:ListObject"",
                ""s3:Get*"",
                ""s3:List*""
            ],
            ""Resource"": ""arn:aws:s3:::my-open-fda-bucket/*""
        }
    ]
}
Now that you have the permission (and you will pay to get files from that bucket), you want to sync by using the following aws s3 command:
aws s3 sync s3://download.open.fda.gov s3://my-open-fda-bucket --source-region us-east-1 --region [my-open-fda-bucket-region]The last example on this page: http://docs.aws.amazon.com/cli/latest/reference/s3/sync.html shows you how to sync files between two buckets in different regions.
--region is the target region, while --source-region is the source region."
Cyber-attacks with demand dataset,"
I am looking for a dataset containing a list of cyber-attacks were attackers made a demand (e.g., a ransom), with as many following fields as possible: 

date of attack
duration of attack
date of demand
type of demand (if ransom, the amount)
target
information on the executers
whether the demand was met 

","['data-request', 'finance', 'internet', 'computing']",
Looking for open source funding data of South American startups,"
Looking for open source data sets for funding details of South American startups.
Would be more interested in that of the messaging apps startups, but a general dataset of the funding details of all startups would also do.
[Any format would do]
","['data-request', 'economics', 'latin-america']",
"Is there an open database of elementary, middle, and high schools with special education departments in the United States?","
Is there an open database of elementary, middle, and high schools with special education departments in the United States?
I'm hopping to get names and addresses and if possible number of children enrolled.
","['data-request', 'usa', 'education']",
Looking for dataset of pharmacy Locations in Chicago area,"
I'm looking for a dataset of pharmacy Locations in Chicago area. The city of Chicago said they do not have this dataset, I'm wondering where I can find it.
","['data-request', 'geospatial', 'data.gov', 'medical', 'uses-of-open-data']",
Sentiment classification from Smiles-data need,"
I am looking for data that are classified according to the smiles, for example :( is negative sentiment (labeled may be -1, :) is positive sentiment (labeled may be 1). I know twitter has such data set, but I am not sure where to find it actually. If the data set looks like this,
label     text
-1       I am sad :(
 0       this is a mango
 1       I am so happy today :)

Suggesting pls.
","['data-request', 'sentiment-analysis']",
All the cities and their state codes,"
I need for my database a list of all the cites, countries and states in the world. 
If I'm looking for Albany in this list, I need it to be like this:
USA, NY, Albany
Can anyone help me?
",['data-request'],
Publicly Available UK Datasets,"
With no disrespect to our fellow data scientists over ""the pond"", one major problem from the rest of the world's point of view with questions like Publicly Available Datasets is the American focus of the answers. They are great answers, and great sources of data, but lack a lot relevance to others not in the US due to geographic, demographic, social or other factors.
This question I have is particularly focused on public data sites for the UK. 
Are there sites that have a large variety of data collected? I suspect at the moment the UK isn't as progressive as the USA in terms of meta-data repositories, so I would be happy for sites that are quite rich in content and interesting in terms of their data science or analytical possibilities!
","['uk', 'data-portal']","Try https://geovation.uk/data-sources/ for a pretty comprehensive list of links to sources with crime data, retail data, consumer data, transport data and government data.You can also refer to this list to fill in the gaps on English Heritage data, environment data and Ordnance Survey data.I hope this helps!"
Percentage of patients worldwide who have electronic medical records managed by a software company founded in a given country,"
I am looking for a dataset containing:

Percentage of patients worldwide who have electronic medical records managed by a software company founded in a given country.

Or even better (since more fine-grained):

Percentage of patients worldwide who have electronic medical records managed by a given software company.

Example: Epic Systems software hold medical records of 54% of patients in the U.S. and 2.5% of patients worldwide.
Ideally:

evolution of these percentages throughout the year

","['data-request', 'medical']",
Discrepancies between the api url and the original one on collegescorecard?,"
There seem to be some discrepancies (Or maybe I did something wrong) between the data retrieved from the api url: https://api.data.gov/ed/collegescorecard/v1/schools and from calling the original url: https://collegescorecard.ed.gov on a web browser. 
For example, I tried to do a search via java using the api url for schools with the zip code 13902 and radius 2 miles and I got 2 results. But if you do the same thing on a web browser using the original url, it returns nothing. Can someone explain this to me? Thanks a lot!
","['data-request', 'api', 'collegescorecard']","This could be due to the fact that some of the institutions for which data are provided for in the API, do not appear in the consumer website.  The consumer website includes predominantly associate’s and bachelor’s awarding schools (PREDDEG=2 , PREDDEG=3). In addition, the Department recently added institutions to the consumer site such that institutions that predominantly award certificates (PREDDEG=1) are included IF the highest degree is at least an Associate's (HIGHDEG>=2 ) AND the institution offers an associate's or bachelor's degree (CIPxxASSOC>0 OR CIPxxBACHL>0).  All other institutions are not included on the consumer website."
Contractors licence data,"
There is any open data source for contractors licence in the U.S.? 
I'm interested in electricians, architects, interior designers and alike. 
","['data-request', 'usa']",
Bulk download Sci-Hub papers,"
I wonder whether it is possible to bulk download all papers stored in Sci-Hub.

I am aware of the questions:

Is there a more user-friendly way to download multiple articles from arXiv?
Bulk download of arXiv (or other publication data set) with metadata AND citations

but they focus on arXiv.
","['data-request', 'research']","Sci-Hub is a paywall-bypassing website that uses ""shared"" user credentials to provide PDF or HTML scientific papers. The website itself doesn't store any papers. (There are interesting comments on your same question on another site.)But LibGen (via wayback machine) is said to archive each PDF retrieved by Sci-Hub.http://gen.lib.rus.ec has a downloads page - (click the tab to show more options)Torrent - books and text books - http://libgen.io/repository_torrent/Torrent - scientific papers - http://gen.lib.rus.ec/scimag/repository_torrent/Usenet - http://libgen.io/repository_nzb/DB dump - http://gen.lib.rus.ec/dbdumps/"
Where to get historical 1 minute forex data?,"
i've been searching for ways to obtain historical 1 minute forex data, does anyone knows where i can find the most realiable data?. I've found histdata.com, but i can't check how reliable it is, does anyone knows if it's reliable?
","['data-request', 'finance']",
Evolution of fruits throughout the history,"
I am looking for a dataset containing information regarding the evolution of each fruit throughout the history. Either images of fruits, or textual description of the fruit, or some more structured data, accompanied with some approximative date.
Example of image descriptions for watermelon:
1645–72:

1824:

Current:

Example of structured data describing watermelon:

","['data-request', 'images', 'food']",
Big Data and machine learning to Predictive analytics,"
This is the first time I post a question here. I am a newbie researcher and want to write a report about Big Data influence on machine learning to improve predictive analytics. I looked through Google for any relevant study shed the light on this subject, but what I found only briefed articles that are not suited to be good resource. Is there any resource I can use through the web as I looked through different libraries and didn't find any good resources relevant? Any help would be much appreciated.
","['machine-learning', 'big-data']",
What are the limitations of the Wikidata data model?,"
Wikidata data model is as follows:

The following diagram is a more summarized version of it (source):

All terms are defined here.
I wonder what the limitations Wikidata data model are.
","['data-format', 'wikidata']",
Data for geographical advantage of a country,"
I was wondering if anyone came across an index for geographical advantage of a country with regards to warfare. This index could be based on, for example, Paul R. Hensel's (1997) paper ""Theory and Evidence on Geography and Conflict"". It could comprise of elements of, for example, geographical characteristics (e.g. island, peninsula, continental) or how geographically central a capital is etc. I could try to make such an index myself, but I don't want to reinvent the wheel. if there is already anything out there.
",['state'],
People names by country [duplicate],"







This question already has answers here:
                                
                            




Multinational list of popular first names and surnames?

                                (16 answers)
                            

Closed 7 years ago.



I'm building an application where I will need to sort a persons nationality according to his/her name, is there any such dataset for this somewhere?
It would be great to have something like:
Name          Country
Pierre        France
Carlos        Spain
Carlo         Italy
.
.
.
I know names are very subjective but an approximation can be made, even if only from the European Union or China would be good.
","['data-request', 'europe', 'names']",
Breast conserving surgery in the US,"
I'm looking for data on breast-conserving surgery in the US. I am specifically researching re-excision/re-operation rates of those who had lumpectomies in the US.
Would anyone know where I can get data on this?
","['data-request', 'usa', 'medical']",
API that matches food names to categories,"
I am using an API that provides a load of nutritional information for food, for example calories, protein, etc. However what it does not provide is any sort of categorization of that food. Can anyone recommend a database or API, free or paid, that would allow me to match food names to general categories (like meat, fruit, vegetable, etc)? I am thinking if this is not in the food-database related space perhaps it's in some kind of text processing or NLP library I might not be familiar with?
Thanks for any suggestions!
","['api', 'food']",
Pulse transit time values (PTT),"
It seems that PTT based on the ABP & ECG signals is ~300 ms, but when based on the PPG signal then PTT is ~550 ms (consistent for multiple subjects). As I understand both ABP and PPG were measured on the arm. Do you have any idea PTT varies so much? 
",['mimic-iii'],
Historical Chinese Coal Plants Data,"
I'm looking for open data on the locations and duration of Chinese coal power plants from 1950 - present. The data would have the completion data of the power plant, latitude, longitude, and (if applicable) when the plant was shut down. 
Any ideas where such data might exist?
","['data-request', 'energy', 'china']",
Class Action Lawsuit data,"
Is there a government database of class action lawsuit settlements with open claims?
If not, where do sites like Top class actions get their info?
","['data-request', 'government']",
Number of possible actions the player may take in each ATARI arcade game,"
I am looking for a dataset containing:

the list of ATARI arcade games
the number of possible actions the player may take in each game (e.g., 4)

Ideally:

the name of each action (e.g.,  press left)

","['data-request', 'games']",
Querying Wikidata : WDQ vs. WDQS / SPARQL,"
I'm new to Wikidata and I'm wanting to query it. The official page list several promising syntax / APIs :

WDQ ""Wikidata Query"" syntax : http://wdq.wmflabs.org/api_documentation.html
SPARQL syntax via WDQS ""Wikidata Query Service"" endpoint : https://www.mediawiki.org/wiki/Wikimedia_Discovery#Wikidata_Query_Service_.28WDQS.29

The WDQ syntax seems more concise, ex :

WDQ : CLAIM[31:6465] AND NOCLAIM[576]
vs.
SPARQL (same query) :

prefix wdt: <http://www.wikidata.org/prop/direct/>
prefix wd: <http://www.wikidata.org/entity/>
SELECT ?item WHERE {
  ?item wdt:P31 wd:Q6465 .
  OPTIONAL { ?item wdt:P576 ?dummy0 }
  FILTER(!bound(?dummy0))
}


However, reading https://www.mediawiki.org/wiki/Wikimedia_Discovery#Wikidata_Query_Service_.28WDQS.29 I'm under the impression that WDQ is an unofficial experiment and that SPARQL is the official query syntax.
So is there an official or preferred way of querying wikidata ? Is it safe to invest in WDQ or should I go SPARQL ?
","['wikidata', 'sparql']","I'm the developer of WDQ. It was developed as a stop-gap measure, until Wikidata would get its own query service. That took some years, but now we have SPARQL and https://query.wikidata.org/ so I plan to retire WDQ in the not-too-distant future. I strongly recommend you go for SPARQL, even if it seems a little verbose at first."
Dataset of regular expressions for named entity recognition,"
I am looking for a dataset containing:

regular expressions useful for named entity recognition. The regular expressions can be used either as a feature or directly as a rule (in case it always correctly capture a named entity).

Example:

r'(\d{1,2}/\d{1,2}/\d{4})' captures date entities formatted like 03/16/1946.

I mostly interested in texts written in English.
","['data-request', 'nlp']",
Database or API to quickly check whether an image is a meme or not,"
Some websites like to illustrate articles with meme pictures, which can be considered as funny or distracting, for instance depending whether you are at work or not. So I want to create a browser add-on to block them.

QUESTION: Is there a huge list of checksums/fingerprint of meme images, or an API to check whether an image is a meme or not?
Requirements:

Identify memes even if resized
Fast lookup time, less than a second
Works even if the caption has been modified (memes are often the same image with a different caption, see second example above)

","['data-request', 'api', 'images']",
ASCII Character Frequency Analysis,"
I've been looking for a table of the frequencies of all 128 ASCII characters, not just letters. The best table I've been able to find is this one, but that one only includes printable ASCII characters, and is still missing some very important ones (namely \n and \r). Is there anywhere I can find the frequency table for all ASCII characters?
","['data-request', 'language', 'nlp', 'programming']",
American Fact Finder vs ACS from IPUMS,"
What is the relationship between the data from the Census's American Fact Finder  and the data from IPUMS ACS?
If the data are different, what are the circumstances in which I should use one over the other?
",['us-census'],"The aggregate statistics from the ACS Summary File found through the American FactFinder and the data from the IPUMS ACS are both from the ACS microdata.The ACS Summary File statistics are based on and weighted from the full sample of the ACS microdata.The IPUMS ACS is a republished (and in my opinion more polished) version of the ACS PUMS that includes some extra information that can be deduced from other available sources such as technical documentation and geographic shapefiles. The ACS PUMS is also a reduced sample of the original ACS microdata. It is meant to be a ~1% sample of the population. If you want exact  numbers, the ACS microdata has 5,454,957 people among 2,487,838 living quarters and the IPUMS ACS has 3,018,308 people among 1,501,119 living quarters.Comparing the same estimate for the same geography (e.g. the uninsured rate in Kentucky) will yield slightly different numbers between the ACS Summary File and the IPUMS ACS.If you are searching for statistics, try to rely on the estimates from American FactFinder. If you are searching for specific sub-populations not found in the ACS Summary File through American FactFinder, or are trying to get accurate standard errors for the differences between two estimates, then you might want to use the IPUMS ACS."
Why are lab tests splitted into 2 tables: chartevents and labevents?,"
For example, blood sodium has itemid 837, 220645 etc... in chartevents and 50983 in labevents. Most patients have recordings in both tables, of which some are duplicates and some are unique.
I'm using MIMIC-III version 1.3.
",['mimic-iii'],"LABEVENTS data is from the actual hospital wide laboratory data management system.CHARTEVENTS data is from the ICU database that is used as an electronic chart for the patient at the bedside.Since the chart needs to contain lab values, as they are relevant to the patient's health, the laboratory data is pulled from the hospital wide laboratory database to the more local ICU database. Consequently, labs in the LABEVENTS table will re-appear in the CHARTEVENTS table. However, LABEVENTS spans more than just the patient's ICU stay, and in fact covers their entire hospital stay (and sometimes out patient stays too). As a result, I would recommend only using LABEVENTS to extract lab values.Regarding non-unique values in CHARTEVENTS: care providers can insert or modify the values in the electronic chart. As a result, these could be measurements from some other source (e.g. a fingerstick glucose measurement), or they could be a modification of an original lab value.As a general tip, the CHARTTIME for automatically synchronized lab values in CHARTEVENTS is unusually precise. Most measurements are hourly or every 15 minutes, but often lab values in this table are at ""19:43"" (for example). This generally implies it's been automatically synchronized into the table."
RCDC for the fiscal years prior to 2011,"
How/where do I access estimates of Funding for Various Research, Condition, and Disease Categories (RCDC) for the fiscal years prior to 2011?
","['data.gov', 'medical']",
List of organization names,"
I am looking for a dataset containing: 

organization names

Optionally:

abbreviation of the organization name
location of the organization (e.g., in which state)
size of the organization (e.g., number of employees, or revenues)

I mostly interested in the United States.
.
","['data-request', 'usa', 'business']",
List of hospital names with their abbreviations,"
I am looking for a dataset containing: 

hospital names: either full names or abbreviations (ideally, both)

Optionally:

location of the hospital (e.g., in which state)
size of the hospital (e.g., number of beds, or surface)

I mostly interested in the United States.

https://en.wikipedia.org/wiki/Lists_of_hospitals_in_the_United_States is incomplete and doesn't contain hospital name abbreviations.
","['data-request', 'usa', 'medical']",
Hospital Expenditure Dataset,"
I am looking for a data set containing expenditures of hospital/medical facility, ideally day to day, containing detailed spending information on items, supplies and other costs.
Also, if there is patient data, at least a count of patients with the data, it will be ideal.
One hospital or facility would do but it will be great to have more than one.
","['data-request', 'medical', 'finance', 'spending']",
Environmental open GIS data for the Caribbean countries,"
I'm looking around for reliable data sets that cover various environmental and socioeconomic variables for the Caribbean community. The project I'm working on is trying to determine environmental risks using GIS and data science approaches. I've searched around for DEMs, shapefiles and census data and have found a few good resources:

DIVA-GIS has a nice repository of relatively up-to-date (5 years old) administrative and environmental data (as .shp): http://www.diva-gis.org/Data
The USGS has 3 arc-second resolution rasters of elevation data available through their HydroSHEDS project: http://hydrosheds.cr.usgs.gov/index.php
The Harmonized World Soil Database has processed global soil data, but isn't very high-res or up-to-date

The goal of my research is more focused on environmental change, so high-res hydrological, climate (observed/projected), soil, DEM, etc., data sets that's relatively up-to-date would be useful. 
","['data-request', 'geospatial', 'environment']","the nature conservancy has some gis datasets with global coverage, roughly in the areas that you want:
http://maps.tnc.org/gis_data.html"
"German political party memberships, during 80s and 90s to","
is there any chance of getting data on members of German political parties? In particular the ""big ones"". Anything starting from lists of Names to more structured data would be a great start. The period of interest would be 1980 to 2000
","['data-request', 'germany', 'politics']",
Datasets with individual rankings,"
I am looking for real-world dataset examples where there are two types of entities, i.e. students and colleges, and each students has individual ranking for each college (or some of them).
For example are there any datasets for the Stable marriage problem?
",['research'],
Problem with base+gain of signals,"
There seems to be a problem with the gain/base when correcting the base/gain of several subjects. For example  the gain/base of subject a44012am (mimic2db) should 512 /255 respectively (according to the .info file), but the ABP signal results in values between -50 to 10 mmHg, although the ATM web presentation seems to have reasonably physiological values. 
Used the following command:
wfdb2mat -r mimic2db/a44012/a44012a -f 137110 -t 137170 -l s1000000 >a44012am.info

Is it possible the the gain/base values in the .info file are wrong?
",['mimic-iii'],
How can I find a dataset in the field of eye tracking for a recommender system?,"
I want a dataset to be used implementing a web recommendation system by combining Markov and eye tracking.
",['data-request'],
Data Set for Recommender System that contains contextual aspect-level ratings (as well as reviews),"
I am looking for a data set for building a recommender system that takes into account contextual aspect-level ratings.
For example, a data set from Tripadvisor would be great if it contained ""traveler type"" (like business or family) and ""time of year"" (like Jun-Aug) (as contexts) as well as aspect-level ratings (like ""Rooms"" and ""Cleanliness"" and so on).
What I want to check is, if recommendation accuracy can be improved by incorporating contextual aspect-level ratings as I expect recommendations to be more accurate in this case than when e.g. only aspect-level ratings/only context/just overall ratings is/are used.
Any other data set from any other domain in which the approach would be useful is appreciated, too. It would be a plus, if the data set also contained text-based reviews.
Thank you for your time!
","['data-request', 'research']",
"A license catalog project with RDF description, exist?","
(Edit after first answer to avoid cross-post)
Popular public copyright licenses like GPL3, MIT, Apache2, CC-BY-SA3, etc. have official human-readable texts, and, I suppose, in nowadays, have also translations to ""machine-readable texts"", that are  REL interpretations/translations of the official texts... Each license is a set of clauses that can be described by REL, and this set is my interest.
There are a ""license catalog"" (content with semantic markup) with each license translated to REL or RDF?

The RDFLicense dataset (with git here and an article here) is a near to perfect catalog (!), but have some critical problems:

No criteria for grouping ""semantically equivalent licenses"", that is, equivalent versions (where no relevant ""contractual change"" was made) and equivalent translations (by definition an translation must be equivalent). So there are two problems: 1.1) no criteria; 1.2) the catalog has very less than 100 ""real licenses"", then its volume is yet small. PS: see semantic definition of frbr:Expression, frbr:realization, etc. 
No standard markup to show content with semantics as microdata examples, that have ""probative value"" for indicated/elected properties of the license.
Use of ""exotic"" standard in both, the license-content (used VoID description)  and summarized (only RDF-like, used .ttl) dataset. PS: the ideal is pure RDFa (a W3C de jure standard) or Microdata (most popular, a de facto standard) for content-semantic markup; and JSON-LD for summarized semantic (and join efforts with OKFN project or other iniciatives).

So, a good suggestion to overcome these problems is also a good answer. 

NOTES
Existing translations and samples. The only that I found was a CC licenses translated to  CC-REL.
""REL is RDF"". 
Any REL (Rights Expression Language), ex. CC-REL or RightsML, can be translated to RDF, so we can suppose that any popular license tranlated to REL, is a RDF descriptor of the license.
""RDF is JSON-LD, RDFa, Microdata"", no problem for me, all can be translated to another.
""catalogues"". They exist, as Wikipedia lists, OKFN lists, tldrlegal lists,  and others... But no one have a  REL or RDF translation/interpretation. 

About REL lanuages and license catalogues, Rodríguez-Doncel et al. (2014)   commented,

(...)  languages to digitally represent the key information in licenses have existed for at least a decade (...), but no effort was made to  systematically map existing licenses to these languages. 


example
Reference-example (BSD-2-Clause license) of markup text, 

Redistribution and use in source and binary forms (...) are permitted provided that (...):

Redistributions of source code must retain the above copyright notice (...).
Redistributions in binary form must reproduce the above copyright notice (...).


So, in HTML + Microdata markup, will be something as
<div itemscope itemtype=""http://creativecommons.org/ns#License""> 
<p itemtype=""#Permission""> Redistribution and use in source and binary forms (...) are permitted provided that (...)</p>
<p itemtype=""#Distribution"">1. Redistributions of source code <span itemprop=""#notice"">must retain the above copyright notice</span> (...).</p>
<p itemtype=""#Distribution"">2. Redistributions in binary form <span itemprop=""#notice"">must reproduce the above copyright notice</span> (...).</p>
</div>

and summarizing it in JSON-LD something like,
{ 
  ""@context"": {
    ""cc"":""http://creativecommons.org/ns#"",
  },
  ""@id"": ""cc:License"",
  ""cc:Permissions"": [ 
    {
    ""@type"": ""cc:Distribution"",
    ""value"": ""Redistributions of source code"",
    ""cc:notice"": ""must retain the above copyright notice""
    },
    {
    ""@type"": ""cc:Distribution"",
    ""value"": ""Redistributions in binary form"",
    ""cc:notice"": ""must retain the above copyright notice""
    }
  ]
 }

work and information chain
The ""marked license"" (example with Microdata), is the ideal aim, and need a lot of human work (!), reviewers and endorsement to be valid as oficial interpretation.
The ""summarized license"" (example with JSON-LD) can be obtained from the markup by software; and a ""basic extract"" like this (columns ""is_by"", ""is_sa"" and ""is_nd"") can be obtained by software from the ""summarized license"".
","['licensing', 'rdf', 'translation']","The criteria for grouping ""semantically equivalent licenses"" might be implemented as an external HTTP REST service. There are already some services based on that dataset running here: http://licensius.com/apidoc/index.htmlVolume of licenses. Contributions of new licenses or suggested revisions to this github folder are welcome; only a TTL has to be dropped for each new license here. This might be a good tool against the ""license proliferation"" problem.Yes, having microdata would be great. Deep linking for each of the asserted statements would be a plus (namely, if the license claims ""distribution is permitted"" then a link to the specific paragraph would be great. "
labeled sentiment words according to 8 different human sentiments,"
I am trying to do sentiment analysis using lexicon based sentiment analysis. My goal is detecting 8 different basic sentiments (not positive and negative sentiment only). I found there is plenty of word dictionary for two class sentiment only, but I need 8 different word dictionary where words are being labeled according to their sentiment level. e.g. for say, this is a fear dictionary where words are being labeled in a 0-5 range. 
words  sentiment polarity
loser      -4
evil       -3
terrorist  -5
I googled a lot but could not find actually such dictionaries. Looking for suggestions from experts. 
","['data-request', 'sentiment-analysis']",I found NRC Word-Emotion Association Lexicon has something that I was looking for. 
Scraping pages to get prices can be considered as OpenData,"
I have a discussion in a Google Group about the next thing:
One person wants to scrape multiple web sites to gather prices of different types of technology products (cell phones, TVs, computers, tablets, etc.) and then provide this collected information as Open Data.
I said that this is not open data, because the person does not own the source of the data. However, other people say that it is open data, because the prices are available to the public, and they give examples of multiple companies that do similar stuff of scraping multiple sites.
Can scraping specific data from multiple websites and providing this in a database be considered as open data? Where can I find information about this activity? I want to read articles where this action is accepted as Open Data OR specifying that this is not open data, but just an extraction and cannot be reused.
Many sites explain OpenData for governments, but very few talk about open data for the private sector.
(The Google group is the Spanish OpenDATA Productos de consumo)
","['uses-of-open-data', 'web-crawling', 'prices', 'open-definition']","There's a big difference between “available to the public” and “belonging to the public”. By accessing a privately-owned website, you are accepting its terms and conditions. These conditions typically preclude scraping and aggregation. Here's an example from Amazon's (Canada) Licence and Access terms:The last clause is pretty clear that you can't legally scrape from their website."
"Tweets about past disasters (flood, storm, earthquake, volcanic eruption)","
Where can I download tweets about past disasters (flood, storm, earthquake, volcanic eruption) for research purposes?
","['data-request', 'social-media', 'geohazard']",
OPEN FDA spam phone calls,"
I am receiving unwanted voice messages detailing several FDA initiatives from 909-394-5110.  It talks about inspections detecting illegal drugs and also a short blurb about Open FDA and natural gas extraction.
can you guide me to the responsible organization that is spamming me with FDA subject matter?
Very Respectfully,
Roy Malmberg
",['openfda'],
University of Phoenix Salary Data,"
I am skeptical about the College Scorecard data for University of Phoenix.
Why do all the campuses have the same median salary?  
","['data-request', 'collegescorecard']",
GTFS vs SIRI wich one is more used nowaday,"
i 've searched a lot for this kind of information unfortunaetly  i can't find the right information about , we know all that gtfs was 
Standarisedby google the last 3 years , siri was and still used  especially in Europe , for those who have an idea or have worked with these kind of feeds files   wich one should i use for my web application destined to bus transit ?
","['uses-of-open-data', 'public-transport']",
does bugzilla have an updated dump for all of its project,"
I am planning on text mining bug reports. so i am in need of a dataset of bug report.
does Bugzilla have an updated dump for all of its project?
does any other bug tracking system provide free access to their archives?
",['data-request'],
Are there time series of population data for the world urban areas?,"
A list of the world's largest urban area is available on wikipedia and cites 9 different possible data sources. This list gives only 2014 data (or another, single year). Is it possible to obtain time series population data for example for the last 20 years? 
I'm looking for something similar to the world bank country data but for urban areas (cities).
I would like to use the data set to illustrate a training on statistical software and data visualisation.
","['data-request', 'population']",
finding old cookies from Chrome [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 7 years ago.







                        Improve this question
                    



so I was using chrome to do research on subatomic particles and the website got taken down so I'm on my C Drive under the path users username app that a local Google Chrome user data default and there are just a lot of folders and files I was just wondering which one of these files or folders could I open and using what software to read the articles that I have no access to
",['research'],
"Phone Tracker, How does this work, and could it be used?","
So I found a website: Phone Report and the peculiar thing about it is that it provides a activity map of where that phone has been. I quickly tried to dig through the website's source and network activity, and found it was loading a Open Street Map Layer. I'm wondering if the common GPS locations of a phone number could be extracted from that. Unfortunately I'm not familiar with Open Street Map, Most of my time has been spent in World Wind. Could anyone look into this as a possible data source?

",['data-request'],
"where can i download archives of eclipse,ibm jazz and mozilla","
Where can i find and download bug reports, mailing list archives,execution logs,test cases,for the following projects?
1.Eclipse
2.Ibm jazz and
3.Mozilla
","['data-request', 'releasing-data', 'machine-learning', 'nlp', 'research']",
Luxury watches database,"
perhaps someone knows where can I find a public database for watches and their reference numbers? Timepieces are quite standardized and I would be very interested on checking it out for a personal project.
Something like this would be helpful:
http://www.watchtime.com/watch-database/
",['data-request'],do you mean something like http://watchbase.com/watchesi am looking for something similar for woocommerce projects i am working on.
Keyboard keystrokes with timing,"
Similar to this question: Where to find key log data for keyboard usage?
...but it doesn't have the answers I am looking for.
I am researching keyboard layouts. I want to get timing data for each key to research delays in typing. I am trying to find what may contribute most to delays from key positions to language itself. If you know of any keystroke data sets that contain timings as well, that would be helpful.
It doesn't have to be too exhaustive or big. This is a hobby, not any kind of funded research.
","['data-request', 'language', 'computing']",
Find a List of Private Companies That Use Canadian Government Open Data?,"
How can I find a list of Canadian private companies that use Canadian government open data?
","['data-request', 'government', 'uses-of-open-data', 'companies']",
How data data.gov tend to perform?,"
I am currently deciding whether to use the USDA's Nutritional Database as the backend provider of nutritional information for my app. The other option I am considering is the FatSecret platform. My concern about the USDA API is there are no guarantees as it's not a business. Has anyone built real-time analytics/apps with the USDA API and can you tell me whether you've had good performance? Have there ever been gaps in service/etc?
",['data.gov'],
Formats of texts from wikisource?,"
In what formats can I retrieve texts from wikisource?
The obvious format is the HTML they deliver for reading, but the HTML source is very layout oriented and messy.
Is there a downloadable source format available that is more logical (XML or wiki format)? How can I download it?
","['data-format', 'text']","For automated processing, by far the best alternative is a database dump.  They might be a little bit old, but hopefully that won't be a problem.You can select database dumps by language and wiki, with or without edit history.At the time of writing, the most recent enwikisource dump is from 26 December 2015.  You can also find dumps for dewikisource, frwikisource, etc."
Where can I get vector datasets for Nasarawa state in Nigeria?,"
I would be happy to be pointed to the right direction where I can access vector data for Nasarawa state in Nigeria?
","['data-request', 'geospatial', 'africa']",
Data sets for evaluating cluster analysis,"
I'm studying data clustering algorithms.
However, I can only find little labeled real data suitable for clustering. Probably the most popular one is the iris data set, since it contains some well defined clusters that agree with the classes. Most of the data sets here are synthetic and tiny, or unlabeled.
Please don't point me to the UCI machine learning repository. Much of the data sets that are categorized as ""clustering"" there don't cluster well, and don't have labels suitable for clustering evaluation either.
I'm looking for data sets with the following characteristics:

preferably multivariate-numerical, since many algorithms only support this (text can be vectorized, but usually is not labeled into clusters. Graph clustering is very different, and I'm not looking into this right now)
large enough - 10,000 instances is small, 100,000 would be better. Beyond this, many algorithms will fail (many scale O(n²) or O(n³), unfortunately).
labeled for clustering. Many classification data sets are not good, because classes themselves contain multiple clusters, or multiple classes may be the same cluster (you can observe this on the iris data set, too - give an unlabeled data set to a human, and he will say there are two clusters instead of three).

Since many of the UCI data sets do not appear to work well for clustering, I'm figuring I should put out a call here at OpenData to find fresh data sets.
I am also interested in:

studies of clustering quality that use real data.
toolkits for data clustering (such as ELKI) that have many and fast algorithm implementations. Since I'm interested in advanced methods, I don't care about k-means-only, nor about tools that can't cluster at least 100,000 instances.

","['data-request', 'machine-learning']",
"Federal, state, and county prisons & jails","
Looking for a list of all city, state, and federal related prisons & jails in the united states.  
Looking for the list to include the name of facility, type, and address.  
Can anyone point me in the right direction?
","['data-request', 'usa', 'geospatial', 'government', 'geocoding']",
German news/text data set,"
I am looking for (possible buy) a dataset of German news data (i.e., the largest daily newspapers), where the data span at least ten years back up until now/recent.
Any tips? 
","['data-request', 'language', 'nlp', 'europe', 'media']",
Looking for open source LGBT datasets,"
I have been looking for any general datasets about LGBT Americans. The type of file I look for are either CSV or TSV. Although my inquiry will hopefully yield some spatial indices at the county or state level, because of the apparent lack of initial success in searching I am hoping for data of some depth of any sort.  Any suggestions or help is greatly appreciated. 
","['data-request', 'usa', 'geospatial', 'csv', 'lgbt']","There is not a lot of good nation-wide data on LGBT topics. Here are a few I was able to find for you. Some of them are already in CSV/TSV and/or Excel format (and therefore trivial to convert to CSV) while some are PDF reports with tables embedded (which, given some effort, could be converted to CSV/TSV tables):"
Is there open data set on Facebook status?,"
I am looking for a data set that contains Facebook's status and its privacy settings for each status.
If there is a kind of this data set available for public access, could you help me?
","['data-request', 'social-media']",
Where can I find information for standard deviation and mean for real life data?,"
Can someone please point me to a resource where I can find the mean and standard deviation for real life data, for example the wingspan of an eagle or the weight of an elephant or anything meaningful. I can easily find data for the mean, but not for the standard deviation. I am trying to come up with questions about normal distribution for high school students. I can of course make up the numbers, but it would be better to have the numbers reflecting the actual facts.
",['data-request'],
"Urban, suburban, and rural blockgroup data","
Is there an open source data classifying Urban, suburban, and rural  blockgroups? I am specifically looking for the urban continuum data for Hillsborough County, Florida. I know that Nielsen Claritas has developed a specific variable named urbanicity for the purpose of classifying blockgroups. However, it is not free. Just wondering if I can get similar data from any other open source?
","['data-request', 'geospatial', 'us-census']",you can probably find what you are looking for inside the census summary filesfile layout from http://www.census.gov/prod/cen2010/doc/sf1.pdf#page=18some code examples of how to work with those files:http://www.asdfree.com/2014/12/maps-and-art-of-survey-weighted.htmlhttps://github.com/davidbrae/swmap
Repository of virus-infected computer files,"
I have set up an Alfresco document management server and an extension that claims to block virus-infected documents from being uploaded to the server.
Now I want to test it with files infected with a variety of commonly found viruses.
Is there a freely reusable repository of such files?

Of course .exe viruses should be present, but also .doc files or .pdf files that are specially-crafted to trigger privilege escalation and attacks in Word or Acrobat, for instance.
For obvious reason, the files should be distributed within an archive file.
As recent and representative as possible.

","['data-request', 'software', 'security']",
Where to find data on Australian business types and locations?,"
There are numerous Australian government websites which manage businesses, including:

Australian Business Register
Australian Securities and Investments Commission
Business.gov.au
ABN lookup webservice

However, I can't see any datasets which show the location and business type of Australian businesses.
The closest I've found is the ABN Bulk Extract dataset on data.gov.au, which shows the business name and postcode, but no information on the business type (eg, is it a pharmacy or a donut shop?).
Are there any publicly available datasets showing the Name, Type and Location of businesses across Australia? (Either free or paid is fine.)
","['data-request', 'business', 'australia']","I wasn't able to find any free datasets which answered my question.But the next best thing was a reasonably cheap dataset from http://datajet.com.au which had business name, type and lat/long:"
Big data set for Document Classification,"
I'm looking for big data set which is suitable to be used for document classification task. The data set which I'm looking for should composed of the frequency of the words which exist in each document, so the main goal of the task is classifying each document to one category such as Sport, Political etc. All what I found in Internet is some small data sets, if anyone can help me to find a big data set that can be used for a such task, I will be very thankful.
Note: all the attributes values should composed of integer number which represent the frequency of word in each document.
edit: I'm looking for CSV file to use it as input for multinomial naive bayes classifier.
","['data-request', 'machine-learning', 'corpora']",
Dataset of clinical trial accidents,"
I am looking for a dataset of clinical trial accidents, with ideally:

drug tested
phase of trial
number of casualties, and description of injuries
country

I am interested in both clinical trials of drugs and clinical trials of devices. I have mostly interested in human subjects.
","['data-request', 'medical']",
Getting influences / influencedBy data from DBpedia,"
I am struggling with DBpedia. The description is unclear (to the point that for me it is hard to tell which data can be obtain, which - cannot), and (what is worst) it does not have many examples (direct links) I could learn from.
I want to get all ""influences"" and ""influencedBy"" fields for all philosophers, preferably in JSON format.
The closest things I found are:
http://dbpedia.org/sparql?default-graph-uri=http%3A%2F%2Fdbpedia.org&query=DESCRIBE+%3Chttp://dbpedia.org/resource/Bertrand_Russell%3E&output=application%2Fmicrodata%2Bjson
http://dbpedia.org/data/Bertrand_Russell.json
But it is:

per-person (it is not clear if it is only way to query)
a lot of other data I don't care about (heavy)
even ""influences"" are passes in complicated format (OK, this thing is not the worst, but I maybe there is something lighter)

Ideally something like:
[{""name"": ""Bertrand_Russell"",
  ""influences"": [""Euclid"", ""John_Stuart_Mill"", ...],
  ""influencedBy"": [""Ludwig_Wittgenstein"", ""A._J._Ayer""]},
 ...
]

(Whether in a single query, or in a few.)
Is it possible? How?
","['json', 'wikipedia', 'dbpedia']","Using this SPARQL end-point: http://dbpedia.org/sparql you can enter this query:which will give you a list of pairs of philosophers (influencer, influencee) and their years of birth.  You can choose JSON as the results format."
Statistics on car life length for each car model?,"
Authorities of each country register cars when they are bought or scrapped. Is there an open statistics of average life time for each car model?
","['data-request', 'foia', 'cars']",
Arterial line location and PPG sensor location,"
1) From which artery the ABP signal was collected?
2) Where was the PPG device located? Fingertip? What wavelength was used?
",['mimic-iii'],
Discrepancy between OpenFDA and FAERS,"
I noticed there are discrepancies in counts of events for a given drug when querying OpenFDA for a given quarter (I tried q1 2014) and trying to get a matching answer from the downloadable FAERS dataset. What is the explanation for this? The error is typically small (maybe 5 %), but bothering nonetheless.
",['openfda'],
Electricity and (space) heating load curves for a city,"
I want to get a visual feeling for the distribution of electricity and heating load over the year. There are national load curves, then there are reference load curves for individual (mainly residential) buildings. But I would like to get something in between. Proxies like output of district heating or cogeneration plants are fine, too.
I'm not picky: The preferred time resolution is 1 hour, covering a full year, in moderate (i.e. summer-winter-cycle) climate. But I take daily, even weekly resolution anywhere on the globe.
The only hard requirement: open data with clear license, not a pixelated graph in a report that may not be reused.

Motivational picture: Wikimedia commons: Lcurve.jpg [PD]
","['data-request', 'city', 'energy']","GreenButtonData.org (open source) is compiling this type of information from its users. They currently claim that upto 60 million households can access their monitoring/analysis system via partnerships with utility companies. They have a REST API, but I do not know how much aggregated data is available yet. They have though given some datasets (or samples), including hourly loads, to openEI (crowd sourced project for energy usage/information - http://en.openei.org/wiki/Main_Page)32 day hourly sample - http://en.openei.org/datasets/node/901UPDATE: 
Below is the dataset for monthly energy usage and CO2 emissions for Boston's municipal buildings.https://data.cityofboston.gov/dataset/Municipal-Energy-Data/bcnb-bux2Below is the datast for annual energy and water usage and CO2 emissions for NYC's buildings > 50K square feet.https://data.cityofnewyork.us/Environment/Energy-and-Water-Data-Disclosure-for-Local-Law-84-/5gde-fmj3"
Tennis dataset of hawk-eye or other stats,"
Is there any available tennis dataset regarding hawk-eye tracking statistics?
Other than the historical data on the official ATP site are there out any other free db of tennis statistics analyzing different variables?
",['sports'],
Error when importing data from SQL dumps to MIMIC-III tables,"
I am having trouble importing data to the created MIMIC-III tables. I followed the installing MIMIC locally instruction on mimic.physionet.org and failed at step 6. When I enter the code, it outputs an error message: ERROR: character with byte sequence 0x8f in encoding ""WIN1252"" has no equivalent in encoding ""UTF8"".
My OS is Windows 10 and I am using PostgreSQL 9.5. I created my tables in the default Postgres database, the encoding is UTF8. Any help would be greatly appreciated.

",['mimic-iii'],
A standard format for English vocabulary,"
Is there a standard format for English vocabulary lists and some data sources in that format? (For example a standard XML)
For example SAT vocabulary or Basic English words, including definition, examples, phonetic,... in that format.
",['data-format'],
Open datasets of lottery winning numbers,"
I saw only paid feeds for lotteries games. Also would be great to get dataset of virtual betting games
","['data-request', 'sports', 'games']",
Scientometric/bibliometric data retrieval from a list of DOI,"
I am a conducting bibliometric analysis on small/midsize sets of academic papers (40-400), in a longitudinal study (repeated over time on the same dataset).  I am interest in retrieving data for each paper, in order of importance (to me):

year and number of citations (the essential ones, the others are not mandatory)
number of authors, number of non-self citations and journal name (ISO form for instance)

This could be performed by hand, using different sources (ResearcherID or Web of Science, Scopus, Google Scholar). Are there open bases or tools to retrieve such information from a set of Digital Object Identifiers (DOI)? It would be a plus to retrieve the same set of data from these three main sources.
","['data-request', 'tool-request', 'research', 'extracting', 'bibliometrics']","Maybe the rcrossref package for R is helpful. To find the number of citations, You can do things such asResult:The API will only work for CrossRef DOIs.
This means that the only works that can be searched for must have been published with a member of the Crossref consortium of publishers.If you are not familiar with R, then instead you can work with the CrossRef REST API directly."
Looking for high (temporal) frequency wind data,"
I'm looking for data sources providing high temporal frequency wind data. Once per minute would be preferred. The TCOONS dataset is a great example. I identified this after speaking with a local National Weather Service office, who directed me to it.
Is there any nationwide listing of such datasets? Most of the wind data available appear to be daily or 20 minute averages......
",['weather'],"Try the Met Office in te UK - http://www.metoffice.gov.uk/datapoint 
They collect and model peta bytes of global data. Not sure if they have your  particular dataset but are the nr 1 weather experts globally. 
In the UK there is one centralised organisation (funded by tax money),  unlike several ones in the US. However their data is used globally by many."
Games for education [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 7 years ago.







                        Improve this question
                    



I'm searching an Open Data (free code) for Education Games, like Puzzle. Actually, I need a game that presents the context information and which is the educative game for the children. I would like to use it for demonstrating the MAKEY MAKEY Kit.
","['education', 'games']",
Meaning of SEQ_NUM in DIAGNOSES_ICD table and missing values in ICD9_CODE field,"
I am just starting to analyze v1.3 of MIMIC-III data. I have two questions about the DIAGNOSES_ICD table.

According to the documentation [1] : ""ICD diagnoses are ordered by priority - and the order does have an impact on the reimbursement for treatment."" What does priority really mean in clinical settings? Also, does it mean the dataset does not have any information about when a diagnosis is confirmed? E.g. a patient may have some cancer on day 1 but acquire pneumonia on day 5?
There are 47 rows in this table where the ICD9_CODE is an empty string, what do they mean? Should I just remove them from my analysis?

[1] http://mimic.physionet.org/mimictables/diagnoses_icd/
Thank you very much.
Cheers.
",['mimic-iii'],"For Q1 see diagnoses_icd.sequence in MIMIC-III: does the order matter aside from the primary diagnosis? and Priority sequence column in diagnosis_icd. (#156 - The SEQUENCE column in DIAGNOSES_ICD and PROCEDURES_ICD has been renamed SEQ_NUM in MIMIC-III v1.2)For Q2: see https://github.com/MIT-LCP/mimic-code/issues/24:Question:I see 47 diagnoses_icd.hadm_id are null:Bug or intended?Answer:Depends on your perspective! The null entries appear in the raw
  hospital data for reasons unknown to us.We try to provide a true representation of the underlying data and
  generally err on the side of too little cleaning rather than too much,
  so the rows were not removed during the process of building MIMIC.We could remove them in the future. I'll make a note to consider this
  for the next release."
Countries with a Census,"
I am looking for a list of countries that have a census. The attributes would be the last census dates or dates of censuses and the census unit. I do not want variables from a census but meta information such as:

Has a census:Yes / No 
Date(s) of census: 1992, 2002, decadal, etc.
Census geographies: Blocks / enumeration districts.

Was hopeful something may exist at UN / World Bank / IMF level or compiled by an academic.
A census of censuses.
This is the best I have come up with so far (useful but just a start): Census in Different Countries of the World (dec 2010) and UN 2010 World Population and Housing Census Programme. I am also working my way through IPUMS.
If you just know for a large group of countries this will help. Such as the information for all of Africa then this would help. I am trying to avoid going country-by-country for 200 countries.
","['metadata', 'census', 'global']",
Assignment file for VTD's to Congressional Districts? (NYS 2010),"
I'm working with some data at the 2010 Voting Tabulation District level (like the 2010 Census, Vote, and Enrollment data on this page).  I'd like to merge in some information about US House districts, and I'm looking for an easy way of seeing which Congressional district each VTD belongs in.  I could grab the district shapefiles and do this with GIS, but worry about it being messy and imperfect.  Is there a relationship file somewhere that maps 2010 New York State VTD's into 2010 NYS Congressional districts?  I'm thinking of something like the Census' Congressional District Relationship Files, but for VTD's.
","['geospatial', 'us-census']","You can get block assignment files for a given state from this Census Bureau pageIn those files, there are block assignments for all of the geographies which need to be assigned. You should be able to ""join"" the VTD and CD tables on common block IDs to get what you need."
Data by county or by zip code on commercial new construction permits issued across the United States,"
I am looking for number of new commercial buildings built or permitted at the county or zip code level and would like to know if there is somewhere I can find this for the entire country.  Specifically, I am looking for 5 states - North Carolina, South Carolina, Kentucky, Ohio, and Indiana.  Ideally, the data would include state, zip code, county, date permit issued or building completed, value of property, and intended sector (e.g. restaurant, manufacturing, multifamily) of building.  The data does not need to list every individual building permitted - if I just had number totals by county/zip code, sector, and month/year, that would be sufficient.
Here is a link I found that provides exactly the type of data I'm looking for - however it is only for one county in Maryland:
https://catalog.data.gov/dataset/commercial-permits-6d3e5
If you know of any sources for this type of data, it would be greatly appreciated.
Thank you
","['data-request', 'economics', 'historical', 'postal-code', 'county']",
dataset access for icpsr members [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 7 years ago.







                        Improve this question
                    



I've just found a dataset which would really fit my intentions with an assignment I was given. Unfortunately I'm not allowed to access the data neither is the college where I study. I wonder  if someone would be able to access it and download it for me.  http://www.icpsr.umich.edu/icpsrweb/RCMD/studies/35163#usage
thank you in advance for your help!
",['data-request'],
What you look for in a codebook,"
I'm putting together a few codebooks/data dictionaries for our transparency portal. In doing so I have been reviewing some examples to get an idea of what civic hackers look for in such a document.
My working plan is to prepare them as .md files that can be loaded into a data frame. Is there anything else I should keep in mind? Do you have an example of an ideal codebook?
","['government', 'tool-request', 'uses-of-open-data']",
"openFDA Device Adverse Events missing for Dec, 2015 (as of 19-Jan-2016)","
There still appears to be a problem with the data for Dec, 2015... the following query returns zero results as of now:
http://api.fda.gov/device/event.json?search=date_received:[20151201+TO+20151231] 
",['openfda'],
Database of evacuation sites in Japan (places to take refuge after a natural disaster),"
Japan has thousands of ""evacuation sites"" that people should flee to in case of disaster, in particular if their house is burning, or about to collapse.
Is there a database of the latitude/longitude of all of them?
I would like to make an app pointing to the closest one.
They are known under different names, because there are various types of them, and various municipalities might use different names:

一時滞在施設 (""temporary meeting place"")
避難場所 (""evacuation site"")
避難所 (""shelter"")

The data for Tokyo can easily be scraped from http://map.bousai.metro.tokyo.jp but rather than scraping Japan's 1719 municipalities one by one, I would prefer a data set that already contains them all. Or at least by prefecture (Japan has 47 prefectures).
","['data-request', 'geospatial', 'japan', 'geohazard']",
Where to Find Data....Project Idea [closed],"







Closed. This question needs to be more focused. It is not currently accepting answers.
                                
                            











Want to improve this question? Update the question so it focuses on one problem only by editing this post.


Closed 7 years ago.







                        Improve this question
                    



I am currently taking a SAS class. We were advised to think of a project that we could do on our own, as newbies. Does anyone have any ideas that a newbie to SAS could take on, and where I can find the data for it? 
I thought about doing gas prices, and how that relates to holidays; i.e. which specific day would be the best day to buy gas according to trends, as it relates to each holiday--throughout the year; however, the only data I could find was monthly averages and not daily averages. Moreover, it was only for one state, and I would obviously need more data points than just a monthly average for entire states. 
","['data-request', 'uses-of-open-data']",
TwoCircles Dataset,"
I am analysing an article dealing with: ""Semi-supervised Graph Clustering: A Kernel Approach"" I need to reproduce figure 1 on page 7. http://www.cs.utexas.edu/users/inderjit/public_papers/kernel_icml.pdf
I didn't find the dataset of two circles? Could you please help me find that?
",['data-request'],You could generate a similar dataset in Python using scikit-learn's  make_circles function.In Matlab you could could generate the dataset with something like:
Music Festival Datasets Resources,"
I am working on a project right now and I am having a very difficult time finding any open data sets for historical information on american musical festivals or rap concerts. Does anyone know of any great resources that I could use to find data on musical festivals or rap concerts?
Types of data I am looking for include, but are not limited to:

number of Rap tours per state, season, month, and year
number of ticket sales per season, per month
Demographic information around venues such as average age, income, music of interest
etc..

I would like the data to go back 5 - 10 years. 
","['uses-of-open-data', 'music']",
Where can I find Open Data on Nigeria's Annual Budget?,"
I need a resource or information on where/how I can get access to Nigeria's Annual Budget
","['data-request', 'africa']",
Do some publishers offer to host a mirror of webpages used as a reference?,"
Using a link as a reference is often problematic as the link might disappear at a future time. However, the content might be of high relevance to the reader, so it might be worthwhile to add it as a reference. Do some publishers offer to host a mirror of webpages used as a reference?
",['publications'],
"5-star Open Data rating scheme, are there URIs for the ratings?","
I'm in the process of constructing a DCAT catalogue and we want to show how each dataset conforms to the 5-star open data rating scheme. I assumed that someone would have coined URIs for each rating but have been unable to find them.
Do such URIs exist?
","['linked-data', 'rdf', 'ontology', '5-star-scheme']","I'm not sure I agree that you need to have any URI to demonstrate how open a set of data is.  Either the data is open and shareable or it is not, the openness of the data is described by the openness of the data.Let's say I publish a set of RDF linked data, as soon as it is published it is open to be consumed as a whole or in part, people can take which bits they want to put in a triple store or use how they like, so where do you put the link to the accreditation, I mean you can't link it to everything directly.But OK, you want some URI that you can publish in a metadata catalogue, that documents the openness of the data described by the metadata, then why not use the Linked Open Data star badgeshttp://lab.linkeddata.deri.ie/2010/lod-badges/img/data-badge-0.png no star Web datahttp://lab.linkeddata.deri.ie/2010/lod-badges/img/data-badge-1.png one star open Web datahttp://lab.linkeddata.deri.ie/2010/lod-badges/img/data-badge-2.png two star open Web datahttp://lab.linkeddata.deri.ie/2010/lod-badges/img/data-badge-3.png three star open Web datahttp://lab.linkeddata.deri.ie/2010/lod-badges/img/data-badge-4.png four star open Web datahttp://lab.linkeddata.deri.ie/2010/lod-badges/img/data-badge-5.png five star open Web data"
Predictors for AD/senile dementia dataset,"
I'm looking for some raw datasets about Alzheimer Disease/Senile Dementia. 
In particular I'd like to investigate the relationship between Physical activity/diet/occupation-education and the occurrence of Alzheimer and Senile Dementia.  Chance of multilevel analysis would be welcomed.
To give some specific exmaples of the kind of research in this field you can look at these papers (I contacted the authors BTW):
Effect of physical activity on cognitive function in older adults at risk for Alzheimer disease: a randomized trial.
Rate of memory decline in AD is related to education and occupation: cognitive reserve?
","['data-request', 'medical']",
Cryptocurrency historical prices,"
I'm looking for cryptocurrency historical data, including prices and market cap (either from exchanges or average price) of the main cryptocurrencies, namely: Bitcoin, Ripple, Litecoin, Ethereum, Dash.
So far I've only been able to find this source on Quandl and the historic daily price on blockchain.info 
Any additional additional sources for other cryptocurrencies and more detailed data (like hourly price or Open-High-Low-close) will be helpful.
Ideally the data should go back as far as possible but realistically data since 2012 would be enough. As for younger cryptocurrencies 1 or 2 years will suffice.
","['data-request', 'finance', 'historical']","As it turns out there are several resources one can use for all main cryptocurrencies so I will post here the most relevant and flexible I was able to gather.All CryptocurrenciesCoinmetricshttps://coinmetrics.io/data-downloads/This page has data for: Bitcoin, Litecoin, Ethereum, NEM, Decred, ZCash (transparent transactions only), Dash, Dogecoin, Ethereum Classic, PIVX, Monero.ETH -  BTCPoloniex As chartPoloniex As JSONOne needs to edit the timestamps in the API to get a different snapshot. And edit the period to adjust the details.BitcoinCoindesk Closing price and OHLCClosing price blockchain.infoBitcoin data on QuandlBitcoin data on Quandl IIEtherThanks to the answer to this question on Ethereum's stackexchangeEtherchain's APII will keep updating this answer with more links as I find them."
Corpus of human-scored machine translations?,"
Most of the parallel corpora (Opus, EuroParl, OpenSubtitles) have only human translations.
src_txt | human_trans_of_src_txt_into_trg_lng

(We assume all the translations are good.)
Is there a corpus of machine translations, annotated with human eval scores?
src_txt | machine_trans_of_src_txt_into_trg_lng | score

* Any score is fine (label vs number, sentence-level vs word-level)
OR  
src_txt | machine_trans_of_src_txt_into_trg_lng*

*Where all translations are known to be good (or all known to be bad)
","['data-request', 'language', 'nlp', 'corpora', 'translation']",
"Average income by age group, for all countries?","
Is there any data source that lists average income, disposable income, or salary by age group? I would like to get something like the follows.

Country | 25-34 | 35-44 | 45-54 | 55 and over
Belgium | 30,000 | 33,000 | 46,000 | 52,000
Italy | 23,000 | 32,000 | 39,000 | 51,000

The numbers are illustration purposes' only (US$). I would like to get data that includes at least 20 or so developed countries.
Of course the different age threshold can be accepted. 
","['data-request', 'economics', 'income']",
How to map MIMIC-II's SUBJECT_ID and HADM_ID with MIMIC-III's SUBJECT_ID and HADM_ID?,"
I wonder how to map SUBJECT_ID and HADM_ID of MIMIC-II with SUBJECT_ID and HADM_ID of MIMIC-III.
",['mimic-iii'],"The SUBJECT_IDs in MIMIC-II are the same as SUBJECT_IDs in MIMIC-III.HADM_IDs are different because MIMIC-II used an ICU database to define hospital admission and discharge (and only had dates), whereas MIMIC-III uses a hospital database (and has dates and times). You could create an approximate mapping, but since there will be erroneous entries in both databases which won't line up, it's probably more effort than it's worth."
The list of projected GDP in the past?,"
I would like to get any data that predicted GDP in the past (e.g. the projected 2015 GDP that was released in 2000). I don't mind what organization the data was released by, as long as it is prominent (e.g. UN, OECD, IMF, or WB) because I just want to know how the future GDP prediction diverges. 
Can I download those datasets for free? 
","['data-request', 'economics', 'gdp']",
sports-reference.com legality of using their data for other applications [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 7 years ago.







                        Improve this question
                    



I am interested in using sports-reference's data for web modelling and a web application. I was checking the TOS of sports-reference and I can't quite grasp the main idea about the legality of using their data for other applications. Does anybody here have experience with sports-reference data and it's legality of use. Is it fine for me to use their data freely or do I need to get a license from SRL?
","['sports', 'legal']","The TOS are quite explicit you can't use their data without their consent and buy having a license. Any use, reproduction, or distribution of this Site or Content without SRL's advance written consent is prohibited, except, however, you may download one copy of these materials, and you may print one copy of these materials for your use in learning about, evaluating, or acquiring SRL's or its licensees' or licensors' services or products, provided that you include a complete copy of this entire page."
where can I find world-wide commercial flight routes information?,"
I'm looking for a full list of all commercial passenger routes across the world.
","['data-request', 'transportation']",
UK Mobile phone gps location database,"
I working on a system that will be doing spatial calculation across UK - finding users within proximity to some location. What I am after is data that would be a snapshot at certain point in time of mobile device positions across UK (to fine tune spatial grid index in SQL Server). If it's not a snapshot and has data on how people move it's even better, as I will be able to do concentration of people during time of day.
Update: If you have partial data of, lets say one region, of UK that would suffice too.
","['data-request', 'geospatial', 'uk']",
BLS Consumer Expenditure Survey at MSA level,"
I'm trying to get annual data on purchases of televisions at the MSA or city level.
I looked at BLS Consumer Expenditure Survey, but it looks like the MSA-level data is aggregated into coarse categories. The public use micro data, has individual-level data, but it looks like it only has state but not MSA.
Is there a way to get MSA-level total purchases that are not aggregated into very coarse purchase categories? I am interested both in free data like BLS and also potentially private data (so long as it's affordable on a academic research budget 
    ","['data-request', 'usa', 'government', 'labor']",
Are there any open datasets for LinkedIn public profiles?,"
Is there a way to obtain a dataset consisting of LinkedIn data? Is there any existing open dataset for this purpose? If no, can I collect the data using LinkedIn API?
","['data-request', 'api']",
Data on refugee migration,"
Are there any current data sets on the migration of refugees in Europe available? As information seems to be sparse, I don't really care what kind of data. For example, data on migration routes or registration data would be interesting, preferably from the governments or the EU.
","['data-request', 'migration']","Check global-refugees.info's data. It's available as a excel spreadsheet (.xlsx). And they also have some code explaining the process they used for making the visualizations on their website and on github
https://github.com/NikolaSander/refugees/UNHCR database The main source of all the articles and visualizations is this http://popstats.unhcr.org/en/persons_of_concernUNDATASome journalists also use this as their source http://data.un.org/Data.aspx?d=UNHCR&f=indID%3AType-Ref, although many argue that it's basically UNHCR's data afterreported."
Where can I find Nefazadone CBASP dataset?,"
I am searching for data that was collected as part of the job described in the New England Journal of Medicine article A Comparison of Nefazodone, the Cognitive Behavioral-Analysis System of Psychotherapy, and Their Combination for the Treatment of Chronic Depression. 
I have seen many articles that use this data and it seems that this data should be open, but I cannot find it.
All of these articles contains citation to the aforementioned paper. 
Does anyone know where I can get this dataset?
","['data-request', 'medical']",
Kidney transplant dataset,"
I'm looking for raw data regarding kidney transplant or any organ transplant in order to perform a survival analysis with random  effects given by some kind of attributes such as hospital dimension/location.
","['data-request', 'medical']",It seems that some of the information you are looking for is available but not completely out there in the open. Some leads to track down:
weather dataset,"
I am looking for a dataset exactly similar to http://forecast.io/raw/ that gives the values for London in 2015:

temperature
precipIntensity
windSpeed
windBearing
cloudCover
humidity
pressure
visibility
ozone

I am not familiar with programming so please suggest a simple tool.
","['data-request', 'weather', 'uk']",
Income cohorts based on household size,"
I am looking for income cohort data by household size for USA, preferably 2014. This is not available in Census FactFinder and I am not sure where else to look. Could anyone guide me on this, please.
","['data-request', 'us-census', 'income']",
Is there an API for drug approval packages from the FDA?,"
I am building an application where we'd like to reuse information from drug approval packages (Example).
The FDA API does not have a query interface for drug approval packages. Is there an alternative API for this information, via the FDA or otherwise? 
I'd prefer to use an API, rather than writing a scraper for the same.
","['openfda', 'medical']",
How to scrape rugby union data from espn.co.uk,"
This is the site I want to gather data from but I'm really not sure where to start.
http://www.espn.co.uk/rugby/playerstats?gameId=271423&league=271937
",['programming'],
Travel statistics by gender and country,"
Is there any statistics available that includes gender differences? I would like to know the rate of male vs female travelers. For example, something like this:

Country: male%
USA: 48%
Germany: 43%
Japan: 38%
China: 42%

Of course it is sufficient if you can compute it by manipulating the raw data.
","['data-request', 'demographics', 'global', 'travel']","I don't know of a global database but Eurostat does provide some insights into European countries if that is of interest. You can find their tourism database here.If you navigate through tour_dem > tour_dem_tt > tour_dem_ttsd > tour_dem_ttsex you will find what you are looking for. The data is available for viewing in Eurostats interface or as a downloadable tsv. If you want to compare this to expenditure by gender you can find this data in tour_dem_ex > tour_dem_exsd > tour_dem_exsex. The raw tourism data is split into different variables. You will have Personal trips as well as Professional, business trips and Domestic, Outbound or All countries of the world trips. You can also see amount of time spent by 1 night or over, from 1 to 3 nights and 4 nights or overDirect links to the raw data can be found here:Number of trips by country and sex (and type of trip, length of trip, type of destination)Expenditure on tourism by country and sex (and type of trip, length of trip, type of destination)"
Employment data by income at the state level,"
Where can I find data on the number of people employed in each state for each level of income? I need data that includes at least the year 2014, and back to at least 2009.
I would like the following variables:
-income
-state of residence
-employment
-year
","['data-request', 'labor', 'income']","Here it is for 2014 (ACS 2014 1-year) from CensusReporter(.org)* by poverty status: http://censusreporter.org/data/table/?table=B17005&geo_ids=01000US,040|01000US&primary_geo_id=01000USMore information on this topic can be found from CensusReporter at http://censusreporter.org/topics/employment/*The data ultimately comes from Census and you can use their FactFinder tool with this data table at http://factfinder.census.gov/bkmk/table/1.0/en/ACS/13_5YR/B17005/0400000US49"
Domestic accidents due to exploding plates and bowls,"
I am looking for a dataset that lists domestic accidents due to plates and bowls exploding due to heat or other factors, put aside direct human/animal mistake (e.g. we ignore cases where a human dropped a plate).
Ideally, it would contain the year, country, the type of materials used in the plate/bowl, the severity of the injury, and a description of the injury.
","['data-request', 'medical']",
Statistics of the yearly amount of beds in private prisons in the US,"
I'm seeking a list of how many prisoners got incarnated in each year in the US by private prisons compared to state-run facilities. Is such a list publically available?
","['data-request', 'usa', 'crime']","There is tons of data at the US Bureau of Justice Statistcs - CorrectionsBut I think the best way is to get these data points from the two major private prison companies (CCA and GEO Group).Luckily (for you), both are publicly traded - so you can download their annual reports and find all sorts of info about number of beds, and different types of housing.For example, from the GEO Group 2012 annual report (PDF)
So then you just need to download a bunch of PDFs, and then copy/paste into a spreadsheet.CCA annual reports (2008 - 2014) - http://www.cca.com/investors/financial-information/annual-reportsGEO Group annual reports (2001 to 2014) - http://www.snl.com/irweblinkx/FinancialDocs.aspx?iid=4144107p.s. you can get more years of annual reports by contacting to the investor relations department"
Elevation data sources,"
I need to know for example, heights of bridges/fly-overs from the land surface (just to know there is an elevated structure). How and where from can I get this data (preferably for EU)? Any open source databases/ any 3d maps with this data?
","['data-request', 'geospatial', 'europe']",
Access to anonymous personal financial portfolio data,"
Is there a corpus about personal financial portfolios? I.e. data which is anonymous user data and shows financial portfolios for these users.
","['data-request', 'finance', 'corpora']",
How can I download datasets from Twitter and Facebook from an specific event and time period?,"
I need to download a dataset related to the Umbrella movement in Hong Kong from Twitter and Facebook (tweets, hashtags, followers, contacts, etc.).
",['social-media'],
Literacy rates of Asian countries,"
What are the literacy rates of Asian countries (Myanmar, Bhutan, Pakistan, China, Nepal) for last five censuses?
","['education', 'census', 'demographics', 'asia']","I think data.worldbank.org is going to be your best bet for getting this information. Here is a direct link to the indicator for ""Adult literacy rate, population 15+ years, both sexes (%)"" (SE.ADT.LITR.ZS)http://data.worldbank.org/indicator/SE.ADT.LITR.ZSYou can click ""Databank"" from that link to go to a table generator where you can limit your query to specific countries and years."
API for getting data from a disease name?,"
For example, entering: ""lung Adenocarcinoma"" should return (JSON preferably) large chunks of information about that disease, such as definition, alternate names, validity, treatments, signs, etc..
I've tried using the seer API. but I run into an issue trying to get the correct disease identifier. If I try inputting ""lung Adenocarcinoma"" into the disease search endpoint, I get no results.
{
terms: [
""lung adenocarcinoma""
],
total: 0,
count: 25,
order: ""score""
}

","['openfda', 'uses-of-open-data', 'disease']",
Sustainability Contacts for Educational Facilities,"
I am looking for a list of the sustainability contacts at universities, colleges and private schools in New York state.
","['data-request', 'data.gov', 'education']",
"Taxonomy of web pages for illustrating the reach of ""open data""","
I would like to do two things:
First, I want to draw some kind of structure of the web (data) in order to divert discussions about loose term ""big data"" to specific data topics.
Second, within this structure, I want to highlight the subset which is is considered open data.
Does anyone know if there is anything like that (e.g. a taxonomy tree) already available? Any pointer would be greatly appreciated.
E.g., one example structure of the web (data):

social media
a) facebook
b) twitter
...
government data
homepages
a) individuals
b) companies
E-Commerce sites
a) Amazon
b) EBay
...
Blogs 
Weather data

...
Then parts of 2. government data, homepages and weather data could be available as open data...
",['uses-of-open-data'],"I have some links which are useful for my question that I came across after performing a Google search for ""types of web sites"" brought among other these results:https://en.wikipedia.org/wiki/Website
https://en.wikipedia.org/wiki/Social_media"
Dataset of number of car accidents per cause in the United States,"
I am looking for a dataset that lists the number of car accidents broken down by causes in the United States. By cause I mean the direct cause of the accident such as failure to stop at red light, or changing lane without checking for the blind spot. (not the indirect cause such a driving under the influence). Ideally, broken down by year as well.

The Wikipedia page on Epidemiology of motor vehicle collisions contains a list by type of crashes (not cause):

Crashes are categorized by what is struck and the direction of impact,
  or impacts. These are some common crash types, based on the total
  number that occurred in the U.S.A. in 2005, the percentage of total
  crashes, and the percentage of fatal crashes:

Rear impacts (1,824,000 crashes, 29.6% of all US crashes, 5.4% of US fatal crashes)
Angle or side impacts (1,779,000 crashes, 28.9% of all US crashes, 20.7% of US fatal crashes)
Run-off-road collisions (992,000 crashes, 16.1% of US crashes, 31.7% of US fatal crashes)
Collisions with animals (275,000 crashes, 4.5% of US crashes, 0.4% of fatal crashes)
Rollovers (141,000 crashes, 2.3% of all US crashes, 10.9% of US fatal crashes)
Head-on collision (123,000 crashes, only 2.0% of all US crashes, but 10.1% of US fatal crashes)
Collisions with pedestrians and bicyclists (114,000 crashes, only 1.8% of US crashes, but 13.5% of US fatal crashes)
Back-up collisions killed 221 people in the US in 2007, and injured about 14,400. This is one of the most common types of non-traffic auto
  collision in which road workers and children 15 and younger are
  killed.


","['data-request', 'usa', 'cars']",
MIMIC-II Introduction document: errors in example code?,"
I am new to SQL and am trying to explore the MIMIC-II dataset using the query builder so the logical step seemed to be follow the tutorials within the introduction document [1]. Unfortunately I believe it contains errors. The errors start in example 5 with 'missing right parenthesis' in the second part of code and 'missing by keyword' in the third longer piece.
Can anyone more experienced than me see the errors and how to correct them?
Or alternatively does anyone have some good examples of simple code I can learn from and adapt.
To start with I would ideally just like to do some simple things such as age of patients and length of stay looking to then plot any correlation.
Ultimately I am looking to predict mortality and length of stay but I know there are many baby steps required between where I am now and that. If anybody know of similar work carried out that may be useful would be greatly appreciated.
[1] http://mimic.physionet.org/archive/introduction-mimic-ii.pdf
",['mimic-iii'],"I am new to SQL and am trying to explore the MIMIC-II dataset using the query builder so the logical step seemed to be follow the tutorials within the introduction document [1]. The current version of the MIMIC database is MIMIC-III. MIMIC-II is an old version that is no longer supported by the MIT Laboratory for Computational Physiology, so I would not recommend using it as a starting point for your studies. The introduction document that you are using is not current and may well contain errors, particularly as it is a static PDF document that is not well-suited to continuous updates.The errors start in example 5 with 'missing right parenthesis' in the second part of code and 'missing by keyword' in the third longer piece. Can anyone more experienced than me see the errors and how to correct them?The second chunk of code in example 5 reads:The code runs as expected for me when tested against MIMIC-II v2.6 in an Oracle database (it returns 36,095 rows). It is possible that your error is a result of copy and pasting (weird things can happen when you copy and paste from a PDF!). SQL syntax varies between database systems (Oracle, Postgres, MySQL, ...), so this could be another source of error. Note that while the semicolon (';') is generally required at the end of an SQL query, the (outdated, unsupported) MIMIC-II querybuilder returns an 'invalid character' error unless it is removed.Either way, I wouldn't recommend treating the code snippet as best practice because it uses old-style comma syntax to join the admissions and d_patients tables. It is generally considered better practice to use the join keyword.The third code chunk in example 5 reads:This code also runs as expected for me on MIMIC-II, and also returns 36,095 rows. I can't explain your 'missing by keyword' error, but it may be a copy and pasting issue here too. To start with I would ideally just like to do some simple things such as age of patients and length of stay looking to then plot any correlation.If you would like to explore the MIMIC database, the first step is familiarising yourself with the current MIMIC website and documentation. Content in the ""archive"" directory should only be used if you have specific reasons to refer to old content (for example, you are attempting to reproduce a study which used previous versions of the MIMIC database).After installing the latest version of MIMIC-III by following the instructions on the website, I would recommend referring to the MIMIC Code Repository for sample code. There is a direct link to the repository on the front page of the MIMIC website.The code repository is being developed continuously by the MIMIC research community. It includes a MIMIC Cookbook directory that contains introductory queries to get you started. Once you become more confident with SQL then we encourage you to make your own contributions to the repository."
Retrieve US Census Data in Excel format,"
I am hoping you could help me find some information. I am trying to pull census data such as (age median, race, sex, weather) however I want it in a excel spreadsheet type format. I am unsure if API and census data can be formed to create something, if there is something already out there to do this, or if there is somewhere I can get this raw data. I am trying to find this data for various cities and states.
Thank you
","['api', 'us-census', 'census']",
OpenFDA report_date for Food/Enforcement doesn't seem to work after 9/23/2015,"
I am getting 0 results for any ranges after 9/23/2015. 
See last day of results here: https://api.fda.gov/food/enforcement.json?search=report_date:[20150923+TO+20160106]
No results from 9/24 on: https://api.fda.gov/food/enforcement.json?search=report_date:[20150924+TO+20160106]
Did the report_date property become deprecated? I am using report_date in my site's (https://defender.ionep.io) queries to get the previous 90 days -- reporting 0 results at the moment.
Also you can see in the example enforcements graph there are no results after 9/2015 https://open.fda.gov/food/enforcement/
",['openfda'],"Thanks for catching this one. It is true for all of the enforcement endpoints (food, drug and device). The link on the FDA that we are crawling is dead (it hangs). There is a bug in pipeline code that shows the enforcement step as complete even though the download of the XML file is timing out. I will get that fixed right now. I will also contact the FDA to make sure they know about the broken link. Once the link works again, I re-run the enforcement pipelines retroactive to 2015-09-30 (they are weekly reports).Thanks again. UPDATE: Please note that this bug has been fixed and the data has been reloaded so that it is up-to-date. 
https://api.fda.gov/food/enforcement.json?search=report_date:[20150924+TO+20160106] now yields results."
Active Fast-Flux Domains,"
I am looking for fast-flux domains that are currently active so I can train a model that I build. I found this so far: https://atlas.arbor.net/summary/fastflux but it is outdated. 
",['data-request'],
How do I get just city-level data on data.gov?,"
I want to get all the datasets with this icon next to them - how do I go about doing this ?

","['data.gov', 'extracting']","Below is the link to city level datasets in data.govhttp://catalog.data.gov/dataset?groups=local&organization_type=City+Government#topic=local_navigationYou will see there is only 2600 datasets, so there is still alot of city datasets not accessible from data.gov. In these cases, you will need to go to the city's own open data portal.You can find a fairly extensive listing (links) to open data portals at the [US] city level the link below. This is a crowd sourced project for cataloging government data portals throughout the world.http://www.opengeocode.org/opendata/"
Global Precipitation Measurement (GPM) data download in R,"
I would like to know if resources exist for downloading GPM data in R. I'm aware of the Hydrological Data Discovery Tools (""hddtools"") package, which can be used for accessing Tropical Rainfall Measuring Mission (TRMM) data but does not include a library for GPM.
","['data.gov', 'programming']",I created a function to download data IMERG HDF5 and convert them to raster GeoTIFF. You can see the code in https://github.com/AybarCL/GPM-data-management
Looking for zip codes and elevation of high schools,"
I'm researching United State zip codes and elevation. Specifically high schools elevations in US.
","['data-request', 'data.gov', 'geospatial', 'education']",
Retrieving Every Amazon Product ASIN,"
I am looking to retrieve every ASIN in Amazon's product database. In setting up a sample scrapy web scraping script - it became clear that crawling is not the efficient solution.
Looking at answers about the Product Advertising API I found a similar question: Amazon ASIN and Category
If the goal is to retrieve all of the physical products currently listed on Amazon is the following method the most efficient:

Get List of All Parent Categories
Find List of Sub Categories of the Parents (http://www.amazon.com/gp/site-directory/ref=nav_shopall_btn)
From that list of all sub categories that I am interested in use the Product Advertising API to find the ""browsenodes"" of each.
Use a recurring loop on each browse node until there are no more children nodes
Use that list of categories with api's ItemSearch to return all of the ASIN's in that node

This would be run as a python script - due to the immense number of categories/subcategories/sub-sub-categories and ultimately ASIN's I know this will be a huge collection of product ASINs.
Is there a resource that already has this information? Or is the usage of Amazon's API the most efficient method?
","['data-request', 'api']",
"Is there a data source indicating how long most major surgeries take, and what are the associated risks/outcomes?","
I'm looking to play around with statistics around major surgery types; is there a publicly available data source I can work with which lists information such as:
types of major surgeries, together with amount of time per procedure (average, standard deviation, broken down by complication, etc...)
risk information to any level of detail
any sort of other aggregate information
Any data set would be interesting (ie, for any geographical region or legal jurisdiction - i know some of this info might be harder to collect in say the US than elsewhere)
",['medical'],
List of United States cities,"
I'm looking to get some data of this page
http://www.greatschools.org/california/san-francisco/schools/?gradeLevels=e&page=2
To do it I need to create the links in this format:
http://www.greatschools.org/'state'/'city'
So at first I need to have a list with all the US cities sorted by state, where can I find that data? Preferably in .csv format or some other machine readable format (I am using Python).
","['usa', 'openfda', 'city', 'python']","I have a CSV file you can download that lists all US cities by state. The data was compiled from the US Census 2013 Gazetteer.http://www.opengeocode.org/download.php#statecity In case you must have the data from that domain, each state's information is listed on the states index pagef, and follows similar naming conventions. For example, here's Virginia's index page:
http://www.greatschools.org/virginia/
All Cities in Virginia:
http://www.greatschools.org/schools/cities/virginia/VA/
All School Districts in Virginia:
http://www.greatschools.org/schools/districts/Virginia/VA"
Open data set to calculate the correlation between different brands,"
Is there any data sets / methods available to find correlation between different 'bands' ?
Brands : Puma, Google, Microsoft, Nike, BMW etc
Is there any open data set available to find this correlation ?
Also what are the different attributes/ methods that can be used to find correlation between them ?
eg : Nike is similar to Adidas with score say 0.9 (fitness brands)
     Nike is similar to Levis with score say 0.3 (apparels brands)
     Nike is similar to Google with score say 0.0 (different industry)
","['data-request', 'tool-request']","You should clarify your question, maybe giving more details about the application. There are many different ways a brand can be similar (or correlated) to another one, for example:"
Test data set for calendar data,"
Is there anything comparable to the Enron Corpus, but for calendar data? I already do text categorization based on Enron Emails but I would like to combine my approach with other business data, preferably calendar data which correlate to the mails.
","['data-request', 'machine-learning', 'calendar', 'email']",
List of complex datasets for ML in the cloud comparison,"
I'm looking for complex datasets for performing a comparison on machine learning in the cloud solutions such as Amazon Machine Learning, Microsoft Azure, IBM Watson, Google Prediction API, Rapid Miner and some others.
In particular I will try the blackbox prediction (and/or classification) capabilities offered by some of these systems, and compare it with state of the art results. SaaS such as Google Prediction API say they can pick the best algorithm for our problem; I'm analyzing how well do they perform in order to compare them with the closeness to state of the art results and some other further analysis.
It's hard to define complexity for this case, however I'm looking for datasets that have available results for at least 3 different algorithms, and where at least 1 has shown considerably bad performance (e.g. accuracy or error) in comparison with the best one. Size of the dataset will not be an issue. Following this idea complex would mean that there exists bad performing typical approaches that are considerably worst performing than the best solution.
Where should I look for that can have multiple algorithm results both well and bad performing? Any datasets recommendations?
PS: Naturally I would need datasets for supervised learning.
",['machine-learning'],Have a look at this great tour-de-force study by Manuel Fernandez-Delgado at JMLR. They ran lots of classifiers against plenty of data sets from UCI. I believe you will find everything you need. hth
PlanFinder API Data Availability,"
Planfinder API-
Can you let us know if any of the data in the planfinder API will expire? (Will 2015 data be replaced by 2016 data or will the API continue to hold both years of data?)
",['healthcare-finder-api'],
American English pronunciation dictionary in text form showing syllables,"
Looking for pronunciation and syllabification data for American English.  I want to analyze pronunciation and spelling rules/heuristics to see how accurate they are and identify exceptions.  The goal is to help English as a Second Language students.  Rule example: most English words have the accent on the second-to-last syllable.
If it's useful I would make it available to others.  No commercial ambitions for now.
The CMU Pronouncing Dictionary (http://www.speech.cs.cmu.edu/cgi-bin/cmudict) has 133K pronunciation entries but without syllabification.
I plan to use data from http://www.wordfrequency.info/ to limit the analysis to the most frequent words (20K?  30K?).
Thanks.
","['data-request', 'language']",
Where can I get a sample dataset for A/B split testing?,"
I'm working on A/B split testing now. Where can I get a sample dataset for A/B split testing?
","['data-request', 'programming']",Based on the answer for this question on Cross-validated there are two great packages in R that include useful datasets from completed A/B and multi-variate tests: Agricolae and Agridat
Mapping between mimic-iii clinical data and mimic II V3 waveforms,"
How can I map between a subject id and and its waveform record id in the mimic II v3 DB?
For example, what is the waveform record id of a patient with subject_id = 8915?
In the previous MIMIC II Waveform DB I found that this patient mapped to case_id = a44193
",['mimic-iii'],
Resources on Data Science for Football / Soccer in-line?,"
Similar question was already asked in https://datascience.stackexchange.com/questions/6201/resources-on-data-science-for-football-soccer, but I am looking for historical data of off-line + in-line matches.
I know few portals that provides coefficients during the game:

http://www.oddsportal.com/
http://www.betbrain.com

However, I would be very appreciated for advise where I can find resources with already saved in-line historical data for soccer matches.
","['data-request', 'sports', 'historical']",
Free quad polarization SAR images of San Francisco in bands X and L?,"
For comparing the results in my scientific article I need quad polarized sample data for San Francisco in bands C(RADARSAT-2), L(probably ALOS-PALSAR) and X(probably TerraSAR-X)

Up to now I have downloaded band C of this data from GEOSPATIAL SERVICES INTERNATIONAL but I don't know where can I download the X and L bands of the same area?
","['data-request', 'usa', 'geospatial', 'city', 'research']",
Proxy access.log file or dataset,"
I'm a undergraduate student and I am doing a study relating to replacement algorithms that requires the access.log of proxy systems. I have searched for access.log datasets for this purpose on the following links:  

Data.Gov 
Socrata 
Programmable Web 
UCLA Dept of Statistics 
“Let Me Get That Data For You”

But I couldn't find anything that meets my needs. Are there any sites that provide proxy access.log datasets? Help would be most appreciated.
",['data-request'],
Amazon price history dataset,"
Are there any datasets on Amazon products' price history? http://camelcamelcamel.com/ doesn't make it available and the Amazon Product Advertising API doesn't seem to give access to the price history.
","['data-request', 'historical', 'products', 'prices']",
Is there any public dataset related to fashion objects?,"
I'm looking for large datasets of images related to the fashion industry. It could be garments or people in the street wearing some dress or models. I saw a related post but it's very general and does not contain any reference to the industry I'm interested in. Any idea???
","['data-request', 'machine-learning', 'fashion']",
How can I find state level data on NLRB 81a3 cases,"
I'm having the biggest trouble downloading XML files from the NLRB.  I'm interested in state-level numbers of NLRB ordered reinstatements for 8.1.a.3 ULP cases.
",['data.gov'],
Data sets for predicting home value,"
I'm working on a project for predicting the cost of houses. I'm looking for data sets enumerating the number of schools, hospitals, parks and any other condition that may affect the price of houses (e.g., crime rate). Ideally, the data set should include zip codes information. Can anyone point me to a good resource for this?
I'm looking for recent data, not more than 5 years ago, would be great if it's already organized but if not I can scrape, just need to know where it is.
","['data-request', 'web-crawling', 'big-data', 'real-estate']","You're probably going to need to get information from many jurisdictions - at least in the US, there is not a good/granular sources for property tax, crime, and other information for all states in one dataset.For crime data, check out FBI UCR reports which are usually not granular. Each city may (hopefully) report their own data. Try google and/or http://opendatanetwork.com (a search engine for open data)**.For hospital and school data, national datasets may suffice.You can find CMS/Medicare certified hospitals (most in the US) in a list at 
https://data.medicare.gov/Hospital-Compare/Hospital-General-Information/xubh-q36uhttps://nces.ed.gov should have school-level location data for you as well.I would also suggest checking out aggregators like Trulia.com, Zillow.com, and WalkScore.com. They all have APIs if I remember correctly but with limits on access as well as data use.** I help run this site at work (Socrata.com)"
Required a audio format baby crying data set,"
For my undergraduate research project, I'm trying to train my system with infant child crying frequencies and predict the reason for a new baby crying sound. I'm following this journal  and they are using 78 different crying sounds manually collected from 31 babies by paediatricians. I'm trying to train the system in five different categories:

HUNGRY
SLEEP
PAIN
NEED TO BURP
UNCOMFORTABLE

for now, I'm working with very little data collected online.
I'm looking for a good dataset for more than 4 months. The dataset should have more than 50 data with labels (the categories I mentioned above ). If anyone knows a good source please help me out with this hurdle. Looking for a public dataset. but even a paid version won't be a problem.
","['data-request', 'audio']",
MIMIC-III: When exactly was MIMIC-III v1.3 released?,"
What is the release history for MIMIC-III?
I was using some version and now I see there is version 1.3.
When was 1.3 officially released?
When was 1.2 officially released?
Are there other versions?
Do you expect a new release very often? Or will now the time between releases be longer?
",['mimic-iii'],"When was 1.3 officially released? When was 1.2 officially released?MIMIC-III v1.3 was released on 10 December 2015. MIMIC-III v1.2 was released on 20 November 2015. What is the release history for MIMIC-III? Are there other versions?The first version of MIMIC-III v1.0 was made available on 25 August 2015. For an outline of the release history for MIMIC-III, see the release notes page of the MIMIC website.Do you expect a new release very often? Or will now the time between releases be longer?We expect MIMIC-III to become increasingly stable over time, with progressively long intervals between updates. We do however plan to make releases for as long as there are bugs and usability issues to be addressed and there is new data to add."
Where can I find biological time series data?,"
I'm looking for datasets for biological systems that have been modelled by systems of ODEs (or more general biological time series data). I can't even find a simple predator-prey dataset (from a legit source). Where can I find biological data (ecological, protein concentrations, etc vs. time)?
","['data-request', 'time-series', 'biology', 'population']","You can find data related to the Canadian lynx and snowshoe hare pelt-trading records of the Hudson Bay Company, starting in 1845. It seems to be a standard dataset, described for instance in Predator-Prey Models.The base repository is Lynx and Hare Data, and you can find for instance the csv file lynxhare.csv. The Lotka-Volterra Models for predactor/prey pairs have apparently been used here and here, for instance. Run, hare, run."
"Government standards, guidelines, and practices for collecting data","
By standards, guidelines, and practices for collecting data I mean the rules that facilitate:

Practical value: Collecting data with a specific goal in mind
Data integrity: Minimizing omissions and biases
Infrastructure: Integrating the data into decision making

National census and household surveys meet these requirements, and so do other data collected by the federal government and universities.
Almost each agency has some guidelines for dealing with information. Examples:

BEA (many references). Google ""site:bea.gov filetype:pdf data collection guidelines"". E.g.: Information Quality Guidelines and Statement of Commitment to Scientific Integrity.
Office of Management and Budget, Standards and Guidelines for Statistical Surveys
FBI, Data Quality Guidelines
SEC, XBRL

My questions are:

What are the standard references for these purposes?
Have any standards been updated to account for big data, like for recording those NYC taxi trips or 311 calls?

","['government', 'releasing-data', 'data-format', 'standards']",
Historical world records,"
Is there a place where I can get world records going back as far as they have been measured, and also see when there was a new world record holder?
For example, if the world record for the mile run was 5:00 in 1900, then it was beat in 1905 at 4:58 etc.
","['data-request', 'sports']",
"Reliable source for getting free land use map for Ahmedabad city, India?","
Could you please help me to find out the land use map for Ahmedabad city, India preferably in GIS format (Shapefile).
","['geospatial', 'india']",
How to output the description of Wikidata items using SPARQL?,"
I am trying to output a table using query.wikidata.org and SPARQL, with the name, birthdate, and brief description of notable, living Americans (i.e. those with wikidata entries) who will turn 100 years old between January and June 2016.
I've cobbled together some code which seems to be working, but I can't figure out how to output the description of the people.
For example, one of the people the code grabs is Beverly Cleary, whose wikidata description is ""American writer of children's books."" I would like to print that in the table.
Any help is much appreciated; code below. Thanks so much.
--
prefix wdt: <http://www.wikidata.org/prop/direct/>
prefix wd: <http://www.wikidata.org/entity/>
SELECT ?Name ?Birthday WHERE {
  ?item wdt:P569 ?Birthday .
  FILTER ( ?Birthday >= ""1916-01-01T00:00:00Z""^^xsd:dateTime && ?Birthday <= ""1916-06-01T00:00:00Z""^^xsd:dateTime )
  ?item wdt:P27 wd:Q30 .
  OPTIONAL { ?item wdt:P570 ?dummy0 }
  FILTER(!bound(?dummy0))
  OPTIONAL {?item rdfs:label ?Name filter (lang(?Name) = ""en"") .} 
}
ORDER BY ASC(?time0)

","['wikidata', 'sparql']","I am far from expert in this, but your question motivated me to learn a little, and I have a solution, below.In short, there is a ""label service"" which can be added to the WHERE clause. By simply adding it, you get access to the label, altLabel, and description of items in the query.  There seems to be more nuance, but I'd be fooling if I tried to explain it..."
MIMIC-III severity score,"
Is there any severity score in the MIMIC-III beyond SOFA? I've found many itemdid with APACHE IV label but I did not retrieve any information in the chartevents. Best
",['mimic-iii'],"While you might find itemids for various severity scores such as APACHE IV in the hospital data, there will be few associated values. This is because the scores are rarely calculated or recorded by caregivers. Most of the scores are computed retrospectively by the MIMIC research community. Code for generating scores will be collaboratively developed and shared via the MIMIC Code Repository."
Knife deaths by country per year,"
I am trying to find the number of knife deaths and/or knife attacks by country per year.  There are many sources for gun deaths, but strangely not any that I could find for knife deaths.  
",['data-request'],"You can download crime/murder statistics that are classified by ""mechanism"" from the United Nations Office on Drugs and Crime.Data portalOn the left menu sidebar, choose ""Crime and Criminal Justice""Then select ""Homicide""Then select ""Percent of homicides by mechanism (2005-2012)Create an XLS export (here's a direct link)The term they seem to use is ""Sharp"" for knife deathsNote that there are some other potential categories, so you may find better data sets by digging around."
MIMIC-III. Select only the first ICU admission,"
How can I select data only for the first ICU stay of each patient? In the MIMIC-II, there was a column with the sequence of ICU stay (first, second) and another column with the icustay_id. In the MIMIC-III, icustay_id does not appear to be a good identifier. For example in the prescription table, there are many rows with subject_id but no icustay_id.
",['mimic-iii'],"Patients may move between various care units over a single hospital admission. MIMIC-III provides significantly more detail than MIMIC-II about these movements thanks to the addition of the transfers table. As noted in the MIMIC documentation, icustay_id is an identifier that has been generated using the transfers table for convenience of analysis. The hospital and ICU databases are not intrinsically linked and they do not share the concept of an ICU encounter.""In the MIMIC-III, icustay_id does not appear to be a good identifier. For example in the prescriptions table, there are many rows with subject_id but no icustay_id.""Many of the entries in the prescriptions table do not have an icustay_id because the order times are not easily associated with a single ICU stay. For example, many prescriptions do not occur while the patient was in the ICU. In these cases it could be misleading to associate the order with any one particular ICU stay, so the icustay_id field is null.""How can I select data only for the first ICU stay of each patient?""Code has been shared in the MIMIC Code Repository for creating an icustay_detail table. The table includes an icustay_seq column which would allow you to select only the first ICU stay for each patient:To ensure that relevant data is included from sources like the prescriptions table, you could select data for these icustay_id using the subject_id along with restrictions on the intime and outtime. Whether or not you would like to include data in your analysis that occurs beyond the time of the ICU stays is a question that you might also want to consider. "
MIMIC-III Elixhauser comorbidity table,"
How can I obtain a table containing the 30 Elixhauser comorbidities for patients in the MIMIC-III database? Did anybody already run the code in the MIMIC-III forum?
",['mimic-iii'],
US Residential Mailing Addresses Databases,"
What I'm looking for I can almost guarantee I won't find openly available anywhere but I'll try anyway.
Simply, I'm looking for a list of residential addresses of a given county or city/municipality in the USA for personal use. I can't find anything like this without shelling out huge bucks.
","['usa', 'geospatial', 'api', 'address']","OpenAddresses.io does not have nearly 100% coverage but you may get lucky: http://results.openaddresses.io/Open Street Map (""OSM"") is another potential source: https://gis.stackexchange.com/questions/121266/extracting-list-of-addresses-in-particular-region-from-openstreetmap-osm-dataOne less expensive option may be to buy voter registration lists from jurisdictions which will have less coverage but also be less expensive than traditional marketing lists, it seems."
Corpus of documents with important sentences marked,"
I'm looking to create a sentence extraction program, so a program that aims to get the most important sentences from a body of text. The first step for me is to try to evaluate what characteristics important sentences share, and how they are different from non-important sentences. 
As such, I am looking for a corpus of documents which have the most important sentences somehow marked. I already have some metrics in mind, and I would like to do inference on how important each of those metrics are in distinguishing the interesting from the filler, and so need some data. 
Edit: I believe that it defeats the purpose to use the results of a different sentence extraction program, and am instead looking for the results of human work.
",['corpora'],"I actually ended up paying folks on MechanicalTurk to label questions as important/unimportant from a couple of news articles I downloaded. There are 410 sentences total, which I have on my github here. "
Does Google correlate stop for Belgium in 2014?,"
I calculated for each week in 2013 and 2014 the proportion sales amount of kids shoes to the total sales for a shoe shop in Belgium. Then, on [google correlate][1], I looked for correlated search terms.
I found significant results in the US (mainly soccer related) and the Netherlands (mainly children clothes related). In Belgium, I find significant results for my 2013 data (specifically September), but if I supply my 2014 data too, it finds nothing. If I supply only my 2013 for a search in the US or the Netherlands, I see the data for the correlated term is displayed for 2014 too, but not for Belgium.
What could explain this?
",['europe'],"I think this might be due to insufficient data or a change in Google's algorithms because there is data for Belgium when you search for mentions of the word ""google"": https://www.google.com/trends/correlate/search?e=google&t=weekly&p=be ; If you search for other words like ""election"" and ""vote"", the data for the second half of 2013 through present day for Belgium does appear flat/empty.Bottom line: it seems to depend on the word/phrase you are querying."
Lake Victoria bathymetric data,"
I am trying to find bathymetry for Lake Victoria (or portions).
Any GIS format and almost any resolution will do.
As a last resort a hydrographic chart will suffice.
https://gis.stackexchange.com/questions/116738/lake-victoria-bathymetric-data
",['geospatial'],"I made my own from 10,000 points. http://bit.ly/LV_Bathy is the URL."
Is there any data set for querying labor certification data?,"
Is there any dataset for querying data available in the Labor Certification registry (https://icert.doleta.gov/index.cfm?event=ehLCJRExternal.dspQuickCertSearch)
",['labor'],
Is there anything like Quandl for social sciences or health services research? [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 7 years ago.







                        Improve this question
                    



I would love to see something that gathers all the public data, as Quandl does for finance and macroeconomics, but for social science and health services research in general. I am aware of www.asdfree.org but I'm asking for something as user friendly as Quandl.
","['uses-of-open-data', 'survey']",
California Private School Data,"
Where can I find California's private school data? I'm specifically interested in exploring whether or not these schools are offering Computer Science education formally–and informally. 
","['data-request', 'education', 'computing']",
MIMIC-III inputevents MV or CV,"
An intravenous drug that is not continuous appears to be in the inputevents_mv table but not in the inputevents_cv table. Is it right? How can I work with the full dosage of medication?
",['mimic-iii'],"Two different ICU data management systems were in operation over the period of data collection: Philips Carevue (pre ~2008) and IMDSoft Metavision (post ~2008). The structure of the data collected by these systems is fairly different, so we have provided two separate tables rather than a single merged one. The tables are inputevents_cv (Carevue) and inputevents_mv (Metavision). For an overview of how to work with these tables, please see the MIMIC-III documentation: http://mimic.physionet.org/mimicdata/io/#inputsHow can I access the dosage per day of furosemide received?The principle is similar for both the inputevents_cv and inputevents_mv tables, though the inputevents_mv table provides more detail (e.g. start and stop times). Your question specifically mentions difficulty in finding data in the inputevents_cv table, so I will use this as an example.First you need to find the appropriate itemids using the d_items table. Concepts have not yet been mapped between systems, so a single concept may be associated with multiple itemids. Using the example of furosemide/Lasix:So for inputevents_cv the itemid of interest is 30123. We can search for data for a sample patient using the query below:The rate column indicates when the rate of delivery was set or updated, so in this case the rate remained at 20mg/hr throughout the period. The amount column indicates the quantity of medication that had been received by the associated charttime. For rates, the charttime corresponds to a start time (when the drug was set to that rate). For amounts, the charttime corresponds to an end time.Summing the amount gives the total amount delivered over the time period (in the above example, 20mg * 5 = 100mg). While no start time is available in the Carevue data, the start time can often be inferred from the rate. In this case, given that the rate of delivery is indicated to be 20mg/hr at 2.30pm and the amount delivered at 3pm was 20mg, it would be reasonable to assume that delivery began at 2pm."
MIMIC-III prescription problem,"
How can I sum the full dose of a medication in the dose_val_rx column in the prescription table? I had tried to sum(dose_val_rx) nbut it does not work.
",['mimic-iii'],
"Is there a dataset on existing flow of people between US cities?(could be car, bus, train or plane)","
I am working on a project and would love to see in a year how many people go from one city in the US to another. I know this is fairly extensive and might require putting together multiple sets.
","['usa', 'traffic']",review the codebooks forhttp://www.asdfree.com/search/label/national%20household%20travel%20survey%20%28nhts%29andhttp://www.asdfree.com/2012/12/analyze-american-community-survey-acs.htmlnhts has day-to-day travel movement.  acs has migration info
Historical NWS GFS forecast data,"
The National Weather Service (NWS) makes the results from its Global Forecast System model (GFS) available for download as GRIB2 files.
While accessing current (or recent) forecasts is straight-forward, I am looking for the archived forecasts over at least the last year, better multiple years back for the purpose of statistical analysis of predominant weather patterns in certain areas.
Does anybody know how to access this information?
",['weather'],
Independent Census Data for 3rd World Countries,"
A standardized dataset for 3rd world countries, preferably younger than 10 years.
","['data-request', 'data.gov', 'census']",
A global database of email addresses,"
Does anyone know of an open database of email addresses and meta data on the owners (not personal information)?
The sort of data I'm looking for has more to do with spam scores, creation date and other indicators that will help me determine the credibility behind an email address.
Please note that I am not looking for names, age, sex and other similar personal information...
","['data-request', 'email']",
Patient admitted to ICU after cardiac arrest (post cardiac arrest) in MIMIC-III,"
How to select patients in the MIMIC-III database admitted to ICU immediately after a cardiac arrest? Although ICD-9-CM 427.5 is related to cardiac arrest, it is unclear to select the patients admitted in the context of a successful resuscitation also called ROSC (return of spontaneous circulation). Patients with a successful resuscitation in the medical history can be admitted to ICU in the context of another event. 
","['uses-of-open-data', 'mimic-iii']",
Statistics on the number of seats per car,"
I am looking for some data on the (average) number of seats per car. I know one could assume such number to be 5, but I would like to have some statistics to support such an assumption.
",['transportation'],
List of political blogs,"
I'm analyzing political texts and I need the writings of random political authors.
So far I found a dataset of four political blogs normalized for text analysis. But that's not enough.
I thought about RSS of political blogs. Feedly and Wordpress have these categories, but no convenient way of extracting RSS feeds or even the list of the blogs. The same for Dmoz.
Do you have any ideas where such a list of RSS feeds (or blogs) might be? Or only crawling may help?
","['data-request', 'web-crawling', 'text']",
Affirmative action data for college admissions,"
Is there data out there on college admissions by race, entry GPA, SAT score, major, and ideally earnings after graduation?
Does such a dataset (or datasets) exist? Any standard format would be useful (csv, xml, accdb, mysql backups, etc).
I know of some summary tables (for example those that are at the end of The Shape of the River) but I am looking more for more raw data.
","['data-request', 'education']",
People check-in Dataset,"
I am looking for people's check-in data, whether it's google history location dataset or Foursquare check-in dataset. Would you please let me know where can I find similar datasets ?
Apparently a lot of interesting studies have been going around academia but I couldn't find anything to download.
","['data-request', 'uses-of-open-data']",
Initial public offerings,"
All pre-IPO companies fill the SEC form S-1. It mentions underwriters, offering price, executives, and financials. Example for Etsy.
This information is available via SEC and elsewhere, but not structured.
Have you seen a structured dataset of these forms or other IPO-related information online?
","['data-request', 'usa', 'finance', 'companies']",
List of all UK sports clubs,"

Hi Friends,

I'm looking for a list/ database containing a list of all UK sports clubs. Not just the community amateur sports clubs (CASCs) hosted by HMRC. Their status as professional or amateur, their geographic or sport distribution, or anything else is irrelevant. Just a list of identifiers would be great.
Any help? Much appreciated.

Big data guy.

","['data-request', 'data.gov', 'sports']",
"Where can I find natural language artifacts (requirements document, design documents, change requests) of open source software?","
I am working on cleaning various natural language artifacts of open source software. I was able to download mailing list archives.
Can anyone suggest where I can get other artifacts such as IRC chat messages, requirements documents, design documents, and change requests?
","['data-request', 'machine-learning', 'uses-of-open-data', 'nlp']","Thu Ubuntu linux distribution is developed in the open. You might already know that not only the source code of the linux kernel is open-source (and of course developed by a whole lot of other people unrelated to ubuntu), but the  design process of the userland tools, of many libraries, services, and desktop environment is also somewhat open.Go to the development platform launchpad.net (you might need to register to get access to more features), and then at Ubuntu Blueprints you can see a sortable table. Click on  column head ""Delivery"" (= Completion status). For the completed items, often a lot of design documents, requirements, review docs, bug reports, etc are listed or linked. Maybe pick an item that is easy to understand, e.g docs concerning implementation of the ""Ubuntu One music store"", (now gone).For newer items, less is available. "
Where to get average US profit by industry?,"
I'm looking more for average profits of small businesses per year, which are 99.7% of the US businesses, as defined by the SBA. The BLS.GOV website has a lot of data by industry, but I couldn't find any data on average profits by industry. Hopefully I'd like to see profits going back to 2007. I'm a Perl programmer so I plan to read this raw data and analyze it myself by industry. 
Thank you.
",['business'],
Downloadable word embeddings,"
I am looking for downloadable word embeddings (a.k.a. word vectors, distributed word representations). I'm aware of:

word2vec
GloVe
SENNA

as well as the retrofitting tool.
What else is available?
","['data-request', 'nlp']",
Information retrieval problem,"
I am doing some work on emotions and the web. To do this I need some data on search queries that relate to the user's emotion. For example songs. Can anyone give me a source for this kind of data?
","['research', 'search-engine']",
Where are the rich and poor living?,"
Where to find a raster data set with population density and GDP per capita (global)? Earlier examples use an even distribution of GDP per capita, which makes no sense if you want to compare other indicators in relation to income inequality. The resolution should be 1 degree or less. The goal is to see where rich people live and where poor people live. I am familiar with the GPWv3 dataset. 
","['geospatial', 'population', 'gdp']",
Is there a OpenFDA API Basics for medical devices?,"
Reading the documentation of OpenFDA fields, we are linked to the API Basics reference guide. Every time that I try to find information about API fields (including other questions on this site) I end up landing on that same page.
Unfortunately (to me) the NDC sections explains some dataset fields that are used to annotate records in openFDA regarding drugs. I can't find a similar thing for devices.
Is there a API or field list for medical devices related information?
","['openfda', 'uses-of-open-data']",
Do the College Scorecard's debt amount variables include only debt among students who borrowed?,"
Do the College Scorecard's debt amount variables represent debt among only students who borrowed, or debt among all students (whether they borrowed or not)?
",['collegescorecard'],
Do repayment variables in the College Scorecard refer only to debt acquired as an undergraduate?,"
Do the repayment variables in the College Scorecard refer only to debt acquired as an undergraduate, or do they include debt acquired in graduate programs as well? Also, do they refer only to debt acquired by students at a particular institution, or do they include debt acquired by students at other institutions as well?
",['collegescorecard'],
Is it possible to get a complete list of medical devices through OpenFDA?,"
I was trying to get a complete list of medical devices through openFDA, but then I came to realize that through that data set the list can never be complete, since I can only get devices involved in a event report. 
If I run https://api.fda.gov/device/recall.json?count=openfda.device_name.exact I will never get, for example, a tongue depressor, if a tongue depressor has never been involved in a adverse event.
I was going to try by getting device's categories, such as https://api.fda.gov/device/classification.json?&count=medical_specialty_description and then running queries to get devices by medical_specialty_description or similar field, but I'm still reading the site's documentation, trying to learn about heir API and lists of terms available for searches
How, if it is possible, can a get a list of medical devices permitted by the FDA by  using openFDA?
","['openfda', 'uses-of-open-data', 'medical']",
Flight Plans filed with the FAA,"
Various apps such as Window Seat can access the flight plans that aircraft -- specifically airline flights -- have filed with the FAA.  This is NOT about delays, nor about flight tracking, but things like the proposed departure time, the filed route of flight (shown on the Window Seat front page, starting with ""SFO8 SFO SAC J32 BAM...""), and the filed altitude.
While the FAA has various APIs and sources of data, I haven't been able to locate a way to access this information.  I realize that various flight tracking services such as FlightAware offer this and a great deal of other data by subscription, but it would be nice if I could get it from the source rather than paying a third party for it, and since apps like WindowSeat seem to get access, it looks like it should be available somewhere.
","['data-request', 'usa', 'transportation']",
Physician notes with annotated PHI,"
I am looking for a data set of physician notes with annotated PHI (protected health information) as defined in Health Insurance Portability and Accountability Act (HIPAA)'s de-identification guide (US regulations). I.e. the following information are considered as PHI:
(i) Names of patients and family members
(ii) Addresses and their components
(iii) Dates (month and day parts, unless the inclusion of the year part identities an individual to be older than 90 years old)
(iv) Explicit mention of ages over 89 years old
(v) Telephone and fax numbers
(vi) Social Security numbers
(vii) Medical record numbers
(viii) Health plan beneficiary numbers
(ix) Account numbers
(x) Certificate or license numbers
(xi) Vehicle identifiers and serial numbers
(xii) Device identifers and serial numbers
(xiii) Electronic mail addresses
(xiv) Web universal resource locators (URLs)
(xv) Internet protocol (IP) addresses
(xvi) Biometric identifiers
(xvii) Full face photographic images
(xviii) Employers
(xix) Any other unique identifying number, characteristic or code

","['data-request', 'medical', 'nlp']",
OPTIONS request failing to api.finder.healthcare.gov from the browser?,"
Is anyone successfully making requests to the healthcare api from the browser? I can do it successfully from the command line, or from the Postman REST client (which has special Chrome permissions). But if I try to do it from the browser using just $.ajax, it gives me a 501 on the preflight OPTIONS request. 
I couldn't see anything in the documentation about an OPTIONS request. Anyone else run into this?
",['healthcare-finder-api'],
"data.gov CKAN API ignores row parameter, returns duplicate results for different search terms","
Using the data.gov CKAN api, this search via the web GUI returns 566 results: children
However, post requests via the CKAN API returns 10 results despite the row parameter being set and, incidentally, it appears that no matter the search query that the results are the same.
import json, requests
url = 'http://catalog.data.gov/api/3/action/package_search'
headers = {'Content-type': 'application/json'}
q1 = {'q':'abcdefghijklmnopq', 'rows':600}
q2 = {'q':'children', 'rows':600}

queries = [q1, q2]
responses = []

for q in queries:
    r = requests.post(url, data=json.dumps(q), headers=headers)
    r = r.json()
    print(len(r['result']['results']))
    responses.append(r)

print(responses[0] == responses[1])

Given the example above code what modifications allow the CKAN api to reflect the web GUI search results.
note: this question has been posted as an data.gov issue
note: the solution at data.gov action api parameters seem to be ignored appears to no longer return just 2 results
","['data.gov', 'api', 'ckan', 'python']",
Photoplethysmogram sampling frequency problem,"
I'm doing some calculations on the photoplethysmogram signal it seems that the metrics I'm using suffer from a cyclic artifact each 94-96[s].
The waveform seem ok at the ""breakpoints"".
Is it possible that photoplethysmogram signal was sampled with a different frequency and then interpolated to 125 Hz? 
Is it possible that the interpolation was applied on data chucks of 94-96 [s]?
",['mimic-iii'],
Looking for downloadable H1B LCA application data,"
There are various sites like 
foreign-employment.findthedata.com
http://www.myvisajobs.com/Reports/
which provide you customized view but i need it for further trend analysis.
Can anyone help me finding this.
",['data-request'],
Snow days per county per monthly in US specifically in Colorado?,"
I am seeking a detail monthly snow days where I can look it up for more accurate information. I have looked at the Weather Channel, RoCoRaHS,  Accuweather and others and it does not provide me more information and it is not what I am looking for.
What I want to focus the Snow days for each county all over the United States But I am more specific in Colorado.
","['data-request', 'usa', 'weather']",
Looking for an e-commerce backend dataset,"
Does anybody know of a data set that has been open sourced that contains significant (or all) the tables from and e-commerce backend. Examples could include:

A small store (like a pet store)
A non-profit's membership management system
A small restaurant's backend

","['data-request', 'business']",
How do I find out how much doctors get reimbursed by medicare for certain procedures?,"
Financial incentives are often an important driver of people's actions. I want to better understand how different medical procedures get reimbursed in the US by medicare. Unfortunately I couldn't find the price list via Google myself.
Is there a public website that lists the amount that doctors get reimbursed for various procedures?
",['medical'],
Bike sharing data with customer ID,"
Is there any bike sharing dataset available that INCLUDES a customer ID (not only a bike ID)?
","['data-request', 'time-series', 'bikesharing']",
Open Source MRI Image Dataset,"
I'm working on a voxel-based modelling application and one of the features that I've implemented is a method to do a 3D mesh reconstruction from a series of 2D image slices (similar to an MRI). I've got a basic brain scan image set that I've been working on, but ultimately I'd like to release a small demo example showing how to do the mesh reconstruction. However, in order to do this I need the images to be legally open source so that I'm not distributing images that have copy right restrictions. I've scoured the net trying to find a suitable image set but haven't been able to find anything.
Does anyone have any resources they could point me to that I could use for my application?
","['data-request', 'medical', 'images']",
Are there data sets that contain math problems (and preferably their solutions) at the college level,"
I was looking for data sets that contain math problems at the college level and above.
It would be great if the data sets:

Have each problem by topic such as: basic calculus, analysis, etc.
Have solutions for the math problems

Any reference, links, tips would be appreciated.
",['data-request'],
National Women's Soccer League API,"
I am looking to build an iOS application for the NWSL that displays live sports scores and schedules as well as other data you would expect to find in any sports app. I have found plenty of sources that will give out data either for exorbitant prices or don't even offer data for the NWSL, mostly the latter. 
If anyone knows of a good API for women's soccer that would be great!
","['data-request', 'api', 'sports']",
Image Data for Semantic Segmentaion,"
Could someone recommend some image database which has a pixel-wise label for each image? I've downloaded PASCAL VOC 2012, it has around 20,000 images but only 3,000 of them are pixel-wise labeled.
","['data-request', 'images']",
Data set of Online Store's Customers' Transaction Web Logs?,"
How can web log transaction dataset of customers for my research be obtained?
","['data-request', 'business']",
(mimic-iii) Why D_LABITEMS doesn't have reference range while D_ITEMs has?,"
Often Lab test should come with a reference range, which is likely to be included in D_LABITEMS. 
On the other hand, although D_ITEMS has columns lownormalvalue and highnormalvalue, there is no record that has a no-null value of these two columns. 
Is this caused by a mistake when exporting?
",['mimic-iii'],
Cost of 1-bedroom apartment rental in US by zip code?,"
I'm looking for a cost of housing by zip code; even better if I can get data on 1-bedroom apartments.
For clarification: I would like to query over many thousands of zip codes, and not just one at a time.
",['data-request'],
Geodata to make a map of the UK with counties outlined,"
I will be using AngularJS and D3.js, but that's not really important. 
This blog post by the developer of D3.js, which is a fantastic JavaScript charting library, shows how he made a map of the UK from open source data and delimited each of the countries, giving each of them a different colour.
He also labelled major cities, which, for me, is very ""nice  to have"", but not complete ""must have"".
I would like to take that one step of granularity further, by delineating the individual counties, as well as countries.
Does anyone know of any open data which already does that?
","['data-request', 'geospatial']","In the end, I went with http://d-maps.com/ I don't think there is anything to beat it! "
Modelled air pollution data for UK at monthly resolution,"
I have found background data at the right spatial resolution from:
http://uk-air.defra.gov.uk/data/pcm-data
However this is by year, I ideally need the same data by month. 
There is a lot of site-specific Automatic Urban and Rural Network (AURN) data available from DEFRA which goes down to hourly observations. Although, I would expect it would be extremely challenging to get this data into a monthly 1km gridded dataset...
","['data-request', 'uk', 'environment']",
Publicly available dataset of physician notes,"
I am looking for a publicly available data set of physician notes that describe medical reasoning, ideally freetext indexed by the level of training of the author. 

MIMIC-III has physiologic data, and nursing and procedure notes. Procedure notes do not describe physician reasoning. They document the procedure but not why the procedure was done. 
IIB2B has a data set of about 1000 discharge notes. This is an acceptable starting point, but I was hoping for something larger. 

","['data-request', 'medical', 'nlp']",
User profiles from professional social network,"
I'm doing a project in which I need data about users in a professional social network. I need information related to the experience, education, or skills of the users. So far I've tried LinkedIn but the API does not allow getting this kind of information and I've also tried Xing but I'm having several problems using the API since the information I retrieve is mostly about test users and not the real ones. I've also searched the web for a dataset with similar characteristics but I couldn't find anything.
Please if you could recommend me another social network with an API that allows developers to retrieve this information or even better if you know where can I find a data set with this or similar characteristics I would really appreciate it.
","['data-request', 'api', 'releasing-data', 'social-media']",
How to get the location of every pub in Britan?,"
Someone managed to draw a map of the UK - using only the locations of pubs!
Alas, I have been unable to contact them. Does anyone know the source of their data? I would like to have the lat/long and/or street address of every pub in the uk for a new project.

",['address'],"It says: Data: OpenStreetMap in the image.You can download OpenStreetMap data dumps in a variety of formats, such as shape-files.  Like a database, it will contain nodes of certain types, including one for pubs.  They will all include geographic coordinates.  Simply extract all the nodes that are pubs and you're there."
Is there any open data set related to fault of telecom network or ISP?,"
I am trying to get data from network fault example alarms and alerts. I can get CDR but could not find any fault related data set.
","['data-request', 'machine-learning', 'telecom']",
Macro Indicators of Economic Data by ZIP Codes or Cities in the US,"
I am looking for a tabular (preferably) dataset or a website's API that contains the economic data of zip codes, counties or cities in the US. This dataset has to go back at least to 2003 (it's not strictly required but being recent data is a must). I am interested in statistics like average income per citizen and metrics similar to Gross Domestic Product by city.
What I've tried so far

One source I could find was the 2007 economic census but it appears unavailable https://www.census.gov/econ/geo-county.html and unrelated. Plus according to the release schedule economic data by ZIP will be released in June 2016 https://www.census.gov/econ/census/schedule/
Following the answer to this question I explored the Longitudinal Employer-Household Dynamics (LEHD), Quarterly Workforce Indicators and they did include economic data at the micro scale, meaning Hires, Separations, employment counts etc. That is not really the macro metrics like average income or GDP I need. 
And finally I looked at the County and Zip Code Business Patterns but that dataset only includes details about industries in those areas. Not really macro indicators either

Any additional source will be greatly appreciated.
","['data-request', 'api', 'economics', 'city', 'postal-code']","I can certainly help you with the income estimates. The Census Bureau publishes mean/average income at the ZCTA level. For cities and ZCTA's, the estimate come from a pooled 5-year sample that ranges from 2010-2014 back to 2005-2009.You might only need the first table (S1901), but I figured posting the table giving information on the estimated aggregate sum of income would be good for info too:INCOME IN THE PAST 12 MONTHS (IN 2014 INFLATION-ADJUSTED DOLLARS)City, ZCTAAGGREGATE INCOME IN THE PAST 12 MONTHS (IN 2014 INFLATION-ADJUSTED DOLLARS)
City, ZCTA"
Where can I find a cost of living index by zip code?,"
I am particularly interested in housing costs; specifically 1-bedroom apartment rentals.
For clarity, I mean a database that's free (as in beer) to query with an arbitrarily large number of zip codes.
","['data-request', 'economics', 'prices', 'real-estate']",
getIFPPlanQuotes - Filters and Maximum Page Size,"
I need below clarifications regarding these two APIs (getIFPPlanQuotes & getSMGPlanQuotes):
1- Can filter criteria be sent in request?
2- What maximum page size can be returned?
","['medical', 'healthcare-finder-api']",
Is there a global database of all products with EAN 13 barcodes?,"
EAN 13 is an international system. Is there an API or database that contains all items that have these barcodes? Like all food, goods you can buy in a regular convenience store. Is there a global open database for this?

","['data-request', 'products', 'barcodes']",
Telecommunications Spending Data for Businesses,"
I wasn't 100% sure if this was the right community to ask this in, this community was recommended to me.
 Is there a database or source where I can find how much businesses spend on their Telecommunications budget. I work for a Telecom company and am trying to do data analysis for network planning. I apologize if this isn't the right location. We have previously used Equifax but each report from them is very expensive.
","['data-request', 'business', 'telecom']",
Where can I find Historical GIS datasets?,"
I've been looking for a while for Historical GIS datasets. In a lot of places (also in answers here at StackExchange), people are referring to a great dataset at ThinkQuest, which contains detailed shapefiles for many years inbetween 2000 BC and 1994 for the whole world (I am interested in Europe, in particular).
But since ThinkQuest has been discontinued, the archive is only accessible through the ThinkQuest Library. Unfortunately, this archive does not contain the actual downloads of the datasets...
Does anybody know where I can find these datasets, or is there maybe someone who downloaded these in the past willing to share them here?
Note: Earlier I have asked this question at gis.stackexchange.com, but I was informed that the question would be better suited at this stackexchange.
","['data-request', 'geospatial', 'historical', 'europe']","The ThinkQuest data that the original poster is still downloadable here.
As mentioned above though, there is no information on licensing. The best I could find was this disclaimer page."
Domain Name Service (DNS) A/ASN/NSrecords of Fast-Flux Domains,"
I am looking for DNS Resource Records of Fast-Flux networks. I have been searching for a while now and I did find some torrents but I am not allowed to download torrents from my work. This is the link I found:
https://www.reddit.com/r/netsec/comments/1t6nz8/dns_census_2013_dataset_containing_2676380336_dns/ 
",['data-request'],
Common words missing from typical spellcheckers,"
I find the spellcheckers included with most software to be woefully inadequate.
Many common words are not included in your typical spellchecker.
For example, try spellchecking these common words:

superset
formulary
voicemails
analytics
customizations

Most spellcheckers will claim that a majority of those common words are erroneous.
Is there an open data source of words commonly missing from spellcheckers?  
Note that I'm not looking for a massive list with every corporation and product name.  I'm looking for a simple list of words similar to the above five examples.  I don't know how many common words are missing from most spellcheckers, but I would imagine a list of about 50-500 words will be adequate.
","['language', 'software']",
Understanding Precipitation data,"

I am trying to perform an analysis on weather and car collisions data of New York city. I have downloaded weather data from NOAA. But I am not able to understand the data provided in the precipitation column of the weather dataset. It has a numerical value followed by capital letter. Some of these letters are: A,B,C,G,I,H. 
Example: 0.03G, 0.08A, 0.0H
Can anyone please help me understand what these letters mean here. I have provided a picture of this column. Also, the name of the column in the dataset is PRCP.
","['weather', 'metadata', 'noaa']","This seems to be the same data mentioned at  http://shallowsky.com/blog/programming/NOAA-weather.html .In their write up, they also link to NOAA's documentation for the document.Note that this is what's commonly called an 'ASCII table', in which it is not delimited, but contains a number of fixed-width columns.As such, the field is not '0.00G' but actually two fields, '0.00' (columns 119 to 123) and 'G' (column 124).Column 124 is a notation of how the value was measured at the given site:"
cattle and sheep production and reproduction records,"
I am looking for some records (spread sheets) that I can use for teaching/analysis. I am specifically looking for dairy/beef cattle and sheep/goat farm production and reproduction records.
Appreciate your help.
Baz
","['data-request', 'uses-of-open-data', 'csv']",
Customer Support Interactions data?,"
I need to answer some of the following questions:

What is the average amount of time taken to close a customer issue?
What is the average length of chat for a particular segment of the complaint?  (For example: Kindle, delivery, etc can be different segments for Amazon)
Predicting the next possible complaint, and in which category.

I know this data would be highly varying from company to company. But, open data of any customer support team would do.
I think this need multiple datasets.  If all of them are not possible to get, a subset would also do, which can answer atleast one or more of the questions.
",['data-request'],"Most open data these days is coming from governments and some non-profits... and I have not seen any data such as the ones you're asking for.Somewhat related data may include 311 call requests, requests for assistance from police, and building code enforcement/complaint cases. In case it's helpful, I have included a few examples below:"
"Accounts payables, accounts receivables, invoices, and bills","
I'm looking for a big sample of accounts (payable or receivable) or bills. No matter if it's structured data, scans, or physical receipts.
I haven't found data more relevant than government contracts. But contracts usually include a bulk of goods and services, and it's difficult to separate those.
Some firms use software to manage their accounts, but that's closed data, even when exportable.
Do you have any hints where I can get it anyway?
","['finance', 'prices']",
New York City weather data,"
I am looking for daily weather data for New York City. I have searched the NOAA website but could find only the weather data for New York State. It doesn't have many records for New York City Boroughs other than the Manhattan.
Please suggest some links for weather data that covers all the five Boroughs of New York City.
","['data-request', 'weather', 'noaa']","nyc noaa:
http://www.weather.gov/okx/
areas in ny, including some boroughs but i don't see them all:
http://weather.noaa.gov/weather/NY_cc_us.html
historical nyc noaa data:
http://w2.weather.gov/climate/index.php?wfo=okx
wunderground for yesterday 2015-12-05, you can alter dates back to 1943 via omnibox browser command line, aka url ;):
http://www.wunderground.com/history/airport/KNYC/2015/12/5/DailyHistory.html?req_city=New+York&req_state=NY&req_statename=New+York&reqdb.zip=10001&reqdb.magic=5&reqdb.wmo=99999"
Do some Kaggle contest organizers remove the data sets after the end of the contest?,"
I wonder whether Kaggle contest organizers sometimes remove the data sets after the end of the contest, or is that made impossible by Kaggle's policies?
",['legal'],
Violent crime statistics involving guns,"
I'm looking for datasets that contain violent crime stats involving guns. I've googled but have only found organised and graphed data and I would prefer raw data that I can aggregate.
","['data-request', 'crime', 'unstructured-data']",This link is the Bureau of Justice Statistics start page on fire-arm related crimes:http://www.bjs.gov/content/guns.cfm
Russian Ruble exchange rate,"
I am looking for currency exchange data, specifically USDRUB and EURRUB quotes. I managed to find tick-by-tick data on the official site of the Moscow Exchange (MoEx). But I search data at a 15-30-minute timeframe.
","['finance', 'historical', 'programming', 'russia']",
Political candidate demographics,"
I'm trying to answer this question about whether a politician's female / minority status increases the chance that challengers will be female or minority. The fun begins when I have machine-readable raw data, but the closest I've found is this list of datasets, which do not include the races or sexes of the candidates. Anybody know where to find that?
",['data-request'],
"Where can I find data on the winner of the presidential popular vote by U.S. county, for as many elections as possible?","
I'm trying to find data on the breakdown of the popular vote in each U.S. county, for each presidential election going back as far as possible. I realize that counties change over time, but are these data available somewhere in machine-readable format?
For example, I'm trying to find the data behind this map:

for as many presidential elections as possible. Obviously going back decades means that not all of these states existed (as states) at the time, but I'm still hoping the data are available. Some data are available in PDF format here but are there other sources that are easier to work with?
","['data-request', 'usa', 'elections']","Because of the decentralized nature of US elections it's difficult to find a free, public source for county or precinct level election data. The Federal Election Commission only publishes state-level results. The Census Bureau does not publish data on election results - they publish survey data from the CPS that shows how many people are registered and how many voted - but not who they voted for.The National Atlas (which no longer exists - de-funded) did publish county-level results. Previously, if you searched http://www.data.gov/ for Presidential General Election Results county you'd find archived versions of the data from 2012, 2008, and 2004. But - in 2017 this data mysteriously vanished from the repository. Luckily I had saved copies of them, and you can access them from my college's repository here:https://www.baruch.cuny.edu/confluence/display/geoportal/US+Presidential+Election+County+ResultsThere's also a project at Harvard where they're gathering county and precinct data, but the county results appear to be state by state: http://projects.iq.harvard.edu/eda/pages/about.Gathering it the hard way would be to go to each election office, state by state... the Harvard site has a link to each state secretary of state who is charged with collecting this information - Wikipedia also provides direct links back to individual state election results pages. "
uk streets for UK postcodes,"
I have most geocoded UK postcodes and would like to obtain all streets close to each postcodes. I am aware of this open data source:
https://www.ordnancesurvey.co.uk/business-and-government/products/os-open-roads.html
Which gives you most:
Motorways, A-roads, B-roads
Unfortunately, this is not as exhaustive as I thought. Is anyone aware of any other exhaustive/complementary data sources? Thanks.
","['data-request', 'geospatial', 'uk']",
How can I find state-level data on the unemployment rate of youth for 2014 and 2015?,"
I have found state-level, monthly unemployment data for 2014/2015, and I have found national monthly youth unemployment data for 2014/2015. However, I need all four together; State-level, monthly youth unemployment data for 2014 and 2015. In addition to scouring their website, I have called the Bureau of Labor Statistics and they were not helpful, unfortunately.
Alternatively, state-level monthly unemployment data on low-wage earners for 2014/2015 would work as well.
Basically, I want to find the effects of the state-level minimum wage changes occurring in January 2015, and these affect primarily youth and other low-wage earners.
If I could find this data at the yearly level for 2014 and 2015 instead of the monthly level, that wouldn't be too bad. It wouldn't be quite as useful as monthly, but I could still run the regression and get some results. The other elements are pretty crucial though.
","['data-request', 'data.gov', 'economics', 'research', 'state']",
Database of images to estimate cloud cover,"
Is there any freely available database of sky pictures, which also already has an information about the cloud cover in metadata (by percentage, or by okta)?
I am no meteorologist, but I want to train my program to estimate cloud cover from pictures of sky I will take.
Do you think it makes any sense?
Or do you think it would be better, more precise, to calculate cloud cover from image processing?
Edit: I am looking more for a database of pictures like this - allskycam.com but with the cloud cover already calculated
","['data-request', 'weather', 'metadata', 'photographs']",
Networks of three actors data set,"
A network of one actor is a network where all nodes are of the same type, like the Facebook network where all nodes are humans. Two actor networks (Bipartite) are networks where there are two kinds of actors, like book and writer, where there are links between two different actors and not between the same actor. Similarly, the three actor networks is composed of three different disjoint sets and links can happen to be between any two nodes from any two different sets. I am looking for data sets for the 3 actors networks. Any help?
","['data-request', 'network-structure']",
Is the patient's height available?,"
Is the patient's height available in MIMIC-III? In my use case, I would be interested in having it in order to compute the patient's ideal body weight.
On Oracle DB:
SELECT  *
FROM all_tab_columns
WHERE LOWER(column_name) = 'height'
AND owner = 'MIMIC';

or on PostgreSQL:
select table_name 
from information_schema.columns
where LOWER(column_name) LIKE '%height%';

didn't return anything.
Looking at the D_ITEMS:
SELECT *
FROM mimiciii.D_ITEMS
-- not ideal, but %ht% will find labels containing 'Ht' and 'Height'
WHERE lower(label) like '%ht%'
ORDER BY label ASC;

there are a few itemid of interest:

But using them to look for heights in chartevents table only returns the heights for a fraction of patients (mostly neonates):
-- Result: 12958 rows 
SELECT ICUSTAY_ID, MIN(VALUENUM) mini, MAX(VALUENUM), 
  AVG(VALUENUM), STDDEV(VALUENUM)
FROM mimiciii.CHARTEVENTS 
WHERE ITEMID IN (920)
AND VALUENUM IS NOT NULL
AND VALUENUM > 0
GROUP BY ICUSTAY_ID
ORDER BY mini ASC
;


-- Result: 11385 rows 
SELECT subject_id, MIN(VALUENUM) mini, MAX(VALUENUM), 
  AVG(VALUENUM), STDDEV(VALUENUM), COUNT(*) cnt
FROM mimiciii.CHARTEVENTS 
WHERE ITEMID IN (920)
AND VALUENUM IS NOT NULL
AND VALUENUM > 0
GROUP BY subject_id
ORDER BY mini ASC
;

Are the patients' heights available somewhere else?
",['mimic-iii'],"You can use this query (tested on MIMIC-III v1.1, took around 80 seconds to run on my computer):Some statistics:It will create the following table:If you prefer to group by hadm_id instead of icustay_id, you can simply replace icustay_id by hadm_id in the table creation query:Some statistics:This will give you:If you want to all get the means of heights and weights for each patient:output:To add the ideal body weight:"
Where can I find datasets of mailing list archives of open source software?,"
I plan to mine the mailing list archives of any open source software to answer interesting research questions. 
How can I request for the data?
What is the procedure?
Are any small datasets of the mailing list archives available to perform a test run? If so where can I find one?
","['data-request', 'machine-learning', 'open-source']","Here is a list of papers discussing the use of email in studying FLOSS (free, libre, and open source software) development.(Disclosure, I run the flosshub site, and I wrote a few of those papers, including a survey of how FLOSS researchers have used email in the past, and what projects they've studied most)I personally think that the MarkMail service is very handy for general studies of email. Here is a paper where we used Markmail to look at the use of pastebins over time on FLOSS projects. (Are they adopting pastebins as an innovation or not?) Markmail was a great source for that kind of ""mile wide, inch deep"" analysis where we were just counting words.However for doing large text analysis, usually there is so much mail that most people don't use a service like MarkMail or Gmane, but rather they look for the original mbox files for the email. This is so that you can put them in a database and do your own cleaning. Keep in mind that some projects like the LKML do not have the original mbox any more (a tragic loss, IMO) so you are stuck scraping your own data from various web sites that provide archives, such as lkml.org. Other projects, like Apache ones, DO have email archives where the mbox are available. Keep in mind that if you are studying FLOSS, the messages themselves will be quite messy and very technical, full of source code, replies, and all kinds of garbage. Right now I am working on a data cleaning project with a 20-year set of email and it has taken nearly a full year for myself and a student to clean and process this mail properly.Good luck!"
Medical Terminology in Patient Medical Records - Public Data Sets,"
I am interested in sample data of real patient medical records (anonymized or demographics removed completely) for the purpose of running through NLP system - specifically diagnoses, admissions and progress notes - anything where medical terminology is used. I have no interest in linking data to specific patient types or categories - I just want the text of the notes
Ideally I would like a data such as:
10/4/2011 - 59 year old male admitted with right sided chest pain, reduced air entry and fever for 7 days. X-ray showed occlusion of right lower lobe consistent with community-acquired bacterial pneumonia.Non-smoker.

13/4/2011 - Reviewed by MO. Left leg swelling noted with some tenderness on extension - DVT suspected. No fever, SOB. BP 120/90. Ix to follow. U/S ordered. Heparin commenced.

Are there any free data sets with this sort of data? I have looked at various public data repositories such as http://www.healthdata.gov/ and https://www.nlm.nih.gov/hsrinfo/datasites.html without much luck.
","['data-request', 'data.gov', 'medical', 'nlp']","The MIMIC-III dataset would be well suited to the kind of natural language processing (NLP) study that you are interested in doing. MIMIC-III includes deidentified nursing progress notes, imaging reports, and discharge summaries for tens of thousands of patients who were admitted to intensive care units in the US.You can read about several NLP studies that have used the MIMIC dataset on PubMed (note that most use MIMIC-II, an earlier version of MIMIC). For example, the following study explored text classification methods for use in risk adjustment: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4147615/While MIMIC-III is a freely available dataset, the information that it contains is sensitive and so there is a formal process for requesting access. For details, see: http://mimic.physionet.org/gettingstarted/access/ "
How do I get Google Analytics data for teaching college course?,"
Does anyone know how I can obtain a Google Analytics database for teaching undergraduates how to work with Google Analytics?
I don't have a commercial website which I can attach to, and I want to explore some of the more advanced campaigns and tagging options for tracking purposes.  
Seems like a ""Chicken & Egg"" problem, and thus far Google staff have been useless in answering this query. 
",['education'],
Where can I find data for Formula 1 races and race cars,"
I am looking for dataset on the outcomes of Formula 1 races, what cars partook in the race, and the specifications of these cars (such as type of tire used; type of engine; width, length and other parameters that describe the shape of the car).
If the dataset contained information about the drivers as well as the weather conditions and geographic information of the race track that would be all the more better.
I can't seem to find any datasets on Formula 1 racing, so I was wondering if anyone could suggest one? 
","['data-request', 'sports', 'historical']","This is not a direct answer for your question, but you might find these links useful. Haven't tested it personally, but free for non-commercial use Ergast API seems appropriate for building such a dataset. A commercial solution, SportsAPI offers 14 days free of charge. You may use it to build such dataset."
Where to get data for each WBAN ID and Station ID and its corresponding city,"
I am trying to search for a dataset which contains WBAN id and Station ID for each weather station in New York and its corresponding city or county. I want this data set for my course project.
I want to map all the weather stations in New York into 5 boroughs of New York. The data I currently have has WBAN ID and the corresponding Counties. But the counties for half of the data is missing. Also, the data doesn't have corresponding Station IDS
","['data-request', 'weather', 'noaa']",This list from NOAAhttp://www.ncdc.noaa.gov/homr/file/emshr_lite.txthas a bunch of station data for various networks (primarily WBAN and COOP) its a text file but it opens very nicely in excel with fixed width columns where you can sort based on the criteria you've specified. It includes counties for most stations and lat lon for all stations. Stations without a WBAN ID are part of a different network.There's also this list from the EPA:http://www2.epa.gov/sites/production/files/documents/STATION_LOCATIONS.PDFWhich only includes stations with a long history.For future post include the data you already have.
"To whom does ""author"" refer when using schema.org's ""MusicAlbum"" schema?","
I am trying to encode reviews of music albums. If I understand the ""MusicAlbum"" schema correctly, the =reviewer= is the ""author"" of the ""review"" content? Can anyone point me to examples of well-constructed reviews (MusicAlbum"" or otherwise)? Likewise, what is the best way to note the language in which the MusicAlbum is recorded--in my case, often not the same as the language of the review?
",['best-practice'],
Average Internet Download Speeds for All Countries,"
I've already explored Akamai's State of the Internet Reports and the ITU's ICT Indicators Database, and tried to access Ookla's old data which is not offline. Is there anyone who can recommend where I could find average internet speeds by country?
",['internet'],Ultimately I contacted the editor of the Akamai State of the Internet report to explain the purpose of my research and he was willing to provide aggregate data by country for average speed and average peak speed. Very good quality data :-)
"ADMISSIONS Table, recent Mimic-III Postgres Updates","
Just updated my mimic-code directory after some changes were made yesterday to the postgres configuration files. Reimporting the data and getting the following error for the admissions table:
postgres=# \set admissions_csv :mimic_data_dir 'ADMISSIONS_DATA_TABLE.csv'
postgres=# COPY ADMISSIONS FROM :'admissions_csv' DELIMITER ',' CSV HEADER;
ERROR:  invalid input syntax for type timestamp: ""CHEST PAIN\CATH""
CONTEXT:  COPY admissions, line 2, column edregtime: ""CHEST PAIN\CATH""

I know this is because the data I'm using is missing the edregtime column - is the appropriate data for these updates accessible on physionet?
",['mimic-iii'],"It looks like you are trying to load MIMIC-III (v1.1) data using the MIMIC-III (v1.2) build scripts. edregtime is a new column that was added between v1.1 and v1.2.Major issues addressed, including additional data made available:...#151 - The time of emergency department registration and exit has been added to the admissions table, where available.The latest version of the data can be downloaded from the MIMIC-III project page on PhysioNet."
Any data about Mobile Phone Contacts?,"
I am going to do some analytics on Mobile Phone Contacts data, in particular, I would like to find the average number of contacts, to determine social groups(family, friends, сolleagues), but I didn't find anything on the web :(
I need it for my master's thesis
Maybe anyone could help me and suggest open sources where I can get this data?
","['data-request', 'telecom']",
Better global elevation data,"
For my online 3D earth model on guadTree algorithm I need elevation data for all land and oceans.
I recently discovered SRTM 1 Arc-Second Global, but it does not have data for the oceans and the most northern and southern latitudes. I studied the article, but I still can not decide. What data are better?
And where better to store this data? In MySQL? If I need to get the elevation of a particular point by lat/long in order to generate an arbitrary terrain pieces.
",['metadata'],
Dataset suggestions for teaching data science in a for-profit setting,"
I'm developing an ebook for a publishing company on Data Science. I'm hunting for a dataset that would be appropriate for this. I've seen many tutorials use iris, but I don't want to - I want to use a larger dataset that allows the audience to have some experience with something that's more realistic.
I welcome suggestions for good datasets that would illustrate various aspects of data science - data collection, data munging & cleaning, visualisation, and modelling. 
Here are some of the criteria I'd ideally love to see in the dataset - 

The dataset needs to be available for private and for-profit use. I'm happy to give credit to those that curated it, though (this is crucial)
The dataset should be long enough - examining by hand is not an option (which, in my opinion, iris is). This also allows me to demonstrate sampling and dealing with at least moderately-sized data. I'm thinking about something in the 100k row range. 
The dataset can (and should!) be slightly unclean - I'd like to give the audience some sense of which rows should be removed for analysis
The data should be wide enough - have a reasonable number of attributes (10-20, maybe?) to allow for some feature selection, feature elimination, and feature engineering.
A mix of numeric, string, dates, categorical data to demonstrate operations and challenges dealing with each of them
Multiple predicted variables (some classification, some regression) so that I can demonstrate different techniques. One example could be loan data with a 'Defaulted (Yes/No)' as we as 'Income (in USD, EUR, INR, etc.)' 
Multiple tables that can be joined or merged on some Key variable

I recognise that a dataset with all of these (very specific) expectations might be difficult to come by. However, anything meeting at least some criteria would be greatly appreciated.
",['machine-learning'],
Dataset suggestions for teaching data science in a for-profit setting,"
I'm developing an ebook for a publishing company on Data Science. I'm hunting for a dataset that would be appropriate for this. I've seen many tutorials use iris, but I don't want to - I want to use a larger dataset that allows the audience to have some experience with something that's more realistic.
I welcome suggestions for good datasets that would illustrate various aspects of data science - data collection, data munging & cleaning, visualisation, and modelling. 
Here are some of the criteria I'd ideally love to see in the dataset - 

The dataset needs to be available for private and for-profit use. I'm happy to give credit to those that curated it, though (this is crucial)
The dataset should be long enough - examining by hand is not an option (which, in my opinion, iris is). This also allows me to demonstrate sampling and dealing with at least moderately-sized data. I'm thinking about something in the 100k row range. 
The dataset can (and should!) be slightly unclean - I'd like to give the audience some sense of which rows should be removed for analysis
The data should be wide enough - have a reasonable number of attributes (10-20, maybe?) to allow for some feature selection, feature elimination, and feature engineering.
A mix of numeric, string, dates, categorical data to demonstrate operations and challenges dealing with each of them
Multiple predicted variables (some classification, some regression) so that I can demonstrate different techniques. One example could be loan data with a 'Defaulted (Yes/No)' as we as 'Income (in USD, EUR, INR, etc.)' 
Multiple tables that can be joined or merged on some Key variable

I recognise that a dataset with all of these (very specific) expectations might be difficult to come by. However, anything meeting at least some criteria would be greatly appreciated.
",['machine-learning'],
Database or download of Amtrak station codes?,"
Is there available an easily digestible (i.e., CSV or something) source for Amtrak rail station codes?  They have a code page here but I'm looking for something that could be included in a database lookup, without scraping and building it myself.
",['data-request'],"Scraped and built for you, up on Open Data SE's datahub.io account; note, these are only for America, not all Amtrak stations/codes:
https://datahub.io/dataset/amtrak-stations 2017-04-03 Update:
Added official Amtrak Stations (of U.S.) GeoJSON dataset:
Updated database of the Federal Railroad Administration's (FRA) Amtrak Station database. This database is a geographic data set containing Amtrak intercity railroad passenger terminals in the United States and Canada. Attribute data include services and passenger amenities provided at the station  Official Source:
Amtrak Stations - US DOT "
Standard digit database in English and Marathi language,"
Hi i am working on speech recognition project.For testing my algorithm i need a standard digit database in English and Marathi languages i.e. i need an audio file that would be an input of my system. I tried or TIDIGITS standard database but cold not download it. please help me if anyone have it.
",['data-request'],
Where can I find data to determine the US county from an US address?,"
I'm searching for some kind of database which would allow me to determine the county from an existing US address (consisting of number, street, city, zip and state).
Obviously that would require some sort of database including street names and ranges, city, county and state; however I have not been able to find anything of the sort.
I'd appreciate any help. Thanks!
","['data-request', 'usa', 'county']",
International Median Income Data at City Level,"
I would like to investigate relationships between Airbnb city listing data, and median income. In the United States NHGIS works lovely, but how about internationally at the city level?
","['city', 'income', 'global']",
Inconsistent UCC usage in Consumer Expenditure Survey,"
This question perhaps does not belong here. If you do know where it belongs, please let me know and I will delete the question.
Data: 
Consumer Expenditure Survey from the BLS (PUMD)
Files used: 
MTBI (expenditure by UCC codes) and FMLI (expenditure per category)
Goals:
1) Make a time series of FMLI data. 
2) Fine tune some FMLI variables by dropping some UCC from the MTBI files and reconstructing them.
Problem:
The same variable is sometimes constructed from different UCC.
For example:
The variable MAINRPPQ (Maintenance and repairs last quarter) in 2012 and 2013 CE files.
For 2012 the UCC used are:
""470220 COOLANT/ADDITIVES/BRK/TRNS FLD""
""480110 TIRES PURCHASED/REPLACED/INSTALL""
""480212 VEHICLE PRODUCTS & SERVICES""
""480213 PARTS/EQUIP/ACCESSORIES""
""480214 VEHICLE AUDIO EQUIPMENT""
""480215 VEHICLE VIDEO EQUIPMENT""
""490110 BODY WORK AND PAINTING""
""490211 CLUTCH, TRANSMISSION REPAIR""
""490212 DRIVE SHAFT AND REAR-END REPAIR""
""490221 BRAKE WORK""
""490231 REPAIR TO STEERING OR FRONT END""
""490232 REPAIR TO ENGINE COOLING SYSTEM"" 
but for 2013 the UCC are:
""470220 COOLANT/ADDITIVES/BRK/TRNS FLD""
""480110 TIRES PURCHASED/REPLACED/INSTALL""
""480212 VEHICLE PRODUCTS & SERVICES ""
""480213 PARTS/EQUIP/ACCESSORIES""
""480215 VEHICLE VIDEO EQUIPMENT""
""480216 VEHICLE CLEAN SRVCS INCL CARWASH""
""490110 BODY WORK AND PAINTING""
""490232 REPAIR TO ENGINE COOLING SYSTEM""
""490300 VEHICLE OR ENGINE REPAIRS""
""490311 MOTOR TUNE-UP""
""490312 LUBE, OIL CHANGE AND OIL FILTERS""
""490313 FRNT END ALIGN, WHEEL BAL/ROTAT""
""490314 SHOCK ABSORBER REPLACEMENT""
""490318 TIRE REPAIR AND OTH REPAIR WORK""
""490501 VEHICLE ACCESSORIES INCL. LABOR""
""490900 AUTO REPAIR SERVICE POLICY""           
There are five issues:

UCC that are in the 2012 variable but are not in the 2013 variable:
""480214 VEHICLE AUDIO EQUIPMENT""
""490211 CLUTCH, TRANSMISSION REPAIR""
""490212 DRIVE SHAFT AND REAR-END REPAIR""
""490221 BRAKE WORK""
""490231 REPAIR TO STEERING OR FRONT END""
UUC that are in the 2013 varaible but are not in the 2012 variable:
""480216 VEHICLE CLEAN SRVCS INCL CARWASH""
""490300 VEHICLE OR ENGINE REPAIRS""
""490311 MOTOR TUNE-UP""
""490312 LUBE, OIL CHANGE AND OIL FILTERS""
""490313 FRNT END ALIGN, WHEEL BAL/ROTAT""
""490314 SHOCK ABSORBER REPLACEMENT""
""490318 TIRE REPAIR AND OTH REPAIR WORK""
""490501 VEHICLE ACCESSORIES INCL. LABOR""
""490900 AUTO REPAIR SERVICE POLICY""    
The UCC that are in 2012 but not in 2013 variable still exist in the 2013 UCC text file and MTBI files. So, why were they dropped? From the description of the new UCC in 2013, I could not find the reason.
Some of the UCC that exist in 2013 but not in 2012 were measured in 2012 but some were not.
I could not find documentation of what is going on without manually going through everything.

My questions are:

Does proper documentation of UCC changes in the CE exist? If a code exists both in 2012 and 2013, but is not used in 2013, what is the reason? Please note that in 2013, ""Brake Work"" was dropped...
What should be my strategy for time series variables?

Thank you.
","['government', 'economics', 'survey']",
Wireshark capture files,"
I am looking for Ethereal / Wireshark / tcpdump captures (.pcap or .pcapng files) for training purposes. They should cover a wide range of protocols on all OSI layers. Those files would be analyzed by students with Wireshark 2.0.
The captures should be available for free and for commercial use.
Ideally, each of the captures has a problem description and a description on how to find the result.
","['data-request', 'internet']",
Windows kernel or user mode crash dumps,"
I am looking for a set of Windows crash dumps (.dmp files) that I could use during trainings. This may be user mode crash dumps (application crashes, ""Send information to Microsoft"") or kernel mode crashes (blue screen). They should all contain an unhandled exception to ba analyzed with WinDbg or Visual Studio.
The crash dumps should be available for free and for commercial use.
Ideally they would already have been analyzed, so that one could look up the expected result.
","['data-request', 'programming']",
Examples of openly accessible field or farm-level soil acidity (pH) data?,"
Can anyone provide examples of openly accessible field or farm-level soil acidity (pH) data? Ideally for one or more locations in New Zealand, the UK or Australia?
","['data-request', 'agriculture']",
"In the CSD, which Institution ID is used to merge in Earnings/Repayment Data","
I noticed that for many CSD observations at chain schools, such as University of Phoenix, the earnings and repayment variables in levels (#repayers, #working 6 years after, etc.) seem disproportionately high, even after accounting for the fact that they are pooled cohorts, and I am assuming this is because this data is reported at the OPEID level. What OPEID or alternative variable is used to identify/merge in this information to the CSD? (i.e. 6-digit OPEID, 8-digit OPEID).
",['collegescorecard'],
MIT reality mining [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 7 years ago.







                        Improve this question
                    



I'm going to work in Mobile Crowd sensing in my master of thesis . I need MIT reality mining  data so I had submitted in this site http://realitycommons.media.mit.edu/realitymining.html
and it had told me the download linke will be sent for me in next few day. but they dont send me yet .
 can someone help , or tell me why?
",['crowdsourcing'],
"Which format (CSV, JSON, Atom, RSS?) should events data be published in?","
I'm developing recommendations for local councils publishing event listings. Compared to other kinds of data, events data seems very likely to be used by web and mobile apps (as opposed to downloaded for analysis), and is inherently chronologically ordered and time sensitive.
I'm really not sure which format to recommend:

CSV is the format I recommend for most non-spatial data. It's easy to process and supported by lots of software.
JSON is the preferred format of web and mobile developers.
RSS remains probably the most widely used format for feeds of information like blog posts
Atom is a better format than RSS, but from memory is a bit more work.

Are there any recommendations on the topic I can follow?
EDIT
By ""events"", I mean public events like concerts, workshops, festivals etc. They generally have specific locations, but the people that produce the data don't seem to include lat/longs.
Here's an example.
","['releasing-data', 'data-format', '5-star-scheme']",
publicly available dataset of loan advertisement,"
I'm looking for samples of advertisements by illegal money lending online, e.g. in comment sections of online forums etc. My intention is to use it as a training dataset to build a filter against such comments.
Does anyone know if there is an existing publicly available dataset for this?
","['data-request', 'finance']",
Does anyone know a public open GPS datasets with labeled visited places (POI) that we can use in research projects?,"
We are working on outdoor activity recognition and we need to test our approaches using a labeled dataset containing pedestrians' mobility traces.
After some research, I have found GeoLife dataset (can be found here : crawdad.org/keyword-GPS.html). Sadly, this dataset doesn't contain labels of visited places. Any suggestions of labeled mobility traces (e.g. home, work) ?
","['data-request', 'geospatial']",
Huge Biomedical Corpus for Unsupervised Experiments,"
I am looking for a very large collection ( > 10 GB) of biomedical text documents to run some unsupervised experiments with (for recognizing drug names, etc). Do we have access to such a thing for free? Or is it legal to crawl pubmed and use the crawled dataset for research experiments (no idea about how the licensing/copyright is at pubmed)?
","['data-request', 'machine-learning', 'nlp']","There is an open access subset in PubMed Central which can be crawled via an API and might be what you are looking for: http://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/. There are currently around 1 million articles in the open access subset, which I imagine would be getting towards your GB target. It looks like versions of the subset are available on torrent sharing sites.""is it legal to crawl pubmed and use the crawled dataset for research experiments?""The open access subset includes articles with a range of licenses, some of which restrict ""commercial use"" and creation of ""derivatives"". If you are worried about legality, you could focus your search on specific licenses (e.g. there are over 500K CC-BY licensed articles).Europe PMC would be worth considering as an alternative source of content: https://europepmc.org/Help#doesEPMChaveallPMandPMC. It covers the majority of PubMed Central content, plus additional content like NHS Clinical Guidelines."
Hindi tweets datasets freely available,"
I am working on macaronic language analysis. I need a dataset of hindi tweets or other devnagri languages. Could someone send me the datasets or the links where I can find them? 
",['data-request'],
Happiness Cross Sectional Data,"
Looking for a data set that attempts to measure happiness, welfare, and security. Ideally at an individual level across countries and or states. Thanks for any help you are provide.
",['data-request'],"Not sure what exactly you mean with ""happiness, welfare, and security"" but the Life in transition survey (http://www.ebrd.com/what-we-do/economic-research-and-data/data/lits.html) has several possibly related questions including ""How satisfied are you with your life"", and exists in two waves with relatively big samples"
Is there a Glossary of Terms for the Federal Elections Commission API?,"
Maybe I missed it on the FEC API site (https://api.open.fec.gov/developers/) but does anyone know if there's a glossary which defines all of the elements in the models? For example, if you scroll down to /Financial/ and open up /committee/{committee_id}/reports/ you some obvious items like: all_loans_received_period (integer, optional),
Which I imagine is all the loans taken by the committee in that period; and some mysterious ones, like: fed_candidate_committee_contributions_period
Are these contributions to the committee from Federal candidates? To Federal candidates?
I have a bunch of clarifying questions on the listed items but before I start just asking everything I was wondering if these terms are defined somewhere.
Thanks!
","['government', 'metadata', 'openfec']",
Effect of foods on diseases,"
I am looking for a data set that lists different kind of foods and diseases, and for each pair food-disease indicates whether the food is bad/neutral/good for the disease.
","['data-request', 'medical']",
Why are some PubMed IDs missing?,"
PubMed IDs (a.k.a. PMIDs) seem to have been assigned sequentially:

https://www.ncbi.nlm.nih.gov/pubmed/1
https://www.ncbi.nlm.nih.gov/pubmed/2
https://www.ncbi.nlm.nih.gov/pubmed/3
https://www.ncbi.nlm.nih.gov/pubmed/4
...

However, some some PubMed IDs missing. I.e. https://www.ncbi.nlm.nih.gov/pubmed/2260 returns Error occurred: The following PMID is not available: 2260. Why are some PubMed IDs missing?
",['pubmed'],
Deaths by falling coconuts,"
I am looking for the number of deaths caused by the natural fall of coconuts from trees each year.

Number  of deaths each year worldwide, estimated if needed
Bonus for extra information about each death, such as country and date
Must exclude coconuts that have been thrown rather than felt from the tree normally
Data for recent years, though further historical data is good too if available

Wikipedia only talks about separated incidents, without giving any statistics.
","['data-request', 'medical', 'global']","National Electronic Injury Surveillance System (NEISS) is a great resource for free-text details of emergency-room visits, including fatalities.Unfortunately (for you), years 2009-2015 show cutting-based coconut-related injuries (plus one allergy):201546 YOF WAS CUT W/KNIFE WHILE CUTTING A COCONUT. DX:  FINGER LAC W/DIGITAL NERVE INJURY.31YOM CUTTING A COCONUT WITH A KNIFE AND SUSTAINED A FINGER LACERATION53YOM WAS CUTTING COCONUT AND LAC FINGER WITH KNIFE72YM FOR AF, WAS CUTTING THE BOTTOM OF COCONUT TO MAKE BIRDHOUSE
  WHEN IT SPUN RUNNING HIS HAND ON THE TOP OF THE TABLESAW>>LAC2014 34YOM CUT LEFT FINGER WITH A KNIFE WHILE CUTTING A COCONUT, LACERATION OF LEFT THUMB201324  YOM WAS TRYING TO CUT A COCONUT WITH A KNIFE AND CUT HIS HAND. DX HAND LAC13 YO MALE SLICING A COCONUT AND CUT FINGER WITH A KNIFE.  DX LACERATION FINGER20129 YOF STABBED HAND W/A KNIFE WHILE OPENING A COCONUT. DX:  R HAND LAC .5 CM.
  9YO M OPENING A COCONUT WITH A SHARP BLADE AND POKED FINGER  DX PUNCTUR E WOUND TO FINGER46 YO M, C/O CUT TO LT HAND, WAS TRYING TO OPEN A COCONUT W/ A KNIFE WH EN HE ACCIDENTALLY CUT HIMSELF, DX HAND LACERATION27YOF W/ALLERGY TO COCONUT, MOTHER USED COCONUT ROOM DEODORIZER PT. HAD SOB AND CHEST PAIN.43 YOF, PT WAS USING KNIFE TO CUT A COCONUT, KNIFE SLIPPED & STABBED L T HAND. DX; LAC LT HAND2011None!2010CUT WITH KNIFE WHILE CUTTING COCONUT. 35 YO F LACERATION L HAND # 36 YOM WAS CUT W/KNIFE WHILE PEELING COCONUT. DX:  L HAND LAC 3 CM.41YOF DRILLING A HOLE IN A COCONUT AND BIT R AND PUNCTURE HAND 2009PT CUTTING A COCONUT WITH A KNIFE AND SUSTAINED A LACERATION TO FINGER PT WAS CUT W/KNIFE  WHILE CUTTING COCONUT. DX:  R HAND LAC.PT TRYING TO OPEN A COCONUT WITH A HAMMER STRUCK SELF IN THE HEAD WITH THE HAMMER CLOSED HEAD INJURYDX LAC REPAIR/TETANUS BOOSTER: LAC TO PALM OF L HAND W PAR'G KNIFE W CUT'G ON COCONUT THIS EVEN'GPT CUT FINGER WITH A KNIFE WHILE CUTTING OPEN A COCONUT AT HOME TODAY DX// LEFT INDEX FINGER LACSo, probably there are very few recorded falling-coconut accidents, and, similar to shark attacks, most would be then cataloged on Wikipedia.By the way, you can download individual years as XLSX, or you can export year-by-year by search the Query Tool without any parameters, and then exporting CSV, or this data has been exported to R-stats."
Text of US Presidents' inaugural addresses,"
I'm trying to reproduce some text analyses of Presidential inaugural addresses, such as was done by this New York Times interactive display, and I'm looking for a good source for the texts.
I've found sites (Miller Center) that have texts of speeches in human-accessible formats (via browsing web pages), but I'm hoping there's some machine-friendly archive that I haven't found.
","['government', 'text']",
"Which agencies and which part to get training data for passports, id cards and licenses","
I am interested in doing some research relating to computer vision and passports, id cards and licenses.
I have reached out to several agencies seeking data I would use as training data but keep running into dead ends.
Who would you start with for this data?
",['machine-learning'],
Land Use Data for Beijing for 1985 and 2010,"
I am looking for land use data for Beijing for 1985 and 2010
","['data-request', 'economics', 'city']",
Clouds realtime,"
Is there somewhere free maps of clouds in real time? They should be used for the 3D model of the Earth (must be free of the Earth's surface).
I found only this, but there are an uneven stitched (there are breaks) and clouds cover the surface of the earth. How can I pull out the clouds?
",['geospatial'],
Where can I find OPRA data?,"
Where can I find OPRA data. Here are a few criteria:

Preferably free or for a small price;
Supports quant API on cloud (so I don't number crunch on my computer);
Good reputation company.

","['data-request', 'finance']",
Historical weather data for Pyrenees Atlantiques,"
I really need to get hold of historical weather (precipitation, temperature most important) of an area in the Pyrenees Atlantiques. More specifically at a refuge, Arlet Lat/Lon: 42.83570°N / 0.6125°W, but I realise I won't get data that accurate. Any help would be massively appreciated. This is urgently needed for a project we're currently working on, investigating amphibian declines in the area. 
","['data-request', 'weather', 'france']",
19th Century Patent Data,"
Any 19th century patent data with geo-referenced locations of the submitter? So, for each city or county, it lists the number of patents filed in a given year/month etc?
",['data-request'],
How do you maintain continuity in race definitions across time?,"
If you're looking to track enrollment of minority students over time, what's the best way to accommodate changes in IPEDS definitions after 2009?
I am presuming UGDS_WHITE (after 2009) maps to UGDS_WHITENH and UGDS_BLACK maps to UGDS_BLACKNH. 
Looks like things get a bit tougher converting UGDS_ASIAN and UGDS_NHPI back to UGDS_API.
",['collegescorecard'],"Note that IPEDS detailed descriptions of changes in race categories are noted here: https://nces.ed.gov/ipeds/news_room/ana_Changes_to_10_25_2007_169.asp . In developing trend reports, NCES converts race categories to the new naming categories and shows the old Asian and Pacific Islander Category and the new Asian and the new Hawaiian and other Pacific Islander categories with N/A in the appropriate cells where old and new reporting begins and ends.  A resource that can provide assistance on this matter is the IPEDS Data Use Help  Desk (866) 558-0658 or ipedstools@rti.org "
"Good, free dataset to practice cross validation?","
I've been searching online for free data sets with which I would be able to apply cross validation techniques. Preferably, I'd like to find data with ≈30 (or more) observations that has significant curvature so that I can demonstrate how one can use cross-validation to perform model selection.
I'd also like to demonstrate the use of a gradient estimation algorithm to estimate the polynomial parameters.
I would use the dataset to perform my final course project. I'd like to demonstrate that I have a good handle on the topics I mentioned above- so I am working backwards and trying to fit the data to the technique. I haven't had much luck searching online- most of the data sets I've found are either practice applications for linear regression or include many variables- which I'd like to avoid if possible.
Does anyone have any suggestions? I'd greatly appreciate it!
","['data-request', 'machine-learning']",
Heavy tailed dataset for heavy hitters problem,"
I'm looking for datasets for evaluating algorithms for finding top-k on data streams (e.g.).
I currently have network trace from Caida, and some self-generated zipf i.i.d. distributed datasets.
I'm looking for real-life data sets which are heavy tailed, i.e., for any fixed k, the top-k elements only consists a small portion of the stream.

Any suggestions for available datasets for academic research which are used for streaming algorithms and are heavy tailed?

",['machine-learning'],
Publishing Weather Data under Creative Commons / Peer Production License,"
I am from a volunteer at FSHM (Free Software Hardware Movement, Puducherry, India).
As a part of our community project, we have been working on building a weather station using Freedom Hardware. We are experimenting various things, and are building prototypes for the same. The aim of this project is to build a low-cost distributed community based local weather stations.
As a part of this project, we also were exploring ways to keep the weather data open to all, by releasing the data we capture, in either Creative Commons / Peer Production License.
Upon our exploration, we ended up finding, openweathermap.org, who promised to keep the weather data open (We want to post data, not consume it). When we started exploring their api's for posting, we discovered it doesn't work. Our data was never uploaded. Tough we have contacted them on the same, we also wanted to explore other options or online website, where weather data would be kept open and accessible to all.
Please do let us know, if you have come across or used anything.
PS : We want the data to be available under Creative Commons / Peer Production License.
PPS : If there really is none, then we are left with no choice but to write one. Do also let us know if somebody has already started anything similar or already half way through. 
","['api', 'releasing-data', 'weather', 'metadata']",
Larger data sets with random treatment (Randomized Trial Data),"
We are looking for data sets which are divided into a treatment and control group and where a ""treatment effect"" can be identified.
It is important only that the sample is ""large"", since we want to be able to run computations on sub-samples. ""Large"" is in this context simply defined as "" even with a sub-sample of the data, the main treatment effect can be identified.""

The field from which the data stems could be any (e.g. medicine, economics, biology, pol sci).
""Treatment"" should be random, binary and ideally without any stratification (simply i.i.d Bernoulli)
It is fine (and even desired) if this data has been studied extensively in previous studies.

The more independent data sets we could get the better.
Update/Edit:
I feel I need to add that I placed the bounty after the first two answers were given, with  the intention of rewarding additional answers!
","['data-request', 'randomized-trial']",
Dataset for emotion classification,"
I'm looking for a dataset for moods or emotions (Happy, Angry, Sad) classification. That's to classify the sentiment of a given text. I would like to use Naive Bayes classifier for this analysis. Not only to train and test the model with the dataset, but rather to practice doing sentiment classification. Do you suggest any resources?
","['data-request', 'machine-learning', 'research', 'sentiment-analysis']","Some nice data sets for practicing sentiment classification are:These are some open datasets which contain emotions like happy, sad, etc:"
Looking for structured US Secretary of State public schedule,"
I'm trying to track down a structured version of the public schedule for the Secretary of State, during Clinton's term. I don't care about under/deputy/assistant secretaries either, just the Secretary.
The data is available online here: http://www.state.gov/r/pa/prs/appt/index.htm. It has many (but not all) days. However, it's messy and unstructured enough that simple web parsing is unreliable.  So, does anyone know if this is already available in a structured format?
To clarify, I'm interested in specific events with time and a description. Perhaps an XML calendar feed (but I want data back to 2009). Another idea would be a CSV with columns for Date, Time, Description, and Media Coverage:
2015-11-14,9:40 a.m. LOCAL,""Secretary Kerry meets with the Tunisian National Dialogue Quartet, in Tunis, Tunisia."",(CLOSED PRESS COVERAGE)
2015-11-14,10:30 a.m. LOCAL,""Secretary Kerry participates in the U.S.-Tunisia Strategic Dialogue Plenary, in Tunis, Tunisia."",(POOLED CAMERA SPRAY AT THE TOP)

","['data-request', 'usa', 'state', 'federal']",
Grouped vocabulary list as .txt or .csv files,"
I'm working on a project with email data.And simply i need to group up all the emails according to suitable categories. Therefore, i use the dictionary mapping method. So, 
My project required lots of word/vocabularies related to categories like Business, Academic, technology, personal ,political, entertainment and so on.
I found few websites(eg:like) its provide words around 20-50 for each categories. i'm looking for little large data set to increase my accuracy of classifying. any help appreciated.
thanks in advance.
","['data-request', 'csv', 'dictionary', 'txt']",
Library containing dictionary definitions,"
I'm looking for some sort of library (preferably .NET, XML, or JSON) that can provide me with words and their definitions. But, I would prefer for it to be local on my machine. I've looked into the Webster's online API, but again, I would prefer it to be local on my machine and also not have the limitations.
I'd like to think that there probably something already on my Windows pc that I could just tap into.
",['dictionary'],"WordNet from Princeton:
""WordNet® is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. Synsets are interlinked by means of conceptual-semantic and lexical relations. The resulting network of meaningfully related words and concepts can be navigated with the browser. WordNet is also freely and publicly available for download. WordNet's structure makes it a useful tool for computational linguistics and natural language processing.""
http://wordnet.princeton.edu/"
Health rated data and information in Ghana and Kenya needed,"
I am a student from georgetown university. I am doing a research on health instruments sterilization in Ghana and Kenya. I am wondering if any one can help me find the data or information to following answers:

What type of autoclaves (brand name)  are hospitals in Kenya and Ghana using?
What is the average cost of purchasing these autoclaves?
How frequently is the autoclave used in a day?
How long is one cycle (two hours, eight hours, etc)? How much is the electricity consumption per cycle? 
How much water is needed per cycle?
Is there a backup generator? How much does it cost? How often does it operate?
How is maintenance support provided for autoclaves in the facility? How much does this support cost? How often is maintenance required?
If a facility does not use an autoclave, what are they using for sterilization? 

If you know where to find these data or know someone who may know these data, please feel free to contact me.
Thank you very much! !
","['data-request', 'medical']",
Sierra Leone Ethnic Groups - Shapefile,"
I am looking for open data on the Sierra Leone Ethnic groups.
Preferably in Shapefile format or any other format that can be used on a map.
So far I created a map with the districts and their population (population was just for testing purposes) in R. Now I want to overlay these districts with the Ethnic groups located in Sierra Leone.
Such as show in this image.
My search on the internet didn't come up with any Shapefiles regarding Ethnic Groups in Sierra Leone. Maybe someone knows where I can find these?
Also if it's not to difficult and time consuming I can try to create one myself... Although some advice on this will be very helpful!

","['uses-of-open-data', 'programming']",Google search:african ethnic groups GISFirst item: ArcGIS.com | Feature Service - Ethnic Groups in Africa
Tools and steps for converting 3-star data to 4 star,"
I am working on a project to upgrade a set of 3-star open data (mostly in CSV and JSON formats) to a 4-star level. I would like to know if there is any guideline for doing so? What tools may be needed to speed up the process? Examples of the conversion process will be of great help.
","['conversion', '5-star-scheme']",
STRIDE data all years,"
The DEA collects data on illegal drugs and makes one year available here: http://www.dea.gov/resource-center/stride-data.shtml. I need this data for every year since 1999. What is the best way to get it?
","['data-request', 'drugs']",
Looking for chat bubble icon in SVG format [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 7 years ago.







                        Improve this question
                    



I want to implement an iMessage like chat screen, and I need images like the two below. But in a flat style like what in iOS 9 Apple uses.


",['images'],
Open database for ski resorts/stations,"
I'm looking for an open database which contains information about Ski Resorts (called too as Ski Stations or Winter Stations), in Europe preferably.
",['sports'],
Heat map of Belgium,"
Is there a heat map covering Belgium? having enough resolution to be able to differentiate between houses would be ideal.
",['geospatial'],
Where can I find open data about sport's competitions?,"
I have been looking for formula one racing open data, but I haven't found anything...
I'd need open data about any sports or about topics like health, university etc... to build up a project of datawarehouse
","['data-request', 'sports']",
Looking for conversation transcripts,"
I am looking for conversation transcripts. These can be from real sources such as radio or TV interviews, or even phone and IM captures, or fictional conversations such as plays and movies.
I don't need the actual audio/video, I am only looking for transcripts at this time. Personally identifying information is unnecessary, aliases or even [SPEAKER 1] would be fine. 
I would prefer to avoid mixed narratives like ""This American Life"".  
YouTube could be a good source for interviews that have closed-captioning.  In which case I just need the list of videos.
Thanks
","['data-request', 'nlp']",
Looking for the smoking count or rate per census tract in New York State,"
It seems like this only exists at the county level here - PA-Percentage-of-Cigarette-Smoking-Among-Adults
","['medical', 'census']",
Looking for sample lat/long data of thousands of US addresses,"
In order to test some mapping and geocoding functionality, I'm looking for a free data source containing a few thousand US addresses, including latitude and longitude. I need them distributed among a number of states.
","['data-request', 'usa', 'geocoding', 'csv']",Some time on Google brought up this list of 8902 Starbucks around the US: http://www.gpspassion.com/forumsen/topic.asp?TOPIC_ID=67416Here it is as a gist: https://gist.github.com/dankohn/09e5446feb4a8faea24f
How do I acquire bike network shapefiles for a particular region?,"
I'm working on a bike project that spans a number of cities in a region. Some of the cities have their existing bike infrastructure available as open data, but not all.
Is there a way to extract from OpenStreetMap or some other source only the bike infrastructure network, which preferably has a breakdown of facility type (sharrow, bike lane, protected bike lane).
","['data-request', 'usa', 'geospatial', 'openstreetmap']","Yes; go to overpass turbo and build your query based on cycleway tags. It's not guaranteed that OSM will have official open data in it, as manual collection and addition always takes priority over imports.You might also want to ask on OpenStreetMap Help Forum."
What is the coverage of Google case law for New York state?,"
I can't seem to find how any information about what kind of coverage Google offers for case law, what the selection for cases is, etc. Does anyone have any idea? I literally don't see any comments at all. 
","['usa', 'legal']",
Collection of related datasets (akin to transfer learning),"
I am trying to do a certain kind of evaluation (not worth detailing here), and I am on the lookout for a collection of related datasets.
Allow me this simplistic (and unrealistic perhaps) example in order to clarify what I am looking for:

Imagine having multiple ""Iris"" datasets.
Each of these datasets measures the same thing. By this I mean the same (type and number) of features appear in all the datasets, and they are associated with the same kind of target (regression value/label).
In the case, of the Iris dataset this would mean, that in all datasets, the data items are composed of the same four features and all associated with one of the three labels. The distribution of features, however, in each dataset can be different (also the proportion of classes can be different).
Is anybody aware of such a collection of datasets?

So far I have been looking into transfer learning literature, but have not managed to find something like this so far.
ps. This question was previously posted on the Data Science forum where it was deemed off-topic.
","['data-request', 'machine-learning']",
Dataset: Car types by country,"
I am looking for a free dataset that shows the number of car types sold/in use in every country.
For example:
Italy: SUV: 2.500.000
          Sedan: 3.00.000
          ...
Spain: SUV: 3.500.000
            Sedan: 4.00.000
         ...
I just found datasets about cars manufactured in countries.
","['data-request', 'transportation', 'global']",
In which cases is a waveform recording split into two recordings in MIMIC WDB 2v3?,"
http://physionet.org/physiobank/database/mimic2wdb/ lists two cases where one waveform recording is split into two recordings:

a patient was admitted more than once to any of the study ICUs during the study period
gaps of an hour or more have been split into separate records

Are there other cases that cause a waveform recording to be split into two recordings in MIMIC WDB 2v3?
",['mimic-iii'],"Technically, those are the only two reasons for a waveform record to be split into two segments. However the actual underlying reason why the gap occurred varies."
How often does a waveform record come from two or more patients?,"
http://physionet.org/physiobank/database/mimic2wdb/ says:

the raw data file [might] contain data from two (or more) patients.

Is there any estimation of how often a waveform record comes from two or more patients?
",['mimic-iii'],
Example of credit card usage data,"
I want to understand the data saved when a person uses his or her credit card in a shop or online. Is there a common data set format for this? If so, what does it contain? Furthermore, can anyone point to an example dataset?
I know that in the telecommunications industry one standard format used is the call detail record (CDR) for making calls or sending texts. I'm trying to find the ""bank equivalent"" of such a format for credit card usage.
I've seen A typical bank database for credit card accounts? and Credit card metadata database, but these are related to the numbers used for the accounts associated with the credit cards, whereas I'm interested in the information captured every time the card is used.
","['finance', 'data-format', 'bank']",
Show areas defined by sets of latitude/longitude,"
I have a list of casinos. Each casino has:

latitude
longitude
boss (a single boss runs from 1 to 50 casinos)

Sample:
40.642 -73.997 Freddy Queens
40.680 -73.985 Freddy Queens
40.697 -73.949 Freddy Queens
40.651 -73.968 Freddy Queens
40.772 -73.981 Manhattan Michael
40.813 -73.939 Manhattan Michael
40.755 -74.000 Manhattan Michael
40.781 -73.964 Manhattan Michael
40.721 -74.062 Nicole Je. Polizzi
40.750 -74.042 Nicole Je. Polizzi
40.694 -74.090 Nicole Je. Polizzi
[... 70,000 casinos for 27,000 bosses ...]

From this data I want to generate a map like this:
 (hand-drawn representation, not accurate)
One color per boss. The casinos of each boss should not ""overlap"" too much.
The final goal is to find anomalies (casinos that should be transferred to a different boss because they are clearly in that boss' ""territory""). Boss ""territories"" do not match any official geographical subdivisions, for all that matters the same problem could be set on Mars (Earth map background would be nice though).
Is there a webapp (desktop program also OK) to which I could feed this data (CSV) and that would show this kind of map? It can look different, for instance monochrome areas would be OK too, as long as it can be used to detect anomalies.
",['geospatial'],
Open Audio Database of English Letters,"
I have embarked on a project to gather spoken english letters into a free and open database. I call it the English Alphabet Audio Database.
My question is simple: does any other such database already exist? I could not find one which is why I made this one but I wanted to be doubly sure and I thought that this community might be able to help.
","['english', 'audio']",
historical price data for Sdax Index,"
I am looking for historical price data in .csv or .txt format to download for the following financial instrument:
Sdax Performance Index (It's a german smallcap indice in case you care)
ISIN: DE0009653386
RIC: ^SDAXI

I need the data starting from 30.12.1987 as far as possible.
","['finance', 'germany']",
Facebook data Africa,"
say I want all users along with their friend lists across all of Africa. The user data needs to be georeferenced. Is this possible to obtain?
","['data-request', 'africa']",
diagnoses_icd.sequence in MIMIC-III: does the order matter aside from the primary diagnosis?,"
The column diagnoses_icd.sequence, according to the documentation:

provides the order in which the ICD diagnoses relate to the patient. ICD diagnoses are ordered by priority.

Does the order really matter aside from the primary diagnosis (i.e. does the diagnoses_icd.sequence matter when diagnoses_icd.sequence > 1)?
I see diagnoses_icd.sequence has values that range from 1 to 39:
SELECT distinct(sequence),  COUNT(*)  
FROM  mimiciii.diagnoses_icd 
GROUP BY sequence
ORDER BY   sequence ASC  ;


",['mimic-iii'],
Detecting use of vasopressor in a patient in MIMIC,"
To detect whether vasopressor was used for a patient in MIMIC, is looking at the presence of itemids whose labels are dobutamine, dopamine, epinephrine, epinephrine-k, levophed, levophed-k, vasopressin, milrinone, neosynephrine, neosynephrine-k in d_items enough? (case insensitive, as done by https://github.com/MIT-LCP/hdlvef/blob/master/sql/echo_vasopressors.sql)
or shall one be more exhaustive like:
SELECT d_items.label, MIN(d_items.itemid) item_id, count(distinct(hadm_id)) hadm_id_count
FROM  mimiciii.d_items, mimiciii.chartevents
WHERE chartevents.itemid = d_items.itemid
AND (
upper(label) like '%DOBUTAMINE%'
or upper(label) like '%DOPAMINE%'
or upper(label) like '%EPINEPHRINE%'
or upper(label) like '%LEVOPHED%'
or upper(label) like '%VASOPRESSIN%'
or upper(label) like '%MILRINONE%'
or upper(label) like '%NEOSYNEPHRINE%')
group by d_items.label
ORDER BY label ASC 
;

and
SELECT d_items.label, MIN(d_items.itemid) item_id, count(distinct(hadm_id)) hadm_id_count 
FROM  mimiciii.d_items, mimiciii.ioevents
WHERE ioevents.itemid = d_items.itemid
AND (
upper(label) like '%DOBUTAMINE%'
or upper(label) like '%DOPAMINE%'
or upper(label) like '%EPINEPHRINE%'
or upper(label) like '%LEVOPHED%'
or upper(label) like '%VASOPRESSIN%'
or upper(label) like '%MILRINONE%'
or upper(label) like '%NEOSYNEPHRINE%')
group by d_items.label
ORDER BY label ASC 
;

which returns many more though not widely used itemids:

",['mimic-iii'],
Mapping between MIMIC-II v2.6's meditems' itemids and MIMIC-III d_items?,"
I wonder whether there exists a mapping between MIMIC-II v2.6's meditems' itemids and MIMIC-III d_items.
",['mimic-iii'],
How to map WFDB_Annotation().getTime() to actual timestamps?,"
I'm trying to link some arterial blood pressure beats that I extracted from the MIMIC waveform database to events in the MIMIC clinical database. I obtained the arterial blood pressure beats using WFDB to get the beat onsets. For the beginning of a beat, I call WFDB_Annotation().getTime() to get the sample number to which the annotation ""points"". How can I map it to an actual timestamp (e.g. 2015-05-24 17:47:59) so that I can link it to events in the MIMIC clinical database?
Assume that the sampling frequency is 125 Hz, and that the waveform record started at timestamp 2567-03-30 17:47:59 (which I believe we can see in the waveform header, e.g. s00020-2567-03-30-17-47.hea) for patient s00020:  if WFDB_Annotation().getTime()  returns 65133, is the actual timestamp 65133/125 + 2567-03-30 17:47:59?
",['mimic-iii'],
Where to find the most recent mapping between Clinical and Waveform Records?,"
I saw a few mappings between Clinical and Waveform Records:

http://www.physionet.org/physiobank/tutorials/using-mimic2/#linking (MIMIC Waveform database 2V2)
http://physionet.org/physiobank/database/mimic2wdb/MAP-CW (MIMIC Waveform database 2V3)
http://physionet.org/physiobank/database/mimic2wdb/matched/ (MIMIC Waveform database 2V3 +  MIMIC II Clinical Database version 2.6 (or later))

Is the last one in this list the most recent mapping between Clinical and Waveform Records?
http://physionet.org/physiobank/database/mimic2wdb/MAP-CW looks incomplete. It has no patient whose ID is greater than 26715 while http://physionet.org/physiobank/database/mimic2wdb/matched/ has up to 32805.
",['mimic-iii'],
Is there a log of BIDMC's bed capacity changes?,"
I heard that one more MICU was added in 2008 (8 bed unit was added as MICU7). Is there a log of BIDMC's bed capacity changes somewhere, or at least a log of addition/deletion of ICUs? I guess I could infer some approximation of it from the data but if it already exists I'd be interested.
",['mimic-iii'],"Based on conversation with staff I believe that the hospital does keep a log of changes to resources such as bed capacity. These records are not available to the Laboratory for Computational Physiology at this time, however, so the information that you are looking for has not been incorporated into the MIMIC database. If the records are made available to the laboratory in the future, then the situation may change."
Are the APACHE scores available somewhere?,"
I wonder whether APACHE scores are available somewhere in MIMIC-III.
There doesn't seem to be any widely used APACHE ITEMIDs in the table CHARTEVENTS:
 SELECT LABEL,  COUNT(*) cnt
 FROM  mimiciii.CHARTEVENTS,
 mimiciii.d_items
  WHERE LOWER(d_items.LABEL) LIKE '%apache%'
  and CHARTEVENTS.itemid = d_items.itemid
   GROUP BY d_items.LABEL
 ORDER BY cnt DESC ;


",['mimic-iii'],"""Acute Physiology and Chronic Health Evaluation"" (APACHE) scores are rarely recorded by caregivers, so they are not well documented in the core MIMIC dataset.Several APACHE-related itemids appear in the d_items table, as shown in the question, but there are few associated values in the chartevents table. APACHE scores also appear as free text in the NOTEEVENTS table (for example, ""On admission, APACHE II score of 10...""), but again infrequently.The MIMIC research community is developing code to calculate scores retrospectively which will be shared in the MIMIC Code Repository."
Why are some transfers.ICUSTAY_ID null?,"
Why is the ICUSTAY_ID null for some rows in the transfers table?
-- returns 174176 rows
SELECT * FROM mimiciii.transfers  
WHERE ICUSTAY_ID IS NULL
ORDER BY ICUSTAY_ID ASC ;


",['mimic-iii'],"The transfers table provides a record of the movements between wards made by patients during a hospital stay. Not all of the transfers listed in the table are made between intensive care units.If the current care unit (curr_careunit) is an intensive care unit then we would expect the icustay_id to be populated. If the curr_careunit is not an intensive care unit, we would expect the icustay_id to be null.An empty field in the curr_careunit or prev_careunit indicates that the care unit is not an intensive care unit. In addition, certain other entries may not be intensive care units (for example, 'NWARD' is a ward for newborns). To summarise, all or almost all of the icustay_ids returned by your query are expected to be null because the curr_careunit is not an intensive care unit."
Is the patient's height available?,"
Is the patient's height available in MIMIC-III? In my use case, I would be interested in having it in order to compute the patient's ideal body weight.
On Oracle DB:
SELECT  *
FROM all_tab_columns
WHERE LOWER(column_name) = 'height'
AND owner = 'MIMIC';

or on PostgreSQL:
select table_name 
from information_schema.columns
where LOWER(column_name) LIKE '%height%';

didn't return anything.
Looking at the D_ITEMS:
SELECT *
FROM mimiciii.D_ITEMS
-- not ideal, but %ht% will find labels containing 'Ht' and 'Height'
WHERE lower(label) like '%ht%'
ORDER BY label ASC;

there are a few itemid of interest:

But using them to look for heights in chartevents table only returns the heights for a fraction of patients (mostly neonates):
-- Result: 12958 rows 
SELECT ICUSTAY_ID, MIN(VALUENUM) mini, MAX(VALUENUM), 
  AVG(VALUENUM), STDDEV(VALUENUM)
FROM mimiciii.CHARTEVENTS 
WHERE ITEMID IN (920)
AND VALUENUM IS NOT NULL
AND VALUENUM > 0
GROUP BY ICUSTAY_ID
ORDER BY mini ASC
;


-- Result: 11385 rows 
SELECT subject_id, MIN(VALUENUM) mini, MAX(VALUENUM), 
  AVG(VALUENUM), STDDEV(VALUENUM), COUNT(*) cnt
FROM mimiciii.CHARTEVENTS 
WHERE ITEMID IN (920)
AND VALUENUM IS NOT NULL
AND VALUENUM > 0
GROUP BY subject_id
ORDER BY mini ASC
;

Are the patients' heights available somewhere else?
",['mimic-iii'],"You can use this query (tested on MIMIC-III v1.1, took around 80 seconds to run on my computer):Some statistics:It will create the following table:If you prefer to group by hadm_id instead of icustay_id, you can simply replace icustay_id by hadm_id in the table creation query:Some statistics:This will give you:If you want to all get the means of heights and weights for each patient:output:To add the ideal body weight:"
How to get the list of ICUSTAY_IDs that happened in a given HADM_ID?,"
In the MIMIC-III database, I wonder whether there is an easy way to obtain the list of ICUSTAY_IDs that happened in a given HADM_ID.

",['mimic-iii'],"In MIMIC 2V30, to get to the list of ICUSTAY_IDs that happened in a given HADM_ID, you can use:or maybe to account for the fact that ICUSTAYEVENTS.OUTTIME is often after ADMISSIONS.DISCH_DT:In MIMIC-III, it's much easier:It can still use the same strategy as the one used a for MIMIC2V30, but it will yield a less complete list:"
Any APIs available that provide data of Indian vehicles?,"
I was looking for APIs that provide current latest data of vehicles (2-wheelers/4-wheelers) in India. I found quite a few but none had data of Indian vehicles. I looked at this question which is almost same as mine but couldn't get any help either.
I found one website http://dataweave.in/apis/usage/15/Car-Prices-India which has some of the data I'm looking for but unfortunately, it is very old data and not really of much use to me.
Does anyone know any good API sites for Indian vehicles or APIs that provide Indian vehicle data too?
Thanks in advance!
","['api', 'india']",
Is there a openFDA Data Pipeline version supported for Windows?,"
Everything in the openFDA data pipeline API seems Linux-centric, including several dependencies; dependencies require me to compile the source because packages only exist for Linux (like leveldb). 
I don't want to go through all the trouble to find it still not working. So, is this supported for Windows?
","['openfda', 'api']",
Where do I find what to put in queries to openFEC,"
Trying to use the openFEC API but can't make the most simple query. Trying to search for current candidates, I need a ""district"" and a ""cycle"" but have no idea where to get this information. 
","['api', 'openfec']",
Does Rutgers University Provide Open-Source Geospatial Datasets?,"
Might these datasets include business names, addresses (some goecoords), County, CBSA, NAIC, SIC, USPS Postal Carrier route and more information for United States and Canada?. 
",['releasing-data'],
Immigrant destination by city of entry or city of birth,"
I need a data set that contains variables for immigrant location and city of entry into the US. Alternatively, I could use immigrant location and city of birth outside the US. 
The US census contains variables for country of birth, but I need more detailed geographic area. Is there an immigration data set that contains these variables? 
","['data-request', 'migration']",
How do I get paginated data sorted by load date from the OSHA api detailed here?,"
http://developer.dol.gov/health-and-safety/dol-osha-enforcement/#osha_accident
Without pagination it's useless and I'm forced to download and parse the entire CSV file.
","['api', 'labor']",
"Batch conversions of lat, lon to US census tract?","
I have 700,000 latitude/longitude pairs I need to convert to US Census tracts. Is there a free API that offers this in batches? So far the only option I have found is from the FCC and does not state a rate limit but has the form of a 1-1 call to return.
",['us-census'],
Can I get 1000 images from any image search engine for education/research purpose?,"
I'm researching on machine learning system that learns to recognize items based on image search results from search engine. After I searched around I found that Google and Bing Image Search api allow only small number of images and doesn't allow script/bot to makes the search request.
I want to get about 1000 images for one item. Does anyone know is it possible to do this using Google, Bing or any search engine? Though free search engine is preferred, but any paid one is also welcomed.
Best regards.
","['data-request', 'api', 'machine-learning', 'images']","In addition to the API, you can use a bulk downloader* tool to collect images from a Flickr groupExample of bulk downloader toolExample of Creative Commons group (pool)Wikimedia Commons Public Domain ArchiveOther ideas*instead of a bulk downloader tool, you can use wget "
Where can I find a global life expectancy table?,"
I've found good information on specific countries and demographics, but I can't seem to find global numbers. I know that the world life expectancy is around 71.0, but I'm trying to get a percentile breakdown in the form of something like an actuarial life table.
I've checked out sources like the WHO and the Worldbank, but it doesn't really give me the data I'm looking for. I want something that is in a format similar to the SSA life table.
","['data-request', 'demographics', 'biology', 'global']",
Seeking gis data or geospatial wildfires,"
I am looking for information about data that has wildfires in the United States but I am interested more specifically in Colorado. Do not be confuse with the Forest Fires. How or where do I find the GIS or geospatial data ?
","['data-request', 'geospatial']","Wildfire Location Data: National Interagency Fire Center (NIFC) supplies the fire data to geomac
https://www.nifc.gov/fireInfo/nfn.htmNIFC Statistics
https://www.nifc.gov/fireInfo/fireInfo_stats_totalFires.html Office of Wildland Fire funds geomac
https://www.doi.gov/wildlandfire Wildfire - Wildland Fire Information Federal Fire Occurrence Website
http://wildfire.cr.usgs.gov/firehistory/data.htmlDaily Incident Map
http://activefiremaps.fs.fed.us/lg_fire2.phpInciWeb Incident Information System has a lot of fire data, but you can search by wildfire
http://inciweb.nwcg.gov/ GeoMAC - existing wildfire situation in continental US and Alaska
http://www.geomac.gov/Boulder has wildfire parameters, boundaries and a few more like that, which aren't live fire data, but you may find useful:
http://www.bouldercounty.org/gov/data/pages/gisdldata.aspxOpenColorado has two more sets from Boulder, not sure but I'm guessing there may be overlap there:
http://data.opencolorado.org/dataset?q=wildfire Here's an old Denver wildfire .kml
http://extras.denverpost.com/media/maps/kml/2013/ColoradoWildfires2013BlackForestRoyalGorgeBigMeadows.kml Virginia's Department of Forestry Wildland Fire, Incident and Suppression Resources, and Wildfire Risk Assessment for the state and regions:
http://www.dof.virginia.gov/gis/dwnload/index.htmVirginia's Department of Forestry Wildland Fire Incidents Map
https://vdof.maps.arcgis.com/home/index.htmlMODIS satelitte imagery via NASA
https://earthdata.nasa.gov/data/near-real-time-data/data/hazards-and-disasters/fires
https://earthdata.nasa.gov/data/near-real-time-data/firms/active-fire-data
http://lance-modis.eosdis.nasa.gov/cgi-bin/imagery/firemaps.cgi "
Multi-Sample Reliability Data that follows Weibull Distribution,"
I am looking for a real-worlds k-sample (k>3) reliability data (complete not censored) that follow a two-parameter Weibull distribution with shape parameter β and scale parameter θ. I want to compare k  reliability function at time t* which is defined as R(t*)=exp[-(t*/θ)^β].
Any hint, link or reference to a particular data-set would be appreciated. Preferably, data should be large enough so that Weibull distribution can be fitted by means of ML procedure.
","['data-request', 'reliability']",
Data for testing sequence tagging algorithm,"
I am currently performing research in field of sequence tagging algorithms and I need dataset to compare some algorithms like CRF on this dataset. I have already found CoNLL2000 POS recognition dataset, but I need something more general, with real numbers for example.
","['data-request', 'machine-learning', 'research']",
Research paper on machine failure prediction or predictive maintenance [closed],"







Closed. This question needs to be more focused. It is not currently accepting answers.
                                
                            











Want to improve this question? Update the question so it focuses on one problem only by editing this post.


Closed 7 years ago.







                        Improve this question
                    



My graduation project is about machine failure prediction or predictive maintenance. I want to know what had been done in this fields, what's similar and what is the different between these projects.
Where can I find data sets about machines failure (ex: sensors read temperature, vibration ...) 
I have tried a lot to find some useful links but i can't find any link ! 
","['data-request', 'research']","Take a look at my answer here. Basically, it goes over a primary manufacturing technology that allows collecting data from various machine tools. However, the same MTConnect ""standard"" can be applied to anything that can be digitally monitored using sensors. Take a look at this ""live"" (but fake) XSLT stream from a 3-Axis mill."
Number of Museums' visitors and ticket revenue,"
I am looking for details about Museums' visitors and revenue from tickets, in specific European Museums.
I made a simple Google research and couldn't find something useful. Only a couple of pages where other people were looking the same data as me.
Ideally, I would love to have in addition a dataset of reviews for each of the museums. For example, tripadvisor reviews.
Are you aware any dataset like this or any way that I could construct it myself?
","['data-request', 'historical', 'europe', 'glam']",
Syntax for tobacco use on healthcare.gov API,"
I am trying to use the healthcare.gov api for accessing plan data.  The sample POST request includes the following syntax for encoding tobacco use:
   <p1:TobaccoLastUsedMonths>2</p1:TobaccoLastUsedMonths>

I don't understand what this means.  Does this mean tobacco was last used two months ago?  How would I indicate that tobacco was never used?
",['healthcare-finder-api'],
National Flood Insurance Data,"
I'm looking for any data on the National Flood Insurance Program. I've already found a bit but I'm curious if I'm missing anything. Here's what I have:
FEMA Flood Risk Rate Maps- https://catalog.data.gov/dataset/national-flood-hazard-layer-nfhl
Loss statistics/policy information from http://bsa.nfipstat.fema.gov/reports/reports.html
The link above has a variety of reports but only the most current are posted when I asked FEMA for access to historic records I was told to file a FOIA which I did but if the records are archived anywhere online (I've already downloaded everything on the Internet Archive's site) I would be very interested.
Thanks!
","['government', 'weather']",
GIThub to share a set of SPARQL queries,"
I am using github to share a set of SPARQL queries:
http://www.boisvert.me.uk/opendata/sparql_aq+.html?file=specific%20sensor.txt
Currently the simple work allows end-users to access queries stored on the github repository, but ultimately I want to allow them to also modify the queries, as with a pastebin, and make use of the repository to better manage the shared system. Ideally I would want end-users who may not be very tech-savvy, to be able to make minor changes to queries to an open, linked data endpoint: so to keep the technology barrier low.
My problem is this: how best to structure the github project and exploit the API to make the most of the available information? I can think of different points:

Currently the project (https://github.com/boisvert/unshaql) holds client code and example queries. Does it make a difference to create an independent project (separate from the web client code) for SPARQL queries?
I would use directories within the project to classify/tag queries, and file names to title them. Are there better alternatives? It strikes me that a hierarchical structure is not a good fit to tags.
When end-users save, a simpler (and cruder) option is to allow them to push their file into just one branch, which holds the examples. A better engineered one would be to allow them to use their github credentials to fork the set of SPARQL queries and edit theirs, but with unaware users, how do I avoid creating a mess?

","['linked-data', 'sparql', 'git']","You could allow users to upload/email .txt files containing queries, or upload URLs (e.g. pastebin, gist). Then your local code would read these .txt queries and add them to the repository (also standarized the query, validate the query, format the query, etc)."
U.S. Sports Scheduling Data at a League level,"
I am looking for a database or API or something to poll from that will give me current and future (a bonus would be past as well) data for Major League sports (Basketball, Hockey, Football, Baseball) and the schedules thereof. Minor leagues would also be awesome as well.
Overall I have yet to find a legitimate source for this data, that either doesn't cost thousands of dollars a year to licence or is even remotely valid data. I am hoping someone here can point me in the right direction.
Ideally I'd like to find some scores as well, but that's moot in comparison to what I need overall, which is 

team vs team names, 
schedules in one timezone or at least 
knowledge of what timezone the schedule implies for the time of the game vs location thereof. 
Knowing if its a home game for one team or the other is also fantastic. 

But overall what I want to know is what teams playing when. The rest is bonus nice to have stuff.
","['data-request', 'sports']",
Data on ethnicity of African names,"
Is there any data that lists the first/last name along with the dominant ethnicity associated with the name? I'm mostly interested in Africa. 
","['data-request', 'demographics', 'names', 'africa']",
When will the API V3.0 be updated for 2016 Rates,"
According to the API overview:
""Beginning October 23, 2015: The Finder Plan Benefits and Coverage API will be updated to include 2016 plan year data.""
I could very well be entering the wrong effective date:
<p:InsuranceEffectiveDate>2016-01-01</p:InsuranceEffectiveDate>
I get no results.  Am I going about this wrong or is the data not available yet?
",['healthcare-finder-api'],
Data set of objects with properties,"
I am looking for data sets containing a list of objects or concepts as well as some of the properties.
Example 1:
#Format: [identifier][concept][feature][annotator1][annotator2][annotator3]
1   accordion   a_musical_instrument    all all all
2   accordion   associated_with_polkas  concept most    most
3   accordion   has_buttons all all all
4   accordion   has_keys    all all all
6   accordion   produces_music  all all most
7   accordion   requires_air    all all all
8   accordion   used_by_moving_bellows  all all all
9   accordion   worn_on_chest   all all all
10  airplane    crashes few some    few
11  airplane    flies   all all all
12  airplane    found_in_airports   most    all most
13  airplane    has_a_propeller some    some    some
14  airplane    has_engines all all most
15  airplane    has_wings   all all all
16  airplane    is_fast all some    some
18  airplane    made_of_metal   all most    most
19  airplane    requires_pilots all all most
20  airplane    used_for_passengers all some    some
21  airplane    used_for_transportation all most    most
22  airplane    used_for_travel all most    most
23  alligator   an_animal   all all no
24  alligator   a_reptile   all all all
25  alligator   eats_people most    few few
26  alligator   has_a_mouth all all all
27  alligator   has_a_tail  all all all
28  alligator   has_jaws    all all all
29  alligator   has_scales  all all all
30  alligator   has_teeth   all all all
32  alligator   is_green    most    some    some
33  alligator   is_long all some    some
35  alligator   lives_in_Florida    most    some    some
37  alligator   lives_in_water  all all some
38  alligator   swims   all all most

Example 2:

1 row = 1 object (aka concept)
1 row = 1 property (aka feature)
cell value: indicate how frequently the object has the property. 0 = never, 1 = always.



So far I have found:

herbelot_iwcs13_data.txt 
(Aurelie Herbelot. 2013. What is in a text, what isn’t, and what this has to do with lexical semantics. In Proceedings of the Tenth International Conference on Computational Semantics (IWCS2013), Potsdam, Germany.)
mcrae-quantified-majority.txt (
Aurelie Herbelot and Eva Maria Vecchi. 2015. From concepts to models: some issues in quantifying feature norms. Linguistic Issues in Language Technology. To appear.)

","['data-request', 'nlp']",
Finding data yielded in search results,"
I am looking to access datasets surrounding Medicaid enrollment, Medicaid buy-in, Medicaid statistics, eligibility criteria, etc.  My searches yield plenty of results, but the actual data comes back unavailable.  How do I access the dataset?  The results are: ""No file downloads have been provided. The publisher may provide downloads in the future or they may be available from their other links.""  
What are my options for finding the actual data?
","['data.gov', 'medical']",
Speech audio files dataset with language labels,"
I am working on building a language classifier in speech/audio samples. I have been trying to find a dataset which may have considerable number of speech samples in various languages. The audio files maybe of any standard format like wav, mp3 etc. containing human voice/conversation with least amount of background noise/music.
I am unable to find any such dataset. Can someone share link of any speech dataset that may be good for this research.
","['language', 'machine-learning', 'audio']",You can use the Tatoeba website which has full sentences in text and audio as downloads.Sentences with audioDownloadhttp://downloads.tatoeba.org/exports/sentences_with_audio.tar.bz2Fields and structureFile descriptionThanks to Nicolas Raoul in this answer.
Financial Accounts - Intersectoral Flow-of-Funds Data,"
I am looking for data that contains financial liabilites/assets of different sectors in an economy to other sectors for different countries. In Europe this is regulated by ESA 2010 (or ESA 95, the older version) and can be found here, the FED issues similar data in its Z1 release.
However, I need the intersectoral data, whereas both sources only deliver them accumulated. As an example, I want to know how many assets households own that are liabilities of the Government. The accumulated version would give the assets households hold originating in the other sectors.
I know that the German Bundesbank delivers this data in such a detail, and was wondering where I can find the data from sources that contain more than one country.
Any hint or direction where to look is highly appreciated.
Addition
I already talked to Eurostat (the first link), they do not provide intersectoral data. So is the OECD and the UN.
","['data-request', 'finance', 'federal']","Try the link below, 
is the datasets on multiple counties, I'm not sure if is all free but is a good start point. Is by countries( did not check if all countries are listed, saw for European Central Bank, Swiss, US, Brazil, China etc). ww.quandl.comlong-term debt securities database"
"Employer's website is ""web scraping"" from another site, can I be liable even though I did not write that code?","
So recently I came about an article about web scraping, and it said how most of the time scraping is illegal.  I did not know this in past, and did not know the website I was working on  was using a script to gather information from another website. Of course I don't work for this business anymore but I did let my boss know. My concern is, what if my company gets caught, am I liable?  I am scared since I did use the file that had the actual code-block that did the web scraping.  I did not write this code, but I did use the results that it extracted.  However, at the time I did not know this was bad, or knew even what the process was of getting the information that I was using.  Should I be concerned?  
","['legal', 'web-crawling', 'ethics']",
MIMIC-III Citation,"
Is there a new citation for MIMIC-III? If so, what is that citation?
If not, should we continue to use the citation for MIMIC-II?

@article{MIMICII, 
  Author = {Saeed, Mohammed and Villarroel, Mauricio and Reisner, Andrew T. and Clifford, Gari and Lehman, Li-Wei and Moody, George and Heldt, Thomas and Kyaw, Tin H. and Moody, Benjamin and Mark, Roger G.}, 
  Title = {Multiparameter Intelligent Monitoring in Intensive Care II (MIMIC-II): A public-access intensive care unit database}, 
  Journal = {Critical Care Medicine}, 
  Volume = {39}, 
  Number = {}, 
  Pages = {952-960}, 
  Month = {May}, 
  Year = {2011},
  Howpublished = {\url{http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3124312/}},
  Note = {}
}

",['mimic-iii'],
Data for the distribution of US household annual income by year and state,"
I am looking for data regarding the annual household income distribution filtered by year and state (and finer geographical feature like cities). In other words, I am looking for data with the following features (label being the number of earners):
year
state
income range (e.g. 10K-20K, finer better)
Does anyone know if there is a publicly available dataset containing these?
Thanks.
","['data-request', 'usa', 'us-census', 'income']",
List of inverse and polarity flip words required,"
I'm a computer science student and I'm doing a research on sentimental analysis with a large database. Therefore, i need to create dictionaries to mapping words. 
 Now i'm facing the problem of ""Double Negation"" in my project.
For an example:

""The eggplant is not bad.""
  contains the word bad but the sentence is a positive opinion about the eggplant. This is because the appearance of the negation word not, that flips the meaning of the negative adjective bad.

We could take into account these types of polarity flips defining a dictionary of inverters:
inv.yml

lack of: [inv]
not: [inv]
To fill this script i need hundreds of inverse words to get a good accuracy. 
can anyone help me to find a list of inverse word that can cause double negation. 
Any answer appreciated.
thank you
","['data-request', 'language', 'english']",
Open datasets on medicine/drugs and its uses in treatment,"
I'm looking for a dataset that contains a list of medicine/drugs and what is it used for.
Example :
Medicine        To treat
Paracetamol     Pain 
Paracetamol     Fever
Adderall        Narcolepsy

Is there any database that contain a dataset like this with/without using any query ?
","['data-request', 'medical', 'drugs']",
Where can I find data on the number of social media users who checked in to a store at any given period of time?,"
I want to build an application that helps the user figure out when, during a 24-hour period, to go to a store based on how busy that store will be. Ideally, the data will go as far back as possible (to account for seasonal trends). 
",['data-request'],
Database of adult sites,"
I would like to ban all adult content in my DNS/VPN service and I wouldn't like to outsource this. Is there a list of URLs I can use as a blacklist in my routers/servers?
Format doesn't matter and if it would be actively maintained that would be nice.
",['data-request'],
NDC's in Enforcement Reports - Package vs Product vs Product Description?,"
In queries such as this, for example, notice some results include a product_ndc and package_ndc, while others include a NDC in the product_description. Some include no NDC identifier in any field. 
Is there a way to reliably extract product_ndc and package_ndc and/or have NDC included in the product_description for every result in an Enforcement Report? Currently, it seems like about 1 in 10 results include any NDC identifier.  
My question is similar to this one posted last week. 
","['openfda', 'json']",
Admitted to the ICU before admission to the hospital,"
It would be expected that the time of admission to the intensive care unit would occur after the time of admission to the hospital. Sometimes, however, admission to the intensive care unit occurs before admission to the hospital. How is this explained?
",['mimic-iii'],"For around 61046 admissions out of the 61532 admissions (~99.2% admissions), the ICU intime occurs after the hospital admission time. SELECT i.intime - a.admittime as tdiff,
        a.subject_id, a.hadm_id, a.admittime, i.intime, 
        a.dischtime, i.outtime
FROM mimiciii.admissions a
INNER JOIN mimiciii.icustays i
ON a.hadm_id = i.hadm_id
ORDER BY i.intime - a.admittime desc;
For the remaining proportion of records where admission to the ICU is recorded as occuring before admission to the hospital, the time differences are generally very small.In all but 41 admissions the ICU intime occurs no more than 12 hours before time of admission to the hospital. In all but 2 admissions the ICU intime occurs no more than 24 hours before the time of admission to the hospital.In principle hospital admission time should not occur before ICU intime, but in some cases it is possible that administration delays or errors lead to date mismatches such as these."
Where did the attribute ICU_EXPIRE_FLAG go from MIMIC-II to MIMIC-III?,"
MIMIC is an openly available dataset developed by the MIT Lab for Computational Physiology, comprising deidentified health data associated with >40,000 critical care patients. It includes demographics, vital signs, laboratory tests, medications, and more. - MIMIC homepage
The MIMIC-III database currently provides a HOSPITAL_EXPIRE_FLAG. In the MIMIC-II database, a ICU_EXP_FLG was also available. Is there a particular explanation why it is not included in the MIMIC-III database?
",['mimic-iii'],The ICUSTAY_DETAIL table was shared by researchers at the Laboratory for Computational Physiology to simplify certain queries on the MIMIC-II database. It is derived from other tables within the database and so does not form part of the 'core' dataset.ICU_EXP_FLG is not included in MIMIC-III database (as of version 1.2) because we have not yet attempted to create derived tables such as ICUSTAY_DETAIL. We expect to do this in future and would welcome code contributions from the community (see the MIMIC Code Repository linked from http://mimic.physionet.org/).
Priority sequence column in diagnosis_icd,"
The order in the sequence column is related to the patient and based on priority. Priority of patients in critical care medicine are related to triage which is a scoring system including: 

the severity of the clinical condition
the urgency of the clinical condition

Examples are the Manchester Triage System. 
Besides that, patients are scored for reimbursement, which is very much influenced by the location and setting you work in.
Scoring severity of disease by priority and by reimbursement rules are frequently different. Patients can have from chronic diseases, requiring a huge amount of budget, but are not severe in the context of a critical care condition. 
Which ""priority"" logics or rules are used in MIMIC?
",['mimic-iii'],
MIMIC-III diagnosis column,"
I understand the fact that a diagnosis column as provided in the admissions table is difficult, almost impossible to structure. 
It is necessary however to specify the position of this diagnostic description. Because it is located in the table admissions and this table only relates to the hospital admission (HADM_ID), one could associate with the diagnosis of hospital admission. However, the website mentions : 

The DIAGNOSIS column provides the admitting diagnosis for the patient. The diagnosis does not use a systematic ontology: as of MIMIC-III v1.0 there are 15,693 distinct diagnoses for 58,976 patients. The diagnoses can be very informative (e.g. chronic kidney failure) or quite vague (e.g. weakness).

This suggests that distinct diagnosis are used related to ICU admissions (58,976). 
Even in an unstructured way, this diagnosis column is informative but it should be defined more clearly (diagnosis for ICU admission or hospital admission) and 58,976 ICU admission in stead of patients, right?
",['mimic-iii'],"That's a typo in the documentation page. 
The DIAGNOSIS column in the ADMISSIONS table is the diagnosis on hospital admission. It should read 58,976 admissions. It has been corrected now, and reads:The DIAGNOSIS column provides a free text diagnosis for the patient on hospital admission. The diagnosis does not use a systematic ontology: as of MIMIC-III v1.0 there are 15,693 distinct diagnoses for 58,976 admissions. The diagnoses can be very informative (e.g. chronic kidney failure) or quite vague (e.g. weakness). Coded diagnoses for hospital admissions can be found in the DIAGNOSES_ICD table.If you spot any issues with the MIMIC-III website documentation, I would recommend posting it on the associated GitHub repository issues:
https://github.com/MIT-LCP/mimic-website/issues"
Energy usage in Canada,"
I'm looking for the most recent data on energy usage by sectors in Canada. Statistics Canada has updated their table up to 2008. But this is too old. Where can I get more recent data, say 2014 or 2013, on energy usage?
","['data-request', 'energy', 'canada']",
Free public real time social data APIs,"
Similar question might have been asked before, but APIs are in constant flux and my question is quite specific.
At this point, are there any other free public real time social data APIs similar to Twitter's Streaming API?
","['api', 'social-media']",
Memory consumption MIMIC-III,"
How much memory is needed to join (psql) the patient and labevent table using: 
SELECT 
  patients.subject_id, 
  patients.gender, 
  patients.dob, 
  patients.dod, 
  patients.dod_hosp, 
  patients.dod_ssn, 
  patients.hospital_expire_flag, 
  labevents.subject_id, 
  labevents.hadm_id, 
  labevents.itemid, 
  labevents.charttime, 
  labevents.value, 
  labevents.uom
FROM 
  mimiciii.patients, 
  mimiciii.labevents
WHERE 
  patients.subject_id = labevents.subject_id;

It might be interesting to define the hardware requirements for researchers analyzing the MIMICIII database.
",['mimic-iii'],
Property ownership data,"
Is it generally considered open data who owns a given piece of property? I am looking at the San Francisco Property Information Map but it does not include any information about who owns a building, and it also includes several buildings in each search result.
Specifically, I'd like to generate a map of San Francisco by landlord, so anything that points me toward that direction would help.
","['city', 'real-estate', 'land']",
Current biohazard/disease outbreak dataset,"
I am looking for api or dataset that shows current disease outbreaks and/or biohazards around the world. I have not been able to locate this yet.
","['api', 'medical']","CDC
CDC Current Outbreak List:
http://www.cdc.gov/outbreaks/
Multistate Foodborne Outbreaks - Foodborne outbreaks listed by year
http://www.cdc.gov/foodsafety/outbreaks/multistate-outbreaks/outbreaks-list.html
Health Alert Network - Health alerts, health advisories, updates, and info service messages. Designed for public health and medical communities.
http://www.bt.cdc.gov/HAN/
Recent Outbreaks and Incidents - Events involving the CDC Emergency Operations Center
http://emergency.cdc.gov/recentincidents/index.asp
Morbidity and Mortality Weekly Report - Outbreak investigation reports included among other content. Note that outbreak material includes state health department investigations. Designed for public health and medical communities.
http://www.cdc.gov/mmwr/mmwr_wk/wk_cvol.html WHO
http://www.who.int
Outbreaks and emergencies listed on WHO index page:
Ebola outbreak
http://www.who.int/csr/disease/ebola/en/index.html
MERS-CoV outbreak
http://www.who.int/emergencies/mers-cov/en/index.html
Emergencies
http://www.who.int/hac/en/index.html"
"Does ""Salary After Attending"" variable include all attendees or only those who graduate?","
I'd like to chart some institutions' typical total debt variable against the salary after attending variable.  I know the typical total debt variable is only for students who complete, but what about the salary after attending variable?  The documentation report seems to suggest it includes all students, but I'm not sure.
",['collegescorecard'],
Is there a global database of all products with EAN 13 barcodes?,"
EAN 13 is an international system. Is there an API or database that contains all items that have these barcodes? Like all food, goods you can buy in a regular convenience store. Is there a global open database for this?

","['data-request', 'products', 'barcodes']",
How can I obtain OSHA 300 nursing home data?,"
I am trying to obtain OSHA 300 form data submitted by nursing homes.  Is this data available for download from the Department of Labor?  
",['labor'],
Looking for open dataset containing data for disease and symptoms,"
I am doing a data mining project on ""health prediction system"". 
So, Is there any open dataset containing data for disease and symptoms.
","['programming', 'python']",
Start and stop times for non-invasive mechanical ventilation in MIMIC,"
To obtain the start and stop times for non-invasive mechanical ventilation for each ICU stay event in MIMIC, I tried to use:
SELECT ICUSTAY_ID, MIN(CHARTTIME) start_mv, MAX(CHARTTIME) stop_mv
FROM mimiciii.CHARTEVENTS
WHERE ITEMID IN (225794)
GROUP BY ICUSTAY_ID;

since 
SELECT itemid, label, linksto FROM mimiciii.d_items 
WHERE LOWER(label) LIKE '%vent%' ORDER BY itemid ASC;`

returns

However, 
SELECT COUNT(*) FROM mimiciii.IOEVENTS WHERE ITEMID = 225794;

returns 0 so it doesn't work.
Which ITEMIDs should I look at to obtain the start and stop times for non-invasive mechanical ventilation in MIMIC?
E.g. for invasive mechanical ventilation, the ITEMIDs to look for are ('720', '722', '224685', '682', '683', '224686', '684', '224684', '721').
",['mimic-iii'],
"MIMIC-III: Why is the time stamp of prescription only ""per day""?","
How can I tell the exact time of prescription, or the start of medications?
",['mimic-iii'],"A critical care physician makes a prescription during morning rounds. That does not mean that any change is impossible but it initiates a logistic process to obtain the medication on the right spot. We prescribe per 24h, but changes are possible ad hoc.
Cheers
Sven"
Is there anyway to get the NDC code for a drug from the drug enforcement report fields?,"
Given the fields acquired from a drug enforcement report:

country
reason_for_recall
classification
recall_number
recalling_firm
initial_firm_notification
code_info
product_quantity
event_id
product_type
recall_initiation_date
distribution_pattern
state
product_description
voluntary_mandated
report_date
status

Is there anyway to obtain the NDC code for the drug associated with that recall?
https://api.fda.gov/drug/enforcement.json?limit=10&search=report_date:%2220141105%22
","['openfda', 'json']",
"Ontology with concepts about many domains (transport, environment, engineering, …)","
I am looking for an ontology or a controlled vocabulary which contains concepts about many domains such as transport, environment, engineering. 
Is there such a vocabulary available?
",['ontology'],
Open access efforts for computer vision datasets & databases?,"
There are quite a few datasets for training and testing computer vision algorithms, such as the ImageNet database and PASCAL databases. Most of the these databases are created from images with various restrictive licenses. Are there databases (with training data, such as classifications, segmentations, etc.) that are based on open access images (ie. Creative Commons, public domain, or the like) or are there meta-projects to help create such databases?
A possible example would be a project to collect open access images that are well suited for computer vision algorithms (particularly natural everyday images, not mathematical plots, cartoons, etc). I'm mainly interested in data for tasks that humans can perform, such as object detection, classification, object segmentation, etc.
mldata.org is perhaps the closest thing that I've found. They give the licenses of the datasets, although they don't provide a way to filter by license or type of license and it doesn't seem like they are always accurate.
","['images', 'computing']",
What is the ISERROR column in MIMIC-III's noteevents table?,"
I see that MIMIC-III's noteevents table contains a column ISERROR, which is a CHAR(1), but no explanation. What does ISERROR represent (i.e. what error are we talking about)?
",['mimic-iii'],"The Metavision workstation allows physicians to add notes relating to patients. These notes are created using template forms, which include a 'Set as Error' button as shown in the following screenshot (captured from the training notes highlighted below):A '1' in the ISERROR column of the noteevents table indicates that a physician has selected the 'Set as Error' button. An example of an error is where a note has been associated with the incorrect patient.Training notes for the Metavision system with a brief discussion of the 'Set as Error' button are available at: http://portal.mah.harvard.edu/metavision_training/pnotes.asp (see slide 89/109)"
Too few results from DBpedia,"
I'm running the following query to get Athletes data from DBpedia
  SELECT * WHERE {

  ?player a <http://dbpedia.org/ontology/Athlete> .
  ?player foaf:name ?firstname .
  ?player foaf:surname ?lastname .
  ?player <http://dbpedia.org/ontology/country> ?birthplace .
  ?player <http://dbpedia.org/ontology/birthDate> ?birthDate .
  ?player <http://dbpedia.org/ontology/Person/height> ?height .
  ?player <http://dbpedia.org/ontology/Person/weight> ?weight .
}

but it only returns about 300 records! What's the problem with my query?
","['linked-data', 'dbpedia']",I had to make the last four attributes optionalthis way I could get all the records even when there are missing values
Too few records from DBpedia [duplicate],"







This question already has an answer here:
                                
                            




Too few results from DBpedia

                                (1 answer)
                            

Closed 7 years ago.



I run the following query to get Athletes data from DBpedia:
  SELECT * WHERE {

  ?player a <http://dbpedia.org/ontology/Athlete> .
  ?player foaf:name ?firstname .
  ?player foaf:surname ?lastname .
  ?player <http://dbpedia.org/ontology/country> ?birthplace .
  ?player <http://dbpedia.org/ontology/birthDate> ?birthDate .
  ?player <http://dbpedia.org/ontology/Person/height> ?height .
  ?player <http://dbpedia.org/ontology/Person/weight> ?weight .
}

but it only returns about 300 records! What's the problem with my query?
","['linked-data', 'dbpedia']",
Where can I get data on released inmates in the US?,"
I'm dealing with a small rural town where a common belief is that a significant number of former inmates are resettled after their release from prison. I've examined proxies for this by looking at probation budgets, and other related services compared to the rest of the state. I feel that the proxies I'm using could be unconvincing and would like more direct data.
","['data-request', 'usa']","There are data sets that you may not be aware of at BJS including1995 Survey of Adults on Probation (SAP) 
This Bureau of Justice Statistics survey is the first nationally representative survey of probationers. The collection detailed information on the characteristics of probationers through a review of probationers' administrative records and personal interviews with probationers.2006 Census of State Parole Supervising Agencies 
The 2006 Census of State Parole Supervising Agencies collected data from parole supervising organizations about the organizational structure of the agencies, staffing, supervision levels of offenders, and whether the parole agency had a role in considering prisoners for release, setting the conditions of supervision, and conducting parole revocation hearings. This collection was conducted one time in 2006. The census was sent to 68 respondents, including 50 central state reporters, the California Youth Authority, and the District of Columbia. Sixteen local Minnesota Community Corrections Act agencies were asked to provide information on staffing and supervision not available from the state.Annual Probation Survey and Annual Parole Survey 
Collect data from probation and parole agencies in the U.S. on an annual basis. Data include the number of adults on state and federal probation and parole at the beginning and end of each year, the number of adults entering and exiting probation and parole supervision during the year, and the characteristics of adults under the supervision of probation and parole agencies."
Is the FIFA 16 Ultimate Team database available anywhere?,"
I know there's already websites such as Futhead that can act as a database. However, I'm looking for something (preferrably a single file) that can actually be parsed, as I'm looking to make my own application using it. I suppose as a last resort I could simply crawl and scrape the Futhead website, but that would require a lot more effort to implement and would be significantly slower to run too.
","['data-request', 'web-crawling', 'games']",
Web services access to OSHA regulations,"
Data is available for OSHA compliance but are the regulations themselves available through web services? Is there an ontology for OSHA regulations? If not, would the DOL be interested in developing one (possible collaboration)?
","['labor', 'ontology']",
Does anyone know a dataset that has both time-series data and descriptive (non-temporal) features?,"
An example of an ideal dataset would look like:

There are some devices, say computers
Each computer has parameters (number of cpus, amount of ram, hdd space, etc.)
Also we know some time-series data (energy consumption log, load log, etc.) about each of the devices
And we need to predict whether it will fail soon or not.

This is just an example, the domain of the dataset does not matter, it could be hospital records about patients, some other devices, unicorns, whatever. The main requirement is that each instance has some number of useful ""static"" features and some number of useful ""dynamic"" features.
Has anyone seen a dataset(s) like this?
","['data-request', 'metadata', 'time-series']",
where can I find data on web-research?,"
My purpose is to find a service (provide by Google or others) able to extract the frequencies of the web-researches of a website or a key term.
I know Google Trends but I would need a service that can look at the hierarchies (the terms correlated with my query) and that indicates also the geographical provenience.
",['data-request'],
Is there detailed play by play data for US NCAA football games available online?,"
I'm looking for the availability of current and ongoing data for US college football games, specifically play by play data.  Something with the type of play called (run/pass), number of yards needed, outcome of the play (success and # yards gained, or failure), etc.  I would like to do a hobbyist analysis of play calling success, and came across a site that had a ""top plays"" chart for a recent game along with details of each play.  I'm reaching out to them for details on where they got that info, but I wondered if there was a known source out there with that sort of data?  Or does everyone screen scrape their own sources?
","['data-request', 'sports']",
Where can I find Colombia municipality geometries?,"
I'm looking for shape files (or some similar format) of Colombia's municipality boundaries. 
Wikipedia has a map that seems to be correct and which matches another dataset that I will eventually be merging in based on municipality names and DANE codes. I've tried contacting the file creator about the underlying source data, but without success.
I've tried GADM, but some of the municipalities are missing/incorrect, e.g. all the way in the South Amazons should have 11 municipalities, not 8. 

Here's OpenStreeMap with data export via Mapzen. Many municipalities are simply just missing, although the borders for those that are there appear to be correct and more detailed than GADM. 

I guess I could try to combine departments that OpenStreeMap had all municipalities for with the GADM data, but it looks like that would still only partially get me there. And in general it just makes me a bit suspicious about using the GADM data at all.
",['data-request'],"You can try the WFS or WMS servers of the Instituto Geográfico Agustín Codazzi (here:http://www.igac.gov.co/wps/portal/igac/raiz/iniciohome/MapasdeColombia/Descargas). These services have different layers for geodesic features and demographics. I hope it can help you. Iván PD: If that doesn't work, you can check this link with the shape file I use for Colombian municipalities: https://www.dropbox.com/sh/i0ao837gj5wpkic/AAAnzZf-tJIKUmZvTKrvXPMpa?dl=0"
"Can I take ""open data"" from a website like Quandl, modify it, and then resell it to clients?","
I am just wondering if open data have any limitations I may be missing.  Can I for example get data through the Quandl API, do some calculations using the data, and resell the data?  Is this legal? 
Note:  I am talking about free ""open data"", I understand premium open data does have terms attached to it.
","['api', 'releasing-data', 'legal']",
API to get Wikimedia Commons images that are near a particular latitude/longitude,"
I have a geographical coordinate, and I want to know what Commons images are the closest.
For instance, for 40.7576,-73.9857 I would get like 10 pictures taken in Times Square.
Is there an API that gives this?
Rather than me having to decide a rectangle and not knowing the number of results in advance, I prefer to receive like the 10 closest pictures from the given point.
The API needs to be free, and the faster the better.  
","['geospatial', 'api', 'photographs', 'wikimedia-commons']",
Common queries for Location Sharing,"
I am wondering whether there exist some datasets where users are explicitly asking to share their location to some friends, family members, colleagues.
The examples can be something like:
* share my location with jim
* let theresa know where am i
* stop sharing my location

Ideally this would be spoken data to a mobile device.
","['geospatial', 'social-media']",
Data on deportations,"
Is there data on deportations out of the United States? It seems that to get it from the government, you need a freedom of information act request for a specific individual. Are there any open data alternatives? 
",['data-request'],
rail track data of the UK as arcs (lines consisting of lat long points),"
I am looking for a free/open data source for rail tracks of the UK network (the rail network as arcs - lines). I have all the train station points as lat long pairs.
","['data-request', 'geospatial', 'geocoding', 'space']",The UK open data site has datasets for both stations (which you have) and what they call the centre-lines of the railway track for the network. It is in a shapefile.https://data.gov.uk/dataset/railway-network-inspirehttp://inspire.misoportal.com/geoserver/transport_direct_railnetwork/wfs?amp;version=2.0.0&SERVICE=WFS&VERSION=1.0.0&REQUEST=GetFeature&TYPENAME=transport_direct_railnetwork:railnetwork&SRSNAME=EPSG:27700&outputFormat=shape-zip
Get all the data from category or subcategory from Collegescorecard API,"
I started playing with the API at https://api.data.gov/ed/collegescorecard/v1/schools
Querying a school by id 
https://api.data.gov/ed/collegescorecard/v1/schools?id=238476&api_key=***

returns me a lot of information about it, but is there a way to get only a subset of this data without explicity write down all the fields in the _fields query param?
lets say I want all the data from ""2013"".
By doing 
https://api.data.gov/ed/collegescorecard/v1/schools?id=238476&_fields=id,2013&api_key=***

I get field_not_found error.
Going deeper in the tree didn't help much. Let's say I'm intereted only in 2013.academics information. Querying 
https://api.data.gov/ed/collegescorecard/v1/schools?id=238476&_fields=id,2013.academics&api_key=***

returns me the same field_not_found error.
","['api', 'collegescorecard']","V1 of the API is a GET API with /v1/schools as the endpoint.The basic structure of an API call is year.dev-category.de-friendly-variable-name, except that the school category has no year and id, ope6_id, ope8_id and location have no category or year.The subsetting that you wish to do can be done with explicit fields and is rich. For exampleis powerful. You will need to list fields or subset locally."
Approval dates for drugs from FDA?,"
OpenFDA is awesome! I wish we had anything similar here in the UK. 
Is there a way to get drug approval dates via the API? I'm interested in knowing what date a drug was approved by the FDA. 
I think this exists in the API for devices, but I can't see the information in queries for drugs. 
The data exists on the FDA website, but it would be awesome if these could be retrieved through the API too. 
",['openfda'],
"Can someone explain ""openfda data is not for clinical use""?","
I am looking for OTC Labelling information and was curious how I might be able to use the information in my applications since it says the data is not for clinical use. 
",['openfda'],
list of approved active ingredients,"
If I wanted to define how drugs and cosmetics chemicals/ingredients overlap, could I use openFDA to help answer the drug part of that comparison?  Would I be able to take the contents of all the active_ingredient fields in the drug/labeling records of the openfda beta project, parse the results, and have a list with which to work?  Would it be comprehensive, timely, partially so?  Perhaps naively, is there already a public list (or db) of all approved drug ingredients (not finished products) already? (Not having a 150 reputation, I could not begin a cosmetics tag.)
","['openfda', 'drugs']",
How quickly after FDA approval will adverse events be listed on openFDA?,"
I cannot seem to find information on what the lag time is between FDA approval (drug on market) and results for adverse events being listed on openFDA. Does anyone have an idea of the timeline?
For example I can find adverse event reports for Promacta which was approved on August 24th 2015 (almost 2 months since approval). Looking at a drug that has just under 1 month of approval I cannot find any AE reports (or any basic information), an example is Lonsurf which was approved September 22nd 2015. What is the general time for posting of this information?
Thanks!
",['openfda'],
Need Tamil Bible open data source,"
I need the royalty free tamil bible datasource.datasources can be any format (JSON,XML,SQL etc.....).The data source format not the problem. Where i can find?
I found the open datasource for english bible in GitHub, but i can't find the datasource for tamil
",['data-request'],
Wikidata Query Service reliability,"
I encountered a partially incorrect result set from Wikidata Query Service.
Requested Wikipedia article urls were missing for an item where this information existed, see https://stackoverflow.com/questions/33178986/wikidata-query-service-incomplete-result-wikipedia-url-missing
A day later the service was returning the urls.
What may have been the reason for the error?
When is the service expected to leave beta status and to become fully reliable?
And where can I find information about

temporary problems (such as the one mentioned above)
progress and current status
future plans and milestones

of Wikidata Query Service? 
","['wikidata', 'sparql']","The reason is an error in loading data. It was a temporary problem, now fixed. The information about future plans and work on WDQS can be found on Wikimedia Discovery team page and Phabricator board."
Where can I find commercial flight information?,"
I want to start a data analysis project to analyze flight delay times in Madrid - Barajas airport and relate those to the time / distances used as thresholds to request a compensation from the airline according to European law. However, I haven't been able to find such dataset. I've been looking in the website of the Spanish flight authority, as well as Amadeus, and some other Google-fu did not help me.
But I need, specifically, is a dataset that contains origin / destination routes, the actual timetable and the scheduled one. Does such an API / historical database exist?
","['data-request', 'europe', 'travel']",
"A ""proper"" Data Set","
I am preparing 2/3 neural networks models (I have chosen ""neuralnet"", ""nnet"", ""AMORE"" randomly among the R packages) for a certain problem. At the moment I do not have the Data Set, but I would like to train my neural networks on a similar one.
I am looking for a Data Set with some features:

a set of n-1 independent variables (where n is not extremely large);
a dependent variable assuming values in a very wide range (for example y varies from 0 to hundreds of thousands).
Only a very few rows have a very high y.

Do you know some Data Set similar to the one I will have to deal with? 
","['machine-learning', 'programming']",
Redistribution ICPSR Data - Terms of Use,"
On the website (site), it says:

Access Notes: These data are freely available.

At data download page (download page), it has the term of use:

Redistribution of Data You agree not to redistribute data or other materials without the written agreement of ICPSR, unless: 
  (1) You serve as > the OFFICIAL or DESIGNATED REPRESENTATIVE at an ICPSR MEMBER
  INSTITUTION and are assisting AUTHORIZED USERS with obtaining data, (2) or
  You are collaborating with other AUTHORIZED USERS to analyze the data
  for research or instructional purposes.

Question: 
Can I put the downloaded data on my website? 
Is putting data on personal website (on internet, open to public) considered redistribution?
","['data-request', 'legal']",
Subnational data on corruption,"
Any sub-national data on corruption (any form)? Interested in any nation, but primary interest in Central and South America.
","['data-request', 'government', 'global', 'latin-america']",
Where is the data I need to fully understand federal revenue and their budget?,"
I am currently looking to become better educated when it comes to taxes currently paid to the US federal government, and get a better look at our expenses/budget. (hopefully to build a youtube video to better explain this to people like myself)
There is a lot of information out there, but I have never fully understand the source of this data. Through Excel Power Pivot I am planning on using this data to better understand what the issue is. 
I have been following Trump's plan for Taxes and want to better understand if this plan is actually possible. What do corporations truly pay? What portion goes to the federal government?
Data is the key to understanding the issue that we face. I know as an individual 30% of my income goes to state and federal taxes. Where is this money actually going? Why do I have such a large percentage of my income going to taxes?
Thank you for your help!
",['data.gov'],
A typical bank database for credit card accounts?,"
I am working on a project to develop a system that detect credit card fraud. I have no data set to test my system on instead I want to create a database that looks similar to that of a real bank database.
Are there some samples out there? I mean one that would show some columns to include? Of course, I know it depends on the requirements of my system but, what have you done - that is what I want to see.
I know some would have worked on similar situations. What have you included?
PS: I know (from SO) that credit card information must not be stored without authorization or some policies out there BUT this is specifically for demonstrating my system, just demonstration!  
","['data-request', 'finance', 'bank']",
How can I get a list of synonyms that work across all contexts?,"
Many synonyms are context specific. For example ""force"" is a synonym for ""drive"" in the context of urging or inspiring, but not in the context of journeying by vehicle.
Other synonyms seem to work across all contexts, for example ""sea"" and ""ocean"".
How can I get a list of all synonyms that work across all contexts?
Update
Reflecting on TimLymington's comment, is there some measure of synonym distance?
Consider some of the words that thesaurus.com offer as synonyms for sea: expanse, lake, ocean, pond, surf, abundance and blue. Intuitively, I'm confident I can replace sea with ocean more often than with blue. So I could say ocean has a shorter synonym distance from sea than blue.
How can I measure this distance? And, back to my question of a list, how can I get a list of all synonyms with distances?
(n.b. same question on English stackexchange)
","['language', 'english']",
database of email domain aliases?,"
I'm working on a problem merging some internal customer data on email address.  However, I know that different email address can resolve to the same person. Some examples are:

mapping a vanity domain to your free web mail (e.g. example@gmail.com and example@example.com)
company mergers like BigCorp.com and HugeCorp.com merge, creating BigHugeCorp.com (so first.last@bigcorp.com and first.last@bighugecorp.com are the same person).

In these case, emails are delivered to the same inbox.  I would like to merge these, so I am looking for an open database of email domain aliases.  I'm not even sure domain alias is the right term, but Google Apps uses this in Give users an address at another domain.
Potentially this could leverage answers from Dataset of domain names or Open database of domain registration information? if you could query on matching MX records.
","['data-request', 'internet']",
Pre-Colonial Population Density in the Americas,"
Any data that estimates pre-colonial population density in the Americas (especially, S. America)? 
",['data-request'],
Fitness Exercise Database / API,"
Im looking for a online database / API where i can pull information about some fitness exercises with basic information like difficulty, name, how to do it, etc. I hope you get my point. I saw one question about this topic but i couldn't find any good results with the answers that were postet there so i thought i ask a new question with the faith that someone got something ""newer"" for me. appreciate any help :)
","['api', 'sports']",
What real-time Open Data do you want to use?,"
I work for OpenSensors.io, we are an Internet of Things company working on making real-time data more accessible, easy to use. We've built a real-time Open Data exchange through which you can publish to, search for, subscribe to and access Open Data like earthquake, air quality or transport feeds through a real-time firehose. All open data projects are free to use too, we only charge if you want to keep the data private. We're partnered with the Open Data Institute.
We want to provide open data-sets that people want to use. Which begs the question, what real-time data sources to do you most want to see and access? What tools do you need to make use of this data?
Thanks!
","['api', 'uses-of-open-data', 'real-time']",
British Empire Budgets,"
Is there any open data on the public budget for the British empire across their colonies? Any other open data related to the administration of the colonies (such as heirarchy in each colony, allocation of expenditures, etc.) would also be interesting.
I'm specifically interested in the 1850-1950 time period.
",['data-request'],
Data for Auctions,"
Originally posted here:
https://webmasters.stackexchange.com/questions/85933/data-for-auctions
and was put on hold and suggested for this site.
Does anyone know how I can get a data feed for auction data? I would like to be able to display auctions local to users on my classifieds site. I've googled a lot but nothing is turning up. Something like adconnect.com is what I am looking for except for auctions and adconnect seemed to have very little data.
If I can get a data feed in some standard format I would be able to parse and display.
Also, if there is an easier way such as just including some HTML or javascript that would be great.
Thanks.
",['data-request'],
Looking for hourly data of traffic congestion in Beijing,"
Does anyone know where to find it? I would take daily, but hourly would be better. Something like:
Oct 15, 2014 at 9pm: 1.4
Oct 15, 2014 at 10pm: 1.6
",['traffic'],
Funding data for US Department of Education CSV format,"
I am looking for data about the funding from the Department of Education, Energy and Defense. The data I want is the fund/award number, the PI, Co-PI (if any) and the award amount along with the year of the grant.
I searched in data.gov but could not find. Any suggestions as to where I can get this data.
","['usa', 'data.gov', 'government', 'education']",
Mapping a Wikimedia project URL to the corresponding Wikidata entity id,"
I am looking for the best method to map a given Wikipedia/Wikisource/Wikibooks/... URL to the corresponding Wikidata entity id (similar to this question but via API calls instead of a full data dump). The URL can be in many forms, e.g.

http://en.wikipedia.org/w/index.php?title=Element_18 is redirected (HTTP) to
https://en.wikipedia.org/w/index.php?title=Element_18 is redirected (HTTP) to
https://en.wikipedia.org/wiki/Element_18 is redirected (JavaScript/HTML) to
https://en.wikipedia.org/wiki/Argon

Methods I tried so far:

SPARQL query service - requires the URL to have a canonical form and seems to not know about redirects
MediaWiki API at Wikidata, e.g. https://www.wikidata.org/w/api.php?action=wbgetentities&sites=enwiki&titles=Argon&languages=en&props=labels|descriptions&format=jsonfm requires to securely split URL into title and ""site"" key
MediaWiki API at project site, e.g. https://en.wikipedia.org/w/api.php?action=query&prop=pageprops&titles=Argon requires to securely split URL into project and title
Info page, e.g. https://en.wikipedia.org/w/index.php?title=Argon&action=info requires to modify URL and to parse resulting HTML

The most reliable (but nasty) method seems to enulate a browser to do a HTTP request to the URL, follow all redirects and parse the resulting HTML page to get the Wikidata ID.
",['wikidata'],"As a general rule, Wikidata won't know about redirects - they're not part of the model there. They only record the canonical page title (leaving aside a few rare cases where the Wikidata sitelink is a redirect, which is deprecated but does occasionally happen). So any 'de-redirecting' will need to be done on the Wikipedia side.If you use the local API with &redirects, you can get the Wikidata entity ID in a single query whether or not there's a redirect -https://en.wikipedia.org/w/api.php?action=query&prop=pageprops&titles=Element_18&redirectshttps://en.wikipedia.org/w/api.php?action=query&prop=pageprops&titles=Argon&redirectsboth contain ""wikibase_item"": ""Q696""You'll still have to process the URL a bit to get the API call, though."
What APIs are there that are provided over websockets?,"
What real time APIs are there that don't require polling, for things like bus locations, flight locations, etc... -- which I can just poll with a web socket?
","['api', 'real-time']",
Why are some notes written in uppercase in MIMIC-III?,"
I see that some notes from the medical personnel entirely written in uppercase in MIMIC-III. Why?
",['mimic-iii'],"When they type their progress notes, some nurses use all caps and some don't! Just personal style!"
Gold annotations for diabetic patients in MIMIC-III,"
I am looking for a list of patients in MIMIC-II or MIMIC-III who have been annotated as diabetic by experts. I.e. a gold standard, physician-validated, data set for diabetic patients in MIMIC-II/III. 
","['data-request', 'mimic-iii']",
Finder API list ACA Approved Health Insurance API JSON?,"
Does Healthcare.gov or Finder API list ACA Approved Health Insurance in API JSON format?
","['data-format', 'healthcare-finder-api']",
Single-word Translations in All Languages,"
I am looking for a dataset of single-word translations, essentially a translation dictionary for all languages. I don't need all words, but simply a set of very common words: ""yes"", ""no"", ""true"", ""false"", ""zero"", ""one"", etc. It also doesn't have to be every language, though more languages the better. If the dataset comes with ISO 639 codes that would be even better.
This question is related, but it is asking for whole sentence translations, whereas I'm simply looking for individual word translations. The accepted answer there points to tatoeba.org, which might work for my needs, but I'm hoping to find other options to consider.
","['data-request', 'language', 'translation']",
"Data on the number of ""remote"" workers by country","
I'm trying to find estimates of how many workers in each country have remote (also known as 'virtual' or 'digital') sources of income. This is focused on developing countries so I really need data that goes beyond advanced industrial economies.
What would also be helpful is a storehouse of data from popular freelancing websites, or even case studies focused on individual countries such as the Philippines, Ukraine, others. The data will be used for an economic development study (non-commercial).
","['data-request', 'economics', 'labor']",
"What exactly do the variables named ""Unemployment rate, via Census data"" and ""Poverty rate, via Census data"" represent?","
What exactly do the variables named ""Unemployment rate, via Census data"" and ""Poverty rate, via Census data,"" found in the College Scorecard data dictionary, represent?
Do these rates represent the unemployment rate/poverty rate among the student body, among the graduates of the institution, or in the region in which the institution is located?
","['usa', 'education', 'collegescorecard']",
How can I calculate the proportion of students at an institution who are low-income or first-generation?,"
I would like to use data from the College Scorecard to calculate the proportion of students who are low-income or first-generation at each institution. In the dataset, I only see ""number of"" low-income and first-generation student variables. How do you recommend I calculate the proportion, if possible? Divide by the number completed in fill-in-the-blank cohort? Thanks in advance!
","['collegescorecard', 'analysis']",
Where can I find a REST API of stars and constellations?,"
I'm looking for an open REST API to make ocasional queries of stars and constellations. Concretly I'm looking for getting the right ascension and declination of the most important stars of a few constellations (other parameters are optional).
","['api', 'astronomy']","For simple, there is a webservice called LookUP which provides a web, REST and XML api for star and constellation data by name. If that doesn't quite meet your need, there's SIMBAD Astronomical Database, which is where the above-noted LookUP tool is getting its data."
unable to get lat long in api call,"
I am trying to get the latitude and longitude for different schools, and keep getting an error. Location is at the root, and I am able to get ids which are also at the root, so I'm not sure what I'm doing wrong.
This does not work: https://api.data.gov/ed/collegescorecard/v1/schools?_fields=location.lon&school.name=pepperdine&api_key=**********
but this does:
https://api.data.gov/ed/collegescorecard/v1/schools?_fields=id&school.name=pepperdine&api_key=***********
Am I doing something wrong?
","['data.gov', 'api', 'collegescorecard']",
openFDA - Recalls - quantity in commerce,"
Any reason this field is not available on openFDA? It can be seen on individual queries on the website: (random example) https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfres/res.cfm?id=131707
Are there any plans to add it?
",['openfda'],
openFDA Device Adverse Events Data out of date,"
Does anyone know why the Device Adverse Events data available via the openFDA API has not been updated since 01-Jul-2015?
","['data-request', 'openfda']",
Is stock data available for bulk download for free?,"
Is it possible to download a dump of stock data?
I've seen the following:

Alternative to google finance api
Is there anywhere to get a free stockmark data feed/dump?
Quandl - seems only to offer current prices. The ""bulk downloading"" option 

But I'm not interested in the current data, but rather a dump for the past years (at least one value per day) for the most important stocks (e.g. the ones in DAX, Dow Jones Industrial Average, ...), preferable with the price from Frankfurt or Xetra.
Is such data available for free?
(Non-free options are only interesting for me if it is below 20 Euro and if one may publish images created with this data)
","['finance', 'historical', 'time-series']",
Display only reactions where drugcharacterization=1 (drug was suspect drug),"
I'm trying to get the number of reactions for a certain drug, but only where the drug was classified as suspect drug (drugcharacterization=1). 
I tried: 
http://api.fda.gov/drug/event.json?search=patient.drug.medicinalproduct:Fish%20Oil+AND+patient.drug.drugcharacterization:1&count=patient.reaction.reactionmeddrapt.exact
Looking at the output, I believe the system is also returning cases where the Fish Oil was only listed as concomitant. 
This is confirmed by the following, where fish oil is returned as concomitant drug: 
http://api.fda.gov/drug/event.json?search=patient.drug.medicinalproduct:Fish%20Oil+AND+patient.drug.drugcharacterization:1
Is there a way to filter, so that I only get reactions where Fish Oil was listed as suspect drug? 
","['openfda', 'api']",
Error 503 for seemingly valid getIFPPlanQuotes request,"
I am using an XML I generated and as well as the one indicated on the sample but I am getting returned a 503 Service Unavailable
Sample Request:
<?xml version=""1.0"" encoding=""UTF-8""?> <p:PlanQuoteRequest xmlns:p=""http://hios.cms.org/api"" xmlns:p1=""http://hios.cms.org/api-types"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://hios.cms.org/api hios-api-11.0.xsd "">
  <p:Enrollees>
    <p1:DateOfBirth>1959-03-03</p1:DateOfBirth>
    <p1:Gender>Male</p1:Gender>
    <p1:TobaccoLastUsedMonths>2</p1:TobaccoLastUsedMonths>
    <p1:Relation>SELF</p1:Relation>
    <p1:InHouseholdIndicator>true</p1:InHouseholdIndicator>
  </p:Enrollees>
  <p:Enrollees>
    <p1:DateOfBirth>1982-03-03</p1:DateOfBirth>
    <p1:Gender>Female</p1:Gender>
    <p1:TobaccoLastUsedMonths>2</p1:TobaccoLastUsedMonths>
    <p1:Relation>SPOUSE</p1:Relation>
    <p1:InHouseholdIndicator>true</p1:InHouseholdIndicator>
  </p:Enrollees>
  <p:Location>
    <p1:ZipCode>22901</p1:ZipCode>
    <p1:County>
      <p1:FipsCode>51003</p1:FipsCode>
      <p1:CountyName>ALBEMARLE</p1:CountyName>
      <p1:StateCode>VA</p1:StateCode>
    </p1:County>
  </p:Location>
  <p:InsuranceEffectiveDate>2015-01-01</p:InsuranceEffectiveDate>
  <p:Market>Individual</p:Market>
  <p:IsFilterAnalysisRequiredIndicator>false</p:IsFilterAnalysisRequiredIndicator>
  <p:PaginationInformation>
    <p1:PageNumber>1</p1:PageNumber>
    <p1:PageSize>20</p1:PageSize>
  </p:PaginationInformation>
  <p:SortOrder>
    <p1:SortField>BASE RATE</p1:SortField>
    <p1:SortDirection>ASC</p1:SortDirection>
  </p:SortOrder>
</p:PlanQuoteRequest>

",['healthcare-finder-api'],
Antebellum State and Local Election Data,"
Is there data on voter turnout and election returns for state and local elections (gubernatorial, etc) during the 1840-1860 time period in the United States at the county level? 
If no comprehensive or piecemeal dataset exists, I'd also be open to primary source references that would allow me to build such a dataset myself.
","['data-request', 'usa', 'elections']",
"""Fuzzy"" search of Mediawiki Commons categories","
I am developing an app that lets smartphone users upload a picture to Wikimedia Commons. The user must categorize the picture by typing Commons category names. Typing on a smartphone is slow/painful/erratic, and category names are not obvious, so the app should do its best to guess what category the user is trying to find.
QUESTION: Is there an API that takes a string, and returns 1~10 Commons category names that fuzzy-match the beginning of the string?
Requirements:

Response of the server must be very fast (as-you-type)
Free, as there is no budget for the app
Scalability should not be a problem for now, less than 5 concurrent users at any one time

For instance, Category:Power plants in New Zealand‎ should be found even if the typed string is:

Power plants in New Z (as-you-type)
power plants in new zealand (lowercase)
Power plants in New-Zealand (dash instead of space)
Power plant in New Zealand (singular)
Pwer plants in New Zeland (typo - ideally)
New Zeland power plant (word order - ideally)

","['api', 'nlp', 'wikimedia-commons']",
People Mobility Data,"
I am student, doing research on people mobility. Is there any dataset that I can use to benchmark my work (kind of a framework); I am looking for any kind of data (CDR Dataset, GPS/Location data .. ) ?
",['data-request'],
Combined DHS and MICS survey results,"
Is there any data set that has already merged the DHS survey data from a given DHS phase? Preferably geo-referenced at the survey cluster level. I'm particularly interested in Africa.
","['data-request', 'africa']",
Where is the block assignment file linking 2010 Census data with 113th congressional districts?,"
The block assignment files from the US Census are very nice.  Unfortunately, they appear to tell you which census blocks make up each district in the 112th congress.  This makes some sense, since this is the congress that was elected in 2010.  However, the 2010 census was used to create the districts for the 113th congress, so it is natural to want to know which 2010 census blocks make up each 113th congressional district.
What I want is a file that tells me, for each census block, which 113th congressional district that block is in.  In other words, exactly like the existing block assginment files, but for the 113th congress instead of the 112th.  I can't find any such file on the census website or in my wanderings through the FTP.  Where is this information?
","['government', 'us-census', 'district']",
Health forum data sets,"
I am looking for data sets that contain health-related forum posts. Ideally, with as much structured information as possible (post, post timestamp, poster ID, history of edits, etc.). I know I can crawl fora myself but I would prefer to have ready-to-use data sets.
","['data-request', 'medical', 'nlp']",
Does the openFDA drug adverse events dataset (or any other dataset) have a geographic dimension?,"
I want to produce visualizations of PRR and ROR of drug adverse events using openFDA data using d3 and shiny. I want to build interactive map view (map of the US with PRR values by state, for example). Does the openFDA drug adverse events report dataset (or the source dataset) have a spatial (geographic) dimension?
","['openfda', 'api']",
API to get Wikimedia Commons categories that are near a particular latitude/longitude,"
I have a coordinate, and I want to know what Commons categories are nearby.
For instance, for 40.7576,-73.9857 I would get Category:Times Square and probably Category:Broadway and a few others nearby.
Is there an API that gives this?
If not, is there a way to get the same via several APIs calls? 50% of false positives is OK.
Note: Once again, my question is about Wikimedia Commons categories.
","['geospatial', 'api', 'wikimedia-commons']","You can use WikiData SPARQL service to run itRun it in query service:
https://w.wiki/FQ4"
API for crowd sourced gas prices,"
Does anyone have a source for current daily gas prices at any given pump? IE the Kirkland Costco is selling regular unleaded for 2.89 on 10/15/2015.
The data I am looking for is at gasbuddy.com but they charge and I am looking for current, and not historical, prices.
","['api', 'crowdsourcing']",
Where can I find pre-1951 median wage information?,"
I'm working on some data visualization for buying power pre-WW2, but I'm having trouble actually getting to information from before 1951. So far I have found data from 1951-present from social security.gov. However, I am trying to look back as far as 1935 to examine how WW2 industry affected average wages. I have found reports for single years (IRS publications), but no tables of year-by-year information before 1950. I've seen documents examining price trends pre-1950, but can't seem to find the underlying data they reference. 
Does anyone have any experience with this?
","['data-request', 'us-census']",
Vehicle Crash DataSet with Accelerometer,"
I am looking for an open dataset of vehicle crashes that includes the vehicle location, heading, speed and accelerometer data. Availability of Gyro and Magnetometer data is a plus but not necessary.
","['data-request', 'transportation', 'accelerometer']",
What is the variable that closest resembles Sticker Price?,"
I'm currently using the variable COSTT4_A, (Average Cost Of Attendance, Tuition and Fees) and this looks like it would best match the idea of the sticker price (the price without scholarship, fees deducted). Is this correct?
",['collegescorecard'],
geolocalization of tweets,"
Do you know a technique to find spatial indicators using the package TwitteR in R?
For instance if I have to find the word ""dog"" using the package twitteR, but I miss the coordinates, there is the possibility to find the localization of the tweets thanks to some indications included in the  time-zone, websites, UTC24offset,text message. How can I say to R to detect my list of Tweets contains the word ""dog"" using the spatial indicators just mentioned?
","['api', 'social-media', 'geocoding', 'programming']",
"Infanticide rate, divided by the sex of the murderer","
Ideally the data would include a cross-section of countries.
Spinelli (2008) writes on p.xx
""Although infanticide may be viewed as an act of child abuse (Lowenstein
1997), and males are responsible for half of these crimes, child abuse
by fathers is a neglected area of study. Of 66 studies of child abuse published
in the literature over 5 years, 28 included only mothers; 2 included
fathers, and the 36 remaining articles neglected to mention sex differences
(Martin 1984). Haskett et al. (1996) reviewed 126 articles of maltreatment
from 1989 through 1994; males were included in fewer than half
(47.7%) of 77 reviewed articles. Only 3 studies included males, yet 40 involved
female participants.""
Spinelli, M. G. (Ed.). (2008). Infanticide: Psychosocial and legal perspectives on mothers who kill. American Psychiatric Pub.
","['data-request', 'crime']",
Extracting variables from unstructured Excel files [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 7 years ago.







                        Improve this question
                    



I have hundreds of Excel files (databases) from which I want to extract a subset of variables.
The data are not systematically in the same cell (e.g. G4) and also don't always start on the same row. However, they do have the same variable name. The titel of the file contains a date which I would need to extract as well.
I am basically looking for a way to get all values under a certain variable name within a file in a single file.
What would be the easiest approach to combine all sheets in a single database ? Using Macro's? All tips/links are very welcome.
","['extracting', 'unstructured-data', 'excel']",
"For a given 5 year ACS (American Community Survey), when is the effective date of estimation?","
The ACS Survey provides the most up-to-date census estimates for US population groups. The 5 year survey is the most comprehensive. For example, the most recently available 5 year survey as of Sept 2015 is the 2009-2013 ACS 5 Year Survey.
I'm trying to calculate population changes since that survey was taken with a number of methodologies, but what I don't know is when the effective estimate date is supposed to be. For the 2009-2013 survey, is it January 1, 2013? Is it December 31, 2013? Is it some date in 2012? I'm assuming it is January 1, 2013, but have no way of knowing this other than an educated guess.
Thanks
","['usa', 'us-census', 'census']","As a student of demography myself, my professor's often treat the effective date as the midpoint of the survey period. So for a 1-year survey period, the estimate would be said to be July 1st of that year. When you start getting into 5-year survey periods, the flaws in thinking of the survey as a point-in-time estimate become more apparent. As fdonnelly has suggested, the best way to think of ACS estimates is that they are the average population or proportion estimate across 12 (or 60) months.If you are still keen on using the point-in-time estimate approach, then I would say the midpoint date for the 2013 5-Year ACS would be July 1st, 2011."
Downloadable free movies API,"
Looking for an API with free movies and download links for them. Something like this list: https://en.wikipedia.org/wiki/List_of_open-source_films
But an API and with download links.
","['data-request', 'api', 'film']",
Shapes of ZIP codes - polygons for each ZIP code,"
I'm looking for an open data set that contains polygons with the shape of each ZIP code in the US.  GeoJSON format would be ideal.
I've done a bunch of searching, and I've been able to find shape data for counties, but not for ZIP codes.  Searching for it with Google has trouble because it finds a lot of .zip files, rather than ZIP codes.
","['data-request', 'usa', 'geospatial', 'postal-code']",
Company ownership data,"
I am trying to find company ownership data (e.g. names of shareholders that own say up to top x% of the shares?) for companies in any major country.
Ideally this would be associated to main industry of operation of the actual company etc.
My intention would be to do some shareholder network analysis on this basis.
",['data-request'],
Creating data from web tables with import.io failed - other tools?,"
I found this site with solar system moon orbit data:  Table of moons in solar system.
I ran that through the http://import.io site and it only came up with Jupiter data. Is there a more comprehensive tool that will identify multiple tables and import into a single table?
(I also tried the import.io desktop app).
","['tool-request', 'web-crawling']",
City's Satellite Images over Time?,"
I'm interested in the landscape change (observed by satellites) for a certain city. I have found some videos where they show a city and how it evolved over the years. 
My guess was that there are websites where they provide those images, I just couldn't find them. Do you know any databases/websites where I can find such historical satellite images?
Thanks
","['geospatial', 'images']",
List of surnames of popular people in English,"
My question is similar to this one. The difference is that I do not care about the ordinary people. All I need is a list of famous:

scientists/inventors
artists/musicians/authors
politicians
actors/actress/singers
businessman/leaders
sportsman 
explorers
some other famous people whom I forgot

The person should not be from US/UK, but his surname should be written in English (Dostoevsky, Mahatma)
","['data-request', 'names']",
Paraphrase data sets,"
I am looking for paraphrase data sets.

I am aware of the following:

PPDB: The Paraphrase Database (Ganitkevitch, Juri, Benjamin Van Durme, and Chris Callison-Burch. ""PPDB: The Paraphrase Database."" HLT-NAACL. 2013.).  Its English portion, PPDB:Eng, contains over 220 million paraphrase
pairs.
The Microsoft Research Paraphrase Corpus (2005): 


5800 pairs of sentences which have been extracted from news sources on the web, along with human annotations indicating whether each pair captures a paraphrase/semantic equivalence relationship. No more than 1 sentence has been extracted from any given news article. We have made a concerted effort to correctly associate with each sentence information about its provenance and any associated information about its author. If any attribution information is incorrect or missing, please send email to billdol@microsoft.com and we will update the file.


The DIRT Paraphrase Collection (Dekang Lin and Patrick Pantel. 2001. Discovery of Inference Rules for Question Answering. Natural Language Engineering 7(4):343-360.)

","['data-request', 'nlp']",
where can I find geocoded sentiments?,"
I am a student of economics and I am conducting my master thesis on cultural industries. Trying to understand what is the feeling of the people about different themes, I'am using TwitteR package in R and in particular the function searchtwitter. everything works fine but when I am trying to geocode the tweets(geocode is an argument of the function) the results provided are very few. I have tried with different coordinates and setting also the argument ""since"" and ""until"" but significant results are obtained only if I don't set the argument ""geocode"", ""since"", ""until"". Poorly speaking I obtain a relevant number of tweets but I don't know their provenience. Do you know some strategy to deal with this issue? Are there better programs to map feelings posted by people on social network? 
","['programming', 'sentiment-analysis']",
Invalid API Key - Accessing OSHA data,"
I am trying got download OSHA data via API. I have registered my email and got key.
When i sent request its throwing invalid API KEY.
https://data.dol.gov/get/accident?KEY=REMOVED

What should we give for ""Application Name"" when creating Tokens ?
https://data.dol.gov/get/violation_gen_duty_std?KEY=REMOVED

I gave 'violation_gen_duty_std"" for the above one.
Any help appreciated .
API Details are found at http://developer.dol.gov/health-and-safety/dol-osha-enforcement/#osha_inspection
","['usa', 'data.gov', 'api', 'labor']",
Graduate students included in loan repayment and/or earnings data?,"
Are graduate students included in loan repayment and/or earnings data?  The documentation does not specify.  If these data pertain to undergraduates only, how are undergraduate students identified?
",['collegescorecard'],
Data sets for short text classification,"
I am looking for short text classifications (multilabel is OK). By short text I mean ~50 words max.

The data set used in Xin Li, Dan Roth. Learning Question Classifiers. COLING. 2002. is a good example: The data can be obtained at the group's website. The training data consists of 5500 labelled questions. The test data is 500 questions taken from the TREC
10 set. In both the training and test data, there are a total of 50 different
question classes.
Excerpt:
DESC:manner How did serfdom develop in and then leave Russia ?
ENTY:cremat What films featured the character Popeye Doyle ?
DESC:manner How can I find a list of celebrities ' real names ?
ENTY:animal What fowl grabs the spotlight after the Chinese Year of the Monkey ?
ABBR:exp What is the full form of .com ?
HUM:ind What contemptible scoundrel stole the cork from my lunch ?
HUM:gr What team did baseball 's St. Louis Browns become ?

","['data-request', 'nlp']",
"Text data sources in German, primarily news articles","
Can anyone recommend good sources for getting archived news texts in German language?
Good source would satisfy the following conditions:

recent in date (for example 2005-2015)
variety of topics (politics ,sport, fashion, lifestyle, food...)
easy availability (free for download)
clean (it's easy to separate articles)
more than 50k articles

Of course, not all of the conditions must be fully satisfied.
","['language', 'corpora']",
Looking for modern english texts in public domain / CC-BY-SA,"
Is there a library of public domain / CC-BY-SA english texts, written later than 1990? I need it to build a corpora with links to full texts, which isn't possible with copyrighted material. At the same time I would like this corpora to be up-to-date with current state of the language.
","['data-request', 'english', 'corpora', 'creative-commons', 'books']",
Dataset of weather as it was *forecast* at the time,"
I have been able to find very detailed weather datasets from noaa (ftp://ftp.ncdc.noaa.gov/pub/data/noaa/). But I realized that for my purposes I can not simply use weather prediction probabilities to get probable weather forecasts of the time.
I need a dataset of dates and what weather people thought that particular date would have days or weeks in advance of it. In other words: actual weather, weather predicted 1d ago, 2d ago, 3d ago, ... 2 weeks ago (or something).
Does such a dataset exist? I fully anticipate that this is too niche and possibly not public. If so, would anyone know if it's possible to rerun a climate model to generate accurate weather forecasts of the time? Or are such algorithms proprietary?
","['data-request', 'weather']",
US Median Household Income by Age and Cohort,"
I'm  looking for a dataset of US block-groups (or lowest available) that has household income by age bracket.  E.g. Age 35-50 Household Income, broken into monetary segments - 0-15k, etc.
Is this available in open form?  I'm aware of something pretty similar in the ESRI Business Analyst data, but wondered if there were an open source.
",['demographics'],
High School Football Stats [closed],"







Closed. This question needs to be more focused. It is not currently accepting answers.
                                
                            











Want to improve this question? Update the question so it focuses on one problem only by editing this post.


Closed 4 years ago.







                        Improve this question
                    



I am in a application development course (CSC 400), required for my Computer Science major, and have been asked to create a ""web scrapper"" utility that harvests data of high school football statistics. I have been searching for APIs but cannot find any. There are plenty for NFL and college football but none for high school that I can find. I found the website: http://www.maxpreps.com/ which has the data I need but they do not offer developer APIs; and scraping html from this site would be extremely tedious, and perhaps unethical. Could anyone please recommend any APIs or data feeds that are available for consumption?
","['usa', 'api', 'sports']",
Need real time data source for wind direction and weather forecast,"
Where can I get real time data for wind direction and weather forecast?
","['data-request', 'weather', 'real-time']","You can get wind speed & direction from METAR files, which every open airport should be publishing.I don't know if forecasts are as standardized.  I'm used to looking at NOAA's National Weather Service, but there might be better services for non-U.S. locations."
Open and free electronic Case Report Form e-CRF system options,"
Does anyone know any good platform for gathering clinical data during clinical trials?
I was not able to set up Open Clinica... 
I think that this problem should be addressed more easily with a form for data acquisition.
I am looking for a simple solution not a mySQL database and involvement of the whole IT department. 
Google Forms were ok but they lack conditional logic. 
Any other options?
",['medical'],
Standards for parking restriction spatial data,"
I'm working with some local governments in Australia to publish parking restriction data. Are there any existing standards to conform to? The kind of data I'm talking about:

spatial (one polygon per zone that has a shared set of restrictions)
several restrictions at different times (eg, 2 hours between 9:00 and 17:00, unlimited after)
may also have special restrictions: loading zones, clearways, disabled access...

An example of such (non-standardised) data: http://data.gov.au/dataset/ballarat-car-parking-areas 
","['geospatial', 'city', 'standards', 'parking']",
Where can I find statistics of polio cases in different countries,"
I would like to know how many cases of polio were reported in different countries for last 20 years or more. So far I've looked into the WHO webiste and also The Global Polio Eradication Initiative, but haven't find what I am looking for.
I also wanted to add the 'polio' and 'vaccination' tags to this question, but I don't have enough rep. Would be grateful if someone with enough rep can add these tags. Thank you.
","['data-request', 'medical']","This was a tough one to find. The WHO, CDC, and GPEI were referenced all over the web as sources, but I couldn't find any pre-compiled data tables. WHO had a data system that includes polio cases but it only went back to 2010.Then - I found a citation in a PDF of WHO's Global Health Observatory reports. The report has the most recent data, but also a link back to a data series called the vaccines preventable diseases monitoring system. A search through that database, with some filtering, finally leads you to this:http://apps.who.int/immunization_monitoring/globalsummary/timeseries/tsincidencepolio.htmlIt's country data from 1980 to 2014, reported cases of polio.
This also contains data on several other diseases: Diphtheria, Japanese encephalitis, Measles, Mumps, Pertussis, Rubella, Rubella (CRS), Tetanus, and   Yellow fever."
List of European countries and capitals with populations,"
I am searching a list of European countries and capitals with populations. This list must include the name of country with its population and area in square kilometer, the capital of country with its population. I want get this data in format of JSON document like
{
    ""countryName"": ""Belgium"",
    ""countryPopulation"": ""11258000"",
    ""area"": ""30510.0"",
    ""countryCapital"": ""Brussels"",
    ""capitalPopulation"": ""107307""
} 

","['data-request', 'json', 'europe']","A source of data in JSON would be a port of the CIA World Factbook.Github repoFor example, the entry for BelgiumHas dictionary entries:andandto select a few.There are other ports of the CIA World Factbook that may better structure that data."
Factoid question answer data sets with text containing the answer,"
I am looking for factoid question answer data sets. Each sample should contain a question, an answer, and a text where the answer can be derived from.
","['data-request', 'nlp']",
How is average cost in college scorecard derived?,"
The Average Cost does not seem to be what the institution charges, how was it determined?
",['collegescorecard'],
Are graduate programs included College Scorecard data?,"
Are graduate programs included College Scorecard https://collegescorecard.ed.gov/ website data?
",['collegescorecard'],
Any open public data sets for the Rugby World Cup (in England 2015)?,"
The Ruby World Cup 2015 kicked off in England on Sep/18 and runs until Oct/31.
 Wondering what's the state of open data for Rugby. Any open data sets available (incl. teams, players, squads, stadiums, old tournaments, match stats, and so on)?
Ideally the data set is in an open plain text format such as CSV (comma-separated values), JSON (javascript objects), SQL (structured query language), etc. and in the public domain (no rights reserved, no copyright) or using a permissive license (only attribution required, for example).
Any insight appreciated.
Disclosure: I'm the project lead of the sport.db project (incl. rugby.db) - e.g.:

opensport/rugby.db - free open public domain datasets incl. in plain text Rugby World Cup 2015

","['data-request', 'sports', 'sql', 'txt']",
Dataset for queries that are questions or others,"
I am looking for a dataset of queries that are posted in live chats or service providing chats. I want to test my API for tagging a query that is entered by the customer as a question or not a question. I am not able to find a suitable dataset that include some samples like:

where should I go to eat food.
Book a cab which serves food.

The first statement is a question where as second is not.These are the types of queries that a customer might use with out it being grammatically correct.
I need a dataset consisting of such data which are used in spoken English.
","['data-request', 'machine-learning', 'nlp']",
looking for data source: all businesses in USA,"
I'm looking for a source where I can download all business telephone listings (yellow pages) in the USA. Does anyone know where I might find such a data set? 
Ideally, I'd like to be able to get historical listings also.
Update/Clarification I'm really looking for business names & geographic location. Telephone directories seem like a convenient place to get this information, but I don't actually need phone numbers. Any data set that contains business names and addresses (really just ZIP code would be enough) would be sufficient.
","['data-request', 'usa', 'business']",
Dialogs with labeled slot(s)-value(s),"
I am looking for data sets containing dialogues labeled with slot-values. I am open as to the definition of a dialogue, e.g. message board posts are good too.

Definition of slot-values:
A dialog is a sequence of utterances between one or more dialog participants. Dialog participants can be humans, computerized dialog systems, etc. In a dialog system, the goal of the dialog state tracker is to keep track of all dialog states for each utterance. A dialog state represents what dialog participants appear to have in mind. One common representation for a dialog state is a list of slot-value pairs: the slot is a general category, while the value indicates more specifically what the dialog participants have in mind.
Example 1:

Example 2:

","['data-request', 'nlp', 'corpora']",
Where can I find state by state polling prior to recent presidential elections?,"
I am looking for data on polling estimates for different states in presidential elections in the United States. 
","['data-request', 'usa', 'elections', 'survey']",
Real world applications of Streaming data,"
Any idea where I can get source of current research topics on data streams with focus on real time applications.
","['machine-learning', 'real-time']",
Get Wikipedia URLs (sitelinks) in Wikidata SPARQL query,"
I can use the following query to list all sovereign states via the Wikidata query interface:
PREFIX wikibase: <http://wikiba.se/ontology#>
PREFIX wd: <http://www.wikidata.org/entity/>
PREFIX wdt: <http://www.wikidata.org/prop/direct/>

SELECT ?cid ?country WHERE {
    ?cid wdt:P31 wd:Q3624078 .
    OPTIONAL {
        ?cid rdfs:label ?country filter (lang(?country) = ""en"") .
    }
}

The result listing contains the Wikidata entity ID and the English label, if available. I'd like to also query the URL of the corresponding English Wikipedia article if it exists. As far as I can tell, Wikipedia URLs are not properties of a Wikidata entity and I have no idea how I can express a relation between a Wikidata entity and Wikipedia URL in the SPARQL query.
","['wikidata', 'wikipedia', 'sparql']","Try this one:More details about sitelinks are in the RDF docs. Note that right now the only way to distinguish between Wikipedia links and other English links (like sources, news, etc.) is by URL match, thus a somewhat ugly filter. "
What is your level of external data?,"
I'm working on an internship of Big Data, I've build a predictive model. To enrich my model, I'm searching for the open data / external (paid) data. But I could only find the data that is in type of regional - zip code related data, there are no data that correspond specifically to each individual. 
So my question is, do you have the same situation, or you are able to find an external data set perfectly coresponds to each observation in your data set?
",['data-format'],
Open text document corpus for information retrieval evaluation,"
INTRODUCTION: document collections (corpora) for evaluation of information retrieval (search engine) systems are pretty often behind a paywall. A notorious example is the TREC conference (http://trec.nist.gov/). Apart from money, they ask for affiliation, making the data unavailable for the hobbyist/open-source. A few older corpora exist (http://www.daviddlewis.com/resources/testcollections/reuters21578/) but these are ""antique"" in ways that make then less useful for the evaluation of current systems. Others like the Wikipedia dumps(1), the European Union multilingual corpora (2)(often used in automatic translation) or the RFCs (3) could be used but are not standard in the research community.
QUESTION: does any open text document corpus of a decent size and quality in English exist, that is widely used for evaluation of information retrieval systems? The widespread usage puts the result of one's own evaluation into a meaningful context.
","['data-request', 'nlp', 'corpora', 'search-engine']",
"Machine Learning imputable ""common-sense"" datasets","
I need a dataset that can be used to build imputation models upon and that is also a ""common-sense"" data such as countries econometrics, Forbes2000 etc. That is, I am not interested either in customer survey datasets or sensor dataset.
 I have already tried to compile countries econometrics dataset which include fields such as gdp, gdp per capita, population, internet penetration rate, poverty etc. to impute missing poverty rates for example.
Unfortunately, all of the different techniques I have tried failed utterly and produced no meaningful models. I have also tried Forbes2000 datasets to predict market value of a company based on other available information on the aforementioned dataset. Although somewhat better than the econometrics dataset, this also failed with no reproducible models with a high predictive power.
Now I am stuck, since I can not find any other dataset that has ""common-sense"" data (for a lack of a better word) and also machine-learnable. If you could advise any hints, it would be appreciated.
","['data-request', 'machine-learning']","If you are developing an ML model, the cool way to find relevant data is to launch a data search in upgini library.It searches for relevant features for the ML model through data about 700+ mln phone numbers, 400+ mln emails, 239 countries, and up to 41 years of history."
What equivalent license for CC SA without BY? Share-alike but no attribution,"
I would like to publish my pictures, and the license that I like most is CC BY-SA... except that I don't care about attribution.
So, what license should I use?
Requirements:

Exactly like CC BY-SA 3.0 but not requiring attribution
English language, translations available
The best well-known the better

If several licenses satisfy these requirements, the winner will be picked by Google fight.
Non-solutions:

CC-SA looks perfect but its page says:
""This license is retired. Do not use for new works.""
GFDL is burdensome when printing so it won't do either.

","['licensing', 'creative-commons']",
Concert Events Data,"
I am looking for an historic dataset of concert events. I have tried the last.fm api but the query endpoint I need appears to be broken: 
https://stackoverflow.com/questions/32409011/last-fm-geo-getevents-returns-invalid-method-no-method-with-that-name-in-this
I have also tried the eventbrite api but it didn't have much in the way of major concerts. Basically, I need a list of concerts that occurred within a given city/country. I would need the dataset to go back to January 2015.  
","['data-request', 'api']",Setlist.fm offers this data; here's Madison Square Gardens 2015 Schedule just to show you an example of the data you requested. You can either scrape or use Setlist.fm API
NSLDS Completion and Transfer Rates,"
I'm confused as to how this set of variables works.  From reading the documentation, it seems like wdraw_orig_yr4_rt for 2012, wdraw_orig_yr3_rt for 2011, and wdraw_orig_yr2_rt for 2010 should all refer to withdrawal rates for the 2009 cohort in different measurement years (2013, 2012, and 2011, respectively).  But if I look at these numbers for a given institution, they don't seem to obey that description.  

Could someone be more specific as to what these measure?
If I wanted to calculate a cumulative withdrawal rate for given cohort and a specific institution (i.e. total % drop outs over 4 years), could that be accomplished with this data and how?

",['collegescorecard'],
Dataset of large graphs for classifiction,"
I want to evaluate a graph kernel designed for large graphs (> 10^6 nodes). Hence, I'm looking for suitable graph data sets, i.e., a set of (huge) graphs and corresponding classes.
Any ideas?
","['machine-learning', 'network-structure', 'big-data']",
College Scorecard First Year Returning Students Calculation,"
How is Students Who Return After Their First Year calculated on the College Scorecard website? The closest field I can see in the Data Dictionary is ENRL_ORIG_YR2_RT, but that doesn't seem exactly to be it.
I know at least some of the code is available on Github, but I don't know where in the codebase it indicates which fields from the API queries specifically populate which section of the page for a given school. If someone let me know where to look, I could answer these type of questions for myself :)
",['collegescorecard'],"The ""Students Who Return After Their First Year"" corresponds to RET_FT4 for 4-year institutions and RET_FTL4 for less than 4-year institutions.  These variables were created from IPEDS and includes first-year retention information on all first-year full-time undergraduates. The ENRL_ORIG_YR2_RT was created from the National Student Loans Data System and only includes students receiving federal loans and grants."
How is the Students Paying Down Debt field calculated in the College Scorecard website?,"
How is the Students Paying Down Debt field calculated in the College Scorecard website? I don't see a field in the data dictionary that precisely corresponds to it, nor even a set of fields that could.
",['collegescorecard'],"On the consumer website, you can click the ""i"" button below the ""Students Paying Down Debt Field"" on each college page and it will display a brief definition for the measure. It should also correspond to the 3-year repayment rate field on the more technical website at collegescorecard.ed.gov/data  The short definition for this measure is: The share of students who have repaid at least $1 of the principal balance on their federal loans within 3 years of leaving school. "
In the College Scorecard Data Directory--what is N=30,"
In the directory file, for all the loan and debt numbers it says ""suppressed for n=30"". What is ""n""?
","['education', 'collegescorecard']","I would guess that n probably means number of students in cohort, but am not sure. Gainful Employment reporting I know is not publicly released when n<30 due to privacy reasons.Here is some suppporting documentation: ""[F]or elements that we expect to highlight on the consumer-facing College Scorecard, a separate version of the element is vailable that suppresses the data for schools with fewer than 30 students in the denominator to ensure the data are as representative as possible.""Full College Scorecard Data Documentation"
Sector Variable?,"
I am searching through the data files and dictionary using a variety of keywords (sector, public, etc.) and can't seem to find the Sector variable from IPEDS.
Control is there, as are a few clues to derive a level (Carnegie for some, highest degree), or I can just match from another database using UNITED, but please tell me I'm missing something!
Otherwise, great launch on the programming and UX side from 18F!
",['collegescorecard'],
Why the 8-digit UnitID,"
In the raw data released with the Scorecard, some institutions have an 8 digit unitid (the one tied to IPEDS not the OPE IDs).  Can someone explain why this is?  I can see they tend to be branch campuses. So is it a case of the institution has its own 8-digit OPE ID but is not in IPEDS?  Thus there is no assigned unique IPEDS ID.  But if that is the case, why are these branch campuses not in IPEDS too?
",['collegescorecard'],
Data on Latin America Households TV sets with HDMI ports,"
Is there a reputable source, data firm / report where I can get info, per country basis preferably, of households in Latin America who have Televisions with HDMI ports?
","['telecom', 'latin-america']",
Incorrect Information on College Scorecard,"
I am the Marketing Communications Director at a college listed on your website, and much of the information is incorrect (enrollment, academic programs, and costs are listed as including room and board and are not stated as such). How can we revise this information to make it more accurate?
",['collegescorecard'],
I need data set for climate changes in San Diego?,"
If any of you guys could find accurate data sets for temperature and several other parameters for climate change in San Diego please share the link. Please share any other accurate datasets available for san diego city.
","['data-request', 'weather']",I wrote some Python scripts that can be adapted for that. You just need an API key from wunderground.https://github.com/joshmalina/pollution/blob/master/Build_historical_weather_data.ipynb
All Demonym's in their native language,"
COUNTRY - ? / ?
US - American / Americans
UK - English / English
DE - Deutscher / Deutsche

Anyone an idea where to find this? We're trying to find any sort of source for this for weeks now.
","['data-request', 'language', 'global']",
High Resolution Imagery - USA,"
Needed a online high resolution imagery for USA free to be used anyone for personal and commercial purposes.

RGB
2012-2015
Full or partial country coverage
0,5-2 meters per pixel
WMS/TMS and Other GIS-Services

Any suggestion?
","['usa', 'geospatial']",
Cyberattacks on Small- Medium Business?,"
Does anyone have a dataset of type of cyber attack, amount of attacks and damage on SME's?
Edit:
The possible duplicate Public Datasets on Data Breach didn't really help me because it's about databreaches and it only says ""hacked"" or ""incidental leak"" etc. I'm looking for info about SMB's that got hacked, or attempted hacked (by APT's), got infected with malware, got attacked by DDoS, etc.
","['business', 'security']",
List of public holidays by countries?,"
When working across country border it makes things easier to know in advance if people in a specific country are going to be on public holiday a certain day.
While some calendars application offer to import this information, is there an open list of public holidays per country (and ideally in icalendar format) available similar to what is available for time-zones (Olson DB)?
Note: I'm aware of:

countries specific sites like opm.gov
Also other SO thread

But looking for an international list and thought that people on Open Data may have other data sources than listed above.
","['data-request', 'calendar']","Just came across Azure open dataset:https://azure.microsoft.com/en-us/services/open-datasets/catalog/public-holidays/Worldwide public holiday data sourced from PyPI holidays package and Wikipedia, covering 38 countries or regions from 1970 to 2099.
Each row indicates the holiday info for a specific date, country or region, and whether most people have paid time off."
Databases for pdf tables,"
Are there databases for the open data Dietary Reference Intake PDFs?
I found the PDFs for the DRI tables but wish to have the format as a database table for purposes of creating a computer app.
The PDFs can be found here
",['data.gov'],
Question regarding earnings by major,"
I wasn't able to find earnings by major.  Do those data exist in the database?  If not, have you considered collecting them?
",['collegescorecard'],
College not showing on College Scorecard [duplicate],"







This question already has answers here:
                                
                            




Missing schools on college scorecard

                                (2 answers)
                            

Closed 7 years ago.



The college I am IR director for does not show on the College Scorecard web site. It does not show by zip code, state or name search. Data do show for the college in the raw data file. An answer to a prior question about missing colleges indicates the Scorecard is currrently ""limited to institutions that predominantly grant 2-year and/or 4-year degrees. The Department of Education is exploring whether and how to add predominantly less-than-two-year schools that offer associate’s or bachelor’s degree programs to the site in future iterations of Scorecard."" My college grants predominantly associate's degrees. Other colleges in the state system (NC) are displayed. Why wouldn't our college be showing?
",['collegescorecard'],
Missing schools on college scorecard,"
Does anybody know why are some schools not showing up on the College Scorecard (https://collegescorecard.ed.gov) recently released by the Obama administration? For example, why isn't Gateway Community & Technical College in Kentucky showing up?
",['collegescorecard'],
Are Creative Commons licenses suitable for data?,"
Since OpenStreetMap has migrated from CC BY-SA to the newly created ODbL for its database, I have lived under the impression that the CC-family of licenses are - at least - not ideal for use with data. Here a little more
background story, abridged from the post ""Why CC BY-SA is unsuitable"" [for the OSM database] on the OSM Foundation blog.
Background
Lack of Copyright Protection in some jurisdictions (e.g. USA), difficulties in Combining CC BY-SA with Other Data. While the Share-Alike requires map tiles to stay open, modified/improved data does not have to be shared. Finally, there was Uncertainty and doubt over extent of derived work before the license change: with thousands of copyright holders (i.e. all contributors), the OSM foundation could not easily make an authoritative statement about what consituted a derived work (which would trigger the ""SA"" part in the CC license).
Therefore, OSM foundation did announce that ""We are changing the license"" to the Open Database License (ODbL) 1.0, with a lot of transitional work involved.
Fast-forward to CC 4.0
In the OSM discussion (in times of CC 2.0 licenses), I remember having read about the CC creators explicitely not recommending the use of CC licenses for databases. A quote-quote from the license change announcement:

""Creative Commons does not recommend using Creative Commons licenses for informational databases, such as educational or scientific databases.""

This notion seems to have changed. The current Creative Commons FAQ says:

Can I apply a Creative Commons license to databases?
Yes. CC licenses can be used on databases. In the 4.0 license suite, applicable sui generis database rights are licensed under the same license conditions as copyright. Many governments and others use CC licenses for data and databases.

The question
With all that said, does this mean that today Creative Commons licenses can be recommended for use with databases/data sets? What recent statements/blog posts/opinions/judgements have you heard of?
","['licensing', 'creative-commons', 'odbl']","Creative Commons sure seems to think so; they just launched a new initiative called open business models:
Open Business Models – Call For Participation
http://creativecommons.org/weblog/entry/45022
Open Business Models, Open Data, and the Public Interest
http://creativecommons.org/weblog/entry/45417
Open Data tags found on Creative Commons site:
http://creativecommons.org/tag/open-data
Creative Commons wiki document on data
https://wiki.creativecommons.org/wiki/Data
Open Data Commons Attribution License tags found on Creative Commons site:
http://creativecommons.org/tag/open-data-commons-attribution-license
This is a hot button topic in many circles of openness; good luck navigating the trolling and toxicity.  Speaking of, Open Source Stack Exchange provides another forum for you to ask this, and you'll get detailed, informative feedback. You'll have to wade through the comments of user strife and inner turmoil, and you'll also most likely also get downvoted/closed. Asker beware...  UPDATE 2015-10-16
ODI Node in North Carolina spell this out very clearly in their slidedeck ""Open Data in a Day - Licensing, Law and Best Practice"", where they essentially say on slide 18:  ""Only CC-BY and CC-BY-SA can be used for Open Data
The best Open Data license remains CC Zero, while all of the others are very hard to enforce.""  http://www.slideshare.net/TheODINC/open-data-in-a-day-licensing-law-and-best-practice"
Fundamentals data for European stocks,"
I am building a website than uses restful api to fetch stocks fundamentals data, like ROIC, EPS, for ten years history.
I am using SF1 database from Quandl for US stocks.
Where can I find the same kind of data for same european stocks?
Commercial data provider as xignite.com are too expensive (i.e. more than 1k$/month).
A sample request for Apple quarterly sales per shares data is:
https://www.quandl.com/api/v1/datasets/SF1/AAPL_SPS_MRT.json?auth_token=<you api key for quandl>

with a reply of
""errors"":{},""id"":13996054,""source_name"":""Core US Fundamentals Data"",""source_code"":""SF1"",""code"":""AAPL_SPS_MRT"",""name"":""APPLE INC (NASDAQ:AAPL) - Sales per Share (Most Recent - Trailing Twelve Months)"",""urlize_name"":""APPLE-INC-NASDAQ-AAPL-Sales-per-Share-Most-Recent-Trailing-Twelve-Months"",""display_url"":""http://www.sharadar.com/s/GsnxIPnFSpMZefYqX"",""description"":""<p><b>Indicator Description</b> [Sales per Share]: Sales per Share measures the ratio between <a href='AAPL_REVENUE_MRT'>[REVENUE]</a> and <a href='AAPL_SHARESWA_MRT'>[SHARESWA]</a>.</p> <p><b>Company Self Description</b> [APPLE INC]: The Company designs, manufactures, and markets mobile communication and media devices, personal computers, and portable digital music players, and sells a variety of related software, services, peripherals, networking solutions and third-party digital content and applications. The Company's products and services include iPhone, iPad, Mac, iPod, Apple TV, a portfolio of consumer and professional software applications, the iOS and OS X operating systems, iCloud, and a variety of accessory, service and support offerings. The Company also sells and delivers digital content and applications through the iTunes Store, App Store, iBooks Store and Mac App Store. The Company sells its products worldwide through its retail stores, online stores, and direct sales force, as well as through third-party cellular network carriers, wholesalers, retailers, and value-added resellers.</p> <p><b>Dimension</b>: (Most Recent - Trailing Twelve Months) - MRT</p> <p><b>Statement</b>: Metrics</p> <p><b>Units</b>: ratio</p> <p><b>Sector</b>: Technology</p> <p><b>Ticker</b>: AAPL</p> <p><b>Exchange</b>: NASDAQ</p> <p><b>Index Membership</b>: S&P500, NASDAQ100, DJIA, RUSSELL1000</p> "",""updated_at"":""2015-07-23T03:23:54.591Z"",""frequency"":""quarterly"",""from_date"":""2004-03-27"",""to_date"":""2015-06-27"",""column_names"":[""Date"",""Value""],""private"":false,""type"":null,""premium"":true,""data"":[[""2015-06-27"",39.15208784],[""2015-03-28"",36.61915092],[""2014-12-27"",34.19428309],[""2014-09-27"",30.03743937],[""2014-06-28"",29.62827446],[""2014-03-29"",28.74837792],[""2013-12-28"",27.73884241],[""2013-09-28"",26.38591269],[""2013-06-29"",26.34455532],[""2013-03-30"",25.70984323],[""2012-12-29"",25.05731534],[""2012-09-29"",23.91726059],[""2012-06-30"",22.69800121],[""2012-03-31"",21.78399204],[""2011-12-31"",19.61567751],[""2011-09-24"",16.73141358],[""2011-06-25"",15.47520838],[""2011-03-26"",13.53233766],[""2010-12-25"",11.85428321],[""2010-09-25"",10.24547193],[""2010-06-26"",9.57186723],[""2010-03-27"",8.68179188],[""2009-12-26"",8.02223756],[""2009-09-26"",6.86357883],[""2009-06-27"",6.16897358],[""2009-03-28"",5.8226172],[""2008-12-27"",5.58339227],[""2008-09-27"",5.26304361],[""2008-06-28"",4.97901285],[""2008-03-29"",4.66912963],[""2007-12-29"",4.32211932],[""2007-09-29"",3.96651446],[""2007-06-30"",3.72896094],[""2007-03-31"",3.57323704],[""2006-12-30"",3.44463049],[""2006-09-30"",3.26907122],[""2006-07-01"",3.04650041],[""2006-04-01"",2.94001227],[""2005-12-31"",2.78395527],[""2005-09-24"",2.4617106],[""2005-06-25"",2.20886547],[""2005-03-26"",1.96156971],[""2004-12-25"",1.76762702],[""2004-09-25"",1.59142373],[""2004-06-26"",1.4559107],[""2004-03-27"",1.40277599]]};

Other data I am using are: 
AAPL_BVPS_MRQ, AAPL_DEBT_MRQ, AAPL_NCFO_MRQ, AAPL_EQUITY_MRQ, APL_PE_MRT, AAPL_EPS_MRQ, AAPL_NETINC_MRQ

Any alternatives?
","['api', 'finance']",
"What is the profile of gradutes from University of Louisville, College of Arts and Sciences and Dept of Biology?","
I have looked at the following webpage: College Scorecard 
https://collegescorecard.ed.gov/school/?157289-University-of-Louisville
and obtained some University-wide data, but am looking for program-specific data. For University of Louisville overall, could you provide a more detailed undergraduate student profile (for example 1) Demographic data, but also 2) Income data, 3) First time college student data). Secondly, is it possible to get that information for the College of Arts and Sciences and  also the Dept of Biology (both BA and BS programs combined is fine)?
","['education', 'collegescorecard']",
College Scorecard full data base,"
The Obama administration recently release College Scorecard Data with detailed information on college cost and earning after graduation. 
Does anybody know if the full data set is available for analysis? Or has somebody created a scraper (for me, ideally in R) to get the data?
","['data-request', 'government', 'education', 'collegescorecard']",College Scorecard Data:  https://collegescorecard.ed.gov/data/Download all data (~200 MB)Documented APIGithub repo for website
Dataset for english words of dictionary for a NLP project,"
I am working on a NLP project, and for that I need a dataset of English words (words typically found in dictionary). Could somebody please guide me how to put together such dataset?
Is there any online resource for such requirements? If not, what is the best way to go about making such dataset on our own?
","['data-request', 'language', 'nlp']",
Speech act prediction data sets,"
I am looking for data sets containing dialogues labeled with speech acts. I am open as to the definition of a dialogue, e.g. message board posts are good too (1).
Example (FOL, QST, and RES are speech act categories; opening, info, confirm, positive are speech act attributes): 
(G) Hi, good afternoon. 0000    FOL(opening)
(T) Hi, good afternoon. 0001    FOL(opening)
(G) %Uh this is tour guide %uh number one And my name is Lynnette.  0002    FOL(opening); FOL(info-opening)
(G) And how do I address you?   0003    QST(opening)
(T) I'm %uh participant number twenty and my name is %uh John.  0004    FOL(info)
(G) John?   0005    QST(confirm-opening)
(G) Hi John.    0006    FOL(opening)
(T) Yup.    0007    RES(confirm)
(T) I'm good.   0008    FOL(opening-positive)


(1) Qadir, Ashequl, and Ellen Riloff. ""Classifying sentences as speech acts in message board posts."" Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2011.
","['data-request', 'nlp']",
Green Button energy data,"
The Green Button Data program in the US allows energy consumers to easily download their consumption data in a standard XML format. With that exported file, they can upload to a 3rd party site or app, who will provide a customized report.


My question: Are there any public data sets of real consumer green button data? For example, home-efficiency enthusiasts who have made their data public, either alone or as a group?
(I'll self-answer with some better know sample data sources)


Related question: 
Is there a list of all utilities that offer the Green Button Download and Green Button Connect?
","['data-request', 'usa', 'time-series', 'energy']","Some better known sample data setsElectricity usage data that reflect different usage patterns common among PG&E customersDepartment of Energy Data by Design Challenge sample dataGreen Button sample from Texas - two householdsOpenEI Energy Datasets (I can't quickly find any Green Button formats)SDGE (San Diego Gas & Electric) Electric Interval Data Feb 1 2011 to Feb 1 2012 (CSV?)NIST Software Development Kit - seems to be only simulated time seriesOntario Green Button Sample Datasets - Six total, including hourly, daily, and monthly datasets.(my source for some links)"
Flight delays for Europe,"
From @RufusPollock (founder of OKFN) on Twitter... (link to tweet)

Anyone know if #EU has any #OpenData on flight delays like the US does?

(Assuming he is referencing US flight delays, from the Bureau of Transportation and Statistics)
","['data-request', 'transportation', 'europe']",
"Simple, online collaborative database","
I would like to launch an online collaborative database (< 100 MB, most likely < 10 MB). I'll use either MySQL, MariaDB or PostgreSQL.
I need a platform that would allow people to submit pull requests to improve the database, and the pull requests should be readable. Is there such platforms? Perhaps GitHub can be used for that purpose (unsure how readable diff of large SQL dumps would be)?
I am aware of dat but I don't want to have to host the repository. I am also aware of DataHub (1) but it looks like a prototype only.

(1) Bhardwaj, Anant, et al. ""Datahub: Collaborative data science & dataset version management at scale."" arXiv preprint arXiv:1409.0798 (2014).
",['tool-request'],
Structured movie/TV dataset,"
I am looking for a downloadable, always up to date and structured comprehensive dataset of movies and TV shows.
I found this question and it does have some answers - DBPedia and Freebase, but they do not provide the same kind of comprehensive data+images that TheTVDB/TheMovieDB have.
Essentially what I need is a structured dataset with the data TheMovieDB/TheTVDB/IMDB have. Scraping/downloading this from an API is also an option, as long as the given service has a reasonable limit which would allow retrieving their whole dataset in a couple of days.
I would imagine there's a paid service that would sell this kind of data?
Details on what kind of information I need:

Title, first aired/release year, certification, description, tagline
Genres
IMDB ID
Cast, directors, etc.
IMDB Rating
TV show specific info: episodes (name, release date), seasons, runtime, status (ended/active), air date
Posters/images
Any additional data might be useful

Any ideas?
","['data-request', 'film']",
Reporting Poorly Secured Non-Public Use Federally Funded Data,"
I work for a non-profit and recently I applied for access to non-publicly available data. My concern is that this data is not very well protected, as it potentially contains personally identifiable information, and all it took to access it was a URL.
This data comes from another non-profit that is predominantly federally funded. I know this stack exchange is focused primarily on open data, but does anyone know where / how I might go about reporting my concern? Is there a federal agency for this sort of thing?
","['government', 'releasing-data', 'nonprofit', 'security']",
Requirements management data,"
Requirements management software produces data (either stored on a database server or as individual files). Export to CSV is also usually supported.
Where can I get this data for real-life projects? I actually need the software specification data/document which is created at the end of requirements phase.
Both proprietary or open source software are OK, as long as they have a proper requirements phase.
","['machine-learning', 'software']",
Is there any state wise and quarterly downloadable US economic data apart from GDP?,"
I am looking for some downloadable US economic dataset, apart from GDP data, which has data state wise and quarterly. I went through BLS website but either couldn't find any relevant data which has state wise and quarterly information or couldn't find a way to download those.
Is anyone aware of any such economic dataset that I can download?
","['data-request', 'usa', 'data.gov', 'economics']",
"Non-violent misbehaviors in California, 2014","
Where can I find the stats for the NON-VIOLENT MISBEHAVIORS were referred to on January 8, 2014 by U.S. Secretary of Education Arne Duncan, citing California’s data?

“nearly half of the more than 700,000 suspensions statewide in the 2011-12 school year were for, quote, ‘willful defiance’”.
“Nationwide,” he noted, “as many as 95 percent of out-of-school suspensions are for nonviolent misbehavior--like being disruptive, acting disrespectfully, tardiness, profanity, and dress code violations”.

Rethinking School Discipline, Arne Duncan, 2014.
","['data-request', 'usa', 'education']",
Are there sources for interstate movements of companies?,"
Is there data on the interstate migration of companies. Including

Headquarters moving from one state to another
Employment, by job or broad category, increasing or decreasing by company by state?

","['data-request', 'economics', 'migration']",
Trade imbalance at the County level in the US,"
I am looking for some source of data on trade imbalance at a county level in the US, preferably for the years 1990-2007. Does anyone know if such data can be publicly available? Or any paper that has been using data like this?
UPD: to break this down, I am looking for:

international import/export statistics by US county,

intra-state trade statistics, meaning shipments between counties within the US.


","['data-request', 'usa', 'county', 'trade']",
Number of automobiles produced inside the borders of the us annually last 20 years by manufacturer?,"
How many automobile units have been manufactured inside the borders of the United States annually last 20 years by manufacturer?
",['data-request'],
Number of automobiles produced inside the borders of the us annually last 20 years?,"
How many automobile units have been manufactured inside the borders of the United States annually last 20 years?
",['data-request'],
Banknotes database,"
Are there a free banknotes database. By saying banknotes database I mean database of all world currencies banknotes values.
For example for the US Dollar values are
$100, $50, $20, $10, $5, $1, 50c, ... 
",['data-request'],"The data you're looking for seems to be available here:
http://www.whichwaytopay.com/world-currencies-by-country.asp
though not in a machine readable format. Yet this is a list where each entry is a link to the information you care for. So if you are familiar with any scripting/programming language, you should be able to crawl this site easily and extract that info."
Academic private grant funding database,"
I'm looking to figure out what academic research has been funded through private/corporate grants. I have found places that list private grants that are currently available, but nothing on historical grants that have been funded and their recipients.
",['data-request'],
Meta-analysis of public 16S data - help!,"
I am trying to start a meta-analysis for which I want to extract some 16S-based information from public databases. Moreover, I want to relate this information with any metadata found in the associated studies (everything from environmental variables to sequencing details).
For this, I realized some databases are available, like NCBI-Nucletotide, NCBI-SRA and EMBL-EBI-ENA, but I am not sure about which one to use or whether I can use them all.
How can I filter only whole 16S sequences? Or even the most used 16S region?
One more thing would be how can I extract all the corresponding metadata?
Has anyone here tried this or anything similar before?
","['metadata', 'computing']",
Memex open data (Dark web),"
Has any data been created by Memex that is available for open use? Is Memex even available to be used in order to create open data of the ""dark web""?
","['data-request', 'tool-request', 'web-crawling']",
Pictures of the Prince Edward Islands,"
I am looking for open pictures of any of the Prince Edward Islands (for instance Marion Island).
Not satellite or maps: rather landscapes or really any picture taken from a boat or from the ground.
https://commons.wikimedia.org/wiki/Category:Prince_Edward_Islands does not have any match.
(Fairy Prion with egg.jpg is probably an error and actually from Macquarie Island, currently under discussion)
The pictures must have a license compatible with Wikimedia Commons (CC-BY-SA, GFDL or more permissive).
","['images', 'wikimedia-commons']",
Are coordinates of pixel clicked on Google Maps reusable?,"
Let's say Joe wants to add the coordinates of the Eiffel Tower to OpenStreetMap.
Joe opens Google Maps, enters ""Eiffel Tower"" in the search box. The Eiffel Tower appears at the center of the map. Joe then estimates where the center of the Eiffel Tower is and right-clicks on that pixel to show the exact latitude/longitude of the clicked point.
Can Joe add these coordinates to OpenStreetMap, which uses the Open Database License? Or does the Google Maps copyright still apply?
Note: All of this is done manually. While Google Maps probably has exact coordinates for the Eiffel Tower, Joe clicked pretty randomly so he won't have the exact same coordinates.
","['geospatial', 'licensing', 'geocoding', 'openstreetmap', 'odbl']",
How can I find a comprehensive list of USAID Cooperative Agreements by country?,"
I am looking for a dataset of all USAID awarded Cooperative Agreements by the country for the last 5 years (at least).
","['data-request', 'usaidopen']",
What gives people the right to license factual data?,"
Data sets, databases, or APIs we can find these days are either licensed openly or commercially. I'm a bit confused as to how the publishers / owners / compilers are rightfully licensing these factual data by their own terms?
I mean, first of all, they are not the creator nor originator of the data. Second of all, the data are almost certainly harvested or collected from public sources such as Internet or government / university or other sources such as users' inputs / contributions, over the years.
This is not to mention that lots of the data sets have repetitive data (same piece of factual data) that are actually licensed under very different terms, which makes the situation even more confusing.
What actually gives someone the right to license factual data under their own terms? How and why someone can govern how a piece of factual data can be used?
My guesses:

It's not the data itself, because nobody can own factual data, right?
But is it the unique structure / organization / compilation of data set / database? So the license is about the particular organization of data. As long as I have a different organization, e.g. from various different sources, or very different tables, columns, names, I can then license my data set / database in my own terms?
Or is it the effort paid to gather / organize the data? So as long as I paid an effort in making the data set different, I'm entitled to license it in my own terms?
Is it the user input / contribution that transfers the right to the website / company that they are contributing to? When a user contributes some local business contact information to a website, does it give the website the right to license this data in their own terms?

Why should I follow some data license that disallows me to use the factual data (such as Earth parameters, birthday of Elvis, etc.) commercially?
Update (of some examples)
For instance, a hotels booking website clearly states in the terms that they disallow any usage of their hotel listings for commercial purposes other than on their website. But why should I follow it? Do they own the hotels information such as title, phone number, address, website URL, etc.? If not, why should I follow the terms?
A similar example is IMDB. They definitely wouldn't allow commercial purposes regarding their movie data (factual data, title, date, names, etc., not creative texts / descriptions, etc.), but why should I follow the terms if they don't own the data? Especially if I'm not blatantly copying the entire database exactly as is on a grand scale, just some of its data remixed / rearranged with movie data from other sources.
Another example is data on Freebase, Dbpedia, and Wikidata. They disallow commercial purposes and mandates that I share-alike the data openly without charging people. But why should I follow the terms? Can't I do business and profit from these data if I can? Because open and free is not always the answer in a business world, otherwise Linux would be the most popular OS.
Sui generis database right
What makes up the Sui generis database right? I read the Wikipedia article and yes database has rights in the EU and UK but what kind of databases? 
If I gathered data from dozens or hundreds of different databases (each of their own Sui generis rights) and made 'substantial investment in obtaining, verifying or presenting the contents' of the database, remixing and rearranging the original data so they become better categorized / indexed and more searchable / traversable, do I have my own Sui generis rights to this new and much bigger database with the same factual data?
","['licensing', 'legal']",
Scraping vehicle reporting data from regulator's website,"
Website in question: http://www-odi.nhtsa.dot.gov/ewr/qb/index.cfm
Automakers are required to report on a quarterly basis to NHTSA any claims brought against them that involve death, injury or property damage. 
While NHTSA makes other databases open to the public in the form of large flat files (text) EWR reports are still segregated by automaker, by Report Type and by Quarter. 
I'm trying to find the best tool (and tool operator) to use to scrape all this data from the website. 
Currently, if you select an Manufacturer, Report Type and Report Period - then click on, in my case ""light duty vehicle"" you are taken to a new page where you have the option of downloading into a text file the results of that one inquiry. 
With 26 automakers (listed below) and multiple types of reports and multiple quarters - doing this by hand will take an eternity. 
Any thoughts on an easier, faster way to pull all of this data into a single file? 
UPDATE: 
I was able, with the help of a friend, to come up with the following code that works for production data, but doesn't seem to work for Death and Injury.When I chane ""prod"" to ""di"" I get the correct ""app"" option value, but for some reason the script skips over the ""yr_qtr"" selection and loops back to the next manufacturerCode. 
import csv
import itertools
import os
from selenium import webdriver
from selenium.webdriver.support.select import Select
from selenium.webdriver.support.ui import WebDriverWait


def createDir(filepath):
    if os.path.exists(filepath):
        pass
    else:
        os.mkdir(filepath)



# Create directory at ""C:\Data"" to hold all of the files
createDir(r""C:\Data"")

# Base URL to receive queries        
url = ""http://www-odi.nhtsa.dot.gov/ewr/qb/index.cfm""

# Read in the file containing manufacturer names and EWR codes
# Data is in the format ""EWR code,ManufacturerName""
with open(""C:/Data/manufacturer_codes.csv"", ""r"") as f:
    csvreader = csv.reader(f)
    manufacturerDict = {row[0]: row[1] for row in csvreader}


# Define which time periods we are interested in.  The data comes quarterly with
# period values in the format YYYY,m
requestedPeriods = list(itertools.product(range(2001,2016),range(1,5)))


# Iterate through each of the manufacturer entries and download the entire history
# for that manufacturer
for manufacturerCode, manufacturerName in manufacturerDict.items():
    # Get rid of characters that might complicate file/folder naming
    charactersToReplace = [""."", "","", ""-""]
    manufacturerName = manufacturerName.strip().translate("""".join(charactersToReplace))
    # Set the location for file downloads to a folder with the manufacturer's name
    filepath = os.path.join(r""C:\Data"", manufacturerName)
    createDir(filepath)


    # Set the selenium browser profile to control how it handles the dialog box
    # asking us to download the EWR text file
    profile = webdriver.FirefoxProfile()
    # Setting Firefox folderList option to 2 tells Firefox to direct downloads to 
    # a user-defined folder 
    profile.set_preference(""browser.download.folderList"",2)
    profile.set_preference(""browser.helperApps.neverAsk.saveToDisk"",""text/plain"") 
    profile.set_preference(""browser.download.dir"",filepath)
    # Create the selenium web driver using the profile settings we created earlier
    wb = webdriver.Firefox(firefox_profile=profile)

    def fetchData():
        wb.get(url)
        try:    
            wb.find_element_by_name(""ewr_id"")
            wb.find_element_by_xpath('//select[@name=""ewr_id""]/option[@value='+ manufacturerCode + ']').click()
            wb.find_element_by_xpath('//select[@name=""app""]/option[@value=""prod""]').click()
            currentPeriod = ""{},{}"".format(periodval[0],periodval[1])
            wb.find_element_by_xpath('//select[@name=""yr_qtr""]/option[@value=""' + currentPeriod +'""]').click()
            wb.find_element_by_css_selector(""a[href*='javascript:document.ewrsearch']"").click()
            wb.find_element_by_xpath('//input[@name=""Download""]').click()

            return True
        except:
            return False


    for periodval in requestedPeriods:
        failureCounter = 0
        # If it fails to download (e.g. because the site is slow to respond), try again
        while failureCounter < 3:
            if not fetchData():
                failureCounter += 1
            else:
                break

    wb.close()
wb.quit()

","['data-request', 'python']",
Which one will be better to join startup or service based [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 7 years ago.







                        Improve this question
                    



I am MTech from CSE branch and a fresher. I have 2 offers one in service based company and other one is startup though package is same for both. I am really confused which company should I choose. Startup is currently working on charting JavaScript library like kendoUI and the startup is started about 2and half year back. But I am confused which one would be better for career growth. Because job profile also matters and as I am a fresher I don't know what to do. Can you please guide me. Thanks in advance.
",['companies'],
Get the details of all Indian films from Wikipedia,"
My application needs the details of All Indian movies. I can't take it from IMDB or OMDB because the number of Indian movies is too less there. I need to fetch it from Wikipedia. Freebase is deprecated now and I have heard DBPedia has many less entries. The only option left is Wikidata's query API. But it is getting too tough to form the query. Couldn't understand through Wikidata's 1 page api documentation. Tried the following query, but it returned just 2118 entries, which is too less compared to what we can see in Wikipedia (10000+) entries.
https://wdq.wmflabs.org/api?q=claim[31:(TREE[11424][][279])]%20AND%20tree[668][150][17,131]

Can anybody help me in fetching the details of all Indian movies from wikipedia? It would be a great help 
","['linked-data', 'film', 'wikidata']",
Inconsistent fields,"
This question is related to https://stackoverflow.com/questions/32363315/gson-fields-that-sometimes-are-strings-and-others-arrays
I'm parsing json with Gson but I'm struggling with the data I'm getting. This is part of an API out of my control (openFDA) so changing that might not be an option.
Here's the json I'm strugling with: https://api.fda.gov/device/event.json?search=device.generic_name:generator&limit=10
There are some fields that are not consistent, for example remedial_action. Sometimes it comes out like this:
""remedial_action"": [
        ""Recall""
]

and in other results like this:
""remedial_action"": """"

So it's either an array or a plain string. Looks like a bug to me. But I'm a json newbie.
","['openfda', 'api']",
"Social connections, income/profession and intelligence","
I have a hypothesis that people with more social connections on social networking sites will also tend to have higher incomes. What I lack is data. Does anyone know of any good data set for this?
Is there any data linking income and number of social connections on social networking sites?
","['data-request', 'social-media', 'income']",
"Can state, county or city sales tax records be retrieved in the U.S. under FOIA?","
Just  stopped by my local state government department of revenue office and ask them about how to go about requesting sales tax receipts of certain businesses in my area under the FOIA act. I was told that ""I don't think those records are  covered under FOIA, but you can try contacting the main state office"". Is this true? Are public sales tax records requests not covered under FOIA?
","['data-request', 'releasing-data', 'taxes', 'foia']","Sales tax records for an individual business are probably protected (or exempted) by FOIA authorizing legislation as competitive business records. With that information, a competitor could determine quite a lot about an individual business.Much like an individual's income tax returns are not public, you'll probably not be able to drill down to the level you seek.Look at this site for details of each state's FOIA rules:
http://www.nfoic.org/state-freedom-of-information-laws"
Is there a complete list of what US Census data is available for every type of geographic unit?,"
The US Census provides many kinds of data (population, income, age, etc.) grouped by many kinds of geographic units (census block, tract, city, urban cluster, etc.).  I have not been able to find a comprehensive list saying which combinations of these are available.  That is, something that looks like this:

Total Population data is available for each


block
block group
etc.

Income data is available for each


tract
urban cluster
etc.


I can imagine there might be a separate such list for each census data source (e.g., 2010 Census, 2012 American Community Survey, whatever).
Does such a list (or lists) exist, giving a complete statement of exactly which values are available for which geographies?
","['usa', 'census']",
Looking for a blood glucose data set for predictive algorithm,"
Student in data analysis and diabetes, I'm looking for a data set that contains the features below to test some algorithm of prediction (random forest). Where can I get such a data set, please?
The features:

Continuous blood sugar
recent food out to several hours depending on the type and how much
activity levels
stress levels
illness
basal and bolus insulin rate (the patient wears a pump)

","['data-request', 'medical']",
What are some good approaches for predicting sub-state level population changes before census data is released,"
I am currently working with US census data from 2013 at the latest. I am very interested in getting population and other demographic data pertaining to 2014 and   Early 2015 as soon as possible. What approaches have people used in the past to get a sense of where the major Demographic changes are happening before the official census data is released?
NOTE: I'm interested in geographically specific information. Any information about US areas that is any less specific than the city or county level is not of any interest to me
","['data-request', 'usa', 'us-census', 'demographics', 'census']",
What data formats that can be published on the first level (1 star) of open data?,"
I wonder what are the possible data formats that can be published for 1-star level of open data.
The only example I have found is with the PDF format, I wonder if there are other possible formats to obtain the first star.
","['data-format', '5-star-scheme']",
Theme park visitor data,"
Is there anywhere that I can obtain data on the numbers of visitors to attractions, such as museums, theme parks, etc.?  The most granular level I can seem to find is approximate figures per year, for example here.  I would like something per month, week or even day if possible.
Note I am UK-based so would like to see something for UK attractions, though if anyone knows of anything for other locations then please do share!
","['data-request', 'glam']",
Public music database that expose APIs to get most popular songs?,"
I know there are a lot of public music databases, but I'm not able to find one that expose APIs to get most popular/played/listened songs, for example I checked last.fm APIs and the only method to search songs that I found is getTracks that retrieves 

paginated list of all the tracks in a user's library

So my question is: Is there any music database that expose APIs to get most popular/played/listened songs/tracks?
","['data-request', 'api', 'music']",
"Worldwide holidays, and their names in the local dominant language","
Might be slightly OT here but I'll give it a try since the topic is probably well known to many here:
We're looking for a database or system to get current and upcoming holidays by location, worldwide, and in english and in each of the countries language.
As in if there is a holiday on the first Sunday of April we would want to know that. I found various databases and small to large companies that export the data by year but most of them only offer the holiday names in English.
We would appreciate any idea about this because we're kinda stuck on this one ;)
","['data-request', 'language', 'calendar']","Several are found here: http://holidays.kayaposoft.com/A lot more are found here: https://www.mozilla.org/en-US/projects/calendar/holidays/Language is an issue though. Not sure what you want. In the case of e.g. Algeria would you want Arabic or French? Or in the case of Nigeria, would you want English or another of the ~500 languages.Maybe the best would be to separate these steps:"
California Gubernatorial Election Turnouts,"
I'm able to find the number of votes by a particular year on each election's Wikipedia page (such as https://en.wikipedia.org/wiki/California_gubernatorial_election,_2010), but they all link back to a pdf on the state website (such as http://www.sos.ca.gov/elections/sov/2010-general/complete-sov.pdf).
Have there been any attempts to aggregate this data in tabular format? I see http://openelections.net/results/#ca but it is not populated yet.
The reason I care is because I have recently found out that the gubernatorial turnout is directly related to the amount of signatures necessary to put a California proposition onto the ballot, so would like to compare the rates of the two.
",['elections'],This resource has a more direct reference to what I want: http://ballotpedia.org/Signature_requirements_for_ballot_measures_in_California. It seems to circumvent the data quality issues (or at least -- the interpretability issue) of the nationbuilder data too.
Price of property prices in local currency for countries in Latin America,"
I am working on a project thesis and I haven't been able to find this set of data, mostly because everything I do encounter are global indexes and for specific countries, and looking into each country's specific website to find it. 
I'm looking for any kind of file that has property prices in local currency for countries in Latin America in the same table, so I can run a comparative analysis. 
","['data-request', 'prices', 'real-estate', 'latin-america']",
What are some sources for interesting data sets to play with?,"
I'm pretty new to data science and want to get my hands dirty. What are some good publicly available data sets to play with? 
",['data-request'],
Data about indian businessmen,"
I am doing a social network analysis of Indian politicians and Businessmen.
I found the biodata of Indian politicians on Indian parliament websites.
Are there any datasets / sites giving the same for famous businessmen / company directors like Vijay Mallya or Naveen Jindal?
","['business', 'india']",
Protocol/software to publish weather information online,"
I've got a temperature and humidity sensor that captures the data outside the house and whose data I collect every 5 minutes.
Is there a standard protocol/format that I can use to publish those data on the web, preferably on my homepage? Maybe even a software that does this automatically?

I found the following online services that one can send data to:

Weather underground - no public protocol; you have to be registered
OpenWeatherMap - protocol
WeatherBug Backyard Stations - protocol (search for ""developer"")

They have only submission protocols, but no standard way to publish the data (make them available to others).
","['releasing-data', 'weather', 'data-format']",
Disease Symptom Dataset?,"
I am currently working on a disease diagnosis system, it is a prototype based on one of my dissertation papers S-Approximation: A New Approach to Algebraic Approximation and S-approximation Spaces: A Three-way Decision Approach.
Up to now, I have used randomly generated datasets, most of them are toy examples which I have generated myself randomly. However, it would be great if I can access some disease and symptoms datasets, so I can test my system with real data.
So far, I have searched for months over the Internet, but the more I went, the less I found.
Cutting the story short, are there any freely available datasets in which for every disease x we have a set of symptoms like {a,b,c,d,e,f,g}.
","['data-request', 'disease']",
How do I download a Socrata graph or map definition I have created?,"
When I create a custom view, a map, chart, graph or report, and save it, the definition of that view is stored somewhere on Socrata.
How is the definition stored? Is it a schema?
How can I download the definition?
How can I upload a modified version of the view back to Socrata?
My goal is two fold:
I want to do version control of my views
Many times I want to use the same map or view with different datasets.
The answer ""Version control can be done with the abcd-wxyz Socrata unique identifier at the end of the URL is not very useful. I can not diff one version of the view with the next other than eye-balling it. I would like to be able to download the schema as a text file that I could then store in a git repository.
Once I have a local copy of the schema, I could then generate the same type of view by uploading it to a different data set. Perhaps a different dataset on the same open data portal. Perhaps the same type of dataset at a different open data portal.
It would also aid me when importing new datasets. If the dataset was incident or ticket type data I could then import a standard set of views. A map, bar charts of types, age or status.
I like the Socrata web UI. It is easy to use and fairly powerful. It would be nice to be able to also manage the view schemas the same way I manage code or in my case as a Linux systems administrator, operating system/application configurations.
Sorry for the long message but version control of views is an such an obvious requirement for a open data portal. I am surprised I can not find any information about it?
","['data.gov', 'uses-of-open-data', 'socrata', 'git']",
"List of Pennsylvania Nursing Schools their Addresses, Enrollment, Graduation Rates?","
I'm looking for a list of nursing schools in Pennsylvania (PA) along with the addresses, enrollment, and graduation rates.  Preferably in a non-scrapable format like JSON or CSV.
","['data-request', 'usa', 'medical', 'state']",
Previous Craigslist Postings,"
Is there a way to access previous craigslist postings in bulk? Particularly interested in being able to select certain categories and download all listings at certain time periods for that category.
Or am I better off just crawling and slowly building the required data set over time?
","['data-request', 'web-crawling']",
MLB Ball/Strike data,"
Particularly interested in ball/strike calls for each at-bat along with the batter, pitcher, and umpire name. Any time frame would work. Data on the outcome of the at-bat would also be valuable.
","['data-request', 'sports']","PITCHf/x Search function by Baseball Savant provides search functionality for the MLBAM PITCHf/x database:
http://www.baseballsavant.com/pitchfx_search.php"
Data on the percentage of Frenchmen who are in favor of allowing UberPOP in France,"
I am looking for surveys or any other kind of data source indicating the percentage of Frenchmen who are in favor of allowing UberPOP in France.
","['data-request', 'france', 'survey']",
Get season statistics for NFL players,"
So as the title suggests I'm trying to retrieve NFL stats for players. I've found that Wikipedia has a quite extensive statistics panel for a lot of players (i.e Tom Brady https://en.wikipedia.org/wiki/Tom_Brady#Professional_statistics) but I can't seem to figure out how to retrieve this data. The Wiki API doesn't seem very helpful and I can't get it from the DOM because the class is wikitable and there are many wikitables on the site. 
Does anyone have a solution for this? Or perhaps a better method of retrieving NFL stats (preferably free or close to it).
","['api', 'sports', 'wikipedia']",
I'm trying to find the amount of federal funding allocated to US cities since 1970. Blocks grants and earmarked funding,"
I'm looking at changes in federal spending on cities since 1970, in ten-year intervals. Ideally, this data would be in two parts: 1) payments to cities that they could spend as they wish and 2) total federal support for cities including grants for specific purposes. I'm looking both for total dollar amounts and as a percentage of city spending.
I'm also looking for comparable figures of cities by US state.
My belief is that federal and state support for cities has declined, but I need to demonstrate or refute that claim. Any advice for a step in the right direction is helpful.
",['data.gov'],
Where can I publish small database for free?,"
Is there any site where one can easily publish a small database (<5MB)? Ideally, the data should be published in a way that it could be sql selected by number of parameters. Just like any national statistical office (for example, Sweden). 
Of course, I only need to publish small datasets. But the key feature, it the possibility to select a subset of the data easily. 
","['releasing-data', 'sql']","If it's really simple, you can use the CSV viewer from Github, which has a built-in search tool.A similar tool is datapipes and for HTML from OKFN Labs.  See the demo.For a more complicated dataset, with more than one table, then another simple option is to export the database as a .SQL file and then let users import it into the SQL database of their choice. You can host the .sql file anywhere, but Github and Datahub.io are two good choices. Here is a simple example.I can expand this answer for tips on how to do this if that is the direction you go.Another option is then to use visualization tool or other Javascript library for display CSV data. See for example D3.js + CSV. There are hosts of other CSV-editors and viewers for the browser."
Publicly Available 'English Opinion Lexicons' Txt,"
I'm an undergraduate and i working on a sentiment analysis project on email data. my first task is to do an opinion mining on the data-set. I train the data with two separate 'English opinion lexicon' data (positive and negative of course ). but the results are not much satisfied. I think if i have more related lexicons results may more accurate. My interest on business related lexicon text.
Anyone have any business related text English opinion lexicons available for public download ..?
","['data-request', 'machine-learning']",
"Database of labeled voice data, specifically laughter","
I'm interested in building a tool for extracting regions of laughter from sound files. Can anyone give me a sense for what publicly available datasets I might use for training such a model?
",['audio'],
Issues with collecting a data set via crowd-sourcing,"
Consider a tight-knit community that might be willing to contribute to a communal data set via a website, Facebook group, etc. As a concrete example, let's say that the data set is a list of landmarks.
The goals of the project would be clearly stated, including that the data set will be explicitly licensed as open data.
What are the best-practices (or risks) with this approach? Should contributors be asked to acknowledge a ""terms of service"" before submitting?
Suppose further that another data set is a list of businesses with operating hours and a contact number. Does that change the complexion of the risks?
Generally speaking, how does one determine what is acceptable in these cases? I'm curious in general but especially vis-a-vis Canada and US law.
","['legal', 'crowdsourcing']","Crowd-sourcing businesses name/hours/number is a big part of what Wikivoyage does, and they have been doing that successfully for quite some time, so their case is worth studying.So, just decide what license to use (I would recommend public domain as it is hardly copyrightable data anyway), state it in any place where people will be contributing data, and make the data easily downloadable."
"Real-time location of trains in France, Germany, Switzerland, and other countries","
In Great Britain, Real Time Trains shows the actual departure, arrival, and passing times at any control point (station stop or not) for any train (passenger, freight, or other) anywhere in Great Britain (England, Wales, and Scotland).  Many sites offer a similar service for flights.  In the United States, Amtrak has an interactive map showing where their passenger trains are right now.
Are there any websites offering information similar to Real Time Trains for other European countries, such as France, Switzerland, or Germany?  I'm mostly interested in a service showing all trains (passenger, freight, others) at any place (station stop or not).  If that doesn't exist, I'm also interested in a website offering information as close to this as publicly available.
","['data-request', 'europe', 'public-transport', 'real-time']",
Solving the daily commute,"
I'm looking for something that would give statistics on my daily commute.
A friend of mine is thinking about leaving their job because the daily driving commute is too dangerous. Nearly got into two major accidents in the first two weeks.
What would be interesting is to investigate different times of travel, maybe reroute suggestions, based on different times of the year etc. lots of ideas but nothing comes to mind except tell the friend to go with their gut.
And yes ""drive slower"" has been offered as a suggestion. It would be interesting to know what lanes could be more dangerous too.
I'm looking for any ideas to help in this real life scenario.  Would be interesting to see what kind of data is out there and how you could get it on a specific driving route. 
There's lots of stats on accidents but not a tool that I know of to help you make a safer commute/pick a job with a safe commute.  Maybe this tool is achievable with the right data set.  
Chicago is a region of particular interest. 
",['traffic'],
Time of arrival and departure of ships in ports,"
Initially asked this question in GIS SE.
Needs to have from port, to port, and time stamps for each (arrival, departure times) and would ideally have route taken in some kind of format I can easily map i.e. geoJSON
Is there a dataset with all of this, or will I need to combine some other ones?
Aware of Database of ships?, it doesn't give me the info I need.
","['transportation', 'geospatial', 'trade', 'oceanographic']",
Where to find public dataset on teachers and public employees salary?,"
I saw some data on internet that showed this info at the individual level.
Is such data available to public to download?
","['data-request', 'finance', 'economics', 'income']",
Linked Open Data Statistics,"
Where i can find a good document about Statistics of Linked open data cloud (organizations, number of triples and number of links) year by year?
In the official web site (lod cloud) there's only Statistics of 2011 and 2014. Where is the information about the other years?
","['linked-data', 'uses-of-open-data']",
Database of smartphone sensor data,"
I'm working on a machine learning project for classifying activity level (walking, running, sitting etc) based on smartphone accelerometer, gyroscope, and gps data
Of course I can just collect this data myself but this is very time consuming. I'm wondering if anybody knows of a database that contains this type of data, and importantly including labels for what type of activity they were doing?
","['machine-learning', 'accelerometer']",There is a dataset on the UCI Machine Learning repository. Check this link for the data and data description. There is no GPS information available. The names for the relevant papers are there as well. So you can look those up if you want to.
Regional Economic Accounts from BEA in a single dataset,"
The Bureau of Economic Analysis has some basic data on the US state and metropolitan areas:

http://www.bea.gov/regional/index.htm

It also has bulk downloads and a query system.
Still, I wonder whether anyone put all this data together in a single panel dataset for quick access? 
","['usa', 'economics']",
Recommendations for calculating unemployment and labor force participation at the block group level,"
I'm new to working with census data and am wondering about best practices for calculating labor force participation and unemployment at the block group level.  I've been using the ACS R package to gather table data from these tables here. 
My current thinking says for unemployment:

Add all estimates for civilian labor force for Ages 16 and older (not including Armed Services) to get total civilian labor force (TCLF)
Divide the sum of all unemployed by TCLF to get proportion unemployed

My current thinking says for labor force participation:

Add all estimates for those Ages 16 and older (including Armed Services) to in labor force to get total labor force (TLF)
Add all estimates for those Ages 16 and older not in labor force to get total out of labor force (TOLF)
Divide the TLF by total population of block group to get proportion in labor force
Divide the TOLF by total population of block group to get proportion out of labor force

Is this the best way to go about this?  Like I said, I'm new to working with census data so any thoughts would be much appreciated.  We are mostly interested in looking at associations between block group characteristics (employment, poverty, walkability) and health behaviors.
","['us-census', 'census']",
How can I Share my Data Sets Without Worrying About Copyright Issues?,"
I'm doing a lot of research in the field of Digital Text Forensics (e.g., authorship attribution, authorship verification, or author profiling). In this field there are only very few data sets available which can be used for own research. One of the few important sources is the evaluation lab on uncovering plagiarism, authorship, and social software misuse (named PAN).
Over the years, I collected texts from many different internet sources (blogs, forums, Amazon, news portals, Project Gutenberg, etc.) on my own, which I aggregated and compiled into various data sets that could be very valuable for the Digital Text Forensics community. Since, as a researcher, I am very interested to share data in order to make experiments reproducible, I'm now facing a big problem, which I don't know how to handle...
How/Can I share my data sets, without worrying about copyright issues?
It should be also highlighted that the data cannot be anonymized, otherwise it would be totally useless for the research community. Hence, I don't know where to start. Of course there are platforms such as FigShare, where data sets can be published, but if I would do this I would first don't get any credit, and secondly can run in a lot of troubles for publishing texts which are not mine (even though they are publicly available).
Has someone else faced this problem?
","['releasing-data', 'research', 'nonprofit']","Without being a trained copyright expert, the crux of your endevour lies in your process of aggregating your text corpus:Over the years, I collected texts from many different internet sources (Blogs, Forums, Amazon, News portals, Project Gutenberg, etc.) by my own, which I aggregated and compiled into various data sets that could be very valuable for the Digital Text Forensics community. If you want to share the resulting data set with your name on it (and don't risk any trouble), every  source you use must be published under a license which explicitely allows its reuse. That means, to be sure, you would have to read the terms/license statement of every blog you scrape. Forums, if they are older, usually don't enforce a permissive license on user contributions. Project Gutenberg usually has an explicit per-book license, and a general license information page. Their content looks rather fine to use. For commercial entities like Amazon, they probably don't have a license that allows reuse without explicit, written permission.If your process of generating your derived data sets (the ones you want to share) from a set of given inputs is rather automated, you could recreate a reduced version that only relies on sources that were explicitely published under a permissive license.Then, in the end, you must choose a license for your own publication. If your data set resembles a database, the ODbL might be a good choice. And just like you want to be attributed for your work, you should accompany your dataset with sufficient attribution for the creators of your sources.Yes, this is all very cumbersome, but that's how copyright law is right now."
Where can I find an interesting data set with 3 way interactions?,"
I am writing about moderation and interactions and would like a data set that has some interesting 3 way interactions. 
",['data-request'],
Datasets in which people make quantity estimates,"
I'm looking for datasets in which any quantity is estimated by an individual person. These are datasets in the tradition of Galton (1907), in which individuals estimated the weight of an ox.
Ideally the individual persons would be making these estimates without consultation with other individuals or resources, but this is not essential.
I need to know the true value for the estimate.
Galton, F. (1907). Vox populi (the wisdom of crowds). Nature, 75, 450-451.
",['data-request'],
making my data LOD-compatible,"
I would like to incorporate the LOD (Linked Open Data) concept an app I built.
My app is a map where users search and can find points on the map, click them and get relative text and multimedia. Power users can add data via a CMS. So it's a simple digital archive.
I do not want to find LOD to put in my app. I want to publish LOD. I want my app data to be in a LOD-compatible format so others can search them and put them in their apps or use them as they want.
How do I do that? Where do I start? Please advise me about starting points and books.
While I am at it, allow me another question. I want to put a section in my app where data relative to the user's choice appears. For example, if the user searched for castles and clicked one,  this section suggests/other similar castles. Will LOD help me implement this?
",['linked-data'],
A source of classical music,"
I am looking for a database with classical music (approximately from the period of 1500-1900). What I need is just music (notes, names of composers/compositions, type of musical instruments the composition was designed for are nice to have but not important).
Ideally it would be a lot of compositions of Vivaldi, Beethoven, Wagner, Chopin, Mozart, Rachmaninoff and many many more whom I do not know. The quality does not really matter (as long as it is not distorted really much).
One option is to search for the names of composers and download their compositions, but this does not look appealing to me, mostly because of my lack of knowledge of the composers and even with googling I will not be able to find a lot of not well-known (for the amateur) composers.
Does anyone know where to get such a database?
","['data-request', 'music']","Free Music Archive and MUSOpen are two off the top of my head:  Classical Genre Section - FMA (Free Music Archive)
https://freemusicarchive.org/genre/Classical/ MUSOpen - Royalty Free Music, Public Domain and Copyright Free Classical Music
https://musopen.org/ Public Domain Sherpa has a blog post on where to find public domain recordings, its pretty in-depth:
http://www.publicdomainsherpa.com/public-domain-recordings.html"
"Black market premium data, all countries 1960-2010","
The ""black market premium"" is commonly used as a determinant of economic growth. Data for all countries between 1960 and 1999 is available from the Global Development Network Growth Database at NYU here: 
http://www.nyudri.org/resources/global-development-network-growth-database/
Does anyone know if there is a source that provides this variable after 1999?
Alternatively, is there a credible source that provides data on unofficial/parallel exchange rates that has decent coverage?
","['data-request', 'economics']",
How to get a review page link or review files for a certain drug using API on FDA?,"
I wanna get the review link for a certain drug links via API, e.g, for the drug ""AUBAGIO"", it's 
""http://www.accessdata.fda.gov/scripts/cder/drugsatfda/index.cfm?fuseaction=Search.Set_Current_Drug&ApplNo=202992&DrugName=AUBAGIO&ActiveIngred=TERIFLUNOMIDE&SponsorApplicant=SANOFI%20AVENTIS%20US&ProductMktStatus=1&goto=Search.Label_ApprovalHistory""
And that can be access by search ""Abagio"", then within the drug page, click on the ""Approval History, Letters, Reviews, and Related Documents"".
That link refers to the review link I need.
So is there any possible way to obtain that using API or programmatically?
If there is no way to do that, how I can obtain the review pdf files or file link for each certain drugs? 
Coz I'm going to fetch the review pdf files for each drugs approved in a certain year. I am thinking that first I can locate a unique link for each drug, and then to get the review files, which are just on the page, is not hard. Or if there is a way that can directly locate the review files would be better.
Thank you!
",['openfda'],
Fitness activity data,"
Seems like something easy to find, but somehow I have hit a brick wall. I am trying to find data set with list of exercises and meta data - exercise name, difficulty, picture, description. Preferably in JSON format.
{
    ""title"": ""Pull-up"",
    ""description"": ""Pull yourself up against horizontal bar fixed above your head."",
    ""muscles"": [""shoulders"", ""arms"", ""back""],
    ""equipment"": ""Pull-up Bar"",
    ""difficulty"": ""hard"",
    ""picture"": ""/img/dude-makeing-a-pull-up.png""
}

I found a Reddit post with scraped data from bodybuilding.com, but I obviously can't use that for legal reasons.
I tried googling, but all I get is some programming exercises.
","['data-request', 'sports']",
publicly available spam dataset of social networks,"
I am trying to create a naive bayes spam filter for social networks and i need a spam dataset (containing posts/tweets etc.) of popular social networks like twitter/facebook. Is there any publicly available dataset which i can use to train the classifier?
","['data-request', 'network-structure', 'machine-learning', 'social-media']",
Is it possible to know the number of American residents/students/tourists leaving France each year?,"
Regarding an implementation my company is conducting in France, I would like to know if it would be possible to know the number of American citizens leaving France each year?
","['data-request', 'usa', 'demographics', 'france']",
Date of Next Inspection for REAC data,"
Is there a dataset that will provide me with the date of the next (upcoming) inspection for REAC (HUD)? The basic data is available via this link, https://hudapps.hud.gov/public/pass/scheduler/publicscheduler.action; however it is not available with the other property data (name, address, etc.) that can be downloaded from HUD's website. 
",['data.gov'],
Commercial Medical Diagnostic testing Precision and Accuracy,"
Since the accuracy and precision (repeatability) of a test is relevant to any decision; how do I find (or phrase) search's to find data on this for commercial clinics?
I used to work for an animal diagnostic company and they continually evaluated their accredited testing facilities; so I am sure that human diagnostic testing facilitates must have records and audits by somebody.
This a rephrase of Validity, Utility and Cost of Clinical Tests
",['medical'],
"Where can I download US secondary (high school, etc) educational test score data for school districts, individual schools, etc?","
This has so far been a surprising difficult task. It appears some aspect of public policy sees it fit to make this data difficult to obtain(?) I'm sure its out there though. No child left behind data, SAT/ACT score statistics for school districts, something like that. I'm looking for (United States) middle & high school academic performance data, not academic ""attainment"", which is very easy information to obtain. Obviously, I'd love to get it at a census block group level of geographic resolution, but anything at this point beneath the county or state level would be great.
","['usa', 'education']",
Is there a specification for versioning a dataset?,"
In computer software, semantic versioning (or something like it) is something of a standard for how to version software releases. The Major.Minor.Patch semantics make clear how big of a change has occurred between the present and an earlier release. Is there something similar for versionining a dataset? Unlike with software, any change to a dataset might be a ""major"" change, so I'm not sure that the logic translates directly. Is there any commonly used specification for versioning a dataset?
",['metadata'],
"Football (Soccer) Player x,y,t data","
I am looking for something that has the (x,y) coordinates of all players on the pitch over time. 
I found this:
https://heim.ifi.uio.no/paalh/publications/files/mmsys2014-dataset.pdf
however, they only track the movements of the home team. I found various papers that discuss the techniques required to do this, but unfortunately don't provide the dataset. 
","['data-request', 'geospatial', 'sports', 'time-series']",
is there road traffic accident data set,"
Is there publicly available raw traffic accident data set which includes the following attributes driver diet pattern,accident time,behavior and vision status. 
",['data-request'],
Historical Oil Price Forecasts - MENA/West Africa Region,"
I am looking for historical crude oil price forecasts, ideally from 1970's - present.
I want to look at impacts of oil price expectations rather than real oil prices in the MENA (https://en.wikipedia.org/wiki/MENA) and West Africa Region with specific focus on Nigeria. Thus, data on any type of crude oil but preferably from this region would be helpful. I would even more prefer data on the type Bonny Light Crude.
Hints on data sources on any license and any format are appreciated
I am aware of the historical forecast archive of the World Bank but I am looking for a longer time-series.
Thanks
","['data-request', 'historical']",
Finding tables in messy structured Excel / csv file to import them in DB,"
we have a lot of messy structured excel files containing tables somewhere on a sheet and we want to import these tables into a database to do some analytic on it. There problem is that we don't have the time to run through the files and clean them and therefore we looking for a tool or algorithm to help us.
We had some ideas to export the excel files to csv and then analyse the structure of them by kicking out empty lines (only semicolons) and finding tables based on the count of semicolons and used columns in the lines.
The following files shows an example of what we have:

The black and white table area is what we want to import into a DB or extract out of the file. The orange area is what we want to delete / skip.
And mostly every files looks different. Did somebody came across this and found a solution?
","['csv', 'excel']",
Dataset of Business Schools in the US,"
Is is there a dataset of all the business schools in the US, with total undergrad enrollment in the Business School, Dean (and Associate Dean's) name and email address, and if there is an online component.  Thanks!
Ideally, it should look like this

","['data-request', 'data.gov', 'government', 'finance', 'education']",
What offices/divisions of U.S. federal agencies and bureaus can do site inspections at private companies?,"
Hoping that someone somewhere collated this stuff already - is there any single dataset that lists all federal offices that can do compliance on-site inspections of any kind? The Federal Register is huge, and life is short.
","['usa', 'government']",
Cleaning up addresses in a large data set,"
I have a dataset of about half a million unique addresses. An address consists of a StreetAddress1, StreetAddress2, City, State and Zip code (all addresses are in the United States).
One of my main problems dealing with this dataset coherently is inconsistency in the wording of addresses. For example, ""1 MAIN STREET"" might also be phrased ""ONE MAIN ST"" referring to the same address.
Are there any free utilities that can help me remedy addresses in this very large set?
I was thinking about writing my own simple script to make addresses consistent with the following rules:
1. ROAD / STREET / AVENUE etc. are replaced by their abbrevations RD / ST / AVE
2. Written numbers ONE / TWO / THREE etc. are replaced by 1 / 2 / 3

However I'm concerned that there are a number of edge cases where this treatment will mangle valid addresses.
Are there existing utilities I can use to accomplish this, ideally locally on my own machine?
",['tool-request'],
RIKEN integrated database of mammals,"
The RIKEN integrated database of mammals is an integrated database of multiple large-scale programs that have been promoted by the RIKEN institute. (Wikipedia)
Where can this database be downloaded?
What is its license?
","['biology', 'japan']",
Raw housing stock of particular city,"
I want to get the raw number of units of housing stock that there is in a particular city in month X of year Y (even yearly data would be fine). This place shows yearly stock from 2010 onwards. Here shows data for every 10 years. This link
www(dot)washingtoncitypaper.com/blogs/housingcomplex/2014/10/24/d-c-s-housing-stock-in-charts/ 

makes me think there should be more yearly data since this has 2013 data.
Is there anywhere I can find a more comprehensive data set?
","['economics', 'us-census', 'historical']",
List of Emails to Student Activities Board of all Universities,"
Does anyone know if there is a public list of all the emails of the student activities board (or something similar to that- student affairs, student governing boards, etc) of all universities?
","['data-request', 'data.gov']",
Option 2: Structured Product Labeling & Language - Which data to pick up?,"
According to the OpenFDA problem definition, it says:
Level 1: Create visualization (word cloud) of boxed warnings
Level 2: Develop a language model to categorize the language in the warning sections of SPLs
Are the data elements to be used for these two different? That is, should I pick up ""boxed_warning"" for Level 1, and ""warnings"" for Level 2 from the API output?
Thanks,
J
",['openfda'],
Pictures of the Korean Central Intelligence Agency,"
I am looking for open (and Wikipedia-usable) pictures describing the Korean Central Intelligence Agency. For instance the building or a plaque in front of it.
The agency has been renamed/transformed, so either old pictures, or new pictures of the building that used to host it, are OK.
Wikipedia Commons has a related category but it contains only a logo (which I guess is not open, only fair-use, and thus not usable everywhere on Wikipedia), a building picture which is tagged for imminent deletion, and watches that are newer than the KCIA:
https://commons.wikimedia.org/wiki/Category:National_Intelligence_Service
",['images'],
Cloud Storage - Usage and Impact [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 7 years ago.







                        Improve this question
                    



Looking for details on usage, adoption, impact, challenges on using public cloud storage platforms example Google Drive, Microsoft Skydrive, Box, Dropbox and so.
",['data-request'],
Open data on African social networks at the micro level,"
I'm looking for open data on household social networks at the micro level in Africa. Preferably I'd like to get piece together a dataset that has networks of households within villages dispersed all across Africa. Am I a dreamer to even think such a dataset is possible to piece together right now? Any village network datasets in Africa?
Data on online African social networks with some sort of geographical or ethnic identification would also work. 
","['data-request', 'network-structure', 'africa']","This doesn't exist as of now. There are very limited datasets on social networks at the micro-level. Especially if you're interested in full village census, you are restricted to very few data sets which you will only get by asking the authors of the respective papers themselves. We are currenly working on a networks data set covering over fifty villages in the Gambia, but this won't be available anytime soon and is also not comparable to data collected in other countries.Most often used in existing research is the network data by De Weerd and Dercon (http://edi-europe.com/docs/JDE_deweerdtdercon.pdf) which is from a single village in TZ.Data that has comparable networks survey data on the micro level from several different country does not exists.Maybe if you describe somewhat more detailed what exactly you need, someone may suggest other options. Non-network survey data could proxy for some aspects of network characteristics. Or worldwide online/trade/misc data could be used, even though this would also not give you household-level networks.For example -but that really depends heavily on the context- you could use household- or family size as a proxy for network characteristics, such as average degree. This would be available from various sources.Maybe your best shot is to look at large scale surveys and figure out which questions of those are suitable in your context. I think the WVS doesn’t have a lot in terms of social ties. But from the DHS roster you could extract how many non-household members stayed overnight in the last night, which could already be a decent proxy for some form of social network, provided that you find variation in that. Maybe you could also look at how many people without blood-ties are currently staying in each household. A bid odd, but potentially useful is the number of people one had sexual intercourse with, which is also asked in some DHS questionnaires, but I guess that’s too far out of your theoretical framework."
Average temperature by country 1990-2012,"
I am looking for a dataset that provides me with one (or a few, e.g. summer and winter average day temperature) average temperature per year per country. I am aware that there are quite a few ways this could be calculated (and I can provide further details on what my preference would be), but any dataset that provides me with one (or a few) temperature datapoint per country per year would likely be useful.
(I would prefer each temperature to be an average over major cities or over the population, but a value for the capital or averaged over the area of the country would probably also work. The dataset should be fairly complete (200+ countries, all years 1990-2012). Preferred temperature would be Dry Bulb Temperature. I am aware of http://data.un.org/Explorer.aspx?d=CLINO , but using that would likely require looking up the GIS data for weather stations and cities in each country. Ideally I would like to avoid GIS and simply be able to look up temperatures based on country name.)
","['data-request', 'geospatial', 'weather']",
"Multiple snapshots of social network, showing people leaving","
Are there any available data sets for social networks, like facebook, where the data is longitudinal (multiple versions over time) and captures the leave (or any similar activity like inactivity, account deactivation, or account permanent deletion)?
","['data-request', 'social-media']",
Looking for shapefiles describing Katmai National Park in Alaska,"
As detailed as possible - including streams, lakes, rivers, trails, and elevation changes. 
",['geospatial'],
Spatial commodities data global,"
I'm looking for data on commodities (corn and potato). Tools such as USDA's cropscape are great but lack global cover.
I found this dataset, but it is for the year 2000 and not very recent.
Are you guys aware of any better datasets containing the location of commodity crops, such as corn and potato?
","['data-request', 'geospatial', 'food']",
Guide to open data for beginners,"
Is there a guide or an introduction of some sorts to open data, indicating to a beginner how and where he or she should go about trying to find interesting datasets?
","['data-request', 'data-portal']",
Coordinates of villages in The Gambia/Senegal,"
I am looking for sources of geo-referenced data on villages and cities (or all other things there are) in The Gambia (and Senegal if available). One issue with geocoding in rural West Africa is the varying spelling of village names.
I own a (possibly incomplete) list of some 2000 Gambian village names, I was able to acquire some 1000 coordinates from HERE maps, Google maps, and MapQuest, through the respective APIs. But I estimate that this is missing roughly halve of the villages in The Gambia. What is more. Some of these one thousand are rather bad/uncertain matches, so it would be good to compare with additional sources.
Are there any other sources, with a decent level of detail and fairly up-to-date?
Here is a list of villages that I was not able to find with any of the above sources. Since I know for sure where they are located I use those as a benchmark:

Kulukulel (district: Fulladu East): 13°17'47.1""N 14°08'29.3""W
Toubanding (district: Fulladu West): 13°28'03.7""N 14°41'09.6""W
Sami Kuta (district: Upper Niumi): 13°23'43.9""N 16°19'19.5""W

(I am aware that some of these  actually have labels with different spellings/entirely different names in google maps. However, this is so far of no help to me though, as these spellings mostly nowhere close to how the village names are usually spelled/pronounced) 
Clarification in response to some comments/answers: geonames for Gambia is in most cases rounded to minutes, which in the case of Gambia gives a grid in which places are as far as ~1.3kms, away from where they actually are. In the case of Gambian villages which are densely and rather uniformly distributed, this is not very helpful. If there are ways to obtain unrounded geonames data I'd be happy.
","['geospatial', 'geocoding', 'africa']",
Spanish Sentiment Dataset,"
I'm looking for a Spanish language corpus tagged with sentiment (just positive & negative are needed, though neutral might be helpful.) I could use a Twitter dataset, but I'd prefer to use something like the IMDB corpus (that's in English though) so it reflects longer documents better. Is there anything out there that's relevant to this?
","['data-request', 'machine-learning', 'nlp', 'sentiment-analysis']","(Example) Spanish Language Corpora:ESCOW14Project GutenbergAny of the wiki projects starting with ""es"" - https://dumps.wikimedia.org/backup-index.html
For example - https://dumps.wikimedia.org/eswiki/20150805/http://www.corpusdelespanol.org/Twitter API public stream with lang:es as stream filter - detailsAffective Word list for SpanishThe Spanish adaptation of ANEW (Affective Norms for English Words) is an adaption of the ANEW affective word list for the Spanish language.
  The wordlist is downloadable from:"
USA basement map or data available,"
I am looking for information about basement for each state or in USA. They can be either a map, dataset, or on the website.
i am looking for that to get an information about a local in the state of Colorado. My understanding is that each state has its own basement, for example, in California they do not have basement for all or some of the houses due to earthquakes, or like some states in the Midwest some or all ore none  of the houses have their basement because of tornadoes. Some states cannot build basement due to unstable soils under the surface.
I've google it but such as no luck...
","['data-request', 'geospatial']",
Guidelines on surveying email addresses in the public domain?,"
I've built a script to extract emails from scientific publication data that is in the public domain (http://www.ncbi.nlm.nih.gov/pubmed) with the aim of sending email surveys to these people.
Are there any guidelines or laws that I need to be aware of for these people to participate in the survey?
Edit: I'm based in the UK but the recipients can be based in any country
","['legal', 'email', 'survey']","Yes there are laws about spam: here's for the US, here are some links about Europe spam laws.I'm pretty sure that in France (not sure about other countries), unsolicited commercial emails are illegal if sent to a person BUT commercial prospection IS legal so if the email addresses are professional that would be OK.Anyway, in my opinion the ethic problem is not solicited or unsolicited, the problem is will the email be useful for the receiver? If I receive an email, even a survey, concerning a topic I'm interrested in, that's okay for me.Hope it answers your question. Not sure if it's the good place to ask though :)Cheers
Nicolas"
How many people ever lived having a certain profession?,"
Is there any data on how many 

politicians(including feudal lords)
clergy (priests, imams, monks ...)
scientists(whatever that may be called in ancient cultures)
...

have ever lived on earth? (or in the universe :)
","['historical', 'demographics']",
Resources to create CC0/ CC BY cartography?,"
Cartography and map-based mashups are often based on Google Maps/ Google Earth (all rights reserved) or Open StreetMap (ODbL/CC BY-SA), neither of which are compatible with publishing the results under CC BY (default license for open-access journals) or CC0.
Which resources exist that allow to create maps/ map tiles/ geoshapes/ mashups under CC0 or at least CC BY? 
The main use cases I have in mind are mapping
* disease outbreaks, floods or other disasters
* biodiversity
* scientific expeditions.
Since these may occur anywhere, it would be beneficial to be able to build an infrastructure using specific tools and services that can be applied to any location around the globe (perhaps also across historic times and geological ages), or even for other celestial objects.
",['geospatial'],
"Publishing location based data in Easting and Northing, Longitude and latitude, or Addresses?","
I am working on publishing a listing of shelters and hostels, I would like to expose my data to anyone who would like to use it. One of the things I would like to do is allow the shelters and hostels to be plotted on a map.
There are three methods of posting locational based data:
Addresses

This is the traditional street and Avenue system that the postage system uses.

Easting and Northing

These are (usually) used for horizontal and vertical from the a specified datum position. For example, a mountain close to where I live is located at 50° 52′ 10″ N, 115° 39′ 3″ W.

Longitude and Latitude

This is a common grid system that uses two numbers (a coordinate) to pinpoint a location. For example, the same mountain can be fount at 50.869444, -115.650833.

My thoughts so far
The addresses system good for projects in a city but if the location is away from a road (like some hike-to hostels) it does not work so well. My data is already in Easing/Northing, however with everyone using GPS and cell phones now it sounds like longitude and latitude may be more popular?
Question
What type of location system should I chose if I want as many parties as possible to use my data in their work? It's hard to know how the data could be used, but I suspect consumers of my data to be interested in travel, real estate, poverty and government.
","['geospatial', 'releasing-data', 'geocoding']","This is very problem-dependent, but if the most likely use of the data is for positions to be plotted on a map (rather than, for example, sending mail to those places) then the data should be given as positions, rather than street addresses. This way they are unambiguous, wheras addresses may change over time, and the locations that correspond to them may depend on what lookup tool is used to convert addresses to locations.If you're giving location data, then the most important thing is not the exact format that you give it in, but that it is clear what the format is. Coordinates should be accompanied by metadata explaining what the coordinate system is. For example,If using lat/lon, you should ideally note what geoid is referred to
(usually WGS84 these days, since that's what GPS uses, but best to
specify if you know).  If it's something more complicated (e.g. UTM
coordinates) then that needs to be clear and the appropriate metadata
given.   If vertical elevations are given, it's important to know
what datum is used (i.e. where is zero elevation).With regard to your specific dataset (and without knowing the details of the likely uses) I would recommend giving position data rather than address data, and (less importantly) expressing that in degrees rather than degrees / minutes / seconds, because in many cases it will be easier for software to parse."
"Automobile data including weight, engine output","
Is there an open data set of car metrics? I'm looking to combine these with other data such as accidents, thefts, etc.
I imagine that these types of data are readily available within auto insurance companies to calculate rates, and I was hoping an open data set exists out there.
I'd like to find the following fields for each car:

Manufacturer
Model
Country (at least Canada/USA)
Release year
Weight
Drive (FWD, RWD, AWD, 4WD)
number of doors
number of passengers
Engine displacement/cylinders
Engine output

",['data-request'],
Database for sovereign bond upgrades/downgrades,"
I am looking for a database of sovereign bond upgrades/downgrades by Moodys/Fitch/Standard & Poors, for as many countries as possible.
I would need:
date|country|rating before|rating after|outlook
","['data-request', 'finance']",
"What are the most unexpected, weird, crazy or funny open datasets available online?","
Basicaly everybody is used to usual data like GDP, population, administation budget. So I'm looking some original and unexpected open datasets.
",['data-request'],I could say that I have spent hours on datasets research and the most unexpected dataset I have found till now is the last words of every inmate executed since 1984 in Texas. You can find the portal with the data in the official page of Texas here:http://www.tdcj.state.tx.us/death_row/dr_executed_offenders.html
Where can I find some publicly available dataset for retail/grocery store companies?,"
I am looking for some publicly available dataset for retail/grocery store companies which (preferably) includes data about there stores, number of employees and operations. I tried to look around but couldn't find any dataset related to retail/grocery store companies. Does anyone know about such datasets that I can view and download(free or paid-any option)?
",['data-request'],
Where can I find some publicly available dataset for retail/grocery store companies?,"
I am looking for some publicly available dataset for retail/grocery store companies which (preferably) includes data about there stores, number of employees and operations. I tried to look around but couldn't find any dataset related to retail/grocery store companies. Does anyone know about such datasets that I can view and download(free or paid-any option)?
",['data-request'],
IQ scores from individuals and their siblings and/or twins,"
I'm looking for a data set that will allow students to make heritability calculations for IQ.
It would be nice if the dataset included data on whether siblings were raised apart as well as together, but that's not essential.
",['data-request'],
European crime data with spatial coordinates,"
I am looking for prostitution arrest and drug arrest data for a couple of major cities in Western Europe. So cities such as Paris, Rome, Rotterdam, Amsterdam, Berlin, etc. Ideally the data would have dates for each arrest, as well as latitude and longitude coordinates--or atleast some street address that I can geocode. The date range would be between for at least 1 year between 2010-2015.
I looked at the police department sites for different European city police stations, but in many cases I could not read the language to navigate the site. I have found similar data for US cities, such as Boston and San Diego. But I wanted some European data to compare.
","['data-request', 'geospatial', 'crime', 'europe']","london.gov has a crime dataset for 2014. It breaks down crime on a per month basis/number of incidents:
http://data.london.gov.uk/dataset/recorded-crime-summary-data-london-lsoa-level"
Extract labels from Wikidata entity,"
Is there a way to extract the labels of the statements (property and object) in Wikidata? I want to get all the information that there is here:https://www.wikidata.org/wiki/Q42, properties and objects with labels so both (wikidata.org/wiki/Property:P21, sex or gender) and (wikidata.org/wiki/Q6581097, male).
I've tried to do this using the wiki data toolkit, but I can't find a way to avoid doing multiple requests to the API (I'm now getting ids from the Q42 entities and then, for each of these, I send an API request to get the label.)
The problem is the same I've found in these two questions:
How to get the name of a Wikidata item
https://stackoverflow.com/questions/31266398/getting-readable-results-from-wikidata
There's a way to get all the information when I retrieve the data for the Q42 entity?
","['linked-data', 'wikidata']","You could do it with SPARQL:Try it.Perhaps the problem was that Wikidata supplies labels for entities in the wd: namespace only.In order to provide labels for properties in the wdt: namespace, one have to use the special predicate wikibase:directClaim, which connects the wd: namespace entity for the property to its wdt: namespace representation."
World Marine Regions & Subregions Polygons,"
I'm looking for a set of world marine regions & subregions to help augment some analyses I'm doing with the ASAM database. I found the following:

at http://fas.org/irp/world/para/docs/geol_geo.htm but I'm at a loss as to where the shapefiles are (and I did ""google-the-heck"" out of this so please post the google terms you used if that's how you ended up finding it).
",['geospatial'],
Series of integers to test sorting algorithms,"
That may sound trivial, but do any of you know where I could find a database of test cases for sorting algorithms? It's common to test sorting algorithms on corner cases or with datasets with specific patterns (sorted values, decreasing values, pipe organ pattern...). Note that I am interested in regular sorting, not in external sorting.
Where can I find an open database of integers series to test sorting algorithms?

Update: I guess that some of you might be interested in how I eventually solved the problem. I wrote functions to generate the data for me instead of relying of fixed data sets. The result is a bit specific to my project but here it is: https://github.com/Morwenn/cpp-sort/blob/develop/testsuite/distributions.h
","['data-request', 'computing']",
Is there a source for OTC Vitamin ingredients?,"
The FDA site doesn't have much on Over The Counter (OTC) vitamin ingredients/strengths. 
I know there are a few sources out there that charge quite a bit. 
I'm trying to match UPCs with their individual ingredients and strengths. 
Anyone know of a source?
","['products', 'barcodes']",
"Where is the original data set for the ""German tank problem""?","
I am looking for the original data set for: the ""https://en.wikipedia.org/wiki/German_tank_problem"" , but can't seem to find it.
Any suggestions on where it might be available from?
","['data-request', 'historical']",
Should a Linked Data Platform (LDP) server answer to a request for a container that does not exist in the dataset?,"
I'm developing a partial implementation of the LDP specification and I have the following issue:
Suppose that my dataset contains book resources with URIs like: http://example.org/book/lord-of-the-rings. If I understand correctly, when a client makes a GET request to http://example.org/books/, the server should return a list of books in a LDP container. Does this mean that the dataset have to contain the triples describing this container, or does it have to happen automatically?
The container could look like this:
@prefix dcterms: <http://purl.org/dc/terms/>.
@prefix ldp: <http://www.w3.org/ns/ldp#>.

<http://example.org/books/>
   a ldp:BasicContainer;
   dcterms:title ""A container of books"";
   ldp:contains <http://example.org/book/lord-of-the-rings>,
                <http://example.org/book/don-quixote>,
                <http://example.org/book/moby-dick>.

","['linked-data', 'rdf']",
"Database of Japanese meibutsu, with locality and since when","
Almost any town in Japan has its own ""speciality food"" called meibutsu.
Is there a database of containing for each town its meibutsu(s)?

Ideally each item should also say since when the meibutsu has been produced in this city, as many meibutsu are actually recent inventions designed specifically to cash on passing travellers.
A picture would also be great.
Quantity produced and distributing brands would be wonderful.

Information can be in Japanese or any language.
","['data-request', 'food', 'japan']",
Get results for partial drug name searches,"
Currently I can get results for a generic drug name if I use a query like:
https://api.fda.gov/drug/label.json?search=generic_name:atorvastatin
But is there a way to get results back if the drug name is not completely typed out. If I search for ""atorvastat"", I get no results. It only returns a result if the drug name is typed out perfectly and completely.
",['openfda'],
data.gov Action API Parameters Seem to be Ignored,"
When I hit the ""package_search"" action API at data.gov, 26564 results are currently returned:
http://catalog.data.gov/api/3/action/package_search?q=fish

When I pass the ""rows"" parameter to limit the results, it seems to be ignored and I still get 26564 results returned:
http://catalog.data.gov/api/3/action/package_search?q=fish&rows=1

However, when I pass an unrecognized parameter, I get an error saying so. So, it's recognizing the ""rows"" parameter but seemingly not applying it.
Also, http://docs.ckan.org/en/latest/api/index.html says that the parameters should in fact be sent as a JSON payload. It provides an example using the ""HTTPie"" utility to pass the ""id"" parameter to the ""group_list"" action API:
http http://demo.ckan.org/api/3/action/group_list id=data-explorer

However, I get the same result whether I pass ""id=data-explorer"" or any ""id=(string of random characters)"". The same goes for making a proper request directly from Python, too.
What am I missing? This is really annoying.
Thanks.
","['data.gov', 'ckan']",
Raw Clinical Growth Charts height & weight data for age,"
I'm looking for height & weight data points, with associated age & sex.
This is the kind of raw data from which Web percentile calculators derive their calculations.

","['data-request', 'medical']",
How to use multiple wikipedia categories for Quick Intersection?,"
I'm using http://tools.wmflabs.org/quick-intersection/index.php to get a list of articles within categories but I have a list of over 35 categories and I'd like to use Quick Intersection to get the articles. Problem I have found, and perhaps I just don't know what I'm doing, but I can't seem to add multiple categories within the tool. 
Every time I try and add multiple categories separated by a new line I get some strange articles. Any advice? Thanks
",['wikipedia'],"If you're looking for union, CatScan 2 (http://tools.wmflabs.org/catscan2/catscan2.php) can do that. It also has quite a few more features, at the expense of being slower. For the examples you gave, you would something like http://tools.wmflabs.org/catscan2/catscan2.php?categories=A-League_players%0D%0AAllsvenskan_players&comb%5Bunion%5D=1."
Source of aggressively toned texts for machine learning,"
I was looking for a source where there would be an extended amount of texts with aggressive tone. It can be intertwined with non-aggressive texts, but it would be good if the ratio of aggressive texts to non-aggressive texts be no less then 1:5.
I was thinking about discussion forums which would be discussing the immigrants issue with contributors of lesser mind who would be very hateful and xenofobic. Or supporters of extreme political parties. 
The content being spoken about is not really important, the more diverse it would be the better.
In the past I was looking for a less specific sentiment like ""like/dislike"" something for which reviews of movies on IMDB were an ideal source and I had some good results. 
However it is very difficult to find a base of data with aggressive sentiment or at least some good internet sources from which the data could be gathered.
Do you have any ideas on how I could gather up such data?
","['data-request', 'language']",
Source of aggressively toned texts for machine learning,"
I was looking for a source where there would be an extended amount of texts with aggressive tone. It can be intertwined with non-aggressive texts, but it would be good if the ratio of aggressive texts to non-aggressive texts be no less then 1:5.
I was thinking about discussion forums which would be discussing the immigrants issue with contributors of lesser mind who would be very hateful and xenofobic. Or supporters of extreme political parties. 
The content being spoken about is not really important, the more diverse it would be the better.
In the past I was looking for a less specific sentiment like ""like/dislike"" something for which reviews of movies on IMDB were an ideal source and I had some good results. 
However it is very difficult to find a base of data with aggressive sentiment or at least some good internet sources from which the data could be gathered.
Do you have any ideas on how I could gather up such data?
","['data-request', 'language']",
Predictive Maintenance Data,"
I'm eager to try out some more with Microsoft Azure Machine Learning and would like to find a data set to make a use case concerning predictive manufacturing. Microsoft already offers a data set (semi conductor) for a use case like this, but I would like to try out some more. Does anybody of you know where I can find another data set similar to the one provided by MS?
Basically I'm looking for a bunch of sensor data in a manufacturing process and a classification whether it came to a failure or not. I have tried the UCI Machine Learning datasets already (it only features the semiconductor dataset that I have already used) and researched the Kaggle repositories as well. 
","['data-request', 'machine-learning']",
Dataset for US Boat Launches (both Fresh and Salt)?,"
Does anyone know where to find a dataset for US Boat Launches (both Fresh and Salt)? I have found several statewide results, but nothing on a national level. Does anyone know if this information is aggregated in a single location anywhere either as an open or paid dataset?
","['data-request', 'usa']",
Annual Mean temperature of Africa countries for past 50 years? [duplicate],"







This question already has an answer here:
                                
                            




How can I get temperature data for each Country (Annual)

                                (1 answer)
                            

Closed 7 years ago.



I'am trying to find annual mean temperature data for all countries in Africa for past 50 years.
The data should not be mean of the entire 20 years, but should be yearly mean. Can somebody please redirect me to a good source of data?
This is for research work.
","['data-request', 'africa']",
How can I find annual temperature data for Chile?,"
How can I find annual average temperatures for Chile?
Not monthly but annually. And not changes to average.
","['data-request', 'chile']",
De-identified longitudinal K-12 student letter grade data,"
Does anyone know of any de-identified longitudinal student-level letter grade data for a K-12 school system?
I'm aware that this data would be sensitive--I'm not interested in demographics or anything like that, just trying to model individual teacher effects on student performance.  As such, an ideal dataset would include students graded over multiple years with anonymized IDs, where each student letter grade is associated with an (anonymized) teacher ID.
","['data-request', 'education']",
"public data on vehicle speed/acceleration for a route, for multiple trips","
Is there a public database containing vehicle speed or vehicle acceleration with location info like GPS, in a particular route, (for one trip or multiple trips)?

latitude-x, longitude-x, speed1 or acceleration1
latitude-y, longitude-y, speed2 or acceleration2 etc...

I tried to find data uploaded from some ""trip recorder"" device or car dash-camera recorded data, but I don't find any such data.
","['data-request', 'transportation', 'traffic']",
Where can I find a CSV file of countries and their cities?,"
where can I find the countries and their cities  as SQL insert statement or csv file?
",['data-request'],"I made this CSV dataset last year. It has the cities, administrative divisions and populated places. Below is an excerpt from my documentation:http://www.opengeocode.org/download.php#citiesCities of the WorldThis dataset consists of the most comprehensive list of cities, administrative divisions and other populated places in the world. The data is compiled from:
    United States: United States Geological Survey (USGS) Geographic Names Information Services (GNIS).
    Other Countries: National Geospatial Intelligence Agency (NGA) Geographic Name Server (GNS).
The NGA/GNS database has been maintained by the NGA since 1994 and contains over 7 million geographic features and populated places records on all countries of the world. For non-US, geographic names are provided both in the local language and local script, as well as romanized and/or English forms of the name.
Many of the non-US entries in the dataset have multiple records, one per language (e.g., English and Spanish) or script (e.g, Arabic and Latin) that the feature (e.g., city) name is specified in. Multiple records for the same feature are identified by the same NGA GNS Unique Feature Identifier (UFI).* "
Where can I find registered company data through web services,"
I am looking to find accurate company search information for companies registered within India and USA (same as companies House API service provided for UK ). 
Any ideas?
","['data-request', 'usa', 'data.gov', 'companies', 'india']",
"Free, Complete Soccer Database? [duplicate]","







This question already has answers here:
                                
                            




Are there any open datasets for soccer statistics?

                                (19 answers)
                            

Closed 8 years ago.



I'm making an application in C # that currently uses the following.
They are very basic and do not even have tables form, wide, half-time and in addition there are very few championships.
I also tried to contact the admin of the site 5 times but she never answered.
I found these API: https://statsfc.com/ but are not free, I would like to know if there is a service that currently offers the most comprehensive database free kick.
",['data-request'],
Real-time position of artificial satellites,"
Is there a database containing the currently known course of most artificial satellites?
For instance, satellite X is travelling at speed n and at time T it will be at point P.
For all countries/owners.
Bonus if it includes space debris and natural objects that enter the vicinity of Earth.
If precise enough it could be used to prevent collisions.
","['data-request', 'geospatial', 'telecom', 'space']",
Database of chess games,"
I am looking for a database of chess games. This might be historical chess games, modern games, or even amateur chess games. Intended to use for academic research and machine learning.
",['data-request'],
Historical dataset of prices of valuable metals,"
I am looking for a dataset that includes the historical price of gold, silver, platinum, copper and other valuable metals.
To be precise I am looking for a dataset that consists of more that 10 variables. It is important to me that data are autocorrelated and there exists a time component in it. 
This is a self study question and I would be happy if you introduce me any other dataset with described property.
",['time-series'],
"Traffic signals, stop lights, red lights","
Is there a database of traffic signals latitude and longitude?
It would be neat to write a game that kept track of when you were stopped at these waypoints.
","['data-request', 'traffic']",
What percentage of all US children 3 years of age or under who have access to an iPad share that iPad with a similar-aged sibling?,"
I'm building a children's app and looking for some quantitative data that will tell me how safely I can assume that only one child is using my app.
","['data-request', 'usa', 'demographics']",
Aircraft models,"
Where can I find an overview of as many aircraft models as possible, preferably commercial passenger and cargo aircrafts?
I'm interested in this data, or as much data as possible:

Model name (ex: Boeing 747-400)
Manufactured from/to
Possible seating/class configurations
Cruising speed and max speed
Fuel capacity
Fuel consumption per ... (any unit)
Minimum takeoff distance
Minimum landing distance

Etc.
Thanks in advance!
","['data-request', 'transportation']","Being unable to find the data I requested myself, I created a Google Docs Spreadsheet for anyone to view which holds most of the data I'm interested in for a ""handful"" of planes. If you are interested in adding to the spreadsheet, or help me keep the data updated, feel free to contact me.It currently contains about 150 items, with the following properties:"
Rugby Union data,"
Does anyone know of any open rugby union datasets?
Looking to doing some data visualisations and I'm a rugby fan.  I know that there has been a big increase of the use of rugby data metrics within the game but I can't find any data that is available to consume.
","['data-request', 'sports']","Statsguru is the rugby statistics database behind ESPN's scrum.com's.Statsguru looks to be the most detailed (matches from 1871), however I'm not sure if they offer bulk download, or if you'll have to scrape it.
http://stats.espnscrum.com/statsguru/rugby/stats/index.html RugbyStats.com has stats, but only shows the latest 200 entries, so very recent matches; again, not sure if there's bulk available (seriously doubt it), but you can scrape here too:
http://www.rugbydata.com/ StatBunker's Rugby Stats has data going back at least to the 1990s; also not sure about bulk/primed for scraping.
http://rugby.statbunker.com/ Pick and Go looks solid; stats from every international match beginning in 1871. After searching from start date 1871-01-01 to the year 2015, a table is returned that holds all of that juicy data. So while there's no bulk download, this dataset is the largest (of this list), so scraping it is ideal. For what its worth, this dataset was created for data/statistics consumption.
http://www.lassen.co.nz/pickandgo.php"
Where can I download 'Daylight Saving Time' for all regions in the world for specific year?,"
Where can I download 'Daylight Saving Time' for all regions in the world for specific year like 2015?
timeanddate.com provides it but it's not free.
This is a sample data provided by timeanddate.com
<?xml version=""1.0"" encoding=""UTF-8""?>
<data version=""2"">
  <dstlist>
    <dstentry>
      <region>
        <country id=""al"">Republic of Albania</country>
        <desc>All locations</desc>
        <biggestplace>Tirana</biggestplace>
        <locations>
          <location id=""284"" name=""Tirana""/>
        </locations>
      </region>
      <stdtimezone offset=""+01:00"">
        <zoneabb>CET</zoneabb>
        <zonename>Central European Time</zonename>
        <zoneoffset>3600</zoneoffset>
        <zonedst>0</zonedst>
        <zonetotaloffset>3600</zonetotaloffset>
      </stdtimezone>
      <dsttimezone offset=""+02:00"">
        <zoneabb>CEST</zoneabb>
        <zonename>Central European Summer Time</zonename>
        <zoneoffset>3600</zoneoffset>
        <zonedst>3600</zonedst>
        <zonetotaloffset>7200</zonetotaloffset>
      </dsttimezone>
      <dststart>2011-03-27</dststart>
      <dstend>2011-10-30</dstend>
    </dstentry>
  </dstlist>
</data>

As you can see, we have
  <dststart>2011-03-27</dststart>
  <dstend>2011-10-30</dstend>

Which shows start and end time of daylight saving for 2011.
",['data-request'],"The Internet Assigned Numbers Authority maintains a database of time zones. For countries/localities that have daylight savings, they have documented the rules.The database is here: http://www.iana.org/time-zonesIATA's TZ coordinator also has a github repository with this information: https://github.com/eggert/tz"
Offensive words - English and Spanish,"
Have a system generating four letter code and in testing just got up to AA-BJ ... and the BJ got me thinking.
In a while the one after AR-SD could cause offence in the UK!
Does anyone know of a list of swear words/unacceptable words anywhere? Have been looking for 20 mins without any joy.
If not will set up a little project as a resource.
","['data-request', 'language', 'nlp', 'dictionary']","Here's a list of all the offensive words banned from Google's ""What Do You Love?"" site:
https://gist.github.com/jamiew/1112488 Wiktionary has a pretty thorough list of English Euphemisms:
https://en.wiktionary.org/wiki/Category:English_euphemisms Wiktionary also has a (seemingly) scarce list of Spanish Euphemisms:
https://en.wiktionary.org/wiki/Category:Spanish_euphemismsYou touched on this, but its important to clarify that certain English words are/aren't offensive, depending on where you are. "
UK Postcode Outcode Border Data Isle of Man and Northern Ireland,"
I am aware of this as a great source for UK postcode outcode border data as KML. Unfortunately, uk postcode outcode border data for the Isle of Man (IM -> IM1, IM2 ...) and Northern Ireland (BT -> BT1, BT2 ...) are missing.
Is anyone ware of any other free data sources of UK postcode outcode border data - ideally as KML?
","['data-request', 'geospatial', 'uk']",
Full UN Comtrade Database,"
UN Comtrade database, the major source of bilateral trade data online, has a free query tool:

http://comtrade.un.org/data/

But it has limits on ""query complexity"", which makes bulk downloads burdensome.
Does anyone have this entire database as a single file to make panel analysis easier?
","['data-request', 'economics', 'trade']","You can query the entire database through the legacy interface. BUT, it still restricts the download to max of 50,000 records. You will need to breakup your queries to get what you wanthttp://comtrade.un.org/db/dqBasicQuery.aspxThis shows the contact info if you want to get it directly from them. Note, I queried for the entire database:"
Time Series Regression and Correlated Residuals Dataset,"
Can somebody please introduce me to a time series regression dataset that has many variables and data point?
In a nutshell, I have a time series regression with auto correlated residuals.
Note that I can artificially simulate a dataset. Then I need a real dataset. For sure there are many datasets that this model works well on them but I cannot find anything at the mean time.I  also have checked this page link but no progress. I would be thankful if somebody introduce me a dataset and probably associate paper. 
","['data-request', 'time-series']",
Local Area Unemployment - Month-County level since 2007,"
I am trying to download month-county level unemployment data from the bls's LAU, but I can't find data extending earlier than the ""latest 14 months."" This data set is exactly what I want EXCEPT that it does not extend far enough into the past. If that data extended to at least 2007, I would be done. I know the data is available, because I can download it county by county from the BLS multi-screen-data-search tool. 
Where can I download the archives of monthly-county level LAU data?
",['data-request'],"If you are hoping to use not seasonally adjusted monthly predictions of estimated county unemployment rates, I would suggest keeping in mind some of the changes to county borders that have taken place since 2007. For instance, there has been A LOT of changes to ""county"" borders in Alaska since 2007; Colorado, has had a major county border change; and Virginia has had one county wholly incorporate another county.That being said, this directory has what you are looking for. Be sure to read all of the smaller sized files that fully explain the meaning of the data."
Where can find a comprehensive list of all the Computer Science courses in California on CBEDS?,"
I'm looking for a comprehensive list of all the Computer Science courses in CA on CBEDS with the following course codes: 

2451  Computer Programming
2453  Computer Science
2465  IB Computer Science
2470  AP Computer Science A
2471  AP Computer Science AB
4619  Computer Programming for Solving Applied Problems 
4634  Exploring Computer Science

And maybe:

2454  Computer lab
2455  Web design
2458  Other Computer Education

","['data-request', 'education']",
Datasets: Is there any public data-set for FAQ (Frequently asked questions) in different domains?,"
My thesis is about Analysis and Auto generation of FAQ in different domains. For conducting experiments, I need high volume of FAQs. That's the reason I am looking for a publicly available data-set containing FAQs in various domain (or even one specific domain).
","['machine-learning', 'web-crawling', 'nlp']",There are (among others)
Where can I get a list of ATM identifiers that I can map to Geographic Location?,"
Most bank statements (at least mine here in the UK) contain coded information for cash withdrawls such as:
CASH RB SCOT JAN11 TESCO STREAT@08:56
CASH SAINSBY JUN23 STREATHAM C @10:46

I'm fairly sure this can be broken down into the following tuple (tran_type, operator, date, location, @time)
What I'd like to do is translate from (operator,location) to GPS coordinates, a postcode, or some other geographic identifier.
Is anyone aware of where I might find such an information source? Is it commercial, or open-source?
N.B. Imported from Data Science
",['data-request'],
Where can I find data on method of travel to train stations?,"
For the UK or international. I am interested in studying how people's method of travel to/from a train station varies with station location characteristics. 
",['data-request'],
How do we get Vets 100 Compliance Documentation [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 7 years ago.







                        Improve this question
                    



We are pursing a VA construction project and one of the required pieces of information is Vets 100 Compliance documentation.  How do we go about getting said documentation ?
",['usa'],
How do you get access to large amount of data for your project?,"
I have a question and Googling doesn't really give me a concrete answer so I'm hoping someone on here could explain this to me. I have an idea for an app/website and it needs access to a large database. If we use plants as an example, my app would need access to plant names, color, where it is found, how to treat it, etc., etc...
My question is when developing an app such as this, how would you get all the data about the plants into a database that you have access to (or better, my own database)? I read that there are companies that already have this information that others can use, but I also read that it is a security risk if a company was to let you have access to their data (which is obviously true). I'm just curious about how startup companies get all this data into their database without having to manually type all of the information about each plant because there are tons and tons of them.
If someone could please explain to me how this works I would greatly appreciate it. (I taught myself SQL/MySQL/Java/HTML/CSS/C#/C++ and I don't really have a mentor/instructor to ask this question). If I wasn't concrete enough in my question, please let me know and I'll try to change it.
","['data-request', 'releasing-data']","There is not, as yet, a comprehensive and central resource for finding datasets. Many datasets are available for free (1); access to other datasets (or databases) may be purchased (2); and still more data can be collected by you (3).In my experience, it is unlikely that you will be granted direct access to someone else's database. More likely is that they will use an API, where you can access specific pieces of data from your own program. If you need a lot of data, you can purchase it, but often starting a larger project can be done with creative uses of data that is available for free."
Any databases with this data?,"
Has anybody seen a medical data set with:

 clinical data (patient's age, gender, prior history, and stuff like that) 
 biomarkers (blood pressure, blood oxygenation, etc.) 
 genetic data (preferably gene expression or miRNA data) 
 imaging data (not necessary, but preferred) 
 and most importantly information about treatment and how the patient changed as a result of the treatment.  

For example, I want to see a specific patient's gene expression data, then see that they went through ""Radiation Therapy"", then see the new gene expression levels afterwards.
What disease this is for or the completeness of the data doesn't concern me (i.e I'd be fine with having imaging data for just a couple of patients). I'm looking into applying some graph theory state-based algorithms to this data in order to create a model that determines which treatment to use for a specific patient.
","['data-request', 'medical', 'biology']",
Financial text data/corpora,"
I'll be delving into text mining applications for my master thesis and I need data for it. Ideally, I would need a corpora of texts/news articles from some single (or multiple) credible and authoritative source covering financial markets/economy and the like, spanning a time period as long as possible.
It turns out that there is data somewhat what I'm looking for: the Wall Street Journal corpus or Reuters corpus. The problem is that these datasets have many texts for each day, but spanning only few years time.
For my purposes, I would be more interested to have only a few texts/news articles for each day/workday but the whole corpora spanning a decade or more.
Does anyone know of datasets/corporas that would suit my requirements?Any other possibilities/ideas to construct one such dataset using open resources?
","['data-request', 'releasing-data', 'finance']","Your school's library might have access to databases of newspaper and magazine archives, some going back decades. If you're in a large city, your public library might also have those. The New York Times is one of the most common, but some databases, like ProQuest, have many different archived titles. To get the articles over decades, you may need to download more than you need and apply some criteria to select only a few per day. The criteria, of course, would depend on your project.  "
Database of programming terms,"
I want to find a terminology database with programming terms , for example:

Front-end
UI/UX
ruby
RoR
HTML 5
HTML

Any idea ?
","['data-request', 'programming', 'english']",
Is there an API for searching the US Copyright database?,"
I was pointed to this StackExchange from Twitter --  I'm wondering if there's any kind of stable/published API for accessing the Copyright data exposed over here.
As it is, it's not incredibly difficult to grab with curl or parse with beautifulsoup, but it's not clear if there's a TOS for searching, or if the site is friendly to bots.
Thanks for any info you can provide!
",['api'],
What should I think about when making JSON data into JSON-LD?,"
I've added a little more of my work to show how I'm thinking
I hope this question isn't too broad. I'm thinking through a number of things and thought I'd try to put a ""basic"" question down here.
I have some data for a game I play with some friends online. I have a very simple php page which spits out some data from a database that looks like this: 
[
{
    ""Name"": ""David Alger"",
    ""Id"": ""1"",
    ""Username"": ""Dave"",
    ""Colour"": ""green""
},
{
    ""Name"": ""John Smith"",
    ""Id"": ""2"",
    ""Username"": ""JohnS"",
    ""Colour"": ""blue""
    }
]

It's simply the player info, with a local ID, a username and a colour used to show the player in the game (it's actually just used as a colour in HTML).
Since I've been looking at JSON-LD I began to think about making this JSON data into JSON-LD. 
My question then becomes: 
1) Is it worth making this data (or data like it) into JSON-LD just ""in case we want to open it up one day""? Or would that be, typically, a waste of energy?
2) How would I make this JSON-LD? What makes sense to ""link"" and how would that look?
I've been playing a little with ideas like allowing individual 'players' to be returned rather than all coming at once, then each getting a URI for an ID. (Can this be a simple url like example.com/player?id=1 or does it have to be more as I have shown?)
I've also looked at:
 - using the idea of context for a type like person. 
 - using ""sameAs"", but it's unclear if that will automatically 'work' in this format?
 - trying to specify what items like ""colour"" are, by giving it a context.
{  
  ""@context"": {        
    ""name"": ""http://schema.org/name"",
    ""Colour"": ""http://dbpedia.org/ontology/Colour""
  },
  ""@type"": ""http://schema.org/Person"",     
  ""@Id"": ""http://example.com/player/1"",
  ""sameAs"" : ""https://www.facebook.com/DaveAlger"",
  ""Id"": 1,
  ""name"": ""David Alger"",
  ""Username"": ""Dave"",  
  ""Colour"": ""green""    
}

It feels rather like I'm blundering around in the dark. So any help is appreciated.
","['linked-data', 'json']",
Cloud providers performance dataset,"
I need to perform some machine learning algorithms on a data set that contains cloud providers' performance. I need some of the following information :

availability,
input/output per second,
max restore time,
processing time,
latency with internal compute resource

I'm already simulating this data, but I need data of real cloud providers and for some users in long time. Few numbers that show the average of those metrics won't do. I need a detailed and large data set. Is there a chance that any company provides such data? 
","['data-request', 'business']",
"Data on alcohol usage, addictions, disease in Africa","
Im looking for an open data set on various alcohol usage statistics for Africa. Preferably the data would be at a subnational/regional or even micro level, such as from surveys. I haven't seen anything from the typical sources such as the world bank though. Any thoughts?
","['data-request', 'medical', 'africa']",usaid's demographic and health surveys collect alcohol consumption in some surveys.  you could start working with the microdata herehttp://www.asdfree.com/search/label/demographic%20and%20health%20surveys%20%28dhs%29
Mailing list datasets,"
Related to this question:

Obtaining personal mail corpus

I'm looking for a list of archived public mailing lists from diverse communities and in diverse languages.
For example, a list would look like this:
English

www.fake-link.com, Debian Linux
www.fake-link.com, Bird Watching group 

German

www.fake-link.de, Fans of Berlin
www.fake-link.de, Photography club

and so on (und so weiter)
One way would be to find these mailing lists, and to create a list of them, would be to use clever google searches for things like Pipermail, and other mailing list software
https://mail.python.org/pipermail/chicago/

A great structure would be .mbox, but it's not necessary.
","['data-request', 'language', 'email']","It's not a ""diverse"" community, but here are some lists of mailing lists from tech communities.https://lists.w3.org/https://lists.wikimedia.org/mailman/listinfohttps://commons.apache.org/mail-lists.htmlEspecially with the Wikimedia lists, there would be multiple written languages."
Margin of software resellers,"
I am looking for data about the typical margins taken by software resellers.
A software reseller takes a packaged software and sells them to their clients. Additional installation/integration services are typically additional fees.
The margin often comes with some restrictions, for instance to a particular geographical zone. It can be zero in some cases.
Margins are usually confidential, so any data would probably be leaked, or old/declassified.
","['data-request', 'business', 'software', 'leak']",
How to demonstrate that a document cited by law must be also open access?,"
The ""Principle of Access to Information"" (PAI) expressed in the legislation of many countries — usually countries with some ""Access to Information Act"" or freedom of information laws —, apply to any law document or ""obligation rule records"", stated by the State. In some countries the obligation of law-publicity and no-payment for information is reinforced by the  Ignorantia juris non excusat.
The question here is

How to use PAI for (legally) demonstrate that any other norm or document, citaed by a law document, must be submited also to the PAI?

This situation is similar to the ""contamination by use"" of a share-alike licenced document (ex. CC by-sa), but here the mechanism is ""contamination by citation"".

Notes and examples:
This is a question for use with any democratic country where we can start with the hypothesis that  “country's law has no copyright”. So, the question is: how to (!?) convince citizens, the government and the court that ""any document cited by law also has no copyright""?
Examples where the problem was recognized by court:

in the Brazil, before 2004, some construction process law was obligating the law-reader to read (cited) payed technical standards. After 2004 a juridical decision made free these standards.

coherent use of postcodes: many laws and rules of countries (any, like Brazil, Croatia, Finland, or Uruguay) obligate citizens to use postcodes, and cite explicitly the postcode standards in law.   Finland and Uruguay are countries where obligation is coherent with freedom of access (to postcode databases).


Example where the problem (of no oficial answering of this question) exist:

coherent use of postcodes: ... explanation above...   Finland and Uruguay are coherent ... But Brazil and Croatia are not. In Brazil the postcodes are protected by Authors' rights, but is a country with strong Access to Information Acts, etc. so is possible to create opennes/coherence by using  some PAI principle.

",['legal'],
Where can I find data about released product models? (e.g. Computers),"
I am searching for a dataset containing multivariate product information. For example about notebooks with data as price, color, size, cpu speed, ram, hard drive capacity, number of usb ports, CD slot, etc. - even better if the set says where I am able to but it for which price. The focus however is on the product attributes. It could be completely different products as well (e.g. shoes), but I guess technical product would have the greatest number of quantifiable features.
I looked at the suggestions from Where can I find data from released computer models? but the links lead to 404s or the data is really old.
","['data-request', 'products']",
Paper sludge production / recycling,"
I'm interested in any dataset with yearly production (generation) of paper sludges, hopefully by country (even approximate figures would be ok). 
Big pluses:

Dollar (or Euro) values for disposing it
Humidity and/or calorific value
Recycled tons
Wether the source is tissue or standard paper

",['data-request'],
"For natives of each language, most common second language and proportion of people fluent in it","
I am trying to prioritize what languages my software should be translated to. Regardless of other factors, I want to first look at how many people are native speakers of each language, example:
Punjabi: 102 million
Wu: 80 million

PROBLEM: Most Wu speakers also speak Mandarin fluently, so translation is not such a priority. I suspect many Punjabi speakers are also fluent in Urdu, but I am not sure what proportion. I need to know that proportion, so that I can for instance prioritize Punjabi over Wu.
QUESTION: For each language: What is the second language of most of the speakers? What proportion of the group can be considered fluent in this second language?
Example (made up):
Punjabi: Urdu, 50%
Wu: Mandarin, 98%
German: English, 60%
English: Spanish, 20%
[...]

""Fluent"" means being able to normally use a full-featured auctions mobile app in this language, or something similar of that level.
Context: While usually software localisation is prioritised more with regard to market considerations than with regard to actual numbers of speakers on Earth, my case is different. The software is open source, my only goal is education, I don't care about the users' per capita GDP. The software is designed for offline use, and runs on old/cheap phones, so network connectivity and technological advancement is not really an issue, at least not an issue that requires twisting the question.
","['data-request', 'language']",
How should US SSN be anonimized?,"
I have just gotten access to a US government dataset. It is not open, but could eventually be made open. The dataset includes hashed US SSNs. It looks like they used some general hashing function that is causing collisions. The collisions are already a problem in the relatively small version of the dataset I have now. Once the full version is pulled, the collisions will be even worse. How should one anonimized a US SSN to avoid collisions while still protecting the private information?
","['usa', 'best-practice', 'ethics']",
NY Times full weekly bestseller lists,"
Are there any open data compilations of NYT weekly bestseller lists? Other U.S.-centered bestseller lists would also be acceptable.
","['data-request', 'usa', 'books']","""With the Books API, you can retrieve New York Times book reviews and get data from all best-seller lists. There are two request types within the API: Best Sellers and Book Reviews."""
Movie Script Database,"
I'm looking for a database of movie scripts to use to train a ChatterBot application.
I saw this article that mentioned that a database of movie scripts was used to train the program that generated a selection of responses.
(http://blogs.wsj.com/digits/2015/06/26/artificial-intelligence-machine-gets-testy-with-its-programmers/) It would be awesome if this was an open database somewhere.
Alternately, does anyone know if there are any similar data sets that are available that could be used. I imagine dialog scripts from plays would work equally as well?
","['data-request', 'film', 'ai']","Try these screenplay datasets:But, perhaps, you may use subtitles to train only talks:"
Booking historical data,"
I am looking forward for any kind of booking historical data:

Plane tickets
Hotel
Other

What I need to test on is:

Prices
Bookings
Other booking relevant information

Best Regards,
N
","['data-request', 'prices']",
Cities with open geotagged Twitter data or Foursquare checkin data?,"
I'm doing a research project on population dynamics and would love to find a dataset of Foursquare checkins or geotagged tweets within a reasonably large time period (one month or more, ideally not during the winter) in a major city (New York, San Francisco, Boston, etc.). Does anyone know of an open dataset, perhaps originally collected for research purposes, that includes this data?
","['data-request', 'geospatial', 'social-media']",
Disease and Symptoms Hierarchy,"
I have a huge list of symptoms (1 million rows+ ). I would like to reduce the data by grouping the symptoms. For example, lower abdominal pain and upper abdominal pain are in the ""abdominal pain"" category. Is there any free API or downloadable database available to refer to the hierarchy of diseases and symptoms for grouping?
","['data-request', 'openfda', 'medical', 'disease']",
Filtering and Searching Data Using Department of Labor Quarry API (v2),"
I am attempting to query the OSHA Inspection data from the DOL Quarry API as shown at http://developer.dol.gov/health-and-safety/dol-osha-enforcement/#osha_inspection. I have found API documentation at http://developer.dol.gov/accessing-the-apis-using-http-requests/ for data.dol.gov that indicates you can search by dates, however I would like to search by other fields like site_state or naics_code. I tried simply appending something like site_state/ct to my request and it did not filter or search. Is there anyway to do this or documentation I am missing?
","['api', 'labor']","Please see github.com/USDepartmentofLabor/DOLAPI/issues/12 where we're tracking this issue. We don't yet support WHERE clauses in the request, but we're considering it and tracking that feature request in GitHub."
Problem with date format,"
I'm getting some problems with the format dates on openfda. Is there an existing method to format or process to show on a chart?
",['openfda'],
Where can I find a part-of-speech corpus free for commercial use?,"
I'm looking to teach myself more about NLP. I started with NLTK and I see that it has potential to eventually become something I could get paid for.
From there, my journey continued to reading this blog post by Matthew Honnibal. So I'm interested in writing my own NLP algorithms.
The main issue I have is with licenses, specifically with training data. I don't want to ship software to clients that have any licensing issues.
I've narrowed my search down to three: the Brown corpus (license), the CoNLL2000 corpus and the portion of the Penn Treebank that NLTK provides on their downloads page. I understand that each of these downloads has a small snippet about licenses, but it doesn't describe fully what commercial use cases it supports. They only briefly describe that it's free for academic or learning purposes.
Perhaps it's a non-issue?
If I extract statistics from these words, is that a derivative work also under the same copyright? Perhaps I can train my new tagger on the results of an older tagger?
I know that the CoNLL2000 corpus is derived from the Brill tagger. Since the Brill tagger is in the public domain, does that necessarily mean that all of the data it produces is also public domain?
","['data-request', 'language', 'licensing', 'nlp']",
How to resolve type not declared errors in V3 Healthcare Finder API Schema?,"
I am a developer, wanted to use the API for one of our website builded in C#.
I tried to convert the schema to C# classes. But it seems that, there are too many ""type not declared"" error on https://finder.healthcare.gov/api/finder_api_v3.0.xsd
Please suggest.
",['healthcare-finder-api'],
open database photos of human faces with age,"
Is there an open database with photos of the human face, with related data such as age, sex or ethnicity, but I am most interested in age. 
","['data-request', 'images', 'faces']",
"Is there a taxonomy based on concepts of ""fiscal"" and ""utility"" data?","
Is there are a theory, division, classification or taxonomy schema for open data? With classes like ""fiscal"" and ""utility"".
Explaining and illustrating
Perhaps ""utility""  (or ""public utility"" or day by day util data) is not the correct term... I will try to explain: public utility open data are the input for innovation and improving the quality, of private and public services. Some examples show better the concept:

Postcodes: all people need, all the time we need the same database... So, it is util for us.  The open data is the list of all postcodes of a country.
Data Packaged Core Datasets: each dataset (of this project) is a set of util data.
Words: all people need...  The open data is the list of all words, or any other more complex structure like a dictionary.
Digital street lines: OSM has a repo with ""very util data"" (!).

""Fiscal data"" perhaps, also, is not the correct term (perhaps audit is a better name), but some examples show the concept:

Data of the IUCN Red List
Data of spending reports (ex. UK)
Data of the Corruption Perceptions Index
Data from Wikileaks

Of course, a dataset can be both, ""util"" and ""fiscal"", so in a classification schema they are like ""root facets"".

notes
Historically OpenData activism started as ""fiscal"" (with activists working in data scraping for audit the data)... Today Open Data community also is investing in cleansing, organize and standardize util data, for open collective/collaborative use.
",['metadata'],
# of people convicted of a felony within a census tract? (USA),"
I am trying to find any of the following counted by some small geographical unit like census tract or block:
--number of arrests per year (maybe by crime type?) within each area
--number of convicted felons living within each area
I don't believe such data is collected through the American Community Survey. I could probably get arrest records by police precinct, but # of felons who have either completed their sentence or are on probation is what I'm really looking for. Any advice? 
Note that this is for the USA. Thank you!
",['crime'],"For your first request, I would guess that the FBI's Crime Statistics would be your best source:
https://www.fbi.gov/stats-services/crimestats
lots of great data, but not necessarily neatly divided into geographical units.As far as convicted felons who have completed their sentences, I would guess that any data you can get on this topic would be extremely suspect, as once they have completed their sentences, they are not required to tell anyone about their status, and have a strong incentive to not do so.One exception to this would be sex offenders, who are required to register with local law enforcement. You can access some of that data via the National Sex Offender Public Website:
http://www.nsopw.gov/
You should definitely look at the TOS for that site before digging in too deeply, as there are restrictions on how the data can be used."
Historical weather data in France (Sceaux),"
I am looking for historical weather data (mostly temperature and sunshine hours) for France (specifically the City of Sceaux).
I found meteofrance who offer free  historical weather data per day. The only way that I found to download the data is one file per day with all stations. What I would be looking for is a download of a single file that contains information for multiple days at the same station. So to say historical data per station, not per day. Does meteofrance or a similar source offer something like this or should I use weatherunderground for this?
","['weather', 'france']",
How to get all tweets from a given Twitter #hashtag,"
Can anybody point me to steps how I can get all tweets from #databreach or any #hashtag on Twitter? 
The goal is to take all data and export to a file (can be unstructured, structured or semi-structured).
Bonus if usable with the Fabric plugin and Beautiful Soup.
","['data-request', 'social-media']","My experience has been that you cannot reliably get complete historical tweet data directly from the Twitter API. There are a couple of commercial services who offer exactly that type of service, though neither of them are well set up for one-time usage:
Gnip is owned by Twitter, and DataSift provides similar servicesOther (also commercial) services you might want to look at are Infinigon and Nexalogy. There may be others."
Problem displaying charts in clone of open.fda.gov,"
I have cloned the open.fda.gov repository and followed instructions to get the site running on my machine.  I've been meticulous to install all the ruby and nodejs dependencies, however when jekyll is serving my site, I am not able to see any of the charts. For example, http://localhost:4000/drug/event/ does not show the chart as is displayed on https://open.fda.gov/drug/event/ . 
How can I get my local site to display the charts?
",['openfda'],
Frequent Micro health care data,"
I need a dataset with some health outcome (like immunization rates or reported disease cases) that is both frequent (weekly or more frequent) and micro-geographic (zip code or finer). 
","['data-request', 'medical']",
Open database for JEL code crawling (using article names),"
I'm currently working on a project to create a database (for analysis later on) of 100 journals, and all the articles for these journals between 1969 and 2014. This of course results in over half a million articles. The most important parameters i need for these articles is the JEL code and the date(year) of publication. So far I have created a list of journals and used the crossref API to get an approximation of the number and names of articles they include.
Example is for the journal ""Econometrica"", the API query: http://search.crossref.org/?q=Econometrica&type=Journal+Article Returns 6200+ articles, each of them with full name and a DOI link. The problem is the DOI link does not always include the general information, however they often include the pdf version of the article, which in term of data crawling is not really efficient to scan through 500.000 articles for JEL code.
I was wondering if you know another database/API that might return the JEL and publication date by using the article name as query?
","['data-request', 'api', 'research', 'python']",
Available QR Code Prefixes,"
A customer asked me to make a QR code to hold an ean-13 barcode's data but it seems they don't want to change there hardware/software that their staff use. The customer asked:

Good Morning,
  and 'can then use the qr code instead of the bar code, but then you have to check if the program we use (zucchetti) and' able to read the codes during the qr behalf of a client in our cash carry,
  Now we have more or less than 1,000 items, the expiration date will vary depending on each arrival and lot of the goods, the qr code will have to be printed by us the bar code that we are using mainly and 'ill ean13 code, but on other products there are also other types of bar codes

Googling for this company and there products does not bring much useful info (not what I would call technical), So (also out off interest) I started to try to find out all the different data types (prefix:data) I can implement in a QR code so far I have only found (I think there may be more):
Plain text      Hello Stack Exchange!
Website URL     http://www.example.com/
E-mail Address  mailto:example@exmaple.com
Phone Numbers   tel:+00000000000
Text (SMS)      sms:9052091306
Geo Address     geo:43.838613,-79.330831,120
Contact Info    MECARD:N:Ben,Muircroft;ADR:PO Box 1, London, UK 90030;TEL:+000000000;EMAIL:me@example.com;;
Bitcoin Address bitcoin:1Exampleytfu545yfu98TUYGT87t9787uy

Denso-Wave say that they can be used for warehouses to track products
http://www.denso-wave.com/en/solution/typeofuse/traceability.html
This kind of implies that a QR Code could do the same job as a normal Bar Code (ean-13).
Though I cannot see how unless (ether) a hardware scanner read QRs and a prefix was designed for that specifically or custom scanning software was built to handle the prefix and look up the product.
Unfortunately I don't have a hardware Bar Code scanner and I cant tell which one they have apart from that it can presumably scan both QR codes and Bar Codes; so I am speculating on what happens at the point of scanning. I have a smartphone and can scan both QR codes and Bar codes. I can also make qr codes using Javascript and I could probably make Bar codes as well.
I would like to put something along the lines of this inside a QR code:
ean-13:5901234123457
but the prefix should be a real one so a scanner could understand to do a look up (I am also assuming that a hardware scanner would just accept the ean-13 number then do it's job and perform its look up on a internal/external database)
I really fail to see how the QR code only has the above prefixes as it was created for corporate use originally and has only become popularized in use for marketing. So logically it would make sense that there are less commonly known more technical prefixes.
1) Are there more prefixes to add to this list?
2) Is there one which I can use in my case?
",['barcodes'],"QR codes hold a string of information.  It can be anything, as it's just a way to encode the string.It's quite common for them to contain URIs (http:, https:, etc.) for smartphones and the like to access, but there's nothing stopping it from holding code to be processed (javascript:, if it's going to be passed off to a web browser), or anything else.  The problem is when the client encounters a URI scheme that it's not familiar with -- as there are a lot of them.A more recent recommendation for identifiers is to prefix them with a webresolver -- so your 5901234123457 becomes http://www.upcitemdb.com/upc/5901234123457 or similar.  But this is a problem if the remote site goes under, or changes their TOS in the future.  If these are for your company's use, you might want to set up your own resolver -- it can always redirect to another site, if you don't want to set up a full database.(if you find that clients don't support redirecting, you can proxy the connections, but be aware that it might be a violation of the site's TOS)"
A good dataset to experiment NoSQL databases,"
I need to do some experiments in HBase and Cassandra. To do that I need an adequate dataset. The dataset I'm looking for has to be large enough (more than 2GB) and the data in it has to be sufficiently unstructured to be representative of the kind of problems that relational technology can't cope. Maybe data derived from social networks, and so on. Has anyone that kind of dataset? Or anyone knows where can I find such a dataset?
Thanks for your help. 
","['data-request', 'unstructured-data']","4.5gb twitter data. 41.7 million user profiles, 1.47 billion social relations, 4,262 trending topics, and 106 million tweets.
http://an.kaist.ac.kr/traces/WWW2010.html
download link bellow:
http://an.kaist.ac.kr/~haewoon/release/twitter_social_graph/twitter_rv.zip
also you can check site SNAP from Stanford University
https://snap.stanford.edu/data/#web
or Amazon Public data Sets repository (specially Google or CCAFS-Cimate Data sets)
https://aws.amazon.com/datasets?_encoding=UTF8&jiveRedirect=1you can check also last.fm datasets but are only close to 1.1gb all combined.
http://labrosa.ee.columbia.edu/millionsong/lastfmOne more thing: you can get any data and convert to Cassandra and can see difference.One more repository http://www.cs.waikato.ac.nz/~ml/weka/datasets.htmlUltimately if none of the data fulfill your requirements, than you can generate own data under hadoop cluster (you can get around 10 gb per node,  textual data ) and connect to that datasets. Good luck."
Australia Hotel/Motel Data,"
I am wondering if there is anyone here that either has 2013-2015 list of hotels in Australia with contact phone numbers and if it had emails that would be a bonus.
I am currently putting an excel spreadsheet together of Melbourne Hotels. But in 3 hours I have only been able to get 46 hotels, and I know that there has to be a quicker and more effective way to do this.
If anyone can help that would be great.
","['data-request', 'csv', 'sql', 'australia', 'excel']",
Hotel internal historical data required,"
I am looking for hotel data to dig through.
What I need as historical information is:

Pricing
Room Capacity
Occupancy

","['data-request', 'historical', 'prices']",
Exhaustive list of speed radars,"
I am looking for an exhaustive list of speed radars in France, USA (especially California and Massachusetts) and Seoul, Korea.
","['data-request', 'geospatial', 'traffic']",
"Data repositories like UCI and mlData, for biological data","
Are there any other data repositories like UCI and mlData, for biological data?? I want to know about mostly biological data set.(The format of data set would be like that of UCI)
","['data-request', 'metadata', 'data-format', 'machine-learning']","There are many biology repositories, including 446 Biology data repositories listed in the re3data repository catalog. Its not clear from your question how you want them to be similar to UCI, which seems to be a compendium.  The KNB Data Repository has a huge variety of biological data sets, some of which represent unique experiments and some of which represent synthetic data sets, such as the Global Population Dynamics Database (GPDD):Prendergast J , Bazeley-White E , Smith O , Lawton J , Inchausti P , Kidd D , and Knight S. 2010. The Global Population Dynamics Database (doi:10.5063/F1BZ63Z8)"
API / dataset for Singapore cinemas showtimes,"
Are there any APIs or dataset for the list of movie showtimes in Singapore?
Official websites from theatre operators in Singapore, (e.g. Eng Wah, Shaw, Cathay, Filmgarde, Golden Village) does show the data but it's truncated  (data is only available for showtimes right then and onwards; showtimes of previous days will no longer be showed). 
Also, is there any way to obtain misc info regarding the shows? This includes the seat information (2D; DBox; IMAX; Dolby Atmos; type of 3D; HFR), the set of available / occupied seats, and the seats booking cost, discounts and booking limitations.
","['data-request', 'film', 'singapore']",
Automate API Queries,"
I'm a project manager. I'm interested in IATIStandard.org an International Aid Transparency Initiative that makes it possible for humanitarian organizations to share information on aid activities formatted into XML files posted online. Organizations use an XML standard to format their data, then register metadata on the files with IATI and IATI makes the files searchable. IATI also has an API folks can use to query all the files/data. Can someone please explain to me how IATI is doing this in simple technical terms?
Thanks!
","['data-request', 'api', 'metadata', 'uses-of-open-data', 'xml']","Well, if you take a look at this link, you can get a good idea of what's going on. Basically, the IATI hold data which references data which is hosted elsewhere. They act a lot like the index in a library - the index doesn't contain the actual text in the book, but it contains metadata which describes the book, and tells you where to find it. Similarly, the IATI don't actually host the data, they just give you a reference to it:The IATI Registry holds meta-data on files published in the IATI XML
  format. The files themselves are stored in different places across the
  web, and you will need to fetch and process the original files
  yourself. If you are looking for an API directly onto IATI data, you
  can use the IATI DataStore or consult the tools section of the IATI
  Wiki to learn about other third-party platforms. In doubt, ask on the
  iati-technical mailing list.Developers who want to query the data use standard HTTP protocols to find out where the data is located. This page is important, because it gives us an FAQ:The publisher record contains a lot of fields. Do I need to fill them
  all out?Yes, this is very important as it provides you with an opportunity to
  explain to the users of the data how to interpret your particular
  business circumstances and methods of operations and accounting. It
  also provides a statement of your progress towards full-compliance of
  the IATI standard that you have agreed to reach.Without actually trying it out myself, this is a good indication that the IATI asks publishers to provide a description of the data set they are registering. This suggests that the data sources themselves are not necessarily standardised (i.e. parsing the data may depend on the publisher supplying a sufficient data description to the application consuming the API).EDIT:In response to the comment, you could take a look at their API documentation to get an idea of how their system works. They use CKAN, which:...is built with Python on the backend and Javascript on the frontend,
  and uses the Pylons web framework and SQLAlchemy as its ORM. Its
  database engine is PostgreSQL and its search is powered by SOLR. It
  has a modular architecture that allows extensions to be developed to
  provide additional features such as harvesting or data upload.ckan is open source, so you should able to look a the source code. In fact, it looks like you can get the IATI source code too. From what I can see, it's much as you would expect - a web server wrapped around a database. How you choose to interface with the data IATI provides depends on the application you want to make, but it sounds like you are describing a pretty standard web stack which hosts whatever user interfaces to the data you want to provide (including an editor, if you want). For more info, I would definitely recommend visiting the IATI technical mailing list. As an organisation which seems committed to open data, one of the best things to do is to contact them directly. If they like what you're attempting, they may be able to help you out in all sorts of ways."
Looking for a data set that gradually changes through the time,"
I'm looking for a proper data set for my anomaly detection model. At this point, we are looking for a parameter which has the following characteristic: it is a data stream that gradually (or even quickly) changes through the time.
We want to detect anomalies in such data stream with our own model. Could you please help me by introducing a parameter that has the above feature and also it is worth to detect outliers in that?
","['data-request', 'time-series']",
What should I do with a database of public library greeter questions?,"
I work at a county public library, and recently I found out that our greeters have been writing down the questions patrons ask them. I gave them a form to make the data more coherent and I've been keeping it in an Access database. There are only about 5000 data points so far, about 1.5 years worth. All I've done with it to date is keep an updated FAQ at the greeter's desk. Any suggestions for what else I might do with it?
Also, if the library agrees, would anyone else like to use it for anything?
","['releasing-data', 'uses-of-open-data']",
Annual Telecommunications Wire Production,"
I'm trying to find a data set that includes the amount of telecommunications cable production in terms of length produced dating as far back as possible.
",['data-request'],
"How do I query for a field with a single quote or apostrophe? e.g. ""CROHN'S DISEASE""","
I want to list all drugs that have ""CROHN'S DISEASE"" or ""CROHN^S DISEASE"" as drugindication:
http://api.fda.gov/drug/event.json?search=patient.drug.drugindication.exact:%22CROHN'S+DISEASE%22&count=patient.drug.openfda.brand_name.exact&limit=100

If you list Humira's drug indications
http://api.fda.gov/drug/event.json?search=patient.drug.openfda.brand_name.exact:%22HUMIRA%22&count=patient.drug.drugindication.exact&limit=100

Crohn's Disease shows up as a very common drug indication for Humira. Now I want to find other drugs that also have Crohn's Disease as a drugindication. How should I query for this? I don't believe it is currently possible.
","['openfda', 'api']","First of all, in your Humira drug indications response, there is some data quality idiosyncracies because I see ""CROHN'S DISEASE"" and CROHN^S DISEASE as possible values of patient.drug.drugindication.exact.Unfortunately, this has been a known issue since 2014 (at https://github.com/FDA/openfda/issues/29) and there isn't a fix just yet.For the time being, you could do a fuzzy-ish search like the following:which should match both of the permutations of Crohn's disease above."
Campgrounds in the United Kingdom,"
I'm looking for a dataset with campgrounds in the United Kingdom that I can load into a handheld Garmin GPS-receiver.  Openstreetmap includes some, but it is not complete and it is not easy to search specifically for campgrounds.  Is there such a database?
","['data-request', 'geospatial', 'uk']",
Broadband data conversion from Census Block to Zip Code,"
I'm basically trying to duplicate broadbandmap.gov and how you can enter a zip code and return local broadband providers for a project. I downloaded their data files here. They use census blocks to identify locations. Then if you search by zip code or city, they say, ""The list above only displays the broadband providers offering service in the Census Block that is in the center of your search results. The results do not display a summary of the search area, only the center of the search. For example, if you search for a city name only, then the search would return the approximate center of that city and only the information in the Census Block at the center of the city would be displayed.""
How do I convert this data from census block to geo-center of zip code? Is there a resource available somewhere?
","['data-request', 'usa', 'geocoding']",
Where can I find data related to Availability of world energy resources?,"
I am looking for data related to availability of world energy resources. I am collecting this data for a project which deals with creating Infographic.
","['data-request', 'energy']",
"How does USAID facilitate public access to USAID-funded research publications (i.e., journal articles)?","
I see that USAID provides public access to research data via DDL.
I don't see how it provides public access to USAID-funded journal articles, as required by Feb 2013 OSTP public access memo.
Does USAID plan to collect articles/manuscripts from authors and establish a repository giving full-text access to articles? (for example: after a 12-month embargo period)
","['research', 'usaidopen']",
Basic English proficiency in the world,"
I am looking for data showing how all world countries compare in terms of basic English proficiency.

In answers, the SAME METRIC should be used for all countries.  
Reasonably recent, at least after year 2000.
The answer with most countries wins.

Pretty much any metric is welcome, for instance the number of people who passed a given test divided by population with correction for representativeness, or the proportion of the population who can handle a basic English discussion measured by UNICEF or others. The important (and difficult) thing is to have the same metric for all the world.
I am looking for basic proficiency, so at this level British/American English distinctions do not matter.
","['data-request', 'education', 'english']",
Specifying sort direction in openFDA queries,"
Is it currently possible to specify a field and sort direction for the openFDA api? I don't see any mentioning of it within the documentation.
",['openfda'],
California Community Colleges Transfer Data,"
Can someone point me to where I can find California Community Colleges transfer data? 
","['data-request', 'education', 'state']",
Querying CKAN in Python using ckanapi,"
I used to query with ckanclient thusly:
import ckanclient
ckan = ckanclient.CkanClient('http://catalog.data.gov/api/3')
search_params = {                                           
    'q': 'tags:""sea_water_temperature"" AND metadata_modified:[2012-06-01T00:00:00.000Z TO NOW]',  
    'fq': 'res_format:HTML',                                
    'extras': {""ext_bbox"":""-71.5,41.,-63,46.0""},                   
    'rows': 3                                                     
}
d = ckan.action('package_search', **search_params) 
print d['count']search_params = {                                           
    'q': 'tags:""sea_water_temperature"" AND metadata_modified:[2012-06-01T00:00:00.000Z TO NOW]',  
    'fq': 'res_format:HTML',                                
    'extras': {""ext_bbox"":""-71.5,41.,-63,46.0""},                   
    'rows': 3                                                     
}
d = ckan.action('package_search', **search_params) 
print d['count']

How would I do the same with ckanapi?
This doesn't work:
import ckanapi
ckan = ckanapi.RemoteCKAN('https://data.noaa.gov/api/3')
search_params = {                                           
    'q': 'tags:""sea_water_temperature"" AND metadata_modified:[2012-06-01T00:00:00.000Z TO NOW]',  
    'fq': 'res_format:HTML',                                
    'extras': {""ext_bbox"":""-71.5,41.,-63,46.0""},                   
    'rows': 3                                                     
}
d = ckan.call_action('package_search', data_dict=search_params) 
print d['count']

Returns a 404 error.
","['ckan', 'python']",
Antebellum Newspaper Data,"
Is there data on the circulation numbers for newspapers in the antebellum (pre-1861) United States? I'm also interested in any other pieces of data about these newspapers.
","['data-request', 'usa', 'media']",
Location accuracy with 3taps API,"
I'm using the 3taps API and there's a field it returns called ""accuracy"", which the documentation describes: 

An integer indicating the accuracy of the supplied lat/long value.

But I can't seem to find additional details.  Does accuracy mean how close the lat/long provided are to the actual location? How is this determined? What is the range and is higher better?
Sorry for so many questions, but it is really important to my use case to know whether the lat/longs are accurate.
",['api'],
Get All medicine names,"
My aim is to give intelligent support to the textbox where the user will type the medicine name that they want, and I will provide suggestions of the medicine.
For this purpose, i want to get the list of all names of medicines from OpenFDA.
I am able to retrieve the particular medicine details from their site, by using this query:
https://api.fda.gov/drug/event.json?api_key=yourAPIKeyHere&search=patient.drug.medicinalproduct:Crocin
But, I am unable to get all the details of the medication.
I have also seen this link, and have been told to use this API all alone and not any other API.
Could someone help me to understand how to do this?
Thanks.
",['openfda'],"If, for some reason, you must use openFDA for this use case, you could go ahead and page through the following API call:https://api.fda.gov/drug/label.json?count=openfda.brand_name.exact&limit=1000However, this isn't too helpful because brand_names are duplicated so you would then have to have the user specify, somehow, which record they want (or maybe you can make some sort of assumption)."
ISO 3166-2 codes to Olson Time Zone Codes,"
Just curious, is it possible to link ISO 3166-2 codes to Olson Time Zone Codes. For example the US has these Olson Time Zone Codes:
US  United States   America/Adak
US  United States   America/Anchorage
US  United States   America/Boise
US  United States   America/Chicago
US  United States   America/Denver
US  United States   America/Detroit
US  United States   America/Indiana/Indianapolis
US  United States   America/Indiana/Knox
US  United States   America/Indiana/Marengo
US  United States   America/Indiana/Petersburg
US  United States   America/Indiana/Tell_City
US  United States   America/Indiana/Vevay
US  United States   America/Indiana/Vincennes
US  United States   America/Indiana/Winamac
US  United States   America/Juneau
US  United States   America/Kentucky/Louisville
US  United States   America/Kentucky/Monticello
US  United States   America/Los_Angeles
US  United States   America/Menominee
US  United States   America/New_York
US  United States   America/Nome
US  United States   America/North_Dakota/Beulah
US  United States   America/North_Dakota/Center
US  United States   America/North_Dakota/New_Salem
US  United States   America/Phoenix
US  United States   America/Yakutat
US  United States   Pacific/Honolulu

If so, is there a free and curated data source? Alternatively, are there polygon data of time zones available?
","['data-request', 'metadata', 'geospatial']",
Return an Enforcement record for search=recall_number,"
Whenever I attempt to query the API with a specific recall_number, I receive the API error message. Is there another method for retrieving an individual record that I am overlooking in the docs?
Also, it would be nice to see what type of error response we are dealing with rather than the same error response for malformed APIs, URL encoded entities, and no results found. Any guidance on that would be welcomed!
","['openfda', 'api']",
OpenFDA: BAD_REQUEST when searching with URL encoded inputs,"
I am trying to search some of the ""free text"" fields that have values with commas, apostrophes, etc. With the encoding I have tried all combinations of quotes, parenthesis, etc. however it always results in an error.
I have tried URL encoding and other approaches that seem RFC 3986 compliant, however I always seem to get this error:
{
  error: {
    code: ""BAD_REQUEST"",
    message: """"
  }
}
Here's an example of a search:
http://api.fda.gov/food/enforcement.json?limit=1&search=product_description:(Today%27s+Harvest)
[The above should search for Today's Harvest]
Is this type of search possible/supported?
",['openfda'],"Unfortunately, we don't allow embedded single-quotes in search strings. You will have to get creative. The following query appears to get find what you are looking for: http://api.fda.gov/food/enforcement.json?limit=10&search=product_description:%22Harvest(TM)%22Good luck."
Need to analysis the physiological data,"
I have to do a project to analysis the human physiological state. I have able to got the heart rate, ECG, and temperature sensor data. What things I have to analysis to get the human physiological states. 
Is there any open data set available to analyse human state? like 
if heart rate between 79 - 110 he is cool 
else if  heart rate between 111 - 120 he is stress 
like this  
","['data-request', 'uses-of-open-data', 'biology']",
"Bulk access to data on scientific literature (affiliation, citations etc)","
I want to compare the scientific performance of different countries and/or institution via the relation of first and second etc authorship of papers in relation to the number of citations of each paper to answer specific questions.
Therefore, i need a dataset that covers the following aspects of publications:

All author's affiliations with categorial indexing (1st or 2nd etc),
including the address of the institution (just the country actually)
Number of citations 
(Title and/or) field of study 
For a representative number of papers in as many fields as possible (e.g. 
Earth Sciences, Medicine, Math etc)

So the question is: Where do i get this kind of data in bulk, preferably free?
What i have tried so far:

Web of Science, which can cover part of the information i'm looking for, but basically blocks downloading it. 
A basic crawler that scrapes the info from an individual journal's web page. However, i don't have the computing power and coding experience in this field for this to be time efficient. 

","['data-request', 'metadata', 'bibliometrics']",
Searching for Arrays containing Vectors of States/Countries,"
So I don't really know how I should aks this question to make it understandable for everybody but in specific:
I am searching for Data, which has, for example every point of the path of the Border of the USA (or any other country),
My aim is to make a windows forms control, using an array containing that data and set it to its shape.
Does anyone know where I can get that kind of data? I searched for geodata but i don't know if that is the right search key and everything I got is a .shp File from which I can't do what I want to do, at least as far as I know.
","['data-request', 'geospatial']",You can use the .shp files without having to use GIS... Download the shapefile with the resolution (scale) you want from Natural Earth then convert it to GeoJSON using Shape Escape... Learn more about GeoJSON at geojson.org/geojson-spec.html
Can anyone suggest a big dataset for the purpose of regression?,"
I am working on a regression model.I need a big dataset for this purpose.
I have already worked with the famous Airlines dataset(http://stat-computing.org/dataexpo/2009/) and the million song dataset (http://labrosa.ee.columbia.edu/millionsong/) .I want another dataset to gain deeper insights into the research problem.
Most of the datasets which I found are not so big in UCI repository.
Can anyone suggest a source for this purpose?
","['data-request', 'big-data']",
Searching for label by NDC,"
I'm trying to use the label API to search for a specific OTC drug.  Lets take CVS's 10mg Loratadine for example.  The NDC number is 59779-612-75.
Based on the API docs I think the right query should be:
https://api.fda.gov/drug/label.json?search=openfda.product_ndc:59779-612-75&limit=100
That returns several hundred results, none of which have a openfda.product_ndc field that matches.  Most are substrings or similar strings.  The correct product is in there, but the product_ndc doesn't match.  The package_ndc field (which isn't documented) does.
None of the variations on NDC substring seem to work either, all return several hundred results:
    https://api.fda.gov/drug/label.json?search=openfda.product_ndc:59779-612&limit=100
https://api.fda.gov/drug/label.json?search=openfda.package_ndc:59779-612-75&limit=100
https://api.fda.gov/drug/label.json?search=openfda.package_ndc:59779-612&limit=100
A lookup on the following site returns exactly one correct match:
http://www.accessdata.fda.gov/scripts/cder/ndc/dsp_searchresult.cfm
Am I missing something or is the API behaving a bit strangely?
",['openfda'],I think if you use quotes around the product_ndc field it should give you the results you are looking for.Link for reference:https://open.fda.gov/api/reference/#exact-matches
google nutritional info database,"
I wanted to make a talk-to app with a lot of info about foods,
do you know how can I get access to all the google nutritional info on foods and vegetables?
",['data-request'],
I need to analyse buying pattern of consumer buying data,"
I need to analyse the consumer buying data to predict what the customer will buy when he back to the shopping mall again.
My problem is data sets - where can I get the appropriate data sets for this ?
","['data-request', 'products']",
(Non)Prescription Drug Use Location/Date,"
I'm doing a data science project that requires information about the use of specific prescription and over-the-counter drugs by location and date. The location data don't have to be US-specific, but should be more fine-grained than ""country"" if possible. 
I looked at the FDA Adverse Events database, but it doesn't seem list anything other than country. 
I have also poked around in Google Trends (assuming that search for a particular drug correlates with its usage) and there is some useful data there, but pulling it together seems like it will be a pain.
Does anyone know of data bases that can directly or indirectly provide this information?
","['data-request', 'medical', 'drugs']",
Can Linked Data URIs be parameters?,"
I'm still looking into Linked Data and what it takes to get up to the fourth and fifth star of Tim Berners-Lee's 5-Star classsification.
We are to use URIs to denote things. I'm wondering if URIs can include parameters?
For instance there are two URLs that can be used to point to the same YouTube video: 
https://www.youtube.com/watch?v=4x_xzT5eF5Q
is the typical one, but you can use the short-form:
https://youtu.be/4x_xzT5eF5Q
Can the relevant parts of both of these URLs be considered a URI? 
If so then exposing data through an API so that you select e.g. www.example.com/population?country=USA would be a method of making the data ""linkable"". 
","['api', 'linked-data']","If by ""relevant parts"" you mean the video IDs, I think those alone could be considered URIs, but not very good ones, as they do identify the resource, but not unambiguously. If I ask you to find me 4x_xzT5eF5Q, that could be difficult because there could be any number of things named 4x_xzT5eF5Q, and that name tells you nothing about what the thing I expect to find is.On the other hand, the full URLs both uniquely identify one particular object. Nothing else in existence (probably) is named https://youtu.be/4x_xzT5eF5Q. That also happens to be a URL, so tells you once place you can find that object, but if you treat it as the object's name, you can imagine you might be able to find that object elsewhere under the same name (e.g. on some theoretical Youtube mirror). (Also, this object has many possible names: any URL which leads to it can be considered another name for it.)(Of course if you want to make sure nothing else has the same name as your object, you should ideally use a UUID or hash. A hash also has the advantage that all copies of it automatically have the same name, and all variations automatically have different names, which are also unique to them.)tl;dr a Youtube video ID, and any valid URL for that video, can be seen as one of many possible ""names"" for the video (and a URI is essentially a name), but these are poor URIs because there's no guarantee that a) nothing else has the same name and b) all copies of the video have these names."
Where to get historical weather forecast? [duplicate],"







This question already has answers here:
                                
                            




Historical Weather Forecasts

                                (3 answers)
                            

Closed 7 years ago.



With weather being quite often an important external data. I'm trying to find where could I get historical weather forecast.
(I am not interested in where to get past weather)
",['weather'],"Forecast.io has an API that delivers historical forecasts. You can call a past date and time get the daily, hourly, and minute forecasts (in addition to actual forecasts). That is, ask for the weather on April 16th and will include forecasts for April 20th in the daily summaries.It's free for under 1,000 calls per day, and then $1 for 10,000 calls--a pretty reasonable price."
Venues of the Tokyo 2020 Olympics competitions,"
The Tokyo 2020 Olympics & Paralympics competitions will presumably be held at many stadiums and other sport venues.
Is there a list of them?
Necessary details for each venue:

Name of the venue in English
Name of the venue in Japanese
Latitude/longitude
Sports the venue is used for

An official list would be the best.
","['data-request', 'geospatial', 'sports', 'japan']","The venue list on the official page now lists venue for both Olympics and Paralympics.Additionally, the HTML source has geographical names in addition to venue name, which should help for geocoding."
Mapping all Wikipedia URLs to Wikidata entity ids,"
Is there a Wikidata dump that maps all Wikipedia URLs to their corresponding Wikidata entity ids, e.g. the Wikipedia URL https://en.wikipedia.org/wiki/Tom_Hanks to the Wikidata entity id Q2263?
","['wikidata', 'wikipedia']","If you want to do this from the dumps, you can use the wb_items_per_site dump (current version, 625 MB; most recent dumps)For each Wikidata item, this contains rows with the corresponding page name on a given wiki project.For individual articles, you can use &action=info on Wikipedia as Ainali suggests, but you have to use the /w/index.php?title=PAGENAME&action=info URL format, not /wiki/PAGENAME&action=infoWith your example: https://en.wikipedia.org/w/index.php?title=Tom%20Hanks&action=info"
US Population Demographic Data,"
I’m hoping someone can help me find some demographic data for the US. I'm looking for data with first name, last name, sex, date of birth, and zip code and a unique identifier for each person.  I want to calculate the rate of people in the population who have the same first name, last name, sex, date of birth, and zip code but are unique individuals.
","['data-request', 'usa', 'us-census', 'uses-of-open-data']",
"Who else sings Do, Re, mi?","
I'm looking for human voices singing do, re, me etc. for sampling. Each sample is then asscociated with a particular MIDI key. My challenge is to find more (public) recordings to sample. I don't need the whole Rogers & Hammerstein number (thats copyright anyway), just someone singing the solfege scale.
Julie Andrews in ""Sound Of Music"" is a starting point, although backing music can be heard in some samples. I have also found Harry Secombe, in the movie ""Sunstruck"". Does anyone know of other recordings or performances? 
Edit: A similar question was asked before here.  That request was [from my understanding] covering general choir sounds, like ""ooh"" and ""aaah"" available in a choir sound font. I'm looking for the specific ""Do Re Mi"" etc.
The idea being: when playing a MIDI file, you hear a voice intoning the name of the note, in the right key. Primary use is an aide in learning the musical scale.
","['data-request', 'music']",
City road maps as graphs,"
City streets can be represented as graphs with crossings as vertices and roads as edges. And, naturally, that's the representation traffic routing services (like Google Maps) are based on.
These graphs can be recovered from the road layers available on OpenStreetMap or elsewhere. For example, see https://gis.stackexchange.com/questions/104452/how-to-build-a-graph-from-a-map.
Are there any repositories of the ready-made graphs for cities that would let me to avoid going through this conversion process?
","['data-request', 'geospatial']",
Is there an open geospatial dataset to resolve historical and modern places?,"
Given a documentary edition with settlements and regions spanning the American founding era--documents originating from and correspondences delivered to place names which may no longer exist--is there open data on historical places in order to map to cities in the modern world? If there's nothing for GIS then coordinates could be added in preprocessing before loading into database for a geospatial query, so that is not a requirement of the data, it could be any taxonomy or ontology.
","['geospatial', 'historical']","The Atlas of Historical County Boundaries (AHCBP) at the Newberry Library covers historical/modern, and is a geospatial open dataset.  ""The Atlas presents in maps and text complete data about the creation and all subsequent changes (dated to the day) in the size, shape, and location of every county in the fifty United States and the District of Columbia. It also includes non-county areas, unsuccessful authorizations for new counties, changes in county names and organization, and the temporary attachments of non-county areas and unorganized counties to fully functioning counties. The principal sources for these data are the most authoritative available: the session laws of the colonies, territories, and states that created and changed the counties.""http://publications.newberry.org/ahcbp/index.html"
Business microdata from UK Data Service,"
UK Data Service has several very interesting business surveys with the data that rarely appear elsewhere. It describes turnover, cost of capital, organizational structure, and other microeconomic variables.
But the problem is that the access is granted only to certain institutions (not sure if they pay for it). I also haven't found this data elsewhere.
Are there any ways to obtain this data, except through these institutions?
","['releasing-data', 'economics', 'uk']",
"Looking for automotive data (camera images for feature extraction, tracking, fusion etc.)","
I recently graduated from college and realize that I need to turn my theoretical knowledge into skills. I am very much interested in the automotive industry. There, experts for Advanced Driving Assistance Systems (ADAS) functions like Automated Emergency Braking (AEB), Lane Departure Warning (LDW), Parking assistants and upcoming functions for autonomous driving are needed. I am looking for projects which provide data for exactly this or similiar functions. I think it will be hard if not impossible to find data that describes a whole function from one of the above. But there are similiar skills needed in many other topics.
I want to cover the following topics

image processing (detect cars, lanes, traffic signs, etc.)
kalman filtering/ particle filters etc. (represents the state of an image feature.)
object tracking (track one feature e.g. a blue car over a series of pictures/ video)
object fusion (let's say there is redundant data of one and the same feature, because the feature is tracked with radar and camera. Then I want to apply object fusion techniques on this data)

I know it is hard to find the perfect data for it, but I am grateful for any hints where I could find exactly the desired or similiar data. It does not need to be from the automotive field, as long as it covers the topics.
It would be great if I could process the data with Matlab, but I am open to C and C++, too. Though the latter would be the tough road.
","['images', 'machine-learning']",
"Are there opendatasets of English terms describing nationalities, ethnicities?","
Say one needs to parse text for any mention of nationality or ethnicity, or otherwise use these terms in the course of an NLP project. Is there a comprehensive resource of English words describing these? The interest is in both adjectives and nouns, e.g. ""Turkish"" and ""Turk.""
","['data-request', 'language', 'english', 'nlp']",
Source of illegal immigrants to the US over the years,"
Would like to find a source, that shows or estimates the numbers of illegal immigrants entering the US broken down by their country of origin, each year.
","['data-request', 'demographics']",ctrl + f on this pagehttp://www.dhs.gov/immigration-statistics-publicationsfor the text unauthorized
How to crowd source open data,"
Is there a way to get a list of the top accessed open data sets by organizations and the organizations which use them?
","['data-request', 'data.gov', 'releasing-data', 'linked-data', 'metadata']",
Historical US population by Age/Sex,"
I'm looking for US population data since 1900 (or earlier) with age and sex breakdowns. The data appears to be available from the US Census Bureau, but in may different text or Excel files, sometimes differently per decade. For example, 1980s data is one loosely structured text file.
I thought this might be common enough that someone knows of an aggregated source, or multiple files with consistent structure.
","['data-request', 'us-census', 'historical']",You could see if Historical Statistics of the United States 1789-1945 is useful.You could also calculate it using iPUMS.
OpenFDA API: Including the skip parameter limit,"
I was working with the API and trying to paginate the results and I ran into an error which says 'Skip value must 5000 or less'.  It would be nice if you guys could add this to your documentation because I had no idea that this limit was being imposed until I started to try and clean the data.  Now I must go and download it all over again to make sure I've captured all the data.
","['openfda', 'api', 'medical']",
Where can I get decibel level data for NBA games?,"
I am trying to find data that reports the decibel level at NBA games. I prefer as granular as possible - minute-by-minute would be fantastic. 
","['data-request', 'sports']","This is an incredibly specific data request -- I don't think there's any chance of just finding this in the wild. Your best bet is probably to obtain TV recordings of NBA (either record them yourself or hunt around online) and analyze the decibel levels in audio track yourself. Of course, this has a few issues: you'll have to cut out commercial breaks/instant replays/etc, you'll have to somehow filter out the commentators or something (the commentators' volume should be consistent on average over the course of the game, so this should be feasible, if not ideal), etc.That's a lot of work and it won't produce the most accurate results, but I think that's the best you're going to get in the realm of open data."
Where can I get a complete word and phrase list for English?,"
I am looking for a complete set of all possible English words and phrases (i.e. 'fire', 'fire up', 'fire ant', 'under fire').
Actually, I need it for parsing online dictionary.
The best thing i found was standard words file in my GNU/Linux system. It's pretty neat in terms of consistency and contains about 100k words (or 40k excluding plurals), but it has no two-word phrases with adpositions, such as 'hold on'.
","['data-request', 'english', 'dictionary']",Try http://en.wiktionary.org – it's free and it has a lot of idioms and phrases.
Social classification data for the UK,"
Is anyone aware of 'social classification' data sources used, for example, here:

http://www.checkmyarea.com/EC3N4AB.htm ""Wealthy singles in small city flats and suburban terraces""
http://www.checkmyarea.com/B66HE.htm ""Ethnically mixed young families and singles in terraced housing""
http://www.checkmyarea.com/EH12NG.htm ""Suburban scottish households in small terraces and flats""

","['data-request', 'metadata', 'geospatial', 'geocoding']",
Novels with chapters annotated POV,"
I'm looking for one or more novels, that multiple characters points of view.
(I don't care if it is 3rd person or 1st person), 
with each chapter (or paragraph) annotated as to which character's POV it is from.
A good example of a in-copyright work is George R.R. Martin's Song of Ice and Fire. It has over a dozen POVs and each chapter it titled with the name of the character.
I'm sure these exist as there are many many books out of copyright.
But I have no idea how to work out which match my criteria.

The purpose of this is to investigate a machine learning approach to POV detection, as in this question.
","['data-request', 'english', 'corpora', 'books']",
How to get soccer players Wikipedia URL?,"
I'd like to grab as many soccer players names and their Wikipedia URL. For example:
""David Beckham"": 'David_Beckham',
""Wayne Rooney"": 'Wayne_Rooney'

The first portion is their name and the second is the extension for their Wikipedia page. 
I've found a few lists like this: https://en.wikipedia.org/wiki/List_of_current_Major_League_Soccer_players
The URL above lists a few hundred/thousand names, and I suppose I could scrape it, but is there a better method since not every league has a list like that? Perhaps there is an already available index?
","['api', 'sports', 'wikipedia']","First of all, if you want the page content, the best way to do this isn't by scraping, but by processing one of the database dumps - you can do this locally, and it'll allow you to get the raw page content rather than rendered HTML.To identify the pages, there are a number of possible options.First, categories - these are comparable to index pages, but dynamically generated. Taking the example of Anatole Abang, the first man on your MLS list, scroll to the bottom of the page and you'll see the article is in categories such as ""Cameroonian footballers"", ""Major League Soccer players"", etc. The category system is a hierarchical tree, and they should all be underneath ""Association football players"". Unfortunately, the category tree is a little messy. If you just took everything downstream of this category, you'd pick up (among others) every fictional footballer Wikipedia knows about. A good compromise is to use something like ""Association football players by club"" and work downstream from there to a depth of perhaps four categories (the UK ones are pretty deeply nested).If all you want to do is get page titles/URLs, you can use a tool like catscan or (preferably) quick-intersection for this; be prepared to wait a while for it to process everything, but it'll give you a useful html/csv/etc file. You will still get some entries that shouldn't be there, but scraping would have the same problem!Secondly, wikidata. Wikidata is the structured-data ""spine"" to Wikipedia; almost every article in every language has a corresponding data element, which for Abang is Q19594142. In theory, you should be able to query Wikidata to pull out, for example, - a) every person with occupation ""footballer""; b) every person with a FIFA player ID; c) every person who was a member of a team which itself was a football team; ...Unfortunately, as of the time of writing it looks like this data has not yet been fully imported for sports players, and so it won't give you a comprehensive answer. But if you're someone reading this reply in 2017, take another look :-)"
Original titles of books,"
Where can I get the original title of books, i.e. Marquez's book ""100 Years of Solitude"" has the original title ""Cien Años de Soledad"".
Some of the Hungarian publisher list this info, but especially in English language countries, book stores not do it.

","['data-request', 'api', 'books']",
UK Rural and Urban Data,"
I am looking for some reliable and potentially free data that divides the UK into rural, urban etc. sections:
https://www.gov.uk/government/collections/rural-urban-definition
the classification can either be associated with postcodes or wsg84 lat long borders.
","['data-request', 'geospatial', 'uk']",
Historical Aerial Imagery of Ivory Coast,"
I'm looking for historical aerial imagery for Ivory Coast (Cote d'Ivoire).
My first web searches have turned up nothing, but I know the French (and possibly the Soviets) created basemaps of the region in the post-colonial period (therefore there must be aerial imagery from which these maps were created).
Anyone have suggestions of where to start looking?
","['data-request', 'historical', 'aerial-photography', 'ivory-coast']",
Where can I find asset finance or microfinance data at the individual (loan recipient) level?,"
I'm looking for asset finance and microfinance data at the individual level.  I'm already aware of Kiva, Prosper and Lending Club (links below).
Specifically, I'd like to find individual loan repayment histories and sociodemographic details from a variety of microfinance products.  If developing world, even better; if sub-saharan Africa, best!
Here's what I've found so far:
Lending Club:
https://www.lendingclub.com/info/download-data.action
Prosper:
https://www.prosper.com/tools/DataExport.aspx
Kiva:
https://build.kiva.org/
Can you help me add to the above list?  Thanks!
","['data-request', 'finance']",
Dataset of User Transaction history,"
I am looking for User Transaction Dataset for movies
I have recently come across Movielens Dataset. http://grouplens.org/datasets/movielens/
This dataset consists ratings of the movies given by users. But I need a dataset that contains user transaction histories
Like User 1 purchased movie X Y in first transaction, C,D,X in another transaction and so on. 
",['data-request'],
Data Sharing by Other Orgs/Businesses,"
I work for a nonprofit organization and we are establishing a policy platform that will house research and policy reports, data, articles, etc.  What government data can we include on our platform that does not require prior permission or a formal contract.
",['api'],
Popularity of given names through the ages,"
Wikipedia has articles about given names (example: John).
In each of these articles, I would like to add a histogram showing how popular the name has been through the ages. For each year, it could be the number or proportion of children who received this name.
Where can I find data for this?
Requirements:

Must be reusable in Wikipedia (CC-BY-SA 3.0)
Since as far back as possible, for instance there have been Johns since 134BC at least. Estimation data is OK.
Some will argue that John was actually spelt another way and should be considered another name. Any stance is fine, as long as the data stays consistent with the stance they have chosen.
I am looking for data for the whole world, but dataset for parts of it (for instance Chinese names only) are welcome too.

","['data-request', 'names']",
overview on all stages and theatres that play a. Bertolt Brecht b. W. Shakespeare,"
I need an overview on all stages and theatres that play: 
a. Bertolt Brecht
b. William Shakespeare 
I am interested to find out all stages in the USA and Europe.
How can this be achieved?
","['data-request', 'calendar']",
Database of non-packager-specific drug information,"
DailyMed lets me look up the Structured Product Label files for various medications, and I know that I can download a database of those drug labels from DailyMed here.
The Structured Product Labels (SPLs) are all as supplied from the drug packager. That means none of them is suitable for displaying general information about the generic drug, like ""ibuprofen"" rather than ""Advil"" - even the generic listings you find will be for something like ""Some-Company Ibuprofen"". So, if I search for gabapentin I will find hundreds of results, but each of them makes reference to the company that makes the particular product. For instance, this is one of the gabapentin medication guides found by that search, and it includes the name and phone number of the company that makes it, and further it only has information about capsule, not other forms. (By contrast, this other manufacturer's product label talks about capsules, tablets and suspensions, since they make all those forms.)
I know you can find similar company-specific information on OpenFDA, such as this JSON document describing the same product as the first medication guide I linked to above; that has the same issues as the data straight from DailyMed.
So, is there a way through DailyMed or some other source to get information for a generic drug, without packager/manufacturer-specific information? To use an RxNorm term, I'm looking for information about a ""concept"" rather than a ""brand"".
","['data-request', 'openfda', 'medical']",
Discrepancies between World Bank and OECD GDP data,"
I just noticed that basic data such as historical Gross Domestic Product (GDP) at market prices in local currency differs between the World Bank (WB) and the OECD. For instance, for Canada between 2010 and 2013:
WB   : 1,662,757,000,000  1,760,011,000,000  1,819,967,000,000  1,881,200,000,000
OECD : 1.66276E+12        1.77001E+12        1.83123E+12        1.89376E+12

Or France: 
WB   :          1,998,481,000,000   2,059,284,000,000   2,091,059,000,000   2,113,687,000,000
OECD :          1.99711E+12         2.05812E+12         2.08639E+12         2.11789E+12
[OECD]/[WB]-1 : N/A                 -0.06%              -0.22%              +0.20%

Sources: WB and OECD.
The differences are not huge, but for data that has presumably been sourced straight from national statistical institutions with no inflation correction, I'm still surprised. Also, the WB site mentions for its sources: ""World Bank national accounts data, and OECD National Accounts data files."" 
Figures for GDP growth (real) in France in 2013 then differ by 46bp (OECD: 0.74%, WB: 0.29%) (42bp are explained by the difference in current GDP figures, the other 4bp come from differences in GDP deflator data), which is rather material. 
Is anyone familiar enough with these 2 institutions' data collection methodologies to explain where these differences come from? 

Edit: Just for fun, I have downloaded the data for France from the ""official"" sources (INSEE, and Eurostat which gets its data from INSEE) and here is the result: 
For GDP at current (market) prices: 
         2010        2011        2012        2013
INSEE    1,998.5     2,059.3     2,086.9     2,116.6 
Eurostat 1,998.5     2,059.3     2,086.9     2,116.6 
OECD     1,997.1     2,058.1     2,086.4     2,117.9 
WB       1,998.5     2,059.3     2,091.1     2,113.7 

And for real GDP growth:
         2010    2011    2012    2013
INSEE    2.0     2.1     0.2     0.7 
Eurostat 2.0     2.1     0.2     0.7 
OECD     1.88    2.09    0.21    0.75 
WB       1.97    2.08    0.33    0.29 

That's quite depressing ...
","['economics', 'worldbank', 'oecd']","I have just checked the OECD's Statistics database, and I find the following GDP figures for France:The output approach figures from the OECD match those of the INSEE and Eurostat. The figures that you attribute to the World Bank correspond to the figures that the OECD obtains by using the income and expenditure approaches. The three approaches are explained by the OECD. The OECD figures that I have found are in line with those from INSEE and Eurostat. You should know that national accounts are regularly revised. In such a case, international organisations, such as Eurostat, the OECD or the Worldbank update their databases, but it may take some time. And they possibly only due it at certain fixed dates and not all at the same time. Thus, figures from different sources can temporarily get out of sync.In short, there is nothing to be depressed about. You just need to update you data. That's it. And anyway, the differences are really small.Edit:Nevertheless, I suspect that in your case there is yet another explanation. According to your references, you are using data from the OECD's Economic Outlook. These data are displayed as annual data. However, a glance at the metadata reveals that the underlying data are not ""genuine"" annual data, but come from quarterly national accounts and are aggregated to annual data:"
Are there any open datasets for soccer statistics?,"
I'm mainly interested in soccer related statistics. There are quite a few different API's relating to soccer, but most of them are commercial and far, far out of my price range. I've looked at DBpedia, but a lot of their data is quite out of date.
","['data-request', 'api', 'sports', 'football']",
Linking Outpan's PHP API with Android [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 8 years ago.







                        Improve this question
                    



I have successfully integrated Zxing's Bar-code Scanning Library with my android app. So, now I am able to get bar-code data of any product.
Now, the problem that has arised is I need to link Outpan's PHP API with my android app. I tried a lot, but failed each and every time. Please help me guys. Please do write the entire code if possible, for integration the PHP API with my app.
This link also ain't helping me. 
This is the link for Outpan's PHP API. And yes, I shall keep my PHP file on a web server.
Please do not down-vote my question, as I have done a lot of research and tried a lot before asking this question! Please do understand!
Please do help me!
","['api', 'barcodes']",
"Where to upload media not yet compatible with Wikimedia Commons licenses? (""open dark archive"")","
I took many pictures of modern art paintings at a museum.
I uploaded the public domain ones to Wikimedia Commons, and wonder to what website I could upload the others.
Requirements:

The website should keep the uploaded images, and provide visitors with as much as what the copyright laws allow (for instance only metadata and a fair-use thumbnail)
The website should upload images to Wikimedia Commons as soon as they become public domain (the website should make calculations and keep track of that)
The website should allow visitors to provide metadata, such as title, author, year, description. This metadata should be semantic/searchable, for instance one could query all paintings painted in 1925. Ideally it would use the same classification as Wikimedia Commons
Users should not have to worry about licenses or copyright expiry dates. Users should just be asked the author's name/country/etc. From that information, the website should calculate the copyright expiry date and current rights.
Pictures that are reusable except for commercial use (like pictures of sculptures in Japan) should be available for download with a specific license excluding commercial use.

Illustration: Thumbnail of my picture of a 1925 painting realized in France by Catalan painter Joan Miró (1893-1983), owned by MOMAT and kept in Japan, will become public domain in 2053 if my calculations are correct and if laws do not change:

My goal is that:

Wikimedia Commons receives the images as soon as legally possible.
Copyright length calculations are double-checked and organized, I don't have to keep track of all laws by myself.
If the painting is bought by a collector and kept private forever, at least we have a picture that will eventually be released.
If the museum burns, at least we know that a picture exists.
Have my pictures go to the greater good even if I die before 2053. And even if my backup disks fail before 2053, which is probable as well.

This ""open-input dark archive"" would prove vital to preserve:

My pictures of copyrighted public murals in Syria, where they have probably been destroyed by war
My pictures of modern art installations at a annual event after which installations are discarded
My rare picture of a stadium that has been demolished while still protected by France's architecture copyright law
My pictures of copyrighted election leaflets and transient propaganda material

I suggested the idea at WMF and got 53 votes for, 3 votes against. An issue has been created but is stagnating.
","['tool-request', 'licensing', 'images']",
"Dataset of radio stations live streaming URLs, collaboratively curated","
Many radios all over the world are streaming live over the Internet.
Each of them have one or several URLs. I am looking for a curated dataset of these streams.
Requirements:

Name of the radio (ex: ar:راديو هلا: هلا أخبار , en:Radio Hala)
URL(s) of the stream (ex: http://mp3hdfm32.hala.jo:8132)
(Optional) Bandwidth(s) (ex: 128kbps)
(Optional) Genre (ex: All-news)
(Optional) Official website (ex: http://www.hala.jo)
(Optional) Place where the radio's main studio is (ex: 31.962021, 35.940223)
(Optional) URL to the logo of the radio (ex: http://www.hala.jo/wp-content/uploads/2015/03/hala-logo-retina.png)

Notes:

Bonus for any further curated data like wiki description or even aggregated ratings.
The database must be reusable.
Both established brick-and-airwaves radios and Internet-only radios are welcome.

","['data-request', 'audio', 'media']",
Parking Tickets\Citations (impersonified) data for USA cities,"
i've been trying to find data on Parking Tickets/Citations for US cities.
but it looks like it's really a rare occurrence for just a couple of cities like NY, Baltimore and Toronto
My search was inspired by this article 
http://iquantny.tumblr.com/post/76937212765/using-open-data-to-predict-when-you-might-get-your
i even tried calling a couple of US cities but they were quite surprised to hear such a request.
Bottomline, does anyone know any other US cities to open the data on   parking violations?
Thanks!
","['data-request', 'crime', 'parking']",
Database of Android phones with out-of-the-box root access,"

Most Android phones can not be used as root without performing special tricks.
Others can be used as root immediately after purchase, without doing anything special.

Is there a database listing the latter?
","['data-request', 'computing', 'telecom']",
Data request: Multiple networks for multiple observation,"
I am looking for a networked data set for the same set of actors with multiple networks.
These multiple networks may represent different kind of interactions, or the same type of interaction under different conditions.
Any help is appreciated.
",['data-request'],"The CASOS Network Archive has a number of networks that may be of interest. For instance, the 50 Women network tracks friendship networks (three realizations) among 50 adolescent girls.Another resource, if you're into very large data sets, if the Stanford Large Network Dataset Collection, which has social, communication, and citation networks, among others. Some of these are temporal networks.The Siena data set page has temporal networks as well.Perhaps if you provide a bit more information about what you are specifically looking for, you will get more relevant answers."
501c compensation dataset?,"
I know Guidestar offers a paid product for publicly available, practically hidden,  nonprofit IRS 990 filings. 
Does this data live somewhere else? 
","['finance', 'nonprofit']",
How to Set a Range of Data in request URL from DOL API Returning Unemployment Insurance Claims?,"
I tried a request,
http://api.dol.gov//V1/Statistics/OUI_InitialClaims/unemploymentInsuranceInitialClaims?KEY=mykey
, but it returns old data.
How can I set range of data in request url?
","['api', 'labor']",
How to access past data for mobiles,"
I am writing a paper on the variation of mobile prices in last 2 years. How can I get access to the past few year's data on mobile phones?
",['data-request'],
"Coordinates of nearby parking lots, findable by street name","
I am looking for open latitude, longitude data with information about parking lots.
I am looking for data or an API with an open source client library, using which I can specify a street name, and get in return information about legal parking lots on that street.
Especially parking lots in the country Israel, planet Earth.
","['geospatial', 'transportation', 'parking']",
"Where can I download tagged dataset of text related to finance, programming, analytics etc","
I want to create and train a model which classifies a new text content into finance, programming, analytics, design etc. Where can I get enough dataset to train my models?
TIA.
",['machine-learning'],
1840-1900 Income Data in U.S,"
Does income data exist during the 1840-1900 time period (or any span within in) that is at the micro level? Or was this information never collected in censuses, etc?
","['data-request', 'usa', 'us-census', 'income']",It doesn't look like a question on income or earnings was asked as part of the Census during this time period: http://www.census.gov/history/www/through_the_decades/index_of_questions/.
Time series database to test algorithms of anomaly detection,"
I'm looking for a time series database with which I can be able to test some anomaly detection algorithms.
It would be best if the ouliers can be listed on another file in order to evaluate the effectiveness  of the algorithm.
Is there such a database somewhere ?
","['data-request', 'time-series']",You should check out Rob Hyndman's Time Series Data Library.
What happens to the data submitted to the DDL?,"
After working with several of the Missions and implementing partners, the question comes up on what happens to data once it gets submitted to the DDL. For data tagged as Public, does it enter a searchable archive similar to the DEC? Is the intent to make the submitted openly available and downloadable by the public?
","['releasing-data', 'uses-of-open-data', 'usaidopen']",
Can I put a CC BY-SA photo in a non CC BY-SA work?,"
Assuming there are no copyright restrictions on the subject, can I insert a CC BY-SA photo as a figure in another work, for example an academic paper, that is not itself CC BY-SA?
(Somewhere along the line I picked up this idea that CC BY-SA is more like LGPL than GPL when it comes to inclusion in other works. If so, is the difference between inclusion and modification clearcut?)
","['licensing', 'creative-commons', 'photographs']",
OpenFDA: Is there a data source which provides descriptions of the ingredients listed in EAFUS DB?,"
Is there a data source which provides descriptions of the ingredients listed in EAFUS DB?
I have been able to find details from varied sources (PubChem, Wikipedia etc etc) but I need something that explains the presence of a particular ingredient in that particular food.
Searching via regnum (see EAFUS Table) using CFR Title 21 Search leads to mixed results.
Edit: Updated link to EAFUS DB
","['data-request', 'openfda']",
Bug in count in openFDA Adverse Events?,"
When using ""count"" I have found that less frequent counts in a query are often incorrect. My ad hoc workaround has been to always set limit to 999, and only use the first 100 counts.  For example,
the following query 
https://api.fda.gov/drug/event.json?search=receivedate:([20000101+TO+20170101])&count=patient.reaction.reactionmeddrapt.exact&skip=0
indicates there are 13428 reports with patient.reaction.reactionmeddrapt.exact=NEUTROPENIA.
This query 
https://api.fda.gov/drug/event.json?search=patient.reaction.reactionmeddrapt.exact:(NEUTROPENIA)+AND+receivedate:([20000101+TO+20170101])&limit=1 
indicates there are 26220 such reports.
Interestingly, this (with ... replaced by text in previous links):
.../drug/event.json?search=receivedate:([20000101+TO+20170101])&limit=999&count=patient.reaction.reactionmeddrapt.exact&skip=0
also indicates there are 26220 reports.
Is this a bug, or am I missing something?
",['openfda'],
Employment density in the USA (Employees per sq. ft. by industry),"
I am looking for employment density in the USA.
Dimensions needed:

Per industry
Per sq. ft. (per county or smaller could be acceptable too)
Per year if available, otherwise something relatively recent

I guess ""per sq. ft."" makes more sense in cities, areas with too few datapoints would have wider averaging areas.
","['data-request', 'usa']","i think you are looking for the american community survey's summary files?  if you want annual estimates, you will have to settle for geographies with at least 65,000 individuals.  if you can forgo annual estimates, the 5-year pooled file will give you areas down to 20,000 population.http://www.census.gov/acs/www/data_documentation/summary_file/if you want very very small areas and can accept slightly more dated information, use the 2010 census summary file instead.ordinarily i would recommend using the acs microdata (person-level rather than aggregations), but you will get smaller geographies by using the aggregated information.  if you can accept pumas as your smallest area, you can work with acs microdata herehttp://www.asdfree.com/search/label/american%20community%20survey%20%28acs%29"
Where can I find criminal data with basic info?,"
Where can I find a database that compiles US/world criminal data with basic description of the crime? (Preferably with keyword search function)
For example, something like:
Crime: homicide
Year: 20xx
Country/state: xxx
Criminal: husband
Victim: wife
How crime happened: criminal shot victim
","['data-request', 'crime']",
Sorting or populating qualitative data into specified fields from qualitative text?,"
I am trying to process a large amount of qualitative data (a large body of text) into separate fields. I am trying to take a large amount of text and divide or sort it into individual fields.
Is there a way to add ""tags"" or demarcate the text I want to fall into specific categories I want them to go into?
For instance, there is a large paragraph of text with several pieces of information I want to sort into individual categories (e.g. a name, a year, a small blurb about a company). How can I do that? Thanks
","['data-request', 'research', 'parsing']",
"Composite Index creation, using WDI database from World Bank","
This question might sound vast, however I really need some help finding a composite index which I could calculate using specifically World Bank's WDI database.
The concept of that index is not really a matter. It could be about anything, such as e.g., environment, finance, ..., as long as its parameters are included in that WDI list.
I am trying to find a known composite index like Green national product, Happy Planet Index (HPI), Human Development Index (HDI), or even simpler ones if the complex ones cannot be calculated with WDI available data.
My indices knowledge is short here, so please if someone knows about an index formula and can locate its parameters in that WDI list, do suggest that to me.
","['economics', 'worldbank']",
county borders with US county names,"
So I downloaded QGIS and the 2014 TIGER/Line Shapefiles for US counties from ftp://ftp2.census.gov/geo/tiger/TIGER2014/COUNTY/
When I open the shapefiles up in QGIS I don't see any of the county names. Does the TIGER data simply not include county names or is there some option in QGIS that I'm just unaware of?
","['usa', 'geospatial', 'county']","The data is in the Shapefile and the packaged dbf file. In QGIS, you can use the Attribute Table or Identify Feature tools to expose these attributes. Animated GIF below here: http://i.imgur.com/lSXp4Qr.gif"
Official data from census,"
I'm going to collect demographic data from official sources.
There is a list of census sites with informations like license, data format, granularity, direct links, languages, etc?
Will it be useful if shared or data aggregated?
Any other info that will be useful?
I'm going to do some edits to this post, or opening a page on some website (is it possible to make a table here anyway?). So I'm starting list here:

Italy, csv and excel format, city granularity, english available, link: http://dati-censimentopopolazione.istat.it/?lang=en&SubSessionId=06184093-56c2-4f00-a62a-416c934fd65e
New Zeland, Excel format, english language, link: http://www.stats.govt.nz/browse_for_stats/population/estimates_and_projections/historical-population-tables.aspx

","['data-request', 'census', 'demographics']",
Language specific words dataset,"
Where can I find a dataset with all (or the most important) words from a language? For example, I need a dictionary for the Romanian language.
In the first stage just the words, the frequency would be useful also, nothing else.
","['data-request', 'dictionary']","It seems that you're looking for a lexicon, which normally contain words with their inflections, derivatives, frequencies, etc, derived from a corpus of text in a particular language.The only thing that I could find for Romanian is the Romanian WordForm Lexicon, which contains lexical data extracted from the Romanian Balanced Corpus, and it has slightly restricted use. It seems that you need to contact Dan Tufis, who is the maintainer. Information about the lexicon can be found here, including contact information for Dan Tufis, the structure of the lexicon, how to cite the lexicon, etc.You may also be interested in the Romanian WordNet, which contains sets of cognitive synonyms; it is a derivative work of Princeton's original WordNet project for English, and falls under the same jurisdiction as the Romanian WordForm Lexicon.Unfortunately I don't know what is required to use MetaShare (which hosts/licenses all of these documents); it is part of MetaNet, the European Multilingual Technology Alliance."
"Validity, Utility and Cost of Clinical Tests","
Medical tests are characterized by validity, utility and cost:

Validity is the probability that the test results are correct.
Utility is the usefulness of having correct results (e.g. how much life can be gained by taking a test, finding out that there is a disease, and treating it in time).
Cost is, simply, the cost of taking the test.

I am looking for tables which show the validity, utility and cost of some commonly used clinical tests.
I don't need them for clinical use; I only intend to bring some examples to illustrate a theoretical paper about diagnostics. So, the tables don't have to be very accurate or up-to-date.
I found several research papers that try to assess the validity and utility of novel tests, e.g. some genetic or molecular tests for cancer, but they are too difficult for me because I don't have sufficient background in genetics or molecular biology. I need a simpler and more approximate table.
","['data-request', 'medical']",
List of German local politicians,"
I am looking for a dataset/list of all mayors of German municipalities. In particular I am interested in smaller municipalities (<10'000 inhabitants).
I care most about the following data

Age
Party affiliation
Time in office

But data containing partial or additional info are fine too
PS: This is related to this question: German municipality-level data (Gemeinde) on demographics, but since the answers would be distinct I am creating a second question.
","['government', 'city', 'germany']","The elections for the the mayors in German municipalities are organised by the respective states and the Landeswahlleiter of the state publishes the results.For the state of Saarland, the mayor elections can be found here:http://www.statistikextern.saarland.de/wahl/internet_saar/BM_SL/The data contain: Date of election, all candidates with affiliations, detailed vote turnout. They do not contain gender or age of the candidates.For the other states, searching ""Landeswahlleiter <name of the state>"" brings you close to the results. You may need some German knowledge (or at least a dictionary) to navigate the pages; often no other language versions are provided."
German municipality-level data (Gemeinde) on demographics,"
I'm trying to find comprehensive Gemeinde-level data for small (<10'000 inh.) municipalities in all of Germany.
The (joint-)distribution or at least some summary shares of the following characteristics is most important for me:

Gender
Education
Age
Migratory background

I've found some data from the zensus2011 (https://www.destatis.de/DE/PresseService/Presse/Pressekonferenzen/2013/Zensus2011/zensus_pk.html) but this - if I understand correctly - has no Gemeinde-level info on education, and I'm not sure if it's comprehensive (i.e. containing ALL Gemeinden in Germany). I am also happy if you point me to other data sources/Gemeinde-level data sets.
PS: this request is related List of German local politicians
","['city', 'germany', 'census']",
Mapping of Facebook identifier to account creation date,"
Every Facebook user has an identifier, for instance 73209645 or 1000002894239.
Identifiers are given incrementally to newly created accounts.
Some users even boast about their low number of digits. Typically, anyone below 100 is a classmate of Facebook's creator, and anyone below 10000 studied at Harvard.
QUESTION: Is there a mapping of identifiers and account creation dates?
Example:
100030000 < id < 100030000 : Account created between 20080411 and 20080412
100040000 < id < 100050000 : Account created between 20080412 and 20080414
[...]

","['data-request', 'social-media']","This CSV file details identifiers for each month between August 2010 and February 2013:http://metadatascience.com/downloads/code/fbid_accountage.csvColumns explanation:
http://metadatascience.com/2013/03/14/lookup-table-for-inferring-facebook-account-creation-date-from-facebook-user-id/PROBLEM: No data before 2010, nor after 2013.
Any other answer very welcome!"
Where can I find a data set of US Individuals?,"
I'm looking for a data set of US citizens/residents, etc. With data on things such as age, geographic location, gender, income, marital status, etc. The more the better. Where can I find an appropriate set of data?  A sample population made up of individuals.
","['data-request', 'usa', 'medical']",
Microdata from the German Census,"
I am looking for open German census data at the micro or census block level. I am particularly interested in economic/health/educational outcomes. However, I cannot find any in English. Is this open data even available?
","['data-request', 'germany', 'census']",
"Large (n > 1,000) Interval Censored Datasets","
Is anyone aware of fairly large publicly available interval censored datasets with covariates? I would like to use one for demonstrative purposes for an R-package. 
One that comes to mind is the tooth study, (see 'tooth24' in the R-package 'straweib'). However, despite being in several R-packages, this dataset is part of a private study and isn't available for use without permission. Also, it'd be nice to have new datasets in the statistical literature.
","['data-request', 'research']","You can have a look at the European Social Survey. In this survey, household income is an interval censored variable. The survey also provides plenty of variables that can be used as covariates. For the reference year 2012, the complete survey comprises more than 54 000 individuals from 29 countries. The sample sizes for individual countries vary between 752 for Iceland and 2958 for Germany.  The survey documentation has an appendix on the definition of the income intervals. For a given country the income intervals are disjoint. However, each country has its own definition of the income intervals. That means if  you merge the data of two or more countries, the income intervals become overlapping.The data can be used ""without restrictions, for not-for-profit purposes"", as long as you cite it properly (cf. European Social Survey (ESS) - Conditions of use)."
What makes Open Data tools specific to Open Data?,"
What makes some data visualization tools like CKAN, Socrata, OpenDataSoft, and Junar specific to Open Data? Is there anything special about Open Data formats that make it easier to work with in one tool over another? Has anyone done any comparisons of Open Data Visualization Tools? I've searched, but haven't found anything extensive. I saw one that only compares CKAN and Socrata.
",['data-request'],
Temporal discrete data with ground truth labels for clustering purpose,"
I would like to know if there is any temporal discrete data-set available with the ground truth labels. The goal is to test the performance of the temporal/evolutionary clustering methods, such as the Dynamic Topic Model.
","['data-request', 'nlp', 'time-series']",
Potentially missing Plan data from Plan Finder API,"
There have been observed discrepancies between the list of plans retrieved from Plan Finder API (via getIFPPlanQuotes call) and people's independent knowledge of which plans are offered in a particular location.  Some of these examples are documented here: http://hhs.ddod.us/wiki/Use_Case_28:_Verify_accuracy_of_healthcare.gov_Plan_Finder.  Note that the data is consistently missing from both the API and Plan Finder website for consumers.
I wanted to see if anyone else had noticed similar issues.  Does anyone know if the issue might be just a matter of plans not submitting their data to the CMS Enterprise Portal?  If so, is there a systematic way to account for missing data?
",['healthcare-finder-api'],
"Structured demographic, economic and geographic attributes of US States","
I'm looking for long lists of structured demographic, economic, agricultural and/or geographic attributes of US States. For example:
<geo name=""Iowa"" population=3107000 cows_per_capita=1.2* etc=...>
<geo name=""Connecticut"" population=3597000 cows_per_capita=0.2* etc=...>

*Cows_per_capita are my estimates
A great source would be the CIA Factbook (i.e. US), but I don't know where analogous attributes can be found for individual States (also, it's only really structured by 3rd parties - example).
I feel like Wikidata would be also good source, but it seems the attribute lists are limited to qualitative data.

Formats: Appreciated formats are CSV, JSON, XML, .SQL, and even XLS/ODS files.

License: it's for non-commercial use and I'll give plenty of attribution
","['data-request', 'usa', 'demographics', 'state']","The US Census Bureau has an API for most of its datasets, which will allow you to retrieve state-based data in a structured form. You just have to request an API key. They provide examples for each of the datasets - a small and basic dataset like the Population Estimates might be a good place to start. This example shows you what you would get if you select all states and the population and date variables from the 2013 dataset (copy and paste the entire link to get it to work):It's plain text data - the format resembles the list type that's used in Python. I don't know if XML is an option or not.If you want a wide variety of variables, but don't want to query tons of different tables, you can try pulling from the demographic profile tables from the 2010 Census (table DP-1) and the American Community Survey (tables DP02 through DP05)."
Where can I go to get statistics on iPhone thefts?,"
I'd like to know how many iPhones have been stolen since Activation Lock was introduced.
",['police'],
Looking for soccer player data,"
I'm looking for dataset for England clubs' players. No need for the statistics of clubs' win/lose. I'm looking for players' specific statistics. Like number of shoots or goals or position. Preferably if it includes historical data  
Any other clubs/league can be great too. (if the data are rich enough)
Please some share resources 
","['data-request', 'sports', 'uk']",
Where could one find financial big data,"
As part of my thesis on Visual Analytics I need to find a financial dataset to work on. The purpose of the thesis is to analyze a big-data-grade dataset and then visualize it in different ways. However so far I haven't a reliable source of financial big data. Where could one find such data?
",['finance'],"I'm an accounting major and I know that for a number of my classes I've had to use various financial databases that have just tons of information available, but they're pay-services. However, I'd check out what your school has and see what can be downloaded.All publicly traded companies also have to submit annual reports (10-K) and quarterly reports (10-Q) which you can find here: http://www.sec.gov/edgar.shtmlThe Yahoo finance API for Python is also extremely convenient:
https://pypi.python.org/pypi/yahoo-finance/1.2.1
It includes being able to get historical stock information with some very simple function calls.Of course, there's no dearth of sources available since the government kind of makes a big deal about financial data having to be public. This was the number two result on my google search for ""financial datasets"": http://www.kdnuggets.com/datasets/index.html"
Cases where open data has been removed?,"
I'm looking for cases where data (including software) that once was open is not anymore, or was not for periods of several months or more.
I can imagine several scenarios for this, including

Technical problems (e.g. server failures, bandwidth issues)
Legal problems (e.g. uncertainties over applicability of EU database rights)
Social issues (e.g. new management at data producer, financial problems at data host)

I am interested in all of these and would appreciate pointers to concrete examples and attempted remedies. I have seen this related question that addresses the symptom of missing once-open data, but not the underlying causes. 
As for link rot, I am right now only interested in cases where the data is actually not available any more, as opposed to not available on the original location, though distinguishing the two may of course be difficult.
","['data-request', 'best-practice', 'legal', 'software', 'social-process']",
CKAN - ckanext-scheming - Add dataset button,"
I've been following the instructions and the examples to configure ckanext-scheming extension (ckanext-scheming).
I am able to access by URL to the different schemas (as the example shows) that I've configured. Now I wanted to put these links in the main Dataset page in order to choose the schema of the new dataset before is going to be created.
Does anybody know if the extension does that by configuration? Should I modify the CKAN templates to add different schema buttons to be able to creat each new Dataset type? How do I should to modify the template?
","['ckan', 'python']",
search for data by structure,"
Is there some way to search for data sets by structure, for example, I might want to search on the internet for time series data by time period, categorical data, share amount of total, or multiple columns of the above.  In particular, I want to search for (time series, category, share %1, share %2, share %3)
",['metadata'],
List of iOS and/or Android apps,"
I am looking for as large as possible list of app names. The app names can be iOS or Android, does not really matter.
The data is needed for a machine learning solution that requires large number of training examples. I can harvest manually a couple of hundreds but that is not enough.
Spent some time searching on the web and could not find any. Perhaps this information is classified but I wonder why.
",['machine-learning'],
Where can I find actual agricultural contracts?,"
I'm looking for real agricultural contracts, that is actual contracts between farmers and processors (preferably in North America). Any ideas?
Generally I am thinking of contracts between farmers and middlemen. One example that has been in the news recently has been contracts between poultry growers and processors like Tyson and Perdue.
","['data-request', 'usa', 'finance', 'economics', 'legal']",
% share in 3 datasets or portfolios in time-series. Data or API request for my animation,"
I'm looking for an aggregate data set which shows three datasets of related data, and a percentage share for each over time.  So for example, it might show manufacturers share over time for each of 3 categories of product.  I want the shares to total 100% in each category.   Another example might be 3 portfolios of similar stocks over time.  I want this for my cross section visualization of a series of nested shells.  Each axis will be a different dataset--the equivalent of an animated pie chart.  From the middle to the outside will equal 100%.  So 5 dimensional data.
Clarification:  5 dimensions:  Time, categories (companies, for example) and 3 share dimensions, each of the 3 total 100%.  The values of category are preferably the same for the 3 share dimensions (not the share values), but not necessarily.
I'm sorry if this is vague, I don't have a particular type of data in mind.  At least 5 measurements in the time dimension would be nice.  Something cyclical in time would be nice too.  I can munge data.  Would something on data.gov work?  I'm basically a novice at data gathering, and would trade a visualization for data, Thus:
Once the 3D visualization is complete, I will post the visualization in source form here.  Here it is as it now stands: http://coderextreme.net/earth/world.html  I will animate each plane of the cross-section individually over time.
","['data-request', 'api']",
Comparing FDA drug data with other countries,"
We are trying to link the openFDA drug data with similar databases from other countries, and struggling to find a set of identifiers that will allow us to match drugs in different formats.
Can't see a field for the WHO's ATC code in the FDA data, and there are many other unique identifiers - which is best for international comparisons?
","['openfda', 'drugs']",
Traffic Volume/flow prediction Method [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 8 years ago.







                        Improve this question
                    



i have traffic volume data (surrey city, ca) like this

I wish to use Artificial neural network (Deep Learning) or ARIMA to predict traffic flow/volume of the urban area with the use of previous traffic count data. I want to know whether it is a good technique to predict traffic condition, I want to make the data 2013 as training set and the data 2014 as a testing, is it possible to do traffic flow/volume prediction in next time period if only use this dataset or we need other data to support it?
did i choose right method? or which method is suitable for this case
i really appreciate if somebody could help me how to do that.. need guidance, i am new in neural network.. 
","['city', 'machine-learning', 'traffic']",
Federal early childhood education funding,"
I'm trying to find a report of federal early childhood education funding levels by state, by year. Any ideas?
","['data.gov', 'education']",
"OpenFDA: Why is the database updated infrequently, given that recall notices are pretty time sensitive . . . and when is it likely to get improved?","
For instance, last update to their database was on 01. of May. But on other pages I could find two reports that were published in May. So the newest report from their api that I could get is from April. They issue reports weekly. So in this case the reports are old 20 days even though it should not be more than a week old. One peculiar thing I noticed from their reports is that the date when the recall has started and the date when the report is issued are sometimes two months away. 
So for apps trying to use the data to warn consumers about recalls, the user probably consumed whatever they bought over that two months lag. 
",['openfda'],
"OpenFDA API: Why do some recalled items have UPCs listed and others don't, and is that something that would likely get improved?","
I know that UPCs are optional. But I'm curious why when a company recalls all codes, those codes aren't listed. It would make it easier for apps to alert consumers accurately if more UPC codes were listed. 
",['openfda'],
Source of CIA World Factbook estimates,"
Does anyone know if the CIA World Factbook (WF) country estimates are the CIA's own or whether they come from the World Bank (WB) or other sources? 
As of today (2015-05-20), CIA WF's page on, for instance, Ethiopia, has economic estimates for 2014, whereas the WB's figures only go up to 2013. Pre-2013 data on CIA WF match with WB's ones, so I assume that WB is the source for these.
","['economics', 'worldbank']","They answer (partially) in the faq: https://www.cia.gov/library/publications/resources/the-world-factbook/docs/faqs.htmlQuoting them:
What is The World Factbook’s source for a specific subject field?
The Factbook staff uses many different sources to publish what we judge are the most reliable and consistent data for any particular category. Space considerations preclude a listing of these various sources.And:
Why are there discrepancies between The World Factbook's demographic statistics and other sources?
Although estimates and projections start with the same basic data from censuses, surveys, and registration systems, final estimates and projections can differ as a result of factors including data availability, assessment, and methods and protocols. .... and continues."
"Other than for nobel prizes, is there some award's/prize's linked data available?","
Other than for nobel prizes, is there some award's/prize's linked data/rdf/schema available?
",['linked-data'],
"In dbpedia vocabulary, why is class ""City"" not linked with class ""Country""?","
In dbpedia vocabulary, why is class ""City"" not linked with class ""Country"" ?
",['linked-data'],
Is it legal to publish under CC-BY-SA a picture of a recent sculpture in Japan?,"
I took this picture of a sculpture in Japan:  (size reduced)
Would I violate any law if I publish this picture under Creative Commons BY-SA 3.0?
Solid references required (law/decree texts), thank you!
Just in case, for info the plaque reads: 
","['legal', 'creative-commons', 'japan', 'photographs']","This is not really an ""open data"" question, but...The answer is ""you are not allowed to do this""; Japan does not allow commercial photography of otherwise copyrighted artistic works in public places, and the CC-BY-SA license allows commercial reuse, so the two are incompatible.The best resource for this sort of question is the (alarmingly comprehensive) Freedom of Panorama list at Wikimedia Commons; it cites s. 46 of the Japanese copyright law. An English language version is here:I am not sure how precise a translation this is, and if an exact translation then ""exclusively"" might offer a little wiggle room, but otherwise the gist seems fairly clear."
Live database of checksums of all files on Wikimedia Commons,"
Wikimedia Commons is a database of 25,000,000+ freely usable media files to which anyone can contribute.
Contributing a file to Commons takes some work (creating metadata, description, selecting categories), and it fails if the file has already been uploaded by someone else (or by forgetful me in the past).
So, a database of all checksums of Commons files would be very useful, to compare before working on metadata.
Is there such a database?

Free
Reasonably up-to-date, though I can bear with a week or so of delay
API to quickly request whether a particular checksum is already on Commons or not
No need to download the whole database before being able to use it

","['api', 'wikimedia-commons']",Wikimedia Commons has developed a special API exactly for this.Documentation and web UI: https://commons.wikimedia.org/wiki/Commons:User_scripts/File_AnalyzerLet's say you want to check whether your file myimage.jpg is already on Wikimedia Commons or not.JSON:
Running/Jogging Behavior/Activity Datasets (Amateur Runners Preferred)?,"
Does anyone know of open data sets about running behaviour/running activity? I'd love to find somewhere there are histories for individual runners, but even data about large numbers of runners (distance, pace, location, you name it) would be interesting. I would prefer the data to be about amateurs runners if that is possible. I haven't found anything yet, but I'm not an expert in this field
",['data-request'],"ARRS - the Association of Road Runner Statisticians seems like the best place for you to start; there's a lot of data that sounds to me to be exactly what you want.
https://arrs.run/ IAAF, the international association of athletics federations has some interesting data too. here's one example for road running marathon records for senior men outdoor:
http://www.iaaf.org/records/by-discipline/road-running/marathon/outdoor/men"
Public Datasets on Data Breach,"
I try to find datasets related to Data breach. Searching does pull only reports. 
I was thinking to use social media, news search and indexing all data, cleaning, mining but I do not have HW resources for running this jobs.
","['data-request', 'security']","The folks at Information is Beautiful have a constantly updated visualization with data breaches:World's Biggest Data BreachesTheir sources: DataBreaches.net, IdTheftCentre, press reportsRaw data (Google Spreadsheet)Fields available for each breach in the raw data:"
Wind energy data in India,"
I am looking for wind energy data (they can be wind speed at any height or wind energy potential) for India in a GIS format.
Like the data displayed the link below: http://www.arcgis.com/apps/OnePane/basicviewer/index.html?appid=f03b21b359964374a1d4c274de254f26
","['data-request', 'geospatial', 'weather', 'energy', 'india']",
Data management practices,"
Software has code repositories and package managers, so installation and maintenance are done in one line (or click).
What are practices for managing data, instead? Apart from manually organized directories with readme files inside, I found a couple solutions:

drake from Factual, https://github.com/Factual/drake
CKAN from OKFN, https://okfn.org/projects/ckan/
Zotero and other librarian tools, so you save datasets instead of books with them

However, drake is mostly about workflows, not maintenance. And CKAN is server-based solution for which I couldn't find a local ""package manager"".
What would such a package manager ideally do:

downloading datasets from source in one click
supporting multiple formats and conversion
maintaining the directory structure
updating the data from the repositories
supporting aliases for datasets
holding meta information about the datasets
tags

Have you seen anything like this? If not, maybe you'd share your practices of maintaining the data manually?
","['data-format', 'linked-data', 'metadata']",
"How to get list of all items that have a particular property, in Wikidata?","
How collect Wikidata's entities by a certain property?
",['wikidata'],"Assuming you are familiar with SPARQL, Wikidata (not to be confused with DBpedia) has an official endpoint and a page with example queries. The following example lists all countries with the property sovereign state:For more information, please visit official reference for data access."
Supermarket Produce Data Set,"
I'm looking for a dataset that describes various types of fruits. The Supermarket Produce Data Set described here seems like a good choice:
http://www.ic.unicamp.br/~siome/papers/rocha-sib08.pdf
However, I tried using the link provided in the paper and it didn't work (http://www.liv.ic.unicamp.br/~undersun/pub/communications.html)
Can someone please tell me where I can find this dataset or another similar?
",['data-request'],"The dataset is available from this page:
http://www.ic.unicamp.br/~rocha/pub/communications.html
Specifically:
http://www.ic.unicamp.br/~rocha/pub/downloads/tropical-fruits-DB-1024x768.tar.gz"
Is there an API to get label info on veterinary drugs for farm animals?,"
Hopefully it would include species, manufacturer, withdrawal and whether for treatment, control, prevention or growth promotant/feed efficiency - although that info would usually be on the label. 
","['data-request', 'data.gov']",
I'm trying to find international obesity prevalence by year,"
I'm trying to find international obesity prevalence by year.  Does anyone have a source at the country level?
","['data-request', 'medical']",
How to get the name of a Wikidata item,"
Let's say I have a Wikidata item QID Q19675, and want to get the name of that item in Spanish.
While getting a property like P281 postal code is easy, how to get the name, which for some reason is not a normal property? Preferably via the REST API.

","['api', 'wikidata']","You probably want this:https://www.wikidata.org/w/api.php?action=wbgetentities&props=labels&ids=Q19675&languages=esThe API command in English: Get information about some entities (action=wbgetentities), namely the label properties (props=labels) of item Q19675 (ids=Q19675) in Spanish (languages=es).For more details, have a look at the full documentation of wbgetentities."
DailyMed RESTful API,"
I am trying to access the INDICATIONS, CONTRAINDICATIONS, ADVERSE REACTIONS, and WARNINGS field using the dailymed API. http://dailymed.nlm.nih.gov/dailymed/services/
However, I cannot seem to find information on their web services page on how to do this. https://dailymed.nlm.nih.gov/dailymed/app-support-web-services.cfm
I see there are ways to access NDC's, drug names, classes etc, but what I need is the actual monograph-type information that I mentioned above.
","['api', 'medical']","You are looking for the /spls/{SETID} endpoint documented at https://dailymed.nlm.nih.gov/dailymed/webservices-help/v2/spls_setid_api.cfmFor example: http://dailymed.nlm.nih.gov/dailymed/services/v2/spls/1efe378e-fee1-4ae9-8ea5-0fe2265fe2d8.xmlNote, this is not super easy to parse. Welcome to SPL!If you are looking for something simple and clean, check out my previous answer at ' Query medicine descriptions API ' and take a look at suggestion #1 which is MedlinePlus (also from HHS/NIH/NLM)."
Amount of English fiction literature in characters / publications,"
What can be a rough estimate of all the English fiction literature published to date in characters? Or the trends for fiction books published yearly? What can be the public sources for such estimates?
Regarding the second question, I have found this data helpful. But as the data concerns only the relatively recent publications, it would be not so helpful in providing the answer to the main question.
","['english', 'literature']",
Data about Bittorrent usage,"
I'm looking for a robust data set about movies on Bittorrent.  I'd like to understand the popularity of individual titles as measured by the number of users who have a particular title available for download.  I'd also like to understand the overlap between title availability.  For example: 5,000 people might have Independence Day, 2,000 people might have Sleepless in Seattle, and 11 people might have both of those titles.
Is any of this data already published and freely available? If not, what would I need to do to set up some sort of a monitor to harvest the data myself? It has been widely reported that the movie studios do this to enforce their copyright so I'm assuming what I describe is possible.
","['data-request', 'film', 'bittorrent']","Step 1: Write a scraper to build a repository of .torrent files or magnet links. You can also use the magnet-hashes from TPB. Or convert a .torrent file to a magnet-link.Step 2: Pass those magnet-hashes to a script that retrieves the seeder/leecher stats. An example is here.Step 3: Repeat step 2, as many times and as often as possible.Step 4: Occasionally update repo in step 1."
Data about completed prison term by country,"
I'm looking data (preferentially free and open data but I can afford small payments) by country worldwide on the percent of population that have completed a prison sentence or were sentenced.
I only found statistics about people who actually are in jail.
","['data-request', 'releasing-data', 'crime', 'global']",
"Why is CSV ""better"" than Excel in 5 star open data schema?","
I am reading about the 5-star schema for Open data. I noticed that the data ranked with three stars are CSV files while data ranked as two stars are like Excel documents. I wonder why is that?
Is excel less quality than CSV?
Is it because for excel we need a specific application to open it while we can process CSV easily using any text editor?
Edit
I have been reading about it and I found the followings: **I am not sure if this is correct or not**:

The two-star-data is data that is formatted under a Close Format or Proprietary Format, which is a way of storing the data according to a specific encoding format that is either secret or not allowed to use in an open license.
The three-star-data is data that is formatted under an Open format or Non-Proprietary Format, which is a way of storing the data according to a specific encoding format that is allowed to use by anyone.

Is that correct, please?
","['uses-of-open-data', '5-star-scheme']",
Individual-level open geographic data on international human trafficking,"
I was actually trying to find some open source data on human trafficking. Basically, I was looking for any individual level data where say an individual was picked up by some law enforcement agency and then ask for their country of origin. I believe the International Organization on Migration has data like this, but they don't release it.
I have been looking around and there only seems to be summary statistics given at the country level. I was hoping that someone might be able to direct me towards a good source. I am a grad student in statistics, so was hoping to do some meaningful analysis.
Update:
The closest thing I have been able to find so far is some data from the European Union. There is a report from the European union based upon input from the legal agencies in different member countries. Here is the report link. On page 36 there is table 3 which provides info on the human trafficking arrests from each nation. So this data at least shows the country of arrest and the country of origin for the victim. 

The problem with this data is that it does not show the path of each victim, so I don't know the routes. 
Thus, I am still searching for additional info.
","['data-request', 'crime']",
World Bank via Pandas - looking up country regions,"
I am getting country data from World Bank via Pandas Remote Data API.
Is there a way to get metadata for each country? In particular:

Is it a country, or a region/group (e.g. Arab World or Upper Middle Income)?
If it is a country, to which region does it belong? 

","['api', 'worldbank', 'python']","You can pull the metadata directly from this URL (xml returned by default):It looks like it has what you need. Regions/groups are treated like countries but you can distinguish them based on empty or ""NA"" field values."
Is there a public web service that will provide hourly forecasts of the solar radiation (irradiance) for a given location?,"
We are looking for a weather forecasting service (ideally free) that will provide hourly values for at least the next 24 hours. In addition to the temperatures, we need values for the solar radiation (aka irradiance), or possibly illuminance.
http://www.wunderground.com/ provides such a service and their first tier is free, but does not provide data for the solar radiation.
Is there such a service somewhere?
","['data-request', 'weather']",
Tourism/survival sentences in most languages,"
I am looking for the first 50 or 100 sentences/words that an English-only-speaking tourist would learn when staying in a non-English-speaking country for a few weeks.
For instance, the first few words would probably be translations of ""Hello"" and ""Thanks"" then maybe numbers and survival sentences like ""Where are the toilets?"", then maybe transportation/time/colours/local food.
Requirements:

Must have the word in local script, the English meaning, and pronunciation in either IPA or English such as asah-lomu ah-lay-koom or both.
Must be freely reusable, as I intend to transform this data into flashcards and redistribute them (freely under the same license)
At least 30 languages, the more the better.

","['data-request', 'language', 'dictionary']",
"What does the second ""rule"" of linked data mean?","
I am reading the four principles for linked data.
the second one is 

Use HTTP URIs so that people can look up those names.

I couldn't understand it. I tried to read some on internet but still didn't understand it.
I understood that the second rule is to give description to the names that has uri, and which was identified in the first rule
is that correct please?
",['linked-data'],
Is there a database that provides metadata for products with barcodes?,"
I am looking for a database (free or paid, but I prefer a free one for now), that contains metadata of products such as cell phones, tv's, etc.
","['metadata', 'products']",
Context-aware dataset of movies or music,"
Looking for access to context aware dataset(s) of movies or music.
Context aware dataset should contain user related information, such as user gender, mood, time, social, location, weather, emotions as well as item related information like genre of movie/music, year, director etc.
","['data-request', 'licensing', 'language', 'programming', 'music']",
Where can I aquire global wind (speed and direction) data?,"
Where can I acquire global wind (speed and direction) data? 
Preferably in some kind of GIS format and free of charge.
Cheers
","['data-request', 'geospatial']",
Looking for neuroinformatics related public datasets,"
I need to work on a research project in big data analysis. I am very interested in neuromarketing, user experience and neuroinformatics. I've searched for an interesting public dataset for my work but still haven't found one. I found one dataset: LSW dataset, but this doesn't seem to be what I'm looking for. Please help me to find some suggestions or links to download free and open source public data sets on neuromarketing and advertisements.
by using neuromarketing data i plan to find out some psychological behavior patterns between Online marketing and Web UI designings. so I'm looking for ""online ads and number of click it had"" or ""website index pages with number of visitors"". and better to have region vice localized data.
Thanks in advance.
",['data-request'],
Datasource for regression model prediction based on micro/macro economic factors,"
I am trying to work using Amazon machine learning, but the data set that I have is small. The model I want to build is for regression based predictions and the domain I am aiming for the data set to belong is financial, say stock price prediction, price and demand prediction based on macro/micro economic factor.
i am looking for a data set that contains the factor that lead to a particular value; say for example- i want to predict the value of 1 unit of polyster after 1 year, the factors over which the yarn price depends are say - figures of IIP , prices of crude oil, GDP of country, Inflation etc .. so i want a data set that contains the quotes of these factors too on which the final price depends.
The reason why i am not arranging the data by my self is because i dont know all the factors that contribute to a certain predictive price.so i was thinking if some expert have already given the data set for a particular problem class then it can be used for my purpose.
",['data-request'],
"Working with Sample Surveys, Statistical Packages, and Fixed Format ASCII Data (.dct ,.do, .sas, .sps) and .dat","
US Department of Education sent me National Household Education Surveys Program data via cd-rom and I'm looking for tips/software/best-practices here for converting/viewing/manipulating this data. Also a basic, if not thorough understanding of the data formats that it contains and what software I can use with them.  
It comes with its own software, but it won't work on win > 7, so I can't use it...and I'm assuming I wouldn't want to anyways.  
The data consists of a few folders, two in question are ASCIIProg and DataFiles:  
DataFiles consist of .dat files, which a search tells me ""DAT, or Data Files, contain generic data which may be utilized or referenced by other programs.""
so I'm assuming its like a typical ASCII file and/or tab-delimited/comma-separated file.
If I'm right, then no worries, I'll quickly convert them to .csv  
ASCIIProg:
consists of files with .dct, .do, .sas, and .sps extensions.
I'm vaguely aware of .dct (dictionary) and that .sas and .sps are (proprietary?) formats that the government utilized heavily in the 1990s.
A quick search tells me that:
Fixed format ASCII with a SAS program - .sas
Fixed format ASCII with an SPSS program - .sps
Fixed format ASCII with a Stata program - .do
So essentially these are all files for specific software?
Seeing as how they are ASCII, can I easily convert them to .csv?  
Any thoughts here are greatly appreciated!
I'd like to know exactly what the programs/software/extensions are so I can find documentation and get a clear picture in my head, as well as know exactly what I can, can't do when converting, etc. Also, with that better understanding I/we can clean up this question for greater accuracy/relevancy.  
Hailing from Virginia, I really only care about the commonwealth's data, but as an added bonus, I'll be sure to upload everything in a fresh datahub.io repository for everyone's use.  
Apologies in advance - I did do some homework here, but after finding multiple definitions for .sas and .sps, I quickly backtracked from the rabbit hole and came here to maintain my sanity.
","['data-format', 'conversion']",
"Typical random keyboard input, in various cultures","
Wikipedia receives a huge number of text additions per day, each falling in one of these categories:

Good-faith addition: in 1789
Subtle misinformation: in 1790
Spam: in any CostMart store
Immature vandalism: in YOUR MOM lol
Random keyboard input vandalism: wqefeqesfdqwedqw

This question is about case 5 only.
A detection algorithm considers:

The behavior of human fingers
The keyboard layout depending on the device (desktop/mobile/etc) and the culture (QWERTY/AZERTY/ЙЦУКЕН/InScript/Arabic/etc)

To train/test the algorithm, I need large quantities of random keyboard input.

At least 5000 strings
Bonus if for each string the device and culture is known, but it is not strictly required

Example:
kdakllkdkldslkdskds, QWERTY
あけさにめはよたかひや, FSKARENテンキー

",['data-request'],
Publicly available faces dataset with height and weight metadata,"
Are there any publicly available faces database where each face is annotated with the person's height and weight?
There is the MORPH dataset but it is not publicly available.
","['data-request', 'images', 'faces']","If you're willing to get your hands dirty, there are plenty of websites out there that post mugshots of arrested individuals.  Many of these come with height and weight attributes.  With a little scraping you could have as many photos as you could possibly want.  You might have to deal with watermarks and artifact removal though.As an example, here is a collection of mugshots from Polk County Iowa.  It even allows filtering by height, weight, age and gender."
Is the Ontology of the Semantic Web dead? [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 8 years ago.







                        Improve this question
                    



Is the Ontology of the Semantic Web dead?
I am developing a work plan for my thesis about ""a knowledge base through a set ontology for interest groups around wetlands."" I have been researching and developing ontologies this but not sure many things, eg I have some doubts?
Which will be the modelling language for ontologies? Methodology for ontologies which is better, or otk methodology? Is there any program that does an analysis of the textual corpus and extraction of the specific terms of the domain of study as does Cratilo 2 (software developed by professors Jorge Antonio Mejia, Francisco Javier Alvarez and John Albeiro Sánchez, Institute of Philosophy the University of Antioquia. Cratilo enables lexical analysis of texts, identifying the words that appear,) its frequency and its location in the text. Through a process of recognition, Cratylus identifies all the words in the text and builds a database becomes the draft analysis of the work.
There is another program to fill or find terms like Cratylus? These relevant terms Catrilo finding can be used to fill a knowledge base? that there are alternatives open semantic framework and performs this framwork
what are the advantages of protecting, what alternatives are there? Automatically creates the RDF OWL and XML? how does it work Tails? JENA? SESAME?
",['ontology'],
Is there an API for USAID's Aidtracker-Plus?,"
We've seen Aidtracker+ implementations at some country Missions. Is there an API available to access the underlying data? 
Alternatively is there a way to pull the data out of the SalesForce backend similar to what the American Red Cross is doing? (https://github.com/AmericanRedCross/GeoForce)
","['data-request', 'iati', 'usaidopen']",
Eating habits and attitudes,"
I have a question, which is along the lines of a previously asked one, regarding people's eating habits, ideally a ""food journal"" type of thing that has data from individuals showing what they ate at what times/days.
However, I also need information with regards to their attitudes towards the food they consume, e.g:

obsession about calories,
avoidance of fat/sugar/processed food out of fear of its perceived un-healthinesss,
rigidity,
etc (think along the lines of eating disorders, particularly specific avoidance/restriction or orthorexia if someone is familiar with that)

Ideally this would be on the level of individuals as well as in conjunction with demographic data.
I want to try out something new for my Dissertation and thus lack knowledge with regards to where to get high quality open data from.
","['data-request', 'medical', 'food']",
Global HIV Incidence Raw Data,"
All information I can find on global HIV incidence broken down into male/female categories is in the form of already processed charts. I've attempted to find a raw HIV dataset that breaks down into a number of categories (drug user, gender, country etc) however these datasets seem to require that I am affiliated with an academic institution and that I am conducting a study, which must be authorized (eg: [1]) (I don't fall into any of these categories, as this project is an independent curiosity of mine).
Would anyone know how I could go about getting access to raw, categorized, global HIV incidence data where I'm not required to be affiliated with an academic institution?
","['data-request', 'medical', 'global']",
Art Market data,"
I'm looking for art market related data for research purposes - especially sales in auction houses. I know there are sites like artprice or its free equivalents, but what I'm searching for is something like a structured database, CSV files or linked data ready for further processing, since crawling these sites is forbidden. Any suggestions?
","['data-request', 'finance']",
ISO 3166-1 and ISO 3166-2 data plus borders (e.g. as kml),"
I am looking for a free or even commercial data source for ISO 3166-1 and ISO 3166-2 data, ideally with border data (e.g. in kml). The ISO 3166-1 and ISO 3166-2 data should contain the hierarchical relationships as shown in the following picture:

","['data-request', 'geospatial', 'metadata', 'geocoding']",
Linked Data vs Linked Open Data,"
I do know what Linked data means and what Open data means.
However, today I found that there is something called Linked Open Data
Is it the same as Linked data or not please?
",['linked-data'],"In 2006, Tim Berners-Lee defined the four rules of Linked Data:In 2010, he introduced the 5 star rating system for Linked Open Data:Both is published on his personal note, Linked Data - Design Issues, where he also explains:Linked Open Data (LOD) is Linked Data which is released under an open licence"
Names of popular products found in retail stores,"
Where can I get names of physical products found in retail stores, like:
""Coca-Cola Zero"", ""LEVIS 501 ORIGINAL FIT JEANS"", etc...
I know there are a lot of products in the world, so it can be limited to a single country, or limited to major brands, or limited to wide-circulation products only, but the less limited the better.
Translations should be considered as the same product, for instance بلاي ستيشن 4 is the exact same product as Playstation 4.
","['data-request', 'products']",
Download East African NDVI data for 5*5km grids,"
I would like to download NDVI data
http://www.mathworks.com/examples/mapping/529-exporting-images-and-raster-grids-to-geotiff
",['data-request'],
Soccer leagues/teams/players API,"
I wanted to know if anyone knows of a website that provides free information related to various soccer leagues.  I am creating a C# application. I'm interested in the following:

table each league
information on the players of the teams
information teams
Any other values that provides the site

Currently I draw these data with a parser on a website, but I would like to speed things up, leaning to the databases that are possibly free, but I am also willing to pay a small amount for the data.
","['data-request', 'api', 'sports']",
Real world social network datasets with ground-truth non-overlapping community structure,"
I am looking for social network datasets which have got non-overlapping community structure preferably ground-truth otherwise would also suffice. I need it for my research work. I could find some on http://snap.stanford.edu/data/index.html but they have got overlapping community structure. Please any suggestions??
","['data-request', 'network-structure']",
How to exclude datasets with no data on datahub.io search?,"
datahub.io contain many datasets, but some of it marked This dataset has no data
For example http://datahub.io/dataset/industrial-production-and-turnover-indices or http://datahub.io/dataset/esis
How to exclude datasets with no data on datahub.io search?
",['ckan'],
Road surface roughness,"
Is there some open data about road surface roughness?
","['data-request', 'geospatial', 'openstreetmap']","In Italy there is a project named SmartRoadSense, started on February 21th, 2015. The goal of this project is monitoring of Italy's road surface (487,700 km [1]) and all results are open data.Now, after nine months, has been collected more than 24,000 km of open data. In the site smartroadsense.it you can see two uses of this data, and donwload it.The project use a simple Android application that senses the roughness via LPC coding (for more detail read the paper SmartRoadSense: Collaborative Road Surface Condition Monitoring). In the roadmap there is also the development of the application for the others platform.You can see a short movie which showing the four phases of the SmartRoadSense process: sampling, map matching, aggregation, and presentation here.The data are available at smartroadsense.it. You find an only CSV file with six fields:[1] ""Italy."" The World Factbook. Central Intelligence Agency, 2013."
Where can I get stats on mouse clicks?,"
I'm interested in finding out whether people tend to click the mouse faster when it's cold or hot, if the time of day affects the speed of mouse clicks, and lots of other information like that.
Does anyone know where I can get this kind of information?
",['data-request'],
Where can I find machine-readable data on which US states and DC border each other?,"
I'm hoping to avoid compiling a dataset like this manually. Ideally, the dataset would look something like this:
state1   state2   share_border
NY       NJ       yes
NY       CA       no

etc. I'm not very knowledgeable about mapping, because otherwise I could probably back out this data from the Census cartography data. 
I realize their are some ambiguities here, because (for example) the borders in the Four Corners region could be interpreted differently, but if I have most of the data I can resolve that based on the needs at hand. 
","['data-request', 'usa', 'geospatial']","Another way to look at it is if the states are within a small distance of each other. Using PostGIS, you can do this rather easily:I have a data table of states in my CartoDB account and ran that query. Depending on the data, you can choose a more accurate number than 500 meters as I did here. I pulled the state polygons from CartoDB's data library. The state polygons were originally from Natural Earth Data.This produces a data table like this:
"
California water district boundaries,"
I'm looking for California water district boundaries, both private and public in any geographic format.  
This data appears to be available on Data.gov HERE and HERE, but the links are dead.  I've contacted all the email addresses linked to from the metadata, and some other folks I found by both email and through Twitter.  
The contact email is listed as metadata@gis.resources.ca.gov but delivery to that email address fails permanently.
Also, don't bother contacting Lorri Peltz-Lewis who is mentioned somewhere in the metadata.  She is helpful, but no longer works at the U.S. Bureau of Reclamation.
I've emailed the U.S. Bureau of Reclamation with no response so far.
If anyone has this data, or is willing to help me out I would greatly appreciate it!  I was about to give up, but have some very cool map visualizations in mind.
EDIT:  If anyone else is looking for this data, it's now converted to GeoJSON and available here.  Make sure to read the README.md file.
","['data-request', 'data.gov', 'geospatial']","Update:
this data is now available on open data se's datahub.io account, here:
http://datahub.io/dataset/california-water-district-boundaries For those times when data was posted, but has since disappeared, you can try The Internet Archive's Wayback Machine.  It does have some limitations, as it won't violate a robots.txt file and it may not archive large files, but in your particular case, it seems to have copies of the two files from 2009-2010:https://web.archive.org/web/%2a/http://projects.atlas.ca.gov/frs/download.php/245/usbr_wat_dist_state_2003_03_25.ziphttps://web.archive.org/web/%2a/http://projects.atlas.ca.gov/frs/download.php/26/usbr_wat_dist_priv.zipI've verified that the most recent copies both unzip without errors, but I haven't done any other testing to determine if they're intact / complete."
Healthcare.gov PlanFinder API v2.0 still accepting requests?,"
I would like to get 2014 off-exchange plan data from the Healthcare.gov PlanFinder API.  I have read (on this site) that the current version v3.0 does not accept insurance effective dates before 1/1/2015, and that v2.0 of the API, which is deprecated, is the version to use to collect 2014 data.  I have recently tried to use v2.0, using the sample query provided on the site, and receive a response about the page not being found and then some text about needing to at least fill in e-mail and phone number.
I have successfully used v3.0 of the API and did not need to provide an email address.  I would like to know if it is still possible to get 2014 off-exchange data from the site.
Thank you.
","['data.gov', 'api', 'healthcare-finder-api']",
"Interesting, open datasets for scoring of location attractiveness?","
I'm considering the problem of assessing attractiveness of location of ""some stuff"". I don't want to provide too many examples since they could bias your ideas and suggestions... Say, we could evaluate attractiveness of houses (measured by their price) with respect to their characteristics (for this example I've found some data, I'm looking for some more interesting options).
Any suggestions and examples of datasets for this problem?
","['data-request', 'geospatial']",
Queue (people waiting) management system data,"
I was looking for the data from electronic ticket systems (like those in hospitals or government units) and unable to find any.
It'd be cool to have raw data, namely, the time when ticket T was issued and time when it was called for. That'd tell a lot about workloads of the unit and its bottlenecks. Maybe workloads are unbalanced and visitors should be recommended to come in certain hours, when there're no long lines.
Relevant APIs would be great as well.
Anyone saw data like this or similar?

","['data-request', 'api']",
Where can I get in-car camera data?,"
I want to write an application which takes a single image an classifies each pixel as ""street"" or ""not street"". To do so, I need training / testing data. One possible application is for self-driving cars or car assistance systems. So the camera is within the car and looks at the street from a drivers perspective.
Where can I get such (preferably labeled) data?
(I have found KITTI, but the site seems to be down at the moment and more data is always better.)
","['data-request', 'images']",
The graph of the web: the dataset of links between web pages,"
I was looking for the dataset of links between web pages and found these options:

Common Crawl: Public web crawling data. It includes ""the HTTP headers returned and the links (including the type of link) listed on the page."" AFAIK, it's the most comprehensive and up-to-date source.
SNAP: Small samples of the web graph (up to 7M edges). Including Google's version.

Are you aware about other sources of the similar data? Preferably comprehensive, with big coverage, rather than frequent updates.
","['data-request', 'web-crawling', 'internet']",
Open content health tips that I can embed in my app/website,"
I am looking for open-source or publicly-available health tips for my app. I am so far not successful in finding any thing alike.
Example of a health tip:

Title: Carrots are good for your health
Body: Did you know that carrots get their bright orange color from β-carotene? α and β-carotenes are partly metabolized into vitamin A, providing more than 100% of the Daily Value (DV) per 100 g serving of carrots.
License: CC-BY-SA-3.0

JSON format would be ideal, but other formats are OK too.
","['data-request', 'api', 'food']",
Phonemic & Syllabic N-Gram Distributions of the World's Languages,"
I am interested in doing some typological analyses by measuring the redundancy and IE entropy across languages in the phonemic and syllabic domains.  I've searched for quite a bit but could not find well documented frequencies of phonemes and syllables (preferably using IPA) across major world languages.
A tool to convert text corpus to phonetic and syllabic transcriptions would also be useful!
","['data-request', 'language']",
"Downloadable smartphones data (name, specs)","
I'm searching for product data, right now I only need smartphone data. I need like every smartphone name and specifications like width, CPU speed, etc. Now I found some reference to semantics3.com which would be perfect, but the only problem is is that they don't allow you to download the data. For multiple reasons I really need to be able to download the data.
Does anybody have more info on this? Is there someone who provides a downloadable dataset like that? Or maybe do the manufactures like Samsung etc offer their smartphone data themselves? I couldn't find any real info on this topic so help would be very welcome. If there is nothing downloadable, would it be legal to scrape it?
Okay so lot's of people recommend scraping for example wikipedia and dbpedia etc. My issues with that however is the fact that the data is not really good organized and also not very complete. So my main question now be  1: ""Do manufactures offer their data?(Like samsung offering a list of smartphones with their specs"" 2: ""Is scraping the website of a webshop or smartphone-comparision website legal, if they have not defined anything about scraping in the Terms?""
","['data-request', 'products', 'europe', 'telecom']",
Recent Macroeconomics dataset of all countries in the World,"
I need a dataset that contains recent macroeconomics attributes for countries. I have tried to make my own by joining Wikipedia tables on GDP, GDP per capita, population, poverty, imports, exports, life expectancy, illiteracy rate, external debt, number of internet users etc. However, the dataset is not very consistent with regards to the sources and timestamp. It would be great to have at least somehow consistent dataset including but not limited to the above mentioned attributes. 
","['data-request', 'economics', 'county']","International organisations provide this kind of data. As you want to cover the whole World, have a look at organisations with the same geographical scope:The World Bank has a database that covers a wide range of topics.  If you are more focussed on economic indicators, you can also have a look at the World Economic Outlook Database of the International Monetary Fund (IMF).Both sites allow you to view the data online as well as to download it further uses.The United Nations Statistics Division also has a couple of databases on various topics."
Where can I find adult abduction victim statistics for the United States?,"
Usually, I can go to the National Crime Victimization Survey's Website for victimization data, but adult abductions are so rare that the Survey doesn't have a category for them.
",['crime'],
Is there a time series data set that includes employment information at the neighborhood level?,"
I am looking for neighborhood level data on employment statistics. Specifically, I would like the number of unemployed individuals and the number of individuals who found jobs each month for each neighborhood. I would prefer to define ""neighborhood"" as geographically small as possible (I'm thinking census tract). 
If there is a data set for just one city (Chicago or New York), that would be good enough. 
","['data-request', 'us-census']",
Time-Series data viewer,"
Looking for a way of visualizing public power generation data. Typical data set has 1–5 years of hourly data, and anything up to 30 columns. Needing to pan and zoom, and perhaps select sections. Needs to run on Linux.
The sometimes recommended TimeSearcher 2 is very shaky under Mono, and has unusual data format requirements.
EDIT: I'm looking to compare years of hourly generation data against regional demand. Some of the data streams may not have corresponding frequencies. I'm not looking for much programming input, as most of the analysis will be visual, so zooming and panning are important. There's unlikely to be a pre-made importer for the XML format used by the particular ISO, so I'd likely be spending the programming time on that. Not sure if I need any stats capabilities, though rolling daily/weekly averages/minima/maxima could be helpful. 
I'm potentially going up against a very polished but misguided speaker in a few days who is using an entrenched industry position to ensure that expensive, polluting energy remains the status quo.
","['tool-request', 'time-series', 'visualization']",
Water level historical data for California,"
I am looking for data attesting for the variation of fresh water availability in California over the years (ideally 20+ years). For instance river levels, river throughput, wells levels.
If data is not available for California, similar USA data is OK too.
Bonus if the data can be easily used from Python
","['data-request', 'data.gov', 'json', 'csv']","If you're okay with talking to people, you might want to contact the chief of the Media & Public Information branch of the California Dept. of Water Resources at (916) 653-9712"
Cumulative income by decile,"
I was wondering if anyone knows of a data source to get national-level cumulative income accruing to each decile data for different countries.
The data used to be available on Povcalnet but I can't find it there anymore.
","['data-request', 'economics']",I was wrong it's actually still freely available on Povcalnet.http://iresearch.worldbank.org/PovcalNet
where i should get USA water historical data for data science in python?,"
I am searching for particulate domain name they provide water data so I can scroll all data for my application.For weather i am using wunderground.
",['data-request'],"usgs water has some historic, and real-time water data
http://www.usgs.gov/water/"
"Database of powered mobility device (wheelchairs, etc) activity logs?","
I would like to know if there exists a publicly accessible collection of activity logs of powered mobility device usage by elderly/disabled individuals.
Specific contents I'm after are user input data such as joysticks etc, and location information in Cartesian co-ordinates or in some representation convertible into a Cartesian co-ordinate system.
","['data-request', 'medical', 'transportation']",
How much data/information should be open? [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 8 years ago.







                        Improve this question
                    



How much information should be published for public. Implementing partners deal with beneficiary data. Should it be open to all? To what extent?
",['usaidopen'],
Where to download dynamics demonstration videos for motion analysis?,"
I'm looking for videos of demonstrations/experiments of dynamics for download. Also they should be clear and of good quality.
I want to use them in a video analysis program (https://www.cabrillo.edu/~dbrown/tracker/). Ideally, they should be
Camera on tripod to fix origin.
plain background for tracking objects
be well lit - should have shorter shutter speed, ie less blur
have decent resolution
be at least 30 fps
be available for download
Some sources are
MIT - http://video.mit.edu/watch/double-pendulum-6392/
Youtube, for example, 
But these aren't available for download, and aren't always up to the lab standards above.
","['data-request', 'video']",
Has there been a spike in the birth rate in Germany?,"
About 40 weeks ago Germany won the FIFA World Cup. At the time I thought there would be a noticeable jump in the Birth Rate there. I've been searching for current information but I can only find statistics as of 2014. 
April 5 would have been 40 weeks after the world Cup win. I'd like to know when 2015 birth rate data is available, so I can see if there been a spike in the birth rate in Germany.
","['data-request', 'germany', 'demographics']","It's much too early to carry out this analysis today. As you say, the 40 weeks period has just passed by. You should not expect the data to be ready in real-time. I am even surprised that you have already found data for 2014. I had a quick look at the two authoritative sources for this kind of data.At the time of writing this answer, Destatis, the Federal Statistical Office of Germany, has only data up to 2013.Eurostat, the statistical office of the European Union, has monthly data on live births. For Germany it has data for January to April 2014. But these figures are flagged as “forecast”.As a conclusion I think that you will have to wait some more months before you can do this analysis."
source of character-level ngrams that include spaces,"
I'm looking for a source of character-level ngrams and counts that include spaces. I've found character-level ngram datasets, but they don't include spaces. Ideally, the dataset will include up to 8-grams and be based on a broad swath of English language text.
For example, ""the quic"" should be one of the 8-grams in the dataset.
","['data-request', 'language', 'english', 'corpora']",
"Free heightmap (elevation?) dataset for Kraków, Poland?","
Is there a freely available (governmental?) heightmap (=elevation?) dataset for Kraków city (in Poland) with horizontal grid ~5m (or better) and vertical resolution ~ +/- 0.1m? Ideally, it would include building heights (i.e. not ""ground level"").
If you don't know one, at least do you know of some good open forum where I could ask such a question with some hope of getting an answer?
Sorry if that question doesn't use proper terms and/or is too unclear, or otherwise totally ridiculous; I'm totally unexperienced in GIS.
","['data-request', 'geospatial', 'poland']",
Forbes.com writer looking for up-and-running examples of data driven applications that improve human services in government,"
I am a writer for Forbes.com / Forbes Insights. 
I am looking for examples of how data is being used to improve the quality in the government provision of human services provision in: 

Child Welfare
Income Security  
Nutritional support   
Employment training/work   
Seniors/aging populations   
Housing/homelessness    
Disability   

I am looking for proven (applications that are up and running in state, local or federal government locations) examples -- although beta counts!!! (So long as a real government agency is testing it!) 
I am also looking for thought leaders -- gurus with credentials -- who can speak on the subject of how data can improve human services in government. 
Are you a good candidate for an interview for this report?
","['data.gov', 'uses-of-open-data']",
Reference data set for benchmarking string comparison algorithms,"
Recently, I have implemented an extension to the classical Levenshtein-Damerau and Gotoh (aka ""affine gaps"") string matching algorithms. To evaluate this modification, however, I need a large (in terms of number of examples) and broad (in terms of word meanings) data set with word pairs in the form of correct spelling, modified variations. The modifications might result from abbreviation, spelling errors or the like but not from artificial contamination.
In other words: I'd like to compare my string matching algorithms with the current state of the art by using correctly labelled real world data. Do you know of any sources, where I can obtain not only the polluted, misspelled etc. data but, along with it, correctly spelled variants of the words?
I have already looked into the data sets mentioned on pp. 65 in 'An Introduction to Duplicate Detection' by Felix Naumann and Melanie Herschel (i.e. Cora Citation Matching, an enriched freeDB data set from Hasso-Plattner institute, and data from scientific publications that has been manually clustered at the University of Trier) but I'd like to apply my tests to as many different data sets as possible.
","['data-request', 'programming']",
"Open data of 1 million or more names, for fuzzy matching experiments","
I am doing some experiments on fuzzy matching and need a set of 1M or more names.  They can be anything, basically: people, plants, addresses, concepts, as long as they look real, i.e. not synthetic and there are lot's of them.
","['data-request', 'names']","Wikipedia let you download the data conveniently, without API limits, so you can get the titles of their 4M+ English articles. Depending on your needs, you can try other languages as well. Seehttp://meta.wikimedia.org/wiki/Data_dumpsIn particular, file *-all-titles-in-ns0.gz.These are domain names, though not sure it meets your requirements.http://s3.amazonaws.com/alexa-static/top-1m.csv.zip"
OpenFDA Data: Labels with Boxed Warnings,"
I'd like to integrate boxed warning information from SPL with the Pillbox Engine so Pillbox users and developers can 1) know when a product has a boxed warning and 2) have access to the boxed warning text.
I haven't been able to determine the syntax to provide a set_id and receive the boxed_warning text, if it exists for that label.
To start, this call returns a label with a boxed_warning, but it appears to have a different set_id.
https://api.fda.gov/drug/label.json?search=exists:boxed_warning+AND+set_id=3af2e694-6fea-46cf-b680-9ee0b0c83c88
 ""spl_set_id"": [
      ""3fcabf90-357a-4a06-b680-9572dc28bcfe""
    ],

","['openfda', 'api']",
"Data about spoon usage when eating spaghetti, by area","
Some people usually use a spoon when eating spaghetti, and some do not.
The proportion seems to be dependent on the country/region.
Has any data been published on the topic?
Preferably raw poll result files, but aggregated data as CSV is OK too.
Bonus if the data is also sorted by age group and by formal/informal setting.

","['data-request', 'food']","No dataset was available, so I got 300+ people to answer a questionnaire about the topic.General view of the data (green=spoon, red=no spoon):"
"Database of all mailing addresses in France, and their coordinates","
Where can I find all currently valid mailing addresses in France?
As well as the latitude/longitude for each.
","['data-request', 'geospatial', 'geocoding', 'address', 'france']",
Smartphone Image sensor brands and utilising devices,"
I am seeking a list (or lists) of smartphone image sensor brands and which smartphone(s) they are used in.
So far, I have found the following page for Sony's Exmor image sensor range, there are lists of sensors and devices (phones and cameras) that employ that particular image sensor brand - but the lists are incomplete.
","['data-request', 'products']",
Website visitors statistics,"
Alexa and Quantcast (and their alternatives) offer limited web statistics for free. For example, Alexa shows one-year data on a website's rank in Alexa's top. You can also download their million of most visited websites.
As for visitors, comScore MMX sells their estimates of the audience major web serivces have.
Is there any open alternatives to these sources? Those that have traffic estimates for websites, perhaps with demographics or geography?
","['data-request', 'internet']",
open Big Data to solve cancer epidemiology challenge,"
I am a doctor and I am coordinator of a project that will call for innovative projects around challenges in the field of Big Data applied to Cancer Epidemiology. The specifity of the projects is to use open big datasets in order to serve them through an API for the callees of the project. So we're looking for these kind of sets
Are there sites that indicate open big health data sets links ? (knowing we're searching for heterogenous sources : clinical, behaviour, imagery...)
","['data-request', 'uses-of-open-data', 'big-data']",
Number of employees of large companies?,"
Where can I find the numbers of employees of large companies?
Are there any open source or free information sources available?
","['data-request', 'companies']",
Is there a comprehensive list of indigenous Australian taxa?,"
I'm fitting models of species' distributions and community composition using occurrence data provided by the Atlas of Living Australia (a node of GBIF). 
Is there a comprehensive list of names of indigenous Australian taxa (either flora, fauna or both), or a global list of taxa that indicates countries in the native range? Alternatively, is there a web API that I can query for these data?
Ideally I'd be able to easily relate returned taxon names to LSIDs such that I can associate them with the ALA occurrence data.
","['data-request', 'environment', 'australia']",
How do I find data that helps US businesses export their products?,"
Are there data sets out there that have data about exporting products and services overseas?  I want to build an app that helps U.S. businesses increase their international sales.
","['data-request', 'usa', 'business', 'trade']",
USAID Dataset Downloads Published List,"
My understanding is that you are collecting data on the frequency of downloads of every dataset uploaded to the DDL (Development Data Library). Have you uploaded that dataset of downloads?
I am interested in knowing the number of downloads of every USAID dataset pertaining to health - funded by the Bureau for Global Health as well as by every USAID mission with a health program. 
","['data-request', 'metadata', 'usaidopen']",
Data on metals and alloys properties (physical and chemical),"
Are there publicly available datasets of physical and chemical properties for (industrially produced) metals and alloys?
","['data-request', 'industry']",
Why is my scraper returning inconsistent results and timing out?,"
I've been building a scraper in python (using mechanize) to get a list of banks off of:
https://connectonline.asic.gov.au/RegistrySearch/faces/landing/ProfessionalRegisters.jspx
The scraper is:
https://github.com/bianca/mapaustralianbanks
1) I keep getting inconsistent results. Sometimes I query and get data, sometimes I don't. What is the best way of making the python script more robust so that it keeps trying in order to eventually get consistent results? I was thinking of some sort of settimeout before requerying, but I was wondering if there was something about the server that I'm making requests to that is the reason why my data is inconsistent...
2) ~2 hours in, the script just stops scraping. I've tried to set a timeout in mechanize to give up after 60 seconds, but that isn't working. Any ideas?
","['finance', 'programming', 'web-crawling', 'australia', 'opencorporates']",
microcredit or microfinance data,"
Data: I am seeking a panel style data set containing information on microfinance. I am aware of large studies around Bangladesh.
Context: I am attempting to undertake a research project on the influence of microfinance.
License: Any licenses are acceptable.
","['data-request', 'economics']","Have you checked USAID's Microenterprise Results Reporting (MRR) Portal?  You may also be able to find other resources at USAID's Development Data Library.
usaidopen"
Dataset of Facebook Users Connectivity,"
Is there any dataset available of Facebook users which shows how people are connected with each other? So that I can use that dataset to do some research on access control in social networks.
","['data-request', 'social-media']","Facebook has the Graph API so you can construct your own queries and collect as much data as you want.Otherwise, there are some collected resources described in this thread (warning: from 2010 and maybe involving hacked data).Online Social Neworks from UC Irvine100 million Facebook pages leaked as torrentIf you don't require Facebook, there are much better resources for Twitter (datasets and public search/stream API access)"
Data on Use of Tax Preparer?,"
Is there a data set for the U.S. that summarizes the use of tax preparers to complete / file tax returns by income of the filer? 
Federal Form 1040 has fields for tax preparer information, but not sure if statistics on usage is made available or broken out by the income of the filer that uses them.
","['data-request', 'taxes']",
How to anonymously share data?,"
Disclaimer: This is a thought-experiment and I have no intention of releasing any data this way, nor do I have any interesting data to release.

Let's say that a person wants to share data anonymously in a way that people can download the data without it linking back to the source. Let's say the data wasn't illegally obtained, it's not illegal to hold a copy of the data (at least in the US and Europe), the data is of general interest to the public, and it's a modest size (on the order of 1GB).
The typical data-releasing ideas aren't appropriate:

pastebin has an upload max of 0.5 MB
github, datahub.io, etc all require registration of some sort. I could create fake accounts and fake email addresses, but let's say that requires too much effort or I'm too paranoid.
wikileaks wouldn't be interested. Let's say it's not whistle-blower data or anything even close to being controversial.
anonymous uses torrents, which could work, except let's say the person doesn't want to get involved with darknet stuff.

What are some ways a person can anonymously release data that doesn't track back to the source?
",['releasing-data'],"The OP says he is fine with Bittorrent now.  After all, Bittorrent was made for large files (outlawing Bittorrent would be like outlawing bombs.) Now, how to do it. First of all, Bittorrent isn't anonymous (again the creators had only one task in mind), so you will need a proxy or something. Now, create the torrent file. Now the torrent file itself will be small (a couple megabytes I think) so it would fit in a paste."
labeled clickstream datasets for intrusion detection,"
I am looking for some clickstream datasets, ideally from an ecommerce website, where the click paths are assigned labels (e.g. good to say that a click path is originating from a genuine user, and bad if the click path is originating from an intruder). I would like to study the behavior of system intruders. I know there are some clickstream datasets out there but those aren't labeled
","['data-request', 'security']",
Dataset of major newspapers content,"
I'm looking for the materials of major newspapers, such as The New York Times, Washington Post, and The Economist. A random sample of their articles or headlines would suffice, but each newspaper has complications.

The New York Times has an article search API that gives access to the newspaper's archives. There's a Python wrapper for it. The NYT allow frequent queries ( > 5,000 calls per day) after contacting them (non-commercial use only).
The Guardian grants free API access to 1.7M articles.

Some newspapers allow crawling.
Naturally, paid services search across newspapers and may do some export. See LexisNexis and Archives.gov.
Is there an open academic dataset of the newspaper content?
","['data-request', 'api', 'media']",
Providers list about biofertilizers,"
I would like to know a providers list about biofertilizers within the USA and outside. Is it possible for you to provide me this information? Or indicate to us where can we find help?
","['data-request', 'data.gov']",
"Business performance data of web company like number of employees, revenue etc","
Is there a dataset describing the #employees, #customers, revenue, investment etc for web company such as google, mozilla, yahoo, facebook?
WIKI has few information like #employees, revenue. Querying SPARQL with DBpedia may extract it. However, the information is few.
Yahoo! finance has much more information, using Yahoo! finance API with company symbol (using fb for Facebook for instance) can extract this information if knowing the company symbol in NASDAQ stock market in advance.
But it has drawbacks. NASDAQ doesn't contain company outside the U.S and outside the stock market. For example, deutsch tekecom in the former case and Mozilla in the latter case. The former case can be solved by considering more than one stock market but it will face the problem of redundancy. Ex. Facebook in London stock market , Facebook in Germany stock market, Facebook in NASDAQ and so on.  
","['data-request', 'finance', 'web-crawling', 'business', 'companies']",
Trying to extrapolate patient costs by physician from public Medicare pricing data,"
I am working on a web application that maps healthcare expenses by providers in a geographic area. Our prototype was previously using mocked data, and I am now trying to replace it with real data from the 2012 Medicare Provider Utilization data set.
Basically I feel like I have good data in front of me, but I'm not  sure how to intelligently interpret it. Below are two (abbreviated) example lines, each of which corresponds with one provider's costs relating to one medical procedure.
avg_Medicare_allowed_amt    avg_submitted_chrg_amt    avg_Medicare_payment_amt
------------------------------------------------------------------------------  
      220.4492           |        517.3611         |          176.3583
      112.8608           |        1181.0625        |          90.2879

The methodology PDF including more detailed variable descriptions is here, variable definitions starting under heading 5 on page 4.
Each number corresponds with a dollar amount. allowed_amt is the amount that Medicare expects to pay that provider for that procedure, submitted_chrg is the amount that a provider actually bills medicare, and payment_amt is how much medicare actually reimburses. I also have unique IDs for each provider and procedure, as well as general identifying and geographical data.
What I want from this data is to be able to make an informed estimate of how much cost is actually incurred by the patient. In a less confusing world, this would just be (avg submitted charge) - (amount reimbursed) with the leftovers being passed on to the patient, but the way I understand this, Medicare billing does not really work this way, and the amount billed to Medicare does not really directly relate with the amount that a provider expects to be paid.
Is there any way from this data that I could make an educated estimate about how much a patient could expect to pay for a given procedure?
","['usa', 'government', 'medical']","For the benefit of the community here is a late answer. The average payment by the beneficiary (and third party payers) is: average_Medicare_allowed_amt - avg_Medicare_payment_amtFrom the PDF:
average_Medicare_allowed_amt is the sum of the amount Medicare pays, the deductible and coinsurance amounts that the beneficiary is responsible for paying, and any amounts that a third party is responsible for paying.It is customary in US health insurance billing to distinguish between submitted charges, that are largely detached from the actual allowed charges. The latter are split between the beneficiary and Medicare. So by subtracting what Medicare actually paid from the price it allowed you get what is left for the beneficiary (or third party payers, meaning other insurers that cover the beneficiary, like Medigap)."
CKAN exposing tables from a relational database,"
I am using CKAN 2.3 and I would like to compose datasets considering a specific schema from a relational database. Indeed, I would like to publish the list of any table into CKAN in order to show which kind of data I have stored in Oracle.
I know that there are some harvesting extensions but if I am not wrong it seems no one is useful to configure a connection to Oracle's database getting a collection of all tables. 
Does anybody know if there's any helpful extension for this purpose or any way to do it easily?
","['metadata', 'ckan']",
Freshness of Unemployment Data,"
Since unemployment data is based off of surveys, I assume the announced data reflects some period in the past.
I cannot find information on the ""currency metric"" of unemployment data.
Does anyone have any ideas?
In case I'm falling for the ""XY Problem"", here's my initial conundrum:
Imagine I have a real-time unemployment model. If for some week my model claims unemployment is relatively high. At the end of the week the monthly unemployment rate will be announced. Should I bet that the announced monthly unemployment rate will be high? If the data was collected from surveys taken a week ago, it would not be. I need to know when the data was collected.
","['data-request', 'government']",There are many sources of surveys/administrative in the United States data you might find useful.
Crime rate data for American cities,"
I'm writing a paper and I'm interested in monthly crime rates in American cities. 
The FBI database contains only yearly crime rates and it stops at 2012 (http://www.ucrdatatool.gov/), and each individual police station varies in their degree of reporting. Anyone know of dataset that will satisfy my needs? 
","['data-request', 'usa', 'legal', 'crime', 'police']",
Is there a data set listing which pharmacies have self-checkout lanes?,"
I am interested in observing the rise of the self-checkout lane. Is there a data set that shows the addresses of pharmacies (not companies, actual establishments) that have self-checkout lanes and when they got them? 
","['data-request', 'business']",
Where can I find shapefiles for the rivers of Puerto Rico?,"
I would like to find shapefile data for all of the rivers in Puerto Rico.  This could be as a subset of the rivers in the United States.  I already have an accurate boundary of the island. 

","['data-request', 'usa', 'geospatial']",
"Find a missing dataset: ""A Week in the life of a browser - Version 2"" from Mozilla Labs","
It's come up as an answer for two questions:

Open, big time-series dataset (ideally web traffic)
Where I can find a repository of software usage/execution logs (traces)?

Here is the main page: A Week in the Life of a Browser - Version 2: Aggregated Data Samples
But the download links for the 3 data files is dead. For example:
https://testpilot.mozillalabs.com/testcases/a-week-life-2/witl_small.tar.gz

The relevant HTML source for the page can be found in this GitHub repo
<table class=""callout"">
    <tr>
        <td><span class=""headers"">Filename</span>
        </td>
        <td><span class=""headers"">Download Size</span>
        </td>
        <td><span class=""headers"">Num. of Tables</span>
        </td>
        <td><span class=""headers"">Num. of Users</span>
        </td>
        <td><span class=""headers"">Description</span>
        </td>
    </tr>
    <tr>
        <td><a href=""witl.db.gz"">witl.db.gz</a>
        </td>
        <td>1.1 GB</td>
        <td>3</td>
        <td>About 27,000</td>
        <td>Gzipped SQL dump of all three tables</td>
    </tr>
    <tr>
        <td><a href=""witl_large.tar.gz"">witl_large.tar.gz</a>
        </td>
        <td>469 MB</td>
        <td>3</td>
        <td>About 27,000</td>
        <td>Gzipped Tar archive of three CSV files, one for each table</td>
    </tr>
    <tr>
        <td><a href=""witl_small.tar.gz"">witl_small.tar.gz</a>
        </td>
        <td>7.4 MB</td>
        <td>3</td>
        <td>About 27,000, 387 w/ event data</td>
        <td>Gzipped Tar archive of three CSV files, one for each table</td>
    </tr>
</table>

In this case, the links to the download files point to the same folder, which is empty otherwise.
Who can find these data sets? (so we can properly host them)
One hint: find this guy and see if he still has a copy.
","['data-request', 'internet']","I just snagged it off the wayback machine here:  but more files can be found here by searching for '.tar.gz' or '.db.gz'Download the dataDownload links from Wayback Machine:witl.db.gz (1.1 GB, SQLite 3.x database)witl_large.tar.gz (469 MB, CSV files)witl_small.tar.gz (7.4 MB, CSV files)Details:"
License of NOAA hourly temperature data,"
I would like use historic hourly temperature data (Integrated Surface Global Hourly Data, DSI-3505) available from NOAA. Using NOAA's Climate Data Online mapping tool, I select the weather stations in the region I'm interested in (Belgium, in my case) and download the data between two particular dates in a CSV format. Using this data, I can determine an approximation of the temperature at a particular location (long/lat) at a given point in time.
While this data is freely downloadable, it is not clear to me whether I can use it for commercial purposes. The data is not being sold as-is, I'm merely querying it as part of a research project we're doing for another company. That company will use the resulting data internally, not sell or distribute it in any other way.
Before I can download the data, the following text is presented to me (emphasis mine):

CONDITIONS
WMO Resolution 40 NOAA Policy
The following data and products may have conditions placed on their
  international commercial use. They can be used within the U.S. or for
  non-commercial international activities without restriction. The
  non-U.S. data cannot be redistributed for commercial purposes.
  Re-distribution of these data by others must provide this same
  notification. A log of IP addresses accessing these data and products
  will be maintained and may be made available to data providers.
For details, please consult WMO Resolution 40.
For additional details/information concerning which data are listed as
  ""additional,"" please see the Microsoft Word document WMO Resolution 40
  If you have questions about NCDC's implementation of this resolution, 
  please contact NCDC at ncdc.orders@noaa.gov or 828-271-4800.

I started reading the referenced WMO Resolution 40, but I'm pretty sure I can't figure out what it's saying in a reasonable amount of time. I was hoping someone else has experience with this and can shed some light on the matter.
","['licensing', 'weather', 'noaa']","I have contacted NOAA directly with this question, and the answer was (emphasis mine):As you have described it below, you are not in violation of Resolution
  40. This would apply if you are redistributing the data as-is for profit.If you are unsure about your particular use case, I suggest contacting NOAA directly."
Need sample E-commerce order data,"
Is there any sample data for Ecommerce orders? What I need is Order no, Customer details, address, ratings by same customer, delivery times etc. 
I need it this for data analysis project i am doing. These need not be really true, like the names and addresses of people can be fictional. 
","['data-request', 'business', 'analysis']",A popular answer comes from a 2010 question on Stackoverflow - Source LinkNorthwind database - (documentation & data model)NopCommerce sample datasetE-commerce dataset from Amazon / Google Products / Abt Buy Other ideas:
Are there open data sets about commuting patterns in large US cities?,"
Are there specific data sets about movement of commuters (in cars, trains, buses, etc.) in major US cities?  Ideally the data would include numbers of commuters, have detailed location information, and across time (throughout the day, and over weeks/months).
","['data-request', 'usa', 'city', 'transportation', 'public-transport']","There's a related question.  This answer may be helpful here too Nick.You can find out information about Americans' commuting habits in relation to specific geographic areas through the U.S. Census American Community Survey.  Access to the data is available.  For example, if you are looking for how people in Los Angeles County get to work, you can find the answer through the Easy Stats online.The longitude and latitude of all U.S. boundaries (from school districts to counties to roads) can be found via TIGER files (topographically integrated geographic encoding and referencing)."
Latitude and Longitude of US Commuting Zones,"
Is there any dataset containing the latitude and longitude of US commuting zones? (e.g. an Excel sheet containing the coordinates of Minneapolis-St. Paul, etc.)
",['data.gov'],
Hourly temperature data for specific locations (Arkansas) for the year 2014,"
I am searching for a site which gives hourly temperature data for specific locations in Arkansas (I have zip codes) for the year 2014. Please assist.
","['data-request', 'weather']","I would start here: http://www.climate.gov/hourlysub-hourly-observational-data-hourly-global-%E2%80%93-gis-data-locator.  It looks like you can go to ""View Data"", then select the stations of interest from the map, then specify the dates and data elements that you want.  It does not guarantee that hourly data will be available from every station."
"For a recommender system, is there a real data matrix that is about 500 by 500 that is complete and has no missing entries?","
I was trying to get together a fully observed matrix for collaborative filtering. For example, some data matrix that was (more or less) at least 500 by 500, of say for example, 500 users that all rate the same 500 movies.
I tried getting something like this from the netflix data set and only got around 256 by 150, which seemed too small.
Is there a data set that is already processed like this that I can use? It doesn't necessarily need to be movies, but it would be best if it was a recommender system data set.
Or maybe a suggested data sat that has a high chance of getting a sufficiently large data matrix. The larger the better obviously.
","['data-request', 'machine-learning']",
Spectral reflectance data for iron rust,"
Are there publicly available datasets of visible (and UV and IR, if possible) spectral reflectance data for the different types of iron rust?
Specifically, I am involved with a project that has an interest in the spectral/optical properties the different types of rust, particularly the 'red' and 'green' rust.
Preferably, a publicly available source of the data would be ideal, though if the data is included as part of a published paper, even behind a paywall - that would be okay as well (one of my contacts would be able to access that through his university library).  (If it turns out to be more than 1 resource, that is fine also).
While researching, it has become clear that through usual research channels, there is no obvious data sets for iron rust optical properties.  Much of the data available is about the electrochemical properties, and most of those are charts.
","['data-request', 'research']",
Where can I find a downloadable grocery store food ingredient database / data set?,"
I'm looking for a downloadable ingredient database / data set.  I'd like to be able to write my own query to the data set, eliminating potentially harmful ingredients to see what would be potentially healthy to eat.
Does such a downloadable data set / database exist?  The closest I've been able to find is foodfacts.com and it's not an open data set.
","['data-request', 'food']","have you tried Open Food Facts? It's a ""free, open and collaborative database of food products from the entire world.""  The data is offered under the Open Database License"
Hyperloop; Which Open-Source License did Musk choose?,"
Which Open-Source license did Elon Musk choose for the Hyperloop?
","['usa', 'transportation', 'licensing', 'open-source']",
Where I can find a repository of software usage/execution logs (traces)?,"
I'm looking for recorded information about a program's execution. I'm not interested in logging information, but in software tracing data.
The more information about software internal it contains the merrier it is.
Following is a trace example:
INFO: Call from main.RunFile line 206 to main.RunFile.main
Mar 31, 2011 2:52:53 PM aspects.Trace ajc$before$aspects_Trace$1$b314f86e
INFO: Call from main.RunFile line 186 to main.RunFile.runList
Mar 31, 2011 2:52:53 PM main.RunFile main
INFO: Starting clustering of 0 files
Mar 31, 2011 2:52:53 PM aspects.Trace ajc$before$aspects_Trace$1$b314f86e
INFO: Call from main.ExperimentRunner line 59 to main.ExperimentRunner.runExperiments

","['data-request', 'software']","You might consider using the EVENT table from the Mozilla Labs ""Day in the Life of a Browser"" dataset.Unfortunately the download links are inactive. But this dataset has come up on another question and hopefully Mozilla will fix it soon. License is Creative Commons Attribution 3.0 United States.UPDATE: data is now hosted here"
Data set of software fault prediction studies,"
Currently I am working in software fault prediction. I want to perform some experiment in software fault prediction data set. But I am unable to find data set related to software fault prediction. Can anyone suggest me some link from where I can download these data sets?
","['data-request', 'machine-learning', 'software']",
"Where do I get the complete fictional data (the titles of Movies/ TV, Characters, People/ cast/ crew) dump","
Freebase is shutting down. 
but I am unable to download the 25GB of zipped file (shows error) dump they are providing.
I used their API to set up my search bar, (segregated into 3 sections Movie titles, Character Titles, People Titles ) but the challenge is there appears to be unnecessary fine filtering like film series, docudrama, historical film, fantasy film,... and a never ending list just for the movies.
Is there a way I could unite all the multiple titles into one. Apart from free base is there any dump provider who does the way I want.   
","['data-request', 'film']",
where can I find shapefiles for the highways of Puerto Rico?,"
I am looking for the shapefiles of the intersetate highways of Puerto Rico in an easy to use geoJSON format.  I found this page here http://www.baruch.cuny.edu/geoportal/data/esri/esri_usa.htm  but when I unpacked could only find 50 states.
Even though PR is an island, there are 3 interstates.

","['data-request', 'usa', 'geospatial']","Since I have promised, I will answer this question without waiting for its migration, if it will ever happen. Basically, I think that the best and latest data set that you can find now is this one - from the US official open data repository's TIGER/Line database. This page is generated, based on a relevant search (Puerto Rico), and might also contain some data sets of your interest.Other potentially useful data sets include ones within U.S. Atlas TopoJSON repository (on how to use the data via R, see this nice tutorial) as well as this repository of U.S. major roads ESRI shapefile and geoJSON data sets (you have to check whether this repository contains PR data)."
Open Badges/Tin Can to open up credential & learning data,"
What are the differences between http://tincanapi.com/  & http://openbadges.org/ ?
I think they are both great ways in opening up credential data, but was wondering in what specific situations you would use one or the other?
Both as provider of open badges/tin can api as on the receiver side of these (learner)
",['uses-of-open-data'],
Journalism examples using officials public data portals? [closed],"







Closed. This question needs to be more focused. It is not currently accepting answers.
                                
                            











Want to improve this question? Update the question so it focuses on one problem only by editing this post.


Closed 8 years ago.







                        Improve this question
                    



I'm living in Europe. For researches purposes, I'm trying to gather news articles explicitly using data from officials portals as data.gov.uk for instance. 
Please consider this, however: 

The data can also come from any data.gov.* portals around the world (such as the UK portal). I'm not specifically asking for US examples ; 
The articles/app doesn't have to be made by journalists, but should have a clear informational purpose ;

","['uses-of-open-data', 'data-portal']","Well, here's one: http://www.theage.com.au/victoria/the-most-ignored-parking-sign-in-melbourne-20140512-zraek.htmlHere's the background: http://www.theage.com.au/data-point/blogs/the-crunch--data-point/melbourne-parking--get-the-data-20140513-386wv.htmlSummary: data journalists from The Age found data on the City of Melbourne's data portal, wrote a story from it."
A database of open databases?,"
While there are many open databases available, is there a database or the project that would contain the information of such databases?
In other words, is there an open meta-database of open databases?
","['releasing-data', 'metadata', 'data-portal']","DataPortals.org (previously DataCatalogs.org) provides a comprehensive list of open data portals from around the world. Their (meta-)data is in the public domain and available for download as CSV and JSON.Data that is somehow related is usually grouped in datasets or databases, contained in files (e.g. CSV or spreadsheets) or some kind of database management system, which might be accessible via an API.In the context of Open Data, data portals, data catalogs, or data hubs make it easier to find these datasets or databases.A great example of such a data portal is the Datahub, which currently lists more than 4,500 open datasets.However, there are already hundreds of data portals. A few prominent examples are the official data portals of the US (data.gov), the UK (data.gov.uk), or the European Union (open-data.europa.eu).This is where DataPortal.org comes in: It is a data portal of data portals.To sum it up:"
Mapping CSV Header to RDF + SPARQL console,"
I would like to know your opinion about the next system:

with a large CSV file
convert it's header to RDF schema, in which exists only the CSV columns information and access point. This way there's no need to convert the hole file to RDF triples, eliminating huge conversion overhead.
launch a web app with SPARQL console, which converts the requests in file searches.

Why, you ask? Because having a 2.5GB cache with triples generated from 100MB CSV file is not useful at all.
In other words, i'm proposing the same system when converting RDB to RDF on p.ex. D2RQ, where all data is kept in the database and what is converted is the relational schema. This saves a lot of space and is a much faster process.
As mentioned in comments and answers below, a similar system might be tarql. The issue with this system is that it converts all the CSV file to rdf, not just the header. The issue with this approach is that a 100mb file is converted into a huge 2.5gb rdf file, which is not practical nor useful.
Here's a diagram that describes what i want to (or aspire to :)) create:

","['tool-request', 'csv', 'rdf', 'sparql']","Before building a completely new system from scratch, you should first check if an existing system satisfies your requirements. There are a few possible candidates out there:As outlined in this answer, D2RQ and RDF HDT might be close to what you are looking for.In addition there is Tarql which provides SPARQL access to CSV files — which is, as far as I can tell, exactly what you want.One more comment: If you want performant search for your CSV files, you won't get around a search index. And instead of building one yourself, I recommend having a close look at D2RQ again."
Where to find number of companies by year revenue?,"
I'm trying to find number of companies which reach a certain scale of revenue per year. For example in USA is x companies with revenue $100k-$1M, y companies with revenue $1M-$10M, z companies in bucket $10M-$100M. I need those numbers for various regions as for USA, north amerika and Europe to begin with. Every tax agency in every modern country has to know required data. I have tried tens different queries in Google and Wolfram Alpha with zero success. Not only I can't find this data for some region but I can't find it for any region at all. I got tons of articles with a list of top 500, 1000, and so on names of biggest companies and their revenue, but they are exactly what I don't want. I'm interested in much smaller ones. Obviously I don't know the right place or the right question to ask. Can you please point me to the right direction where to find right source of such data?
","['data-request', 'economics', 'business']",
Machine-readable way to determine if plant species is native to Australia,"
I'm doing some work visualising tree inventories and thought it would be nice to show whether the species is native to Australia or not. I haven't so far found any database that would answer the question. Wikipedia has a category ""Flora of Australia"" but it's not clear whether that means ""native to"", and I don't know if it's consistently used.
Are there any other databases with this kind of information? Taxonomy information seems straightforward, but what about basic distribution in the wild?
In this case, I really just a very simple ""yes/no"" per species. In some cases, I only have the genus, but I don't know if asking whether a genus is native to a country is a sensible question.
EDIT 
Well, it turns out there are lots of plant databases of various kinds, mostly concerned with taxonomies, tracking name changes, and photos. I've now looked at:

http://www.allcreativedesigns.com.au/pages/speciesbotanical.html (unclear licence, unclear comprehensiveness)
http://www.oznativeplants.com/A-Z/common.html (unclear licence, unclear comprehensiveness)
Australian Virtual Herbarium Great resource, unclear if it actually has native/introduced attribute.
Australian Plant Name Index Unclear if it has that information.
Catalogue of Life Unclear if it has that information. (Also probably not very comprehensive, it didn't have one species that I looked up).

Still more to go at https://en.wikipedia.org/wiki/List_of_biodiversity_databases
EDIT 2
Another one, the ""Colonial Plants Database""
","['data-request', 'biology', 'environment', 'australia']",
Legality of using data against terms,"
Perhaps a bit off-topic, but this is the only relevant SE forum.  I sometimes come across RSS feeds with terms and conditions attached, such as one example permitting use for app-development (that would complement their revenues) but expressly not for any other purpose, and specifically statistical aggregation.
I wonder about the bottom line of legality about this sort of conditionality.  The company has made the data public, without any sign-up.  Can they legally enforce such conditions on usage?  Of course they can sue for damages, but are they likely to succeed?  Are there any legal precedents to be aware of?  Much of course will depend on the legal jurisdictions involved, but if there was any useful guidance available for US/UK/European contexts it would be useful to know.
","['legal', 'licensing']","here's more of an opinion, not an answer:
i'm free software all the way, and i wouldn't give a care to what their terms say, i'd do whatever i pleased with it, until they killed the service.  in reality, corporations will destroy you, unless you have an army of lawyers too. look how broken the patent system is, or the hacker that exposed a public url and went to prison. odds are you won't get nailed, but if you do, it'll probably be severe. remember, hackers are treated like terrorists in america.  it really pains me to say that utilizing an rss feed makes one a hacker, but the media will spin it like that, no doubt."
"Seeking geographical database that, given coordinate boundaries, returns all the mountain peaks within the boundary, their coordinates, and elevation","
I'm looking for a web service that, given a set of coordinate boundaries, in the form of a rectangle or square, returns all the mountain peaks within the boundary, along with the coordinates and the elevation of the peak.
Geonames offers such a service, but I have to make separate requests for the elevation for each peak, which could amount to hundreds of requests for a given (ie hilly) boundary.
","['data-request', 'api', 'geospatial', 'geocoding']",
Does there exist a set of data that measures internet traffic that is specific to image downloading and uploading?,"
I am currently writing a report, I would like to make a claim which I am struggling to back up:

The volume of image data transferred digitally has increased as the
  internet has become more popular and fast download speeds has become
  more easily accessible.

Of course I don't actually know this claim to be true. However, I think it's a reasonable claim given that the number of gadgets people own seems to be increasing (at least where I am from), as does the global population and there are developing countries working on high speed internet infrastructure. 
Does anybody know of any data that could help me back up my claim? For example data where volume of image data being transferred is measured over at least, lets say 10 years would be great!
","['data-request', 'images', 'internet']","I think you're unlikely to find this as true ""open data,"" since there are substantial privacy concerns to internet traffic monitoring, and the volume of data involved to do proper analysis is considerable.That said, there is an organization, the Center for Applied Internet Data Analysis (CAIDA), which makes datasets available to researchers under oversight. A brief look at their data overview doesn't reveal any sets which are obviously content-oriented, but they may be able to advise.Beyond getting the data yourself, you may be able to find a citation in media or academic publishing which substantiates your hypothesis. This GigaOm story, ""How the core of the internet has changed from data to content"" might lead you down the right path.Ultimately, the amount of still image data looks like it will be a drop in the bucket, if the Cisco study covered in this Recode article is correct: they claim that video traffic is currently 78% of internet traffic, and headed for 84% by 2018. If you still want to get numbers about image data, perhaps digging deeper into the Cisco study will yield results."
Linked Geospatial Data in WFS,"
At the Swedish University of Agricultural Sciences we have released some data based on the requirements of the INSPIRE directive. 
We use Geoserver which provides us with a number of standard services. An example can be seen in the data's WMS service. 
We're interested in the 5-star model for open/linked data and from what I understand we'd see this as 3-star data. 
How can we go from here into the realm of linked data? 
","['geospatial', 'releasing-data', 'linked-data', '5-star-scheme', 'inspire']",
Are there any dataset for psychology,"
I am looking for a triple RDF dataset or vocabulary for a psychology website I am developing. I have a large XML schema database and am looking to translate this database to one RDF serialization format. I've searched for websites that have vocabulary such as lov.okfn.org/dataset/lov, but could not find any related vocabulary to translate the data. 
Are there any website or methodology that have such a triple data store for the website?  Any suggestions on building an open data triplestore for such purposes?
","['linked-data', 'rdf', 'ontology']","The Thesaurus of Psychological Index Terms, published by one of your employer's (?) customers, is known now as Psychology Ontology.This ontology is not even a taxonomy, but rather a flat list of classes.BioPortal provides mappings between this ontology and many other ontologies.  Additionally, BioPortal contains other ontologies published by APA:The OntoPsychia ontology seems very interesting, but is not available for download.AberOWL repository provides these links:"
The spread of cable tv,"
Is there a data set that shows the date of the first availability of cable tv or (not necessarily the same data) the date of first public broadcasting in each state or city in the United States? 
","['data-request', 'usa', 'media']","there are a few, certainly not all, dates in this pdf about the history of television. one example: Cable television is introduced in Pennsylvania as a means of bringing television to rural areas. (1948)  not a complete answer, but some information in here for you:
http://tarlton.law.utexas.edu/exhibits/mason_&_associates/documents/timeline.pdf"
"Pictures of all airplanes, organized by tail number","
Whenever a plane crash happens, Wikipedia and Wikinews articles are created within minutes, and good reusable pictures of the aircraft become needed.
Is there a database/website that has pictures for as many aircraft as possible?

Pictures must be easily findable by tail number.
License must be compatible with either CC-BY-SA or GFDL.

Bonus if a web interface allows one to type a tail number and browse the gallery (thumbnails) of images that match it.

(aircraft with tail number ""D-AIPX"", by SEBASTIEN MORTIER, May 2014, CC BY-SA 2.0, via Wikimedia Commons)
","['data-request', 'images', 'public-transport', 'aviation']",
1945 (spring) daily weather Germany,"
Perhaps understandably, I am having difficulty tracking down daily weather data for Germany in early 1945.
My specific interest is in daily temps and any other daily weather observations for January through March 1945, particularly for the area of Bonn or Cologne -- although I would be grateful even if such data were only available for Berlin.  My greatest interest is in the first three weeks of March 1945.
","['data-request', 'weather', 'historical', 'germany']",
Airline check for availability data,"
Where can I find a free web service, or data available in XML format, to check for flights availability?  Something like OpenFlights to which provides airport data.
","['data-request', 'api', 'transportation']",
Open Data about the internet,"
Does anyone know where one can find (if any is available)
open data about the internet, and generally any data about tier1 infrastructure, i.e internet backbone nodes with capacity, coordinates
Also data about broad band coverage by country (and development over time).
Any data about the internet, historical, present, statistics, geographic would be interesting.
","['data-request', 'geospatial', 'internet']",
Any data set available for Twitter tweets classification?,"
Is there any dataset available for different categories like music, politics, business etc which can be used to classify input tweets?
","['data-request', 'machine-learning', 'social-media', 'nlp']",
Electric utility boundary lines in US,"
I'm looking for shapefiles or other spatial definitions for electric utility service areas in the United States. Does this exist in a single place anywhere?
","['data-request', 'usa', 'geospatial', 'energy']",
Looking for data that is a temporal/transient/dynamic network with hierarchical information and edge labels,"
I am looking for a dataset that has a set of features.

network: there are nodes/actors/users which send messages to other nodes as a subset in the network
temporal/dynamic: there are time stamps to the messages sent between nodes so that the edges are 'transient'
ranked nodes: there is some form of hierarchy in the network where nodes are ranked
edge approval: that the edges/messages produced can be classified as either positive/negative.

The last two requirements are hard for me to find in datasets that I have seen. I am trying to test a new algorithm which needs a given hierarchy, and edges to be labelled as +1/-1 for good and bad. I thought of giving sentiment scores to some Twitter network for this edge approval but I am not sure how robust that would be and am not sure how I would make a hierarchy from it.
I imagined a network from primate studies but did not find it.
","['data-request', 'network-structure', 'time-series']",
How to get a list of all strengths & forms for a drug from RxNorm?,"
RxNorm is a database of drugs put out by the U.S. National Library of Medicine. I've pulled the RxNorm data into a Postgres database using some of the supplied MySQL scripts and some code that I wrote myself.
I am able to find the list of all strengths for a given drug, like say ""gabapentin"". First I find the identifier for ""gabapentin"":
select * from rxnconso where str = 'gabapentin' and sab = 'RXNORM';

which gives:
rxcui | lat | ts | lui | stt | sui | ispref | rxaui  |  saui  | scui  | sdui |  sab   | tty | code  |    str     | srl | suppress | cvf  
-------+-----+----+-----+-----+-----+--------+--------+--------+-------+------+--------+-----+-------+------------+-----+----------+------
25480 | ENG |    |     |     |     |        | 417389 | 417389 | 25480 |      | RXNORM | IN  | 25480 | gabapentin |     | N        | 4096

From that I learn that the identifier for gabapentin is '25480'. And then I can get the strengths for '25480' like so:
select * from rxnsat where atn='RXN_STRENGTH' and rxcui in (select distinct(rxcui) from rxnconso where rxcui in (select rxcui1 from rxnrel where rxcui2 = '25480')) order by NULLIF(regexp_replace(atv, E'\\D', '', 'g'), '')::int;

which gives:
  rxcui  | lui | sui |  rxaui  | stype |  code   | atui | satui |     atn      |  sab   |   atv    | suppress | cvf  
---------+-----+-----+---------+-------+---------+------+-------+--------------+--------+----------+----------+------
 997844  |     |     | 3276700 | AUI   | 997844  |      |       | RXN_STRENGTH | RXNORM | 25 MG/ML | N        | 4096
 346365  |     |     | 1533281 | AUI   | 346365  |      |       | RXN_STRENGTH | RXNORM | 50 MG/ML | N        | 4096
 345817  |     |     | 2061711 | AUI   | 345817  |      |       | RXN_STRENGTH | RXNORM | 100 MG   | N        | 4096
 1482816 |     |     | 5937983 | AUI   | 1482816 |      |       | RXN_STRENGTH | RXNORM | 300 MG   | N        | 4096
 345818  |     |     | 2061712 | AUI   | 345818  |      |       | RXN_STRENGTH | RXNORM | 300 MG   | N        | 4096
 345819  |     |     | 2061713 | AUI   | 345819  |      |       | RXN_STRENGTH | RXNORM | 400 MG   | N        | 4096
 346145  |     |     | 1532840 | AUI   | 346145  |      |       | RXN_STRENGTH | RXNORM | 600 MG   | N        | 4096
 1101334 |     |     | 3641350 | AUI   | 1101334 |      |       | RXN_STRENGTH | RXNORM | 600 MG   | N        | 4096
 346146  |     |     | 1532842 | AUI   | 346146  |      |       | RXN_STRENGTH | RXNORM | 800 MG   | N        | 4096

That means gabapentin is available in strengths of 25mg/mL, 50mg/mL, 100mg, 300mg (2 different forms), 400mg, 600mg (2 different forms), and 800mg.
But how do I find out what forms correspond to those different strengths? For instance, some of them are capsules, some are tablets, and some are solutions.
(If you go to this RxTerms demo page, you can enter ""Gabapentin"" in the first ""Drug Name"" field, and then choose the autocomplete option ""Gabapentin (Oral Pill)"", and then click in the Strength field, and you will see that it lists things like ""300 mg Cap"", ""300 mg Tab"", etc. RxTerms pulls its data from RxNorm, so it should be similar to the results gotten from querying RxNorm appropriately.)
","['sql', 'drugs']",
Free data on public holidays? [duplicate],"







This question already has answers here:
                                
                            




List of public holidays by countries?

                                (4 answers)
                            

Closed 8 years ago.



Is there a good live source of data for all public (bank) holidays for all countries in an easy fetch-able format?
","['data-request', 'calendar']","There are many attempts to make a public holiday calendar, and one of the best ones is a python module called workalender (my source).But the main problem with a global holiday calendar is:Please take note that some calendars are not 100% accurate. The most common example is the Islamic calendar, where some computed holidays are not exactly on the same official day decided by religious authorities, and this may vary country by country. Whenever it's possible, try to adjust your results with the official data provided by the adequate authorities."
Database of free WiFi hotspots,"
I want to create an app that shows free WiFi hotspots around you, even if you have no Internet connection yet.
So, I need a re-distributable database of free WiFi hotspots for the whole world.

For each hotspot, I just need its latitude/longitude.
Hotspots that are free but require user registration or terms approval should either be excluded or have metadata indicating that.


http://freewifiwiki.net has hotspots info, but each hotspot is only a line of free text, often including an address but it would be difficult for a program to split address and prose.
","['data-request', 'geospatial', 'internet']",
Exclusion lists when crawling web directories,"
I have a case where I'm building a connector between a federated search engine, and an archive that's serving all of their data via HTTP.  They've been kind enough to have their pipeline generate a series of index files for each day that I can use to get the metadata that I need to allow people to search through their data.
Often for situations like this, I'd use wget to get directory listings ... but I'm running into a few problems:

Some of the directories are huge ... it's taking me minutes for the 'day' directories (and this spans a decade).
They have the autoindex options set so that they also have links to sort the directory in different ways.
I need to check for signs of re-processing, so I'll need to re-crawl, it's not just a one-off crawl.

I was hoping to use wget to skip over the sorting links, as more recent versions allow rejection patterns, instead of just rejecting file extensions:
-R '*index.html[?]C=?;O=?'

Unfortunately, it seems that the 'exclude' option in wget doesn't do quite what I'd have expected:

2015-03-25 14:35:33 (6.30 MB/s) - `index.html?C=N;O=D' saved [2635]

Removing index.html?C=N;O=D since it should be rejected.


... so it downloads the files, and then deletes them ... rather than avoiding them in the first place.
Is anyone aware of a tool that can be used for scraping that processes a reject list before attempting to download things?
",['web-crawling'],
Where can I find State tax income rates from 1995 to present?,"
I'm working on a dataset for a longitudinal analysis and would like to add state income tax rate for the years 1995 to the present.
","['data-request', 'data.gov']","The taxfoundation.org provides this information going back to 2000. In addition to their interactive form, they have a downloadable Excel spreadsheet.http://taxfoundation.org/article/state-individual-income-tax-rates"
List of European Hospitals and Health Clinics,"
I am looking for a overview on hospitals and medical services provided by the public (and also by the private) healthcare sector in Europe.

public hospitals 
private hospitals and medical clinics ...

I am looking for all the European Countries.
Requirements for each item:

name 
address
postal code
town 
street 
website 
(and email address) 

","['data-request', 'medical', 'europe']",
How can I get a full list of US Zipcodes with their associated names/CSAs/MSAs/lats/longs?,"
Is it possible from government sources? I've found a website that will sell the data, but I know all the data is out there for free, I just need to find it. 
I've been looking through Census.gov, but it seems only have zip code data as it relates to other data. 
I tried searching American FactFinder, but I ran in to issues such as this:

(which searched for 'cats' when I was looking for ZCTAs, which I assume will have zip code data).
Census.gov's page on zip code data points the user to a link on USPS.com, which ends up 404-redirecting to their index page.
Data.gov returns just way too many results looking for zip code data, and paring down the list seemed fruitless:
http://catalog.data.gov/dataset?q=zip+codes&sort=score+desc%2C+name+asc
I cannot, for the life of me, find this data.
","['us-census', 'postal-code', 'geocoding']",
Open data version of the Foreign Assistance Program Inventory?,"
http://www.usaid.gov/sites/default/files/documents/1868/ForeignAssistanceProgramInventory2013.pdf
You wouldn’t know where I can find an open data version of the pdf (above)? With descriptions of “infrastructure” for example (under economic development).
This is the taxonomy used by USG to classify all USG foreign assistance but I cannot find an open data list of this classification structure. 
","['usa', 'government', 'state', 'iati', 'usaidopen']",We have requested that a machine-readable (CSV) version of the Standardized Program Structure and Definitions be posted to this website.  Will circle back when we have confirmation of posting. 
USAID DDL - program codes,"
The USAID website has a Development Data Library Submission Form
For the program code field: is this associated with the award funding the creation of the data set or is this related to the specific data set? 
","['state', 'usaidopen']",
Public transport maps for all cities,"
I need public transport maps for all cities in the world (for reuse in an open travel guide).
Requirements:

For use by tourists, typically the kind of map you would print and carry around to quickly find out what lines and changes lead you to your destination
Details of streets are not needed, but major features (like rivers or famous landmarks) are OK
Train, metro/subway, light rail should be shown
Bus lines not needed if that would make the map too crowded
Stylised map prefered, no need for geographical accuracy
Reusable in Wikipedia: Either CC-BY-SA, CC-BY, public domain (official maps are most often not re-usable)
Preferably as SVG
The authority maintaining the repository should have the goal of having up-to-date maps for the whole world, not just for a particular city or country. Bonus for stylistic consistency across all maps.

This transport maps repository would be acceptable, but unfortunately it is not open.
","['data-request', 'geospatial', 'public-transport']",
why doesn't federal reserve services website have all routing numbers?,"
https://www.frbservices.org/EPaymentsDirectory/fpddir.txt contains a list of bank routing numbers but there's at least one that doesn't appear in that list: 111000025 (from https://www.bankofamerica.com/deposits/manage/faq-routing-numbers.go if you select Texas).
https://www.routingnumbers.info/api/data.json?rn=111000025 shows it as well. Given that it seems like the frbservices.org site ought to be showing it even tho it isn't?
","['usa', 'bank']",
"EEG data, specifically for alzheimer's?","
Does anyone have any clues on open (or reasonably scrapeable) sources of EEG data, especially from Alzheimer's patients?
","['data-request', 'medical']","There are two datasets from the UCI Machine Learning Repository related to EEG, but not specific to Alzheimer's patients.This data arises from a large study to examine EEG correlates of genetic predisposition to alcoholism.It contains measurements from 64 electrodes placed on subject's scalps which were sampled at 256 Hz (3.9-msec epoch) for 1 second.All data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset. The duration of the measurement was 117 seconds. The eye state was detected via a camera during the EEG measurement and added later manually to the file after analysing the video frames. '1' indicates the eye-closed and '0' the eye-open state. All values are in chronological order with the first measured value at the top of the data."
List of abbreviations and acronyms,"
I am searching an list of abbreviations,acronyms which should be downloadable as a sql table or json or sth. like that so no api cause it might be not fast enough or has a limit like this one: http://www.abbreviations.com/abbr_api.php
Of course the data needs to have two columns:
abbr and the correct name
but it would be nice to have extra information like categories.
Edit:
I would like to have English acronyms but more languages would be nice as well.
Edit:
Think that this list is a good example but unfortunately not so easy to parse: http://en.wikipedia.org/wiki/List_of_acronyms
","['data-request', 'language']","I found a github repository that scrapes the wiki list of roughly 6000 acronymshttps://github.com/krishnakt031990/Crawl-Wiki-For-Acronymsraw acronyms fileand then I wrote this python script to read that code's output and clean it up, as well as put it into a valid CSV (gist)writes this CSV output (tab separated): gist (still needs some cleaning)sample header:"
Is there any way to get a package's resource's field names/datatypes with downloading the entire resource?,"
The CKAN <site>/api/3/action/package_show API provides a lot of metadata, but for tabular (row-column) resources I don't see any way to get the field names and datatypes other than by reading the resource itself and probably guessing at the datatypes.  Am I missing anything?
","['api', 'ckan', 'okfn']",
Animal movement dataset,"
I am looking for a animal movement dataset  with at least 50  animals recorder for at least 100 times all together.
I know https://www.movebank.org/node/2 but I didn't find what I need.  
Can someone help me?
","['data-request', 'geospatial', 'time-series', 'biology']",
Public datasets containing less-boring and more detailed data,"
I'm looking for datasets, which allow drilling down to something more spesific and less published than datasets, which can only answer to simple questions like ""what is the anti-social behavior rate in certain cities"" or ""what percent of youngsters are not microchipped"".
My intent is to try different JavaScript-libraries for the purpose of presenting data visually. I'd prefer structured data in fileformats like xls, csv and rdf. I also want to challenge myself and force myself to find best ways for letting user of a web-based user interface to feel that he is in control of the information and thus he is able to get insights from it.
Datasets, which I could consider interesting enough include the following examples:

work related: employee names, roles, rooms, buildings, units, departments + employees' work related skillset, their most common personal traits, willingness and ability to learn a, b and/or c
mental health related: people diagnosed as having a schizophrenia, tried treatments, success rates of treating symptoms by changing amount of nutrients, mood changes after jogging
sales related: customer order history, product metadata, task processing times (machines, employees and customers separately), similar products
social happenings related: easiness to approach certain kind of people, typical starting phrases between those who have never met before, less obvious methods for suggesting something

I have a smallish collection of links to the open data portals like Data.gov.co.uk and European Union Open Data Portal, but I have a feeling that they do not contain, what I'm looking for. Any suggestions?
",['data-request'],"The go-to for random, interesting datasets comes from this article:100+ Interesting Data Sets for StatisticsHere are some quotes from the article based on your question:How do gender and mental illness affect crime? This data set was collected explicitly with that question in mind.There’s a lot of data from a series of online personality tests available here.Who receives H1-B visas?List of the most frequently searched-for data (google)etc"
List of all NANP area codes and central office / exchanges and their geographic location?,"
I'm looking for some open data that would list every area code in the NANP.  And all the 3-digit exchanges that exist for that area code.  And what geolocation they relate to.
I have found some of this data in a smattering of Wikipedia pages, for example:
http://en.wikipedia.org/wiki/List_of_North_American_Numbering_Plan_area_codes
Which lists all the area codes, and links out to detailed pages about each area code, such as:
http://en.wikipedia.org/wiki/Area_codes_416,_647,_and_437
And while I could likely build a scraper to get some of this data collected, there are other Area codes on Wikipedia that do not list the exchanges / central office codes.
For example:
http://en.wikipedia.org/wiki/Area_codes_201_and_551
And also there is absolutely no consistency between the individual pages, so building the scraper is going to be a huge task.
There used to be a website called areacodedownload.com that had some of this content, it can still be seen at archive.org
http://web.archive.org/web/20080302180916/http://www.areacodedownload.com/201/index.html
Does anyone know of any open data source for what I am looking for?
Edit: Ok, I think I just found a resource that has pretty much what I want:
http://www.nationalnanpa.com/enas/coCodeReportUnsecured.do?reportType=7
But this only covers the USA, I need Canada as well.
",['data-request'],http://www.nationalnanpa.com/nanp1/npa_report.csv with definitions found in http://www.nationalnanpa.com/area_codes/AreaCodeDatabaseDefinitions.xlsLook through nationalnanpa.com's sitemap has some valuable resources.http://cnac.ca/data/COCodeStatus_ALL.zip gives you Canadian codes.
Using Google Maps Data,"
Is it possible to obtain a dataset of all search results in a google maps search? For example: if I want a list of all gas stations in Chicago, complete with addresses, store name, latitude-longitude coordinates etc. 
Is such a data set against Google user agreement terms? I only plan on using the data for academic research questions. 
","['licensing', 'geospatial']","Yes, it is possible, using the Google Places API.Just for completeness sake: This is most definitely not open data. For an open alternative, have a look at Phil's answer about Open Street Maps.If your usage complies with Google's terms depends on what exactly you plan to do with the data. I guess section 10.1.3 of the Google Maps/Google Earth APIs Terms of Service will be most relevant for you:(a) No Unauthorized Copying, Modification, Creation of Derivative Works, or Display of the Content. You must not copy, translate, modify, or create a derivative work (including creating or contributing to a database) of, or publicly display any Content or any part thereof except as explicitly permitted under these Terms. For example, the following are prohibited: (i) creating server-side modification of map tiles; (ii) stitching multiple static map images together to display a map that is larger than permitted in the Maps APIs Documentation; (iii) creating mailing lists or telemarketing lists based on the Content; or (iv) exporting, writing, or saving the Content to a third party's location-based platform or service.(b) No Pre-Fetching, Caching, or Storage of Content. You must not pre-fetch, cache, or store any Content, except that you may store: (i) limited amounts of Content for the purpose of improving the performance of your Maps API Implementation if you do so temporarily (and in no event for more than 30 calendar days), securely, and in a manner that does not permit use of the Content outside of the Service; and (ii) any content identifier or key that the Maps APIs Documentation specifically permits you to store. For example, you must not use the Content to create an independent database of ""places"" or other local listings information.(c) No Mass Downloads or Bulk Feeds of Content. You must not use the Service in a manner that gives you or any other person access to mass downloads or bulk feeds of any Content, including but not limited to numerical latitude or longitude coordinates, imagery, visible map data, or places data (including business listings). For example, you are not permitted to offer a batch geocoding service that uses Content contained in the Maps API(s)."
Are there open historic cloud cover data files available?,"
I'm thinking of compiling a map showing how often it was sunny at a given location on a given day of the year, one map for every day of the year. The exact definition of ""sunny"" will depend on what cloud cover data I can obtain.
Are any such data sets freely available? I've found MODIS image archives, but they are fairly limited, especially in that they are raw images, not interpreted as cloud cover. I've also found a company that seems to sell exactly what I want, but I don't expect this to come cheap.
Can I get historic cloud cover data for free?
","['data-request', 'weather']","For the satellite era, the best you can get is likely reanalysis data:A meteorological reanalysis is a meteorological data assimilation project which aims to assimilate historical observational data spanning an extended period, using a single consistent assimilation (or ""analysis"") scheme throughout.The two most widely used reanalysis are the ones from ECMWF and NCEP.  Of those, the former is European and semi-free, whereas the latter is fully free.  After making an account, you can download data through this page at UCAR.  Hourly data includes fields like Cloud Amount/Frequency, and Cloud Liquid Water/Ice.Normal users of this data are atmospheric and climate scientists, so you might need to be quite careful to see you are interpreting the data correctly.For before the satellite data, there exists no global record of cloud cover."
Interested in the history of the Washington Data Processing Center [closed],"







Closed. This question is off-topic. It is not currently accepting answers.
                                
                            











 This question does not appear to be about open data within the scope defined in the help center.


Closed 8 years ago.







                        Improve this question
                    



I'm interested in the Washington Data Processing Center that was opened on April 1, 1966.
My questions are:

What year did it close?
What was the street address of the center? 
Are there any early photos of the building that housed it?

",['data-request'],
Related Books API,"
I am looking for an API where I can search for a book and retrieve a list of books related to it. It would also be useful to have this kind of search for authors.
The Spotify API has a function just like this, but for musicians. 
","['api', 'books']",
What's a good file format for presidencies of countries? [closed],"







Closed. This question needs details or clarity. It is not currently accepting answers.
                                
                            











Want to improve this question? Add details and clarify the problem by editing this post.


Closed 8 years ago.







                        Improve this question
                    



I want to build a file with all the data of the different presidents of a country. Is there a defined JSON format to represent this data?
For example:
{
    name: ""President A"",
    Assumed: '01-01-2014',
    ...
}

","['government', 'data-format']",
What's a good file format for sharing 3D models of cities?,"
Some councils have 3D models of the buildings which they're considering sharing. What would be a good format to encourage them to use, if possible? I had thought 3DS would be the standard, but according to Wikipedia, the shortcomings are pretty limiting.


All meshes must be made of triangles.
All texture filenames are limited to the 8.3 DOS format.
The number of vertices and polygons per mesh is limited to 65536.
Accurate vertex normals cannot be stored in the .3ds file. Instead ""smoothing groups"" are used so that the receiving program can recreate a (hopefully good) representation of the vertex normals. This is still a hold-over legacy for many animation programs today which started in the 1980s (3DS MAX, Lightwave and trueSpace still use smoothing groups, and Maya did up to v2.51).
Object, light and camera names are limited to 10 characters. Material names are limited to 16 characters.
Directional light sources are not supported.


","['releasing-data', 'data-format']","In answer to the original question, you should look at CityGML – this is a standardised format that's being heavily used by cities, particularly in Europe. It handles model definition, textures, various feature types (buildings, bridges, street furniture, all sorts) and has been built to keep the data about buildings and other objects intact (eg. which part is the roof and which is the wall). In fact it has various levels of detail that can be used depending on your need, so you could even go as far as modelling the full interior of a building down to the fixtures and fittings. Here's an example CityGML building at LOD2 (not the worst, not the best):That building is actually within a new open building library that I'm creating with the guys at Mapzen that uses ViziCities (I'm the creator of ViziCities). We hope to release it publicly very soon.Failing that – collada or OBJ or fairly well used by cities for sharing buildings."
Average Job Salary by Title/Location/Etc. (US or Intl),"
I'm trying to find an open data source to use for estimating average salaries based on job titles and locations. I had initially considered using Glassdoor's API, but it seems to be too basic for my needs. 
Searching further, I stumbled across the Department of Labor's dev portal, but I'm having a difficult time grokking it for my specific purpose. It sounds like the data I'm looking for is tucked away in the BLS (Bureau of Labor Statistics) datasets, but there is so much information here that I can't seem to parse out what I actually need.
Does anyone with more detailed knowledge of the DoL's data sources be able to help me out here? Or could someone suggest a simpler API that provides this sort of data?
","['data-request', 'data.gov', 'labor']","I recommend Occupational Employment Statistics. Includes approximately 800 job categories/titles (Standard Occupational Classification). Reports estimated employment, average wages and 10th/25th/50th/75th/90th wage percentiles.The upside is that it's pretty easy to download or hit the API. The downside is that there are quite a few ""holes"" in the data, either due to confidentiality issues (e.g., one large company in an area employing the majority of, say, Aerospace Engineers can lead to those values being blanked out) or insufficient sample size.But for free / publicly available, geographically detailed stats on occupations in the US, it's pretty much the only game in town.XLS files for metro and multi-county nonmetro areas here: http://www.bls.gov/oes/tables.htm.For API access, it's similar for most BLS data. Example:The last component is the BLS ""seriesID"". Breaking it down:For additional info on codes, see http://download.bls.gov/pub/time.series/oe/ (esp. the ""oe.area"" and ""oe.occupation"" files). It's a little misleading because this dataset is not actually a timeseries; only the latest year (currently 2014) is available at any given time."
Hourly data on whether it is snowing for a particular location (NYC),"
I am trying to get hourly information on whether it is raining/snowing in a particular location at that point in time (NYC to be exact).
Currently, I am looking at NOAA's QCLCD hourly weather data from the NYC Central Park weather station. The data contains a WeatherType column that states if there is rain or snow. However in a previous question, I asked about inconsistencies with the HourlyPrecip column - there are instances where the WeatherType would indicate rain, but the HourlyPrecip would show 0 inches - and it turns out that the WeatherType is a 3-hour summary of conditions.
The HourlyPrecip column is therefore what I need for the presence of rain. However, there is no corresponding column for snowfall. I took a closer look at the dataset and found that there are some >0 entries for HourlyPrecip when the weather condition indicates ""Snow"" (SN). Does that reflect the hourly snowfall (ie does HourlyPrecip reflect the hourly snowfall as well as rain)?
Here is a small slice of the data that illustrates my point (T= trace amount):
        Date   Time   WeatherType   DryBulbCelsius   RelativeHumidity  WindSpeed   HourlyPrecip 20130302 2011         -SN            0.6               75         9              20130302 2049         -SN            0.0               82        11              20130302 2051         -SN            0.0               79        10            T 20130302 2056         -SN            0.0               79         7              20130302 2151         -SN           -0.6               78        10            T ...  20130318 1851    +SN FZFG           -0.6               96         8         0.11        20130318 2051      -SN BR           -0.6               92         8         0.12 20130318 2103      -SN BR           -0.6               96        10              20130320 2351         -SN            2.8               55         0            T 20130325 1249         -SN            3.0               76        14              20130325 1251         -SN            2.8               76        17            T
I have emailed NOAA to enquire about this but their only contact email on the site appears to be geared towards ordering climatological data from them, so I am not sure if I will get a response. Wondering if anyone here has experience with this.
","['data-request', 'weather', 'noaa']",
What's the train frequency at all stations in the UK?,"
I've been trying to find out how many trains stop at each UK train station, each day (or year, month, doesn't really matter but the more specific the better). But can't find any good sources.
Could also derive it from time-tables, but can't seem to find any good time tables in .csv or .xlsx...
Anyone can help me out?
Would be absolutely amazing!!!!
","['data-request', 'uk', 'public-transport']",
NOAA QCLCD weather data - inconsistencies in hourly data?,"
So I was looking at the QCLCD hourly weather data from NOAA, and I noticed something weird about it. There's a column for hourly precipitation amount (HourlyPrecip), and there's also a column for the current weather condition (WeatherType). However, there appear to be many instances where the WeatherType reflects rain whereas the HourlyPrecip column does not show any rain.
Here's a sample of the data that shows the issue i'm talking about, for a particular station (NYC Central Park):
Date Time WeatherType DryBulbCelsius RelativeHumidity WindSpeed HourlyPrecip
20130801  951         -RA           22.8               71         0            T
20130801 1031      -RA BR           21.1               87         3
20130801 1047      -RA BR           21.0               81         5
20130801 1051      -RA BR           20.6               87         5         0.01
20130801 1120      +RA BR           20.0               90         0
20130801 1132      +RA BR           19.4               93         5
20130801 1144      -RA BR           19.4               93         0
20130801 1151      -RA BR           19.4               93         0         0.15
20130801 1159      -RA BR           20.0               93         6
20130801 1211      -RA BR           20.0               93         9
20130801 1219      -RA BR           20.0               90         6
20130801 1230      -RA BR           19.4               93         6
20130801 1251       RA BR           19.4               90         5         0.09 
As you can see, these columns all indicate some degree of rain (RA) in the WeatherType column, but many do not show hourly precipitation.
Does the WeatherType reflect some sort of aggregated weather condition over a few hours, or is the data wrong (unlikely because this issue affects a large percentage of observations)?
","['weather', 'noaa']","So I emailed the NOAA, and they responded pretty quickly with clarification (props to them!)Q: My understanding of the ""WeatherType"" is that it is an ""abbreviated 3-hourly weather observations"" (from the QCLCD summary at https://data.noaa.gov/dataset/quality-controlled-local-climatological-data-qclcd-publication ). Is it more of a 3-hour summarized outlook of the weather, or a spot determination of rain/snow/haze etc?""A: No, it's hourly, not 3-hourly. It's a spot determination at the time of observation.As for the HourlyPrecip column, the measurements are only taken hourly, so there will only be measurements at 9.51, 10.51, 11.51, etc. "
HealthCare Finder API: Rate Limit?,"
I am trying to determine what the limitations are for someone making calls to the HealthCare Finder API. Specifically, does the HealthCare Finder API have any sort of per minute, per hour or per day rate limit for calls to the API?
",['healthcare-finder-api'],
What standards exist for accessibility of open data?,"
Suppose we have data under an open license and in some standard machine readable format. What has to be considered on top of that with respect to making the data accessible to people with disabilities, or their tools? Do any standards or best practice guidelines exist for that? 
I am roughly aware of WCAG and ISO/IEC TR 29138-X:2009 as well as some key accessibility regulations and intiatives in the US and Europe (see my notes here), but none of them seem to really cover data.
Update: I am especially interested in scientific data, much of which can not usefully be displayed in tabular form – think Magnetic Resonance images or spectra, genome sequences and their annotations, or phylogenetic trees. 
",['standards'],
Alcohol consumption and reaction time,"
Anybody have a source for experimental data on alcohol consumption and reaction time?    
","['data-request', 'medical', 'biology']","cdc is probably your best bet. start here:
http://www.cdc.gov/alcohol/fact-sheets/alcohol-use.htm"
What are best practices for where to answer agency specific Open Data Policy implementation questions?,"
USAID recently launched a Frequently Asked Questions page to handle Q&A concerning their policy ADS 579.
These Q&As are directed at both internal and external audiences.
I could see posting the questions on this site, but based on the questions, it seems appropriate to have them on USAID's website.
How have others approached this?
","['releasing-data', 'best-practice']","this is a ""depends"" question, but i'll lean to always having the answers on your site. you are the authority. you are releasing the data. you are in control.
bringing them here could help alert people to the data and the questions, as well as help crowd source solutions or answers you are seeking.
there's a saying called ""own your data"" and i believe this falls under it as well. "
Data Inquiry: Collections of common objects with attributes,"
Does anybody know if there is any publicly available collection of common objects, animals, events, and things which lists categorical attributes?
Such a database might look the following (if inefficiently organized):
object  aquatic bird mammal domesticated man-made made-of-wood
dog     0       0    1      1            0        0 
door    0       0    0      0            1        1
ostrich 0       1    0      0            0        0

I have been playing around with ConceptNet5 for a few days now but don't feel that it is consistently accurate enough for my needs. I would rather have a smaller database which has been constructed by hand if possible.
",['data-request'],
What product is the Australian government Meteor made using?,"

METeOR is Australia’s repository for national metadata standards for health, housing and community services statistics and information. - http://meteor.aihw.gov.au/

If I want to build a open data repository based with ISO 11179 is it possible with Meteor? Is the code for this available to work as a system on its alone?
","['government', 'tool-request', 'metadata', 'australia']",
Searching for list(s) of babynames containing huge (10k+) amounts of unique names,"
I am looking for datasets or huge lists of human forenames. There's plenty of websites that curate lists of names. But none of these seems to offer functionality to export either raw data/lists of names, nor to list more than a few dozen names per page.
My criteria to the data are:

each entry needs be unique
each entry needs be human readable (not just a random collection of letters such as: quwertzpl)
entries need to number 10'000+ (ten thousand and/or more)

","['data-request', 'names']","The best source of international human given (first) names comes from a German computer magazine. The text file has nearly 50k names that are classified by likely gender, and how popular in each country. It's carefully curated and has a friendly license (GNU Free Documentation License 1.2).The file can be downloaded here : ftp://ftp.heise.de/pub/ct/listings/0717-182.zip (name_dict.txt contains the data).Archive Link: https://web.archive.org/web/20200414235453/ftp://ftp.heise.de/pub/ct/listings/0717-182.zipInstead of parsing this file, you can use the python port SexMachine (really) - package and github repo. I'm sure other languages have their own ports. There is also a windows executable (details).(my reference)For US baby names, you can use the Social Security Admin's download (overview) and link to data. This data can be national or on the state level, and going back to the late 19th century.To safeguard privacy, we restrict our list of names to those with at least 5 occurrences.You'll also find ports of this data to various languages."
Consumption data of gasoline by month and city available?,"
Any idea if there is a public source of gasoline consumption data for US cities?
I am looking at predicting changes in gasoline consumption as a function of recent technological innovations.
","['data-request', 'city', 'energy']",
"Where to host a public KML/GPX/OSM map file? (preview, map links, statistics, conversion)","
I have a few KML files that I would like to share with the public.
Google suggests hosting them on Google Drive, but I would prefer a platform that offers more map-oriented features. Datahub does not offer any map-oriented features either.
Accessed via an easily sharable URL, the page must show to the visitor:

A preview of the KML file, for instance a dynamic map if there is not too much data, or a static map if there is to much data to show dynamically.
Links to map services integrating the data, for instance http://maps.google.com/maps?q=http://example.com/thedata.kml and equivalents with OpenStreetMap, Bing, Wikimapia, etc. See here for more link examples.
Statistics: number of points, etc.
Buttons to download the files as KML/GPX/OSM formats, whatever the format they have been uploaded with (the platform performs the conversion, server-side)
Show license of the file, title, description. Bonus for allowing the public to leave comments about the file. The uploader should be able to choose the license, at least public domain and CC-BY-SA should be available choices.

Must work with 100k+ locations files.
Ideally, The uploader should be able to upload in similar formats like GPX/OSM.
Bonus if the platform allows visitors to download a part of the data, for instance only locations in Indonesia.

How it could look like:

","['releasing-data', 'geospatial', 'openstreetmap', 'kml']",
Where can I find massive and high dimensional survival datasets,"
I am working on developing some high-dimensional survival analysis methods with R, but I do not know where to find such high-dimensional survival datasets.
Could anyone tell me where to find such datasets, for examples the data used in:

""Predicting survival from microarray data—a comparative study""
Dutch breast cancer data van Houwelingen et al. (2006), 295*24885
DLBCL data Rosenwald et al. (2002), 240*7399

Or any other massive high dimensional survival datasets?
","['data-request', 'medical', 'programming']",
Searching for Open Data Dataset That is No Longer Online,"
Many questions are posted here in search of a specific dataset that is either no longer online, or has died from linkrot, or a combination of the two. What is the best way to get around this? Or rather, can these datasets be recovered?
","['data-request', 'best-practice', 'search-engine']","The Memento Web and the Wayback Machine are two possible solutions:The Wayback Machine by the Internet Archive is your best friend for all things that were once online, and even some things that still are, if you want to compare changes.From Wikipedia:  The Wayback Machine is a digital archive of the World Wide Web and other information on the Internet created by the Internet Archive, a non-profit organization, based in San Francisco, California. It was set up by Brewster Kahle and Bruce Gilliat, and is maintained with content from Alexa Internet. The service enables users to see archived versions of web pages across time, which the Archive calls a ""three dimensional index.""If you have a dead link, simply paste it into the search input element of Wayback Machine.Alternatively, you can type https://web.archive.org/web/*/DEAD_LINK'S_URL directly into the address bar of your favorite browser.Los Alamos National Lab has been offering the Memento Web project which unifies search across the archives.Some search engines may provide you with a cached version of the page where the dataset resided (possibly, the dataset files as well).If the steps above fail, you may considerYou can also have a look at http://academictorrents.com to see if your dataset is present there."
What is the status of OKFN's Open Product Data project?,"
Open Product Data (also known as Product Open Data) is a project run by OKFN. Its main goal is to build a public database of product data. There are already several questions and answers related to this project here on Open Data Stack Exchange. However, the main website has been dead for some months now, and the official mailing list is deserted.
What is the current status of this projects? Are there any plans or ongoing initiatives to revive it?
","['products', 'okfn']",We're actually looking for a new maintainer for the project.The new version is running on Django and the source code is here.
Global map of protected areas by IUCN category,"
The International Union for the Conservation of Nature (IUCN) lists seven protection categories for different areas that serve to protect the natural environment and biodiversity.
Is there any international database listing all areas worldwide with their category and exact boundaries (i.e. a polygon of the boundaries, rather than just a single location)? Perhaps as a layer loadable in Google Maps or Google Earth, or on a separate map application like the US Wilderness map.
","['data-request', 'geospatial', 'environment']","Protectedplanet.net comes pretty close to what I'm looking for.  It's a layer on top of Google Maps that does show protected areas in various shades of green, giving detailed information upon closer inspection.  Information is probably not complete and it takes a few more clicks to distinguish different levels of protection than I would like, but it's still a very interesting resource that goes very far into what I was looking for in the question.
Screenshot Protected Planet, taken 2015-12-07."
How can I download the Product Open Data database?,"
I am wanting to find a worldwide open nutritional database.
I know there have been questions about this before and the answers all refer to USDA's Agricultural Research Service and OKFN's Open Product Data sites.
The USDA one is very much restricted to US foods (I am in Australia) and, from what I can tell, doesn't include barcode info.
The OKFN database seems perfect, however, the site has been down since at least Dec '14.
Does anyone know where I could get a copy of the Product Open Data database?
I do not need an API, just the data will suffice.
About the other post:
I have seen a thread with almost the same question. That threat lead me to write this question as the accepted answer mentions the Product Open Data database, but, as I explained earlier, that website has been down. My question allowed me to find a way around this which is exactly what I explained I was looking for. So, no, not a duplicate.
","['data-request', 'food', 'barcodes', 'okfn']","The Wayback Machine is always your best friend; Here's the data from 2014-02
http://web.archive.org/web/20140209011312/http://product-open-data.com/download/OPD Product Browser Web RepositoryThere's also open food facts"
Where can I find publicly available data about internet usage?,"
I'm searching for a data set in the public domain that quantifies degree of internet usage on a global basis for small geographic areas.  For example is there a data set that shows total traffic (e.g. in GBs) consumed in each postal code? I'm particularly interested China.
My initial thought is that some organization like Akamai or other kind of CDN or backbone provider might have published something.  But my searches have come up empty.
","['data-request', 'internet']",
New artists per year/month for music streaming services,"
I'm trying to get some stats for the number of new artists on music streaming service per year or month, weather that's Spotify, YouTube, Beat music, etc. it doesn't matter.
I've tried searching for this information somewhere but I can only find that Spotify has 20,000 new songs per day. I could maybe make the assumption that every 15 songs is a new artist but that probably isn't very accurate.
","['data-request', 'music']",
Looking for home sale data,"
I'm looking for home sale data that includes info such as an address, sale price, home type, sq. ft., etc.  Where (what dataset(s)) can I get that data from?
","['data-request', 'real-estate']",
"Where can I get NY small businesses data, including revenue, number of employees etc?","
I'm helping a nonprofit reach small businesses in NY. Looking specifically for revenue, number of employees, type of business and ethnicity of the owner. Is there any place I can find such information?
","['data-request', 'usa', 'business']",
Historic data on number of houses and number of households in UK?,"
I'm looking for historic data (ideally going back to the 1920s, but whatever is available) on:

the number of houses
the number of households

in the UK.
I've been hunting on the ONS site and gov.uk without success. 
Does anyone know where I could find this data?
",['data-request'],
Pictures of Black Bottom (Detroit neighborhood replaced with Lafayette Park in the 1960s),"
I am looking for pictures of Black Bottom, a Detroit neighborhood demolished and replaced with Lafayette Park in the 1960s. It was the bithplace of the genre known as Detroit blues.
Landscapes, buildings, life scenes, people, anything.
Pictures must be reusable in Wikipedia (compatible with Creative Commons Attribution-ShareAlike 3.0).
Wikimedia Commons does not seem to have any:
https://commons.wikimedia.org/wiki/Category:Historic_districts_of_Detroit,_Michigan
","['data-request', 'images', 'historical']",
Simulated dataset agent based gps,"
I am about to do a project that involves ""trajectory"" prediction of human gps tracks. Preferably I need data of ""agents"" over months. In need some sort of ""routine patterns"" in it (e.g. work <-> home). 
I was wondering if there are any public available data sets that are simulated (because of the privacy issues of such public data). 
I am already aware of actually a public real data set from Microsoft:
http://research.microsoft.com/en-us/downloads/b16d359d-d164-469e-9fd4-daa38f2b2e13/
However, to start with I'd prefer a simulated data set (no gaps, etc.).
Has anyone knowledge of such data sets? 
Alternatively, I'd be thankful if someone knows an easy to use tool that can simulate agents and gps trips - would be also ok to just have car tracks.
P.S.: other public real data sets are also welcome :)
","['data-request', 'geospatial', 'tool-request']","To simulate GPS tracks, consider using the Optimal Roadtrip code from Randy Olson.Steps (taken directly from ipython notebook):Construct a list of road trip waypointsGather the distance traveled on the shortest route between all waypoints (using Google Maps directions)Use a genetic algorithm to optimize the order to visit the waypoints in Visualize your road trip on a Google map (not important for your application)"
Datasets that input GPS and output historical time-series,"
I'm wondering what kind of historical time-series data I can get given GPS coordinates as input.
More than anything I'm interested in:

Temperature
Precipitation
Humidity
Irradiation

I'm largely interested in environmental data, but anything that could be identified by the cross section of a date and a gps coordinate would be of interest. Also, I'd prefer if it included data on the European continent. 
Does anyone have any suggestions for where I may acquire such data?
","['data-request', 'geospatial', 'historical', 'time-series', 'environment']","There Daily Global Weather Measurements, 1929-2009 (NCDC, GSOD) dataset contains:A collection of daily weather measurements (temperature, wind speed, humidity, pressure, &c.) from 9000+ weather stations around the world.Global summary of day data for 18 surface meteorological elements are derived from the synoptic/hourly observations contained in USAF DATSAV3 Surface data and Federal Climate Complex Integrated Surface Data (ISD). Historical data are generally available for 1929 to the present, with data from 1973 to the present being the most complete.The data is global, including ocean measurements, will contain frequent daily measurements as well as latitude and longitude coordinates.One common way to get this dataset is through the hosting by Amazon Web Services, and the original details are found at the NOAA site.Caveat: the license saysThis data set can only be used within the United States.So perhaps your 1 year of free tier AWS instance can be set up in the US."
CPU instruction set,"
I would like to have a structured dataset about instruction set by CPU. The data should include the number of cycles, ALU, FPU used, etc.
Does this exist somewhere?
","['data-request', 'computing']",
Variable/multidimensional json record structure OpenFDA,"
Arguably this is more a general programming question, and I should keep learning; yet, if advice or guidance is forthcoming I wanted to try asking: what is the best way to look for substances that could appear in a variety of OpenFDA fields?
Using PHP, I can extensively construct a variety of query patterns and cash json/text files of records for regex parsing for specific items in specific fields, but am having trouble facing the variable record format of responses to trim out api responses (or parts of responses like npc codes) as they happen (are received) to reduce time/disk space/etc.
I am digging a little deeper into Python, but I suspect all that will give me is more sophisticated tools for working with cached files in a directory (which may not be anything to sneeze at). Not able to work with BI tools at the moment but I did start to look at open source options here, but that seems overkill for the data ""discovery"" tasks I have yet to do/try.
My apologies is this has been addressed in elasticsearch or other introductory kinds of queries (questions/3244/ or questions/3321/), but nothing seemed to address a specific strategy for the variable record structure issue on the receiving end (me) -- maybe that means my approach is right and my skills (and tools?) have to catch up...or maybe a quick look at this from you experts will quickly lead you to say ""try this instead...""
At risk of droning on with only a vague example:  Looking for Retinol (in drug/events for now) which could come up in any number of name fields it seems I'd have to get & parse ~1900 files/records/safetyreportids and THEN process the possibilities from the cache.  Is that the ""right"" idea?
Thanks to all.
","['openfda', 'json']",
Map of Orange County (CA) buildings,"
I'm plotting a map of the Los Angeles metro area, and I'm using TileMill. I've loaded different layers for the geographical data, and wanted to add buildings as well. So I found this map for the LA county link which does exactly what I need. 
But I noticed it's in fact missing the whole Orange County area, since it's a different county of course. 
On the website of Orange County's open data I was not able to find a similar file, so I was wondering if there was any other source I was unaware of that might have the file I'm looking for. 
Thanks in advance for any help!
","['data-request', 'usa', 'geospatial']","As someone who actually has a fair bit of knowledge into the technological progress Orange County, California has made in the way of GIS, I can say that the data more than likely still does not exist for the whole county. Major cities such as Anaheim, Santa Ana, Irvine, Newport Beach may have building footprint shapefiles (I know for a fact that Anaheim and Irvine do). But many of the smaller cities have not done the work from the last time I can recall having the most relevant information (2012).Orange County has only recently taken up the cause of digitizing its infrastructure to data/GIS. They originally hired the utility companies to create the parcel shapefile layout for the county and that was as recent as 2009. The parcel shapefiles have been publicly available for Orange County, CA since 2012 and the most recent data which has sufficient attribute data is for 2014."
Novel Blurb Corpus,"
I am looking for a corpus of fiction book blurbs.
With at least 10,000 entries.
Preferably with a lot more.
I do not care if it is a single publisher (etc) or many.
It should be annotated with author, publisher etc.
Ideally would be annotate with Genre and Subgenre as well.
","['data-request', 'corpora']","Blurbs, or short descriptive material to promote a book, may be impossible to legally share do to individual copyrights of the authors or publishers.The Goodreads API has many endpoints, and they include this note:Book cover images, descriptions, and other data from third party sources might be excluded, because we do not have a license to distribute these data via our API. In contrast, the book metadata can be shared (ISBN, author, publisher, etc). See, for example, the Book-Crossing Dataset.So, in order to get a big data set of blurbs, you'd have to contact (large) publishers and ask for access. I noticed you have university affiliation, so you should mention that it is for non-commercial purposes."
Open database of filename extensions,"
Filename extensions like "".doc"" or "".licx"" are usually associated with a type of file, and are sometimes strongly associated with one or several pieces of software.
Is there an open database of these?

Extension
Associated file format(s)

Description
Optionally, what applications are often associated with it


","['data-request', 'data-format', 'software']",
historical transactions for bidders in e-auctions,"
I need a dataset for my research, which contains historical transactions for bidders in e-auctions for example: profile information, number of bidding auctions, number of wins in auctions, and number of canceling bids.
",['data-request'],
"How would I find on iMDb, all male actors with movies debuts between ages 20 and 30?","
It would be like asking each male actor personally: Which movies were you in when you were between the age of 20 and 30? To be clear, that would be 30 years and 364 days old.
For example, for today, this would find me actors like: Miles Teller (Whiplash), Ellar Coltrane (Boyhood), Evan Peters (Kick-Ass), Aaron Taylor-Johnson (Kick-Ass)
But of course I'd like an overview of all time, so also movie titles that had male debutants aged 20-30 in 1970 or in 1889.
I think this would involve some query that compared Actor-Birthdate to Movie-Shooting-Date.
This might be conceptually as follows:
IF **Actor-Birthdate** -/- **Movie-Shooting-Date** > 20 but < 30
  then give **Movie-Name**.

This query or algorythym or function has to be performed on every single male actor, I guess.
I would need actor datasets with their D.o.B, the movies they made and the film shooting dates of those movies.
I suppose the IMDb site itself does not offer tools to do this, so I guess it would have to be imported into some database program like SQL or Wandora. Or Excel or MS Access  
I'd be very happy if anyone had any idea how to do this.
","['data-request', 'film']",
Open database of ingredient names?,"
I'm making a recipe app. It will let users create their own recipes, and to save them the hassle of writing ingredient names their selves it would be nice to do a search in a database instead. Do anyone know if there exists a dataset with this data anywhere?
example data:
Lettuce, Salmon, Strawberries, Minced meat, Salt, Cinnamon
","['data-request', 'food', 'recipes']","I think USDA.gov's NDB (full name: USDA National Nutrient Database for Standard Reference) would get you what you need.Download links and data metadata is available on the ""About the Database"" file at http://www.ars.usda.gov/Services/docs.htm?docid=8964. If you're looking solely for a list of food items, the latest Food Descriptions file is at http://www.ars.usda.gov/SP2UserFiles/Place/80400525/Data/SR27/asc/FOOD_DES.txtThere are many sites such as nutritionix.com, etc. which have APIs and have added additional commercial off the shelf ingredients like packaged goods, etc. too though so you might look into a more refined/complete collection as well. See http://www.nutritionix.com/api for information about their API."
Average height of males and females for each of the 50 US states: Where can I download the data?,"
Where can I download data for average height of males and females for each of the individual 50 states?
RAW data or SQL data is fine, it does not have to be charted or formatted - I can do that myself - just can't find any data.
","['data-request', 'usa']",
Where to get older digital OCR'd data sets of unsummarized US Census data?,"
I am trying to locate older unsummarized US Census data to do more research than just the statistics provided by the US Census Bureau.
I know the old Census Data itself is located on Archives.gov and Ancestry.com and is searchable.. but not for example names are not directly queryable in any mass form to generate statistics. In particular in addition to the normal categorical (i.e. Occupation) data and the numerical data, to do the analysis I want to attempt I require surnames in combination with this data. So for example I could do occupation to surname analysis by geographic region. 
I have seen Ancestry.com do stats (but you cannot request specific ones) but they are generic and do not account for name variations (SOUNDEX or similar) nor have any granularity or is one able to make any other correlations such as to wealth / value to occupation and surnames (for example).
I have seen other posts here in this forum, but none I have spotted contain surname data which is what I am specifically looking for. 

SE.OD BLS Raw Data
SE.OD Cenus Block Data

I have searched the following without success:

Data.Gov
US Census
Archive.Gov AAD


So I am looking for pre-1901 census data, in particular I would like the 1850 or 1860 AND the 1890 and 1900 census in its entirety. But I will take what years I can get... Ideas?

Note: Yes I realize this would be rather large data set of millions of rows.. but that is exactly what I am looking to obtain. 
","['data-request', 'usa', 'us-census']",
Orthophoto Rwanda Free Download?,"
I'm looking for Image datas for East Africa. Specifically for Rwanda. Does anyone know if such data are available at all free? My target is to digitize roads and buildings with the help of image datas.Thanks in advance.
","['data-request', 'images', 'aerial-photography', 'africa']",
finding online finance datasets,"
I am searching for finance datasets that has the following format
year,quarter,month,Company,S&P index,P/E ration,feature x,feature y, feature z....to test a machine learning prediction algorithm. Does anyone know where to find a good dataset online?
Actually I want year,quarter,month,Company,S&P index,P/E ration,feature x,feature y, feature z for a historical time period (i.e 2005-2009). 
Apparently yahoo finance, Quandl seems to have these but only for the current year. I have been searching high and wide but didn't find a API, dataset that has these features for a certain historical time period. Like for example 

For Google and Microsoft, for years 2005-2009, I want (Sector Price
  Dividend Yield Price/Earnings Earnings/Share Book Value 52 week low 52
  week high Market Cap EBITDA Price/Sales Price/Book).

","['data-request', 'finance']",
HealthCare Finder API Links Broken?,"
It seems that the HealthCare Finder API schema links are no longer working.  If you go to https://finder.healthcare.gov/#services and select any of the versions (or FAQ link) on the left-hand side, the URL updates, but only the API Overview page shows.  I have been to this site many times and have been able to access the schemas in the past, but over the last couple of weeks, nothing on the page updates.  If I go to the link directly (e.g. https://finder.healthcare.gov/#services/version_3_0) it only shows the Overview page.  Is the HealthCare Finder API broken?
",['healthcare-finder-api'],"Yes this looks like a bug on the site. The APIs themselves seem to be working fine, but the links to the documentation are broken. If you are simply interested in the XSD then you should be able to download it from https://finder.healthcare.gov/api/finder_api_v3.0.xsdIf you are looking for a working example, try the following curl request: "
HIOS Plan Year 2016 XSD Schema,"
Can someone provide a link to the new (plan year 2016) XSD schema for HIOS admin/plan/rate/etc. data exchange? There have been changes to the XML format for this year and we need to update our ETL packages.
The latest available at SERFF is PY2014, as there were no changes for 2015.
https://finder.healthcare.gov/#services/ is where it SHOULD be, but it's not there. (Also the site is broken at present...)
Also not at http://www.healthdata.gov/data/dataset/healthcare-finder-api 
Thanks.
","['data-format', 'healthcare-finder-api']",
