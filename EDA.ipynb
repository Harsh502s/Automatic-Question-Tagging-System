{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from gensim.models import word2vec\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Body Features Demographic Distribution\n",
    "\n",
    "print(\"Max length of the body: \", df[\"Body\"].str.len().max())\n",
    "print(\"Min length of the body: \", df[\"Body\"].str.len().min())\n",
    "print(\"Mean length of the body: \", df[\"Body\"].str.len().mean())\n",
    "print(\"Median length of the body: \", df[\"Body\"].str.len().median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of tag count\n",
    "sns.countplot(data=df, x=\"Tags Count\", color=\"blue\", palette=\"viridis\")\n",
    "plt.title(\"Distribution of tag count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Tag count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize tags\n",
    "tag_vectorizer = CountVectorizer(tokenizer=lambda x: str(x).split())\n",
    "tag_mat = tag_vectorizer.fit_transform(df[\"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get names of tags\n",
    "tag_names = tag_vectorizer.get_feature_names_out()\n",
    "type(tag_names), len(tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_names[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_freq = tag_mat.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store tag names and frequency as a pandas series\n",
    "tag_freq_ser = pd.Series(tag_freq.A1, index=tag_names)\n",
    "tag_freq_ser.sort_values(ascending=False, inplace=True)\n",
    "tag_freq_ser.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency top 50 tags\n",
    "fig = plt.figure(figsize=[20, 10])\n",
    "sns.barplot(\n",
    "    x=tag_freq_ser.iloc[:50].index,\n",
    "    y=tag_freq_ser.iloc[:50].values,\n",
    "    color=sns.xkcd_rgb[\"greenish cyan\"],\n",
    ")\n",
    "plt.title(\"Frequency of top 50 Tags\")\n",
    "plt.xlabel(\"Tags\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of tag frequency (top 500)\n",
    "fig = plt.figure(figsize=[10, 7])\n",
    "plt.plot(tag_freq_ser.iloc[:500].values, c=\"blue\")\n",
    "plt.title(\"Tag frequency distribution of top 500 Tags\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Tag ID\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of tag frequency (top 100)\n",
    "fig = plt.figure(figsize=[10, 7])\n",
    "plt.plot(tag_freq_ser.iloc[:100].values, c=\"blue\")\n",
    "plt.title(\"Tag frequency distribution of top 100 Tags\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Tag ID\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of tag frequency (top 50)\n",
    "fig = plt.figure(figsize=[10, 7])\n",
    "plt.plot(tag_freq_ser.iloc[:50].values, c=\"blue\")\n",
    "plt.title(\"Tag frequency distribution of top 50 Tags\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Tag ID\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot word count for tags\n",
    "wordcloud = WordCloud(\n",
    "    background_color=\"black\",\n",
    "    max_words=200,\n",
    "    scale=10,\n",
    ").generate_from_frequencies(tag_freq_ser)\n",
    "fig = plt.figure(figsize=[10, 10])\n",
    "plt.title(\"WordCloud of Tags\")\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text\"] = df[\"Head\"] + \" \" + df[\"Body\"]\n",
    "# Create a list of stopwords\n",
    "stopwords_nltk = nltk.corpus.stopwords.words(\"english\")\n",
    "stopwords_spacy = spacy.lang.en.stop_words.STOP_WORDS\n",
    "stopwords = list(\n",
    "    set(\n",
    "        stopwords_nltk\n",
    "        + list(stopwords_spacy)\n",
    "        + list(STOPWORDS)\n",
    "        + list(\"abdefghijklmnopqstuvwxyz\")\n",
    "    )\n",
    ")\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    return \" \".join(\n",
    "        [word for word in str(text).split() if word.strip() not in stopwords]\n",
    "    )\n",
    "\n",
    "df[\"Text_Uncleaned\"] = df[\"Text\"].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Word2Vec model from text column\n",
    "\n",
    "list_of_sent = [sent.split() for sent in df[\"Text_Uncleaned\"].values]\n",
    "\n",
    "w2v_model = word2vec.Word2Vec(list_of_sent, vector_size=100, window=5, workers=4)\n",
    "\n",
    "w2v_model.wv.most_similar(\"detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Body Feature for Modeling\n",
    "- #### Lemmatization\n",
    "- #### Remove stopwords\n",
    "- #### Remove extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def clean_body(text):\n",
    "    text = str(text).lower()\n",
    "    text = \" \".join([word for word in text.split() if word not in stopwords])\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "df[\"Text_Cleaned\"] = df[\"Text\"].apply(clean_body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Word2Vec model from text column\n",
    "\n",
    "list_of_sent = [sent.split() for sent in df[\"Text_Cleaned\"].values]\n",
    "\n",
    "w2v_model = word2vec.Word2Vec(list_of_sent, vector_size=100, window=5, workers=4)\n",
    "\n",
    "w2v_model.wv.most_similar(\"detection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
